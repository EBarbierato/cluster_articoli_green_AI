Scopus
EXPORT DATE: 21 July 2023

@ARTICLE{Birhane2022451,
	author = {Birhane, Abeba},
	title = {The unseen Black faces of AI algorithms},
	year = {2022},
	journal = {Nature},
	volume = {610},
	number = {7932},
	pages = {451 – 452},
	doi = {10.1038/d41586-022-03050-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140211182&doi=10.1038%2fd41586-022-03050-7&partnerID=40&md5=cca0b94eacf34064587ac09824bceef6},
	abstract = {Pivotal study of facial recognition algorithms revealed racial bias. [Figure not available: see fulltext.]. © 2022, Springer Nature Limited.},
	author_keywords = {Computer science; Ethics; Information technology; Machine learning},
	keywords = {Algorithms; Artificial Intelligence; information technology; machine learning; algorithm; Article; artificial intelligence; biometry; Black person; classification; clinical audit; commercial phenomena; face; facial recognition; gender; human; Internet; racism},
	correspondence_address = {A. Birhane; email: abebe@mozillafoundation.org},
	publisher = {Nature Research},
	issn = {00280836},
	coden = {NATUA},
	pmid = {36261566},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Hauer2022,
	author = {Hauer, Tomas},
	title = {Importance and limitations of AI ethics in contemporary society},
	year = {2022},
	journal = {Humanities and Social Sciences Communications},
	volume = {9},
	number = {1},
	doi = {10.1057/s41599-022-01300-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136102051&doi=10.1057%2fs41599-022-01300-7&partnerID=40&md5=41ac22d71a861c839b4f1ae32a9f019f},
	affiliations = {Department of Philosophy, Faculty of Philosophy and Arts, Trnava University in Trnava, Hornopotocna street 23, Trnava, 918 43, Slovakia},
	abstract = {Research into autonomous intelligent systems and AI platforms evolving over time through self-learning from data currently raises a number of thorny ethical and legal issues. Advances in robotics, artificial intelligence, and machine learning enable AI platforms to autonomously perform activities that have been strictly the domain of humans for centuries, such as writing a book, driving fast cars, or diagnosing serious diseases. The study describes current trends in the approach to ethical problems associated with AI, identifies specific ethical issues through examples, and analyses possible recommendations. The text emphasizes the ethical dimension of the development and implementation of new innovations in robotics and artificial intelligence and their impact on today’s society. © 2022, The Author(s).},
	correspondence_address = {T. Hauer; Department of Philosophy, Faculty of Philosophy and Arts, Trnava University in Trnava, Trnava, Hornopotocna street 23, 918 43, Slovakia; email: tomas.hauer@truni.sk},
	publisher = {Springer Nature},
	issn = {26629992},
	language = {English},
	abbrev_source_title = {Hum. Soc. Sci. Comm},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Satchwell2022,
	author = {Satchwell, Laura and Wedlake, Linda and Greenlay, Emily and Li, Xingfeng and Messiou, Christina and Glocker, Ben and Barwick, Tara and Barfoot, Theodore and Doran, Simon and Leach, Martin O. and Koh, Dow Mu and Kaiser, Martin and Winzeck, Stefan and Qaiser, Talha and Aboagye, Eric and Rockall, Andrea},
	title = {Development of machine learning support for reading whole body diffusion-weighted MRI (WB-MRI) in myeloma for the detection and quantification of the extent of disease before and after treatment (MALIMAR): protocol for a cross-sectional diagnostic test accuracy study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {10},
	doi = {10.1136/bmjopen-2022-067140},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139361152&doi=10.1136%2fbmjopen-2022-067140&partnerID=40&md5=2eac76d998de7e1fe254f099acfa1541},
	affiliations = {Royal Marsden Hospital Nhs Trust, London, United Kingdom; Department of Cancer and Surgery, Imperial College London, London, United Kingdom; Institute of Cancer Research, London, United Kingdom; Department of Computing, Imperial College London, London, United Kingdom; Department of Radiology, Imperial College Healthcare Nhs Trust, London, United Kingdom; King's College London, London, United Kingdom},
	abstract = {Introduction Whole-body MRI (WB-MRI) is recommended by the National Institute of Clinical Excellence as the first-line imaging tool for diagnosis of multiple myeloma. Reporting WB-MRI scans requires expertise to interpret and can be challenging for radiologists who need to meet rapid turn-around requirements. Automated computational tools based on machine learning (ML) could assist the radiologist in terms of sensitivity and reading speed and would facilitate improved accuracy, productivity and cost-effectiveness. The MALIMAR study aims to develop and validate a ML algorithm to increase the diagnostic accuracy and reading speed of radiological interpretation of WB-MRI compared with standard methods. Methods and analysis This phase II/III imaging trial will perform retrospective analysis of previously obtained clinical radiology MRI scans and scans from healthy volunteers obtained prospectively to implement training and validation of an ML algorithm. The study will comprise three project phases using approximately 633 scans to (1) train the ML algorithm to identify active disease, (2) clinically validate the ML algorithm and (3) determine change in disease status following treatment via a quantification of burden of disease in patients with myeloma. Phase 1 will primarily train the ML algorithm to detect active myeloma against an expert assessment ( € reference standard'). Phase 2 will use the ML output in the setting of radiology reader study to assess the difference in sensitivity when using ML-assisted reading or human-alone reading. Phase 3 will assess the agreement between experienced readers (with and without ML) and the reference standard in scoring both overall burden of disease before and after treatment, and response. Ethics and dissemination MALIMAR has ethical approval from South Central - Oxford C Research Ethics Committee (REC Reference: 17/SC/0630). IRAS Project ID: 233501. CPMS Portfolio adoption (CPMS ID: 36766). Participants gave informed consent to participate in the study before taking part. MALIMAR is funded by National Institute for Healthcare Research Efficacy and Mechanism Evaluation funding (NIHR EME Project ID: 16/68/34). Findings will be made available through peer-reviewed publications and conference dissemination. Trial registration number NCT03574454.  © },
	author_keywords = {Diagnostic radiology; Magnetic resonance imaging; Myeloma; ONCOLOGY},
	keywords = {Chlorobenzenes; Cross-Sectional Studies; Diagnostic Tests, Routine; Humans; Machine Learning; Magnetic Resonance Imaging; Multiple Myeloma; Retrospective Studies; Sulfides; Whole Body Imaging; 4-chlorophenyl methyl sulfide; chlorobenzene; sulfide; adult; algorithm; Article; clinical protocol; controlled study; cross-sectional study; diagnostic accuracy; diagnostic test accuracy study; diffusion weighted imaging; disease burden; female; human; machine learning; male; myeloma; phase 2 clinical trial; phase 3 clinical trial; standard; whole body MRI; clinical trial; diagnostic imaging; diagnostic test; multiple myeloma; nuclear magnetic resonance imaging; procedures; retrospective study; whole body imaging},
	correspondence_address = {L. Satchwell; Royal Marsden Hospital Nhs Trust, London, United Kingdom; email: laura.satchwell@rmh.nhs.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36198471},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tuomi2022601,
	author = {Tuomi, Ilkka},
	title = {Artificial intelligence, 21st century competences, and socio-emotional learning in education: More than high-risk?},
	year = {2022},
	journal = {European Journal of Education},
	volume = {57},
	number = {4},
	pages = {601 – 619},
	doi = {10.1111/ejed.12531},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139454507&doi=10.1111%2fejed.12531&partnerID=40&md5=9eb985e853a1b5001bd41b15be16f211},
	affiliations = {Meaning Processing Ltd., Helsinki, Finland},
	abstract = {Over the last two decades, 21st century competences and socio-emotional skills have become a major focus in educational policy. In this article, skills for the 21st century, soft skills, as well as social and emotional skills, are contextualised in the context of technological change, machine learning, and the ethics of artificial intelligence. The use of data-driven AI technologies to model and measure these skills—in this article defined as non-epistemic competence components—can lead to major social challenges that have important implications for educational policies and practices. A moratorium on the use of data on these competence components in machine learning systems is proposed until the society-wide impact is better understood. © 2022 John Wiley & Sons Ltd.},
	correspondence_address = {I. Tuomi; Meaning Processing Ltd, Helsinki, Arkadiankatu 20 A 20, 00100, Finland; email: ilkka.tuomi@meaningprocessing.com},
	publisher = {John Wiley and Sons Inc},
	issn = {01418211},
	language = {English},
	abbrev_source_title = {Eur. J. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Wolfe2022,
	author = {Wolfe, Dianna and Hutton, Brian and Corace, Kimberly and Chaiyakunapruk, Nathorn and Ngorsuraches, Surachat and Nochaiwong, Surapon and Presseau, Justin and Grant, Alyssa and Suschinsky, Kelly and Skidmore, Becky and Bartram, Mary and Cohen, Karen and Garner, Gord and Digioacchino, Lisha and Pump, Andrew and Peters, Brianne and Konefal, Sarah and Porath, Amy and Thavorn, Kednapa},
	title = {Service-level barriers to and facilitators of access to services for the treatment of alcohol use disorder and problematic alcohol use: protocol for a scoping review},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {11},
	doi = {10.1136/bmjopen-2022-064578},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142391445&doi=10.1136%2fbmjopen-2022-064578&partnerID=40&md5=ac5b342bd7a7fc2460e6c2cd2dd4c23d},
	affiliations = {Clinical Epidemiology Program, Ottawa Hospital Research Institute, Ottawa, ON, Canada; School of Epidemiology and Public Health, University of Ottawa, Ottawa, ON, Canada; Department of Psychiatry, University of Ottawa, Ottawa, ON, Canada; Institute of Mental Health Research, University of Ottawa, Ottawa, ON, Canada; Substance Use and Concurrent Disorders Program, Royal Ottawa Mental Health Centre, Ottawa, ON, Canada; Department of Pharmacotherapy, University of Utah, Salt Lake City, UT, United States; Harrison College of Pharmacy, Auburn University, Auburn, AL, United States; Department of Pharmaceutical Care, Faculty of Pharmacy, Chiang Mai University, Chiang Mai, Thailand; Pharmacoepidemiology and Statistics Research Center, Faculty of Pharmacy, Chiang Mai University, Chiang Mai, Thailand; Mental Health Commission of Canada, Ottawa, ON, Canada; Canadian Psychological Association, Ottawa, ON, Canada; Community Addictions Peer Support Association, Ottawa, ON, Canada; Research, Canadian Centre on Substance Use and Addiction, Ottawa, ON, Canada; Canadian Centre on Substance Use and Addiction, Ottawa, ON, Canada; Knowledge Institute on Child and Youth Mental Health and Addictions, Ottawa, ON, Canada},
	abstract = {Introduction Prior to the COVID-19 pandemic, substance use health services for treatment of alcohol use disorder and problematic alcohol use (AUD/PAU) were fragmented and challenging to access. The pandemic magnified system weaknesses, often resulting in disruptions of treatment as alcohol use during the pandemic rose. When treatment services were available, utilisation was often low for various reasons. Virtual care was implemented to offset the drop in in-person care, however accessibility was not universal. Identification of the characteristics of treatment services for AUD/PAU that impact accessibility, as perceived by the individuals accessing or providing the services, will provide insights to enable improved access. We will perform a scoping review that will identify characteristics of services for treatment of AUD/PAU that have been identified as barriers to or facilitators of service access from the perspectives of these groups. Methods and analysis We will follow scoping review methodological guidance from the Joanna Briggs Institute. Using the OVID platform, we will search Ovid MEDLINE including Epub Ahead of Print and In-Process and Other Non-Indexed Citations, Embase Classic+Embase, APA PsychInfo, Cochrane Register of Controlled Trials, the Cochrane Database of Systematic Reviews and CINAHL (Ebsco Platform). Multiple reviewers will screen citations. We will seek studies reporting data collected from individuals with AUD/PAU or providers of treatment for AUD/PAU on service-level factors affecting access to care. We will map barriers to and facilitators of access to AUD/PAU treatment services identified in the relevant studies, stratified by service type and key measures of inequity across service users. Ethics and dissemination This research will enhance awareness of existing evidence regarding barriers to and facilitators of access to services for the treatment of alcohol use disorder and problematic alcohol use. Findings will be disseminated through publications, conference presentations and a stakeholder meeting. As this is a scoping review of published literature, no ethics approval was required.  © },
	author_keywords = {mental health treatment services; primary care; problematic alcohol use; protocols & guidelines; substance misuse},
	keywords = {Alcoholism; COVID-19; Health Services; Humans; Pandemics; Review Literature as Topic; Systematic Reviews as Topic; acamprosate; baclofen; disulfiram; gabapentin; naltrexone; ondansetron; topiramate; alcohol abuse; alcohol consumption; alcoholism; Article; artificial intelligence; Cinahl; classification algorithm; clinical protocol; Cochrane Library; cognitive behavioral therapy; community; drug dependence; DSM-5; DSM-IV; economic status; Embase; emergency ward; ethnicity; food security; health care access; health care personnel; health care system; heavy drinking; human; immigration; income; machine learning; medical record; medical record review; Medline; mindfulness; motivational interviewing; pandemic; patient care; peer pressure; personal experience; practice guideline; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; primary health care; primary medical care; psychosocial intervention; PsycINFO; reinforcement (psychology); risk factor; systematic review (topic); telecare; alcoholism; health service; literature},
	correspondence_address = {K. Thavorn; Clinical Epidemiology Program, Ottawa Hospital Research Institute, Ottawa, Canada; email: kthavorn@ohri.ca},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36410826},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Volkmar2022599,
	author = {Volkmar, Gioia and Fischer, Peter M. and Reinecke, Sven},
	title = {Artificial Intelligence and Machine Learning: Exploring drivers, barriers, and future developments in marketing management},
	year = {2022},
	journal = {Journal of Business Research},
	volume = {149},
	pages = {599 – 614},
	doi = {10.1016/j.jbusres.2022.04.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131124066&doi=10.1016%2fj.jbusres.2022.04.007&partnerID=40&md5=241655914af5314dfb3bdf304a5e1708},
	affiliations = {Institute for Marketing and Customer Insight, University of St.Gallen, Dufourstrasse 40a, St. Gallen, 9000, Switzerland},
	abstract = {Companies neither fully exploit the potential of Artificial Intelligence (AI), nor that of Machine Learning (ML), its most prominent method. This is true in particular of marketing, where its possible use extends beyond mere segmentation, personalization, and decision-making. We explore the drivers of and barriers to AI and ML in marketing by adopting a dual strategic and behavioral focus, which provides both an inward (AI and ML for marketers) and an outward (AI and ML for customers) perspective. From our mixed-method approach (a Delphi study, a survey, and two focus groups), we derive several research propositions that address the challenges facing marketing managers and organizations in three distinct domains: (1) Culture, Strategy, and Implementation; (2) Decision-Making and Ethics; (3) Customer Management. Our findings contribute to better understanding the human factor behind AI and ML, and aim to stimulate interdisciplinary inquiry across marketing, organizational behavior, psychology, and ethics. © 2022 The Authors},
	author_keywords = {Artificial Intelligence; Decision- Making; Delphi Method; Ethics; Machine Learning; Marketing Management},
	correspondence_address = {G. Volkmar; Institute for Marketing and Customer Insight, University of St.Gallen, St. Gallen, Dufourstrasse 40a, 9000, Switzerland; email: gioia.volkmar@unisg.ch},
	publisher = {Elsevier Inc.},
	issn = {01482963},
	coden = {JBRED},
	language = {English},
	abbrev_source_title = {J. Bus. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Currie2022282,
	author = {Currie, Geoffrey and Nelson, Tarni and Hewis, Johnathan and Chandler, Amanda and Spuur, Kelly and Nabasenja, Caroline and Thomas, Cate and Wheat, Janelle},
	title = {Australian perspectives on artificial intelligence in medical imaging},
	year = {2022},
	journal = {Journal of Medical Radiation Sciences},
	volume = {69},
	number = {3},
	pages = {282 – 292},
	doi = {10.1002/jmrs.581},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128085891&doi=10.1002%2fjmrs.581&partnerID=40&md5=68b891aebc05ca755580c4e4591745cf},
	affiliations = {School of Dentistry & Medical Sciences, Charles Sturt University, Wagga Wagga, Australia; School of Dentistry & Medical Sciences, Charles Sturt University, Port Macquarie, Australia},
	abstract = {Introduction: While artificial intelligence (AI) and recent developments in deep learning (DL) have sparked interest in medical imaging, there has been little commentary on the impact of AI on imaging technologists. The aim of this survey was to understand the attitudes, applications and concerns among nuclear medicine and radiography professionals in Australia with regard to the rapidly emerging applications of AI. Methods: An anonymous online survey with invitation to participate was circulated to nuclear medicine and radiography members of the Rural Alliance in Nuclear Scintigraphy and the Australian Society of Medical Imaging and Radiation Therapy. The survey invitations were sent to members via email and as a push via social media with the survey open for 10 weeks. All information collected was anonymised and there is no disclosure of personal information as it was de-identified from commencement. Results: Among the 102 respondents, there was a high level of acceptance of lower order tasks (e.g. patient registration, triaging and dispensing) and less acceptance of high order task automation (e.g. surgery and interpretation). There was a low priority perception for the role of AI in higher order tasks (e.g. diagnosis, interpretation and decision making) and high priority for those applications that automate complex tasks (e.g. quantitation, segmentation, reconstruction) or improve image quality (e.g. dose / noise reduction and pseudo CT for attenuation correction). Medico-legal, ethical, diversity and privacy issues posed moderate or high concern while there appeared to be no concern regarding AI being clinically useful and improving efficiency. Mild concerns included redundancy, training bias, transparency and validity. Conclusion: Australian nuclear medicine technologists and radiographers recognise important applications of AI for assisting with repetitive tasks, performing less complex tasks and enhancing the quality of outputs in medical imaging. There are concerns relating to ethical aspects of algorithm development and implementation. © 2022 The Authors. Journal of Medical Radiation Sciences published by John Wiley & Sons Australia, Ltd on behalf of Australian Society of Medical Imaging and Radiation Therapy and New Zealand Institute of Medical Radiation Technology.},
	author_keywords = {artificial intelligence; convolutional neural network; deep learning; machine learning; nuclear medicine; radiography},
	keywords = {Artificial Intelligence; Australia; Deep Learning; Humans; Radiography; Radionuclide Imaging; adult; article; artificial intelligence; Australia; automation; controlled study; convolutional neural network; decision making; deep learning; diagnostic imaging; e-mail; ethics; female; human; identifiable information; image quality; machine learning; major clinical study; male; noise reduction; nuclear medicine; perception; privacy; radiographer; radiotherapy; scintigraphy; social media; validity; radiography; scintiscanning},
	correspondence_address = {G. Currie; School of Dentistry & Medical Sciences, Charles Sturt University, Wagga Wagga, Australia; email: gcurrie@csu.edu.au},
	publisher = {John Wiley and Sons Ltd},
	issn = {20513895},
	pmid = {35429129},
	language = {English},
	abbrev_source_title = {J. Med. Radial. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Sheetal2022,
	author = {Sheetal, Abhishek and Chaudhury, Srinwanti H. and Savani, Krishna},
	title = {A deep learning model identifies emphasis on hard work as an important predictor of income inequality},
	year = {2022},
	journal = {Scientific Reports},
	volume = {12},
	number = {1},
	doi = {10.1038/s41598-022-13902-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131877087&doi=10.1038%2fs41598-022-13902-x&partnerID=40&md5=a4eff497b74e7a9a97bf2ad31d5251ad},
	affiliations = {School of Business and Law, Central Queensland University, Rockhampton, Australia; Faculty of Business, The Hong Kong Polytechnic University, Kowloon, Hong Kong; Business School, University of Queensland, Brisbane, Australia; Nanyang Business School, Nanyang Technological University, Singapore, Singapore},
	abstract = {High levels of income inequality can persist in society only if people accept the inequality as justified. To identify psychological predictors of people’s tendency to justify inequality, we retrained a pre-existing deep learning model to predict the extent to which World Values Survey respondents believed that income inequality is necessary. A feature importance analysis revealed multiple items associated with the importance of hard work as top predictors. As an emphasis on hard work is a key component of the Protestant Work Ethic, we formulated the hypothesis that the PWE increases acceptance of inequality. A correlational study found that the more people endorsed PWE, the less disturbed they were about factual statistics about wealth equality in the US. Two experiments found that exposing people to PWE items decreased their disturbance with income inequality. The findings indicate that machine learning models can be reused to generate viable hypotheses. © 2022, The Author(s).},
	keywords = {Deep Learning; Humans; Income; Socioeconomic Factors; Surveys and Questionnaires; adult; article; correlational study; deep learning; human; income inequality; machine learning; Protestant; income; questionnaire; socioeconomics},
	correspondence_address = {K. Savani; Faculty of Business, The Hong Kong Polytechnic University, Kowloon, Hong Kong; email: krishna.savani@polyu.edu.hk},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {35701456},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Da Silva2022,
	author = {Da Silva, Michael and Horsley, Tanya and Singh, Devin and Da Silva, Emily and Ly, Valentina and Thomas, Bryan and Daniel, Ryan C. and Chagal-Feferkorn, Karni A. and Iantomasi, Samantha and White, Kelli and Kent, Arianne and Flood, Colleen M.},
	title = {Legal concerns in health-related artificial intelligence: a scoping review protocol},
	year = {2022},
	journal = {Systematic Reviews},
	volume = {11},
	number = {1},
	doi = {10.1186/s13643-022-01939-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132117974&doi=10.1186%2fs13643-022-01939-y&partnerID=40&md5=4748c97b1c9e348744c42231af10f12e},
	affiliations = {University of Ottawa Faculty of Law, Fauteux Hall, 57 Louis-Pasteur Private, Ottawa, K1N 6N5, ON, Canada; The Royal College of Physicians and Surgeons of Canada, Toronto, Canada; School of Epidemiology and Public Health, University of Ottawa, Ottawa, Canada; The Hospital for Sick Children, Toronto, Canada; University of Toronto, Toronto, Canada; University of Ottawa, Ottawa, Canada},
	abstract = {Background: Medical innovations offer tremendous hope. Yet, similar innovations in governance (law, policy, ethics) are likely necessary if society is to realize medical innovations’ fruits and avoid their pitfalls. As innovations in artificial intelligence (AI) advance at a rapid pace, scholars across multiple disciplines are articulating concerns in health-related AI that likely require legal responses to ensure the requisite balance. These scholarly perspectives may provide critical insights into the most pressing challenges that will help shape and advance future regulatory reforms. Yet, to the best of our knowledge, there is no comprehensive summary of the literature examining legal concerns in relation to health-related AI. We thus aim to summarize and map the literature examining legal concerns in health-related AI using a scoping review approach. Methods: The scoping review framework developed by (J Soc Res Methodol 8:19-32, 2005) and extended by (Implement Sci 5:69, 2010) and the Preferred Reporting Items for Systematic Reviews and Meta-Analysis extension for scoping reviews (PRISMA-ScR) guided our protocol development. In close consultation with trained librarians, we will develop a highly sensitive search for MEDLINE® (OVID) and adapt it for multiple databases designed to comprehensively capture texts in law, medicine, nursing, pharmacy, other healthcare professions (e.g., dentistry, nutrition), public health, computer science, and engineering. English- and French-language records will be included if they examine health-related AI, describe or prioritize a legal concern in health-related AI or propose a solution thereto, and were published in 2012 or later. Eligibility assessment will be conducted independently and in duplicate at all review stages. Coded data will be analyzed along themes and stratified across discipline-specific literatures. Discussion: This first-of-its-kind scoping review will summarize available literature examining, documenting, or prioritizing legal concerns in health-related AI to advance law and policy reform(s). The review may also reveal discipline-specific concerns, priorities, and proposed solutions to the concerns. It will thereby identify priority areas that should be the focus of future reforms and regulatory options available to stakeholders in reform processes. Trial registration: This protocol was submitted to the Open Science Foundation registration database. See https://osf.io/zav7w. © 2022, The Author(s).},
	author_keywords = {Artificial intelligence; Health; Health law; Machine learning; Scoping review},
	keywords = {Artificial Intelligence; Humans; Policy; Review Literature as Topic; Systematic Reviews as Topic; Article; artificial intelligence; consultation; demographics; health care personnel; health legislation; human; legal aspect; machine learning; medical device regulation; meta analysis; outcome assessment; scientific literature; systematic review; literature; policy},
	correspondence_address = {M. Da Silva; University of Ottawa Faculty of Law, Ottawa, Fauteux Hall, 57 Louis-Pasteur Private, K1N 6N5, Canada; email: mdasilv3@uottawa.ca},
	publisher = {BioMed Central Ltd},
	issn = {20464053},
	pmid = {35715812},
	language = {English},
	abbrev_source_title = {Syst. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Li2022,
	author = {Li, Song and Van Boekel, Regina L.M. and Van Den Heuvel, Sandra A.S. and Coenen, Marieke J.H. and Vissers, Kris C.P.},
	title = {Pain predict genetics: Protocol for a prospective observational study of clinical and genetic factors to predict the development of postoperative pain},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {11},
	doi = {10.1136/bmjopen-2022-066134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143072392&doi=10.1136%2fbmjopen-2022-066134&partnerID=40&md5=1073452a0bea09c999de0df01cdbe343},
	affiliations = {Department of Human Genetics, Radboud Institute for Health Sciences, Radboud University Medical Center, Nijmegen, Netherlands; Department of Anesthesiology, Pain and Palliative Medicine, Radboud University Medical Center, Nijmegen, Netherlands},
	abstract = {Introduction Postoperative pain remains a challenging medical condition impacting the quality of life of every patient. Although several predictive factors for postoperative pain have been identified, an adequate prediction of postoperative pain in patients at risk has not been achieved yet. The primary objective of this study is to identify specific genetic risk factors for the development of acute and chronic postoperative pain to construct a prediction model facilitating a more personalised postoperative pain management for each individual. The secondary objectives are to build a databank enabling researchers to identify other risk factors for postoperative pain, for instance, demographic and clinical outcome indicators; provide insight into (genetic) factors that predict pharmacological pain relief; investigate the relationship between acute and chronic postoperative pain. Methods and analysis In this prospective, observational study, patients who undergo elective surgery will be recruited to a sample size of approximately 10 000 patients. Postoperative acute and chronic pain outcomes will be collected through questionnaires at different time points after surgery in the follow-up of 6 months. Potential genetic, demographic and clinical risk factors for prediction model construction will be collected through blood, questionnaires and electronic health records, respectively. Genetic factors associated with acute and/or chronic postoperative pain will be identified using a genome-wide association analysis. Clinical risk factors as stated in the secondary objectives will be assessed by multivariable regression. A clinical easy-to-use prediction model will be created for postoperative pain to allow clinical use for the stratification of patients. Ethics and dissemination The Institutional Review Board of the Radboud university medical centre approved the study (authorisation number: 2012/117). The results of this study will be made available through peer-reviewed scientific journals and presentations at relevant conferences, which will finally contribute to personalised postoperative pain management. Trial registration number NCT02383342.  © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {EPIDEMIOLOGY; GENETICS; PAIN MANAGEMENT; SURGERY},
	keywords = {Genome-Wide Association Study; Humans; Observational Studies as Topic; Pain Management; Pain, Postoperative; Prospective Studies; Quality of Life; cytochrome P450 2D6; adult; analgesia; Article; chronic pain; clinical article; clinical feature; clinical outcome; elective surgery; female; genetic risk; genetics; genotype; heredity; human; human tissue; length of stay; machine learning; male; nociception; numeric rating scale; observational study; Pain Catastrophizing scale; pain intensity; patient-reported outcome; postoperative pain; prediction; questionnaire; genetics; genome-wide association study; postoperative pain; prospective study; quality of life},
	correspondence_address = {R.L.M. Van Boekel; Department of Anesthesiology, Pain and Palliative Medicine, Radboud University Medical Center, Nijmegen, Netherlands; email: Rianne.vanBoekel@radboudumc.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36446453},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Surahman20221535,
	author = {Surahman, Ence and Wang, Tzu-Hua},
	title = {Academic dishonesty and trustworthy assessment in online learning: A systematic literature review},
	year = {2022},
	journal = {Journal of Computer Assisted Learning},
	volume = {38},
	number = {6},
	pages = {1535 – 1553},
	doi = {10.1111/jcal.12708},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133524702&doi=10.1111%2fjcal.12708&partnerID=40&md5=84967809aa775bbe28cf636d6ca65bfa},
	affiliations = {International Intercollegiate PhD Program, National Tsing Hua University, Hsinchu, Taiwan; Department of Educational Technology, Faculty of Education, State University of Malang, Malang, Indonesia; Department of Education and Learning Technology, College of Education, National Tsing Hua University, Hsinchu, Taiwan},
	abstract = {Background: Academic dishonesty (AD) and trustworthy assessment (TA) are fundamental issues in the context of an online assessment. However, little systematic work currently exists on how researchers have explored AD and TA issues in online assessment practice. Objectives: Hence, this research aimed at investigating the latest findings regarding AD forms, factors affecting AD and TA, and solutions to reduce AD and increase TA to maintain the quality of online assessment. Methods: We reviewed 52 articles in Scopus and Web of Science databases from January 2017 to April 2021 using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses model as a guideline to perform a systematic literature review that included three stages, namely planning, conducting, and reporting. Results and conclusions: Our review found that there were different forms of AD among students in online learning namely plagiarism, cheating, collusion, and using jockeys. Individual factors such as being lazy to learn, lack of ability, and poor awareness as well as situational factors including the influence of friends, the pressure of the courses, and ease of access to information were strongly associated with AD. A technology-based approach such as using plagiarism-checking software, multi-artificial intelligence (AI) in a learning management system, computer adaptive tests, and online proctoring as well as pedagogical-based approaches, such as implementing a research ethics course programme, and a re-design assessment form such as oral-based and dynamic assessment to reduce cheating behaviour and also sociocultural and sociotechnical adjustment related to the online assessment are reported to reduce AD and increase TA. Implications: Educators should adjust the design of online learning and assessment methods as soon as possible. The identified gaps point towards unexplored study on AI, machine learning, learning analytics tools, and related issues of AD and TA in K12 education could motivated future work in the field. © 2022 John Wiley & Sons Ltd.},
	author_keywords = {academic dishonesty; academic integrity; online assessment; online learning; remote assessment; trustworthy assessment},
	correspondence_address = {T.-H. Wang; Department of Education and Learning Technology, College of Education, National Tsing Hua University, Hsinchu, Taiwan; email: tzuhuawang@gmail.com},
	publisher = {John Wiley and Sons Inc},
	issn = {02664909},
	language = {English},
	abbrev_source_title = {J. Comput. Assisted Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Nicolosi2022761,
	author = {Nicolosi, Gian Luigi and Casolo, Giancarlo},
	title = {Artificial intelligence in cardiology; [L'intelligenza artificiale in cardiologia]},
	year = {2022},
	journal = {Giornale Italiano di Cardiologia},
	volume = {23},
	number = {10},
	pages = {761 – 770},
	doi = {10.1714/3881.38641},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138854730&doi=10.1714%2f3881.38641&partnerID=40&md5=7bb32475ec45b71ddd8b7c3c1eaca9ff},
	affiliations = {Cardiologia, ARC, Policlinico San Giorgio, Pordenone, Italy; U.O.C. Cardiologia, Ospedale Unico della Versilia, USL Toscana Nord-Ovest, Lido di Camaiore (LU), Italy},
	abstract = {Artificial intelligence (AI) in cardiology represents a great opportunity, if further developed in a trustworthy way, to support human intelligence in daily practice. AI could help cardiologists to operate with greater efficacy and efficiency, supporting precision, timeliness, ethics, while meeting all patients' needs. AI, however, is not yet so widely diffused in cardiology and important challenges and obstacles have to be overcome, concerning ethics, conflict of interests, algorithm improvements and transparency, product certification, input processing, cyber security, privacy, and need for collaboration and cooperation of different involved professions, within and between different institutions of heterogeneous complexity.  © 2022 II Pensiero Scientifico Editore.},
	author_keywords = {Artificial intelligence; Cardiology; Machine learning; Multimodality imaging},
	keywords = {Algorithms; Artificial Intelligence; Cardiology; Humans; adult; artificial intelligence; cardiologist; cardiology; certification; computer security; conflict of interest; drug efficacy; ethics; human; machine learning; occupation; privacy; review; algorithm},
	correspondence_address = {G.L. Nicolosi; Cardiologia, ARC, Policlinico San Giorgio, Pordenone, Via A. Gemelli 10, 33170, Italy; email: gianluigi.nicolosi@gmail.com},
	publisher = {Il Pensiero Scientifico Editore s.r.l.},
	issn = {18276806},
	pmid = {36169126},
	language = {Italian},
	abbrev_source_title = {G. Ital. Cardiol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Jangwan2022,
	author = {Jangwan, Nitish Singh and Ashraf, Ghulam Md and Ram, Veerma and Singh, Vinod and Alghamdi, Badrah S. and Abuzenadah, Adel Mohammad and Singh, Mamta F.},
	title = {Brain augmentation and neuroscience technologies: current applications, challenges, ethics and future prospects},
	year = {2022},
	journal = {Frontiers in Systems Neuroscience},
	volume = {16},
	doi = {10.3389/fnsys.2022.1000495},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140059519&doi=10.3389%2ffnsys.2022.1000495&partnerID=40&md5=1edd39ced1d2ba0d147dd9634ac8c9b0},
	affiliations = {Department of Pharmacology, School of Pharmaceutical Sciences and Technology, Sardar Bhagwan Singh University, Balawala, India; Pre-Clinical Research Unit, King Fahd Medical Research Center, King Abdulaziz University, Jeddah, Saudi Arabia; Department of Medical Laboratory Sciences, Faculty of Applied Medical Sciences, King Abdulaziz University, Jeddah, Saudi Arabia; Prabha Harji Lal College of Pharmacy and Paraclinical Sciences, University of Jammu, Jammu, India; Department of Physiology, Neuroscience Unit, Faculty of Medicine, King Abdulaziz University, Jeddah, Saudi Arabia; Faculty of Applied Medical Sciences, King Abdulaziz University, Jeddah, Saudi Arabia; King Fahd Medical Research Center, King Abdulaziz University, Jeddah, Saudi Arabia},
	abstract = {Ever since the dawn of antiquity, people have strived to improve their cognitive abilities. From the advent of the wheel to the development of artificial intelligence, technology has had a profound leverage on civilization. Cognitive enhancement or augmentation of brain functions has become a trending topic both in academic and public debates in improving physical and mental abilities. The last years have seen a plethora of suggestions for boosting cognitive functions and biochemical, physical, and behavioral strategies are being explored in the field of cognitive enhancement. Despite expansion of behavioral and biochemical approaches, various physical strategies are known to boost mental abilities in diseased and healthy individuals. Clinical applications of neuroscience technologies offer alternatives to pharmaceutical approaches and devices for diseases that have been fatal, so far. Importantly, the distinctive aspect of these technologies, which shapes their existing and anticipated participation in brain augmentations, is used to compare and contrast them. As a preview of the next two decades of progress in brain augmentation, this article presents a plausible estimation of the many neuroscience technologies, their virtues, demerits, and applications. The review also focuses on the ethical implications and challenges linked to modern neuroscientific technology. There are times when it looks as if ethics discussions are more concerned with the hypothetical than with the factual. We conclude by providing recommendations for potential future studies and development areas, taking into account future advancements in neuroscience innovation for brain enhancement, analyzing historical patterns, considering neuroethics and looking at other related forecasts. Copyright © 2022 Jangwan, Ashraf, Ram, Singh, Alghamdi, Abuzenadah and Singh.},
	author_keywords = {brain 2025; brain machine interface; deep brain stimulation; ethics; non-invasive and invasive brain stimulation},
	keywords = {flavonoid; attention deficit hyperactivity disorder; autism; behavior assessment; brain augmentation; brain cortex; brain depth stimulation; brain function; brain surgery; cognition; cognitive defect; decision making; depression; dystonia; electrode implantation; electroencephalogram; electroencephalography; electrostimulation; emotionality; epilepsy; functional magnetic resonance imaging; Gilles de la Tourette syndrome; hippocampal CA3 region; human; learning; machine learning; mental disease; motor system; near infrared spectroscopy; neurologic disease; neuroscience; nuclear magnetic resonance imaging; Parkinson disease; physical activity; Review; risk factor; schizophrenia; sleep; transcranial direct current stimulation; vagus nerve stimulation},
	correspondence_address = {M.F. Singh; Department of Pharmacology, School of Pharmaceutical Sciences and Technology, Sardar Bhagwan Singh University, Balawala, India; email: mamta_fr2002@yahoo.co.in},
	publisher = {Frontiers Media S.A.},
	issn = {16625137},
	language = {English},
	abbrev_source_title = {Front. Syst. Neurosci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Ammar2022119,
	author = {Ammar, Ahmed},
	title = {The integration of values-based medical education (VsBME) in the education and training processes: A conceptual framework for neurosurgical/surgical/medical education and training},
	year = {2022},
	journal = {Learning and Career Development in Neurosurgery: Values-Based Medical Education},
	pages = {119 – 132},
	doi = {10.1007/978-3-031-02078-0_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153902782&doi=10.1007%2f978-3-031-02078-0_13&partnerID=40&md5=e450e4e1345d199d6b51e870f9cb4699},
	affiliations = {Department of Neurosurgery, King Fahd University Hospital, Imam Abdelrahaman Bin Faisal University, Al Khobar, Saudi Arabia},
	abstract = {This chapter is an attempt to envision the outlook and illustrate how the revolutionary changes in the information, communication, and medical industry require and need ethical and professional guidelines. These ethical concepts and professional guidelines should be globally accepted, applicable and capable to accommodate, guide and guard all the emerged medical technologies currently and in the future. Virtual, hybrid medical education, augmented reality, metaverse, robotic surgery, machine learning, telemedicine, and virtual universities will become the norm and prevail. It is possible to have a robotic surgeon or neurosurgeon to operate or examine and manage the case, and it is possible to have robotic nurses, paramedical, and virtual clinics. However, patients are and will always remain very much real with blood, flesh, and feelings. Patients seek medical help to save their life and reduce their pain. Therefore, the code of ethics, which respects patient's right and safety, is mandatory. Medical education and training relationships are built on five elements which are (1) visionary and strategic plan of health care and high education stakeholders, (2) trainee, (3) trainer, (4) the curriculum, (5) logistics, premises, and facilities (universities, hospital, labs,...). All these elements interact in different weights, means, and varieties according to stakeholders and clustered interests and plans. The progress of medical information and communication sciences and technological innovations as well as the development of the health systems and the medical-industrial complex create new medical situations that forced the educators and health care planner to take necessary measures to catch up and go online with these welcomed changes. These emerged new medical cares and educational and training situations raised a myriad of ethical questions. The concept of Values-Based Medical Education (VsBME) may offer a global applicable concept to implement and integrate the ethics and values in the daily rapidly changes in medical world. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2022. All rights reserved.},
	author_keywords = {Augmented reality; Machine learning; Medical education; Neurosurgery curriculum; Neurosurgery training; Values-based medical education; Values-based medicine},
	correspondence_address = {A. Ammar; Department of Neurosurgery, King Fahd University Hospital, Imam Abdelrahaman Bin Faisal University, Al Khobar, Saudi Arabia; email: ahmed@ahmedammar.com},
	publisher = {Springer International Publishing},
	isbn = {978-303102078-0; 978-303102077-3},
	language = {English},
	abbrev_source_title = {Learning and Career dév. in neurosurg.: Values-Based méd. educ.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ceva2022,
	author = {Ceva, Emanuela and Jiménez, María Carolina},
	title = {Automating anticorruption?},
	year = {2022},
	journal = {Ethics and Information Technology},
	volume = {24},
	number = {4},
	doi = {10.1007/s10676-022-09670-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141634195&doi=10.1007%2fs10676-022-09670-x&partnerID=40&md5=ae9cdd2470953d8773fc85d47781e349},
	affiliations = {Department of Political Science & International Relations, University of Geneva, Geneva, Switzerland},
	abstract = {The paper explores some normative challenges concerning the integration of Machine Learning (ML) algorithms into anticorruption in public institutions. The challenges emerge from the tensions between an approach treating ML algorithms as allies to an exclusively legalistic conception of anticorruption and an approach seeing them within an institutional ethics of office accountability. We explore two main challenges. One concerns the variable opacity of some ML algorithms, which may affect public officeholders’ capacity to account for institutional processes relying upon ML techniques. The other pinpoints the risk that automating certain institutional processes may weaken officeholders’ direct engagement to take forward-looking responsibility for the working of their institution. We discuss why both challenges matter to see how ML algorithms may enhance (and not hinder) institutional answerability practices. © 2022, The Author(s).},
	author_keywords = {Anticorruption; Artificial intelligence; Corruption; Machine learning algorithms; Office accountability; Opacity},
	keywords = {Machine learning; Opacity; Anti-corruption; Corruption; Forward looking; Institutional process; Machine learning algorithms; Machine learning techniques; Office accountability; Public institution; Learning algorithms},
	correspondence_address = {E. Ceva; Department of Political Science & International Relations, University of Geneva, Geneva, Switzerland; email: Emanuela.Ceva@unige.ch},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Canfell2022,
	author = {Canfell, Oliver J. and Davidson, Kamila and Sullivan, Clair and Eakin, Elizabeth E. and Burton-Jones, Andrew},
	title = {PREVIDE: A Qualitative Study to Develop a Decision-Making Framework (PREVention decIDE) for Noncommunicable Disease Prevention in Healthcare Organisations},
	year = {2022},
	journal = {International Journal of Environmental Research and Public Health},
	volume = {19},
	number = {22},
	doi = {10.3390/ijerph192215285},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142540955&doi=10.3390%2fijerph192215285&partnerID=40&md5=997f484d78f39b8ae836de96f8b65c1e},
	affiliations = {UQ Business School, Faculty of Business, Economics and Law, The University of Queensland, St. Lucia, 4072, QLD, Australia; Centre for Health Services Research, Faculty of Medicine, The University of Queensland, St. Lucia, 4072, QLD, Australia; Queensland Digital Health Centre, Faculty of Medicine, The University of Queensland, Herston, 4006, QLD, Australia; Digital Health Cooperative Research Centre, Australian Government, Sydney, 2000, NSW, Australia; Metro North Hospital and Health Service, Department of Health, Queensland Government, Herston, 4072, QLD, Australia; School of Public Health, Faculty of Medicine, The University of Queensland, Herston, 4072, QLD, Australia},
	abstract = {Noncommunicable diseases (NCDs), including obesity, remain a significant global public health challenge. Prevention and public health innovation are needed to effectively address NCDs; however, understanding of how healthcare organisations make prevention decisions is immature. This study aimed to (1) explore how healthcare organisations make decisions for NCD prevention in Queensland, Australia (2) develop a contemporary decision-making framework to guide NCD prevention in healthcare organisations. Cross-sectional and qualitative design, comprising individual semi-structured interviews. Participants (n = 14) were recruited from two organisations: the state public health care system (CareQ) and health promotion/disease prevention agency (PrevQ). Participants held executive, director/manager or project/clinical lead roles. Data were analysed in two phases (1) automated content analysis using machine learning (Leximancer v4.5) (2) researcher-led interpretation of the text analytics. Final themes were consolidated into a proposed decision-making framework (PREVIDE, PREvention decIDE) for NCD prevention in healthcare organisations. Decision-making was driven by four themes: Data, Evidence, Ethics and Health, i.e., data, its quality and the story it tells; traditional and non-traditional sources of evidence; ethical grounding in fairness and equity; and long-term value generated across multiple determinants of health. The strength of evidence was directly proportional to confidence in the ethics of a decision. PREVIDE can be adapted by public health practitioners and policymakers to guide real-world policy, practice and investment decisions for obesity prevention and with further validation, other NCDs and priority settings (e.g., healthcare). © 2022 by the authors.},
	author_keywords = {decision-making; health policy; noncommunicable diseases; obesity; precision public health; preventive medicine; public health; public health informatics},
	keywords = {Cross-Sectional Studies; Delivery of Health Care; Humans; Noncommunicable Diseases; Obesity; Qualitative Research; Australia; Queensland; decision making; health care; health policy; medicine; noncommunicable disease; obesity; public health; Article; Australia; clinical article; decision making; health care organization; health care policy; health care system; health promotion; human; interview; investment; machine learning; manager; medical informatics; non communicable disease; obesity; physician; preventive medicine; public health; public health service; qualitative research; Queensland; questionnaire; risk factor; semi structured interview; storytelling; thematic analysis; cross-sectional study; health care delivery; non communicable disease; obesity; qualitative research},
	correspondence_address = {O.J. Canfell; UQ Business School, Faculty of Business, Economics and Law, The University of Queensland, St. Lucia, 4072, Australia; email: o.canfell@uq.edu.au},
	publisher = {MDPI},
	issn = {16617827},
	pmid = {36430005},
	language = {English},
	abbrev_source_title = {Int. J. Environ. Res. Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Unver2022,
	author = {Unver, Hamid Akin},
	title = {Using Social Media to Monitor Conflict-Related Migration: A Review of Implications for A.I. Forecasting},
	year = {2022},
	journal = {Social Sciences},
	volume = {11},
	number = {9},
	doi = {10.3390/socsci11090395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138705313&doi=10.3390%2fsocsci11090395&partnerID=40&md5=e300450f964bc37b84622e3e6677cea3},
	affiliations = {Department of International Relations, Özyeğin University, Istanbul, 34337, Turkey},
	abstract = {Following the large-scale 2015–2016 migration crisis that shook Europe, deploying big data and social media harvesting methods became gradually popular in mass forced migration monitoring. These methods have focused on producing ‘real-time’ inferences and predictions on individual and social behavioral, preferential, and cognitive patterns of human mobility. Although the volume of such data has improved rapidly due to social media and remote sensing technologies, they have also produced biased, flawed, or otherwise invasive results that made migrants’ lives more difficult in transit. This review article explores the recent debate on the use of social media data to train machine learning classifiers and modify thresholds to help algorithmic systems monitor and predict violence and forced migration. Ultimately, it identifies and dissects five prevalent explanations in the literature on limitations for the use of such data for A.I. forecasting, namely ‘policy-engineering mismatch’, ‘accessibility/comprehensibility’, ‘legal/legislative legitimacy’, ‘poor data cleaning’, and ‘difficulty of troubleshooting’. From this review, the article suggests anonymization, distributed responsibility, and ‘right to reasonable inferences’ debates as potential solutions and next research steps to remedy these problems. © 2022 by the author.},
	author_keywords = {artificial intelligence; big data ethics; conflict; event data; forced migration},
	correspondence_address = {H.A. Unver; Department of International Relations, Özyeğin University, Istanbul, 34337, Turkey; email: akin.unver@ozyegin.edu.tr},
	publisher = {MDPI},
	issn = {20760760},
	language = {English},
	abbrev_source_title = {Soc. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Willem20221660,
	author = {Willem, T. and Krammer, S. and Böhm, A.-S. and French, L.E. and Hartmann, D. and Lasser, T. and Buyx, A.},
	title = {Risks and benefits of dermatological machine learning health care applications—an overview and ethical analysis},
	year = {2022},
	journal = {Journal of the European Academy of Dermatology and Venereology},
	volume = {36},
	number = {9},
	pages = {1660 – 1668},
	doi = {10.1111/jdv.18192},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132615500&doi=10.1111%2fjdv.18192&partnerID=40&md5=66bfa0244bbbfc8ba2bb97b2f570ada2},
	affiliations = {School of Medicine, Institute of History and Ethics in Medicine, Technical University of Munich, Munich, Germany; Department of Science, Technology and Society (STS), School of Social Sciences and Technology, Technical University of Munich, Munich, Germany; Department of Dermatology and Allergology, Ludwig Maximilian University of Munich, Munich, Germany; Dr. Philip Frost Department of Dermatology and Cutaneous Surgery, University of Miami Miller School of Medicine, Miami, FL, United States; Technical University of Munich, Department of Informatics, School of Computation, Information and Technology, Munich, Germany; Munich Institute of Biomedical Engineering, Technical University of Munich, Munich, Germany},
	abstract = {Background: Visual data are particularly amenable for machine learning techniques. With clinical photography established for skin surveillance and documentation purposes as well as progress checks, dermatology is an ideal field for the development and application of emerging machine learning health care applications (ML-HCAs). To date, several ML-HCAs have detected malignant skin lesions on par with experts or found overlooked visual patterns that correlate with certain dermatological diseases. However, it is well established that ML-HCAs come with ethical and social implications. Objectives: Currently, there is a lack of research that establishes model design, training, usage and regulation of such technologies sufficient to ensure ethically and socially responsible development and clinical translation, specifically within the field of dermatology. With this paper, we aim to give an overview of currently discussed ethical issues relating to dermatological ML-HCAs. Methods: On the basis of a thematic, keyword-based literature search, we performed an ethical analysis against established frameworks of biomedical ethics. We combined our results with current, relevant normative machine learning ethics literature to identify the status quo of the ethics of ML-HCAs in dermatology. We describe the benefits and risks of dermatological ML-HCAs that are currently being developed for clinical purposes. Results: The potential benefits range from better patient outcomes to better knowledge accessibility to decreasing health care disparities, that is, standards of care between different population groups. The risks associated with ML-HCAs range from confidentiality issues to individual patient outcomes as well as the exacerbation of prevalent health care disparities. We discuss the practical implications for all stages of dermatological ML-HCA development. Conclusion: We found that ML-HCAs present stakeholder-specific risks for patients, health care professionals and society, which need to be considered separately. The discipline lacks sufficient biomedical ethics research that could standardize the approach to ML-HCA model design, training, use and regulation of such technologies. © 2022 The Authors. Journal of the European Academy of Dermatology and Venereology published by John Wiley & Sons Ltd on behalf of European Academy of Dermatology and Venereology.},
	keywords = {Delivery of Health Care; Ethical Analysis; Health Personnel; Humans; Machine Learning; Risk Assessment; Article; biomedical technology assessment; clinical decision making; clinical outcome; clinical practice; dermatology; health care application; health care disparity; health care personnel; human; knowledge; machine learning; medical ethics; medical informatics; medical photography; medical research; patient care; patient information; risk benefit analysis; thematic analysis; ethics; health care delivery; health care personnel; machine learning; risk assessment},
	correspondence_address = {T. Willem; School of Medicine, Institute of History and Ethics in Medicine, Technical University of Munich, Munich, Germany; email: theresa.willem@tum.de},
	publisher = {John Wiley and Sons Inc},
	issn = {09269959},
	coden = {JEAVE},
	pmid = {35490413},
	language = {English},
	abbrev_source_title = {J. Eur. Acad. Dermatol. Venereol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kantar2022599,
	author = {Kantar, Nesibe and Bynum, Terrell Ward},
	title = {Flourishing Ethics and identifying ethical values to instill into artificially intelligent agents},
	year = {2022},
	journal = {Metaphilosophy},
	volume = {53},
	number = {5},
	pages = {599 – 604},
	doi = {10.1111/meta.12583},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138213140&doi=10.1111%2fmeta.12583&partnerID=40&md5=7061aad694e37740b8892deff82a8653},
	affiliations = {Center for Computing and Social Responsibility, De Montfort University, Leicester, United Kingdom; Department of Philosophy, Southern Connecticut State University, New Haven, United States},
	abstract = {The present paper uses a Flourishing Ethics analysis to address the question of which ethical values and principles should be “instilled” into artificially intelligent agents. This is an urgent question that is still being asked seven decades after philosopher/scientist Norbert Wiener first asked it. An answer is developed by assuming that human flourishing is the central ethical value, which other ethical values, and related principles, can be used to defend and advance. The upshot is that Flourishing Ethics can provide a common underlying ethical foundation for a wide diversity of cultures and communities around the globe; and the members of each specific culture or community can add their own specific cultural values—ones which they treasure, and which help them to make sense of their moral lives. © 2022 The Authors. Metaphilosophy published by Metaphilosophy LLC and John Wiley & Sons Ltd.},
	author_keywords = {artificial intelligence; cybernetics; Flourishing Ethics; machine decisions; machine learning; Norbert Wiener},
	correspondence_address = {T.W. Bynum; Information Ethics Institute, New Haven, 96 Glenview Terrace, 06515, United States; email: computerethics@mac.com},
	publisher = {John Wiley and Sons Inc},
	issn = {00261068},
	language = {English},
	abbrev_source_title = {Metaphilosophy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Prakash2022,
	author = {Prakash, Sreenidhi and Balaji, Jyotsna Needamangalam and Joshi, Ashish and Surapaneni, Krishna Mohan},
	title = {Ethical Conundrums in the Application of Artificial Intelligence (AI) in Healthcare—A Scoping Review of Reviews},
	year = {2022},
	journal = {Journal of Personalized Medicine},
	volume = {12},
	number = {11},
	doi = {10.3390/jpm12111914},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149247109&doi=10.3390%2fjpm12111914&partnerID=40&md5=1d4aa1ca6e48dbb97928857a6891f43c},
	affiliations = {Panimalar Medical College Hospital & Research Institute, Varadharajapuram, Poonamallee, Tamil Nadu, Chennai, 600 123, India; School of Public Health, The University of Memphis, Memphis, 38152, TN, United States; SMAART Population Health Informatics Intervention Center, Foundation of Healthcare Technologies Society, Panimalar Medical College Hospital & Research Institute, Varadharajapuram, Poonamallee, Tamil Nadu, Chennai, 600 123, India; Bioethics Unit, Panimalar Medical College Hospital & Research Institute, Varadharajapuram, Poonamallee, Tamil Nadu, Chennai, 600 123, India; Departments of Biochemistry, Medical Education, Molecular Virology, Research, Clinical Skills & Simulation, Panimalar Medical College Hospital & Research Institute, Varadharajapuram, Poonamallee, Tamil Nadu, Chennai, 600 123, India},
	abstract = {Background: With the availability of extensive health data, artificial intelligence has an inordinate capability to expedite medical explorations and revamp healthcare.Artificial intelligence is set to reform the practice of medicine soon. Despite the mammoth advantages of artificial intelligence in the medical field, there exists inconsistency in the ethical and legal framework for the application of AI in healthcare. Although research has been conducted by various medical disciplines investigating the ethical implications of artificial intelligence in the healthcare setting, the literature lacks a holistic approach. Objective: The purpose of this review is to ascertain the ethical concerns of AI applications in healthcare, to identify the knowledge gaps and provide recommendations for an ethical and legal framework. Methodology: Electronic databases Pub Med and Google Scholar were extensively searched based on the search strategy pertaining to the purpose of this review. Further screening of the included articles was done on the grounds of the inclusion and exclusion criteria. Results: The search yielded a total of 1238 articles, out of which 16 articles were identified to be eligible for this review. The selection was strictly based on the inclusion and exclusion criteria mentioned in the manuscript. Conclusion: Artificial intelligence (AI) is an exceedingly puissant technology, with the prospect of advancing medical practice in the years to come. Nevertheless, AI brings with it a colossally abundant number of ethical and legal problems associated with its application in healthcare. There are manifold stakeholders in the legal and ethical issues revolving around AI and medicine. Thus, a multifaceted approach involving policymakers, developers, healthcare providers and patients is crucial to arrive at a feasible solution for mitigating the legal and ethical problems pertaining to AI in healthcare. © 2022 by the authors.},
	author_keywords = {application in healthcare; artificial intelligence; artificial intelligence in healthcare; autonomy; deep learning; ethical complications; ethics; legal and ethical guidelines; machine learning; medical ethics},
	keywords = {artificial intelligence; clinical practice; conceptual framework; decision making; deep learning; doctor patient relationship; health care cost; health care industry; health care personnel; health care policy; health care system; health insurance; health service; human; knowledge gap; machine learning; medical liability; medical practice; mental health care; meta analysis (topic); patient safety; practice guideline; professional standard; Review; risk assessment; stakeholder engagement; systematic review (topic)},
	correspondence_address = {K.M. Surapaneni; SMAART Population Health Informatics Intervention Center, Foundation of Healthcare Technologies Society, Panimalar Medical College Hospital & Research Institute, Chennai, Varadharajapuram, Poonamallee, Tamil Nadu, 600 123, India; email: krishnamohan.surapaneni@gmail.com},
	publisher = {MDPI},
	issn = {20754426},
	language = {English},
	abbrev_source_title = {J. Pers. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Alhussain2022,
	author = {Alhussain, Ghadeer and Kelly, Alexandra and O'Flaherty, Ellerose I. and Quinn, Darragh P. and Flaherty, Gerard T.},
	title = {Emerging role of artificial intelligence in global health care},
	year = {2022},
	journal = {Health Policy and Technology},
	volume = {11},
	number = {3},
	doi = {10.1016/j.hlpt.2022.100661},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135939177&doi=10.1016%2fj.hlpt.2022.100661&partnerID=40&md5=0318584235e4cbb4664992fce5cc07bf},
	affiliations = {School of Medicine, University of Galway, Galway, Ireland; School of Medicine, International Medical University, Kuala Lumpur, Malaysia},
	author_keywords = {Algorithm; Global health; Health systems; Health technology; Machine learning; Medical ethics; Sustainable development goals},
	keywords = {Article; artificial intelligence; clinical practice; coronavirus disease 2019; global health; health care access; health care delivery; health care industry; health disparity; human; machine learning; medical ethics; medical information; pandemic; sustainable development goal; workflow},
	correspondence_address = {G.T. Flaherty; School of Medicine, National University of Ireland Galway, Galway, Ireland; email: gerard.flaherty@nuigalway.ie},
	publisher = {Elsevier B.V.},
	issn = {22118837},
	language = {English},
	abbrev_source_title = {Health Policy Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Takats2022,
	author = {Takats, Courtney and Kwan, Amy and Wormer, Rachel and Goldman, Dari and Jones, Heidi E. and Romero, Diana},
	title = {Ethical and Methodological Considerations of Twitter Data for Public Health Research: Systematic Review},
	year = {2022},
	journal = {Journal of Medical Internet Research},
	volume = {24},
	number = {11},
	doi = {10.2196/40380},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143088567&doi=10.2196%2f40380&partnerID=40&md5=93085aa736190155740ec042055e671a},
	affiliations = {City University of New York School of Public Health, New York City, NY, United States},
	abstract = {Background: Much research is being carried out using publicly available Twitter data in the field of public health, but the types of research questions that these data are being used to answer and the extent to which these projects require ethical oversight are not clear. Objective: This review describes the current state of public health research using Twitter data in terms of methods and research questions, geographic focus, and ethical considerations including obtaining informed consent from Twitter handlers. Methods: We implemented a systematic review, following PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, of articles published between January 2006 and October 31, 2019, using Twitter data in secondary analyses for public health research, which were found using standardized search criteria on SocINDEX, PsycINFO, and PubMed. Studies were excluded when using Twitter for primary data collection, such as for study recruitment or as part of a dissemination intervention. Results: We identified 367 articles that met eligibility criteria. Infectious disease (n=80, 22%) and substance use (n=66, 18%) were the most common topics for these studies, and sentiment mining (n=227, 62%), surveillance (n=224, 61%), and thematic exploration (n=217, 59%) were the most common methodologies employed. Approximately one-third of articles had a global or worldwide geographic focus; another one-third focused on the United States. The majority (n=222, 60%) of articles used a native Twitter application programming interface, and a significant amount of the remainder (n=102, 28%) used a third-party application programming interface. Only one-third (n=119, 32%) of studies sought ethical approval from an institutional review board, while 17% of them (n=62) included identifying information on Twitter users or tweets and 36% of them (n=131) attempted to anonymize identifiers. Most studies (n=272, 79%) included a discussion on the validity of the measures and reliability of coding (70% for interreliability of human coding and 70% for computer algorithm checks), but less attention was paid to the sampling frame, and what underlying population the sample represented. Conclusions: Twitter data may be useful in public health research, given its access to publicly available information. However, studies should exercise greater caution in considering the data sources, accession method, and external validity of the sampling frame. Further, an ethical framework is necessary to help guide future research in this area, especially when individual, identifiable Twitter users and tweets are shared and discussed. © Courtney Takats, Amy Kwan, Rachel Wormer, Dari Goldman, Heidi E Jones, Diana Romero. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 29.11.2022. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.},
	author_keywords = {ethical considerations; ethical framework; ethics; public health; public health ethics; public health research; research ethics; research topics; social media; systematic review; Twitter; Twitter data},
	keywords = {Access to Information; Humans; Public Health; PubMed; Reproducibility of Results; Social Media; anonymised data; anonymization; chronic disease; controlled study; data mining; Ebola hemorrhagic fever; eligibility criteria; exploratory research; geographic information system; health promotion; human; identifiable information; influenza; informed consent; lockdown; machine learning; malignant neoplasm; medical research; Medline; metadata; natural language processing; practice guideline; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; PsycINFO; public health; quality control; research ethics; Review; sample size; social media; substance use; systematic review; thematic analysis; Zika fever; access to information; reproducibility},
	correspondence_address = {C. Takats; City University of New York School of Public Health, New York City, 55 W 125th St, 10027, United States; email: courttakats14@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {36445739},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tacconelli2022,
	author = {Tacconelli, Evelina and Gorska, Anna and Carrara, Elena and Davis, Ruth Joanna and Bonten, Marc and Friedrich, Alex W. and Glasner, Corinna and Goossens, Herman and Hasenauer, Jan and Abad, Josep Maria Haro and Peñalvo, José L. and Sanchez-Niubo, Albert and Sialm, Anastassja and Scipione, Gabriella and Soriano, Gloria and Yazdanpanah, Yazdan and Vorstenbosch, Ellen and Jaenisch, Thomas},
	title = {Challenges of data sharing in European Covid-19 projects: A learning opportunity for advancing pandemic preparedness and response},
	year = {2022},
	journal = {The Lancet Regional Health - Europe},
	volume = {21},
	doi = {10.1016/j.lanepe.2022.100467},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136633208&doi=10.1016%2fj.lanepe.2022.100467&partnerID=40&md5=49cddb7c3861f921753809dcf80753b3},
	affiliations = {Infectious Diseases Division, Department of Diagnostics and Public Health, University of Verona, Verona, Italy; Julius Center for Health Sciences and Primary Care, UMC Utrecht, Netherlands; Department of Medical Microbiology and Infection Prevention, University of Groningen, University Medical Center Groningen, Groningen, Netherlands; University Hospital Münster, Münster, Germany; Laboratory of Medical Microbiology, Vaccine and Infectious Diseases Institute, University of Antwerp, Antwerp, Belgium; Life and Medical Sciences Institute, University of Bonn, Bonn, Germany; Institute of Computational Biology, Helmholtz Center Munich - German Research Center for Environmental Health, Neuherberg, Germany; CIBER en Salud Mental (CIBERSAM). Instituto de Salud Carlos III, Madrid, Spain; Parc Sanitari Sant Joan de Déu, Sant Boi de Llobregat, Spain; Department of Public Health, Institute of Tropical Medicine, Antwerp, Belgium; Department of Social Psychology and Quantitative Psychology. Faculty of Psychology, University of Barcelona, Barcelona, Spain; Schweizer Paraplegiker-Zentrum, Nottwil, Switzerland; Supercomputing Applications and Innovation Department, Cineca Consorzio Interuniversitario, Casalecchio di Reno, 40033, Italy; INSERM, IAME, Hôpital Bichat - Claude-Bernard, Infectious Diseases Department, France; Heidelberg Institute of Global Health, Heidelberg University Hospital, Heidelberg, Germany},
	abstract = {The COVID-19 pandemic saw a massive investment into collaborative research projects with a focus on producing data to support public health decisions. We relay our direct experience of four projects funded under the Horizon2020 programme, namely ReCoDID, ORCHESTRA, unCoVer and SYNCHROS. The projects provide insight into the complexities of sharing patient level data from observational cohorts. We focus on compliance with the General Data Protection Regulation (GDPR) and ethics approvals when sharing data across national borders. We discuss procedures for data mapping; submission of new international codes to standards organisation; federated approach; and centralised data curation. Finally, we put forward recommendations for the development of guidelines for the application of GDPR in case of major public health threats; mandatory standards for data collection in funding frameworks; training and capacity building for data owners; cataloguing of international use of metadata standards; and dedicated funding for identified critical areas. © 2022 The Authors},
	author_keywords = {Cohort study; Data sharing; General Data Protection Regulation; Machine learning; Pandemic; Preparedeness; SARS-CoV-2},
	correspondence_address = {E. Tacconelli; University of Verona: Universita degli Studi di Verona, Diagnostics and Public Health, Verona, Piazzale Ludovico Antonio Scuro n.10, 37134, Italy; email: evelina.tacconelli@univr.it},
	publisher = {Elsevier Ltd},
	issn = {26667762},
	language = {English},
	abbrev_source_title = {Lancet. Reg. Health. Eur.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Benner2022,
	author = {Benner, Jordan and Lertzman, Ken},
	title = {Policy interventions and competing management paradigms shape the long-term distribution of forest harvesting across the landscape},
	year = {2022},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	volume = {119},
	number = {41},
	doi = {10.1073/pnas.2208360119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139092652&doi=10.1073%2fpnas.2208360119&partnerID=40&md5=8b08351b0c2463ffc99b4ca5b3f46256},
	affiliations = {School of Resource and Environmental Management, Simon Fraser University, Burnaby, V5A 1S6, BC, Canada},
	abstract = {Industrial economic models of natural resource management often incentivize the sequential harvesting of resources based on profitability, disproportionately targeting the higher-value elements of the environment. In fisheries, this issue is framed as a problem of “fishing down the food chain” when these elements represent different trophic levels or sequential depletion more generally. Harvesting that focuses on high grading the most profitable, productive, and accessible components of environmental gradients is also thought to occur in the forestry sector. Such a paradigm is inconsistent with a stewardship ethic, entrenched in the forestry literature, that seeks to maintain or enhance forest condition over time. We ask 1) how these conflicting paradigms have influenced patterns of forest harvesting over time and 2) whether more recent conservation-oriented policies influenced these historical harvesting patterns. We use detailed harvest data over a 47-y period and aggregated time series data that span over a century on the central coast of British Columbia, Canada to assess temporal changes in how logging is distributed among various classes of site productivity and terrain accessibility, corresponding to timber value. Most of this record shows a distinct trend of harvesting shifting over time to less productive stands, with some evidence of harvesting occurring in increasingly less accessible forests. However, stewardship-oriented policy changes enacted in the mid-1990s appear to have strongly affected these trends. This illustrates both a profit-maximizing tendency to log down the value chain when choices are unconstrained and the potential of policy choices to impose a greater stewardship ethic on harvesting behavior. Copyright © 2022 the Author(s). Published by PNAS.},
	author_keywords = {forest harvesting patterns; government policies; serial depletion; shifting baseline; stewardship},
	keywords = {British Columbia; Conservation of Natural Resources; Forestry; Forests; Policy; Trees; Article; burnout; climate change; decision making; economic model; eutrophication; fishery; fishing; food chain; forest; freshwater environment; geographic distribution; government; harvesting; human; industrialization; machine learning; marine environment; natural resource; productivity; profit; river; satellite imagery; seashore; seasonal variation; species distribution; time series analysis; trophic level; British Columbia; environmental protection; forestry; policy; tree},
	correspondence_address = {J. Benner; School of Resource and Environmental Management, Simon Fraser University, Burnaby, V5A 1S6, Canada; email: jordan_benner@sfu.ca},
	publisher = {National Academy of Sciences},
	issn = {00278424},
	coden = {PNASA},
	pmid = {36191184},
	language = {English},
	abbrev_source_title = {Proc. Natl. Acad. Sci. U. S. A.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@BOOK{Gloor20221,
	author = {Gloor, Peter A.},
	title = {Happimetrics},
	year = {2022},
	journal = {Happimetrics},
	pages = {1 – 223},
	doi = {10.4337/9781803924021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160461871&doi=10.4337%2f9781803924021&partnerID=40&md5=8f6065a85b9a8c2ca13b6761c9305a2d},
	affiliations = {MIT Center for Collective Intelligence, United States; University of Cologne, Germany; Galaxyadvisors AG, United States},
	abstract = {Based on 20 years of research, this book lays out a proven and tested method for reaching the goal of employee happiness, analyzing individuals' communication patterns, and making them self-aware by mirroring their behaviour back to them in a privacy-respecting way. In doing so, Peter A. Gloor introduces artificial intelligence-based methods to identify personality, moral values, and ethics of individuals based on their body language and interaction with others. In this book readers will:;understand the basic concepts of groupflow-when teams collaborate at their best through intrinsic motivation and positive stress;learn how to use artificial intelligence (AI), machine learning (ML) and social network analysis (SNA) to analyze communication by tracking emotions, social networks, morals, and tribes;successfully use virtual mirroring to create entangled teams that work together in collaborative innovation networks (COINs) synchronized and in harmony for superior performance;understand how to implement virtual mirroring using these technologies. Groundbreaking and innovative, Happimetrics will be an invaluable resource for scholars and students in the fields of business analytics, information systems and organizational innovation. It will also be useful for HR professionals and AI developers who are looking to use predictive analytics to measure workforce performance. © Peter A. Gloor 2022. All rights reserved.},
	publisher = {Edward Elgar Publishing Ltd.},
	isbn = {978-180392402-1; 978-180392401-4},
	language = {English},
	abbrev_source_title = {Happimetrics},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Brew-Sam2022,
	author = {Brew-Sam, Nicola and Parkinson, Anne and Lueck, Christian and Brown, Ellen and Brown, Karen and Bruestle, Anne and Chisholm, Katrina and Collins, Simone and Cook, Matthew and Daskalaki, Eleni and Drew, Janet and Ebbeck, Harry and Elisha, Mark and Fanning, Vanessa and Henschke, Adam and Herron, Jessica and Matthews, Emma and Murugappan, Krishnan and Neshev, Dragomir and Nolan, Christopher J and Pedley, Lachlan and Phillips, Christine and Suominen, Hanna and Tricoli, Antonio and Wright, Kristine and Desborough, Jane},
	title = {The current understanding of precision medicine and personalised medicine in selected research disciplines: study protocol of a systematic concept analysis},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {9},
	doi = {10.1136/bmjopen-2021-060326},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138154490&doi=10.1136%2fbmjopen-2021-060326&partnerID=40&md5=a0fadc18c4b5faaa01987d04e6b094d8},
	affiliations = {National Centre for Epidemiology and Population Health, College of Health and Medicine, Australian National University, Canberra, ACT, Australia; School of Medicine and Psychology, College of Health and Medicine, Australian National University, Canberra, ACT, Australia; Department of Neurology, Canberra Health Services, Canberra, ACT, Australia; The Centenary Hospital for Women and Children, Canberra Health Services, Canberra, ACT, Australia; The John Curtin School of Medical Research, College of Health and Medicine, Australian National University, Canberra, ACT, Australia; School of Computing, College of Engineering and Computer Science, Australian National University, Canberra, ACT, Australia; Department of Philosophy, University of Twente, Overijssel, Enschede, Netherlands; Nanotechnology Research Lab, Research School of Chemistry, College of Science, Australian National University, Canberra, ACT, Australia; Csiro, Mineral Resources, Clayton South, VIC, Australia; Department of Electronic Materials Engineering, Research School of Physics, College of Science, Australian National University, Canberra, ACT, Australia; Department of Endocrinology and Diabetes, Canberra Health Services, Canberra, ACT, Australia; Department of Computing, University of Turku, Turku, Finland; Nanotechnology Research Laboratory, Faculty of Engineering, The University of Sydney, Sydney, NSW, Australia},
	abstract = {Introduction The terms precision medicine' and personalised medicine' have become key terms in health-related research and in science-related public communication. However, the application of these two concepts and their interpretation in various disciplines are heterogeneous, which also affects research translation and public awareness. This leads to confusion regarding the use and distinction of the two concepts. Our aim is to provide a snapshot of the current understanding of these concepts. Methods and analysis Our study will use Rodgers' evolutionary concept analysis to systematically examine the current understanding of the concepts precision medicine' and personalised medicine' in clinical medicine, biomedicine (incorporating genomics and bioinformatics), health services research, physics, chemistry, engineering, machine learning and artificial intelligence, and to identify their respective attributes (clusters of characteristics) and surrogate and related terms. A systematic search of the literature will be conducted for 2016-2022 using databases relevant to each of these disciplines: ACM Digital Library, CINAHL, Cochrane Library, F1000Research, IEEE Xplore, PubMed/Medline, Science Direct, Scopus and Web of Science. These are among the most representative databases for the included disciplines. We will examine similarities and differences in definitions of precision medicine' and personalised medicine' in the respective disciplines and across (sub)disciplines, including attributes of each term. This will enable us to determine how these two concepts are distinguished. Ethics and dissemination Following ethical and research standards, we will comprehensively report the methodology for a systematic analysis following Rodgers' concept analysis method. Our systematic concept analysis will contribute to the clarification of the two concepts and distinction in their application in given settings and circumstances. Such a broad concept analysis will contribute to non-systematic syntheses of the concepts, or occasional systematic reviews on one of the concepts that have been published in specific disciplines, in order to facilitate interdisciplinary communication, translational medical research and implementation science. ©},
	author_keywords = {Protocols & guidelines; QUALITATIVE RESEARCH; STATISTICS & RESEARCH METHODS},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Precision Medicine; article; artificial intelligence; bioinformatics; biomedicine; Cinahl; clinical medicine; Cochrane Library; concept analysis; genomics; health services research; human; implementation science; interdisciplinary communication; library; machine learning; Medline; personalized medicine; physics; practice guideline; qualitative research; ScienceDirect; Scopus; synthesis; systematic review; translational research; Web of Science; artificial intelligence},
	correspondence_address = {N. Brew-Sam; National Centre for Epidemiology and Population Health, College of Health and Medicine, Australian National University, Canberra, Australia; email: Nicola.Brew-Sam@anu.edu.au},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36691172},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kaspersen2022,
	author = {Kaspersen, Magnus Høholt and Bilstrup, Karl-Emil Kjær and Van Mechelen, Maarten and Hjort, Arthur and Bouvin, Niels Olof and Petersen, Marianne Graves},
	title = {High school students exploring machine learning and its societal implications: Opportunities and challenges},
	year = {2022},
	journal = {International Journal of Child-Computer Interaction},
	volume = {34},
	doi = {10.1016/j.ijcci.2022.100539},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138995010&doi=10.1016%2fj.ijcci.2022.100539&partnerID=40&md5=bede1b3fa0f523a3dd8ac88a257fa39e},
	affiliations = {Department of Computer Science, Aarhus University, Å bogade 34, Aarhus, 8200, Denmark; Center for Computational Thinking & Design, Helsingforsgade 14, Aarhus, 8200, Denmark},
	abstract = {The increased use of AI and machine learning (ML) calls for a general AI literacy, in particular regarding understanding how ML works, the process behind creating ML models, and reflecting on its implications. Where existing learning tools focus on the first two, we explore opportunities and challenges for meaningfully engaging students in understanding and reflecting on ML in their everyday life. We designed VotestratesML, following a Constructive Design Research approach, as an ethics-first learning tool that allow students to explore implications of ML for democratic elections. Based on deployments of VotestratesML in two high school social studies classrooms, we found that safely exploring ML from a concrete starting point helped students reflect and form opinions about its use, that promoting iterative exploration through collaboration and competition motivated them to explore, and that foregrounding ethics in the design and grounding ML in a well-known subject area allowed them to engage with ML on a personal level. © 2022 The Author(s)},
	author_keywords = {AI literacy; Computational empowerment; Computational thinking; Learning tools; Machine learning},
	correspondence_address = {M.H. Kaspersen; Department of Computer Science, Aarhus University, Aarhus, Å bogade 34, 8200, Denmark; email: magnushk@cs.au.dk},
	publisher = {Elsevier B.V.},
	issn = {22128689},
	language = {English},
	abbrev_source_title = {Int. J. Child-Computer Interact.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Meerwijk2022,
	author = {Meerwijk, Esther Lydia and Tamang, Suzanne R. and Finlay, Andrea K. and Ilgen, Mark A. and Reeves, Ruth M. and Harris, Alex H. S.},
	title = {Suicide theory-guided natural language processing of clinical progress notes to improve prediction of veteran suicide risk: Protocol for a mixed-method study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {8},
	doi = {10.1136/bmjopen-2022-065088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136495598&doi=10.1136%2fbmjopen-2022-065088&partnerID=40&md5=ab43633e360c9a0bfc71e4e247b33bb9},
	affiliations = {Va Health Services Research and Development, Center for Innovation to Implementation, Va Palo Alto Health Care System, Palo Alto, CA, United States; Department of Biomedical Data Science, Stanford University, Stanford, CA, United States; Schar School of Policy and Government, George Mason University, Arlington, VA, United States; Va National Center on Homelessness among Veterans, Durham, NC, United States; Department of Psychiatry, University of Michigan, Ann Arbor, MI, United States; Va Health Services Research and Development, Center for Clinical Management Research, Va Ann Arbor Health Care System, Ann Arbor, MI, United States; Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, United States; Va Health Sevices Research and Development, Va Tennessee Valley Health Care System, Nashville, TN, United States; Stanford-Surgical Policy Improvement Research and Education Center, Stanford University School of Medicine, Stanford, CA, United States},
	abstract = {Introduction The state-of-the-art 3-step Theory of Suicide (3ST) describes why people consider suicide and who will act on their suicidal thoughts and attempt suicide. The central concepts of 3ST - psychological pain, hopelessness, connectedness, and capacity for suicide - are among the most important drivers of suicidal behaviour but they are missing from clinical suicide risk prediction models in use at the US Veterans Health Administration (VHA). These four concepts are not systematically recorded in structured fields of VHA's electronic healthcare records. Therefore, this study will develop a domain-specific ontology that will enable automated extraction of these concepts from clinical progress notes using natural language processing (NLP), and test whether NLP-based predictors for these concepts improve accuracy of existing VHA suicide risk prediction models. Methods and analysis Our mixed-method study has an exploratory sequential design where a qualitative component (aim 1) will inform quantitative analyses (aims 2 and 3). For aim 1, subject matter experts will manually annotate progress notes of clinical encounters with veterans who attempted or died by suicide to develop a domain-specific ontology for the 3ST concepts. During aim 2, we will use NLP to machine-annotate clinical progress notes and derive longitudinal representations for each patient with respect to the presence and intensity of hopelessness, psychological pain, connectedness and capacity for suicide in temporal proximity of suicide attempts and deaths by suicide. These longitudinal representations will be evaluated during aim 3 for their ability to improve existing VHA prediction models of suicide and suicide attempts, STORM (Stratification Tool for Opioid Risk Mitigation) and REACHVET (Recovery Engagement and Coordination for Health - Veterans Enhanced Treatment). Ethics and dissemination Ethics approval for this study was granted by the Stanford University Institutional Review Board and the Research and Development Committee of the VA Palo Alto Health Care System. Results of the study will be disseminated through several outlets, including peer-reviewed publications and presentations at national conferences.  © },
	author_keywords = {Health & safety; Health informatics; MENTAL HEALTH; PREVENTIVE MEDICINE; Risk management; Suicide & self-harm},
	keywords = {Humans; Natural Language Processing; Pain; Suicidal Ideation; Suicide, Attempted; Veterans; adult; ancestry group; Article; clinician; electronic medical record; health care system; hopelessness; human; machine learning; natural language processing; pain; practice guideline; prediction; qualitative analysis; suicidal behavior; suicidal ideation; suicide; suicide attempt; veteran; natural language processing; psychology; suicide attempt},
	correspondence_address = {E.L. Meerwijk; Va Health Services Research and Development, Center for Innovation to Implementation, Va Palo Alto Health Care System, Palo Alto, United States; email: esther.meerwijk@va.gov},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36002210},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Davidescu2022,
	author = {Davidescu, Adriana AnaMaria and Manta, Eduard Mihai and Stoica-Ungureanu, Adina Teodora and Anton, Magdalena},
	title = {Could Religiosity and Religion Influence the Tax Morale of Individuals? An Empirical Analysis Based on Variable Selection Methods},
	year = {2022},
	journal = {Mathematics},
	volume = {10},
	number = {23},
	doi = {10.3390/math10234497},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143603876&doi=10.3390%2fmath10234497&partnerID=40&md5=d0b08b6d9417d71ba47c0f42b59c7422},
	affiliations = {Department of Statistics and Econometrics, The Bucharest University of Economic Studies, Bucharest, 010552, Romania; Department of Education, Training and Labour Market, National Scientific Research, Institute for Labour and Social Protection, Bucharest, 010643, Romania; Doctoral School of Cybernetics and Statistics, Bucharest University of Economic Studies, Bucharest, 010374, Romania},
	abstract = {When people who adhere to tax morality act in a situation where there is no sense of risk, no acceptance of the government, or no environment conducive to tax compliance, it is easier to see how they are motivated to do so. Tax morality is also known as the ethics of compliance. It is the independent cause that motivates a positive tax behaviour. Employees’ religious beliefs may impact their ideas and actions in organizational life, just as individuals’ attitudes, values, emotions, abilities, and behaviours influence their thoughts and actions at work. Religion can positively influence a worker’s loyalty, morale, and communication. In this context, the research seeks to determine whether religiosity and religion may have an effect on tax morale, examining whether an individual’s religiosity reduces tax evasion and increases the degree of tax morale. Using machine learning variable selection techniques appropriate for categorical variables, we have used the dataset of the Joint EVS/WVS 2017-2020 (European Value Survey/World Value Survey), allowing for comparisons of tax morality in more than 79 nations globally (chi-squared and mutual information). The empirical findings showed that the most important aspects of religiosity, such as religious denomination, belief in God, and the significance of God, along with the degree of trust placed in other religions and churches, have a considerable positive impact on the level of tax morale. Another significant conclusion relates to how much people feel the government is responsible, how much they care about their nation, and how satisfied they are with the political system—findings that have been shown to boost employee morale. The following are a person’s primary traits that indicate their financial morale: an adult above the age of 25, a full-time worker or retired person, married, and living alone. Therefore, employees that are morally upright, trustworthy, diligent, and committed to the workplace values of justice and decency raise morale generally and improve an organisation’s success. A business may enhance its reputation and help to secure its long-term success by establishing behavioural policies. © 2022 by the authors.},
	author_keywords = {Joint EVS/WVS 2017-2020; religion; religiosity; tax compliance; tax morale; variable selection method; work environment},
	correspondence_address = {A.A. Davidescu; Department of Statistics and Econometrics, The Bucharest University of Economic Studies, Bucharest, 010552, Romania; email: adriana.alexandru@csie.ase.ro},
	publisher = {MDPI},
	issn = {22277390},
	language = {English},
	abbrev_source_title = {Mathematics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Liang2022741,
	author = {Liang, W.Q. and Chen, T. and Yu, J.},
	title = {Application and progress of artificial intelligence technology in gastric cancer diagnosis and treatment},
	year = {2022},
	journal = {Zhonghua wei chang wai ke za zhi = Chinese journal of gastrointestinal surgery},
	volume = {25},
	number = {8},
	pages = {741 – 746},
	doi = {10.3760/cma.j.cn441530-20220329-00120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135990169&doi=10.3760%2fcma.j.cn441530-20220329-00120&partnerID=40&md5=e60bfbf51135961cb98314cfa6aa3435},
	affiliations = {Department of General Surgery, Nanfang Hospital, Southern Medical University, Guangdong Provincial Key Laboratory of Precision Medicine for Gastrointestinal Cancer, Guangzhou, 510515, China},
	abstract = {人工智能（AI）是生物医学领域过去十年中发展最快的新技术领域之一。以影像组学、机器学习和深度神经网络等为代表的AI技术，因其能从医学资料中高通量地获取特征信息、分析特征数据并挖掘揭示数据与医疗结果之间的潜在联系，愈发被研究者青睐。胃癌在我国具有较高的发病率和死亡率，而将AI技术和内镜、影像、病理及测序分析等相结合的检查手段，已经在胃癌的辅助诊断、疾病分期和预后以及疗效预测等方面取得了重要的进展。AI在医疗行业中的应用极大提升了高通量数据的有效利用率，加速了疾病诊疗的智能化进程，但同时也在医学伦理、患者隐私和医疗AI的法律主体地位等方面产生了许多问题。未来，合理地规划和管理AI技术，有望为推动医学发展及重塑医疗行业提供强大的动力。.; Artificial intelligence (AI) is one of the most rapidly evolving fields in biomedicine during the past decade. Represented by radiomics, machine learning and deep neural network, AI has been increasingly favored by researchers due to its ability to obtain feature information and discover the potential relationship between data and medical outcomes from high-throughput medical data. The incidence and mortality of gastric cancer (GC) has remained high in China. Through combining AI technology with medical examination such as endoscopy, imaging, pathological examination and sequencing, clinical researchers have made great progress in the auxiliary diagnosis, disease staging, prognosis and curative effect prediction of patients with GC. Although the intervention of AI in the medical industry has greatly improved the effective utilization of high-throughput data and accelerated the intelligent process of disease diagnosis and treatment, a number of problems has been raised in medical ethics, patient privacy and the legal status of medical AI at the same time. In the future, rational planning and management of AI technology will provide a strong impetus to promote the development of medicine and reshape the medical industry.},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Neural Networks, Computer; Stomach Neoplasms; Technology; artificial intelligence; human; machine learning; stomach tumor; technology},
	publisher = {NLM (Medline)},
	issn = {16710274},
	pmid = {35970811},
	language = {Chinese},
	abbrev_source_title = {Zhonghua Wei Chang Wai Ke Za Zhi},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Bogina2022808,
	author = {Bogina, Veronika and Hartman, Alan and Kuflik, Tsvi and Shulner-Tal, Avital},
	title = {Educating Software and AI Stakeholders About Algorithmic Fairness, Accountability, Transparency and Ethics},
	year = {2022},
	journal = {International Journal of Artificial Intelligence in Education},
	volume = {32},
	number = {3},
	pages = {808 – 833},
	doi = {10.1007/s40593-021-00248-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105022576&doi=10.1007%2fs40593-021-00248-0&partnerID=40&md5=cbdf5e79bb18ad48f437ad588753d1a8},
	affiliations = {University of Haifa, Haifa, Israel},
	abstract = {This paper discusses educating stakeholders of algorithmic systems (systems that apply Artificial Intelligence/Machine learning algorithms) in the areas of algorithmic fairness, accountability, transparency and ethics (FATE). We begin by establishing the need for such education and identifying the intended consumers of educational materials on the topic. We discuss the topics of greatest concern and in need of educational resources; we also survey the existing materials and past experiences in such education, noting the scarcity of suitable material on aspects of fairness in particular. We use an example of a college admission platform to illustrate our ideas. We conclude with recommendations for further work in the area and report on the first steps taken towards achieving this goal in the framework of an academic graduate seminar course, a graduate summer school, an embedded lecture in a software engineering course, and a workshop for high school teachers. © 2021, International Artificial Intelligence in Education Society.},
	author_keywords = {Accountability; Algorithmic literacy; Education; Fairness; Transparency},
	keywords = {Learning algorithms; Philosophical aspects; Software engineering; Teaching; Technical presentations; Transparency; College admissions; Educational materials; Educational resource; Further works; High school teachers; Software engineering course; Summer school; Artificial intelligence},
	correspondence_address = {V. Bogina; University of Haifa, Haifa, Israel; email: sveron@gmail.com},
	publisher = {Springer},
	issn = {15604292},
	language = {English},
	abbrev_source_title = {Int. J. Artif. Intell. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@ARTICLE{Kim2022482,
	author = {Kim, Amanda and Hsu, Michael and Koire, Amanda and Baum, Matthew L.},
	title = {Incidental Findings from Deep Phenotyping Research in Psychiatry: Legal and Ethical Considerations},
	year = {2022},
	journal = {Cambridge Quarterly of Healthcare Ethics},
	volume = {31},
	number = {4},
	pages = {482 – 486},
	doi = {10.1017/S0963180122000135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142161999&doi=10.1017%2fS0963180122000135&partnerID=40&md5=bff2ce478325d8b24072a8e4bc6109dc},
	affiliations = {Department of Psychiatry, Brigham and Women's Hospital, Boston, 02115, MA, United States},
	abstract = {Substantial advancement in the diagnosis and treatment of psychiatric disorders may come from assembling diverse data streams from clinical notes, neuroimaging, genetics, and real-time digital footprints from smartphones and wearable devices. This is called deep phenotyping and often involves machine learning. We argue that incidental findings arising in deep phenotyping research have certain special, morally and legally salient features: They are specific, actionable, numerous, and probabilistic. We consider ethical and legal implications of these features and propose a practical ethics strategy for managing them.  © 2022 The Author(s). Published by Cambridge University Press.},
	author_keywords = {deep phenotyping; ethics; incidental findings; machine learning; psychiatry; smart phones},
	keywords = {Humans; Incidental Findings; Mental Disorders; Morals; Neuroimaging; Psychiatry; human; incidental finding; mental disease; morality; neuroimaging; psychiatry},
	correspondence_address = {M.L. Baum; Department of Psychiatry, Brigham and Women's Hospital, Boston, 02115, United States; email: mbaum@bwh.harvard.edu},
	publisher = {Cambridge University Press},
	issn = {09631801},
	pmid = {36398513},
	language = {English},
	abbrev_source_title = {Camb. Q. Healthc. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Roy2022,
	author = {Roy, Sudipta and Meena, Tanushree and Lim, Se-Jung},
	title = {Demystifying Supervised Learning in Healthcare 4.0: A New Reality of Transforming Diagnostic Medicine},
	year = {2022},
	journal = {Diagnostics},
	volume = {12},
	number = {10},
	doi = {10.3390/diagnostics12102549},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140635489&doi=10.3390%2fdiagnostics12102549&partnerID=40&md5=5465f01681023c2b25d41b7144b19fb4},
	affiliations = {Artificial Intelligence Data Science, Jio Institute, Navi Mumbai, 410206, India; Division of Convergence, Honam University, 120, Honamdae-gil, Gwangsan-gu, Gwangju, 62399, South Korea},
	abstract = {The global healthcare sector continues to grow rapidly and is reflected as one of the fastest-growing sectors in the fourth industrial revolution (4.0). The majority of the healthcare industry still uses labor-intensive, time-consuming, and error-prone traditional, manual, and manpower-based methods. This review addresses the current paradigm, the potential for new scientific discoveries, the technological state of preparation, the potential for supervised machine learning (SML) prospects in various healthcare sectors, and ethical issues. The effectiveness and potential for innovation of disease diagnosis, personalized medicine, clinical trials, non-invasive image analysis, drug discovery, patient care services, remote patient monitoring, hospital data, and nanotechnology in various learning-based automation in healthcare along with the requirement for explainable artificial intelligence (AI) in healthcare are evaluated. In order to understand the potential architecture of non-invasive treatment, a thorough study of medical imaging analysis from a technical point of view is presented. This study also represents new thinking and developments that will push the boundaries and increase the opportunity for healthcare through AI and SML in the near future. Nowadays, SML-based applications require a lot of data quality awareness as healthcare is data-heavy, and knowledge management is paramount. Nowadays, SML in biomedical and healthcare developments needs skills, quality data consciousness for data-intensive study, and a knowledge-centric health management system. As a result, the merits, demerits, and precautions need to take ethics and the other effects of AI and SML into consideration. The overall insight in this paper will help researchers in academia and industry to understand and address the future research that needs to be discussed on SML in the healthcare and biomedical sectors. © 2022 by the authors.},
	author_keywords = {artificial intelligence; computer vision; deep learning; healthcare; medical imaging; precision medicine; supervised learning; XAI},
	keywords = {algorithm; artificial intelligence; biomedicine; cancer diagnosis; clinical practice; clinical trial (topic); comparative study; computer vision; data quality; diabetic retinopathy; diagnosis; diagnostic accuracy; diagnostic imaging; drug design; health care; health care management; heart disease; hospital; human; image analysis; immunomics; internet of things; knowledge management; malignant neoplasm; medical ethics; nanotechnology; neurologic disease; non invasive procedure; pandemic; patient care; patient monitoring; personalized medicine; prediction; radiomics; reproducibility; Review; robot assisted surgery; skin disease; supervised machine learning; synthetic biology; team building; teleconsultation; telemonitoring},
	correspondence_address = {S. Roy; Artificial Intelligence Data Science, Jio Institute, Navi Mumbai, 410206, India; email: sudipta1.roy@jioinstitute.edu.in; S.-J. Lim; Division of Convergence, Honam University, Gwangju, 120, Honamdae-gil, Gwangsan-gu, 62399, South Korea; email: limsejung@honam.ac.kr},
	publisher = {MDPI},
	issn = {20754418},
	language = {English},
	abbrev_source_title = {Diagn.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kulikowski2022317,
	author = {Kulikowski, Casimir A.},
	title = {Ethics in the History of Medical Informatics for Decision-Making: Early Challenges to Digital Health Goals},
	year = {2022},
	journal = {Yearbook of Medical Informatics},
	volume = {31},
	number = {1},
	pages = {317 – 322},
	doi = {10.1055/s-0042-1742491},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141840023&doi=10.1055%2fs-0042-1742491&partnerID=40&md5=ca26da54cd468bdd3323f5ac6fb66e75},
	affiliations = {Department of Computer Science, Rutgers University, United States},
	abstract = {Background: Inclusive digital health prioritizes public engagement through digital literacies and internet/web connectivity for advancing and scaling healthcare equitably by informatics technologies. This is badly needed, largely desirable and uncontroversial. However, historically, medical and healthcare practices and their informatics processes assume that individual clinical encounters between practitioners and patients are the indispensable foundation of clinical practice. This assumption has been dramatically challenged by expansion of digital technologies, their interconnectable mobility, virtuality, surveillance informatics, and the vastness of data repositories for individuals and populations that enable and support them. This article is a brief historical commentary emphasizing critical ethical issues about decisions in clinical interactions or encounters raised in the early days of the field. These questions, raised eloquently by François Grémy in 1985, have become urgently relevant to the equity/fairness, inclusivity and unbiasedness desired of today's pervasive digital health systems. Objectives: The main goal of this article is to highlight how the personal freedoms of choice, values, and responsibilities arising in relationships between physicians and healthcare practitioners and their patients in the clinical encounter can be distorted by digital health technologies which focus more on efficiency, productivity, and scalability of healthcare processes. Understanding the promise and limitations of early and current decision-support systems and the analytics of community or population data can help place into historical context the often exaggerated claims made today about Artificial Intelligence and Machine Learning solving clinical problems with algorithms and data, downplaying the role of the clinical judgments and responsibilities inherent in personal clinical encounters. Methods: A review of selected early articles in medical informatics is related to current literature on the ethical issues and technological inadequacies involved in the design and implementation of clinical systems for decision-making. Early insights and cautions about the development of decision support technologies raised questions about the ethical responsibilities in clinical encounters where freedom of personal choice can be so easily limited through the constraints from information processing and reliance on prior expertise frequently driven more by administrative rather than clinical objectives. These anticipated many of the deeper ethical problems that have arisen since then in clinical informatics. Conclusions: Early papers on ethics in clinical decision-making provide prescient commentary on the dangers of not taking into account the complexities of individual human decision making in clinical encounters. These include the excessive reliance on data and experts, and oversimplified models of human reasoning, all of which persist and have become amplified today as urgent questions about how inclusivity, equity, and bias are handled in practical systems where ethical responsibilities of individuals patients and practitioners intertwine with those of groups within professional or other communities, and are central to how clinical encounters evolve in our digital health future. © 2022 IMIA and Georg Thieme Verlag KG.},
	author_keywords = {artificial intelligence; clinical decision-making; delivery of health care; digital technology; Ethics; informatics; machine learning},
	keywords = {Artificial Intelligence; Delivery of Health Care; Goals; Humans; Medical Informatics; artificial intelligence; health care delivery; human; medical informatics; motivation},
	correspondence_address = {C.A. Kulikowski; Department of Computer Science, Rutgers - The State University of New Jersey, Piscataway, 08855, United States; email: kulikows@cs.rutgers.edu},
	publisher = {Thieme Medical Publishers, Inc.},
	issn = {09434747},
	pmid = {35654428},
	language = {English},
	abbrev_source_title = {Yearb Med Inform},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Vadapalli2022,
	author = {Vadapalli, Sreya and Abdelhalim, Habiba and Zeeshan, Saman and Ahmed, Zeeshan},
	title = {Artificial intelligence and machine learning approaches using gene expression and variant data for personalized medicine},
	year = {2022},
	journal = {Briefings in Bioinformatics},
	volume = {23},
	number = {5},
	doi = {10.1093/bib/bbac191},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134562978&doi=10.1093%2fbib%2fbbac191&partnerID=40&md5=17af3d3176ba65ac6a7d73c96379e1b1},
	affiliations = {Rutgers Institute for Health, Health Care Policy and Aging Research, Rutgers University, 112 Paterson St, New Brunswick, NJ, United States; Rutgers Cancer Institute of New Jersey, Rutgers University, 195 Little Albany St, New Brunswick, NJ, United States; Department of Medicine, Robert Wood Johnson Medical School, Rutgers Biomedical and Health Sciences, 125 Paterson St, New Brunswick, NJ, United States},
	abstract = {Precision medicine uses genetic, environmental and lifestyle factors to more accurately diagnose and treat disease in specific groups of patients, and it is considered one of the most promising medical efforts of our time. The use of genetics is arguably the most data-rich and complex components of precision medicine. The grand challenge today is the successful assimilation of genetics into precision medicine that translates across different ancestries, diverse diseases and other distinct populations, which will require clever use of artificial intelligence (AI) and machine learning (ML) methods. Our goal here was to review and compare scientific objectives, methodologies, datasets, data sources, ethics and gaps of AI/ML approaches used in genomics and precision medicine. We selected high-quality literature published within the last 5 years that were indexed and available through PubMed Central. Our scope was narrowed to articles that reported application of AI/ML algorithms for statistical and predictive analyses using whole genome and/or whole exome sequencing for gene variants, and RNA-seq and microarrays for gene expression. We did not limit our search to specific diseases or data sources. Based on the scope of our review and comparative analysis criteria, we identified 32 different AI/ML approaches applied in variable genomics studies and report widely adapted AI/ML algorithms for predictive diagnostics across several diseases. © 2022 The Author(s).},
	author_keywords = {artificial intelligence; gene expression; gene variant; machine learning; predictive analysis},
	correspondence_address = {Z. Ahmed; Department of Medicine, Robert Wood Johnson Medical School, Rutgers Biomedical and Health Sciences, New Brunswick, 125 Paterson St, 08901-1293, United States; email: zahmed@ifh.rutgers.edu},
	publisher = {Oxford University Press},
	issn = {14675463},
	language = {English},
	abbrev_source_title = {Brief. Bioinform.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@ARTICLE{Bashir2022,
	author = {Bashir, Muwada Bashir Awad and Basna, Rani and Zhang, Guo-Qiang and Backman, Helena and Lindberg, Anne and Ekerljung, Linda and Axelsson, Malin and Hedman, Linnea and Vanfleteren, Lowie and Lundbäck, Bo and Rönmark, Eva and Nwaru, Bright I.},
	title = {Computational phenotyping of obstructive airway diseases: protocol for a systematic review},
	year = {2022},
	journal = {Systematic Reviews},
	volume = {11},
	number = {1},
	doi = {10.1186/s13643-022-02078-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139812629&doi=10.1186%2fs13643-022-02078-0&partnerID=40&md5=3271b72284ef6caddf22b1c55eb7a75f},
	affiliations = {Krefting Research Centre, Institute of Medicine, University of Gothenburg, Gothenburg, SE-405 30, Sweden; Section of Sustainable Health/the OLIN Unit, Department of Public Health and Clinical Medicine, Umeå University, Umeå, Sweden; Section of Medicine/the OLIN Unit, Department of Public Health and Clinical Medicine, Umeå University, Umeå, Sweden; Department of Care Science, Faculty of Health and Society, Malmö University, Malmö, Sweden; Department of Health Sciences, Luleå University of Technology, Luleå, Sweden; COPD Center, Sahlgrenska University Hospital, University of Gothenburg, Gothenburg, Sweden; Wallenberg Centre for Molecular and Translational Medicine, Institute of Medicine, University of Gothenburg, Gothenburg, Sweden},
	abstract = {Background: Over the last decade, computational sciences have contributed immensely to characterization of phenotypes of airway diseases, but it is difficult to compare derived phenotypes across studies, perhaps as a result of the different decisions that fed into these phenotyping exercises. We aim to perform a systematic review of studies using computational approaches to phenotype obstructive airway diseases in children and adults. Methods and analysis: We will search PubMed, Embase, Scopus, Web of Science, and Google Scholar for papers published between 2010 and 2020. Conferences proceedings, reference list of included papers, and experts will form additional sources of literature. We will include observational epidemiological studies that used a computational approach to derive phenotypes of chronic airway diseases, whether in a general population or in a clinical setting. Two reviewers will independently screen the retrieved studies for eligibility, extract relevant data, and perform quality appraisal of included studies. A third reviewer will arbitrate any disagreements in these processes. Quality appraisal of the studies will be undertaken using the Effective Public Health Practice Project quality assessment tool. We will use summary tables to describe the included studies. We will narratively synthesize the generated evidence, providing critical assessment of the populations, variables, and computational approaches used in deriving the phenotypes across studies Conclusion: As progress continues to be made in the area of computational phenotyping of chronic obstructive airway diseases, this systematic review, the first on this topic, will provide the state of the art on the field and highlight important perspectives for future works. Ethics and dissemination: No ethical approval is needed for this work is based only on the published literature and does not involve collection of any primary or human data. reporting: Systematic review registration: PROSPERO CRD42020164898. © 2022, The Author(s).},
	author_keywords = {Airway disease; Asthma; Clustering; Computation; COPD; Machine learning; Phenotype; Systematic review},
	keywords = {Adult; Asthma; Child; Exercise; Exercise Therapy; Humans; Pulmonary Disease, Chronic Obstructive; Research Design; Systematic Reviews as Topic; Article; clinical outcome; computer model; human; knowledge; machine learning; Newcastle-Ottawa scale; obstructive airway disease; phenotype; quality assessment tool; systematic review; adult; asthma; child; chronic obstructive lung disease; exercise; kinesiotherapy; methodology},
	correspondence_address = {M.B.A. Bashir; Krefting Research Centre, Institute of Medicine, University of Gothenburg, Gothenburg, SE-405 30, Sweden; email: muwada.bashir@gu.se},
	publisher = {BioMed Central Ltd},
	issn = {20464053},
	pmid = {36229872},
	language = {English},
	abbrev_source_title = {Syst. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ruttenberg-Rozen202244,
	author = {Ruttenberg-Rozen, Robyn and Hynes, Katelin},
	title = {A Feminist Ethics of Care Within Counterspaces: Supporting Inclusion in Postsecondary ICT Education},
	year = {2022},
	journal = {IEEE Technology and Society Magazine},
	volume = {41},
	number = {4},
	pages = {44 – 53},
	doi = {10.1109/MTS.2022.3219164},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145616237&doi=10.1109%2fMTS.2022.3219164&partnerID=40&md5=fe185ee933d4f78cffd5e05fb1cebf70},
	affiliations = {Ontario Tech University, Faculty of Education, Oshawa, L1H 4X8, Canada},
	abstract = {There is a dichotomy in computing education. The information communication technology (ICT) field, which includes all areas that pertain to technology, computing, or computational reasoning (e.g., computer science, computer engineering, and machine learning), needs diversity to thrive. Yet, the undergraduate programs that support the field have a difficult time attracting and retaining that diversity [1]. In undergraduate education, ICT is one of the most exclusionary of the science, technology, engineering, and mathematics (STEM) cultures [2] for women. Exclusion challenges a woman's sense of belonging [3] and identity-her sense of 'personal relevance, ownership, and integration into the sense of self' [4, p. 208]. Significantly, women's intersectional identities (e.g., the intersection of race, gender, and disability) frame their experiences with oppression, causing problematic experiences in ICT education to compound and hurt computing identity [5].  © 1982-2012 IEEE.},
	keywords = {Professional aspects; Computer engineering; Computing education; Education informations; Engineering learning; Information communication technology; Machine-learning; Technology education; Technology fields; Undergraduate education; Undergraduate projects; Engineering education},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {02780097},
	coden = {ITSMD},
	language = {English},
	abbrev_source_title = {IEEE Technol Soc Mag},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kelley20223039,
	author = {Kelley, Stephanie and Ovchinnikov, Anton and Hardoon, David R. and Heinrich, Adrienne},
	title = {Antidiscrimination Laws, Artificial Intelligence, and Gender Bias: A Case Study in Nonmortgage Fintech Lending},
	year = {2022},
	journal = {Manufacturing and Service Operations Management},
	volume = {24},
	number = {6},
	pages = {3039 – 3059},
	doi = {10.1287/msom.2022.1108},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148415951&doi=10.1287%2fmsom.2022.1108&partnerID=40&md5=58e1f6b470cfaed522b597aa26b2a1f9},
	affiliations = {Smith School of Business, Queen’s University, Kingston, K7L 3N6, ON, Canada; INSEAD, Fontainebleau, 77300, France; Artificial Intelligence and Innovation Center of Excellence, Union Bank of the Philippines, and Aboitiz Data Innovation, Pasig City, 1605, Philippines},
	abstract = {Problem definition: We use a realistically large, publicly available data set from a global fintech lender to simulate the impact of different antidiscrimination laws and their corresponding data management and model-building regimes on gender-based discrimination in the nonmortgage fintech lending setting. Academic/practical relevance: Our paper extends the conceptual understanding of model-based discrimination from computer science to a realistic context that simulates the situations faced by fintech lenders in practice, where advanced machine learning (ML) techniques are used with high-dimensional, feature-rich, highly multicollinear data. We provide technically and legally permissible approaches for firms to reduce discrimination across different antidiscrimination regimes whilst managing profitability. Methodology: We train statistical and ML models on a large and realistically rich publicly available data set to simulate different antidiscrimination regimes and measure their impact on model quality and firm profitability. We use ML explainability techniques to understand the drivers of ML discrimination. Results: We find that regimes that prohibit the use of gender (like those in the United States) substantially increase discrimination and slightly decrease firm profitability. We observe that ML models are less discriminatory, of better predictive quality, and more profitable compared with traditional statistical models like logistic regression. Unlike omitted variable bias—which drives discrimination in statistical models—ML discrimination is driven by changes in the model training procedure, including feature engineering and feature selection, when gender is excluded. We observe that down sampling the training data to rebalance gender, gender-aware hyperparameter selection, and up sampling the training data to rebalance gender all reduce discrimination, with varying trade-offs in predictive quality and firm profitability. Probabilistic gender proxy modeling (imputing applicant gender) further reduces discrimination with negligible impact on predictive quality and a slight increase in firm profitability. Managerial implications: A rethink is required of the antidiscrimination laws, specifically with respect to the collection and use of protected attributes for ML models. Firms should be able to collect protected attributes to, at minimum, measure discrimination and ideally, take steps to reduce it. Increased data access should come with greater accountability for firms. © 2022 The Author(s)},
	author_keywords = {artificial intelligence; bias; discrimination; ethics; fintech; gender; law; machine learning},
	keywords = {Digital storage; Economic and social effects; Information management; Logistic regression; Profitability; Bias; Data set; Discrimination; Firm profitabilities; Gender; Law; Machine learning models; Machine-learning; Statistic modeling; Training data; Machine learning},
	correspondence_address = {S. Kelley; Smith School of Business, Queen’s University, Kingston, K7L 3N6, Canada; email: stephanie.kelley@queensu.ca},
	publisher = {INFORMS Inst.for Operations Res.and the Management Sciences},
	issn = {15234614},
	coden = {MSOMF},
	language = {English},
	abbrev_source_title = {Manuf. Serv. Oper. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Malins2022,
	author = {Malins, Sam and Figueredo, Grazziela and Jilani, Tahseen and Long, Yunfei and Andrews, Jacob and Rawsthorne, Mat and Manolescu, Cosmin and Clos, Jeremie and Higton, Fred and Waldram, David and Hunt, Daniel and Vallejos, Elvira Perez and Moghaddam, Nima},
	title = {Developing an Automated Assessment of In-session Patient Activation for Psychological Therapy: Codevelopment Approach},
	year = {2022},
	journal = {JMIR Medical Informatics},
	volume = {10},
	number = {11},
	doi = {10.2196/38168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145421740&doi=10.2196%2f38168&partnerID=40&md5=893edd13d5ffee6161dc10f5886588b4},
	affiliations = {Specialist Services, Nottinghamshire Healthcare NHS Foundation Trust, Nottingham, United Kingdom; School of Computer Science, University of Nottingham, Nottingham, United Kingdom; School of Computer Science and Electronic Engineering, University of Essex, Essex, United Kingdom; Mindtech Medtech Co-operative, University of Nottingham, Nottingham, United Kingdom; Hilltop Digital Lab Ltd, Stockport, United Kingdom; Institute of Mental Health, University of Nottingham, Nottingham, United Kingdom; School of English, University of Nottingham, Nottingham, United Kingdom; Nottingham Biomedical Research Centre Mental Health and Technology Theme, University of Nottingham, Nottingham, United Kingdom; School of Psychology, University of Lincoln, Lincoln, United Kingdom},
	abstract = {Background: Patient activation is defined as a patient’s confidence and perceived ability to manage their own health. Patient activation has been a consistent predictor of long-term health and care costs, particularly for people with multiple long-term health conditions. However, there is currently no means of measuring patient activation from what is said in health care consultations. This may be particularly important for psychological therapy because most current methods for evaluating therapy content cannot be used routinely due to time and cost restraints. Natural language processing (NLP) has been used increasingly to classify and evaluate the contents of psychological therapy. This aims to make the routine, systematic evaluation of psychological therapy contents more accessible in terms of time and cost restraints. However, comparatively little attention has been paid to algorithmic trust and interpretability, with few studies in the field involving end users or stakeholders in algorithm development. Objective: This study applied a responsible design to use NLP in the development of an artificial intelligence model to automate the ratings assigned by a psychological therapy process measure: the consultation interactions coding scheme (CICS). The CICS assesses the level of patient activation observable from turn-by-turn psychological therapy interactions. Methods: With consent, 128 sessions of remotely delivered cognitive behavioral therapy from 53 participants experiencing multiple physical and mental health problems were anonymously transcribed and rated by trained human CICS coders. Using participatory methodology, a multidisciplinary team proposed candidate language features that they thought would discriminate between high and low patient activation. The team included service-user researchers, psychological therapists, applied linguists, digital research experts, artificial intelligence ethics researchers, and NLP researchers. Identified language features were extracted from the transcripts alongside demographic features, and machine learning was applied using k-nearest neighbors and bagged trees algorithms to assess whether in-session patient activation and interaction types could be accurately classified. Results: The k-nearest neighbors classifier obtained 73% accuracy (82% precision and 80% recall) in a test data set. The bagged trees classifier obtained 81% accuracy for test data (87% precision and 75% recall) in differentiating between interactions rated high in patient activation and those rated low or neutral. Conclusions: Coproduced language features identified through a multidisciplinary collaboration can be used to discriminate among psychological therapy session contents based on patient activation among patients experiencing multiple long-term physical and mental health conditions. ©Sam Malins, Grazziela Figueredo, Tahseen Jilani, Yunfei Long, Jacob Andrews, Mat Rawsthorne, Cosmin Manolescu, Jeremie Clos, Fred Higton, David Waldram, Daniel Hunt, Elvira Perez Vallejos, Nima Moghaddam.},
	author_keywords = {cognitive behavioral therapy; machine learning; mental health; multimorbidity; natural language processing; responsible artificial intelligence},
	correspondence_address = {S. Malins; Specialist Services, Nottinghamshire Healthcare NHS Foundation Trust, Nottingham, Triumph Road, NG7 2TU, United Kingdom; email: sam.malins@nottingham.ac.uk},
	publisher = {JMIR Publications Inc.},
	issn = {22919694},
	language = {English},
	abbrev_source_title = {JMIR Med. Inform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Van Spanning2022,
	author = {Van Spanning, Sanne H and Verweij, Lukas P E and Allaart, Laurens J H and Hendrickx, Laurent A M and Doornberg, Job N and Athwal, George S and Lafosse, Thibault and Lafosse, Laurent and Van Den Bekerom, Michel P J and Buijze, Geert Alexander},
	title = {Development and training of a machine learning algorithm to identify patients at risk for recurrence following an arthroscopic Bankart repair (CLEARER): protocol for a retrospective, multicentre, cohort study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {9},
	doi = {10.1136/bmjopen-2021-055346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138202324&doi=10.1136%2fbmjopen-2021-055346&partnerID=40&md5=a854745e0b938a964fe78c715bf0c931},
	affiliations = {Orthopaedic Surgery, Olvg, Noord-Holland, Amsterdam, Netherlands; Hand Upper Limb, Peripheral Nerve, Brachial Plexus and Microsurgery Unit, Alps Surgery Institute, Annecy, France; Department of Human Movement Sciences, Faculty of Behavioural and Movement Sciences, Vrije Universiteit Amsterdam, Amsterdam, Netherlands; Orthopedic Surgery, Amsterdam Movement Sciences, Amsterdam Umc Locatie Amc, North Holland, Amsterdam, Netherlands; Academic Center for Evidence-based Sports Medicine (ACES), Amsterdam Umc Locatie Amc, North Holland, Amsterdam, Netherlands; Amsterdam Collaboration for Health and Safety in Sports (ACHSS), International Olympic Committee (IOC) Research Centre, Amsterdam Umc, Amsterdam, Netherlands; Department of Orthopaedic & Trauma Surgery, Flinders Medical Centre, Flinders University, Adelaide, SA, Australia; Roth McFarlane Hand and Upper Limb Center, Schulich School of Medicine and Dentistry, London, ON, Canada; Department of Orthopaedic Surgery, Montpellier University Medical Center, Languedoc-Roussillon, Montpellier, France},
	abstract = {Introduction Shoulder instability is a common injury, with a reported incidence of 23.9 per 100 000 person-years. There is still an ongoing debate on the most effective treatment strategy. Non-operative treatment has recurrence rates of up to 60%, whereas operative treatments such as the Bankart repair and bone block procedures show lower recurrence rates (16% and 2%, respectively) but higher complication rates (<2% and up to 30%, respectively). Methods to determine risk of recurrence have been developed; however, patient-specific decision-making tools are still lacking. Artificial intelligence and machine learning algorithms use self-learning complex models that can be used to make patient-specific decision-making tools. The aim of the current study is to develop and train a machine learning algorithm to create a prediction model to be used in clinical practice - as an online prediction tool - to estimate recurrence rates following a Bankart repair. Methods and analysis This is a multicentre retrospective cohort study. Patients with traumatic anterior shoulder dislocations that were treated with an arthroscopic Bankart repair without remplissage will be included. This study includes two parts. Part 1, collecting all potential factors influencing the recurrence rate following an arthroscopic Bankart repair in patients using multicentre data, aiming to include data from >1000 patients worldwide. Part 2, the multicentre data will be re-evaluated (and where applicable complemented) using machine learning algorithms to predict outcomes. Recurrence will be the primary outcome measure. Ethics and dissemination For safe multicentre data exchange and analysis, our Machine Learning Consortium adhered to the WHO regulation Policy on Use and Sharing of Data Collected by WHO in Member States Outside the Context of Public Health Emergencies'. The study results will be disseminated through publication in a peer-reviewed journal. No Institutional Review Board is required for this study.  © },
	author_keywords = {Adult orthopaedics; Elbow & shoulder; Shoulder},
	keywords = {Arthroscopy; Artificial Intelligence; Cohort Studies; Humans; Joint Instability; Machine Learning; Multicenter Studies as Topic; Recurrence; Retrospective Studies; Shoulder Joint; adult; algorithm; arthroscopic Bankart repair; Article; Cochrane Library; cohort analysis; Embase; human; machine learning; Medline; meta analysis; outcome assessment; patient coding; practice guideline; random forest; recurrence risk; recurrent disease; recurrent shoulder dislocation; retrospective study; shoulder dislocation; systematic review; adverse event; arthroscopy; artificial intelligence; joint instability; machine learning; multicenter study (topic); procedures; recurrent disease; shoulder},
	correspondence_address = {S.H. Van Spanning; Orthopaedic Surgery, Olvg, Amsterdam, Noord-Holland, Netherlands; email: shvanspanning@gmail.com},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36508223},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Pap2022,
	author = {Pap, Iuliu Alexandru and Oniga, Stefan},
	title = {A Review of Converging Technologies in eHealth Pertaining to Artificial Intelligence},
	year = {2022},
	journal = {International Journal of Environmental Research and Public Health},
	volume = {19},
	number = {18},
	doi = {10.3390/ijerph191811413},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138398199&doi=10.3390%2fijerph191811413&partnerID=40&md5=e488a2b00200b9ce7121d6b598c7c4b6},
	affiliations = {Department of Electric, Electronic and Computer Engineering, Technical University of Cluj-Napoca, North University Center of Baia Mare, Baia Mare, 430083, Romania; Department of IT Systems and Networks, Faculty of Informatics, University of Debrecen, Debrecen, 4032, Hungary},
	abstract = {Over the last couple of years, in the context of the COVID-19 pandemic, many healthcare issues have been exacerbated, highlighting the paramount need to provide both reliable and affordable health services to remote locations by using the latest technologies such as video conferencing, data management, the secure transfer of patient information, and efficient data analysis tools such as machine learning algorithms. In the constant struggle to offer healthcare to everyone, many modern technologies find applicability in eHealth, mHealth, telehealth or telemedicine. Through this paper, we attempt to render an overview of what different technologies are used in certain healthcare applications, ranging from remote patient monitoring in the field of cardio-oncology to analyzing EEG signals through machine learning for the prediction of seizures, focusing on the role of artificial intelligence in eHealth. © 2022 by the authors.},
	author_keywords = {artificial intelligence; brain–computer interface; deep learning; eHealth; Internet of Things; machine learning; mHealth; remote patient monitoring; telehealth; telemedicine},
	keywords = {Artificial Intelligence; COVID-19; Delivery of Health Care; Humans; Pandemics; Telemedicine; artificial intelligence; brain; computer; health care; information technology; Internet; medicine; monitoring; artificial intelligence; cardiology; clinical practice; computer security; data privacy; deep learning; electroencephalogram; health care access; health care cost; health care system; human; medical ethics; medical information; medical technology; mhealth; oncology; patient care; prediction; Review; seizure; social aspect; telehealth; telemedicine; telemonitoring; usability; artificial intelligence; epidemiology; health care delivery; pandemic; telemedicine},
	correspondence_address = {I.A. Pap; Department of Electric, Electronic and Computer Engineering, Technical University of Cluj-Napoca, North University Center of Baia Mare, Baia Mare, 430083, Romania; email: iuliu.pap@ieec.utcluj.ro},
	publisher = {MDPI},
	issn = {16617827},
	pmid = {36141685},
	language = {English},
	abbrev_source_title = {Int. J. Environ. Res. Public Health},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Lv2022,
	author = {Lv, Lilang and Xin, Bowen and Hao, Yichao and Yang, Ziyi and Xu, Junyan and Wang, Lisheng and Wang, Xiuying and Song, Shaoli and Guo, Xiaomao},
	title = {Radiomic analysis for predicting prognosis of colorectal cancer from preoperative 18F-FDG PET/CT},
	year = {2022},
	journal = {Journal of Translational Medicine},
	volume = {20},
	number = {1},
	doi = {10.1186/s12967-022-03262-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123973712&doi=10.1186%2fs12967-022-03262-5&partnerID=40&md5=015f04ced5dea377b8bcace3f6cd7f18},
	affiliations = {Department of Radiotherapy, Fudan University Shanghai Cancer Center, No.270 Dong’an Road, Xuhui district, Shanghai, 200032, China; School of Computer Science, The University of Sydney, Sydney, NSW, Australia; Department of Nuclear Medicine, Fudan University Shanghai Cancer Center, No.270 Dong’an Road, Xuhui district, Shanghai, 200032, China; Department of Automation, Shanghai Jiao Tong University, Shanghai, 200240, China; Department of Oncology, Shanghai Medical College, Fudan University, Shanghai, China; Center for Biomedical Imaging, Fudan University, Shanghai, China; Shanghai Engineering Research Center of Molecular Imaging Probes, Shanghai, China},
	abstract = {Background: To develop and validate a survival model with clinico-biological features and 18F- FDG PET/CT radiomic features via machine learning, and for predicting the prognosis from the primary tumor of colorectal cancer. Methods: A total of 196 pathologically confirmed patients with colorectal cancer (stage I to stage IV) were included. Preoperative clinical factors, serum tumor markers, and PET/CT radiomic features were included for the recurrence-free survival analysis. For the modeling and validation, patients were randomly divided into the training (n = 137) and validation (n = 59) set, while the 78 stage III patients [training (n = 55), and validation (n = 23)] was divided for the further experiment. After selecting features by the log-rank test and variable-hunting methods, random survival forest (RSF) models were built on the training set to analyze the prognostic value of selected features. The performance of models was measured by C-index and was tested on the validation set with bootstrapping. Feature importance and the Pearson correlation were also analyzed. Results: Radiomics signature (containing four PET/CT features and four clinical factors) achieved the best result for prognostic prediction of 196 patients (C-index 0.780, 95% CI 0.634–0.877). Moreover, four features (including two clinical features and two radiomics features) were selected for prognostic prediction of the 78 stage III patients (C-index was 0.820, 95% CI 0.676–0.900). K–M curves of both models significantly stratified low-risk and high-risk groups (P < 0.0001). Pearson correlation analysis demonstrated that selected radiomics features were correlated with tumor metabolic factors, such as SUVmean, SUVmax. Conclusion: This study presents integrated clinico-biological-radiological models that can accurately predict the prognosis in colorectal cancer using the preoperative 18F-FDG PET/CT radiomics in colorectal cancer. It is of potential value in assisting the management and decision making for precision treatment in colorectal cancer. Trial registration The retrospectively registered study was approved by the Ethics Committee of Fudan University Shanghai Cancer Center (No. 1909207-14-1910) and the data were analyzed anonymously. © 2022, The Author(s).},
	author_keywords = {         <sup>18</sup>F-FDG PET/CT; Prediction; Prognosis; Radiomics; Stage III Colorectal cancer},
	keywords = {China; Colorectal Neoplasms; Fluorodeoxyglucose F18; Humans; Positron Emission Tomography Computed Tomography; Prognosis; fluorodeoxyglucose f 18; fluorodeoxyglucose f 18; Article; bootstrapping; cancer prognosis; cancer staging; case study; colorectal cancer; controlled study; high risk population; human; image analysis; immunohistochemistry; low risk population; major clinical study; positron emission tomography-computed tomography; prediction; preoperative period; radiation dose; radiomics; random forest; random survival forest; recurrence free survival; retrospective study; China; colorectal tumor; diagnostic imaging; procedures; prognosis; randomized controlled trial},
	correspondence_address = {X. Guo; Department of Radiotherapy, Fudan University Shanghai Cancer Center, Shanghai, No.270 Dong’an Road, Xuhui district, 200032, China; email: guoxm1800@126.com; S. Song; Department of Nuclear Medicine, Fudan University Shanghai Cancer Center, Shanghai, No.270 Dong’an Road, Xuhui district, 200032, China; email: shaoli-song@163.com},
	publisher = {BioMed Central Ltd},
	issn = {14795876},
	pmid = {35109864},
	language = {English},
	abbrev_source_title = {J. Transl. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hetherington20221211,
	author = {Hetherington, Jorden and Brohan, Janette and Rohling, Robert and Gunka, Vit and Abolmaesumi, Purang and Albert, Arianne and Chau, Anthony},
	title = {A novel ultrasound software system for lumbar level identification in obstetric patients; [Un nouveau logiciel d’échographie pour l’identification du niveau lombaire chez les patientes obstétricales]},
	year = {2022},
	journal = {Canadian Journal of Anesthesia},
	volume = {69},
	number = {10},
	pages = {1211 – 1219},
	doi = {10.1007/s12630-022-02300-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135700009&doi=10.1007%2fs12630-022-02300-6&partnerID=40&md5=ab00c51b4d7c13293cecf55f209c7934},
	affiliations = {Department of Electrical and Computer Engineering, The University of British Columbia, 2332 Main Mall, Vancouver, V6T 1Z4, BC, Canada; Department of Anesthesia, BC Women’s Hospital, Vancouver, BC, Canada; Department of Mechanical Engineering, The University of British Columbia, Vancouver, BC, Canada; Department of Anesthesiology, Pharmacology & Therapeutics, The University of British Columbia, Vancouver, BC, Canada; Women’s Health Research Institute, BC Women’s Hospital and Health Centre, Vancouver, BC, Canada},
	abstract = {Purpose: Using machine learning, we developed a proprietary ultrasound software called the Spine Level Identification (SLIDE) system, which automatically identifies lumbar landmarks in real time as the operator slides the transducer over the lumber spine. Here, we assessed the agreement between SLIDE and manual palpation and traditional lumbar ultrasound (LUS) for determining the primary target L3–4 interspace. Methods: Upon institutional ethics approval and informed consent, 76 healthy term parturients scheduled for elective Caesarean delivery were recruited. The L3–4 interspace was identified by manual palpation and then by the SLIDE method. The reference standard was located using traditional LUS by an experienced operator. The primary outcome was the L3–4 interspace identification agreement of manual palpation and SLIDE with the reference standard, as percentage agreement and Gwet’s agreement coefficient (AC1). Results: The raw agreement was 70% with Gwet’s agreement coefficient (AC1) = 0.59 (95% confidence interval [CI], 0.41 to 0.77) for manual palpation and 84% with Gwet’s AC1 = 0.82 (95% CI, 0.70 to 0.93) for SLIDE. When the levels differ from the reference, the manual palpation method identified L2–3 more often than L4–5 while the SLIDE method identified equally above or below L3–4. The SLIDE system had greater agreement than palpation in locating L3–4 and all other lumber interspaces after controlling for body mass index (adjusted odds ratio, 2.99; 95% CI, 1.21 to 8.7; P = 0.02). Conclusion: The SLIDE system had higher agreement with traditional ultrasound than manual palpation did in identifying L3–4 and all other lumber interspaces after adjusting for BMI in healthy term obstetric patients. Future studies should examine factors that affect agreement and ways to improve SLIDE for clinical integration. Study Registration: www.ClinicalTrials.gov (NCT02982317); registered 5 December 2016. © 2022, Canadian Anesthesiologists' Society.},
	author_keywords = {automated ultrasound; lumbar ultrasound; machine learning; neuraxial ultrasound; obstetric anesthesia},
	keywords = {Female; Humans; Lumbar Vertebrae; Lumbosacral Region; Palpation; Pregnancy; Software; Spine; Ultrasonography; adult; Article; automation; body mass; cesarean section; confidence interval; controlled clinical trial; controlled study; echography; elective surgery; female; human; lumbar ultrasound; machine learning; major clinical study; obstetric anesthesia; obstetric patient; palpation; patient identification; prospective study; software; diagnostic imaging; echography; lumbar vertebra; lumbosacral region; palpation; pregnancy; procedures; software; spine},
	publisher = {Springer},
	issn = {0832610X},
	coden = {CJOAE},
	pmid = {35941333},
	language = {English},
	abbrev_source_title = {Can. J. Anesth.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Arnold2022359,
	author = {Arnold, Thomas and Scheutz, Matthias},
	title = {Extended norms: locating accountable decision-making in contexts of human-robot interaction},
	year = {2022},
	journal = {Gruppe. Interaktion. Organisation. Zeitschrift fur Angewandte Organisationspsychologie},
	volume = {53},
	number = {3},
	pages = {359 – 366},
	doi = {10.1007/s11612-022-00645-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137480781&doi=10.1007%2fs11612-022-00645-6&partnerID=40&md5=ae808cbf6aa7d2fe6783a5cf4934f499},
	affiliations = {Tufts University Human-Robot Interaction Laboratory, Department of Computer Science, School of Engineering, Tufts University, 420 Joyce Cummings Center, 177 College Avenue, Medford, 02155, MA, United States},
	abstract = {Machine ethics has sought to establish how autonomous systems could make ethically appropriate decisions in the world. While mere statistical machine learning approaches have focused on learning human preferences from observations and attempted actions, hybrid approaches to machine ethics attempt to provide more explicit guidance for robots based on explicit norm representations. Neither approach, however, might be sufficient for real contexts of human-robot interaction, where reasoning and exchange of information may need to be distributed across automated processes and human improvisation, requiring real-time coordination within a dynamic environment (sharing information, trusting in other agents, and arriving at revised plans together). This paper builds on discussions of “extended minds” in philosophy to examine norms as “extended” systems supported by external cues and an agent’s own applications of norms in concrete contexts. Instead of locating norms solely as discrete representations within the AI system, we argue that explicit normative guidance must be extended across human-machine collaborative activity as what does and does not constitute a normative context, and within a norm, might require negotiation of incompletely specified or derive principles that not be self-contained, but become accessible as a result of the agent’s actions and interactions and thus representable by agents in social space. © 2022, The Author(s), under exclusive licence to Springer Fachmedien Wiesbaden GmbH, ein Teil von Springer Nature.},
	author_keywords = {Artificial intelligence; Ethics; Explainability; Human-robot interaction; Norms},
	correspondence_address = {T. Arnold; Tufts University Human-Robot Interaction Laboratory, Department of Computer Science, School of Engineering, Tufts University, Medford, 420 Joyce Cummings Center, 177 College Avenue, 02155, United States; email: thomas.arnold@tufts.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23666145},
	language = {English},
	abbrev_source_title = {Gruppe. Interaktion. Organisation. Zeitschrift fur Angewandte Organisationspsychologie},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Lee2022,
	author = {Lee, Clifford H. and Gobir, Nimah and Gurn, Alex and Soep, Elisabeth},
	title = {In the Black Mirror: Youth Investigations into Artificial Intelligence},
	year = {2022},
	journal = {ACM Transactions on Computing Education},
	volume = {22},
	number = {3},
	doi = {10.1145/3484495},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140042675&doi=10.1145%2f3484495&partnerID=40&md5=bffa3e7da45505e41c9389928c45b8bb},
	affiliations = {Mills College at Northeastern University, School of Education & YR Media, 5000 MacArthur Blvd, Oakland, 94613, CA, United States; YR Media, 1701 Broadway, Oakland, 94612, CA, United States; 2203 McGee Avenue, Berkeley, 94703, CA, United States},
	abstract = {Over the past two decades, innovations powered by artificial intelligence (AI) have extended into nearly all facets of human experience. Our ethnographic research suggests that while young people sense they can't "trust"AI, many are not sure how it works or how much control they have over its growing role in their lives. In this study, we attempt to answer the following questions: (1) What can we learn about young people's understanding of AI when they produce media with and about it? and (2) What are the design features of an ethics-centered pedagogy that promotes STEM engagement via AI? To answer these questions, we co-developed and documented three projects at YR Media, a national network of youth journalists and artists who create multimedia for public distribution. Participants are predominantly youth of color and those contending with economic and other barriers to full participation in STEM fields. Findings showed that by creating a learning ecology that centered the cultures and experiences of its learners while leveraging familiar tools for critical analysis, youth deepened their understanding of AI. Our study also showed that providing opportunities for youth to produce ethics-centered interactive stories interrogating invisibilized AI functionalities, and to release those stories to the public, empowered them to creatively express their understandings and apprehensions about AI. © 2022 Association for Computing Machinery.},
	author_keywords = {agency; artificial intelligence; computational thinking; Critical pedagogy; engagement; ethics-centered; machine learning; media},
	keywords = {Ethical technology; Agency; Computational thinkings; Critical pedagogies; Design features; Engagement; Ethic-centered; Learn+; Machine-learning; Medium; Young peoples; Machine learning},
	publisher = {Association for Computing Machinery},
	issn = {19466226},
	language = {English},
	abbrev_source_title = {ACM J. Trans. Comput. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Gaudiano2022,
	author = {Gaudiano, Caterina and Mottola, Margherita and Bianchi, Lorenzo and Corcioni, Beniamino and Cattabriga, Arrigo and Cocozza, Maria Adriana and Palmeri, Antonino and Coppola, Francesca and Giunchi, Francesca and Schiavina, Riccardo and Fiorentino, Michelangelo and Brunocilla, Eugenio and Golfieri, Rita and Bevilacqua, Alessandro},
	title = {Beyond Multiparametric MRI and towards Radiomics to Detect Prostate Cancer: A Machine Learning Model to Predict Clinically Significant Lesions},
	year = {2022},
	journal = {Cancers},
	volume = {14},
	number = {24},
	doi = {10.3390/cancers14246156},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144902162&doi=10.3390%2fcancers14246156&partnerID=40&md5=5672474d3fe0f6a14d7f49b561427855},
	affiliations = {Department of Radiology, IRCCS Azienda Ospedaliero-Universitaria di Bologna, Bologna, 40138, Italy; Department of Experimental, Diagnostic and Specialty Medicine (DIMES), University of Bologna, Bologna, 40138, Italy; Division of Urology, IRCCS Azienda Ospedaliero-Universitaria di Bologna, Bologna, 40138, Italy; Radiology Unit, “Infermi” Hospital, Faenza, 48018, Italy; SIRM Foundation, Italian Society of Medical and Interventional Radiology, Milano, 20122, Italy; Department of Pathology, IRCCS Azienda Ospedaliero-Universitaria di Bologna, Bologna, 40138, Italy; Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, 40126, Italy},
	abstract = {The risk of misclassifying clinically significant prostate cancer (csPCa) by multiparametric magnetic resonance imaging is consistent, also using the updated PIRADS score and although different definitions of csPCa, patients with Gleason Grade group (GG) ≥ 3 have a significantly worse prognosis. This study aims to develop a machine learning model predicting csPCa (i.e., any GG ≥ 3 lesion at target biopsy) by mpMRI radiomic features and analyzing similarities between GG groups. One hundred and two patients with 117 PIRADS ≥ 3 lesions at mpMRI underwent target+systematic biopsy, providing histologic diagnosis of PCa, 61 GG < 3 and 56 GG ≥ 3. Features were generated locally from an apparent diffusion coefficient and selected, using the LASSO method and Wilcoxon rank-sum test (p < 0.001), to achieve only four features. After data augmentation, the features were exploited to train a support vector machine classifier, subsequently validated on a test set. To assess the results, Kruskal–Wallis and Wilcoxon rank-sum tests (p < 0.001) and receiver operating characteristic (ROC)-related metrics were used. GG1 and GG2 were equivalent (p = 0.26), whilst clear separations between either GG[1,2] and GG ≥ 3 exist (p < 10 (Formula presented.)). On the test set, the area under the curve = 0.88 (95% CI, 0.68–0.94), with positive and negative predictive values being 84%. The features retain a histological interpretation. Our model hints at GG2 being much more similar to GG1 than GG ≥ 3. © 2022 by the authors.},
	author_keywords = {cancer staging; machine learning; multiparametric magnetic resonance imaging; prostate cancer; radiomics},
	keywords = {adult; aged; apparent diffusion coefficient; area under the curve; Article; clinical significance; cohort analysis; colorimetry; Gleason score; histology; histopathology; human; Kruskal Wallis test; least absolute shrinkage and selection operator; machine learning; major clinical study; medical ethics; multiparametric magnetic resonance imaging; observational study; prediction; predictive model; predictive value; prostate biopsy; prostate cancer; radiomics; rank sum test; receiver operating characteristic; retrospective study; sensitivity and specificity; support vector machine; training},
	correspondence_address = {A. Bevilacqua; Department of Computer Science and Engineering (DISI), University of Bologna, Bologna, 40126, Italy; email: alessandro.bevilacqua@unibo.it},
	publisher = {MDPI},
	issn = {20726694},
	language = {English},
	abbrev_source_title = {Cancers},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Plant2022,
	author = {Plant, Anne L. and Piscopo, Nicole and Saha, Krishanu and Zylberberg, Claudia and Roy, Krishnendu and Tsokas, Katherine and Schumm, Samantha N. and Beachy, Sarah H.},
	title = {Implementing systems thinking and data science in the training of the regenerative medicine workforce},
	year = {2022},
	journal = {npj Regenerative Medicine},
	volume = {7},
	number = {1},
	doi = {10.1038/s41536-022-00271-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144846494&doi=10.1038%2fs41536-022-00271-2&partnerID=40&md5=2178b8fdb97fce4dd96f4bafcc815b88},
	affiliations = {Biosystems and Biomaterials Division, National Institute of Standards and Technology, Gaithersburg, MD, United States; CRISPR Therapeutics, Cambridge, MA, United States; Department of Biomedical Engineering, University of Wisconsin-Madison, Madison, WI, United States; Akron Bio, Boca Raton, FL, United States; Department of Biomedical Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Janssen Research and Development LLC, Spring House, PA, United States; Health and Medicine Division, National Academies of Sciences, Engineering, and Medicine, Washington, DC, United States},
	keywords = {Article; artificial intelligence; basic research; computer security; curriculum; data integration; data science; ethics; graduate education; health workforce; human; information dissemination; information literacy; machine learning; manufacturing; regenerative medicine; social parameters; systems thinking; translational science; undergraduate education},
	correspondence_address = {S.N. Schumm; Health and Medicine Division, National Academies of Sciences, Engineering, and Medicine, Washington, United States; email: sschumm@nas.edu; S.H. Beachy; Health and Medicine Division, National Academies of Sciences, Engineering, and Medicine, Washington, United States; email: sbeachy@nas.edu},
	publisher = {Nature Research},
	issn = {20573995},
	language = {English},
	abbrev_source_title = {npj Regen. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Lamb2022369,
	author = {Lamb, Leslie R. and Lehman, Constance D. and Gastounioti, Aimilia and Conant, Emily F. and Bahl, Manisha},
	title = {Artificial Intelligence (AI) for Screening Mammography, from the AJR Special Series on AI Applications},
	year = {2022},
	journal = {American Journal of Roentgenology},
	volume = {219},
	number = {3},
	pages = {369 – 381},
	doi = {10.2214/AJR.21.27071},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125344928&doi=10.2214%2fAJR.21.27071&partnerID=40&md5=16c80beca954444a3bdfe8a2ab8569fe},
	affiliations = {Department of Radiology, Massachusetts General Hospital, 55 Fruit St, WAC 240, Boston, 02114, MA, United States; Department of Radiology, University of Pennsylvania Perelman School of Medicine, Philadelphia, PA, United States},
	abstract = {Artificial intelligence (AI) applications for screening mammography are being marketed for clinical use in the interpretative domains of lesion detection and diagnosis, triage, and breast density assessment and in the noninterpretive domains of breast cancer risk assessment, image quality control, image acquisition, and dose reduction. Evidence in support of these nascent applications, particularly for lesion detection and diagnosis, is largely based on multireader studies with cancer-enriched datasets rather than rigorous clinical evaluation aligned with the application’s specific intended clinical use. This article reviews commercial AI algorithms for screening mammography that are currently available for clinical practice, their use, and evidence supporting their performance. Clinical implementation considerations, such as workflow integration, governance, and ethical issues, are also described. In addition, the future of AI for screening mammography is discussed, including the development of interpretive and noninterpretive AI applications and strategic priorities for research and development. © American Roentgen Ray Society.},
	author_keywords = {artificial intelligence; breast cancer; implementation; machine learning; screening mammography},
	keywords = {Artificial Intelligence; Breast; Breast Neoplasms; Early Detection of Cancer; Female; Humans; Mammography; artificial intelligence; breast cancer; breast density; cancer risk; cancer screening; computer assisted diagnosis; deep learning; digital breast tomosynthesis; digital mammography; false positive result; histopathology; human; image quality; interdisciplinary communication; intermethod comparison; invasive ductal breast carcinoma; mammography; medical ethics; medicolegal aspect; patient triage; radiation dose reduction; receiver operating characteristic; Review; risk assessment; sensitivity and specificity; workflow; artificial intelligence; breast; breast tumor; diagnostic imaging; early cancer diagnosis; female; procedures},
	correspondence_address = {M. Bahl; Department of Radiology, Massachusetts General Hospital, Boston, 55 Fruit St, WAC 240, 02114, United States; email: mbahl1@mgh.harvard.edu},
	publisher = {American Roentgen Ray Society},
	issn = {0361803X},
	coden = {AJROA},
	pmid = {35018795},
	language = {English},
	abbrev_source_title = {Am. J. Roentgenol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Baughan2022451,
	author = {Baughan, Natalie and Douglas, Lindsay and Giger, Maryellen L.},
	title = {Past, Present, and Future of Machine Learning and Artificial Intelligence for Breast Cancer Screening},
	year = {2022},
	journal = {Journal of Breast Imaging},
	volume = {4},
	number = {5},
	pages = {451 – 459},
	doi = {10.1093/jbi/wbac052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148756417&doi=10.1093%2fjbi%2fwbac052&partnerID=40&md5=ed0510a4794c0727149032a4dacdfa26},
	affiliations = {University of Chicago, Department of Radiology Committee on Medical Physics, Chicago, IL, United States},
	abstract = {Breast cancer screening has evolved substantially over the past few decades because of advancements in new image acquisition systems and novel artificial intelligence (AI) algorithms.This review provides a brief overview of the history, current state, and future of AI in breast cancer screening and diagnosis along with challenges involved in the development of AI systems. Although AI has been developing for interpretation tasks associated with breast cancer screening for decades, its potential to combat the subjective nature and improve the efficiency of human image interpretation is always expanding. The rapid advancement of computational power and deep learning has increased greatly in AI research, with promising performance in detection and classification tasks across imaging modalities. Most AI systems, based on human-engineered or deep learning methods, serve as concurrent or secondary readers, that is, as aids to radiologists for a specific, well-defined task. In the future, AI may be able to perform multiple integrated tasks, making decisions at the level of or surpassing the ability of humans. Artificial intelligence may also serve as a partial primary reader to streamline ancillary tasks, triaging cases or ruling out obvious normal cases. However, before AI is used as an independent, autonomous reader, various challenges need to be addressed, including explainability and interpretability, in addition to repeatability and generalizability, to ensure that AI will provide a significant clinical benefit to breast cancer screening across all populations. © Society of Breast Imaging 2022. All rights reserved.},
	author_keywords = {artificial intelligence; breast imaging; computer-aided diagnosis; machine learning; screening},
	keywords = {artificial intelligence; breast cancer; cancer screening; computer assisted diagnosis; human; integration; machine learning; medical ethics; medical history; patient triage; Review; statistical bias},
	correspondence_address = {M.L. Giger; University of Chicago, Department of Radiology Committee on Medical Physics, Chicago, United States; email: m-giger@uchicago.edu},
	publisher = {Oxford University Press},
	issn = {26316110},
	language = {English},
	abbrev_source_title = {J. Breast Imaging},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@ARTICLE{Jibb2022,
	author = {Jibb, Lindsay A and Nanos, Stephanie M and Alexander, Sarah and Malfitano, Carmine and Rydall, Anne and Gupta, Sumit and Schimmer, Aaron D and Zimmermann, Camilla and Hales, Sarah and Nissim, Rinat and Marmar, Charles and Schultebraucks, Katharina and Mah, Kenneth and Rodin, Gary},
	title = {Traumatic stress symptoms in family caregivers of patients with acute leukaemia: protocol for a multisite mixed methods, longitudinal, observational study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {11},
	doi = {10.1136/bmjopen-2022-065422},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141890653&doi=10.1136%2fbmjopen-2022-065422&partnerID=40&md5=a61ceba1a562ad9f46b7a20365d0202a},
	affiliations = {Child Health Evaluative Sciences, The Hospital for Sick Children, Toronto, ON, Canada; Lawrence S. Bloomberg Faculty of Nursing, University of Toronto, Toronto, ON, Canada; Department of Supportive Care, Princess Margaret Cancer Centre, Toronto, ON, Canada; Division of Haematology/Oncology, The Hospital for Sick Children, Toronto, ON, Canada; Department of Pediatrics, University of Toronto, Toronto, ON, Canada; Department of Medical Oncology/Hematology, Princess Margaret Cancer Centre, Toronto, ON, Canada; Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada; Department of Psychiatry, University of Toronto, Toronto, ON, Canada; Department of Psychiatry, New York University, New York, NY, United States; Department of Emergency Medicine, Columbia University Irving Medical Center, New York, NY, United States; Department of Psychiatry, Columbia University, New York, NY, United States},
	abstract = {Introduction The diagnosis, progression or recurrence of cancer is often highly traumatic for family caregivers (FCs), but systematic assessments of distress and approaches for its prevention and treatment are lacking. Acute leukaemia (AL) is a life-threatening cancer of the blood, which most often presents acutely, requires intensive treatment and is associated with severe physical symptoms. Consequently, traumatic stress may be common in the FCs of patients with AL. We aim to determine the prevalence, severity, longitudinal course and predictors of traumatic stress symptoms in FCs of patients with AL in the first year after diagnosis, and to understand their lived experience of traumatic stress and perceived support needs. Methods and analysis This two-site longitudinal, observational, mixed methods study will recruit 223 adult FCs of paediatric or adult patients newly diagnosed with AL from two tertiary care centres. Quantitative data will be collected from self-report questionnaires at enrolment, and 1, 3, 6, 9 and 12 months after admission to hospital for initial treatment. Quantitative data will be analysed using descriptive and machine learning approaches and a multilevel modelling (MLM) approach will be used to confirm machine learning findings. Semi-structured qualitative interviews will be conducted at 3, 6 and 12 months and analysed using a grounded theory approach. Ethics and dissemination This study is funded by the Canadian Institutes of Health Research (CIHR number PJT 173255) and has received ethical approval from the Ontario Cancer Research Ethics Board (CTO Project ID: 2104). The data generated have the potential to inform the development of targeted psychosocial interventions for traumatic stress, which is a public health priority for high-risk populations such as FCs of patients with haematological malignancies. An integrated and end-of-study knowledge translation strategy that involves FCs and other stakeholders will be used to interpret and disseminate study results.  © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {adult palliative care; anxiety disorders; leukaemia; mental health; paediatric palliative care; qualitative research},
	keywords = {Adult; Caregivers; Child; Humans; Leukemia; Neoplasms; Observational Studies as Topic; Ontario; Surveys and Questionnaires; acute leukemia; adult; advanced cancer; Article; caregiver; caregiver burden; child; clinical outcome; depression; descriptive research; disease course; disease severity; emotional attachment; fear of death; female; grounded theory; hospital admission; human; longitudinal study; machine learning; major clinical study; male; multilevel analysis; observational study; Patient Health Questionnaire 9; patient satisfaction; personal experience; posttraumatic stress disorder; prevalence; promyelocytic leukemia; self report; sex role; social environment; social support; startle reflex; tertiary care center; caregiver; leukemia; neoplasm; Ontario; psychology; questionnaire},
	correspondence_address = {G. Rodin; Department of Supportive Care, Princess Margaret Cancer Centre, Toronto, Canada; email: Gary.Rodin@uhn.ca},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36332954},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Kurfess2022,
	author = {Kurfess, Franz and Vasilaky, Katya Nadine and Cheuk, Tina and Jenkins, Ryan and Nolan, Grace},
	title = {Assessment of Ethics and Social Justice Aspects in Data Science and Artificial Intelligence},
	year = {2022},
	journal = {ASEE Annual Conference and Exposition, Conference Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138253513&partnerID=40&md5=c19d4647192c806430126d9165709965},
	abstract = {This work aims to develop a set of materials and tools, both quantitative and qualitative, for two purposes: First, for the assessment of ethical and social justice (ESJ) considerations in research projects, and second, as a pedagogical toolkit that allows users to improve their understanding of these aspects of data ethics. Below we describe three existing assessment methodologies for evaluating ESJ in data science research projects: a scoring rubric, a questionnaire, and a canvas sheet (i.e., a user-friendly template and tool that captures data), and we propose one additional method, a predictive machine learning model. This document describes an evaluation of the feedback from 124 students in two different classes who used the questionnaire and canvas sheet to assess their team projects. This data set is also being used to test a proof of concept for the machine learning model. Our emphasis at this stage is to improve the instruments, with a quantitative analysis of the numerical and scale-based responses, and a qualitative evaluation of the text-based suggestions from participants. The primary insights from this first round of evaluations indicate that students showed no strong preference between the questionnaire and the canvas sheet, with slight advantages on “Perspective” and “Further Research” for the canvas sheet, and a similar advantage for “Group Discussion” for the questionnaire. © American Society for Engineering Education, 2022.},
	keywords = {Data Science; Education computing; Engineering education; Engineering research; Machine learning; Philosophical aspects; Surveys; Assessment methodologies; Data set; Different class; Machine learning models; Proof of concept; Qualitative evaluations; Science research; Social justice; Team projects; User friendly; Statistical tests},
	publisher = {American Society for Engineering Education},
	issn = {21535965},
	language = {English},
	abbrev_source_title = {ASEE Annu. Conf. Expos. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 129th ASEE Annual Conference and Exposition: Excellence Through Diversity, ASEE 2022; Conference date: 26 June 2022 through 29 June 2022; Conference code: 182495}
}

@BOOK{Tripathi202279,
	author = {Tripathi, Satvik and Musiolik, Thomas Heinrich},
	title = {Fairness and ethics in artificial intelligence-based medical imaging},
	year = {2022},
	journal = {Research Anthology on Improving Medical Imaging Techniques for Analysis and Intervention},
	pages = {79 – 90},
	doi = {10.4018/978-1-6684-7544-7.ch005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161336022&doi=10.4018%2f978-1-6684-7544-7.ch005&partnerID=40&md5=c6b877411e6611e7e0431bdf10ccc139},
	affiliations = {College of Computing & Informatics, Drexel University, United States; Berlin University of the Arts, Germany},
	abstract = {Artificial intelligence has a huge array of current and potential applications in healthcare and medicine. Ethical issues arising due to algorithmic biases are one of the greatest challenges faced in the generalizability of AI models today. The authors address safety and regulatory barriers that impede data sharing in medicine as well as potential changes to existing techniques and frameworks that might allow ethical data sharing for machine learning. With these developments in view, they also present different algorithmic models that are being used to develop machine learning-based medical systems that will potentially evolve to be free of the sample, annotator, and temporal bias. These AI-based medical imaging models will then be completely implemented in healthcare facilities and institutions all around the world, even in the remotest areas, making diagnosis and patient care both cheaper and freely accessible. © 2023, IGI Global. All rights reserved.},
	publisher = {IGI Global},
	isbn = {978-166847545-4; 978-166847544-7},
	language = {English},
	abbrev_source_title = {res. anthol. on improv. méd. Imaging tech. for anal. and interv.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Hagos2022,
	author = {Hagos, Desta Haileselassie and Rawat, Danda B.},
	title = {Recent Advances in Artificial Intelligence and Tactical Autonomy: Current Status, Challenges, and Perspectives},
	year = {2022},
	journal = {Sensors},
	volume = {22},
	number = {24},
	doi = {10.3390/s22249916},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144625263&doi=10.3390%2fs22249916&partnerID=40&md5=32511ef0875356ee7b78a5510478eb06},
	affiliations = {DoD Center of Excellence in Artificial Intelligence and Machine Learning (CoE-AIML), Howard University, Washington, 20059, DC, United States},
	abstract = {This paper presents the findings of detailed and comprehensive technical literature aimed at identifying the current and future research challenges of tactical autonomy. It discusses in great detail the current state-of-the-art powerful artificial intelligence (AI), machine learning (ML), and robot technologies, and their potential for developing safe and robust autonomous systems in the context of future military and defense applications. Additionally, we discuss some of the technical and operational critical challenges that arise when attempting to practically build fully autonomous systems for advanced military and defense applications. Our paper provides the state-of-the-art advanced AI methods available for tactical autonomy. To the best of our knowledge, this is the first work that addresses the important current trends, strategies, critical challenges, tactical complexities, and future research directions of tactical autonomy. We believe this work will greatly interest researchers and scientists from academia and the industry working in the field of robotics and the autonomous systems community. We hope this work encourages researchers across multiple disciplines of AI to explore the broader tactical autonomy domain. We also hope that our work serves as an essential step toward designing advanced AI and ML models with practical implications for real-world military and defense settings. © 2022 by the authors.},
	author_keywords = {aerospace; artificial intelligence; autonomous systems; cybersecurity; defense applications; explainability; machine ethics; military; tactical autonomy; trustworthiness},
	keywords = {Cybersecurity; Ethical technology; Intelligent robots; Network security; Aerospace; Autonomous system; Cyber security; Defence applications; Explainability; Machine ethic; Military; Tactical autonomy; Tacticals; Trustworthiness; Military applications},
	correspondence_address = {D.H. Hagos; DoD Center of Excellence in Artificial Intelligence and Machine Learning (CoE-AIML), Howard University, Washington, 20059, United States; email: desta.hagos@howard.edu; D.B. Rawat; DoD Center of Excellence in Artificial Intelligence and Machine Learning (CoE-AIML), Howard University, Washington, 20059, United States; email: danda.rawat@howard.edu},
	publisher = {MDPI},
	issn = {14248220},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Carruthers2022,
	author = {Carruthers, Robert and Straw, Isabel and Ruffle, James K. and Herron, Daniel and Nelson, Amy and Bzdok, Danilo and Fernandez-Reyes, Delmiro and Rees, Geraint and Nachev, Parashkev},
	title = {Representational ethical model calibration},
	year = {2022},
	journal = {npj Digital Medicine},
	volume = {5},
	number = {1},
	doi = {10.1038/s41746-022-00716-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141352585&doi=10.1038%2fs41746-022-00716-4&partnerID=40&md5=e587616c5bfdee6960880488a102ca2e},
	affiliations = {Department of Computer Science, University College London, London, United Kingdom; UCL Queen Square Institute of Neurology, University College London, London, United Kingdom; Research and Development, NIHR University College London Hospitals Biomedical Research Centre, London, United Kingdom; Department of Biomedical Engineering, Faculty of Medicine, McGill University, Montreal, Canada},
	abstract = {Equity is widely held to be fundamental to the ethics of healthcare. In the context of clinical decision-making, it rests on the comparative fidelity of the intelligence – evidence-based or intuitive – guiding the management of each individual patient. Though brought to recent attention by the individuating power of contemporary machine learning, such epistemic equity arises in the context of any decision guidance, whether traditional or innovative. Yet no general framework for its quantification, let alone assurance, currently exists. Here we formulate epistemic equity in terms of model fidelity evaluated over learnt multidimensional representations of identity crafted to maximise the captured diversity of the population, introducing a comprehensive framework for Representational Ethical Model Calibration. We demonstrate the use of the framework on large-scale multimodal data from UK Biobank to derive diverse representations of the population, quantify model performance, and institute responsive remediation. We offer our approach as a principled solution to quantifying and assuring epistemic equity in healthcare, with applications across the research, clinical, and regulatory domains. © 2022, The Author(s).},
	keywords = {Clinical research; Ethical technology; Health care; Population statistics; Clinical decision making; Decision guidance; Evidence-based; Large-scales; Learn+; Machine-learning; Model calibration; Modeling fidelity; Multi-modal data; Power; article; biobank; calibration; controlled study; human; quantitative analysis; Decision making},
	correspondence_address = {R. Carruthers; Department of Computer Science, University College London, London, United Kingdom; email: robert.carruthers.20@ucl.ac.uk; P. Nachev; UCL Queen Square Institute of Neurology, University College London, London, United Kingdom; email: p.nachev@ucl.ac.uk},
	publisher = {Nature Research},
	issn = {23986352},
	language = {English},
	abbrev_source_title = {npj Digit. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Liang2022,
	author = {Liang, Chen and Weissman, Sharon and Olatosi, Bankole and Poon, Eric G and Yarrington, Michael E and Li, Xiaoming},
	title = {Curating a knowledge base for individuals with coinfection of HIV and SARS-CoV-2: a study protocol of EHR-based data mining and clinical implementation},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {9},
	doi = {10.1136/bmjopen-2022-067204},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137767731&doi=10.1136%2fbmjopen-2022-067204&partnerID=40&md5=bf7dc141f54044cf67fe8b10e264d62e},
	affiliations = {Department of Health Services Policy and Management, University of South Carolina, Columbia, SC, United States; Big Data Health Science Center, University of South Carolina, Columbia, SC, United States; Department of Internal Medicine, University of South Carolina, Columbia, SC, United States; Department of Medicine, Duke University, Durham, NC, United States; Department of Health Promotion Education and Behavior, University of South Carolina, Columbia, SC, United States},
	abstract = {Introduction Despite a higher risk of severe COVID-19 disease in individuals with HIV, the interactions between SARS-CoV-2 and HIV infections remain unclear. To delineate these interactions, multicentre Electronic Health Records (EHR) hold existing promise to provide full-spectrum and longitudinal clinical data, demographics and sociobehavioural data at individual level. Presently, a comprehensive EHR-based cohort for the HIV/SARS-CoV-2 coinfection has not been established; EHR integration and data mining methods tailored for studying the coinfection are urgently needed yet remain underdeveloped. Methods and analysis The overarching goal of this exploratory/developmental study is to establish an EHR-based cohort for individuals with HIV/SARS-CoV-2 coinfection and perform large-scale EHR-based data mining to examine the interactions between HIV and SARS-CoV-2 infections and systematically identify and validate factors contributing to the severe clinical course of the coinfection. We will use a nationwide EHR database in the USA, namely, National COVID Cohort Collaborative (N3C). Ultimately, collected clinical evidence will be implemented and used to pilot test a clinical decision support prototype to assist providers in screening and referral of at-risk patients in real-world clinics. Ethics and dissemination The study was approved by the institutional review boards at the University of South Carolina (Pro00121828) as non-human subject study. Study findings will be presented at academic conferences and published in peer-reviewed journals. This study will disseminate urgently needed clinical evidence for guiding clinical practice for individuals with the coinfection at Prisma Health, a healthcare system in collaboration.  © },
	author_keywords = {COVID-19; Health informatics; HIV & AIDS},
	keywords = {Coinfection; COVID-19; Data Mining; Electronic Health Records; HIV Infections; Humans; Knowledge Bases; SARS-CoV-2; acquired immune deficiency syndrome; adult; Article; clinical outcome; clinical practice; cohort analysis; coinfection; coronavirus disease 2019; cross validation; data mining; decision support system; disease course; electronic health record; exploratory research; female; health care system; human; Human immunodeficiency virus; information retrieval; institutional review; k nearest neighbor; knowledge base; machine learning; male; medical informatics; multicenter study; nonhuman; patient referral; phenotype; principal component analysis; receiver operating characteristic; recurrent neural network; risk assessment; Severe acute respiratory syndrome coronavirus 2; singular value decomposition; South Carolina; supervised machine learning; support vector machine; coinfection; complication; data mining; Human immunodeficiency virus infection; knowledge base},
	correspondence_address = {C. Liang; Department of Health Services Policy and Management, University of South Carolina, Columbia, United States; email: cliang@mailbox.sc.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36100301},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zhou2022337,
	author = {Zhou, Yujun and Zhan, Zehui and Liu, Lu and Wan, Jiayi and Liu, Simai and Zou, Xuanxuan},
	title = {International Prospects and Trends of Artificial Intelligence Education: A Content Analysis of Top-level AI Curriculum across Countries},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {337 – 343},
	doi = {10.1145/3568739.3568796},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147413894&doi=10.1145%2f3568739.3568796&partnerID=40&md5=b95cf05f14a2ec3c22006d9cd6cc8b8c},
	affiliations = {School of Information Technology in Education, South China Normal University, Guangzhou, China; School of Education, South China Normal University, Guangzhou, China},
	abstract = {This study intends to investigate the present situation of AI curriculum offered for grades K-12. We screened 11 representative countries and areas from six continents and assessed the content of their top K-12 AI courses in terms of teaching content and teaching implementation in order to comprehend the current state of K-12 AI courses in diverse nations. Provide some ideas and suggestions for the development of AI courses for students in grades K-12. (1) Countries may choose AI applications, AI influences in various aspects, AI ethics, machine learning, data, classification, reasoning, Identify, and other content to establish independent AI teaching content standards; or choose programming as the core teaching content/starting point; or integrate programming, data, AI, and other content related to improving students’ computational thinking into computer/science/technology courses. (2) Project-based learning is still the primary way of instruction, along with a range of other approaches. There are four categories of available instructional resources, and there is an abundance of them. Most countries emphasize the evaluation of students’ abilities and the results achieved in the learning process. © 2022 Copyright held by the owner/author(s).},
	author_keywords = {Artificial Intelligence; content analysis; curriculum; Education},
	keywords = {Artificial intelligence; Computer programming; Learning systems; Students; Teaching; 'current; AI applications; AI course; Classification reasoning; Content analysis; Data classification; Learning data; Machine-learning; Present situation; Teaching contents; Curricula},
	correspondence_address = {Z. Zhan; School of Information Technology in Education, South China Normal University, Guangzhou, China; email: zhanzehui@m.scnu.edu.cn},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039809-1},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 6th International Conference on Digital Technology in Education, ICDTE 2022; Conference date: 16 September 2022 through 18 September 2022; Conference code: 186284}
}

@ARTICLE{Sebastian2022,
	author = {Sebastian, Anu Maria and Peter, David},
	title = {Artificial Intelligence in Cancer Research: Trends, Challenges and Future Directions},
	year = {2022},
	journal = {Life},
	volume = {12},
	number = {12},
	doi = {10.3390/life12121991},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144841916&doi=10.3390%2flife12121991&partnerID=40&md5=d730788275d206d2177e966f7dccc79a},
	affiliations = {Department of Computer Science, Cochin University of Science and Technology, Kerala, Kochi, 682022, India},
	abstract = {The World Health Organization (WHO), in their 2022 report, identified cancer as one of the leading causes of death, accounting for about 16% of deaths worldwide. The Cancer-Moonshot community aims to reduce the cancer death rate by half in the next 25 years and wants to improve the lives of cancer-affected people. Cancer mortality can be reduced if detected early and treated appropriately. Cancers like breast cancer and cervical cancer have high cure probabilities when treated early in accordance with best practices. Integration of artificial intelligence (AI) into cancer research is currently addressing many of the challenges where medical experts fail to bring cancer to control and cure, and the outcomes are quite encouraging. AI offers many tools and platforms to facilitate more understanding and tackling of this life-threatening disease. AI-based systems can help pathologists in diagnosing cancer more accurately and consistently, reducing the case error rates. Predictive-AI models can estimate the likelihood for a person to get cancer by identifying the risk factors. Big data, together with AI, can enable medical experts to develop customized treatments for cancer patients. The side effects from this kind of customized therapy will be less severe in comparison with the generalized therapies. However, many of these AI tools will remain ineffective in fighting against cancer and saving the lives of millions of patients unless they are accessible and understandable to biologists, oncologists, and other medical cancer researchers. This paper presents the trends, challenges, and future directions of AI in cancer research. We hope that this paper will be of help to both medical experts and technical experts in getting a better understanding of the challenges and research opportunities in cancer diagnosis and treatment. © 2022 by the authors.},
	author_keywords = {artificial intelligence in medicine; cancer diagnosis; cancer prediction; cancer research; cancer treatment; ethics; healthcare; machine learning; oncology; precision medicine},
	correspondence_address = {A.M. Sebastian; Department of Computer Science, Cochin University of Science and Technology, Kochi, Kerala, 682022, India; email: anumseb@gmail.com},
	publisher = {MDPI},
	issn = {20751729},
	language = {English},
	abbrev_source_title = {Life},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ahmad2022,
	author = {Ahmad, Ishteyaaq and Sharma, Sonal and Singh, Rajesh and Gehlot, Anita and Priyadarshi, Neeraj and Twala, Bhekisipho},
	title = {MOOC 5.0: A Roadmap to the Future of Learning},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {18},
	doi = {10.3390/su141811199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138742884&doi=10.3390%2fsu141811199&partnerID=40&md5=ae707801986a49dddaa749e721b6a260},
	affiliations = {Uttaranchal School of Computing Sciences, Uttaranchal University, Dehradun, 248007, India; Uttaranchal Institute of Technology, Uttaranchal University, Dehradun, 248007, India; Department of Project Management, Universidad Internacional Iberoamericana, CP, Campeche, 24560, Mexico; Department of Electrical Engineering, JIS College of Engineering, Kolkata, 741235, India; Digital Transformation Portfolio, Tshwane University of Technology, Staatsartillerie Rd., Pretoria West, Pretoria, 0183, South Africa},
	abstract = {Industry 4.0 has created a whole new world for us to explore, and its effects can be seen in every facet of our lives, especially in the workplace where it calls for technology-driven employment. There is a growing need to teach individuals and assist them in transitioning to longer-term employment prospects to execute Industry 4.0 effectively. Although MOOCs revolutionized the way learners study, it is critical to investigate teaching techniques using Education 4.0 at this time. This article explores how the technologies of Industry 4.0 can be incorporated into MOOCs. This paper proposes MOOCs 5.0, whose features include better universal access, better learner engagement, adaptive learning, greater collaboration, security, and curiosity, which is being developed using Industry 4.0 technologies of the Internet of Things, Cloud Computing, Big Data, Artificial Intelligence/Machine Learning, Blockchain, Gamification Technologies, and the Metaverse and would incorporate the zones of ethics and humanism, while at the same time providing learners with a richer and more individualized experience. © 2022 by the authors.},
	author_keywords = {artificial intelligence; big data; blockchain; education technology; IoT; Metaverse; MOOC},
	keywords = {employment; ethics; Internet; teaching; workplace},
	correspondence_address = {B. Twala; Digital Transformation Portfolio, Tshwane University of Technology, Pretoria, Staatsartillerie Rd., Pretoria West, 0183, South Africa; email: twalab@tut.ac.za},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Carissimo2022,
	author = {Carissimo, Chiara and Cerro, Gianni and Ferrigno, Luigi and Golluccio, Giacomo and Marino, Alessandro},
	title = {Development and Assessment of a Movement Disorder Simulator Based on Inertial Data},
	year = {2022},
	journal = {Sensors},
	volume = {22},
	number = {17},
	doi = {10.3390/s22176341},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137554366&doi=10.3390%2fs22176341&partnerID=40&md5=84937a9ef2fffe765cc6432db9a7cb9f},
	affiliations = {Department of Electrical and Information Engineering, University of Cassino and Southern Lazio, Cassino, 03043, Italy; Department of Medicine and Health Sciences “Vincenzo Tiberio”, University of Molise, Campobasso, 86100, Italy},
	abstract = {The detection analysis of neurodegenerative diseases by means of low-cost sensors and suitable classification algorithms is a key part of the widely spreading telemedicine techniques. The choice of suitable sensors and the tuning of analysis algorithms require a large amount of data, which could be derived from a large experimental measurement campaign involving voluntary patients. This process requires a prior approval phase for the processing and the use of sensitive data in order to respect patient privacy and ethical aspects. To obtain clearance from an ethics committee, it is necessary to submit a protocol describing tests and wait for approval, which can take place after a typical period of six months. An alternative consists of structuring, implementing, validating, and adopting a software simulator at most for the initial stage of the research. To this end, the paper proposes the development, validation, and usage of a software simulator able to generate movement disorders-related data, for both healthy and pathological conditions, based on raw inertial measurement data, and give tri-axial acceleration and angular velocity as output. To present a possible operating scenario of the developed software, this work focuses on a specific case study, i.e., the Parkinson’s disease-related tremor, one of the main disorders of the homonym pathology. The full framework is reported, from raw data availability to pathological data generation, along with a common machine learning method implementation to evaluate data suitability to be distinguished and classified. Due to the development of a flexible and easy-to-use simulator, the paper also analyses and discusses the data quality, described with typical measurement features, as a metric to allow accurate classification under a low-performance sensing device. The simulator’s validation results show a correlation coefficient greater than 0.94 for angular velocity and 0.93 regarding acceleration data. Classification performance on Parkinson’s disease tremor was greater than 98% in the best test conditions. © 2022 by the authors.},
	author_keywords = {IMU data; machine learning; measurement; Parkinson’s disease; simulation; tremor detection},
	keywords = {Angular velocity; Computer software; Machine learning; Philosophical aspects; Simulators; Classification algorithm; IMU data; Key parts; Low-cost sensors; Machine-learning; Movement disorders; Parkinson’s disease; Simulation; Software simulator; Tremor detection; Neurodegenerative diseases},
	correspondence_address = {C. Carissimo; Department of Electrical and Information Engineering, University of Cassino and Southern Lazio, Cassino, 03043, Italy; email: chiara.carissimo@unicas.it},
	publisher = {MDPI},
	issn = {14248220},
	pmid = {36080798},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Birk2022523,
	author = {Birk, Rasmus H. and Samuel, Gabrielle},
	title = {Digital Phenotyping for Mental Health: Reviewing the Challenges of Using Data to Monitor and Predict Mental Health Problems},
	year = {2022},
	journal = {Current Psychiatry Reports},
	volume = {24},
	number = {10},
	pages = {523 – 528},
	doi = {10.1007/s11920-022-01358-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136995184&doi=10.1007%2fs11920-022-01358-9&partnerID=40&md5=fe266b19134d519399a175dfc5e0081e},
	affiliations = {Department of Communication & Psychology, Aalborg University, Aalborg, Denmark; Department of Global Health & Social Medicine, King’s College London, London, United Kingdom},
	abstract = {Purpose of Review: We review recent developments within digital phenotyping for mental health, a field dedicated to using digital data for diagnosing, predicting, and monitoring mental health problems. We especially focus on recent critiques and challenges to digital phenotyping from within the social sciences. Recent Findings: Three significant strands of criticism against digital phenotyping for mental health have been developed within the social sciences. This literature problematizes the idea that digital data can be objective, that it can be unbiased, and argues that it has multiple ethical and practical challenges. Summary: Digital phenotyping for mental health is a rapidly growing and developing field, but with considerable challenges that are not easily solvable. This includes when, and if, data from digital phenotyping is actionable in practice; the involvement of user and patient perspectives in digital phenotyping research; the possibility of biased data; and challenges to the idea that digital phenotyping can be more objective than other forms of psychiatric assessment. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Digital phenotyping; Ethics; Explainability; Objectivity; Sociology},
	keywords = {Humans; Mental Health; Monitoring, Physiologic; clinical practice; data analysis; digital technology; disease surveillance; human; machine learning; mental disease; phenotype; prediction; psychiatric diagnosis; psychologic assessment; publication; Review; social media; sociology; mental health; physiologic monitoring},
	correspondence_address = {R.H. Birk; Department of Communication & Psychology, Aalborg University, Aalborg, Denmark; email: rbirk@ikp.aau.dk},
	publisher = {Springer},
	issn = {15233812},
	coden = {CPRUB},
	pmid = {36001220},
	language = {English},
	abbrev_source_title = {Curr. Psychiatry Rep.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Lawlor2022327,
	author = {Lawlor, Bonnie},
	title = {An overview of the 2022 NISO plus conference: Global conversations/Global Connections},
	year = {2022},
	journal = {Information Services and Use},
	volume = {42},
	number = {3-4},
	pages = {327 – 376},
	doi = {10.3233/ISU-220178},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145646968&doi=10.3233%2fISU-220178&partnerID=40&md5=1dc57471267715c9a93d2a70e4a86d23},
	affiliations = {NFAIS Honorary Fellow, 276 Upper Gulph Road, Radnor, PA, United States},
	abstract = {This paper offers an overview of some of the highlights of the 2022 NISO Plus Annual Conference that was held virtually from February 15 - February 18, 2022. This was the third such conference and the second to be held in a completely virtual format due to the Pandemic. These conferences have resulted from the merger of NISO and the National Federation of Abstracting and Information Services (NFAIS) in June 2019, replacing the NFAIS Annual Conferences and offering a new, more interactive format. As with last year, there was no general topical theme, but there were topics of interest for everyone working in the information ecosystem - from the practical subjects of standards and metadata quality to preprints, Wikidata, archiving and digital preservation, Open Science and Open Access, and ultimately Globalization of the Information Infrastructure, the Metaverse, and Visions of the Future. With speakers and attendees from around the world and across multiple time zones and continents, it truly was a global conversation!  © 2022 - The authors. Published by IOS Press.},
	author_keywords = {archiving; artificial intelligence; authoritative information; climate change knowledge cooperative; co-opetition; COPIM W7; data lakes; digital preservation; discovery services; dynamic semantic publishing; FAIR data; frame; indigenous knowledge; information accessibility; information discovery; information preservation policy; information sharing; knowledge graphs; knowledgebases; machine learning; metadata; metaverse; metrics; miles conrad lecture; NISO; NLM; open access; open data; open science; PDF problems; pluriverse; scholarly communication; scholarly ethics; sustainable development goals; sustainable libraries; virtual reality; visual-meta; wikidata; zooniverse},
	keywords = {Digital libraries; Digital storage; Information services; Knowledge graph; Learning systems; Metadata; Semantics; Virtual reality; Archiving; Authoritative information; Climate change knowledge cooperative; Co-opetition; COPIM w7; Data lake; Digital preservation; Discovery service; Dynamic semantic; Dynamic semantic publishing; FAIR data; Frame; Indigenous knowledge; Information accessibility; Information discovery; Information preservation policy; Information preservations; Information sharing; Knowledge basis (KBs); Knowledge graphs; Machine-learning; Metaverses; Metric; Mile conrad lecture; NISO; NLM; Open datum; Open science; OpenAccess; PDF problem; Pluriverse; Preservation policies; Scholarly communication; Scholarly ethic; Semantic publishing; Sustainable development goal; Sustainable library; Visual-meta; Wikidata; Zooniverse; Climate change},
	correspondence_address = {B. Lawlor; NFAIS Honorary Fellow, Radnor, 276 Upper Gulph Road, United States; email: chescot@aol.com},
	publisher = {IOS Press BV},
	issn = {01675265},
	coden = {ISUSD},
	language = {English},
	abbrev_source_title = {Inf Serv Use},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Cohen2022840,
	author = {Cohen, Eli B. and Gordon, Ira K.},
	title = {First, do no harm. Ethical and legal issues of artificial intelligence and machine learning in veterinary radiology and radiation oncology},
	year = {2022},
	journal = {Veterinary Radiology and Ultrasound},
	volume = {63},
	number = {S1},
	pages = {840 – 850},
	doi = {10.1111/vru.13171},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144116002&doi=10.1111%2fvru.13171&partnerID=40&md5=c149e16e1623c4cdb958d146a3ae6335},
	affiliations = {Department of Molecular and Biomedical Sciences, North Carolina State University College of Veterinary Medicine, Cary, NC, United States; The Oncology Service by United Veterinary Care, Knoxville, TN, United States},
	abstract = {Artificial Intelligence and machine learning are novel technologies that will change the way veterinary medicine is practiced. Exactly how this change will occur is yet to be determined, and, as is the nature with disruptive technologies, will be difficult to predict. Ushering in this new tool in a conscientious way will require knowledge of the terminology and types of AI as well as forward thinking regarding the ethical and legal implications within the profession. Developers as well as end users will need to consider the ethical and legal components alongside functional creation of algorithms in order to foster acceptance and adoption, and most importantly to prevent patient harm. There are key differences in deployment of these technologies in veterinary medicine relative to human healthcare, namely our ability to perform euthanasia, and the lack of regulatory validation to bring these technologies to market. These differences along with others create a much different landscape than AI use in human medicine, and necessitate proactive planning in order to prevent catastrophic outcomes, encourage development and adoption, and protect the profession from unnecessary liability. The authors offer that deploying these technologies prior to considering the larger ethical and legal implications and without stringent validation is putting the AI cart before the horse, and risks putting patients and the profession in harm's way. © 2022 The Authors. Veterinary Radiology & Ultrasound published by Wiley Periodicals LLC on behalf of American College of Veterinary Radiology.},
	author_keywords = {AI; artificial intelligence; ethics; machine learning; medicolegal},
	keywords = {Algorithms; Animals; Artificial Intelligence; Humans; Machine Learning; Radiation Oncology; adoption; adult; artificial intelligence; disruptive technology; ethics; euthanasia; horse; human; machine learning; nomenclature; nonhuman; occupation; patient harm; radiation oncology; review; risk assessment; thinking; veterinary medicine; veterinary radiology; algorithm; animal; machine learning},
	correspondence_address = {E.B. Cohen; Department of Molecular and Biomedical Sciences, North Carolina State University College of Veterinary Medicine, Raleigh, 1060 William Moore Dr., 27606, United States; email: ecohen@dragonflyimaging.vet},
	publisher = {John Wiley and Sons Inc},
	issn = {10588183},
	pmid = {36514231},
	language = {English},
	abbrev_source_title = {Vet. Radiol. Ultrasound},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Starke2022,
	author = {Starke, Georg and Poppe, Christopher},
	title = {Karl Jaspers and artificial neural nets: on the relation of explaining and understanding artificial intelligence in medicine},
	year = {2022},
	journal = {Ethics and Information Technology},
	volume = {24},
	number = {3},
	doi = {10.1007/s10676-022-09650-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132297973&doi=10.1007%2fs10676-022-09650-1&partnerID=40&md5=abb2ba4bd1d955b7f263893287b5ac30},
	affiliations = {Institute for Biomedical Ethics, University of Basel, Bernoullistr. 28, Basel, 4056, Switzerland; Intelligent Systems Ethics Group, College of Humanities, École Polytechnique Fédérale de Lausanne, Lausanne, Switzerland},
	abstract = {Assistive systems based on Artificial Intelligence (AI) are bound to reshape decision-making in all areas of society. One of the most intricate challenges arising from their implementation in high-stakes environments such as medicine concerns their frequently unsatisfying levels of explainability, especially in the guise of the so-called black-box problem: highly successful models based on deep learning seem to be inherently opaque, resisting comprehensive explanations. This may explain why some scholars claim that research should focus on rendering AI systems understandable, rather than explainable. Yet, there is a grave lack of agreement concerning these terms in much of the literature on AI. We argue that the seminal distinction made by the philosopher and physician Karl Jaspers between different types of explaining and understanding in psychopathology can be used to promote greater conceptual clarity in the context of Machine Learning (ML). Following Jaspers, we claim that explaining and understanding constitute multi-faceted epistemic approaches that should not be seen as mutually exclusive, but rather as complementary ones as in and of themselves they are necessarily limited. Drawing on the famous example of Watson for Oncology we highlight how Jaspers’ methodology translates to the case of medical AI. Classical considerations from the philosophy of psychiatry can therefore inform a debate at the centre of current AI ethics, which in turn may be crucial for a successful implementation of ethically and legally sound AI in medicine. © 2022, The Author(s).},
	keywords = {Decision making; Deep learning; 'current; Artificial intelligence in medicine; Artificial intelligence systems; Artificial neural net; Assistive system; Black boxes; Decisions makings; Machine-learning; Model-based OPC; Philosophical aspects},
	correspondence_address = {G. Starke; Institute for Biomedical Ethics, University of Basel, Basel, Bernoullistr. 28, 4056, Switzerland; email: georg.starke@unibas.ch},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Tsang2022,
	author = {Tsang, Kevin Cheuk Him and Pinnock, Hilary and Wilson, Andrew M and Salvi, Dario and Shah, Syed Ahmar},
	title = {Predicting asthma attacks using connected mobile devices and machine learning: the AAMOS-00 observational study protocol},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {10},
	doi = {10.1136/bmjopen-2022-064166},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139121573&doi=10.1136%2fbmjopen-2022-064166&partnerID=40&md5=4dac88a41eb13fbbd06e4b7706758c0f},
	affiliations = {Asthma Uk Centre for Applied Research, Usher Institute, University of Edinburgh, Edinburgh, United Kingdom; Medical Informatics, Usher Institute, University of Edinburgh, Edinburgh, United Kingdom; Norwich Medical School, University of East Anglia, Norwich, United Kingdom; Norwich University Hospital Foundation Trust, Colney Lane, Norwich, United Kingdom; Internet of Things and People Research Centre, Malmo University, Malmo, Sweden},
	abstract = {Introduction Supported self-management empowering people with asthma to detect early deterioration and take timely action reduces the risk of asthma attacks. Smartphones and smart monitoring devices coupled with machine learning could enhance self-management by predicting asthma attacks and providing tailored feedback. We aim to develop and assess the feasibility of an asthma attack predictor system based on data collected from a range of smart devices. Methods and analysis A two-phase, 7-month observational study to collect data about asthma status using three smart monitoring devices, and daily symptom questionnaires. We will recruit up to 100 people via social media and from a severe asthma clinic, who are at risk of attacks and who use a pressurised metered dose relief inhaler (that fits the smart inhaler device). Following a preliminary month of daily symptom questionnaires, 30 participants able to comply with regular monitoring will complete 6 months of using smart devices (smart peak flow meter, smart inhaler and smartwatch) and daily questionnaires to monitor asthma status. The feasibility of this monitoring will be measured by the percentage of task completion. The occurrence of asthma attacks (definition: American Thoracic Society/European Respiratory Society Task Force 2009) will be detected by self-reported use (or increased use) of oral corticosteroids. Monitoring data will be analysed to identify predictors of asthma attacks. At the end of the monitoring, we will assess users' perspectives on acceptability and utility of the system with an exit questionnaire. Ethics and dissemination Ethics approval was provided by the East of England - Cambridge Central Research Ethics Committee. IRAS project ID: 285 505 with governance approval from ACCORD (Academic and Clinical Central Office for Research and Development), project number: AC20145. The study sponsor is ACCORD, the University of Edinburgh. Results will be reported through peer-reviewed publications, abstracts and conference posters. Public dissemination will be centred around blogs and social media from the Asthma UK network and shared with study participants.  © },
	author_keywords = {Asthma; Health informatics; Information technology; World Wide Web technology},
	keywords = {Adrenal Cortex Hormones; Asthma; Humans; Machine Learning; Nebulizers and Vaporizers; Observational Studies as Topic; Smartphone; beclometasone dipropionate plus formoterol fumarate; bronchodilating agent; budesonide; corticosteroid; salbutamol; salbutamol sulfate; corticosteroid; adult; Article; asthma; asthmatic state; classification algorithm; clinical article; corticosteroid therapy; female; hospital; human; lung function; machine learning; male; medical society; observational study; peak expiratory flow; prediction; prescription; self care; self report; severe asthma; social media; asthma; machine learning; nebulizer; smartphone},
	correspondence_address = {K.C.H. Tsang; Asthma Uk Centre for Applied Research, Usher Institute, University of Edinburgh, Edinburgh, United Kingdom; email: k.c.h.tsang@sms.ed.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36192103},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Pandey2022392,
	author = {Pandey, Navneet Kumar and Harsh and Jayant, Himanshu and Kumar, Narendra and Kumar, Vinod},
	title = {Behavioural Cloning in Autonomous Vehicle},
	year = {2022},
	journal = {Advances in Transdisciplinary Engineering},
	volume = {27},
	pages = {392 – 399},
	doi = {10.3233/ATDE220771},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145435278&doi=10.3233%2fATDE220771&partnerID=40&md5=1cc62d2a3cec88ae8fbd57f3914bdfda},
	affiliations = {Delhi Technological University(DTU), Delhi, India},
	abstract = {People have been thinking about driverless cars since the dawn of automobiles themselves. Infact even in ancient scriptures and epics, autonomous transportation of some kind or other has been mentioned time and again. With time, mankind progressed and once a dream driverless car became reality. With great power comes great responsibility. So without morality in AI, there is nothing good in autonomous vehicles. Here comes the moral machine experiment. In this paper, Deep learning network is used to mimic the human steering behaviour while driving and discussion has been done on ethics involved. The dataset is extracted from Udacity with 8037 images divided into training and testing data with a ratio of 80:20 respectively. Keras has been used with TensorFlow backend as ML framework along with dependencies like numpy, pandas and scikit.  © 2022 The authors and IOS Press.},
	author_keywords = {Autonomous Vehicles; CNN; Computer Vision and Pattern Recognition; Ethics in Progress; Keras; Machine Learning; Moral Machine Experiment; Neural and Evolutionary Learning; Python; Regression},
	keywords = {Behavioral research; Clone cells; Computer vision; Deep learning; Ethical technology; Learning systems; Statistical tests; Autonomous Vehicles; Computer vision and pattern recognition; Driverless cars; Ethic in progress; Evolutionary Learning; Keras; Machine-learning; Moral machine experiment; Neural learning; Regression; Autonomous vehicles},
	editor = {Singari R.M. and Kankar P.K.},
	publisher = {IOS Press BV},
	isbn = {978-161499439-8},
	language = {English},
	abbrev_source_title = {Adv. Transdiscipl. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Advanced Production and Industrial Engineering, ICAPIE 2022; Conference date: 11 June 2022 through 12 June 2022; Conference code: 185436; All Open Access, Gold Open Access}
}

@ARTICLE{Shan2022,
	author = {Shan, Zack Y. and Mohamed, Abdalla Z. and Andersen, Thu and Rendall, Shae and Kwiatek, Richard A. and Fante, Peter Del and Calhoun, Vince D. and Bhuta, Sandeep and Lagopoulos, Jim},
	title = {Multimodal MRI of myalgic encephalomyelitis/chronic fatigue syndrome: A cross-sectional neuroimaging study toward its neuropathophysiology and diagnosis},
	year = {2022},
	journal = {Frontiers in Neurology},
	volume = {13},
	doi = {10.3389/fneur.2022.954142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139102113&doi=10.3389%2ffneur.2022.954142&partnerID=40&md5=5c776c471c0e4bd5db6162f03556cde9},
	affiliations = {Thompson Institute, University of the Sunshine Coast, Birtinya, QLD, Australia; Tri-institutional Center for Translational Research in Neuroimaging and Data Science (TReNDS), Georgia State University, Georgia Institute of Technology, Emory University, Atlanta, GA, United States; Medical Imaging Department, Gold Coast University Hospital, Parklands, QLD, Australia},
	abstract = {Introduction: Myalgic encephalomyelitis/chronic fatigue syndrome (ME/CFS), is a debilitating illness affecting up to 24 million people worldwide but concerningly there is no known mechanism for ME/CFS and no objective test for diagnosis. A series of our neuroimaging findings in ME/CFS, including functional MRI (fMRI) signal characteristics and structural changes in brain regions particularly sensitive to hypoxia, has informed the hypothesis that abnormal neurovascular coupling (NVC) may be the neurobiological origin of ME/CFS. NVC is a critical process for normal brain function, in which glutamate from an active neuron stimulates Ca2+ influx in adjacent neurons and astrocytes. In turn, increased Ca2+ concentrations in both astrocytes and neurons trigger the synthesis of vascular dilator factors to increase local blood flow assuring activated neurons are supplied with their energy needs. This study investigates NVC using multimodal MRIs: (1) hemodynamic response function (HRF) that represents regional brain blood flow changes in response to neural activities and will be modeled from a cognitive task fMRI; (2) respiration response function (RRF) represents autoregulation of regional blood flow due to carbon dioxide and will be modeled from breath-holding fMRI; (3) neural activity associated glutamate changes will be modeled from a cognitive task functional magnetic resonance spectroscopy. We also aim to develop a neuromarker for ME/CFS diagnosis by integrating the multimodal MRIs with a deep machine learning framework. Methods and analysis: This cross-sectional study will recruit 288 participants (91 ME/CFS, 61 individuals with chronic fatigue, 91 healthy controls with sedentary lifestyles, 45 fibromyalgia). The ME/CFS will be diagnosed by consensus diagnosis made by two clinicians using the Canadian Consensus Criteria 2003. Symptoms, vital signs, and activity measures will be collected alongside multimodal MRI. The HRF, RRF, and glutamate changes will be compared among four groups using one-way analysis of covariance (ANCOVA). Equivalent non-parametric methods will be used for measures that do not exhibit a normal distribution. The activity measure, body mass index, sex, age, depression, and anxiety will be included as covariates for all statistical analyses with the false discovery rate used to correct for multiple comparisons. The data will be randomly divided into a training (N = 188) and a validation (N = 100) group. Each MRI measure will be entered as input for a least absolute shrinkage and selection operator—regularized principal components regression to generate a brain pattern of distributed clusters that predict disease severity. The identified brain pattern will be integrated using multimodal deep Boltzmann machines as a neuromarker for predicting ME/CFS fatigue conditions. The receiver operating characteristic curve of the identified neuromarker will be determined using data from the validation group. Ethics and study registry: This study was reviewed and approved by University of the Sunshine Coast University Ethics committee (A191288) and has been registered with The Australian New Zealand Clinical Trials Registry (ACTRN12622001095752). Dissemination of results: The results will be disseminated through peer reviewed scientific manuscripts and conferences and to patients through social media and active engagement with ME/CFS associations. Copyright © 2022 Shan, Mohamed, Andersen, Rendall, Kwiatek, Fante, Calhoun, Bhuta and Lagopoulos.},
	author_keywords = {ME/CFS; MRI; neuromarker; neurovascular coupling; translational neuroimaging},
	keywords = {calcium ion; glutamic acid; actimetry; adult; aged; Article; astrocyte; autoregulation; brain blood flow; brain function; breath holding; calcium transport; chronic fatigue syndrome; controlled study; cross-sectional study; fibromyalgia; functional magnetic resonance imaging; hemodynamic response function; hemodynamics; human; major clinical study; multimodal magnetic resonance imaging; neurovascular coupling; nuclear magnetic resonance imaging; nuclear magnetic resonance spectroscopy; population research; respiration response function; respiratory function; sedentary lifestyle; task performance},
	correspondence_address = {Z.Y. Shan; Thompson Institute, University of the Sunshine Coast, Birtinya, Australia; email: zshan@usc.edu.au},
	publisher = {Frontiers Media S.A.},
	issn = {16642295},
	language = {English},
	abbrev_source_title = {Front. Neurol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Ferguson2022,
	author = {Ferguson, Sharon and Magarian, James and Olechowski, Alison and Mao, Katherine},
	title = {Advancing a Model of Students' Intentional Persistence in Machine Learning and Artificial Intelligence},
	year = {2022},
	journal = {ASEE Annual Conference and Exposition, Conference Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138313598&partnerID=40&md5=f4191dad940786d8b14f4668814ac024},
	abstract = {Machine Learning and Artificial Intelligence are powering the applications we use, the decisions we make, and the decisions made about us. We have seen numerous examples of non-equitable outcomes, from facial recognition algorithms, recidivism algorithms, and resume reviewing algorithms, when they are designed without diversity in mind. As Machine Learning (ML) and Artificial Intelligence (AI) expand into more areas of our lives, we must take action to promote diversity among those working in this field. A critical step in this work is understanding why some students who choose to study ML/AI later leave the field. While the persistence of diverse populations has been studied in engineering specifically, and Science, Technology, Engineering and Math (STEM) more generally, there is a lack of research investigating factors that influence persistence in ML/AI. In this work, we present the advancement of a model of intentional persistence in ML/AI in order to identify areas for improvement. We surveyed undergraduate and graduate students enrolled in ML/AI courses at a major North American university in fall 2021. We examine persistence across demographic groups, such as gender, international student status, student loan status, and visible minority status. We investigate independent variables that distinguish ML/AI from existing studies of persistence in STEM, such as the varying emphasis on non-technical skills, the ambiguous ethical implications of the work, and the highly competitive and lucrative nature of the field. Our findings suggest that short-term intentional persistence in ML/AI is associated with academic enrollment factors such as major and level of study. In terms of long-term intentional persistence, we found that measures of professional role confidence developed to study persistence in engineering are also important predictors of intent to remain in ML/AI. Unique to our study, we show that wanting your work to have a positive social benefit is a negative predictor of long-term intentional persistence in ML/AI, and women generally care more about this. We find some evidence that having high confidence in non-technical interpersonal skills may also be a positive predictor of long-term intentional persistence. We provide recommendations to educators to meaningfully discuss ML/AI ethics in classes and encourage the development of interpersonal skills to help increase diversity in the field. © American Society for Engineering Education, 2022.},
	keywords = {Education computing; Engineering education; Face recognition; Philosophical aspects; Students; Artificial intelligence course; Critical steps; Facial recognition; Graduate students; Interpersonal skills; Machine-learning; North American; Recognition algorithm; Science technologies; Undergraduate students; Machine learning},
	publisher = {American Society for Engineering Education},
	issn = {21535965},
	language = {English},
	abbrev_source_title = {ASEE Annu. Conf. Expos. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 129th ASEE Annual Conference and Exposition: Excellence Through Diversity, ASEE 2022; Conference date: 26 June 2022 through 29 June 2022; Conference code: 182495}
}

@ARTICLE{Manimaran2022585,
	author = {Manimaran, Maniragav and Arora, Anmol and Lovejoy, Christopher A. and Gao, William and Maruthappu, Mahiben},
	title = {Role of artificial intelligence and machine learning in haematology},
	year = {2022},
	journal = {Journal of Clinical Pathology},
	volume = {75},
	number = {9},
	pages = {585 – 587},
	doi = {10.1136/jclinpath-2021-208127},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130782945&doi=10.1136%2fjclinpath-2021-208127&partnerID=40&md5=c607f76174672cee50f237cb7b6d53da},
	affiliations = {University College London Hospitals Nhs Foundation Trust, London, United Kingdom; University of Cambridge, Cambridge, United Kingdom; University College London, London, United Kingdom; Cera Care, London, United Kingdom},
	author_keywords = {COMPUTER SYSTEMS; Costs and Cost Analysis; DIAGNOSIS; ETHICS; MEDICAL INFORMATICS},
	keywords = {Artificial Intelligence; Hematology; Humans; Machine Learning; DNA; RNA; warfarin; adverse event; artificial intelligence; bone marrow; clinical classification; clinical pathway; clinical practice; clinical research; clinical trial (topic); convolutional neural network; cost benefit analysis; decision support system; gene expression; genetic trait; hematologic disease; hematologic malignancy; hematology; histopathology; holistic care; human; imaging algorithm; leukemia; liquid biopsy; lymphoma; machine learning; malignant neoplasm; medical informatics; minimal residual disease; Note; patient care; screening test; smear; systemic disease; treatment planning; machine learning},
	correspondence_address = {A. Arora; University of Cambridge, Cambridge, United Kingdom; email: research@anmol.info},
	publisher = {BMJ Publishing Group},
	issn = {00219746},
	coden = {JCPAA},
	pmid = {35470252},
	language = {English},
	abbrev_source_title = {J. Clin. Pathol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lewis2022783,
	author = {Lewis, Armanda and Stoyanovich, Julia},
	title = {Teaching Responsible Data Science: Charting New Pedagogical Territory},
	year = {2022},
	journal = {International Journal of Artificial Intelligence in Education},
	volume = {32},
	number = {3},
	pages = {783 – 807},
	doi = {10.1007/s40593-021-00241-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104720403&doi=10.1007%2fs40593-021-00241-7&partnerID=40&md5=dfd07576e0ce5de9965182c2900612d5},
	affiliations = {New York University, New York, NY, United States},
	abstract = {Although an increasing number of ethical data science and AI courses is available, with many focusing specifically on technology and computer ethics, pedagogical approaches employed in these courses rely exclusively on texts rather than on algorithmic development or data analysis. In this paper we recount a recent experience in developing and teaching a technical course focused on responsible data science, which tackles the issues of ethics in AI, legal compliance, data quality, algorithmic fairness and diversity, transparency of data and algorithms, privacy, and data protection. Interpretability of machine-assisted decision-making is an important component of responsible data science that gives a good lens through which to see other responsible data science topics, including privacy and fairness. We provide emerging pedagogical best practices for teaching technical data science and AI courses that focus on interpretability, and tie responsible data science to current learning science and learning analytics research. We focus on a novel methodological notion of the object-to-interpret-with, a representation that helps students target metacognition involving interpretation and representation. In the context of interpreting machine learning models, we highlight the suitability of “nutritional labels”—a family of interpretability tools that are gaining popularity in responsible data science research and practice. © 2021, International Artificial Intelligence in Education Society.},
	author_keywords = {Constructivism; Data science pedagogy; Model interpretability; Responsible data science},
	keywords = {Curricula; Decision making; Philosophical aspects; Privacy by design; Teaching; Computer ethics; Interpretability; Learning science; Legal compliance; Machine learning models; Pedagogical approach; Science research; Technical course; Data Science},
	correspondence_address = {A. Lewis; New York University, New York, United States; email: al861@nyu.edu},
	publisher = {Springer},
	issn = {15604292},
	language = {English},
	abbrev_source_title = {Int. J. Artif. Intell. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access, Green Open Access}
}

@BOOK{Sharma2022213,
	author = {Sharma, Parinita and Saxena, Ankur and De, Anveshita and Sreedharan, Smitha Mony},
	title = {Artificial intelligence and machine learning in healthcare: An ethical perspective},
	year = {2022},
	journal = {Artificial Intelligence and Computational Dynamics for Biomedical Research},
	volume = {8},
	pages = {213 – 227},
	doi = {10.1515/9783110762044-012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141599678&doi=10.1515%2f9783110762044-012&partnerID=40&md5=0bd62b4c9924850d0c695078fe3c045f},
	affiliations = {Amity Institute of Microbial Technology, Amity University, Sector-125, Noida, U.P., 201313, India; Amity University, Uttar Pradesh, Sector-125, Noida, U.P., 201313, India; University of Glasgow, Scotland, United Kingdom},
	abstract = {Artificial intelligence (AI) has been referred to as "fourth industrial revolution" with widespread global impact. It encompasses the application of engineering, computer science and related fields for developing smart machines which are capable of performing tasks that typically require human intelligence. Machine learning (ML) remains a subdivision of AI which is depended on data-driven rules which are obtained from a large set of data. Based on the sample data, decisions can be made with minimum human intervention. It is known to bring about a paradigm shift in the field of healthcare by enhancing the analytics approach as well as expanding the availability of data related to healthcare. Understanding the ways in which AI technologies perform and help in improving efficiency and safety of health services is imperative for its far-reaching applicability. The overall efficacy of AI in healthcare and medicine makes it more likely to get integrated into regular clinical care in the coming years. Regardless of the numerous merits associated with the AI-driven technologies, its implementation in healthcare sector raises several ethical concerns. This chapter focuses on the fundamental information regarding AI and ethical dilemmas associated with it that need to be tackled for the establishment of AI in the complex healthcare space. © 2023 Walter de Gruyter GmbH, Berlin/Boston.},
	author_keywords = {Artificial intelligence; Data bias; Ethics; Machine learning; Medical; Patients; Privacy},
	correspondence_address = {S.M. Sreedharan; Amity Institute of Microbial Technology, Amity University, Noida, U.P., Sector-125, 201313, India; email: smsreedharan@amity.edu},
	publisher = {De Gruyter},
	isbn = {978-311076204-4; 978-311076208-2},
	language = {English},
	abbrev_source_title = {Artif. Intell. and Comput. Dyn. for Biomed. Res.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kochupillai202290,
	author = {Kochupillai, Mrinalini and Kahl, Matthias and Schmitt, Michael and Taubenbock, Hannes and Zhu, Xiao Xiang},
	title = {Earth Observation and Artificial Intelligence: Understanding emerging ethical issues and opportunities},
	year = {2022},
	journal = {IEEE Geoscience and Remote Sensing Magazine},
	volume = {10},
	number = {4},
	pages = {90 – 124},
	doi = {10.1109/MGRS.2022.3208357},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142780245&doi=10.1109%2fMGRS.2022.3208357&partnerID=40&md5=311c61d9907c5fc1ad9573f34aa45175},
	affiliations = {Technical University of Munich, Data Science in Earth Observation, Ottobrunn, 85521, Germany; University of the Bundeswehr, Earth Observation, Neubiberg, 85577, Germany; Earth Observation Center (EOC), German Aerospace Center (DLR), Oberpfaffenhofen, 82234, Germany; Julius-Maximilians-University, Institute for Geography and Geology, Würzburg, 97074, Germany; Technical University of Munich, Aerospace and Geodesy, Bavaria, Munich, 80333, Germany},
	abstract = {Ethics is a central and growing concern in all applications utilizing artificial intelligence (AI). Earth observation (EO) and remote sensing (RS) research relies heavily on both big data and AI or machine learning (ML). While this reliance is not new, with increasing image resolutions and the growing number of EO/RS use cases that have a direct impact on governance, policy, and the lives of people, ethical issues are taking center stage. In this article, we provide scientists engaged with AI for EO (AI4EO) research, 1) a practically useful overview of the key ethical issues emerging in this field, with concrete examples from within EO/RS to explain these issues, and 2) a first road map (flowchart) that scientists can use to identify ethical issues in their ongoing research. With this, we aim to sensitize scientists to these issues and create a bridge to facilitate constructive and regular communication among scientists engaged in AI4EO research, on the one hand, and ethics research, on the other hand. The article also provides detailed illustrations from four AI4EO research fields to explain how scientists can redesign research questions to more effectively grab ethical opportunities to address real-world problems that are otherwise akin to ethical dilemmas with no win-win solution in sight. The article concludes by providing recommendations to institutions that want to support ethically mindful AI4EO research and provides suggestions for future research in this field.  © 2013 IEEE.},
	keywords = {Artificial intelligence; Ethical technology; Image resolution; Learning systems; Observatories; Remote sensing; Artificial intelligence learning; Direct impact; Earth observations; Ethical issues; Guideline; Machine-learning; Remote sensing use; Remote-sensing; Research fields; Roadmap; artificial intelligence; EOS; ethics; image resolution; research work; Big data},
	correspondence_address = {M. Kochupillai; Technical University of Munich, Data Science in Earth Observation, Ottobrunn, 85521, Germany; email: m.kochupillai@tum.de},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {24732397},
	language = {English},
	abbrev_source_title = {IEEE Geosci. Remote Sens. Mag.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Hagendorff2022,
	author = {Hagendorff, Thilo},
	title = {A Virtue-Based Framework to Support Putting AI Ethics into Practice},
	year = {2022},
	journal = {Philosophy and Technology},
	volume = {35},
	number = {3},
	doi = {10.1007/s13347-022-00553-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132138493&doi=10.1007%2fs13347-022-00553-z&partnerID=40&md5=addb336a85bcd4ec5703c394af6dfe27},
	affiliations = {Cluster of Excellence “Machine Learning: New Perspectives for Science”, University of Tuebingen, Tübingen, Germany},
	abstract = {Many ethics initiatives have stipulated sets of principles and standards for good technology development in the AI sector. However, several AI ethics researchers have pointed out a lack of practical realization of these principles. Following that, AI ethics underwent a practical turn, but without deviating from the principled approach. This paper proposes a complementary to the principled approach that is based on virtue ethics. It defines four “basic AI virtues”, namely justice, honesty, responsibility and care, all of which represent specific motivational settings that constitute the very precondition for ethical decision making in the AI field. Moreover, it defines two “second-order AI virtues”, prudence and fortitude, that bolster achieving the basic virtues by helping with overcoming bounded ethicality or hidden psychological forces that can impair ethical decision making and that are hitherto disregarded in AI ethics. Lastly, the paper describes measures for successfully cultivating the mentioned virtues in organizations dealing with AI research and development. © 2022, The Author(s).},
	author_keywords = {AI ethics; AI virtues; Artificial intelligence; Bounded ethicality; Business ethics; Implementation; Machine learning; Moral psychology},
	correspondence_address = {T. Hagendorff; Cluster of Excellence “Machine Learning: New Perspectives for Science”, University of Tuebingen, Tübingen, Germany; email: thilo.hagendorff@uni-tuebingen.de},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22105433},
	language = {English},
	abbrev_source_title = {Philos. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Thomas2022,
	author = {Thomas, Diana M. and Kleinberg, Samantha and Brown, Andrew W. and Crow, Mason and Bastian, Nathaniel D. and Reisweber, Nicholas and Lasater, Robert and Kendall, Thomas and Shafto, Patrick and Blaine, Raymond and Smith, Sarah and Ruiz, Daniel and Morrell, Christopher and Clark, Nicholas},
	title = {Machine learning modeling practices to support the principles of AI and ethics in nutrition research},
	year = {2022},
	journal = {Nutrition and Diabetes},
	volume = {12},
	number = {1},
	doi = {10.1038/s41387-022-00226-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143186018&doi=10.1038%2fs41387-022-00226-y&partnerID=40&md5=71e14019c61a38a29eadb9e68a33495e},
	affiliations = {Department of Mathematical Sciences, United States Military Academy, West Point, 10996, NY, United States; Department of Computer Science, Stevens Institute of Technology, Hoboken, 07030, NJ, United States; Department of Biostatistics, University of Arkansas for Medical Sciences, Little Rock, 72205, AR, United States; Arkansas Children’s Research Institute, Little Rock, 72202, AR, United States; Army Cyber Institute, United States Military Academy, West Point, 10996, NY, United States; Department of Mathematics and Computer Science, Rutgers University, Newark, 07102, NJ, United States; Department of Electrical Engineering and Computer Science, United States Military Academy, West Point, 10996, NY, United States},
	abstract = {Background: Nutrition research is relying more on artificial intelligence and machine learning models to understand, diagnose, predict, and explain data. While artificial intelligence and machine learning models provide powerful modeling tools, failure to use careful and well-thought-out modeling processes can lead to misleading conclusions and concerns surrounding ethics and bias. Methods: Based on our experience as reviewers and journal editors in nutrition and obesity, we identified the most frequently omitted best practices from statistical modeling and how these same practices extend to machine learning models. We next addressed areas required for implementation of machine learning that are not included in commercial software packages. Results: Here, we provide a tutorial on best artificial intelligence and machine learning modeling practices that can reduce potential ethical problems with a checklist and guiding principles to aid nutrition researchers in developing, evaluating, and implementing artificial intelligence and machine learning models in nutrition research. Conclusion: The quality of AI/ML modeling in nutrition research requires iterative and tailored processes to mitigate against potential ethical problems or to predict conclusions that are free of bias. © 2022, This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply.},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Nutritional Status; Obesity; algorithm; Article; artificial intelligence; controlled study; human; information literacy; machine learning; measurement error; nutrition; obesity; research ethics; responsibility; selection bias; statistical model; nutritional status},
	correspondence_address = {D.M. Thomas; Department of Mathematical Sciences, United States Military Academy, West Point, 10996, United States; email: diana.thomas@westpoint.edu},
	publisher = {Springer Nature},
	issn = {20444052},
	pmid = {36456550},
	language = {English},
	abbrev_source_title = {Nutr. Diabetes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Narock2022,
	author = {Narock, Ayris and Bard, Christopher and Thompson, Barbara J. and Halford, Alexa J. and McGranaghan, Ryan M. and da Silva, Daniel and Kosar, Burcu and Shumko, Mykhaylo},
	title = {Supporting responsible machine learning in heliophysics},
	year = {2022},
	journal = {Frontiers in Astronomy and Space Sciences},
	volume = {9},
	doi = {10.3389/fspas.2022.1064233},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144493514&doi=10.3389%2ffspas.2022.1064233&partnerID=40&md5=b6d7a0010bd079ed05cf50a4bdcd5c95},
	affiliations = {NASA Goddard Space Flight Center, Greenbelt, MD, United States; ADNET Systems Inc, Bethesda, MD, United States; Orion Space Solutions, Louisville, CO, United States; University of MD, Baltimore County, Baltimore, MD, United States; The Catholic University of America, Washington, DC, United States; University of Maryland at College Park, College Park, MD, United States},
	abstract = {Over the last decade, Heliophysics researchers have increasingly adopted a variety of machine learning methods such as artificial neural networks, decision trees, and clustering algorithms into their workflow. Adoption of these advanced data science methods had quickly outpaced institutional response, but many professional organizations such as the European Commission, the National Aeronautics and Space Administration (NASA), and the American Geophysical Union have now issued (or will soon issue) standards for artificial intelligence and machine learning that will impact scientific research. These standards add further (necessary) burdens on the individual researcher who must now prepare the public release of data and code in addition to traditional paper writing. Support for these is not reflected in the current state of institutional support, community practices, or governance systems. We examine here some of these principles and how our institutions and community can promote their successful adoption within the Heliophysics discipline. Copyright © 2022 Narock, Bard, Thompson, Halford, McGranaghan, da Silva, Kosar and Shumko.},
	author_keywords = {community standards; data and information governance; emerging informatics technologies; ethics of artificial intelligence; funding; heliophysics; machine learning; science policy},
	correspondence_address = {A. Narock; NASA Goddard Space Flight Center, Greenbelt, United States; email: ayris.a.narock@nasa.gov},
	publisher = {Frontiers Media S.A.},
	issn = {2296987X},
	language = {English},
	abbrev_source_title = {Front. Astron. Space Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Fusar-Poli202217,
	author = {Fusar-Poli, Paolo and Manchia, Mirko and Koutsouleris, Nikolaos and Leslie, David and Woopen, Christiane and Calkins, Monica E. and Dunn, Michael and Tourneau, Christophe Le and Mannikko, Miia and Mollema, Tineke and Oliver, Dominic and Rietschel, Marcella and Reininghaus, Eva Z. and Squassina, Alessio and Valmaggia, Lucia and Kessing, Lars Vedel and Vieta, Eduard and Correll, Christoph U. and Arango, Celso and Andreassen, Ole A.},
	title = {Ethical considerations for precision psychiatry: A roadmap for research and clinical practice},
	year = {2022},
	journal = {European Neuropsychopharmacology},
	volume = {63},
	pages = {17 – 34},
	doi = {10.1016/j.euroneuro.2022.08.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136591687&doi=10.1016%2fj.euroneuro.2022.08.001&partnerID=40&md5=5158f1de425e9db6bdcec33b25eb27d2},
	affiliations = {Early Psychosis: Interventions and Clinical-Detection (EPIC) Lab, Department of Psychosis Studies, Institute of Psychiatry, Psychology & Neuroscience, King's College London, London, United Kingdom; South London and Maudsley NHS Foundation Trust, London, United Kingdom; Department of Brain and Behavioral Sciences, University of Pavia, Pavia, Italy; Section of Psychiatry, Department of Medical Sciences and Public Health, University of Cagliari, Cagliari, Italy; Unit of Clinical Psychiatry, University Hospital Agency of Cagliari, Cagliari, Italy; Department of Pharmacology, Dalhousie University, Halifax, NS, Canada; Section for Neurodiagnostic Applications, Ludwig-Maximilian-University, Munich; Ethics Theme Lead, The Alan Turing Institute; Center for Life Ethics, University of Bonn; Neurodevelopment and Psychosis Section and Lifespan Brain Institute of Penn/CHOP, Department of Psychiatry, Perelman School of Medicine, University of Pennsylvania, USA; Centre for Biomedical Ethics, Yong Loo Lin School of Medicine, National University of Singapore; Institut Curie, Department of Drug Development and Innovation (D3i), INSERM U900 Research unit, Paris-Saclay University, France; European Federation of Associations of Families of People with Mental Illness (EUFAMI), Leuven, Belgium; Global Alliance of Mental Illness Advocacy Networks-Europe (GAMIAN), Brussels, Belgium; Department of Genetic Epidemiology in Psychiatry, Central Institute of Mental Health, Medical Faculty Mannheim, Heidelberg University, Mannheim, Germany; Department of Psychiatry and Psychotherapeutic Medicine, Medical University of Graz, Graz, Austria; Section of Neuroscience and Clinical Pharmacology, Department of Biomedical Sciences, University of Cagliari, Italy; Department of Psychology, Institute of Psychiatry, Psychology and Neuroscience, King's College London, London, United Kingdom; Department of Psychiatry, KU Leuven, Belgium; Copenhagen Affective disorder Research Center (CADIC), Psychiatric Center Copenhagen, Denmark; Department of clinical Medicine, University of Copenhagen, Denmark; Hospital Clinic, Institute of Neuroscience, University of Barcelona, IDIBAPS, CIBERSAM, Barcelona, Catalonia, Spain; The Zucker Hillside Hospital, Department of Psychiatry, Northwell Health, Glen Oaks, NY, United States; Department of Psychiatry and Molecular Medicine, Donald and Barbara Zucker School of Medicine at Hofstra/Northwell, Hempstead, NY, United States; Center for Psychiatric Neuroscience, The Feinstein Institutes for Medical Research, Manhasset, NY, United States; Department of Child and Adolescent Psychiatry, Charité Universitätsmedizin, Berlin, Germany; Department of Child and Adolescent Psychiatry, Institute of Psychiatry and Mental Health, Hospital General Universitario Gregorio Marañón, Gregorio Marañón; Health Research Institute (IiGSM), School of Medicine, Universidad Complutense de Madrid; Biomedical Research Center for Mental Health (CIBERSAM), Madrid, Spain; NORMENT, Institute of Clinical Medicine, University of Oslo and Division of Mental Health and Addiction, Oslo University Hospital, Oslo, Norway},
	abstract = {Precision psychiatry is an emerging field with transformative opportunities for mental health. However, the use of clinical prediction models carries unprecedented ethical challenges, which must be addressed before accessing the potential benefits of precision psychiatry. This critical review covers multidisciplinary areas, including psychiatry, ethics, statistics and machine-learning, healthcare and academia, as well as input from people with lived experience of mental disorders, their family, and carers. We aimed to identify core ethical considerations for precision psychiatry and mitigate concerns by designing a roadmap for research and clinical practice. We identified priorities: learning from somatic medicine; identifying precision psychiatry use cases; enhancing transparency and generalizability; fostering implementation; promoting mental health literacy; communicating risk estimates; data protection and privacy; and fostering the equitable distribution of mental health care. We hope this blueprint will advance research and practice and enable people with mental health problems to benefit from precision psychiatry. © 2022},
	author_keywords = {Artificial intelligence; Bipolar disorders; Ethics; Precision medicine; Prevention; Psychosis},
	keywords = {Humans; Machine Learning; Mental Disorders; Psychiatry; caregiver; clinical practice; data privacy; data protection; family; health care; health care access; health care personnel; health care quality; health literacy; human; machine learning; medical ethics; mental disease; mental health care; neurobiology; oncology; personalized medicine; psychiatry; psychosomatics; Review; statistics; mental disease},
	correspondence_address = {P. Fusar-Poli; Department of Psychosis Studies, Institute of Psychiatry, Psychology & Neuroscience, London, 5th Floor PO63, 16 De Crespigny Park, SE5 8AF, United Kingdom; email: paolo.fusar-poli@kcl.ac.uk},
	publisher = {Elsevier B.V.},
	issn = {0924977X},
	coden = {EURNE},
	pmid = {36041245},
	language = {English},
	abbrev_source_title = {Eur. Neuropsychopharmacol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}

@ARTICLE{Flores2022759,
	author = {Flores, Lidia and Young, Sean D.},
	title = {Ethical Considerations in the Application of Artificial Intelligence to Monitor Social Media for COVID-19 Data},
	year = {2022},
	journal = {Minds and Machines},
	volume = {32},
	number = {4},
	pages = {759 – 768},
	doi = {10.1007/s11023-022-09610-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137029119&doi=10.1007%2fs11023-022-09610-0&partnerID=40&md5=78cd4265e840aa8c1891a8a66978d854},
	affiliations = {Department of Emergency Medicine, University of California, Irvine, CA, United States; Department of Informatics, University of California, Irvine, CA, United States},
	abstract = {The COVID-19 pandemic and its related policies (e.g., stay at home and social distancing orders) have increased people’s use of digital technology, such as social media. Researchers have, in turn, utilized artificial intelligence to analyze social media data for public health surveillance. For example, through machine learning and natural language processing, they have monitored social media data to examine public knowledge and behavior. This paper explores the ethical considerations of using artificial intelligence to monitor social media to understand the public’s perspectives and behaviors surrounding COVID-19, including potential risks and benefits of an AI-driven approach. Importantly, investigators and ethics committees have a role in ensuring that researchers adhere to ethical principles of respect for persons, beneficence, and justice in a way that moves science forward while ensuring public safety and confidence in the process. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Artificial intelligence; big data; COVID-19; ethics; social media},
	keywords = {Artificial intelligence; Big data; Ethical technology; Learning algorithms; Natural language processing systems; Social networking (online); Digital technologies; Ethical considerations; Language processing; Learning languages; Machine-learning; Natural languages; Public health surveillances; Public knowledge; Social media; Social media datum; COVID-19},
	correspondence_address = {S.D. Young; Department of Emergency Medicine, University of California, Irvine, United States; email: syoung5@hs.uci.edu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Schroder2022,
	author = {Schroder, Marie and Grobe-Bolting, Gregor and Muhling, Andreas},
	title = {Deriving Competency-Based Evaluation Criteria for Ethics Assignments in Computer Science},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3564721.3564744},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142935129&doi=10.1145%2f3564721.3564744&partnerID=40&md5=1f04e033499c8c3a897c97a699d55e00},
	affiliations = {Kiel University, Kiel, Germany; Leibniz Institute for Science and Mathematics Education, Kiel, Germany},
	abstract = {The discussion of the social responsibility of computer scientists and the ethical implications of computer science has, at the latest since the 1970s, been part of computer science curricula. Especially in recent years, the discussion about ethics in computer science has gained new momentum, due to the trending topics of AI and machine learning. The increased attention is also reflected in an expansion of teaching, which in turn creates a need for established teaching materials and assessment standards. This theoretical short paper presents the theory-driven and competency-based development of such evaluation criteria for the final exam performance of an "Ethics in Computer Science"course. The particular challenges of such an interdisciplinary endeavor are discussed, as well as the need for a transparent assessment standard in light of different subject cultures between computer science and philosophy. In addition to deriving the assessment items, the complete instrument is provided as part of our paper.  © 2022 ACM.},
	author_keywords = {assessment; competencies; ethics; theory based assessments},
	keywords = {Education computing; Engineering education; Ethical technology; Assessment; Competency; Computer science curricula; Computer scientists; Ethical implications; Evaluation criteria; Machine-learning; Social responsibilities; Theory based assessment; Trending topics; Social aspects},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039616-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 22nd Koli Calling International Conference on Computing Education Research, Koli Calling 2022; Conference date: 17 November 2022 through 20 November 2022; Conference code: 184335}
}

@ARTICLE{Coorey2022,
	author = {Coorey, Genevieve and Figtree, Gemma A. and Fletcher, David F. and Snelson, Victoria J. and Vernon, Stephen Thomas and Winlaw, David and Grieve, Stuart M. and McEwan, Alistair and Yang, Jean Yee Hwa and Qian, Pierre and O’Brien, Kieran and Orchard, Jessica and Kim, Jinman and Patel, Sanjay and Redfern, Julie},
	title = {The health digital twin to tackle cardiovascular disease—a review of an emerging interdisciplinary field},
	year = {2022},
	journal = {npj Digital Medicine},
	volume = {5},
	number = {1},
	doi = {10.1038/s41746-022-00640-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137102205&doi=10.1038%2fs41746-022-00640-7&partnerID=40&md5=196c116239e369184ab11a14a73828a3},
	affiliations = {University of Sydney, Faculty of Medicine and Health, Sydney, NSW, Australia; The George Institute for Global Health, Sydney, NSW, Australia; Kolling Institute of Medical Research, Royal North Shore Hospital, Sydney, NSW, Australia; University of Sydney, School of Chemical and Biomolecular Engineering, Sydney, NSW, Australia; University of Sydney, Charles Perkins Centre, Sydney, NSW, Australia; Department of Cardiology, Royal North Shore Hospital, Sydney, NSW, Australia; Cincinnati Children’s Hospital Medical Cente, Cincinnati, OH, United States; The University of Sydney, School of Biomedical Engineering, Sydney, NSW, Australia; Westmead Applied Research Centre, Westmead Hospital, Sydney, NSW, Australia; Siemens Healthcare Pty Ltd; and Centre for Advanced Imaging, University of Queensland, Brisbane, QLD, Australia; University of Sydney, School of Computer Science, Sydney, NSW, Australia; Royal Prince Alfred Hospital, Sydney, NSW, Australia; Heart Research Institute, Sydney, NSW, Australia},
	abstract = {Potential benefits of precision medicine in cardiovascular disease (CVD) include more accurate phenotyping of individual patients with the same condition or presentation, using multiple clinical, imaging, molecular and other variables to guide diagnosis and treatment. An approach to realising this potential is the digital twin concept, whereby a virtual representation of a patient is constructed and receives real-time updates of a range of data variables in order to predict disease and optimise treatment selection for the real-life patient. We explored the term digital twin, its defining concepts, the challenges as an emerging field, and potentially important applications in CVD. A mapping review was undertaken using a systematic search of peer-reviewed literature. Industry-based participants and patent applications were identified through web-based sources. Searches of Compendex, EMBASE, Medline, ProQuest and Scopus databases yielded 88 papers related to cardiovascular conditions (28%, n = 25), non-cardiovascular conditions (41%, n = 36), and general aspects of the health digital twin (31%, n = 27). Fifteen companies with a commercial interest in health digital twin or simulation modelling had products focused on CVD. The patent search identified 18 applications from 11 applicants, of which 73% were companies and 27% were universities. Three applicants had cardiac-related inventions. For CVD, digital twin research within industry and academia is recent, interdisciplinary, and established globally. Overall, the applications were numerical simulation models, although precursor models exist for the real-time cyber-physical system characteristic of a true digital twin. Implementation challenges include ethical constraints and clinical barriers to the adoption of decision tools derived from artificial intelligence systems. © 2022, The Author(s).},
	keywords = {Cardiology; Diagnosis; Embedded systems; Patents and inventions; Patient treatment; Cardiovascular disease; Condition; Data variables; Interdisciplinary fields; Phenotyping; Potential benefits; Real-time updates; Systematic searches; Treatment selection; Virtual representations; artificial intelligence; automated pattern recognition; big data; cardiovascular disease; clinical decision making; cloud computing; computational fluid dynamics; computer model; computer security; convolutional neural network; data integration; data mining; data processing; data protection; digital twin; finite element analysis; health care quality; health legislation; human; interdisciplinary research; internet of things; machine learning; medical ethics; medical research; patent; personalized medicine; proof of concept; Review; statistical model; trust; Diseases},
	correspondence_address = {G. Coorey; University of Sydney, Faculty of Medicine and Health, Sydney, Australia; email: genevieve.coorey@sydney.edu.au},
	publisher = {Nature Research},
	issn = {23986352},
	language = {English},
	abbrev_source_title = {npj Digit. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Dossari2022387,
	author = {Dossari, Mae and Ammar, Ahmed},
	title = {The future tools for medical training, assessment, and certification},
	year = {2022},
	journal = {Learning and Career Development in Neurosurgery: Values-Based Medical Education},
	pages = {387 – 403},
	doi = {10.1007/978-3-031-02078-0_34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153902531&doi=10.1007%2f978-3-031-02078-0_34&partnerID=40&md5=bfcd1acb625778d4b4b6abb0a088dff3},
	affiliations = {Department of family and Community Medicine, Faculty of Medicine, Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia; Department of Neurosurgery, King Fahd University Hospital Faculty of Medicine, Prince Abdulrahman Bin Faisal University, Al Khobar, Saudi Arabia},
	abstract = {The medical educators currently are facing unprecedented challenges as they have been racing against the rapid and sometimes beyond imagination development in information and communication technology. The information is the basic fundamental unit of the whole education and learning process. The digital or electronic learning, information technology, and telecommunications revolutionary are providing fast and reliable methods to obtain the right needed information. The timely impact and use of these information should have an impact on ways of medical learning and education and curriculums. For long time, good at memorizing the medical information is one of the major foundations of the education and learning process. Artificial intelligence, virtual learning, visual reality, artificial realities, machine learning, robotic and other new inventions and discovery are aiming to enhance and speed up the time of conducting, and receiving information are important educational and learning tools that should be integrated and used in the education and learning systems and training programs. The use of machine learning (ML) in medical education and training and health care provides a good method and model for learning. However, it raises numerous ethical concerns. One of the questions which has been raised is who teach what! Do we teach the machine (program the machine) to teach our trainees (simulation for example) or the future computer and robot may program itself to teach all of us. The introduction of Autonomous Things (AuT) in learning processes and healthcare services should be regulated. Autonomous Things (AuT) are those created devices and machines that work to do specific tasks autonomously without human interference, permission, or interaction. These machines may include medical robots. Robot ethics is a broad topic too. In the near future, the concept of memorizing subjects should not be stressed upon so much. The concept how to obtain the right information at the right time for the right patient will be the fundamental base of future education. Definitely, electronic learning and advanced information and communication technology significantly increased knowledge, skills, and the trainees' competencies. Therefore the methods of examination and evaluation of trainees skills, knewledges and potentials should be changed from the current method which is mainly testing memories to evaluate the ability of the trainee to obtain the right and needed information, knowledge, solution cinereous in timely fashion. Telemedicine and tele education are globally growing demolishing geographical borders and penetrating the thick walls of universities and hospitals. These welcomed significant development of information and communication technology raised ethical and litigation considerations, which should be dealt with. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2022. All rights reserved.},
	author_keywords = {Artificial technology; Communication technology; Hybrid learning; Information technology; Medical learning; Values-based medicine},
	correspondence_address = {A. Ammar; Department of Neurosurgery, King Fahd University Hospital Faculty of Medicine, Prince Abdulrahman Bin Faisal University, Al Khobar, Saudi Arabia; email: ahmed@ahmedammar.com},
	publisher = {Springer International Publishing},
	isbn = {978-303102078-0; 978-303102077-3},
	language = {English},
	abbrev_source_title = {Learning and Career dév. in neurosurg.: Values-Based méd. educ.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yoon2022581,
	author = {Yoon, Chang Ho and Torrance, Robert and Scheinerman, Naomi},
	title = {Machine learning in medicine: should the pursuit of enhanced interpretability be abandoned?},
	year = {2022},
	journal = {Journal of Medical Ethics},
	volume = {48},
	number = {9},
	pages = {581 – 585},
	doi = {10.1136/medethics-2020-107102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106158756&doi=10.1136%2fmedethics-2020-107102&partnerID=40&md5=dd45ce7b7dae7f6ea181619dc751abe4},
	affiliations = {Big Data Institute, Oxford University, Oxford, United Kingdom; Medical Sciences Doctoral Training Centre, Oxford University, Oxford, United Kingdom; Nuffield Department of Population Health, University of Oxford Richard Doll Building, Oxford, United Kingdom; Faculty of Public Health and Policy, London School of Hygiene and Tropical Medicine, London, United Kingdom; Department of Medical Ethics and Health Policy, Perelman School of Medicine, The University of Pennsylvania, Philadelphia, PA, United States},
	abstract = {We argue why interpretability should have primacy alongside empiricism for several reasons: first, if machine learning (ML) models are beginning to render some of the high-risk healthcare decisions instead of clinicians, these models pose a novel medicolegal and ethical frontier that is incompletely addressed by current methods of appraising medical interventions like pharmacological therapies; second, a number of judicial precedents underpinning medical liability and negligence are compromised when 'autonomous' ML recommendations are considered to be en par with human instruction in specific contexts; third, explainable algorithms may be more amenable to the ascertainment and minimisation of biases, with repercussions for racial equity as well as scientific reproducibility and generalisability. We conclude with some reasons for the ineludible importance of interpretability, such as the establishment of trust, in overcoming perhaps the most difficult challenge ML will face in a high-stakes environment like healthcare: professional and public acceptance. © 2022 Journal of Clinical Pathology.},
	author_keywords = {clinical ethics; decision-making},
	keywords = {Humans; Machine Learning; Reproducibility of Results; Trust; algorithm; article; decision making; empiricism; ethics; human; human experiment; machine learning; medical liability; negligence; reproducibility; trust; trust},
	correspondence_address = {C.H. Yoon; Big Data Institute, Oxford University, Oxford, OX3 9DU, United Kingdom; email: changho.yoon@gmail.com},
	publisher = {BMJ Publishing Group},
	issn = {03066800},
	coden = {JMETD},
	pmid = {34006600},
	language = {English},
	abbrev_source_title = {J. Med. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Mittal2022e068098,
	author = {Mittal, Nimish and Sabo, Andrea and Deshpande, Amol and Clarke, Hance and Taati, Babak},
	title = {Feasibility of video-based joint hypermobility assessment in individuals with suspected Ehlers-Danlos syndromes/generalised hypermobility spectrum disorders: a single-site observational study protocol},
	year = {2022},
	journal = {BMJ open},
	volume = {12},
	number = {12},
	pages = {e068098},
	doi = {10.1136/bmjopen-2022-068098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144588526&doi=10.1136%2fbmjopen-2022-068098&partnerID=40&md5=6a50a02de1aae1eb62b46dbd3af59ff5},
	affiliations = {Department of Medicine, Division of Physical Medicine and Rehabiitation, University of Toronto, Toronto, ON, Canada; Department of Anesthesia and Pain Medicine, University of Toronto, Toronto, ON, Canada; Faculty of Kinesiology and Physical Education, University of Toronto, Toronto, ON, Canada; Toronto General Hospital, Toronto, ON, Canada; KITE Research Institute, Toronto Rehabilitation Institute - University Health Network, Toronto, ON, Canada; University Health Network, Toronto, ON, Canada; Pain Research Unit, University Health Network, Toronto, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Institute of Biomedical Engineering, University of Toronto, Toronto, ON, Canada},
	abstract = {INTRODUCTION: Ehlers-Danlos syndromes (EDS)/generalised hypermobility spectrum disorders (G-HSD) affect the connective tissue of the body and present with a heterogeneous set of symptoms that pose a challenge for diagnosis. One of the main diagnostic criteria of EDS/G-HSD is generalised joint hypermobility, which is currently assessed by clinicians during a physical exam. However, the practice for measuring joint hypermobility is inconsistent between clinicians, leading to high inter-rater variability. Often patients are misdiagnosed with EDS/G-HSD based on an incorrect hypermobility assessment, leading to increased referral rates and resource utilisation at specialised EDS clinics that results in unnecessary emotional distress for patients. An objective, validated and scalable method for assessing hypermobility might mitigate these issues and result in improved EDS/G-HSD patient care. METHODS AND ANALYSIS: This study will examine the use of videos obtained using a smartphone camera to assess the range of motion (ROM) and hypermobility of the joints assessed in Beighton score and more (spine, shoulders, elbows, knees, ankles, thumbs and fifth fingers) in individuals with suspected EDS/G-HSD. Short videos of participants will be captured as they undergo a formal assessment of joint hypermobility at the GoodHope EDS Clinic at Toronto General Hospital. Clinicians will measure the ROM at each joint using a clinical-grade goniometer to establish ground truth measurements. Open-source human pose-estimation libraries will be used to extract the locations of key joints from the videos. Deterministic and machine learning systems will be developed and evaluated for estimating the ROM at each joint. Results will be analysed separately for each joint and human pose-estimation library. ETHICS AND DISSEMINATION: This study was approved by the Research Ethics Board of the University Health Network in Toronto on 26 April 2022. Participants will provide written informed consent. Findings from this study will be published in peer-reviewed journals and presented at conferences. TRIAL REGISTRATION NUMBER: NCT05366114. © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {GENERAL MEDICINE (see Internal Medicine); GENETICS; Quality in health care; REHABILITATION MEDICINE},
	keywords = {Connective Tissue; Ehlers-Danlos Syndrome; Feasibility Studies; Humans; Joint Instability; Observational Studies as Topic; Range of Motion, Articular; connective tissue; Ehlers Danlos syndrome; feasibility study; human; joint characteristics and functions; joint instability; observational study},
	publisher = {NLM (Medline)},
	issn = {20446055},
	pmid = {36526308},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{De León2022,
	author = {De León, Gerardo and Fröhlich, Eleonore and Fink, Elisabeth and Di Pizio, Antonella and Salar-Behzadi, Sharareh},
	title = {Premexotac: Machine learning bitterants predictor for advancing pharmaceutical development},
	year = {2022},
	journal = {International Journal of Pharmaceutics},
	volume = {628},
	doi = {10.1016/j.ijpharm.2022.122263},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140090859&doi=10.1016%2fj.ijpharm.2022.122263&partnerID=40&md5=b474d7f2de3867a96ef70aa0467224e1},
	affiliations = {Research Center Pharmaceutical Engineering GmbH, Graz, Austria; Center for Medical Research, Medical University of Graz, Austria; Leibniz Institute for Food Systems Biology at the Technical University of Munich, Germany; Institute of Pharmaceutical Sciences, Department of Pharmaceutical Technology and Biopharmacy, University of Graz, Austria},
	abstract = {Bitter taste receptors were recently found to be involved in numerous physiological and pathological conditions other than taste and are suggested as potential drug targets. In vivo and in vitro techniques for screening bitterants as ligands come with economical, time and ethic challenges. Therefore, in silico tools can represent a valuable alternative due to their practicality. Yet, the main challenge of already established ligand-based (LB) classifiers is the low number of experimentally confirmed bitterants and non-bitterants. Premexotac models were constructed as a LB bitterants screener, exploring novel combinations of feature extraction, feature selection and learning algorithms as a contrast with the already available screeners. Premexotac came among the top performers, exhibiting a F-1 score up to 81% on external validation. Premexotac identified as well insights on physicochemical and topological descriptors important for bitter prediction. Among the key insights, important molecular substructures from Extended Connectivity Fingerprints for bitterness classification were identified. Also, the importance of a selection of physicochemical/topological descriptors was ranked using mutual information and it was found that descriptors related to the ramification of the molecular structure and molecular weight came at the top of the ranking. The remaining challenges for improving performance were discussed and stated, widening the LB bitterness prediction outlook. © 2022 Elsevier B.V.},
	author_keywords = {Bitter taste receptors; Feature extraction; Feature selection; Learning algorithm; Ligand-based classifier; Premexotac; TAS2R},
	keywords = {Algorithms; Aversive Agents; Drug Development; Ligands; Machine Learning; Taste; aversive agent; ligand; Article; bitter taste; classifier; feature extraction; feature selection; learning algorithm; machine learning; pharmaceutics; physical chemistry; prediction; algorithm; drug development; taste},
	correspondence_address = {S. Salar-Behzadi; Research Center Pharmaceutical Engineering GmbH, Graz, Austria; email: sharareh.salar@rcpe.at},
	publisher = {Elsevier B.V.},
	issn = {03785173},
	coden = {IJPHD},
	pmid = {36208839},
	language = {English},
	abbrev_source_title = {Int. J. Pharm.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Shanklin2022,
	author = {Shanklin, Robert and Samorani, Michele and Harris, Shannon and Santoro, Michael A.},
	title = {Ethical Redress of Racial Inequities in AI: Lessons from Decoupling Machine Learning from Optimization in Medical Appointment Scheduling},
	year = {2022},
	journal = {Philosophy and Technology},
	volume = {35},
	number = {4},
	doi = {10.1007/s13347-022-00590-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140251532&doi=10.1007%2fs13347-022-00590-8&partnerID=40&md5=05ff76e9fc81860b2127197b84cafad6},
	affiliations = {Philosophy Department, Santa Clara University, 500 El Camino Real, Santa Clara, 950053, CA, United States; Department of Information Systems and Analytics, Santa Clara University, 500 El Camino Real, Santa Clara, 950053, CA, United States; School of Business, Virginia Commonwealth University, Snead Hall, 301 W. Main Street, Box 844000, Richmond, 23284-4000, VA, United States; Department of Management and Entrepreneurship, Santa Clara University, 500 El Camino Real, Santa Clara, 950053, CA, United States},
	abstract = {An Artificial Intelligence algorithm trained on data that reflect racial biases may yield racially biased outputs, even if the algorithm on its own is unbiased. For example, algorithms used to schedule medical appointments in the USA predict that Black patients are at a higher risk of no-show than non-Black patients, though technically accurate given existing data that prediction results in Black patients being overwhelmingly scheduled in appointment slots that cause longer wait times than non-Black patients. This perpetuates racial inequity, in this case lesser access to medical care. This gives rise to one type of Accuracy-Fairness trade-off: preserve the efficiency offered by using AI to schedule appointments or discard that efficiency in order to avoid perpetuating ethno-racial disparities. Similar trade-offs arise in a range of AI applications including others in medicine, as well as in education, judicial systems, and public security, among others. This article presents a framework for addressing such trade-offs where Machine Learning and Optimization components of the algorithm are decoupled. Applied to medical appointment scheduling, our framework articulates four approaches intervening in different ways on different components of the algorithm. Each yields specific results, in one case preserving accuracy comparable to the current state-of-the-art while eliminating the disparity. © 2022, The Author(s).},
	author_keywords = {Artificial Intelligence; Bias; Ethics; Healthcare; Machine Learning; Racial Disparities},
	correspondence_address = {R. Shanklin; Philosophy Department, Santa Clara University, Santa Clara, 500 El Camino Real, 950053, United States; email: rshanklin@scu.edu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22105433},
	language = {English},
	abbrev_source_title = {Philos. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ren2022,
	author = {Ren, Simiao and Hu, Wayne and Bradbury, Kyle and Harrison-Atlas, Dylan and Malaguzzi Valeri, Laura and Murray, Brian and Malof, Jordan M.},
	title = {Automated Extraction of Energy Systems Information from Remotely Sensed Data: A Review and Analysis},
	year = {2022},
	journal = {Applied Energy},
	volume = {326},
	doi = {10.1016/j.apenergy.2022.119876},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138547463&doi=10.1016%2fj.apenergy.2022.119876&partnerID=40&md5=1c6ce5191722e157cdcd173a54317eca},
	affiliations = {Energy Initiative, Duke University, Durham, 27701, NC, United States; Department of Electrical and Computer Engineering, Duke University, Durham, 27701, NC, United States; National Renewable Energy Laboratory, Golden, CO, United States; World Resources Institute, Washington, D.C, United States; Department of Computer Science, University of Montana, Missoula, MT, United States},
	abstract = {High quality energy systems information is a crucial input to energy systems research, modeling, and decision-making. Unfortunately, actionable information about energy systems is often of limited availability, incomplete, or only accessible for a substantial fee or through a non-disclosure agreement. Recently, remotely sensed data (e.g., satellite imagery, aerial photography) have emerged as a potentially rich source of energy systems information. However, the use of these data is frequently challenged by its sheer volume and complexity, precluding manual analysis. Recent breakthroughs in machine learning have enabled automated and rapid extraction of useful information from remotely sensed data, facilitating large-scale acquisition of critical energy system variables. Here we present a systematic review of the literature on this emerging topic, providing an in-depth survey and review of papers published within the past two decades. We first taxonomize the existing literature into ten major areas, spanning the energy value chain. Within each research area, we distill and critically discuss major features that are relevant to energy researchers, including, for example, key challenges regarding the accessibility and reliability of the methods. We then synthesize our findings to identify limitations and trends in the literature as a whole, and discuss opportunities for innovation. These include the opportunity to extend the methods beyond electricity to broader energy systems and wider geographic areas; and the ability to expand the use of these methods in research and decision making as satellite data become cheaper and easier to access. We also find that there are persistent challenges: limited standardization and rigor of performance assessments; limited sharing of code, which would improve replicability; and a limited consideration of the ethics and privacy of data. © 2022 Elsevier Ltd},
	keywords = {Aerial photography; Antennas; Data privacy; Extraction; Remote sensing; Satellite imagery; Automated extraction; Decisions makings; Energy systems; High quality; Model-making; Non-disclosure agreements; Remotely sensed data; Research models; System information; Systems research; decision making; energy efficiency; extraction method; literature review; remote sensing; satellite data; satellite imagery; Decision making},
	correspondence_address = {J.M. Malof; Department of Computer Science, University of Montana, Missoula, Social Sciences Building 401, 59812, United States; email: jordan.malof@mso.umt.edu},
	publisher = {Elsevier Ltd},
	issn = {03062619},
	coden = {APEND},
	language = {English},
	abbrev_source_title = {Appl. Energy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Anderson2022701,
	author = {Anderson, Khalil},
	title = {Real-time Feedback for Developing Conversation Literacy},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {701 – 704},
	doi = {10.1145/3536221.3557031},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142807162&doi=10.1145%2f3536221.3557031&partnerID=40&md5=09ec8b41a4fd6c574952752dc10717d0},
	affiliations = {Northwestern University, Evanston, IL, United States},
	abstract = {Learning Analytics (LA) has exploded with the growth in Machine Learning applications. LA, while not new, is always changing, and now allows for automated analyses that used to seem impossible. There is still a need for real-time systems while also centering the design around students and data. By using multiple data streams to provide real-time Learning Analytics, this paper aims to describe a plan for creating a system that aids teachers managing classes and improve the collaboration literacy of students while taking into account ethical, privacy, and user concerns. By surveying and engaging with students and teachers, general guidelines in terms of ethics and privacy in LA will be designed. Along with the data, there will be a way to best present this information in a useful and engaging method to students and teachers that would be determined through studies on the efficacy of different User Interfaces (UIs) and data views along with the surveying.  © 2022 ACM.},
	author_keywords = {audio processing; HCI; Learning Analytics; Multi-modal; video processing},
	keywords = {Human computer interaction; Interactive computer systems; Learning systems; Philosophical aspects; Real time systems; Surveys; User interfaces; Video signal processing; Audio processing; Automated analysis; Learning analytic; Machine learning applications; Multi-modal; Multiple data streams; Real - Time system; Real-time feedback; Teachers'; Video processing; Students},
	correspondence_address = {K. Anderson; Northwestern University, Evanston, United States; email: khanders@u.northwestern.edu},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039390-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 24th ACM International Conference on Multimodal Interaction, ICMI 2022; Conference date: 7 November 2022 through 11 November 2022; Conference code: 184100}
}

@ARTICLE{Liu2022,
	author = {Liu, Fang and Demosthenes, Panagiotakos},
	title = {Real-world data: a brief review of the methods, applications, challenges and opportunities},
	year = {2022},
	journal = {BMC Medical Research Methodology},
	volume = {22},
	number = {1},
	doi = {10.1186/s12874-022-01768-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141388710&doi=10.1186%2fs12874-022-01768-6&partnerID=40&md5=9a1754e37ff0b4d0f1bc85864556cd64},
	affiliations = {Department of Applied and Computational Mathematics and Statistics, University of Notre Dame, Notre Dame, 46530, IN, United States; School of Health Sciences and Education, Harokopio University, Athens, Greece},
	abstract = {Background: The increased adoption of the internet, social media, wearable devices, e-health services, and other technology-driven services in medicine and healthcare has led to the rapid generation of various types of digital data, providing a valuable data source beyond the confines of traditional clinical trials, epidemiological studies, and lab-based experiments. Methods: We provide a brief overview on the type and sources of real-world data and the common models and approaches to utilize and analyze real-world data. We discuss the challenges and opportunities of using real-world data for evidence-based decision making This review does not aim to be comprehensive or cover all aspects of the intriguing topic on RWD (from both the research and practical perspectives) but serves as a primer and provides useful sources for readers who interested in this topic. Results and Conclusions: Real-world hold great potential for generating real-world evidence for designing and conducting confirmatory trials and answering questions that may not be addressed otherwise. The voluminosity and complexity of real-world data also call for development of more appropriate, sophisticated, and innovative data processing and analysis techniques while maintaining scientific rigor in research findings, and attentions to data ethics to harness the power of real-world data. © 2022, The Author(s).},
	author_keywords = {Artificial intelligence; Causal inference; Electronic health records; Machine learning; Real-world data (RWD); Real-world evidence (RWE)},
	keywords = {Delivery of Health Care; Humans; Information Storage and Retrieval; health care delivery; human; information retrieval; procedures},
	correspondence_address = {F. Liu; Department of Applied and Computational Mathematics and Statistics, University of Notre Dame, Notre Dame, 46530, United States; email: fliu2@nd.edu},
	publisher = {BioMed Central Ltd},
	issn = {14712288},
	pmid = {36335315},
	language = {English},
	abbrev_source_title = {BMC Med. Res. Methodol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Basáez2022556,
	author = {Basáez, Esteban and Mora, Javier},
	title = {Artificial intelligence in health: where are we in 2022?; [Salud e inteligencia artificial: ¿cómo hemos evolucionado?]},
	year = {2022},
	journal = {Revista Medica Clinica Las Condes},
	volume = {33},
	number = {6},
	pages = {556 – 561},
	doi = {10.1016/j.rmclc.2022.11.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148864668&doi=10.1016%2fj.rmclc.2022.11.003&partnerID=40&md5=ef94d513fe3b154941c3fba474775314},
	affiliations = {Jefe Departamento de Neurología. Clínica Las Condes. Santiago, Chile, Chile; Jefe Centro de Innovación. Clínica Las Condes. Santiago, Chile, Chile; Departamento Cirugía Cardíaca, Vascular y Tórax, Clínica Las Condes. Santiago, Chile, Chile; Unidad de ECMO, Clínica Las Condes. Santiago, Chile, Chile; Unidad de Ciencia de Datos Clínicos, Clínica Las Condes. Santiago, Chile, Chile},
	abstract = {Artificial Intelligence (AI) has become a daily presence. Its applications in healthcare have proved to be a complement to clinical practice with good results. However, incorporating disruptive technologies in medicine is not easy, due to the principles of non-maleficence, beneficence, autonomy and justice that must be ensured by the medical act, and because it is complex and difficult to break paradigms in an environment where experience and clinical perception have key value. From the use of the thermometer to computational algorithms that diagnose diseases in medical images with greater precision than the human eye, technologies have had to undergo scientific demonstration of their benefits. To this end, evidence-based medicine is now complemented by modern computational techniques for processing huge amount of data in ways that had not been possible before, obtaining valuable new information that enables timely prevention and early disease detection, more accurate diagnoses, increasingly personalized interventions and treatments, and automated follow-up and interaction between patients and healthcare centers. Increasing research in different fields of health sciences support this affirmation. In this review we show some milestones of machine learning and AI incorporation in healthcare, and projections on how our institutions can contribute through research, development and innovation to ensure that these technologies positively impact and benefit patients. © 2022},
	author_keywords = {Artificial Intelligence; Clinical Data; Ethics; Healthcare; Machine Learning; Technology},
	correspondence_address = {E. Basáez; Jefe Departamento de Neurología. Clínica Las Condes. Santiago, Chile, Chile; email: ebasaez@clinicalascondes.cl},
	publisher = {Ediciones Doyma, S.L.},
	issn = {07168640},
	language = {English},
	abbrev_source_title = {Rev. Med. Clin. Las Condes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Sobkowicz2022,
	author = {Sobkowicz, Pawel},
	title = {Hammering with the telescope},
	year = {2022},
	journal = {Frontiers in Artificial Intelligence},
	volume = {5},
	doi = {10.3389/frai.2022.1010219},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143760230&doi=10.3389%2ffrai.2022.1010219&partnerID=40&md5=37466da9e8fe1139a95589d2d1e64ad1},
	affiliations = {NOMATEN Centre of Excellence, National Centre for Nuclear Research, Otwock, Poland},
	abstract = {The rapid pace in which various Artificial Intelligence and Machine Learning tools are developed, both within the research community and outside of it, often discourages the involved researchers from taking time to consider potential consequences and applications of the technical advances, especially the unintended ones. While there are notable exceptions to this “gold rush” tendency, individuals and groups providing careful analyses and recommendations for future actions, their adoption remains, at best, limited. This essay presents an analysis of the ethical (and not only) challenges connected with the applications of AI/ML methods in the socio-legal domain. Copyright © 2022 Sobkowicz.},
	author_keywords = {Artificial Intelligence; crime; ethics; law; machine learning},
	correspondence_address = {P. Sobkowicz; NOMATEN Centre of Excellence, National Centre for Nuclear Research, Otwock, Poland; email: pawelsobko@gmail.com},
	publisher = {Frontiers Media S.A.},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Cowley2022,
	author = {Cowley, Hannah P. and Natter, Mandy and Gray-Roncal, Karla and Rhodes, Rebecca E. and Johnson, Erik C. and Drenkow, Nathan and Shead, Timothy M. and Chance, Frances S. and Wester, Brock and Gray-Roncal, William},
	title = {A framework for rigorous evaluation of human performance in human and machine learning comparison studies},
	year = {2022},
	journal = {Scientific Reports},
	volume = {12},
	number = {1},
	doi = {10.1038/s41598-022-08078-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127443042&doi=10.1038%2fs41598-022-08078-3&partnerID=40&md5=9df4f6d542c9a6a99746c519286c9561},
	affiliations = {The Johns Hopkins University Applied Physics Laboratory, Research and Exploratory Development Department, Laurel, 20723, MD, United States; Sandia National Laboratories, Albuquerque, 87185, NM, United States},
	abstract = {Rigorous comparisons of human and machine learning algorithm performance on the same task help to support accurate claims about algorithm success rates and advances understanding of their performance relative to that of human performers. In turn, these comparisons are critical for supporting advances in artificial intelligence. However, the machine learning community has lacked a standardized, consensus framework for performing the evaluations of human performance necessary for comparison. We demonstrate common pitfalls in a designing the human performance evaluation and propose a framework for the evaluation of human performance, illustrating guiding principles for a successful comparison. These principles are first, to design the human evaluation with an understanding of the differences between human and algorithm cognition; second, to match trials between human participants and the algorithm evaluation, and third, to employ best practices for psychology research studies, such as the collection and analysis of supplementary and subjective data and adhering to ethical review protocols. We demonstrate our framework’s utility for designing a study to evaluate human performance on a one-shot learning task. Adoption of this common framework may provide a standard approach to evaluate algorithm performance and aid in the reproducibility of comparisons between human and machine learning algorithm performance. © 2022, The Author(s).},
	keywords = {Algorithms; Artificial Intelligence; Humans; Machine Learning; Reproducibility of Results; adoption; adult; algorithm; article; cognition; controlled study; ethics; female; human; human experiment; learning; machine learning; male; psychology; reproducibility; algorithm; artificial intelligence},
	correspondence_address = {H.P. Cowley; The Johns Hopkins University Applied Physics Laboratory, Research and Exploratory Development Department, Laurel, 20723, United States; email: Hannah.Cowley@jhuapl.edu; W. Gray-Roncal; The Johns Hopkins University Applied Physics Laboratory, Research and Exploratory Development Department, Laurel, 20723, United States; email: william.gray.roncal@jhuapl.edu},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {35361786},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Adomavicius2022,
	author = {Adomavicius, Gediminas and Yang, Mochen},
	title = {Integrating Behavioral, Economic, and Technical Insights to Understand and Address Algorithmic Bias: A Human-Centric Perspective},
	year = {2022},
	journal = {ACM Transactions on Management Information Systems},
	volume = {13},
	number = {3},
	doi = {10.1145/3519420},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133428210&doi=10.1145%2f3519420&partnerID=40&md5=11d2ec0dc03ce40d366d5bca3560dfc6},
	affiliations = {University of Minnesota, 321 19th Ave S, Minneapolis, 55455, MN, United States},
	abstract = {Many important decisions are increasingly being made with the help of information systems that use artificial intelligence and machine learning models. These computational models are designed to discover useful patterns from large amounts of data, which augment human capabilities to make decisions in various application domains. However, there are growing concerns regarding the ethics challenges faced by these automated decision-making (ADM) models, most notably on the issue of algorithmic bias, in which the models systematically produce less favorable (i.e., unfair) decisions for certain groups of people. In this commentary, we argue that algorithmic bias is not just a technical (e.g., computational or statistical) problem, and its successful resolution requires deep insights into individual and organizational behavior, economic incentives, as well as complex dynamics of the sociotechnical systems in which the ADM models are embedded. We discuss a human-centric, fairness-aware ADM framework that highlights the holistic involvement of human decision makers in each step of ADM. We review the emerging literature on fairness-aware machine learning and then discuss various strategic decisions that humans need to make, such as formulating proper fairness objectives, recognizing fairness-induced trade-offs and implications, utilizing machine learning model outputs, and managing/governing the decisions of ADM models. We further illustrate how these strategic decisions are jointly informed by behavioral, economic, and design sciences. Our discussions reveal a number of future research opportunities uniquely suitable for Management Information Systems (MIS) researchers to pursue. © 2022 Association for Computing Machinery. All rights reserved.},
	author_keywords = {algorithmic bias; augmented decision-making; Automated decision-making; ethics; fairness},
	keywords = {Behavioral research; Economic and social effects; Embedded systems; Ethical technology; Information management; Information systems; Information use; Machine learning; Algorithmic bias; Algorithmics; Augmented decision-making; Automated decision making; Behavioral economics; Decision-making modeling; Decisions makings; Fairness; Human-centric; Machine learning models; Decision making},
	publisher = {Association for Computing Machinery},
	issn = {2158656X},
	language = {English},
	abbrev_source_title = {ACM Trans. Manage. Inf. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Li2022,
	author = {Li, Zhu and Pérez-Suay, Adrián and Camps-Valls, Gustau and Sejdinovic, Dino},
	title = {Kernel dependence regularizers and Gaussian processes with applications to algorithmic fairness},
	year = {2022},
	journal = {Pattern Recognition},
	volume = {132},
	doi = {10.1016/j.patcog.2022.108922},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135965609&doi=10.1016%2fj.patcog.2022.108922&partnerID=40&md5=a9d0e2807558a1b6da1c11c10220ccc8},
	affiliations = {Department of Statistics, University of Oxford, 24-29 St Giles, Oxford, OX1 3LB, United Kingdom; Image Processing Laboratory (IPL), Universitat de Valéncia, Catedrático A. Escardino, Valéncia, Paterna, 46980, Spain; Gatsby Computational Neuroscience Unit, University College London, 25 Howland Street, London, W1T 4JG, United Kingdom},
	abstract = {Current adoption of machine learning in industrial, societal and economical activities has raised concerns about the fairness, equity and ethics of automated decisions. Predictive models are often developed using biased datasets and thus retain or even exacerbate biases in their decisions and recommendations. Removing the sensitive covariates, such as gender or race, is insufficient to remedy this issue since the biases may be retained due to other related covariates. We present a regularization approach to this problem that trades off predictive accuracy of the learned models (with respect to biased labels) for the fairness in terms of statistical parity, i.e. independence of the decisions from the sensitive covariates. In particular, we consider a general framework of regularized empirical risk minimization over reproducing kernel Hilbert spaces and impose an additional regularizer of dependence between predictors and sensitive covariates using kernel-based measures of dependence, namely the Hilbert-Schmidt Independence Criterion (HSIC) and its normalized version. This approach leads to a closed-form solution in the case of squared loss, i.e. ridge regression. We also provide statistical consistency results for both risk and fairness bound for our approach. Moreover, we show that the dependence regularizer has an interpretation as modifying the corresponding Gaussian process (GP) prior. As a consequence, a GP model with a prior that encourages fairness to sensitive variables can be derived, allowing principled hyperparameter selection and studying of the relative relevance of covariates under fairness constraints. Experimental results in synthetic examples and in real problems of income and crime prediction illustrate the potential of the approach to improve fairness of automated decisions. © 2022},
	author_keywords = {Fairness; Gaussian processes; Hilbert-Schmidt independence criterion; Kernel methods; Regularization},
	keywords = {Gaussian distribution; Regression analysis; Risk assessment; 'current; Algorithmics; Covariates; Fairness; Gaussian Processes; Hilbert-schmidt independence criterions; Kernel-methods; Machine-learning; Regularisation; Regularizer; Gaussian noise (electronic)},
	correspondence_address = {Z. Li; Department of Statistics, University of Oxford, Oxford, 24-29 St Giles, OX1 3LB, United Kingdom; email: zhu.li@ucl.ac.uk},
	publisher = {Elsevier Ltd},
	issn = {00313203},
	coden = {PTNRA},
	language = {English},
	abbrev_source_title = {Pattern Recogn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Hirsch2022,
	author = {Hirsch, Jana A and Michael, Yvonne L and Moore, Kari A and Melly, Steven and Hughes, Timothy M and Hayden, Kathleen and Luchsinger, Jose A and Jimenez, Marcia P and James, Peter and Besser, Lilah M and Sánchez, Brisa and Diez Roux, Ana V},
	title = {Longitudinal neighbourhood determinants with cognitive health and dementia disparities: protocol of the Multi-Ethnic Study of Atherosclerosis Neighborhoods and Aging prospective cohort study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {11},
	doi = {10.1136/bmjopen-2022-066971},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141717794&doi=10.1136%2fbmjopen-2022-066971&partnerID=40&md5=5ef08285e7a49982aef93e5b084d501a},
	affiliations = {Urban Health Collaborative and Department of Epidemiology and Biostatistics, Drexel University, Philadelphia, PA, United States; Department of Epidemiology and Biostatistics, Drexel University, Philadelphia, PA, United States; Urban Health Collaborative, Drexel University, Philadelphia, PA, United States; Department of Internal Medicine, Medical Center Boulevard, Winston-Salem, NC, United States; Department of Social Sciences and Health Policy, Bowman Gray Center for Medical Education, Winston-Salem, NC, United States; Department of Medicine, Columbia University, New York, NY, United States; Department of Epidemiology, Boston University School of Public Health, Boston, MA, United States; Department of Population Medicine, Harvard Medical School, Boston, MA, United States; Department of Population Medicine, Harvard Th Chan School of Public Health, Boston, MA, United States; Department of Neurology, University of Miami Miller School of Medicine, Miami, FL, United States},
	abstract = {Introduction The burden of Alzheimer's disease (AD) and AD-related dementias (ADRD) is increasing nationally and globally, with disproportionate impacts on lower-income, lower education and systematically marginalised older adults. Presence of inequalities in neighbourhood factors (eg, social context, physical and built environments) may affect risk of cognitive decline and be key for intervening on AD/ADRD disparities at the population level. However, existing studies are limited by a dearth of longitudinal, detailed neighbourhood measures linked to rich, prospective cohort data. Our main objective is to identify patterns of neighbourhood change related to prevalence of - and disparities in - cognitive decline and dementia. Methods and analyses We describe the process of collecting, processing and linking extensive neighbourhood data to the Multi-Ethnic Study of Atherosclerosis (MESA), creating a 25+ years dataset. Within the MESA parent study, the MESA Neighborhoods and Aging cohort study will characterise dynamic, longitudinal neighbourhood social and built environment variables relevant to cognition for residential addresses of MESA participants. This includes administering new surveys, expanding residential address histories, calculating new measures derived from spatial data and implementing novel deep learning algorithms on street-level imagery. Applying novel statistical techniques, we will examine associations of neighbourhood environmental characteristics with cognition and clinically relevant AD/ADRD outcomes. We will investigate determinants of disparities in outcomes by socioeconomic position and race/ethnicity and assess the contribution of neighbourhood environments to these disparities. This project will provide new evidence about pathways between neighbourhood environments and cognitive outcomes, with implications for policies to support healthy ageing. Ethics and dissemination This project was approved by the University of Washington and Drexel University Institutional Review Boards (protocols #00009029 and #00014523, and #180900605). Data will be distributed through the MESA Coordinating Center. Findings will be disseminated in peer-reviewed scientific journals, briefs, presentations and on the participant website.  © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {EPIDEMIOLOGY; GERIATRIC MEDICINE; SOCIAL MEDICINE; STATISTICS & RESEARCH METHODS},
	keywords = {Aged; Atherosclerosis; Cognition; Cohort Studies; Dementia; Humans; Prospective Studies; Residence Characteristics; amyloid beta protein; aged; Alzheimer disease; Article; body mass; built environment; cardiovascular disease; cognition; cognitive defect; cohort analysis; conceptual framework; controlled study; deep learning; dementia; educational status; ethnicity; female; health disparity; healthy aging; history; human; imagery; information dissemination; institutional review; lowest income group; machine learning; male; mental deterioration; mild cognitive impairment; neighborhood; nuclear magnetic resonance imaging; outcome assessment; prevalence; race; residence characteristics; social determinants of health; social environment; social medicine; T1 weighted imaging; T2 weighted imaging; atherosclerosis; cognition; dementia; demography; prospective study},
	correspondence_address = {J.A. Hirsch; Urban Health Collaborative and Department of Epidemiology and Biostatistics, Drexel University, Philadelphia, United States; email: jah474@drexel.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36368762},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Monson2022,
	author = {Monson, Hayley and Demaine, Jeff and Banfield, Laura and Felfeli, Tina},
	title = {Three-year trends in literature on artificial intelligence in ophthalmology and vision sciences: a protocol for bibliometric analysis},
	year = {2022},
	journal = {BMJ Health and Care Informatics},
	volume = {29},
	number = {1},
	doi = {10.1136/bmjhci-2022-100594},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139339013&doi=10.1136%2fbmjhci-2022-100594&partnerID=40&md5=7e13e4f7db12b602721d1bcee3389dec},
	affiliations = {Department of Mathematics and Statistics, McMaster University, Hamilton, ON, Canada; Library Department, McMaster University, Hamilton, ON, Canada; Department of Ophthalmology and Vision Sciences, University of Toronto, Toronto, ON, Canada; The Institute of Health Policy Management and Evaluation, University of Toronto, Toronto, ON, Canada},
	abstract = {Introduction The aim of this study is to provide an insight into the literature at the intersection of artificial intelligence and ophthalmology. Methods and analysis The project will be performed in four key stages: formulation of search terms, literature collection, literature screening and literature analysis. A comprehensive search of databases including Scopus, Web of Science, Dimensions and Cochrane will be conducted. The Distiller SR software will be used for manual screening all relevant articles. The selected articles will be analysed via R Bibliometrix, a program for mathematical analysis of large sets of literature, and VOSviewer, which creates visual representations of connections between articles. Ethics and dissemination This study did not require research ethics approval given the use of publicly available data and lack of human subjects. The results will be presented at scientific meetings and published in peer-reviewed journals.  © 2022 Authors.},
	author_keywords = {data science; deep learning; informatics; machine learning; medical informatics},
	keywords = {Artificial Intelligence; Bibliometrics; Databases, Factual; Humans; Ophthalmology; adult; article; artificial intelligence; bibliometrics; data science; deep learning; female; human; information science; machine learning; male; mathematical analysis; medical informatics; ophthalmology; research ethics; Scopus; software; systematic review; vision; Web of Science; artificial intelligence; bibliometrics; factual database},
	correspondence_address = {T. Felfeli; Department of Ophthalmology and Vision Sciences, University of Toronto, Toronto, Canada; email: tina.felfeli@mail.utoronto.ca},
	publisher = {BMJ Publishing Group},
	issn = {26321009},
	pmid = {36202424},
	language = {English},
	abbrev_source_title = {BMJ Heal. care inf.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Swann2022,
	author = {Swann, Olivia V and Lone, Nazir I and Harrison, Ewen M and Tomlinson, Laurie A and Walker, Alex J and Seaborne, Michael J and Pollock, Louisa and Farrell, James and Hall, Peter S and Seth, Sohan and Williams, Thomas C and Preston, Jennifer and Ainsworth, J. Samantha and Semple, Freya F and Baillie, J Kenneth and Katikireddi, Srinivasa V and Akbari, Ashley and Lyons, Ronan and Simpson, Colin R and Semple, Malcolm G and Goldacre, Ben and Brophy, Sinead and Sheikh, Aziz and Docherty, Annemarie B},
	title = {Studying the Long-term Impact of COVID-19 in Kids (SLICK). Healthcare use and costs in children and young people following community-acquired SARS-CoV-2 infection: protocol for an observational study using linked primary and secondary routinely collected healthcare data from England, Scotland and Wales},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {11},
	doi = {10.1136/bmjopen-2022-063271},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141580604&doi=10.1136%2fbmjopen-2022-063271&partnerID=40&md5=ef067fcd4e62d4f5a0627683ec1decc5},
	affiliations = {Centre for Medical Informatics, Usher Institute of Population Health Sciences and Informatics, The University of Edinburgh, Edinburgh, United Kingdom; Department of Child Life and Health, The University of Edinburgh, Edinburgh, United Kingdom; Usher Institute of Population Health Sciences and Informatics, The University of Edinburgh, Edinburgh, United Kingdom; Department of Non-Communicable Disease Epidemiology, London School of Hygiene and Tropical Medicine, London, United Kingdom; The DataLab, Nuffield Department of Primary Care Health Sciences, University of Oxford, Oxford, United Kingdom; Centre for Population Health, Swansea University, Swansea, United Kingdom; Department of Child Health, School of Medicine,Dentistry and Nursing, University of Glasgow, Glasgow, United Kingdom; Institute of Cancer and Genetics, The University of Edinburgh, Edinburgh, United Kingdom; School of Informatics, The University of Edinburgh, Edinburgh, United Kingdom; Faculty of Humanities and Social Sciences, University of Liverpool, Liverpool, United Kingdom; School of Medicine Dentistry and Nursing, University of Glasgow, Glasgow, United Kingdom; Division of Genetics and Genomics, Roslin Institute, Edinburgh, United Kingdom; MRC/CSO Social & Public Health Sciences Unit, University of Glasgow, Glasgow, United Kingdom; Swansea University Medical School, Swansea University, Swansea, United Kingdom; School of Health, Faculty of Health, Victoria University of Wellington, Wellington, New Zealand; Nihr Health Protection Research Unit in Emerging and Zoonotic Infections, Liverpool, United Kingdom; Respiratory Paediatrics, Alder Hey Children's Hospital, Liverpool, United Kingdom; Health Data Research, Swansea University Medical School, Swansea, United Kingdom},
	abstract = {Introduction SARS-CoV-2 infection rarely causes hospitalisation in children and young people (CYP), but mild or asymptomatic infections are common. Persistent symptoms following infection have been reported in CYP but subsequent healthcare use is unclear. We aim to describe healthcare use in CYP following community-acquired SARS-CoV-2 infection and identify those at risk of ongoing healthcare needs. Methods and analysis We will use anonymised individual-level, population-scale national data linking demographics, comorbidities, primary and secondary care use and mortality between 1 January 2019 and 1 May 2022. SARS-CoV-2 test data will be linked from 1 January 2020 to 1 May 2022. Analyses will use Trusted Research Environments: OpenSAFELY in England, Secure Anonymised Information Linkage (SAIL) Databank in Wales and Early Pandemic Evaluation and Enhanced Surveillance of COVID-19 in Scotland (EAVE-II). CYP aged ≥4 and <18 years who underwent SARS-CoV-2 reverse transcription PCR (RT-PCR) testing between 1 January 2020 and 1 May 2021 and those untested CYP will be examined. The primary outcome measure is cumulative healthcare cost over 12 months following SARS-CoV-2 testing, stratified into primary or secondary care, and physical or mental healthcare. We will estimate the burden of healthcare use attributable to SARS-CoV-2 infections in the 12 months after testing using a matched cohort study of RT-PCR positive, negative or untested CYP matched on testing date, with adjustment for confounders. We will identify factors associated with higher healthcare needs in the 12 months following SARS-CoV-2 infection using an unmatched cohort of RT-PCR positive CYP. Multivariable logistic regression and machine learning approaches will identify risk factors for high healthcare use and characterise patterns of healthcare use post infection. Ethics and dissemination This study was approved by the South-Central Oxford C Health Research Authority Ethics Committee (13/SC/0149). Findings will be preprinted and published in peer-reviewed journals. Analysis code and code lists will be available through public GitHub repositories and OpenCodelists with meta-data via HDR-UK Innovation Gateway.  © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY. Published by BMJ.},
	author_keywords = {COVID-19; epidemiology; health economics; paediatric infectious disease & immunisation},
	keywords = {Adolescent; Child; Cohort Studies; COVID-19; COVID-19 Testing; Delivery of Health Care; Humans; Observational Studies as Topic; SARS-CoV-2; Wales; anonymised data; Article; child; clinical protocol; cohort analysis; community acquired infection; comorbidity; controlled study; coronavirus disease 2019; COVID-19 testing; England; female; follow up; general practitioner; health care cost; health care need; health care utilization; health data; human; machine learning; male; mental health care; nonhuman; observational study; outcome assessment; pandemic; primary medical care; reverse transcription polymerase chain reaction; risk factor; routinely collected health data; Scotland; secondary health care; sensitivity analysis; Wales; adolescent; epidemiology; health care delivery},
	correspondence_address = {O.V. Swann; Centre for Medical Informatics, Usher Institute of Population Health Sciences and Informatics, The University of Edinburgh, Edinburgh, United Kingdom; email: Olivia.Swann@ed.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {36356998},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Jaillant2022823,
	author = {Jaillant, Lise and Caputo, Annalina},
	title = {Unlocking digital archives: cross-disciplinary perspectives on AI and born-digital data},
	year = {2022},
	journal = {AI and Society},
	volume = {37},
	number = {3},
	pages = {823 – 835},
	doi = {10.1007/s00146-021-01367-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122783375&doi=10.1007%2fs00146-021-01367-x&partnerID=40&md5=322962871d8cb6b13a61eba855c93fa8},
	affiliations = {Loughborough University, Loughborough, United Kingdom; ADAPT Centre, Dublin City University, Dublin, Ireland},
	abstract = {Co-authored by a Computer Scientist and a Digital Humanist, this article examines the challenges faced by cultural heritage institutions in the digital age, which have led to the closure of the vast majority of born-digital archival collections. It focuses particularly on cultural organizations such as libraries, museums and archives, used by historians, literary scholars and other Humanities scholars. Most born-digital records held by cultural organizations are inaccessible due to privacy, copyright, commercial and technical issues. Even when born-digital data are publicly available (as in the case of web archives), users often need to physically travel to repositories such as the British Library or the Bibliothèque Nationale de France to consult web pages. Provided with enough sample data from which to learn and train their models, AI, and more specifically machine learning algorithms, offer the opportunity to improve and ease the access to digital archives by learning to perform complex human tasks. These vary from providing intelligent support for searching the archives to automate tedious and time-consuming tasks. In this article, we focus on sensitivity review as a practical solution to unlock digital archives that would allow archival institutions to make non-sensitive information available. This promise to make archives more accessible does not come free of warnings for potential pitfalls and risks: inherent errors, "black box" approaches that make the algorithm inscrutable, and risks related to bias, fake, or partial information. Our central argument is that AI can deliver its promise to make digital archival collections more accessible, but it also creates new challenges - particularly in terms of ethics. In the conclusion, we insist on the importance of fairness, accountability and transparency in the process of making digital archives more accessible. © 2022, The Author(s).},
	author_keywords = {Artificial Intelligence; Born-digital archives; Copyright; Ethics; Privacy; Sensitivity Review},
	keywords = {Data privacy; Digital libraries; Ethical technology; Learning algorithms; Machine learning; Websites; Born-digital archive; Computer scientists; Cross-disciplinary; Cultural heritages; Digital age; Digital archives; Digital datas; Disciplinary perspective; Privacy; Sensitivity review; Copyrights},
	correspondence_address = {A. Caputo; ADAPT Centre, Dublin City University, Dublin, Ireland; email: annalina.caputo@dcu.ie},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Frost2022,
	author = {Frost, Emma Kellie and Bosward, Rebecca and Aquino, Yves Saint James and Braunack-Mayer, Annette and Carter, Stacy M.},
	title = {Public views on ethical issues in healthcare artificial intelligence: protocol for a scoping review},
	year = {2022},
	journal = {Systematic Reviews},
	volume = {11},
	number = {1},
	doi = {10.1186/s13643-022-02012-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134237891&doi=10.1186%2fs13643-022-02012-4&partnerID=40&md5=8f533abaa00b0ce8a1b273572717bcfc},
	affiliations = {Australian Centre for Health Engagement, Evidence and Values, School of Health and Society, Faculty of the Arts, Social Sciences, and Humanities, University of Wollongong, Northfields Ave, Wollongong, 2522, NSW, Australia},
	abstract = {Background: In recent years, innovations in artificial intelligence (AI) have led to the development of new healthcare AI (HCAI) technologies. Whilst some of these technologies show promise for improving the patient experience, ethicists have warned that AI can introduce and exacerbate harms and wrongs in healthcare. It is important that HCAI reflects the values that are important to people. However, involving patients and publics in research about AI ethics remains challenging due to relatively limited awareness of HCAI technologies. This scoping review aims to map how the existing literature on publics’ views on HCAI addresses key issues in AI ethics and governance. Methods: We developed a search query to conduct a comprehensive search of PubMed, Scopus, Web of Science, CINAHL, and Academic Search Complete from January 2010 onwards. We will include primary research studies which document publics’ or patients’ views on machine learning HCAI technologies. A coding framework has been designed and will be used capture qualitative and quantitative data from the articles. Two reviewers will code a proportion of the included articles and any discrepancies will be discussed amongst the team, with changes made to the coding framework accordingly. Final results will be reported quantitatively and qualitatively, examining how each AI ethics issue has been addressed by the included studies. Discussion: Consulting publics and patients about the ethics of HCAI technologies and innovations can offer important insights to those seeking to implement HCAI ethically and legitimately. This review will explore how ethical issues are addressed in literature examining publics’ and patients’ views on HCAI, with the aim of determining the extent to which publics’ views on HCAI ethics have been addressed in existing research. This has the potential to support the development of implementation processes and regulation for HCAI that incorporates publics’ values and perspectives. © 2022, The Author(s).},
	author_keywords = {AI ethics; Artificial Intelligence; Healthcare AI; Patients; Publics},
	keywords = {Artificial Intelligence; Delivery of Health Care; Health Facilities; Humans; Machine Learning; Review Literature as Topic; adult; artificial intelligence; awareness; Cinahl; ethics; female; human; machine learning; male; Medline; review; Scopus; systematic review; Web of Science; health care delivery; health care facility; literature},
	correspondence_address = {E.K. Frost; Australian Centre for Health Engagement, Evidence and Values, School of Health and Society, Faculty of the Arts, Social Sciences, and Humanities, University of Wollongong, Wollongong, Northfields Ave, 2522, Australia; email: emmaf@uow.edu.au},
	publisher = {BioMed Central Ltd},
	issn = {20464053},
	pmid = {35841073},
	language = {English},
	abbrev_source_title = {Syst. Rev.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Wu20221711,
	author = {Wu, Xiaolong and Wang, Weiwei and Li, Qiyuan and Peng, Zhihai and Zhu, Jianping},
	title = {Current Situation With Organ Donation and Transplantation in China: Application of Machine Learning},
	year = {2022},
	journal = {Transplantation Proceedings},
	volume = {54},
	number = {7},
	pages = {1711 – 1723},
	doi = {10.1016/j.transproceed.2022.03.067},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135503490&doi=10.1016%2fj.transproceed.2022.03.067&partnerID=40&md5=dc71de9465c9880a44c9ffd8b1a312a9},
	affiliations = {School of Medicine, Xiamen University, Xiamen, China; National Institute for Data Science in Health and Medicine, Xiamen University, Xiamen, China; Data Mining Research Center, Xiamen University, Xiamen, China; School of Management, Xiamen University, Xiamen, China; Xiang'an Hospital of Xiamen University, Xiamen, China},
	abstract = {Background: China ranks currently as one of the top countries for organ transplantation according to types, capacity, related research, quality, and quantity of procedures. However, the management systems struggle to support these practices. This study aims to review the current situation with organ donation and transplantation in China recently. Methods: Data about organ donation and transplantation was collected by using web crawler technology from several news sections of representative portal websites in China. A total of 3475 documents about organ donation and transplantation were analyzed after data preprocessing. The documents were analyzed using machine learning to find out the relationship among the hot topics and their social popularity as well as to explore the dominant subtopics of the hot topics. Results: The results of weighted correlation network analysis and documents clustering analysis identified 9 topics about organ donation and transplantation in China with a wide discussion: transplantation ethics, donor compensation, use of the remains, transportation guarantee of living organs, organ allocation, relevant national standards of organ donation and transplantation, legislation on organ donation, penalties for violation, and the Red Cross Society of China. Conclusions: This study found out the main problems and proposed them for future discussion with organ donation and transplantation system in China: the lack of publicity and education and the difficulty of standardizing legislation about ethical issues arousing ethical problems; the need to understand the relationship and the standardization among costs, expenses, and compensation; and the lack of more support from the government and public to ensure regular organ donation and transplantation. © 2022 Elsevier Inc.},
	keywords = {China; Humans; Machine Learning; Organ Transplantation; Tissue and Organ Procurement; Tissue Donors; adult; article; China; compensation; controlled study; education; ethics; female; government; human; human experiment; human tissue; law; machine learning; male; mass medium; organ donor; punishment; Red Cross; standardization; transplantation; weighted gene co expression network analysis; China; donor; machine learning; organ transplantation},
	correspondence_address = {J. Zhu; Professor of Xiamen University, Room 110, Baoxin Liying Bldg, School of Management, Xiamen University, Xiamen City, 422 Siming South Rd; email: jpzhuxmu@163.com},
	publisher = {Elsevier Inc.},
	issn = {00411345},
	coden = {TRPPA},
	pmid = {35934536},
	language = {English},
	abbrev_source_title = {Transplant. Proc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yang20225179,
	author = {Yang, Carl and Li, Xiaoxiao and Baracaldo, Nathalie and Shah, Neil and He, Chaoyang and Lyu, Lingjuan and Sun, Lichao and Avestimehr, Salman},
	title = {The 1st International Workshop on Federated Learning with Graph Data (FedGraph)},
	year = {2022},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5179 – 5180},
	doi = {10.1145/3511808.3557495},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140932443&doi=10.1145%2f3511808.3557495&partnerID=40&md5=d560a37b60578b51fefdc7fd0f2ecb77},
	affiliations = {Emory University, Atlanta, GA, United States; University of British Columbia, Vancouver, BC, Canada; Ibm Research, San Jose, CA, United States; Snap Research, Seattle, WA, United States; FedML Inc, Los Angeles, CA, United States; Sony Ai, Tokyo, Japan; Lehigh University, Bethlehem, PA, United States; University of Southern California, Los Angeles, CA, United States},
	abstract = {The field of graph data mining, one of the most important AI research areas, has been revolutionized by graph neural networks (GNNs), which benefit from training on real-world graph data with millions to billions of nodes and links. Unfortunately, the training data and process of GNNs involving graphs beyond millions of nodes are extremely costly on a centralized server, if not impossible. Moreover, due to the increasing concerns about data privacy, emerging data from realistic applications are naturally fragmented, forming distributed private graphs of multiple "data silos", among which direct transferring of data is forbidden. The nascent field of federated learning (FL), which aims to enable individual clients to jointly train their models while keeping their local data decentralized and completely private, is a promising paradigm for large-scale distributed and private training of GNNs. øurs aims to bring together researchers from different backgrounds with a common interest in how to extend current FL algorithms to operate with graph data models such as GNNs. FL is an extremely hot topic of large commercial interest and has been intensively explored for machine learning with visual and textual data. The exploration from graph mining researchers and industrial practitioners is timely catching up just recently. There are many unexplored challenges and opportunities, which urges the establishment of an organized and open community to collaboratively advance the science behind it. The prospective participants of this workshop will include researchers and practitioners from both graph mining and federated learning communities, whose interests include, but are not limited to: graph analysis and mining, heterogeneous network modeling, complex data mining, large-scale machine learning, distributed systems, optimization, meta-learning, reinforcement learning, privacy, robustness, explainability, fairness, ethics, and trustworthiness. © 2022 Owner/Author.},
	author_keywords = {data privacy; distributed learning; federated learning; graph mining; graph neural networks},
	keywords = {Data mining; Graph neural networks; Graph theory; Heterogeneous networks; Network security; Reinforcement learning; Distributed learning; Federated learning; Graph data; Graph mining; Graph neural networks; International workshops; Nodes and links; Real-world graphs; Research areas; Training process; Data privacy},
	correspondence_address = {C. Yang; Emory University, Atlanta, United States; email: j.carlyang@emory.edu},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039236-5},
	language = {English},
	abbrev_source_title = {Int Conf Inf Knowledge Manage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 31st ACM International Conference on Information and Knowledge Management, CIKM 2022; Conference date: 17 October 2022 through 21 October 2022; Conference code: 183495}
}

@ARTICLE{Wilson2022897,
	author = {Wilson, Diane U. and Bailey, Michael Q and Craig, John},
	title = {The role of artificial intelligence in clinical imaging and workflows},
	year = {2022},
	journal = {Veterinary Radiology and Ultrasound},
	volume = {63},
	number = {S1},
	pages = {897 – 902},
	doi = {10.1111/vru.13157},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144096367&doi=10.1111%2fvru.13157&partnerID=40&md5=a066fa656019afdc7e27c4e4ac5716d9},
	affiliations = {Antech Imaging Services, Fountain Valley, CA, United States; IDEXX Telemedicine Consultants, Westbrook, ME, United States; EponaTech LLC, dba MetronMind, Paso Robles, CA, United States},
	abstract = {Evidence-based medicine, outcomes management, and multidisciplinary systems are laying the foundation for radiology on the cusp of a new day. Environmental and operational forces coupled with technological advancements are redefining the veterinary radiologist of tomorrow. In the past several years, veterinary image volumes have exploded, and the scale of hardware and software required to support it seems boundless. The most dynamic trend within veterinary radiology is implementing digital information systems such as PACS, RIS, PIMS, and Voice Recognition systems. While the digitization of radiography imaging has significantly improved the workflow of the veterinary radiology assistant and radiologist, tedious, redundant tasks are abundant and mind-numbing. They can lead to errors with a significant impact on patient care. Today, these boring and repetitious tasks continue to bog down patient throughput and workflow. Artificial intelligence, particularly machine learning, shows much promise to rocket the workflow and veterinary clinical imaging into a new day where the AI management of mundane tasks allows for efficiency so the radiologist can better concentrate on the quality of patient care. In this article, we briefly discuss the major subsets of artificial intelligence (AI) workflow for the radiologist and veterinary radiology assistant including image acquisition, segmentation and mensuration, rotation and hanging protocol, detection and prioritization, monitoring and registration of lesions, implementation of these subsets, and the ethics of utilizing AI in veterinary medicine. © 2022 American College of Veterinary Radiology.},
	author_keywords = {automated positioning; hanging protocol; NLP; triage; VHS},
	keywords = {Animals; Artificial Intelligence; Humans; Radiologists; Radiology; Software; Workflow; artificial intelligence; computer assisted tomography; image analysis; image quality; machine learning; mitral valve disease; nonhuman; Note; quality control; quality of life; radiography; rotation; sensitivity and specificity; syndrome delineation; veterinary radiology; workflow; animal; human; radiologist; radiology; software; workflow},
	correspondence_address = {D.U. Wilson; Antech Imaging Services, Fountain Valley, 16720 Mt. Herrmann St., 92708, United States; email: Diane.Wilson@antechimagingservices.com},
	publisher = {John Wiley and Sons Inc},
	issn = {10588183},
	pmid = {36514227},
	language = {English},
	abbrev_source_title = {Vet. Radiol. Ultrasound},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Maruejols2022,
	author = {Maruejols, Lucie and Höschle, Lisa and Yu, Xiaohua},
	title = {Vietnam between economic growth and ethnic divergence: A LASSO examination of income-mediated energy consumption},
	year = {2022},
	journal = {Energy Economics},
	volume = {114},
	doi = {10.1016/j.eneco.2022.106222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136539528&doi=10.1016%2fj.eneco.2022.106222&partnerID=40&md5=6a92ca04d82b0cf7e228c485ccfbe07f},
	affiliations = {Department of Agricultural Economics and Rural Development, University of Göttingen, Platz der Göttinger Sieben 5, Göttingen, 37073, Germany},
	abstract = {Ethnic divergence in energy consumption is a phenomenon that threatens the potential gain in welfare that developing countries can achieve with strong economic growth and rise in income. However, the underlying mechanism preventing ethnic groups from accomplishing a successful transition to modern fuels is not yet well-understood, requiring an in-depth analysis of interaction effects between ethnicity and rise in income. The case of highly ethnically-diverse Vietnam offers an opportunity to examine the role of race on energy transition at the stage when grid electricity is available and income begins to rise. A methodological framework exposes the direct effect of ethnicity as well as the indirect, income-related effect of ethnicity on the ability of rural households to increase their electricity consumption. Using data from Vietnam's 2010 Household Living Standards Survey, feature selection is conducted with a machine learning technique, the least absolute shrinkage and selection operator (LASSO), which allows building robust models in the context of high-dimensionality. Furthermore, a mediation analysis complemented with a non-parametric bootstrap approach shows that income acts as a full mediator of ethnicity with respect to electricity consumption and as partial mediator for electricity expenditure. The results thus reveal a positive interaction effect between income and ethnicity, indicating different effects of rising incomes for Kinh and non-Kinh households, where Kinh are more likely than non-Kinh to translate extra income in higher electricity usage. Our results highlight the immanent need to identify and address non-income barriers that create ethnic disparities in the ability of poor, rural households to increase electricity use. © 2022 Elsevier B.V.},
	author_keywords = {Economic development; Electricity consumption; Ethic divide; Income growth; Mediation effect; Vietnam},
	keywords = {Viet Nam; Economic analysis; Economic and social effects; Electric power utilization; Learning systems; Economic development; Economic growths; Electricity-consumption; Energy-consumption; Ethic divide; Income growth; Interaction effect; Least absolute shrinkage and selection operators; Mediation effect; Viet Nam; developing world; economic growth; energy use; ethnic group; ethnicity; income; Developing countries},
	correspondence_address = {X. Yu; Department of Agricultural Economics and Rural Development, University of Göttingen, Göttingen, Platz der Göttinger Sieben 5, 37073, Germany; email: xyu@gwdg.de},
	publisher = {Elsevier B.V.},
	issn = {01409883},
	coden = {EECOD},
	language = {English},
	abbrev_source_title = {Energy Econ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}@ARTICLE{Mullainathan2022897,
	author = {Mullainathan, Sendhil and Obermeyer, Ziad},
	title = {Solving medicine’s data bottleneck: Nightingale Open Science},
	year = {2022},
	journal = {Nature Medicine},
	volume = {28},
	number = {5},
	pages = {897 – 899},
	doi = {10.1038/s41591-022-01804-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129745012&doi=10.1038%2fs41591-022-01804-4&partnerID=40&md5=dfff9f69ce61927d7e0562d41ec560de},
	affiliations = {Booth School of Business, University of Chicago, Chicago, IL, United States; School of Public Health, University of California, Berkeley, Berkeley, CA, United States},
	keywords = {Medicine; Science; anonymised data; cloud computing; diagnostic imaging; ethics; information processing; legal aspect; machine learning; nightingale open science; Note; open access publishing; medicine; science},
	correspondence_address = {Z. Obermeyer; School of Public Health, University of California, Berkeley, Berkeley, United States; email: zobermeyer@berkeley.edu},
	publisher = {Nature Research},
	issn = {10788956},
	coden = {NAMEF},
	pmid = {35534570},
	language = {English},
	abbrev_source_title = {Nat. Med.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Moulin2022,
	author = {Moulin, Jordão Cabral and Lopes, Dercilio Junior Verly and Mulin, Lucas Braga and Bobadilha, Gabrielly Dos Santos and Oliveira, Ramon Ferreira},
	title = {Microscopic identification of brazilian commercial wood species via machine-learning},
	year = {2022},
	journal = {Cerne},
	volume = {28},
	number = {1},
	doi = {10.1590/01047760202228012978},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135525944&doi=10.1590%2f01047760202228012978&partnerID=40&md5=8f3be448ad214cb0c78205ae44c162fc},
	affiliations = {Department of Sustainable Bioproducts/Forest and Wildlife Research Center (FWRC), Mississippi State University, United States; Department of Wood and Forest Sciences, Federal University of Espírito Santo, Jerônimo Monteiro, Brazil},
	abstract = {Background: Multiple challenges are faced by industry and certification agencies when commercializing tropical species. Anatomical similarities of tropical hardwoods impair identification. Deep learning models can facilitate microscopic identification of wood by using sophisticated techniques such as deep convolutional networks (DCNN). Our objective was to microscopically identify 23 commercially available Brazilian wood species using a custom DCNN model. Results: Photographs from microscopic slides of each wood species were processed, and the final data set contained 2,448 images. We applied stratified k-fold cross-validation technique during training to increase model’s robustness and trustworthiness. Thus, the dataset was divided into approximately 80% training (1,958 images) and 20% validation (490 images) for each fold. A series of augmentations were performed only on training data to include variations in rotation, zoom, and perspective. Image augmentation was performed on-the-fly. The network consisted of convolutions, max pooling, global average pooling, and fully connected layers. We tested the performance of the DCNN against accuracy, precision, recall, and F1-score on the validation set for each fold. Conclusion: The custom machine learned model accuracy was higher than 0.90. The model’s worst performance was identified in distinguishing between Toona ciliata and Khaya ivorensis, which was due more to wood variability than to a machine learning deficiency. Future studies should focus on integration, verification/monitoring, and updating of current models for end user manipulation, trust, ethics, and security. © 2022, Federal University of Lavras. All rights reserved.},
	author_keywords = {convolutional neural networks (CNN); deep learning; tropical species; wood anatomy; wood identification},
	keywords = {accuracy assessment; anatomy; artificial neural network; certification; data set; identification method; model validation; performance assessment; photography; training; wood},
	correspondence_address = {D.J.V. Lopes; Department of Sustainable Bioproducts/Forest and Wildlife Research Center (FWRC), Mississippi State University, United States; email: dvl23@msstate.edu},
	publisher = {Federal University of Lavras},
	issn = {01047760},
	language = {English},
	abbrev_source_title = {Cerne},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Gray2022,
	author = {Gray, Kathleen and Slavotinek, John and Dimaguila, Gerardo Luis and Choo, Dawn},
	title = {Artificial Intelligence Education for the Health Workforce: Expert Survey of Approaches and Needs},
	year = {2022},
	journal = {JMIR Medical Education},
	volume = {8},
	number = {2},
	doi = {10.2196/35223},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128474662&doi=10.2196%2f35223&partnerID=40&md5=ef18c87d1f80ad47bf4aecdf867ae605},
	affiliations = {Centre for Digital Transformation of Health, University of Melbourne, Parkville, Australia; South Australia Medical Imaging, Flinders Medical Centre, Bedford Park, Australia; College of Medicine and Public Health, Flinders University, Adelaide, Australia; Murdoch Children's Research Institute, Royal Children's Hospital, Parkville, Australia},
	abstract = {Background: The preparation of the current and future health workforce for the possibility of using artificial intelligence (AI) in health care is a growing concern as AI applications emerge in various care settings and specializations. At present, there is no obvious consensus among educators about what needs to be learned or how this learning may be supported or assessed. Objective: Our study aims to explore health care education experts' ideas and plans for preparing the health workforce to work with AI and identify critical gaps in curriculum and educational resources across a national health care system. Methods: A survey canvassed expert views on AI education for the health workforce in terms of educational strategies, subject matter priorities, meaningful learning activities, desired attitudes, and skills. A total of 39 senior people from different health workforce subgroups across Australia provided ratings and free-text responses in late 2020. Results: The responses highlighted the importance of education on ethical implications, suitability of large data sets for use in AI clinical applications, principles of machine learning, and specific diagnosis and treatment applications of AI as well as alterations to cognitive load during clinical work and the interaction between humans and machines in clinical settings. Respondents also outlined barriers to implementation, such as lack of governance structures and processes, resource constraints, and cultural adjustment. Conclusions: Further work around the world of the kind reported in this survey can assist educators and education authorities who are responsible for preparing the health workforce to minimize the risks and realize the benefits of implementing AI in health care. © 2022 JMIR Publications Inc.. All right reserved.},
	author_keywords = {artificial intelligence; curriculum; ethics; human-computer interaction; interprofessional education; machine learning; natural language processing; professional development; robotics},
	correspondence_address = {K. Gray; Centre for Digital Transformation of Health, University of Melbourne, Level 13, Parkville, 305 Grattan St, 3010, Australia; email: kgray@unimelb.edu.au},
	publisher = {JMIR Publications Inc.},
	issn = {23693762},
	language = {English},
	abbrev_source_title = {JMIR Med. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gundersen2022,
	author = {Gundersen, Torbjørn and Bærøe, Kristine},
	title = {The Future Ethics of Artificial Intelligence in Medicine: Making Sense of Collaborative Models},
	year = {2022},
	journal = {Science and Engineering Ethics},
	volume = {28},
	number = {2},
	doi = {10.1007/s11948-022-00369-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127426130&doi=10.1007%2fs11948-022-00369-2&partnerID=40&md5=6a37fc7074570d000d4da5f379ffea22},
	affiliations = {Centre for the Study of Professions, Oslo Metropolitan University, Oslo, Norway; Department of Global Public Health and Primary Care, University of Bergen, Bergen, Norway},
	abstract = {This article examines the role of medical doctors, AI designers, and other stakeholders in making applied AI and machine learning ethically acceptable on the general premises of shared decision-making in medicine. Recent policy documents such as the EU strategy on trustworthy AI and the research literature have often suggested that AI could be made ethically acceptable by increased collaboration between developers and other stakeholders. The article articulates and examines four central alternative models of how AI can be designed and applied in patient care, which we call the ordinary evidence model, the ethical design model, the collaborative model, and the public deliberation model. We argue that the collaborative model is the most promising for covering most AI technology, while the public deliberation model is called for when the technology is recognized as fundamentally transforming the conditions for ethical shared decision-making. © 2022, The Author(s).},
	author_keywords = {Artificial intelligence; Collaboration; Deliberation; Ethical design; Machine learning; Medical ethics; Professional responsibility},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Morals; artificial intelligence; human; machine learning; morality},
	correspondence_address = {T. Gundersen; Centre for the Study of Professions, Oslo Metropolitan University, Oslo, Norway; email: Torbjorn.Gundersen@oslomet.no},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13533452},
	pmid = {35362822},
	language = {English},
	abbrev_source_title = {Sci. Eng. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Rousi2022,
	author = {Rousi, Rebekah},
	title = {With Clear Intention—An Ethical Responsibility Model for Robot Governance},
	year = {2022},
	journal = {Frontiers in Computer Science},
	volume = {4},
	doi = {10.3389/fcomp.2022.852528},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128553852&doi=10.3389%2ffcomp.2022.852528&partnerID=40&md5=030aebe7556640fef4dbc75a5b6f3231},
	affiliations = {School of Marketing and Communication, University of Vaasa, Vaasa, Finland},
	abstract = {There is much discussion about super artificial intelligence (AI) and autonomous machine learning (ML) systems, or learning machines (LM). Yet, the reality of thinking robotics still seems far on the horizon. It is one thing to define AI in light of human intelligence, citing the remoteness between ML and human intelligence, but another to understand issues of ethics, responsibility, and accountability in relation to the behavior of autonomous robotic systems within a human society. Due to the apparent gap between a society in which autonomous robots are a reality and present-day reality, many of the efforts placed on establishing robotic governance, and indeed, robot law fall outside the fields of valid scientific research. Work within this area has concentrated on manifestos, special interest groups and popular culture. This article takes a cognitive scientific perspective toward characterizing the nature of what true LMs would entail—i.e., intentionality and consciousness. It then proposes the Ethical Responsibility Model for Robot Governance (ER-RoboGov) as an initial platform or first iteration of a model for robot governance that takes the standpoint of LMs being conscious entities. The article utilizes past AI governance model research to map out the key factors of governance from the perspective of autonomous machine learning systems. Copyright © 2022 Rousi.},
	author_keywords = {AI; ethics; framework; governance; intentionality; machine learning; robots},
	correspondence_address = {R. Rousi; School of Marketing and Communication, University of Vaasa, Vaasa, Finland; email: rebekah.rousi@uwasa.fi},
	publisher = {Frontiers Media S.A.},
	issn = {26249898},
	language = {English},
	abbrev_source_title = {Frontier. Comput. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Thylstrup2022655,
	author = {Thylstrup, Nanna Bonde},
	title = {The ethics and politics of data sets in the age of machine learning: deleting traces and encountering remains},
	year = {2022},
	journal = {Media, Culture and Society},
	volume = {44},
	number = {4},
	pages = {655 – 671},
	doi = {10.1177/01634437211060226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129519470&doi=10.1177%2f01634437211060226&partnerID=40&md5=4d4cf844e378333fc2b279cd79646c80},
	affiliations = {Copenhagen Business School, Denmark},
	abstract = {Individuals and communities increasingly depend on, and fill their lives with, machine cultures, in the form of both interfaces and infrastructures. This global push for machine cultures has given rise to an increasing demand for data and engendered a proliferation of public, private and public-private dataset repositories. While datasets form a foundational element of machine cultures, they rarely come into focus as objects of critical study. But in recent years a critical discursive formation on datasets has begun to emerge, which disturbs the idea of datasets as operational instruments of digital knowledge production and seek to instead ‘bring people back in’. The present article identifies these preliminary explorations as ‘critical dataset studies’ and draws on critical archival studies to articulate the ethico-political surfaced by these studies. Specifically it argues that critical dataset studies shows the need for an expanded ethical and conceptual approach to datasets that not only relies on linear notions of deletion and accountability but also on iterative frameworks of remains and response-ability. © The Author(s) 2022.},
	author_keywords = {access; archive; consent; data set; deletion; ethics; infrastructure; machine learning; power; trace},
	correspondence_address = {N.B. Thylstrup; Copenhagen Business School, Denmark; email: nbt.msc@cbs.dk},
	publisher = {SAGE Publications Ltd},
	issn = {01634437},
	language = {English},
	abbrev_source_title = {Media Cult. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Boyd20222069,
	author = {Boyd, Karen},
	title = {Designing Up with Value-Sensitive Design: Building a Field Guide for Ethical ML Development},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {2069 – 2082},
	doi = {10.1145/3531146.3534626},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133017828&doi=10.1145%2f3531146.3534626&partnerID=40&md5=f8e414f02dabdf44d25b03072843fd3c},
	affiliations = {San Diego Workforce Partnership, San Diego, CA, United States},
	abstract = {If "studying up, "or researching powerful actors in a social system, can offer insight into the workings and effects of power in social systems, this paper argues that "designing up"will give researchers and designers a tool to intervene. This paper offers a conception of "designing up, "applies the structure of Value Sensitive Design (VSD) to accomplish it, and submits an example of a tool designed to support ethical sensitivity, especially particularization and judgment. The designed artifact is a field guide for ethical mitigation strategies that uses tool profiles and filters to aid machine learning (ML) engineers as they build understanding of an ethical issue they have recognized and as they match the particulars of their problem to a technical ethical mitigation. This guide may broaden its users' awareness of potential ethical issues, important features of ethical issues and their mitigations, and the breadth of available mitigations. Additionally, it may encourage ethical sensitivity in future ML projects. Feedback from ML engineers and technology ethics researchers rendered several usability improvements and ideas for future development. The tool can be found at: https://ml-ethics-tool.web.app/. © 2022 ACM.},
	author_keywords = {AI ethics; datasets; development practices; ethical sensitivity; ethics; machine learning},
	keywords = {Ethical technology; Machine learning; AI ethic; Dataset; Development practices; Ethical issues; Ethical sensitivity; Machine-learning; Mitigation strategy; Power; Social systems; Value sensitive design; HTTP},
	correspondence_address = {K. Boyd; San Diego Workforce Partnership, San Diego, United States; email: karenlboyd@gmail.com},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210}
}

@ARTICLE{Doya2022542,
	author = {Doya, Kenji and Ema, Arisa and Kitano, Hiroaki and Sakagami, Masamichi and Russell, Stuart},
	title = {Social impact and governance of AI and neurotechnologies},
	year = {2022},
	journal = {Neural Networks},
	volume = {152},
	pages = {542 – 554},
	doi = {10.1016/j.neunet.2022.05.012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131420039&doi=10.1016%2fj.neunet.2022.05.012&partnerID=40&md5=f25aabc8a7466aeded27db0c7807d581},
	affiliations = {Neural Computation Unit, Okinawa Institute of Science and Technology Graduate University, 1919-1 Tancha, Onna Village, Okinawa, 904-0495, Japan; Institute for Future Initiatives, The University of Tokyo, 7-3-1 Hongo, Bunkyo-ku, 113-0033, Tokyo, Japan; Sony Computer Science Laboratories, Inc. 3-14-13, Higashigotanda, Shinagawa-ku, 141-0022, Tokyo, Japan; Brain Science Research Center, Tamagawa University, 6-1-1 Tamagawa Gakuen, Machida City, 194-8610, Tokyo, Japan; Computer Science Division, University of California Berkeley, 94720-1776, CA, United States},
	abstract = {Advances in artificial intelligence (AI) and brain science are going to have a huge impact on society. While technologies based on those advances can provide enormous social benefits, adoption of new technologies poses various risks. This article first reviews the co-evolution of AI and brain science and the benefits of brain-inspired AI in sustainability, healthcare, and scientific discoveries. We then consider possible risks from those technologies, including intentional abuse, autonomous weapons, cognitive enhancement by brain–computer interfaces, insidious effects of social media, inequity, and enfeeblement. We also discuss practical ways to bring ethical principles into practice. One proposal is to stop giving explicit goals to AI agents and to enable them to keep learning human preferences. Another is to learn from democratic mechanisms that evolved in human society to avoid over-consolidation of power. Finally, we emphasize the importance of open discussions not only by experts, but also including a diverse array of lay opinions. © 2022 The Author(s)},
	author_keywords = {AI scientist; Artificial intelligence; Ethics; Governance; Human compatible AI; Neurotechnology},
	keywords = {Artificial Intelligence; Humans; Social Change; Social Media; Economic and social effects; Ethical technology; Artificial intelligence scientist; Brain science; Co-evolution; Governance; Human compatible artificial intelligence; Intelligence science; Neurotechnology; Social benefits; Social impact; Technology-based; abuse; algorithm; amygdala; amyotrophic lateral sclerosis; antitrust law; Article; artificial intelligence; climate change; clinical decision making; cognition; computer assisted tomography; coronavirus disease 2019; data analysis; decision making; deep learning; electric conductivity; ethics; expert system; gene mutation; genomics; health care; human; induced pluripotent stem cell; learning; machine learning; mental disease; neuroscience; neurotechnology; nuclear magnetic resonance imaging; pandemic; pollution; prediction; protein structure; reinforcement (psychology); risk; safety; social inequality; social media; spinal cord injury; technology; visual pattern recognition; X ray; social change; social media; Artificial intelligence},
	correspondence_address = {K. Doya; Neural Computation Unit, Okinawa Institute of Science and Technology Graduate University, Okinawa, 1919-1 Tancha, Onna Village, 904-0495, Japan; email: doya@oist.jp},
	publisher = {Elsevier Ltd},
	issn = {08936080},
	coden = {NNETE},
	pmid = {35671575},
	language = {English},
	abbrev_source_title = {Neural Netw.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Xu2022,
	author = {Xu, Jie and Guo, Yi and Wang, Fei and Xu, Hua and Lucero, Robert and Bian, Jiang and Prosperi, Mattia},
	title = {Protocol for the development of a reporting guideline for causal and counterfactual prediction models in biomedicine},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {6},
	doi = {10.1136/bmjopen-2021-059715},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132267570&doi=10.1136%2fbmjopen-2021-059715&partnerID=40&md5=5ffccc54c237e498f8668dd8415f7fd5},
	affiliations = {Department of Health Outcomes and Biomedical Informatics, University of Florida, Gainesville, FL, United States; Department of Population Health Sciences, Weill Cornell Medical College, Cornell University, New York City, NY, United States; School of Biomedical Informatics, University of Texas Health Science at Houston, Houston, TX, United States; School of Nursing, University of California - Los Angeles, Los Angeles, CA, United States; Department of Epidemiology, University of Florida, Gainesville, FL, United States},
	abstract = {Introduction While there are guidelines for reporting on observational studies (eg, Strengthening the Reporting of Observational Studies in Epidemiology, Reporting of Studies Conducted Using Observational Routinely Collected Health Data Statement), estimation of causal effects from both observational data and randomised experiments (eg, A Guideline for Reporting Mediation Analyses of Randomised Trials and Observational Studies, Consolidated Standards of Reporting Trials, PATH) and on prediction modelling (eg, Transparent Reporting of a multivariable prediction model for Individual Prognosis or Diagnosis), none is purposely made for deriving and validating models from observational data to predict counterfactuals for individuals on one or more possible interventions, on the basis of given (or inferred) causal structures. This paper describes methods and processes that will be used to develop a Reporting Guideline for Causal and Counterfactual Prediction Models (PRECOG). Methods and analysis PRECOG will be developed following published guidance from the Enhancing the Quality and Transparency of Health Research (EQUATOR) network and will comprise five stages. Stage 1 will be meetings of a working group every other week with rotating external advisors (active until stage 5). Stage 2 will comprise a systematic review of literature on counterfactual prediction modelling for biomedical sciences (registered in Prospective Register of Systematic Reviews). In stage 3, a computer-based, real-time Delphi survey will be performed to consolidate the PRECOG checklist, involving experts in causal inference, epidemiology, statistics, machine learning, informatics and protocols/standards. Stage 4 will involve the write-up of the PRECOG guideline based on the results from the prior stages. Stage 5 will seek the peer-reviewed publication of the guideline, the scoping/systematic review and dissemination. Ethics and dissemination The study will follow the principles of the Declaration of Helsinki. The study has been registered in EQUATOR and approved by the University of Florida's Institutional Review Board (#202200495). Informed consent will be obtained from the working groups and the Delphi survey participants. The dissemination of PRECOG and its products will be done through journal publications, conferences, websites and social media. © 2022 BMJ Publishing Group. All rights reserved.},
	author_keywords = {Health informatics; Information technology; Protocols & guidelines},
	keywords = {Causality; Checklist; Humans; Research Design; Systematic Reviews as Topic; Article; biomedicine; causal model; Delphi study; information dissemination; literature; medical research; methodology; predictive model; publication; reporting guideline for causal and counterfactual prediction model; causality; checklist; human},
	correspondence_address = {M. Prosperi; Department of Epidemiology, University of Florida, Gainesville, United States; email: m.prosperi@ufl.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35725267},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Adamson2022905,
	author = {Adamson, Peter C.},
	title = {My Patient Portal},
	year = {2022},
	journal = {Annals of Internal Medicine},
	volume = {175},
	number = {6},
	pages = {905},
	doi = {10.7326/M22-0544},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132741368&doi=10.7326%2fM22-0544&partnerID=40&md5=1f2263a9724531feee3d9993ac92f250},
	affiliations = {Perelman School of Medicine, University of Pennsylvania, Philadelphia, Pennsylvania, and Sanofi, Cambridge, MA, United States},
	keywords = {Humans; Patient Portals; Portal Vein; access to information; artificial intelligence; colonoscopy; colorectal liver metastasis; electronic health record; general practitioner; health care system; human; interdisciplinary communication; internist; laboratory test; machine learning; medical documentation; medical ethics; medical practice; metastatic colorectal cancer; narrative medicine; Note; patient information; pediatric oncologist; personalized medicine; physical examination; text messaging; hepatic portal vein; medical record},
	correspondence_address = {P.C. Adamson; Sanofi, Cambridge, 450 Water Street, 02142, United States; email: peter.adamson@sanofi.com},
	publisher = {American College of Physicians},
	issn = {00034819},
	coden = {AIMEA},
	pmid = {35793491},
	language = {English},
	abbrev_source_title = {Ann. Intern. Med.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Biddle2022321,
	author = {Biddle, Justin B.},
	title = {On Predicting Recidivism: Epistemic Risk, Tradeoffs, and Values in Machine Learning},
	year = {2022},
	journal = {Canadian Journal of Philosophy},
	volume = {52},
	number = {3},
	pages = {321 – 341},
	doi = {10.1017/can.2020.27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141267089&doi=10.1017%2fcan.2020.27&partnerID=40&md5=9a6f461e89681a32cb8489f502a1b7d2},
	affiliations = {School of Public Policy, Georgia Institute of Technology, Atlanta, GA, United States},
	abstract = {Recent scholarship in philosophy of science and technology has shown that scientific and technological decision making are laden with values, including values of a social, political, and/or ethical character. This paper examines the role of value judgments in the design of machine-learning (ML) systems generally and in recidivism-prediction algorithms specifically. Drawing on work on inductive and epistemic risk, the paper argues that ML systems are value laden in ways similar to human decision making, because the development and design of ML systems requires human decisions that involve tradeoffs that reflect values. In many cases, these decisions have significant - and, in some cases, disparate - downstream impacts on human lives. After examining an influential court decision regarding the use of proprietary recidivism-prediction algorithms in criminal sentencing, Wisconsin v. Loomis, the paper provides three recommendations for the use of ML in penal systems.  © },
	author_keywords = {artificial intelligence; equality; ethics; fairness; justice; race; Values in science and technology},
	correspondence_address = {J.B. Biddle; School of Public Policy, Georgia Institute of Technology, Atlanta, United States; email: justin.biddle@pubpolicy.gatech.edu},
	publisher = {Cambridge University Press},
	issn = {00455091},
	language = {English},
	abbrev_source_title = {Can. J. Philos.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Madan2022903,
	author = {Madan, Rohit},
	title = {Artificial Intelligence Diffusion in Public Administration},
	year = {2022},
	journal = {AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {903},
	doi = {10.1145/3514094.3539529},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137163770&doi=10.1145%2f3514094.3539529&partnerID=40&md5=6c5bd77dccb853cc5de8ee23f9ab2198},
	affiliations = {University of Reading, Reading, United Kingdom},
	abstract = {The use of Artificial Intelligence (AI) in public administration has immense benefits but also embodies ethical dilemmas of fairness, transparency, privacy, and human rights. Several frameworks have been developed by governments and technology companies to guide the ethical development of AI solutions. However, within public administration implementations, there is a lack of clarity on how decisions on these dilemmas are made and what is the effect of such decisions on public values. This research aims to undertake a mixed-method study exploring the mechanisms and causal links between AI tensions and public value creation.  © 2022 Owner/Author.},
	author_keywords = {AI ethics; algorithmic governance; machine learning; public value},
	keywords = {Ethical technology; Machine learning; Algorithmic governance; Algorithmics; Artificial intelligence ethic; Ethical dilemma; Government companies; Human rights; Machine-learning; Privacy rights; Public values; Technology companies; Public administration},
	correspondence_address = {R. Madan; University of Reading, Reading, United Kingdom; email: r.madan@pgr.reading.ac.uk},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039247-1},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2022; Conference date: 1 August 2022 through 3 August 2022; Conference code: 181805}
}

@CONFERENCE{Fishman20221516,
	author = {Fishman, Nic and Hancox-Li, Leif},
	title = {Should attention be all we need? The epistemic and ethical implications of unification in machine learning},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {1516 – 1527},
	doi = {10.1145/3531146.3533206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133021408&doi=10.1145%2f3531146.3533206&partnerID=40&md5=678f42ff34be57a4f2daea5808b6cce5},
	affiliations = {University of Oxford, Oxford, United Kingdom; Capital One, McLean, VA, United States},
	abstract = {"Attention is all you need"has become a fundamental precept in machine learning research. Originally designed for machine translation, transformers and the attention mechanisms that underpin them now find success across many problem domains. With the apparent domain-agnostic success of transformers, many researchers are excited that similar model architectures can be successfully deployed across diverse applications in vision, language and beyond. We consider the benefits and risks of these waves of unification on both epistemic and ethical fronts. On the epistemic side, we argue that many of the arguments in favor of unification in the natural sciences fail to transfer over to the machine learning case, or transfer over only under assumptions that might not hold. Unification also introduces epistemic risks related to portability, path dependency, methodological diversity, and increased black-boxing. On the ethical side, we discuss risks emerging from epistemic concerns, further marginalizing underrepresented perspectives, the centralization of power, and having fewer models across more domains of application. © 2022 ACM.},
	author_keywords = {ethics; explanation; machine learning; neural networks; philosophy},
	keywords = {Ethical technology; Attention mechanisms; Domain agnostics; Ethical implications; Explanation; Machine learning research; Machine translations; Machine-learning; Neural-networks; Philosophy; Problem domain; Machine learning},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210; All Open Access, Green Open Access}
}

@ARTICLE{Lorente2022,
	author = {Lorente, Juan Victor and Jimenez, Ignacio and Ripollés-Melchor, Javier and Becerra, Alejandra and Wesselink, Wilbert and Reguant, Francesca and Mojarro, Irene and Fuentes, Maria De Los Angeles and Abad-Motos, Ane and Agudelo, Elizabeth and Herrero-Machancoses, Francisco and Callejo, Paula and Bosch, Joan and Monge, Manuel Ignacio},
	title = {Intraoperative haemodynamic optimisation using the Hypotension Prediction Index and its impact on tissular perfusion: a protocol for a randomised controlled trial},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {6},
	doi = {10.1136/bmjopen-2021-051728},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131264091&doi=10.1136%2fbmjopen-2021-051728&partnerID=40&md5=b0def7b9f1685204957017dad35d7da3},
	affiliations = {Anesthesia and Critical Care, Hospital Juan Ramon Jimenez, Huelva, Spain; School of Medicine and Health Science, Universitat Internacional de Catalunya, Barcelona, Spain; Anesthesia and Critical Care, Virgen Del Rocio University Hospital, Sevilla, Spain; Anesthesia and Critical Care, Infanta Leonor University Hospital, Madrid, Spain; Anesthesia and Critical Care, Complejo Hospitalario Universitario de Badajoz, Badajoz, Spain; Edwards Lifesciences Corp, Irvine, CA, United States; Anesthesia, Fundacio Althaia de Manresa, Manresa, Spain; Predepartamental Unit of Medicine, Science Health Faculty, Universitat Jaume, Castello de la Plana, Spain; Fundación Progreso y Salud, Sevilla, Spain; Intensive Care Unit, Hospital Universitario de Jerez de la Frontera, Jerez de la Frontera, Spain},
	abstract = {Introduction Intraoperative arterial hypotension is associated with poor postoperative outcomes. The Hypotension Prediction Index (HPI) developed using machine learning techniques, allows the prediction of arterial hypotension analysing the arterial pressure waveform. The use of this index may reduce the duration and severity of intraoperative hypotension in adults undergoing non-cardiac surgery. This study aims to determine whether a treatment protocol based on the prevention of arterial hypotension using the HPI algorithm reduces the duration and severity of intraoperative hypotension compared with the recommended goal-directed fluid therapy strategy and may improve tissue oxygenation and organ perfusion. Methods and analysis We will conduct a multicentre, randomised, controlled trial (N=80) in high-risk surgical patients scheduled for elective major abdominal surgery. All participants will be randomly assigned to a control or intervention group. Haemodynamic management in the control group will be based on standard haemodynamic parameters. Haemodynamic management of patients in the intervention group will be based on functional haemodynamic parameters provided by the HemoSphere platform (Edwards Lifesciences), including dynamic arterial elastance, dP/dt max and the HPI. Tissue oxygen saturation will be recorded non-invasively and continuously by using near-infrared spectroscopy technology. Biomarkers of acute kidney stress (cTIMP2 and IGFBP7) will be obtained before and after surgery. The primary outcome will be the intraoperative time-weighted average of a mean arterial pressure <65 mm Hg. Ethics and dissemination Ethics committee approval was obtained from the Ethics Committee of Hospital Gregorio Marañón (Meeting of 27 July 2020, minutes 18/2020, Madrid, Spain). Findings will be widely disseminated through peer-reviewed publications and conference presentations. Trial registration number NCT04301102. © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {Adult anaesthesia; Adult intensive & critical care; SURGERY},
	keywords = {Arterial Pressure; Elective Surgical Procedures; Hemodynamics; Humans; Hypotension; Multicenter Studies as Topic; Perfusion; Randomized Controlled Trials as Topic; biological marker; tissue inhibitor of metalloproteinase 2; abdominal surgery; adult; Article; cardiovascular disease assessment; clinical protocol; compliance (physical); controlled study; early goal-directed therapy; elective surgery; female; fluid therapy; general surgery; gynecologic surgery; hemodynamic parameters; hemodynamics; high risk patient; human; hypotension; Hypotension Prediction Index; intraoperative period; laparoscopic surgery; major clinical study; major surgery; male; maximum heart muscle dP-dt; mean arterial pressure; multicenter study; near infrared spectroscopy; open surgery; organ perfusion; peer review; randomized controlled trial; Spain; tissue oxygenation; urologic surgery; arterial pressure; hemodynamics; hypotension; multicenter study (topic); perfusion; randomized controlled trial (topic)},
	correspondence_address = {J.V. Lorente; Anesthesia and Critical Care, Hospital Juan Ramon Jimenez, Huelva, Spain; email: juanvictor.lorente@gmail.com},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35654467},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kooper2022,
	author = {Kooper, Cece C and Oosterlaan, Jaap and Bruining, Hilgo and Engelen, Marc and Pouwels, Petra J.W. and Popma, Arne and Van Woensel, Job Bm. and Buis, Dennis R and Steenweg, Marjan E. and Hunfeld, Maayke and Königs, Marsh},
	title = {Towards PErsonalised PRognosis for children with traumatic brain injury: The PEPR study protocol},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {6},
	doi = {10.1136/bmjopen-2021-058975},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133144782&doi=10.1136%2fbmjopen-2021-058975&partnerID=40&md5=0d89a855f81b5e580278a491831bec2e},
	affiliations = {Department of Pediatrics, Emma Neuroscience Group, Emma Children's Hospital, Amsterdam UMC Location University of Amsterdam, Amsterdam, Netherlands; Amsterdam Reproduction and Development Research Institute, Amsterdam, Netherlands; Amsterdam Neuroscience Research Institute, Amsterdam, Netherlands; Department of Child and Youth Psychiatry, Emma Children's Hospital, Amsterdam UMC Location Vrije Universiteit Amsterdam, N=You Centre, Amsterdam, Netherlands; Department of Pediatric Neurology, Emma Children's Hospital, Amsterdam UMC Location University of Amsterdam, Amsterdam, Netherlands; Amsterdam Leukodystrophy Center, Amsterdam, Netherlands; Department of Radiology and Nuclear Medicine, Amsterdam UMC Location Vrije Universiteit Amsterdam, Amsterdam, Netherlands; Department of Child and Youth Psychiatry, Amsterdam University Medical Centres, Amsterdam, Netherlands; Department of Pediatric Intensive Care Unit, Emma Children's Hospital, Amsterdam UMC Location University of Amsterdam, Amsterdam, Netherlands; Department of Neurosurgery, Emma Children's Hospital, Amsterdam UMC Location University of Amsterdam, Amsterdam, Netherlands; Department of Pediatric Neurology, OLVG, Amsterdam, Netherlands; Department of Pediatric Neurology, Erasmus MC Sophia Children Hospital, Rotterdam, Netherlands},
	abstract = {Introduction Traumatic brain injury (TBI) in children can be associated with poor outcome in crucial functional domains, including motor, neurocognitive and behavioural functioning. However, outcome varies between patients and is mediated by complex interplay between demographic factors, premorbid functioning and (sub)acute clinical characteristics. At present, methods to understand let alone predict outcome on the basis of these variables are lacking, which contributes to unnecessary follow-up as well as undetected impairments in children. Therefore, this study aims to develop prognostic models for the individual outcome of children with TBI in a range of important developmental domains. In addition, the potential added value of advanced neuroimaging data and the use of machine learning algorithms in the development of prognostic models will be assessed. Methods and analysis 210 children aged 4-18 years diagnosed with mild-To-severe TBI will be prospectively recruited from a research network of Dutch hospitals. They will be matched 2:1 to a control group of neurologically healthy children (n=105). Predictors in the model will include demographic, premorbid and clinical measures prospectively registered from the TBI hospital admission onwards as well as MRI metrics assessed at 1 month post-injury. Outcome measures of the prognostic models are (1) motor functioning, (2) intelligence, (3) behavioural functioning and (4) school performance, all assessed at 6 months post-injury. Ethics and dissemination Ethics has been obtained from the Medical Ethical Board of the Amsterdam UMC (location AMC). Findings of our multicentre prospective study will enable clinicians to identify TBI children at risk and aim towards a personalised prognosis. Lastly, findings will be submitted for publication in open access, international and peer-reviewed journals. Trial registration number NL71283.018.19 and NL9051.  © Author(s) (or their employer(s)) 2022.},
	author_keywords = {Magnetic resonance imaging; Paediatric intensive & critical care; Paediatric neurology; Paediatric neurosurgery; Paediatric radiology},
	keywords = {Brain Injuries, Traumatic; Child; Humans; Magnetic Resonance Imaging; Neuroimaging; Prognosis; Prospective Studies; academic achievement; adolescent; adult; Article; behavior; child; clinical protocol; clinician; demographics; female; follow up; hospital admission; human; intelligence; longitudinal study; machine learning; major clinical study; male; motor performance; multicenter study; neuroimaging; nuclear magnetic resonance imaging; observational study; outcome assessment; peer review; prognosis; prospective study; publication; traumatic brain injury; diagnostic imaging; prognosis},
	correspondence_address = {C.C. Kooper; Department of Pediatrics, Emma Neuroscience Group, Emma Children's Hospital, Amsterdam UMC Location University of Amsterdam, Amsterdam, Netherlands; email: c.c.kooper@amsterdamumc.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35768114},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Rivas2022,
	author = {Rivas, Ana Belen and Lopez-Picado, Amanda and Calamia, Valentina and Carreño, Ester and Cocho, Lidia and Cordero-Coma, Miguel and Fonollosa, Alex and Hernandez, Felix M. Francisco and Garcia-Aparicio, Angel and Garcia-Gonzalez, Javier and Mondejar, Jose Juan and Lojo-Oliveira, Leticia and Martínez-Costa, Llucí and Munoz, Santiago and Peiteado, Diana and Pinto, Jose Antonio and Rodriguez-Lozano, Beatriz and Pato, Esperanza and Diaz-Valle, David and Molina, Elena and Tebar, Luis Alberto and Rodriguez-Rodriguez, Luis},
	title = {Efficacy, safety and cost-effectiveness of methotrexate, adalimumab or their combination in non-infectious non-anterior uveitis: A protocol for a multicentre, randomised, parallel three arms, active-controlled, phase III open label with blinded outcome assessment study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {3},
	doi = {10.1136/bmjopen-2021-051378},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126892305&doi=10.1136%2fbmjopen-2021-051378&partnerID=40&md5=31acd1a74f4debc2e5a88471a33ed5c7},
	affiliations = {Unidad de Investigación Clinica y Ensayos Clínicos, Hospital Clínico San Carlos, IdISSC, Madrid, Spain; Departamento de Enfermería, Facultad Enfermería Fisioterapia y Podología, Universidad Complutense de Madrid, Madrid, Spain; Unidad de Proteómica, Grupo de Investigación de Reumatología (GIR), Instituto de Investigación Biomédica de A Coruña, Complexo Hospitalario Universitario de A Coruña, Universidade da Coruña, A Coruna, Galicia, Spain; Department of Ophthalmology, University Hospital Fundacion Jimenez Diaz, University Hospital Rey Juan Carlos, Madrid, Spain; Department of Ophthalmology, IOBA (Institute of Applied OphthalmoBiology), University of Valladolid, Hospital Clínico Universitario de Valladolid, Valladolid, Castilla y León, Spain; Uveitis Unit, University Hospital of León, IBIOMED, University of León, Leon, Spain; Department of Ophthalmology, BioCruces Bizkaia Health Research Institute, Cruces University Hospital, University of the Basque Country, Barakaldo, País Vasco, Spain; Department of Rheumatology, Hospital Universitario de Gran Canaria Dr Negrin, Las Palmas de Gran Canaria, Spain; Department of Rheumatology, Hospital Universitario de Toledo, Toledo, Spain; Department of Rheumatology, Hospital Universitario 12 de Octubre, Madrid, Comunidad de Madrid, Spain; Department of Ophthalmology, Hospital General Universitario de Alicante, Alicante, Comunidad Valenciana, Spain; Section of Rheumatology, Hospital Universitario Infanta Leonor, Madrid, Spain; Department of Ophthalmology, Hospital Universitario Doctor Peset, Valencia, Spain; Department of Rheumatology, Hospital Universitario Infanta Sofia, San Sebastian de Los Reyes, Madrid, Spain; Department of Rheumatology, Hospital Universitario la Paz, Madrid, Spain; Department of Rheumatology, Complexo Hospitalario Universitario de A Coruña, A Coruna, Galicia, Spain; Department of Rheumatology, Hospital Universitario de Canarias, Santa Cruz de Tenerife Canarias, Spain; Department of Rheumatology, Hospital Clínico San Carlos, IdISSC, Madrid, Spain; Department of Ophthalmology, Hospital Clínico San Carlos, IdISSC, Madrid, Spain; Department of Pathology, Hospital Clínico San Carlos, IdISSC, Madrid, Spain; Musculoskeletal Pathology Group, Fundacion Para la Investigacion Biomedica Del Hospital Clinico San Carlos, IdISSC, Madrid, Spain},
	abstract = {Introduction Non-infectious uveitis include a heterogeneous group of sight-threatening and incapacitating conditions. Their correct management sometimes requires the use of immunosuppressive drugs (ISDs), prescribed in monotherapy or in combination. Several observational studies showed that the use of ISDs in combination could be more effective than and as safe as their use in monotherapy. However, a direct comparison between these two treatment strategies has not been carried out yet. Methods and analysis The Combination THerapy with mEthotrexate and adalImumAb for uveitis (CoTHEIA) study is a phase III, multicentre, prospective, randomised, single-blinded with masked outcome assessment, parallel three arms with 1:1:1 allocation, active-controlled, superiority study design, comparing the efficacy, safety and cost-effectiveness of methotrexate, adalimumab or their combination in non-infectious non-anterior uveitis. We aim to recruit 192 subjects. The duration of the treatment and follow-up will last up to 52 weeks, plus 70 days follow-up with no treatment. The complete and maintained resolution of the ocular inflammation will be assessed by masked evaluators (primary outcome). In addition to other secondary measurements of efficacy (quality of life, visual acuity and costs) and safety, we will identify subjects' subgroups with different treatment responses by developing prediction models based on machine learning techniques using genetic and proteomic biomarkers. Ethics and dissemination The protocol, annexes and informed consent forms were approved by the Reference Clinical Research Ethic Committee at the Hospital Clínico San Carlos (Madrid, Spain) and the Spanish Agency for Medicines and Health Products. We will elaborate a dissemination plan including production of materials adapted to several formats to communicate the clinical trial progress and findings to a broad group of stakeholders. The promoter will be the only access to the participant-level data, although it can be shared within the legal situation. Trial registration number 2020-000130-18; NCT04798755.  © },
	author_keywords = {clinical trials; ophthalmology; rheumatology},
	keywords = {Adalimumab; Clinical Trials, Phase III as Topic; Cost-Benefit Analysis; Humans; Methotrexate; Multicenter Studies as Topic; Outcome Assessment, Health Care; Prospective Studies; Proteomics; Quality of Life; Randomized Controlled Trials as Topic; Research Design; Treatment Outcome; Uveitis; Uveitis, Anterior; adalimumab; antiglaucoma agent; artificial tear; biological marker; cycloplegic agent; methotrexate; nonsteroid antiinflammatory agent; prednisolone acetate; prednisone; adalimumab; methotrexate; adult; anatomical location; Article; clinical outcome; combination drug therapy; comparative study; controlled study; cost effectiveness analysis; drug cost; drug dose increase; drug efficacy; drug safety; eye inflammation; female; follow up; genetic analysis; Hospital Anxiety and Depression Scale; human; loading drug dose; machine learning; major clinical study; male; monotherapy; multicenter study; multiple reaction monitoring; observational study; outcome assessment; patient compliance; pharmacogenetics; pharmacovigilance; phase 3 clinical trial; prediction; prospective study; proteomics; quality of life; randomized controlled trial; single blind procedure; single nucleotide polymorphism; standard; treatment duration; treatment response; uveitis; visual acuity; cost benefit analysis; iridocyclitis; methodology; multicenter study (topic); phase 3 clinical trial (topic); randomized controlled trial (topic); treatment outcome; uveitis},
	correspondence_address = {L. Rodriguez-Rodriguez; Musculoskeletal Pathology Group, Fundacion Para la Investigacion Biomedica Del Hospital Clinico San Carlos, IdISSC, Madrid, Spain; email: lrrodriguez@salud.madrid.org},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35318229},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sato2022310,
	author = {Sato, Maki and McKinney, Jonathan},
	title = {The Enactive and Interactive Dimensions of AI: Ingenuity and Imagination Through the Lens of Art and Music},
	year = {2022},
	journal = {Artificial Life},
	volume = {28},
	number = {3},
	pages = {310 – 321},
	doi = {10.1162/artl_a_00376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135599288&doi=10.1162%2fartl_a_00376&partnerID=40&md5=27b1067208ff25c2ad8a8712e3202ce0},
	affiliations = {University of Tokyo, Graduate School of Arts and Sciences, The New Institute, Japan; University of Cincinnati, United States},
	abstract = {Dualisms are pervasive. The divisions between the rational mind, the physical body, and the external natural world have set the stage for the successes and failures of contemporary cognitive science and artificial intelligence.1 Advanced machine learning (ML) and artificial intelligence (AI) systems have been developed to draw art and compose music. Many take these facts as calls for a radical shift in our values and turn to questions about AI ethics, rights, and personhood. While the discussion of agency and rights is not wrong in principle, it is a form of misdirection in the current circumstances. Questions about an artificial agency can only come after a genuine reconciliation of human interactivity, creativity, and embodiment. This kind of challenge has both moral and theoretical force. In this article, the authors intend to contribute to embodied and enactive approaches to AI by exploring the interactive and contingent dimensions of machines through the lens of Japanese philosophy. One important takeaway from this project is that AI/ML systems should be recognized as powerful tools or instruments rather than as agents themselves. © MIT Press Journals. All rights reserved.},
	author_keywords = {AI ethics; contingency; embodiment; enactivism; interactivity; Japanese philosophy},
	keywords = {Artificial Intelligence; Creativity; Humans; Imagination; Machine Learning; Music; Ethical technology; Art and musics; Artificial intelligence ethic; Cognitive science; Contingency; Embodiment; Enactivism; Interactivity; Japanese philosophy; Natural world; Through the lens; artificial intelligence; creativity; human; imagination; machine learning; music; Artificial intelligence},
	correspondence_address = {M. Sato; University of Tokyo, Graduate School of Arts and Sciences, The New Institute, Japan; email: maki.sato@aya.yale.edu},
	publisher = {MIT Press Journals},
	issn = {10645462},
	pmid = {35881681},
	language = {English},
	abbrev_source_title = {Artif. Life},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Predel2022,
	author = {Predel, Christopher and Timmermann, Cristian and Ursin, Frank and Orzechowski, Marcin and Ropinski, Timo and Steger, Florian},
	title = {Conflicting Aims and Values in the Application of Smart Sensors in Geriatric Rehabilitation: Ethical Analysis},
	year = {2022},
	journal = {JMIR mHealth and uHealth},
	volume = {10},
	number = {6},
	doi = {10.2196/32910},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132841942&doi=10.2196%2f32910&partnerID=40&md5=76720936bc50924d78f2de607e0ecef1},
	affiliations = {Institute of the History, Philosophy and Ethics of Medicine, Ulm University, Ulm, Germany; Visual Computing Group, Ulm University, Ulm, Germany},
	abstract = {Background: Smart sensors have been developed as diagnostic tools for rehabilitation to cover an increasing number of geriatric patients. They promise to enable an objective assessment of complex movement patterns. Objective: This research aimed to identify and analyze the conflicting ethical values associated with smart sensors in geriatric rehabilitation and provide ethical guidance on the best use of smart sensors to all stakeholders, including technology developers, health professionals, patients, and health authorities. Methods: On the basis of a systematic literature search of the scientific databases PubMed and ScienceDirect, we conducted a qualitative document analysis to identify evidence-based practical implications of ethical relevance. We included 33 articles in the analysis. The practical implications were extracted inductively. Finally, we carried out an ethical analysis based on the 4 principles of biomedical ethics: autonomy, beneficence, nonmaleficence, and justice. The results are reported in categories based on these 4 principles. Results: We identified 8 conflicting aims for using smart sensors. Gains in autonomy come at the cost of patient privacy. Smart sensors at home increase the independence of patients but may reduce social interactions. Independent measurements performed by patients may result in lower diagnostic accuracy. Although smart sensors could provide cost-effective and high-quality diagnostics for most patients, minorities could end up with suboptimal treatment owing to their underrepresentation in training data and studies. This could lead to algorithmic biases that would not be recognized by medical professionals when treating patients. Conclusions: The application of smart sensors has the potential to improve the rehabilitation of geriatric patients in several ways. It is important that patients do not have to choose between autonomy and privacy and are well informed about the insights that can be gained from the data. Smart sensors should support and not replace interactions with medical professionals. Patients and medical professionals should be educated about the correct application and the limitations of smart sensors. Smart sensors should include an adequate representation of minorities in their training data and should be covered by health insurance to guarantee fair access. © 2022 JMIR Publications. All rights reserved.},
	author_keywords = {access to health care; autonomy; ethics; justice; machine learning; older adults; personal data; rehabilitation; smart sensor; wearable},
	keywords = {Aged; Confidentiality; Ethical Analysis; Humans; Privacy; Technology; aged; confidentiality; ethics; human; privacy; technology},
	correspondence_address = {C. Predel; Institute of the History, Philosophy and Ethics of Medicine, Ulm University, Ulm, Parkstraße 11, 89073, Germany; email: christopher.predel@uni-ulm.de},
	publisher = {JMIR Publications Inc.},
	issn = {22915222},
	pmid = {35737429},
	language = {English},
	abbrev_source_title = {JMIR mHealth uHealth},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Nawaz2022,
	author = {Nawaz, Aftab and Abbas, Yawar and Ahmad, Tahir and Mahmoud, Noha F. and Rizwan, Atif and Samee, Nagwan Abdel},
	title = {A Healthcare Paradigm for Deriving Knowledge Using Online Consumers’ Feedback},
	year = {2022},
	journal = {Healthcare (Switzerland)},
	volume = {10},
	number = {8},
	doi = {10.3390/healthcare10081592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137380675&doi=10.3390%2fhealthcare10081592&partnerID=40&md5=5564bd54a2fcc7cedc81793e6b45dcb8},
	affiliations = {Department of Computer Science, COMSATS University Islamabad, Attock Campus, Attock, 43600, Pakistan; Department of Rehabilitation Sciences, College of Health and Rehabilitation Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia; Department of Computer Engineering, Jeju National University, Jejusi, 63243, South Korea; Department of Information Technology, College of Computer and Information Sciences, Princess Nourah bint Abdulrahman University, P.O. Box 84428, Riyadh, 11671, Saudi Arabia},
	abstract = {Home healthcare agencies (HHCAs) provide clinical care and rehabilitation services to patients in their own homes. The organization’s rules regulate several connected practitioners, doctors, and licensed skilled nurses. Frequently, it monitors a physician or licensed nurse for the facilities and keeps track of the health histories of all clients. HHCAs’ quality of care is evaluated using Medicare’s star ratings for in-home healthcare agencies. The advent of technology has extensively evolved our living style. Online businesses’ ratings and reviews are the best representatives of organizations’ trust, services, quality, and ethics. Using data mining techniques to analyze HHCAs’ data can help to develop an effective framework for evaluating the finest home healthcare facilities. As a result, we developed an automated predictive framework for obtaining knowledge from patients’ feedback using a combination of statistical and machine learning techniques. HHCAs’ data contain twelve performance characteristics that we are the first to analyze and depict. After adequate pattern recognition, we applied binary and multi-class approaches on similar data with variations in the target class. Four prominent machine learning models were considered: SVM, Decision Tree, Random Forest, and Deep Neural Networks. In the binary class, the Deep Neural Network model presented promising performance with an accuracy of 97.37%. However, in the case of multiple class, the random forest model showed a significant outcome with an accuracy of 91.87%. Additionally, variable significance is derived from investigating each attribute’s importance in predictive model building. The implications of this study can support various stakeholders, including public agencies, quality measurement, healthcare inspectors, and HHCAs, to boost their performance. Thus, the proposed framework is not only useful for putting valuable insights into action, but it can also help with decision-making. © 2022 by the authors.},
	author_keywords = {decision-making; healthcare paradigm; home healthcare; pattern recognition; quality measurement; valuable insights},
	correspondence_address = {N.F. Mahmoud; Department of Rehabilitation Sciences, College of Health and Rehabilitation Sciences, Princess Nourah bint Abdulrahman University, Riyadh, P.O. Box 84428, 11671, Saudi Arabia; email: nfmahmoud@pnu.edu.sa; A. Rizwan; Department of Computer Engineering, Jeju National University, Jejusi, 63243, South Korea; email: atifrizwan@jejunu.ac.kr},
	publisher = {MDPI},
	issn = {22279032},
	language = {English},
	abbrev_source_title = {Healthcare (Basel)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zacharakis20222778,
	author = {Zacharakis, Georgios and Almasoud, Abdulaziz},
	title = {Using of artificial intelligence: Current and future applications in colorectal cancer screening},
	year = {2022},
	journal = {World Journal of Gastroenterology},
	volume = {28},
	number = {24},
	pages = {2778 – 2781},
	doi = {10.3748/wjg.v28.i24.2778},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133184411&doi=10.3748%2fwjg.v28.i24.2778&partnerID=40&md5=fb6a6c1059232a0d2f92a22d9f4bab78},
	affiliations = {Division of Gastroenterology, Department of Internal Medicine, College of Medicine, Prince Sattam bin Abdulaziz University Hospital, Al Kharj, 16277, Saudi Arabia; Department of Gastroenterology and Hepatology, Prince Sultan Military Medical City, Riyadh, 12233, Saudi Arabia},
	abstract = {Significant developments in colorectal cancer screening are underway and include new screening guidelines that incorporate considerations for patients aged 45 years, with unique features and new techniques at the forefront of screening. One of these new techniques is artificial intelligence which can increase adenoma detection rate and reduce the prevalence of colonic neoplasia. © The Author(s) 2022.},
	author_keywords = {Assessment of artificial intelligence in endoscopy; Basic concepts; Current applications; Ethics; Safety challenge},
	keywords = {Adenoma; Artificial Intelligence; Colonic Polyps; Colonoscopy; Colorectal Neoplasms; Early Detection of Cancer; Humans; algorithm; Article; artificial intelligence; cancer diagnosis; cancer epidemiology; cancer screening; China; chromoendoscopy; clinical effectiveness; clinical evaluation; clinical practice; colon polyp; colonoscopy; colorectal cancer; diagnostic accuracy; diagnostic procedure; disease classification; endoscopist; endoscopy; ethnicity; ex vivo study; feasibility study; gastroenterology; health care quality; health care system; health care utilization; human; intestine preparation; Italy; machine learning; magnifying endoscopy; medical decision making; patient risk; population structure; practice guideline; prevalence; quality control; randomized controlled trial (topic); reimbursement; tumor localization; tumor volume; United States; validation study; videoendoscopy; adenoma; artificial intelligence; colon polyp; colorectal tumor; early cancer diagnosis; procedures},
	correspondence_address = {G. Zacharakis; Division of Gastroenterology, Department of Internal Medicine, College of Medicine, Prince Sattam bin Abdulaziz University Hospital, Al Kharj, Arrayan, 16277, Saudi Arabia; email: g.zacharakis@psau.edu.sa},
	publisher = {Baishideng Publishing Group Inc},
	issn = {10079327},
	coden = {WJGAF},
	pmid = {35979167},
	language = {English},
	abbrev_source_title = {World J. Gastroenterol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Altun2022,
	author = {Altun, Sinan and Alkan, Ahmet and Altun, Hatice},
	title = {Application of deep learning and classical machine learning methods in the diagnosis of attention deficit hyperactivity disorder according to temperament features},
	year = {2022},
	journal = {Concurrency and Computation: Practice and Experience},
	volume = {34},
	number = {13},
	doi = {10.1002/cpe.6908},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126062450&doi=10.1002%2fcpe.6908&partnerID=40&md5=efe99d7a6979ce043d13168f3a9ff4d2},
	affiliations = {Department of Electrical and Electronics Engineering, Kahramanmaras Sutcu Imam University, Kahramanmaras, Turkey; Department of Child and Adolescent Psychiatry, Kahramanmaras Sutcu Imam University, Kahramanmaras, Turkey},
	abstract = {Attention deficit hyperactivity disorder (ADHD) is a common childhood neurodevelopmental disorder with symptoms of attention deficit, hyperactivity and impulsivity, with a prevalence of 8%–12% worldwide. Various studies have revealed that there may be a relationship between ADHD and temperament traits in the etiology of ADHD, which has a multifactorial etiology. According to our knowledge, there is no study in the literature that determines the use of machine learning methods in diagnosing ADHD uses a data set created with temperament characteristics. Different methods were used in this first study. The study included 60 ADHD patients and 60 control group children. The test scores of these children were collected from the Department of Child and Adolescent Psychiatry, Kahramanmaraş Sütçü İmam University Medical Faculty, after obtaining the necessary ethics committee permission. ADHD diagnosis was made according to DSM-5 classification. According to temperament characteristics, the highest classification success in ADHD diagnosis was calculated as 92.5% in decision tree method. Long short term memory (LSTM), one of the deep learning methods, achieved 88% classification success. The success of both methods is quite high and they have been compared with some ADHD classification studies in the literature. © 2022 John Wiley & Sons, Ltd.},
	author_keywords = {ADHD; deep learning; temperament features},
	keywords = {Computer aided diagnosis; Decision trees; Long short-term memory; Attention deficit hyperactivity; Attention deficit hyperactivity disorder; Children and adolescents; Control groups; Data set; Decision tree method; Deep learning; Ethics committee; Machine learning methods; Temperament feature; Diseases},
	correspondence_address = {S. Altun; Department of Electrical and Electronics Engineering, Kahramanmaras Sutcu Imam University, Kahramanmaras, Turkey; email: s.altun@yaani.com},
	publisher = {John Wiley and Sons Ltd},
	issn = {15320626},
	coden = {CCPEB},
	language = {English},
	abbrev_source_title = {Concurr. Comput. Pract. Exper.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Park2022759,
	author = {Park, Seong Ho},
	title = {Ethics for Artificial Intelligence: Focus on the Use of Radiology Images},
	year = {2022},
	journal = {Journal of the Korean Society of Radiology},
	volume = {83},
	number = {4},
	pages = {759 – 770},
	doi = {10.3348/jksr.2022.0036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136233765&doi=10.3348%2fjksr.2022.0036&partnerID=40&md5=ac0d6072cd9942bb441fcc5aa2b7091b},
	affiliations = {Department of Radiology and Research Institute of Radiology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, South Korea},
	abstract = {The importance of ethics in research and the use of artificial intelligence (AI) is increasingly recognized not only in the field of healthcare but throughout society. This article intends to provide domestic readers with practical points regarding the ethical issues of using radiological images for AI research, focusing on data security and privacy protection and the right to data. Therefore, this article refers to related domestic laws and government policies. Data security and privacy protection is a key ethical principle for AI, in which proper de-identification of data is crucial. Sharing healthcare data to develop AI in a way that minimizes business interests is another ethical point to be highlighted. The need for data sharing makes the data security and privacy protection even more important as data sharing increases the risk of data breach. Copyrights © 2022 The Korean Society of Radiology.},
	author_keywords = {Artificial Intelligence; Diagnostic Imaging; Ethics; Machine Learning; Medicine; Radiology},
	correspondence_address = {S.H. Park; Department of Radiology and Research Institute of Radiology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, 88 Olympic-ro 43-gil, Songpa-gu, 05505, South Korea; email: seongho@amc.seoul.kr},
	publisher = {Korean Radiological Society},
	issn = {17382637},
	language = {Korean},
	abbrev_source_title = {J. Kor. Soc. Radiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Awad2022388,
	author = {Awad, Edmond and Levine, Sydney and Anderson, Michael and Anderson, Susan Leigh and Conitzer, Vincent and Crockett, M.J. and Everett, Jim A.C. and Evgeniou, Theodoros and Gopnik, Alison and Jamison, Julian C. and Kim, Tae Wan and Liao, S. Matthew and Meyer, Michelle N. and Mikhail, John and Opoku-Agyemang, Kweku and Borg, Jana Schaich and Schroeder, Juliana and Sinnott-Armstrong, Walter and Slavkovik, Marija and Tenenbaum, Josh B.},
	title = {Computational ethics},
	year = {2022},
	journal = {Trends in Cognitive Sciences},
	volume = {26},
	number = {5},
	pages = {388 – 405},
	doi = {10.1016/j.tics.2022.02.009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127359671&doi=10.1016%2fj.tics.2022.02.009&partnerID=40&md5=c4c213ef7ddd960c485bbca3fd762cd6},
	affiliations = {Department of Economics, University of Exeter, UK, Exeter, United Kingdom; Institute for Data Science and AI, University of Exeter, UK, Exeter, United Kingdom; Center for Humans and Machines, Max-Planck Institute for Human Development, Berlin, Germany; Department of Brain and Cognitive Sciences, Massachusetts Institute of Technology (MIT), Cambridge, MA, United States; Department of Psychology, Harvard University, Cambridge, MA, United States; Department of Computer Science, University of Hartford, West Hartford, CT, United States; Department of Philosophy, University of Connecticut, Storrs, CT, United States; Department of Computer Science, Duke University, Durham, NC, United States; Department of Economics, Duke University, Durham, NC, United States; Department of Philosophy, Duke University, Durham, NC, United States; Institute for Ethics in AI, University of Oxford, UK, Oxford, United Kingdom; Department of Psychology, Yale University, New Haven, CT, United States; School of Psychology, University of Kent, UK, Canterbury, United Kingdom; INSEAD, Fontainebleau, France; Department of Psychology, University of California, Berkeley, CA, United States; Global Priorities Institute, Oxford University, UK, Oxford, United Kingdom; Ethics Group, Tepper School of Business, Carnegie Mellon University, Pittsburgh, PA, United States; Center for Bioethics, New York University, New York, NY, United States; Center for Translational Bioethics and Health Care Policy, Geisinger Health System, Danville, PA, United States; Steele Institute for Health Innovation, Geisinger Health System, Danville, PA, United States; Geisinger Commonwealth School of Medicine, Scranton, PA, United States; Georgetown University Law Center, Washington, DC, United States; International Growth Centre, London School of Economics, UK, London, United Kingdom; Machine Learning X Doing, Toronto, ON, Canada; Social Science Research Institute, Duke University, Durham, NC, United States; Duke Institute for Brain Sciences, Duke University, Durham, NC, United States; Haas School of Business, University of California, Berkeley, CA, United States; Kenan Institute for Ethics, Duke University, Durham, NC, United States; Department of Information Science and Media Studies, University of Bergen, Bergen, Norway; Computer Science and Artificial Intelligence Laboratory, MIT, Cambridge, MA, United States; Center for Brains, Minds, and Machines, MIT, Cambridge, MA, United States; Tremau, Paris, France; Development Economics X, Toronto, ON, Canada},
	abstract = {Technological advances are enabling roles for machines that present novel ethical challenges. The study of 'AI ethics' has emerged to confront these challenges, and connects perspectives from philosophy, computer science, law, and economics. Less represented in these interdisciplinary efforts is the perspective of cognitive science. We propose a framework – computational ethics – that specifies how the ethical challenges of AI can be partially addressed by incorporating the study of human moral decision-making. The driver of this framework is a computational version of reflective equilibrium (RE), an approach that seeks coherence between considered judgments and governing principles. The framework has two goals: (i) to inform the engineering of ethical AI systems, and (ii) to characterize human moral judgment and decision-making in computational terms. Working jointly towards these two goals will create the opportunity to integrate diverse research questions, bring together multiple academic communities, uncover new interdisciplinary research topics, and shed light on centuries-old philosophical questions. © 2022 The Authors},
	author_keywords = {AI ethics; computation; ethics; machine ethics; moral cognition; moral psychology},
	keywords = {Decision Making; Engineering; Humans; Judgment; Morals; Philosophy; Economics; Ethical technology; AI ethic; AI systems; Cognitive science; Decisions makings; Judgment and decision makings; Machine ethic; Moral cognition; Moral judgment; Moral psychology; Technological advances; algorithm; analytical parameters; automated reasoning; cognition; computational reflective equilibrium; conceptual framework; decision making; descriptive ethics; human; interdisciplinary research; machine learning; mathematical analysis; medical ethics; morality; resource allocation; Review; engineering; morality; philosophy; Decision making},
	correspondence_address = {E. Awad; Department of Economics, University of Exeter, Exeter, UK, United Kingdom; email: e.awad@exeter.ac.uk},
	publisher = {Elsevier Ltd},
	issn = {13646613},
	coden = {TCSCF},
	pmid = {35365430},
	language = {English},
	abbrev_source_title = {Trends Cogn. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Lazovich2022,
	author = {Lazovich, Tomo and Belli, Luca and Gonzales, Aaron and Bower, Amanda and Tantipongpipat, Uthaipon and Lum, Kristian and Huszár, Ferenc and Chowdhury, Rumman},
	title = {Measuring disparate outcomes of content recommendation algorithms with distributional inequality metrics},
	year = {2022},
	journal = {Patterns},
	volume = {3},
	number = {8},
	doi = {10.1016/j.patter.2022.100568},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135962645&doi=10.1016%2fj.patter.2022.100568&partnerID=40&md5=388bfec9f0211930b38233fc8cd6ea10},
	affiliations = {Twitter, Inc., San Francisco, 94103, CA, United States; University of Cambridge, Cambridge, United Kingdom},
	abstract = {The harmful impacts of algorithmic decision systems have recently come into focus, with many examples of machine learning (ML) models amplifying societal biases. In this paper, we propose adapting income inequality metrics from economics to complement existing model-level fairness metrics, which focus on intergroup differences of model performance. In particular, we evaluate their ability to measure disparities between exposures that individuals receive in a production recommendation system, the Twitter algorithmic timeline. We define desirable criteria for metrics to be used in an operational setting by ML practitioners. We characterize engagements with content on Twitter using these metrics and use the results to evaluate the metrics with respect to our criteria. We also show that we can use these metrics to identify content suggestion algorithms that contribute more strongly to skewed outcomes between users. Overall, we conclude that these metrics can be a useful tool for auditing algorithms in production settings. © 2022 The Authors},
	author_keywords = {AI ethics; attention inequality; DSML 2: Proof-of-concept: Data science output has been formulated, implemented, and tested for one domain/problem; inequality metrics; ranking and recommendation; responsible machine learning},
	keywords = {Social networking (online); AI ethic; Algorithmics; Attention inequality; Domain problems; DSML 2: proof-of-concept: data science output have been formulated, implemented, and tested for one domain/problem; Inequality metric; Machine-learning; Proof of concept; Ranking and recommendation; Responsible machine learning; Machine learning},
	correspondence_address = {T. Lazovich; Twitter, Inc., San Francisco, 94103, United States; email: tlazovich@twitter.com},
	publisher = {Cell Press},
	issn = {26663899},
	language = {English},
	abbrev_source_title = {Patterns},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Van Olmen2022,
	author = {Van Olmen, Josefien and Van Nooten, Jens and Philips, Hilde and Sollie, Annet and Daelemans, Walter},
	title = {Predicting COVID-19 Symptoms From Free Text in Medical Records Using Artificial Intelligence: Feasibility Study},
	year = {2022},
	journal = {JMIR Medical Informatics},
	volume = {10},
	number = {4},
	doi = {10.2196/37771},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129631980&doi=10.2196%2f37771&partnerID=40&md5=98345555b7965760f5d6cf5e51c517cc},
	affiliations = {Department of Family Medicine and Population Health, University of Antwerp, Antwerp, Belgium; Computational Linguistics, Psycholinguistics and Sociolinguistics Research Centre, University of Antwerp, Antwerp, Belgium},
	abstract = {Background: Electronic medical records have opened opportunities to analyze clinical practice at large scale. Structured registries and coding procedures such as the International Classification of Primary Care further improved these procedures. However, a large part of the information about the state of patient and the doctors' observations is still entered in free text fields. The main function of those fields is to report the doctor's line of thought, to remind oneself and his or her colleagues on follow-up actions, and to be accountable for clinical decisions. These fields contain rich information that can be complementary to that in coded fields, and until now, they have been hardly used for analysis. Objective: This study aims to develop a prediction model to convert the free text information on COVID-19-related symptoms from out of hours care electronic medical records into usable symptom-based data that can be analyzed at large scale. Methods: The design was a feasibility study in which we examined the content of the raw data, steps and methods for modelling, as well as the precision and accuracy of the models. A data prediction model for 27 preidentified COVID-19-relevant symptoms was developed for a data set derived from the database of primary-care out-of-hours consultations in Flanders. A multiclass, multilabel categorization classifier was developed. We tested two approaches, which were (1) a classical machine learning-based text categorization approach, Binary Relevance, and (2) a deep neural network learning approach with BERTje, including a domain-adapted version. Ethical approval was acquired through the Institutional Review Board of the Institute of Tropical Medicine and the ethics committee of the University Hospital of Antwerpen (ref 20/50/693). Results: The sample set comprised 3957 fields. After cleaning, 2313 could be used for the experiments. Of the 2313 fields, 85% (n=1966) were used to train the model, and 15% (n=347) for testing. The normal BERTje model performed the best on the data. It reached a weighted F1 score of 0.70 and an exact match ratio or accuracy score of 0.38, indicating the instances for which the model has identified all correct codes. The other models achieved respectable results as well, ranging from 0.59 to 0.70 weighted F1. The Binary Relevance method performed the best on the data without a frequency threshold. As for the individual codes, the domain-adapted version of BERTje performs better on several of the less common objective codes, while BERTje reaches higher F1 scores for the least common labels especially, and for most other codes in general. Conclusions: The artificial intelligence model BERTje can reliably predict COVID-19-related information from medical records using text mining from the free text fields generated in primary care settings. This feasibility study invites researchers to examine further possibilities to use primary care routine data. © Josefien Van Olmen, Jens Van Nooten, Hilde Philips, Annet Sollie, Walter Daelemans.},
	author_keywords = {artificial intelligence; coding procedure; COVID-19; electronic medical records; feasibility study; natural language processing; precision model; prediction model; primary care; structured registry; text mining},
	correspondence_address = {J. Van Olmen; Department of Family Medicine and Population Health, University of Antwerp, Prinsstraat 13 Antwerp, 2000, Belgium; email: josefien.vanolmen@uantwerpen.be},
	publisher = {JMIR Publications Inc.},
	issn = {22919694},
	language = {English},
	abbrev_source_title = {JMIR Med. Inform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Rubeis2022,
	author = {Rubeis, Giovanni and Dubbala, Keerthi and Metzler, Ingrid},
	title = {“Democratizing” artificial intelligence in medicine and healthcare: Mapping the uses of an elusive term},
	year = {2022},
	journal = {Frontiers in Genetics},
	volume = {13},
	doi = {10.3389/fgene.2022.902542},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136904044&doi=10.3389%2ffgene.2022.902542&partnerID=40&md5=7bda3b5ef759c13bc1c7b0fc5f4e964e},
	affiliations = {Karl Landsteiner University of Health Sciences, Krems an der Donau, Austria},
	abstract = {Introduction: “Democratizing” artificial intelligence (AI) in medicine and healthcare is a vague term that encompasses various meanings, issues, and visions. This article maps the ways this term is used in discourses on AI in medicine and healthcare and uses this map for a normative reflection on how to direct AI in medicine and healthcare towards desirable futures. Methods: We searched peer-reviewed articles from Scopus, Google Scholar, and PubMed along with grey literature using search terms “democrat*”, “artificial intelligence” and “machine learning”. We approached both as documents and analyzed them qualitatively, asking: What is the object of democratization? What should be democratized, and why? Who is the demos who is said to benefit from democratization? And what kind of theories of democracy are (tacitly) tied to specific uses of the term? Results: We identified four clusters of visions of democratizing AI in healthcare and medicine: 1) democratizing medicine and healthcare through AI, 2) multiplying the producers and users of AI, 3) enabling access to and oversight of data, and 4) making AI an object of democratic governance. Discussion: The envisioned democratization in most visions mainly focuses on patients as consumers and relies on or limits itself to free market-solutions. Democratization in this context requires defining and envisioning a set of social goods, and deliberative processes and modes of participation to ensure that those affected by AI in healthcare have a say on its development and use. Copyright © 2022 Rubeis, Dubbala and Metzler.},
	author_keywords = {artificial intelligence; big data; democratization; digital technologies; ethics},
	keywords = {adult; article; artificial intelligence; big data; consumer; democracy; digital technology; ethics; female; grey literature; human; machine learning; male; Medline; Scopus; search engine; systematic review; vision},
	correspondence_address = {G. Rubeis; Karl Landsteiner University of Health Sciences, Krems an der Donau, Austria; email: giovanni.rubeis@kl.ac.at},
	publisher = {Frontiers Media S.A.},
	issn = {16648021},
	language = {English},
	abbrev_source_title = {Front. Genet.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Bærøe2022,
	author = {Bærøe, Kristine and Gundersen, Torbjørn and Henden, Edmund and Rommetveit, Kjetil},
	title = {Can medical algorithms be fair? Three ethical quandaries and one dilemma},
	year = {2022},
	journal = {BMJ Health and Care Informatics},
	volume = {29},
	number = {1},
	doi = {10.1136/bmjhci-2021-100445},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127929178&doi=10.1136%2fbmjhci-2021-100445&partnerID=40&md5=4f6fe85b0329bded57822a6fac30baee},
	affiliations = {Department of Global Public Health and Primary Care, University of Bergen, Bergen, Norway; Centre for the Study of Professions, Oslo Metropolitan University, Akershus, Oslo, Norway; Center for the Study of the Sciences and Humanities, University of Bergen, Hordaland, Bergen, Norway},
	abstract = {Objective To demonstrate what it takes to reconcile the idea of fairness in medical algorithms and machine learning (ML) with the broader discourse of fairness and health equality in health research. Method The methodological approach used in this paper is theoretical and ethical analysis. Result We show that the question of ensuring comprehensive ML fairness is interrelated to three quandaries and one dilemma. Discussion As fairness in ML depends on a nexus of inherent justice and fairness concerns embedded in health research, a comprehensive conceptualisation is called for to make the notion useful. Conclusion This paper demonstrates that more analytical work is needed to conceptualise fairness in ML so it adequately reflects the complexity of justice and fairness concerns within the field of health research.  © },
	author_keywords = {artificial intelligence; delivery of health care; health equity; machine learning; public health},
	keywords = {Algorithms; Humans; Machine Learning; Social Justice; algorithm; Article; ethical dilemma; health care access; human; machine learning; medical ethics; medical research; priority journal; algorithm; machine learning; social justice},
	correspondence_address = {K. Bærøe; Department of Global Public Health and Primary Care, University of Bergen, Bergen, Norway; email: kristine.baroe@uib.no},
	publisher = {BMJ Publishing Group},
	issn = {26321009},
	pmid = {35396245},
	language = {English},
	abbrev_source_title = {BMJ Heal. care inf.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Bear Don't Walk2022,
	author = {Bear Don't Walk, Oliver J. and Nieva, Harry Reyes and Lee, Sandra Soo-Jin and Elhadad, Noémie},
	title = {A scoping review of ethics considerations in clinical natural language processing},
	year = {2022},
	journal = {JAMIA Open},
	volume = {5},
	number = {2},
	doi = {10.1093/jamiaopen/ooac039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134874701&doi=10.1093%2fjamiaopen%2fooac039&partnerID=40&md5=95bd4b3ef2bf461a18c5778c20bbdda5},
	affiliations = {Department of Biomedical Informatics, Columbia University, New York, NY, United States; Department of Medicine, Harvard Medical School, Boston, MA, United States; Department of Medical Humanities and Ethics, Columbia University, New York, NY, United States},
	abstract = {Objectives: To review through an ethics lens the state of research in clinical natural language processing (NLP) for the study of bias and fairness, and to identify gaps in research. Methods: We queried PubMed and Google Scholar for articles published between 2015 and 2021 concerning clinical NLP, bias, and fairness. We analyzed articles using a framework that combines the machine learning (ML) development process (ie, design, data, algorithm, and critique) and bioethical concepts of beneficence, nonmaleficence, autonomy, justice, as well as explicability. Our approach further differentiated between biases of clinical text (eg, systemic or personal biases in clinical documentation towards patients) and biases in NLP applications. Results: Out of 1162 articles screened, 22 met criteria for full text review. We categorized articles based on the design (N = 2), data (N = 12), algorithm (N = 14), and critique (N = 17) phases of the ML development process. Discussion: Clinical NLP can be used to study bias in applications reliant on clinical text data as well as explore biases in the healthcare setting. We identify 3 areas of active research that require unique ethical considerations about the potential for clinical NLP to address and/or perpetuate bias: (1) selecting metrics that interrogate bias in models; (2) opportunities and risks of identifying sensitive patient attributes; and (3) best practices in reconciling individual autonomy, leveraging patient data, and inferring and manipulating sensitive information of subgroups. Finally, we address the limitations of current ethical frameworks to fully address concerns of justice. Clinical NLP is a rapidly advancing field, and assessing current approaches against ethical considerations can help the discipline use clinical NLP to explore both healthcare biases and equitable NLP applications.  © 2022 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association.},
	author_keywords = {bias; ethically informed; fairness; natural language processing},
	keywords = {adult; algorithm; beneficence; documentation; ethics; female; human; justice; machine learning; male; Medline; natural language processing; nonmaleficence; patient coding; review; risk assessment; search engine; systematic review},
	correspondence_address = {O.J. Bear Don't Walk; Department of Biomedical Informatics, Columbia University, New York, 622 West 168th Street, PH20, 10032, United States; email: ob2285@cumc.columbia.edu},
	publisher = {Oxford University Press},
	issn = {25742531},
	language = {English},
	abbrev_source_title = {JAMIA Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Doerr202234,
	author = {Doerr, Megan and Meeder, Sara},
	title = {Big Health Data Research and Group Harm: The Scope of IRB Review},
	year = {2022},
	journal = {Ethics and Human Research},
	volume = {44},
	number = {4},
	pages = {34 – 38},
	doi = {10.1002/eahr.500130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133602196&doi=10.1002%2feahr.500130&partnerID=40&md5=e065bb7e37af83024c4a9d9551b57657},
	affiliations = {Sage Bionetworks, United States; Maimonides Medical Center, United States},
	abstract = {Much of precision medicine is driven by big health data research—the analysis of massive datasets representing the complex web of genetic, behavioral, environmental, and other factors that impact human well-being. There are some who point to the Common Rule, the regulation governing federally funded human subjects research, as a regulatory panacea for all types of big health data research. But how well does the Common Rule fit the regulatory needs of this type of research? This article suggests that harms that may arise from artificial intelligence and machine-learning technologies used in big health data research—and the increased likelihood that this research will affect public policy—mean it is time to consider whether the current human research regulations prohibit comprehensive, ethical review of big health data research that may result in group harm. © 2022 by The Hastings Center. All rights reserved.},
	author_keywords = {artificial intelligence; big data; big health data; Common Rule; group harm; human research ethics; human subjects research; institutional review board (IRB); machine learning; research risks},
	keywords = {Artificial Intelligence; Big Data; Ethical Review; Ethics Committees, Research; Humans; article; artificial intelligence; big data; ethics; health data; human; human experiment; institutional review; machine learning; public policy; research ethics; professional standard},
	publisher = {John Wiley and Sons Inc},
	issn = {25782363},
	pmid = {35802789},
	language = {English},
	abbrev_source_title = {Eth.  Hum. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Pachamanova2022178,
	author = {Pachamanova, Dessislava and Tilson, Vera and Dwyer-Matzky, Keely},
	title = {Machine Learning, Ethics, and Change Management: A Data-Driven Approach to Improving Hospital Observation Unit Operations},
	year = {2022},
	journal = {INFORMS Transactions on Education},
	volume = {22},
	number = {3},
	pages = {178 – 187},
	doi = {10.1287/ited.2021.0251ca},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140092958&doi=10.1287%2fited.2021.0251ca&partnerID=40&md5=a7dcd2580d625084114a5ade3760069b},
	affiliations = {Babson College, Wellesley, 02457, MA, United States; Simon Business School, University of Rochester, Rochester, 14627, NY, United States; Departments of Medicine and Pediatrics, School of Medicine and Dentistry and Golisano Children’s Hospital, University of Rochester Medical Center, Rochester, 14642, NY, United States},
	abstract = {This case discusses a process improvement project aimed at maximizing the use of hospital capacity as the flu season looms. Dr. Erin Kelly heads the observation unit and turns to predictive models to improve the assignment of patients to her unit. The case covers three major themes: (1) data analytics life cycle and interface of predictive and prescriptive analytics in the context of process improvement, (2) design and ethical application of machine learning models, and (3) effecting organizational change to operationalize the findings of the analysis. Realistic data, R code, and Excel models are provided. The rich context of the case allows for discussing change management in a healthcare organization, analytics problem framing and model mapping, service process capacity analysis and Little’s law, data summaries and visualizations, interpretable machine learning algorithms, evaluations of predictive model performance, algorithmic bias, and dealing with dirty data. The case is appropriate for use in courses in machine learning, business analytics, operations management, and operations research, both at the advanced undergraduate level and at the master’s/MBA level. © 2021 The Author(s)},
	author_keywords = {change management; data analytics life cycle; ethics; hospital observation unit operations; machine learning; predictive analytics; prescriptive analytics; service process capacity analysis},
	correspondence_address = {D. Pachamanova; Babson College, Wellesley, 02457, United States; email: dpachamanova@babson.edu},
	publisher = {INFORMS Inst.for Operations Res.and the Management Sciences},
	issn = {15320545},
	language = {English},
	abbrev_source_title = {Trans. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Liu2022424,
	author = {Liu, David and Nanayakkara, Priyanka and Sakha, Sarah Ariyan and Abuhamad, Grace and Blodgett, Su Lin and Diakopoulos, Nicholas and Hullman, Jessica R. and Eliassi-Rad, Tina},
	title = {Examining Responsibility and Deliberation in AI Impact Statements and Ethics Reviews},
	year = {2022},
	journal = {AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {424 – 435},
	doi = {10.1145/3514094.3534155},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137163793&doi=10.1145%2f3514094.3534155&partnerID=40&md5=1c1e7df728794b0a5ebf3ba2db475038},
	affiliations = {Northeastern University, Boston, MA, United States; Northwestern University, Evanston, IL, United States; International Rescue Committee, New York, NY, United States; ServiceNow, Montreal, PQ, Canada; Microsoft Research, Montreal, Canada},
	abstract = {The artificial intelligence research community is continuing to grapple with the ethics of its work by encouraging researchers to discuss potential positive and negative consequences. Neural Information Processing Systems (NeurIPS), a top-Tier conference for machine learning and artificial intelligence research, first required a statement of broader impact in 2020. In 2021, NeurIPS updated their call for papers such that 1) the impact statement focused on negative societal impacts and was not required but encouraged, 2) a paper checklist and ethics guidelines were provided to authors, and 3) papers underwent ethics reviews and could be rejected on ethical grounds. In light of these changes, we contribute a qualitative analysis of 231 impact statements and all publicly-Available ethics reviews. We describe themes arising around the ways in which authors express agency (or lack thereof) in identifying or mitigating negative consequences and assign responsibility for mitigating negative societal impacts. We also characterize ethics reviews in terms of the types of issues raised by ethics reviewers (falling into categories of policy-oriented and non-policy-oriented), recommendations ethics reviewers make to authors (e.g., in terms of adding or removing content), and interaction between authors, ethics reviewers, and original reviewers (e.g., consistency between issues flagged by original reviewers and those discussed by ethics reviewers). Finally, based on our analysis we make recommendations for how authors can be further supported in engaging with the ethical implications of their work.  © 2022 Owner/Author.},
	author_keywords = {ai ethics; broader impact; ethics review; impact statements},
	keywords = {Artificial intelligence; Ethical technology; Ai ethic; Artificial intelligence research; Broader impacts; Community IS; Ethic review; Impact statement; Neural information processing systems; Policy-oriented; Research communities; Societal impacts; Economic and social effects},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039247-1},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2022; Conference date: 1 August 2022 through 3 August 2022; Conference code: 181805; All Open Access, Bronze Open Access}
}

@CONFERENCE{Ashurst20222047,
	author = {Ashurst, Carolyn and Hine, Emmie and Sedille, Paul and Carlier, Alexis},
	title = {AI Ethics Statements: Analysis and Lessons Learnt from NeurIPS Broader Impact Statements},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {2047 – 2056},
	doi = {10.1145/3531146.3533780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132965984&doi=10.1145%2f3531146.3533780&partnerID=40&md5=5b698c3a03043a895c0efdac23029619},
	affiliations = {Alan Turing Institute, United Kingdom; Oxford Internet Institute, United States; Harvard Kennedy School, United States; Centre for the Governance of Ai, United Kingdom},
	abstract = {Ethics statements have been proposed as a mechanism to increase transparency and promote reflection on the societal impacts of published research. In 2020, the machine learning (ML) conference NeurIPS broke new ground by requiring that all papers include a broader impact statement. This requirement was removed in 2021, in favour of a checklist approach. The 2020 statements therefore provide a unique opportunity to learn from the broader impact experiment: to investigate the benefits and challenges of this and similar governance mechanisms, as well as providing an insight into how ML researchers think about the societal impacts of their own work. Such learning is needed as NeurIPS and other venues continue to question and adapt their policies. To enable this, we have created a dataset containing the impact statements from all NeurIPS 2020 papers, along with additional information such as affiliation type, location and subject area, and a simple visualisation tool for exploration. We also provide an initial quantitative analysis of the dataset, covering representation, engagement, common themes, and willingness to discuss potential harms alongside benefits. We investigate how these vary by geography, affiliation type and subject area. Drawing on these findings, we discuss the potential benefits and negative outcomes of ethics statement requirements, and their possible causes and associated challenges. These lead us to several lessons to be learnt from the 2020 requirement: (i) the importance of creating the right incentives, (ii) the need for clear expectations and guidance, and (iii) the importance of transparency and constructive deliberation. We encourage other researchers to use our dataset to provide additional analysis, to further our understanding of how researchers responded to this requirement, and to investigate the benefits and challenges of this and related mechanisms. © 2022 ACM.},
	author_keywords = {AI governance; broader impacts; conference policies; ethics statements; NeurIPS policies; research ethics},
	keywords = {Economic and social effects; Ethical technology; AI governance; Benefit and challenges; Broader impacts; Conference policy; Ethic statement; Learn+; Machine-learning; NeurIPS policy; Research ethics; Societal impacts; Transparency},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210}
}

@CONFERENCE{Yurrita2022535,
	author = {Yurrita, Mireia and Murray-Rust, Dave and Balayn, Agathe and Bozzon, Alessandro},
	title = {Towards a multi-stakeholder value-based assessment framework for algorithmic systems},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {535 – 563},
	doi = {10.1145/3531146.3533118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132966395&doi=10.1145%2f3531146.3533118&partnerID=40&md5=7cb2aa18afbe48cee3093e66104d33bc},
	affiliations = {Human Information Communication Design, Delft University of Technology, Netherlands; Web Information Systems, Tu Delft, Netherlands; Knowledge and Intelligence Design, Tu Delft, Netherlands},
	abstract = {In an effort to regulate Machine Learning-driven (ML) systems, current auditing processes mostly focus on detecting harmful algorithmic biases. While these strategies have proven to be impactful, some values outlined in documents dealing with ethics in ML-driven systems are still underrepresented in auditing processes. Such unaddressed values mainly deal with contextual factors that cannot be easily quantified. In this paper, we develop a value-based assessment framework that is not limited to bias auditing and that covers prominent ethical principles for algorithmic systems. Our framework presents a circular arrangement of values with two bipolar dimensions that make common motivations and potential tensions explicit. In order to operationalize these high-level principles, values are then broken down into specific criteria and their manifestations. However, some of these value-specific criteria are mutually exclusive and require negotiation. As opposed to some other auditing frameworks that merely rely on ML researchers' and practitioners' input, we argue that it is necessary to include stakeholders that present diverse standpoints to systematically negotiate and consolidate value and criteria tensions. To that end, we map stakeholders with different insight needs, and assign tailored means for communicating value manifestations to them. We, therefore, contribute to current ML auditing practices with an assessment framework that visualizes closeness and tensions between values and we give guidelines on how to operationalize them, while opening up the evaluation and deliberation process to a wide range of stakeholders. © 2022 Owner/Author.},
	author_keywords = {algorithm assessment; ML development and deployment pipeline; multi-stakeholder; values},
	keywords = {'current; Algorithm assessment; Algorithmics; Auditing process; Driven system; Machine learning-driven development and deployment pipeline; Machine-learning; Multi-stakeholder; Value; Value-based assessment},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Gevaert2022,
	author = {Gevaert, Caroline M.},
	title = {Explainable AI for earth observation: A review including societal and regulatory perspectives},
	year = {2022},
	journal = {International Journal of Applied Earth Observation and Geoinformation},
	volume = {112},
	doi = {10.1016/j.jag.2022.102869},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133305595&doi=10.1016%2fj.jag.2022.102869&partnerID=40&md5=694eb37b8be910cc4fd29a25f7c02b5b},
	affiliations = {Dept. of Earth Observation Science, ITC, University of Twente, Enschede, Netherlands},
	abstract = {Artificial intelligence and machine learning are ubiquitous in the domain of Earth Observation (EO) and Remote Sensing. Congruent to their success in the domain of computer vision, they have proven to obtain high accuracies for EO applications. Yet experts of EO should also consider the weaknesses of complex, machine-learning models before adopting them for specific applications. One such weakness is the lack of explainability of complex deep learning models. This paper reviews published examples of explainable ML or explainable AI in the field of Earth Observation. Explainability methods are classified as: intrinsic versus post-hoc, model-specific versus model-agnostic, and global versus local explanations and examples of each type are provided. This paper also identifies key explainability requirements identified the social sciences and upcoming regulatory recommendations from UNESCO Ethics of Artificial Intelligence and requirements from the EU draft Artificial Intelligence Act and analyzes whether these limitations are sufficiently addressed in the field of EO. The findings indicate that there is a lack of clarity regarding which models can be considered interpretable or not. EO applications often utilize Random Forests as an “interpretable” benchmark algorithm to compare to complex deep-learning models even though social sciences clearly argue that large Random Forests cannot be considered as such. Secondly, most explanations target domain experts and not possible users of the algorithm, regulatory bodies, or those who might be affected by an algorithm's decisions. Finally, publications tend to simply provide explanations without testing the usefulness of the explanation by the intended audience. In light of these societal and regulatory considerations, a framework is provided to guide the selection of an appropriate machine learning algorithm based on the availability of simpler algorithms with a high predictive accuracy as well as the purpose and intended audience of the explanation. © 2022 The Author(s)},
	author_keywords = {Earth observation; Ethics; Explainable artificial intelligence; Machine learning; Regulations; Remote sensing},
	keywords = {algorithm; artificial intelligence; computer simulation; EOS; ethics; geodesy; machine learning; regulatory approach; remote sensing},
	publisher = {Elsevier B.V.},
	issn = {15698432},
	language = {English},
	abbrev_source_title = {Int. J. Appl. Earth Obs. Geoinformation},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Milton2022,
	author = {Milton, Austin G and Lau, Stephan and Kremer, Karlea L and Rao, Sushma R and Mas, Emilie and Snel, Marten F and Trim, Paul J and Sharma, Deeksha and Edwards, Suzanne and Jenkinson, Mark and Kleinig, Timothy and Noschka, Erik and Hamilton-Bruce, Monica Anne and Koblar, Simon A},
	title = {FAST-IT: F ind A S imple T est- I n T IA (transient ischaemic attack): a prospective cohort study to develop a multivariable prediction model for diagnosis of TIA through proteomic discovery and candidate lipid mass spectrometry, neuroimaging and machine learning - study protocol},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {4},
	doi = {10.1136/bmjopen-2020-045908},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127476787&doi=10.1136%2fbmjopen-2020-045908&partnerID=40&md5=2b380b607cf2add5030cecf1a85ed933},
	affiliations = {Stroke Research Programme, Central Adelaide Local Health Network, Adelaide, SA, Australia; Faculty of Engineering, Computer and Mathematical Sciences, Australian Institute for Machine Learning, University of Adelaide, Adelaide, SA, Australia; South Australian Health and Medical Research Institute, Adelaide, SA, Australia; Adelaide Medical School, Stroke Research Programme, University of Adelaide Faculty of Health and Medical Sciences, Adelaide, SA, Australia; Proteomics, Metabolomics and MS-imaging Core Facility, South Australian Health and Medical Research Institute, Adelaide, SA, Australia; Adelaide Medical School, University of Adelaide Faculty of Health and Medical Sciences, Adelaide, SA, Australia; Sa Pathology - Genetics and Molecular Pathology, Women's and Children's Hospital Adelaide, North Adelaide, SA, Australia; Adelaide Health Technology Assessment, University of Adelaide Faculty of Health and Medical Sciences, Adelaide, SA, Australia; Department of Neurology, Royal Adelaide Hospital, Adelaide, SA, Australia; School of Animal and Veterinary Sciences, University of Adelaide, Adelaide, SA, Australia},
	abstract = {Introduction Transient ischaemic attack (TIA) may be a warning sign of stroke and difficult to differentiate from minor stroke and TIA-mimics. Urgent evaluation and diagnosis is important as treating TIA early can prevent subsequent strokes. Recent improvements in mass spectrometer technology allow quantification of hundreds of plasma proteins and lipids, yielding large datasets that would benefit from different approaches including machine learning. Using plasma protein, lipid and radiological biomarkers, our study will develop predictive algorithms to distinguish TIA from minor stroke (positive control) and TIA-mimics (negative control). Analysis including machine learning employs more sophisticated modelling, allowing non-linear interactions, adapting to datasets and enabling development of multiple specialised test-panels for identification and differentiation. Methods and analysis Patients attending the Emergency Department, Stroke Ward or TIA Clinic at the Royal Adelaide Hospital with TIA, minor stroke or TIA-like symptoms will be recruited consecutively by staff-alert for this prospective cohort study. Advanced neuroimaging will be performed for each participant, with images assessed independently by up to three expert neurologists. Venous blood samples will be collected within 48 hours of symptom onset. Plasma proteomic and lipid analysis will use advanced mass spectrometry (MS) techniques. Principal component analysis and hierarchical cluster analysis will be performed using MS software. Output files will be analysed for relative biomarker quantitative differences between the three groups. Differences will be assessed by linear regression, one-way analysis of variance, Kruskal-Wallis H-test, χ 2 test or Fisher's exact test. Machine learning methods will also be applied including deep learning using neural networks. Ethics and dissemination Patients will provide written informed consent to participate in this grant-funded study. The Central Adelaide Local Health Network Human Research Ethics Committee approved this study (HREC/18/CALHN/384; R20180618). Findings will be disseminated through peer-reviewed publication and conferences; data will be managed according to our Data Management Plan (DMP2020-00062). ©},
	author_keywords = {CT; health informatics; MRI; protocols & guidelines; stroke},
	keywords = {Humans; Ischemic Attack, Transient; Lipids; Machine Learning; Mass Spectrometry; Neuroimaging; Prospective Studies; Proteomics; biological marker; plasma protein; lipid; Article; artificial neural network; blood sampling; clinical assessment; clinical outcome; cohort analysis; deep learning; hierarchical clustering; human; informed consent; linear regression analysis; lipid analysis; lipid blood level; liquid chromatography-mass spectrometry; machine learning; mass spectrometry; neuroimaging; nuclear magnetic resonance imaging; practice guideline; prediction; prospective study; proteomics; quantitative analysis; software; transient ischemic attack; diagnostic imaging; machine learning; mass spectrometry; neuroimaging; proteomics; transient ischemic attack},
	correspondence_address = {A.G. Milton; Stroke Research Programme, Central Adelaide Local Health Network, Adelaide, Australia; email: austin.milton@adelaide.edu.au},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35365506},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Korjian2022,
	author = {Korjian, Serge and Gibson, C. Michael},
	title = {Digital technologies and the democratization of clinical research: Social media, wearables, and artificial intelligence},
	year = {2022},
	journal = {Contemporary Clinical Trials},
	volume = {117},
	doi = {10.1016/j.cct.2022.106767},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129748757&doi=10.1016%2fj.cct.2022.106767&partnerID=40&md5=a34023e82955fd80942ea0a38aa1a316},
	affiliations = {Cardiovascular Division, Department of Medicine, Beth Israel Deaconess Medical, Harvard Medical School, Boston, MA, United States},
	abstract = {With unprecedented access to the internet and media devices, a cultural shift in healthcare practice and research is already underway. Social media has transformed the way we communicate and has found applications in healthcare research from data sharing to study recruitment. Wearables and personal health monitoring platforms have become increasingly widespread in the past decade allowing for novel studies with remote clinical monitoring and data collection. Furthermore, artificial intelligence has evolved with the advent of machine learning to exponentially improve prediction algorithms and become a powerful tool for clinical decision making and research. These technologies offer unprecedented opportunities to advance clinical research, while empowering patients to be active participants. As these digital tools evolve, our understanding of their advantages and pitfalls will help us optimize their use while ensuring ethical practices and most importantly, patient safety. © 2022},
	author_keywords = {Artificial intelligence; Pragmatic clinical trials; Research ethics; Social media; Wearables},
	keywords = {Artificial Intelligence; Digital Technology; Humans; Machine Learning; Social Media; Wearable Electronic Devices; adult; algorithm; artificial intelligence; clinical decision making; clinical monitoring; clinical research; digital technology; drug safety; human; machine learning; note; patient safety; pragmatic trial; prediction; research ethics; social media; artificial intelligence; electronic device},
	correspondence_address = {C.M. Gibson; Division of Cardiovascular Medicine, Department of Medicine, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, 930 Commonwealth Avenue #3, 02215, United States; email: mgibson@perfuse.org},
	publisher = {Elsevier Inc.},
	issn = {15517144},
	pmid = {35462032},
	language = {English},
	abbrev_source_title = {Contemp. Clin. Trials},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Raper2022,
	author = {Raper, Rebecca and Boeddinghaus, Jona and Coeckelbergh, Mark and Gross, Wolfgang and Campigotto, Paolo and Lincoln, Craig N.},
	title = {Sustainability Budgets: A Practical Management and Governance Method for Achieving Goal 13 of the Sustainable Development Goals for AI Development},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {7},
	doi = {10.3390/su14074019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127852456&doi=10.3390%2fsu14074019&partnerID=40&md5=6e7ed761fd5f166b45271131ae8bc37c},
	affiliations = {Department of Philosophy, University of Vienna, Vienna, 1010, Austria; Gradient Zero, Vienna, 1010, Austria},
	abstract = {Climate change is a global priority. In 2015, the United Nations (UN) outlined its Sustainable Development Goals (SDGs), which stated that taking urgent action to tackle climate change and its impacts was a key priority. The 2021 World Climate Summit finished with calls for governments to take tougher measures towards reducing their carbon footprints. However, it is not obvious how governments can make practical implementations to achieve this goal. One challenge towards achieving a reduced carbon footprint is gaining awareness of how energy exhaustive a system or mechanism is. Artificial Intelligence (AI) is increasingly being used to solve global problems, and its use could potentially solve challenges relating to climate change, but the creation of AI systems often requires vast amounts of, up front, computing power, and, thereby, it can be a significant contributor to greenhouse gas emissions. If governments are to take the SDGs and calls to reduce carbon footprints seriously, they need to find a management and governance mechanism to (i) audit how much their AI system ‘costs’ in terms of energy consumption and (ii) incentivise individuals to act based upon the auditing outcomes, in order to avoid or justify politically controversial restrictions that may be seen as bypassing the creativity of developers. The idea is thus to find a practical solution that can be implemented in software design that incentivises and rewards and that respects the autonomy of developers and designers to come up with smart solutions. This paper proposes such a sustainability management mechanism by introducing the notion of ‘Sustainability Budgets’—akin to Privacy Budgets used in Differential Privacy—and by using these to introduce a ‘Game’ where participants are rewarded for designing systems that are ‘energy efficient’. Participants in this game are, among others, the Machine Learning developers themselves, which is a new focus for this problem that this text introduces. The paper later expands this notion to sustainability management in general and outlines how it might fit into a wider governance framework. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {AI; AI governance; artificial intelligence; differential privacy; ethical AI; ethics; sustainability},
	keywords = {autonomy; carbon footprint; climate change; governance approach; greenhouse gas; management practice; sustainability; Sustainable Development Goal; United Nations},
	correspondence_address = {R. Raper; Department of Philosophy, University of Vienna, Vienna, 1010, Austria; email: rebecca.raper@univie.ac.at},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Cordell2022132,
	author = {Cordell, Ryan},
	title = {Closing the Loop: Bridging Machine Learning (ML) Research and Library Systems},
	year = {2022},
	journal = {Library Trends},
	volume = {71},
	number = {1},
	pages = {132 – 143},
	doi = {10.1353/lib.2023.0008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164370953&doi=10.1353%2flib.2023.0008&partnerID=40&md5=6dfd4579a645a5c57707d4abb8671904},
	affiliations = {School of Information Sciences, Department of English, University of Illinois Urbana-Champaign, United States; Society of Critical Bibliography, Rare Book School, United States},
	abstract = {This article argues that if libraries are to take leadership in conversations about the ethics and application of machine learning (ML) to cultural materials, they must move beyond the “perpetual future tense” of most library ML proposals and experiments, narrowing the gap separating promises that ML will enhance discoverability for library materials and the library systems through which most users encounter those materials. Even as ML methods have grown more powerful, nuanced, and sophisticated, ambitious hopes that ML might help better identify and describe vast library collections have been largely unmet, at least from the perspective of library patrons, researchers, and students. To address this gap, the article argues that libraries and ML researchers should work together to develop iterative, experimental, and even speculative interfaces that allow users to explore collections through ML-derived patterns that can enhance library data while educating users about ML processes, decisions, and biases. © 2022, Johns Hopkins University Press. All rights reserved.},
	publisher = {Johns Hopkins University Press},
	issn = {00242594},
	language = {English},
	abbrev_source_title = {Libr. Trends},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Constantinescu2022,
	author = {Constantinescu, Mihaela and Vică, Constantin and Uszkai, Radu and Voinea, Cristina},
	title = {Blame It on the AI? On the Moral Responsibility of Artificial Moral Advisors},
	year = {2022},
	journal = {Philosophy and Technology},
	volume = {35},
	number = {2},
	doi = {10.1007/s13347-022-00529-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128193016&doi=10.1007%2fs13347-022-00529-z&partnerID=40&md5=f9d0fccb10b643dcb07b9754f076d03d},
	affiliations = {Faculty of Philosophy, University of Bucharest, 204 Splaiul Independentei St., Bucharest, RO-060024, Romania; Department of Philosophy and Social Sciences, Bucharest University of Economic Studies, Bucharest, Romania},
	abstract = {Deep learning AI systems have proven a wide capacity to take over human-related activities such as car driving, medical diagnosing, or elderly care, often displaying behaviour with unpredictable consequences, including negative ones. This has raised the question whether highly autonomous AI may qualify as morally responsible agents. In this article, we develop a set of four conditions that an entity needs to meet in order to be ascribed moral responsibility, by drawing on Aristotelian ethics and contemporary philosophical research. We encode these conditions and generate a flowchart that we call the Moral Responsibility Test. This test can be used as a tool both to evaluate whether an entity is a morally responsible agent and to inform human moral decision-making over the influencing variables of the context of action. We apply the test to the case of Artificial Moral Advisors (AMAs) and conclude that this form of AI cannot qualify as morally responsible agents. We further discuss the implications for the use of AMAs as moral enhancement and show that using AMAs to offload human responsibility is inadequate. We argue instead that AMAs could morally enhance users if they are interpreted as enablers for moral knowledge of the contextual variables surrounding human moral decision-making, with the implication that such a use might actually enlarge human moral responsibility. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Artificial Moral Advisor; Autonomous Artificial Moral Agent; Machine learning; Moral agency; Moral enhancement; Moral responsibility},
	correspondence_address = {M. Constantinescu; Faculty of Philosophy, University of Bucharest, Bucharest, 204 Splaiul Independentei St., RO-060024, Romania; email: mihaela.constantinescu@filosofie.unibuc.ro},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22105433},
	language = {English},
	abbrev_source_title = {Philos. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{De Leon-Martinez2022,
	author = {De Leon-Martinez, Santiago and Ruiz, Marta and Parra-Vargas, Elena and Chicchi-Giglioli, Irene and Courtet, Philippe and Lopez-Castroman, Jorge and Artes, Antonio and Baca-Garcia, Enrique and Porras-Segovia, Alejandro Albán and Barrigon, Maria Luisa},
	title = {Virtual reality and speech analysis for the assessment of impulsivity and decision-making: protocol for a comparison with neuropsychological tasks and self-administered questionnaires},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {7},
	doi = {10.1136/bmjopen-2021-058486},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133986081&doi=10.1136%2fbmjopen-2021-058486&partnerID=40&md5=2c95a288bfd66107827b00c929c8a92b},
	affiliations = {Department of Signal Theory and Communications, Universidad Carlos Iii de Madrid, Leganés, Spain; Department of Psychiatry, Hospital Universitario Rey Juan Carlos, Mostoles, Spain; Laboratory of Immersive Neurotechnologies (LabLENI), Universidad Politécnica de Valencia, Valencia, Spain; Department of Signal Theory and Communications, Universidad Carlos Iii de Madrid, Getafe, Spain; Unité de Recherche U1061, Institut National de la Santé et de la Recherche Médicale, Paris, France; Department of Emergency Psychiatry and Acute Care, Centre Hospitalier Universitaire de Montpellier, Montpellier, France; Department of Psychiatry, University Hospital Centre Nimes, Nimes, France; Grupo de Investigación en Psiquiatría Translacional, Instituto de Investigacion Sanitaria de la Fundacion Jimenez Diaz, Madrid, Spain; Department of Psychiatry, Hospital Universitario Fundacion Jimenez Diaz, Madrid, Spain; Universidad Catolica Del Maule, Talca, Chile; Department of Psychiatry, Madrid Autonomous University, Madrid, Spain; Department of Psychiatry, General Hospital of Villalba, Villaba, Madrid, Spain; Cibersam (Centro de Investigacion en Salud Mental), Carlos Iii Institute of Health, Madrid, Spain; Department of Psychiatry, University Hospital Infanta Elena, Madrid, Valdemoro, Spain; Division of Psychiatry, Imperial College London, London, United Kingdom; Department of Psychiatry, Hospital Universitario Virgen Del Rocío, Sevilla, Spain},
	abstract = {Introduction Impulsivity is present in a range of mental disorders and has been associated with suicide. Traditional measures of impulsivity have certain limitations, such as the lack of ecological validity. Virtual reality (VR) may overcome these issues. This study aims to validate the VR assessment tool € Spheres & Shield Maze Task' and speech analysis by comparing them with traditional measures. We hypothesise that these innovative tools will be reliable and acceptable by patients, potentially improving the simultaneous assessment of impulsivity and decision-making. Methods and analysis This study will be carried out at the University Hospital Fundación Jiménez Díaz (Madrid, Spain). Our sample will consist of adults divided into three groups: psychiatric outpatients with a history of suicidal thoughts and/or behaviours, psychiatric outpatients without such a history and healthy volunteers. The target sample size was established at 300 participants (100 per group). Participants will complete the Barratt Impulsiveness Scale 11; the Urgency, Premeditation, Perseverance, Sensation Seeking, Positive Urgency, Impulsive Behaviour Scale; Iowa Gambling Task; Continuous Performance Test; Stop signal Task, and Go/no-go task, three questions of emotional affect, the Spheres & Shield Maze Task and two satisfaction surveys. During these tasks, participant speech will be recorded. Construct validity of the VR environment will be calculated. We will also explore the association between VR-assessed impulsivity and history of suicidal thoughts and/or behaviour, and the association between speech and impulsivity and decision-making. Ethics and dissemination This study was approved by the Ethics Committee of the University Hospital Fundación Jiménez Díaz (PIC128-21_FJD). Participants will be required to provide written informed consent. The findings will be presented in a series of manuscripts that will be submitted to peer-reviewed journals for publication. Trial registration number NCT05109845; Pre-results. © Author(s) (or their employer(s)) 2022.},
	author_keywords = {adult psychiatry; impulse control disorders; suicide & self-harm},
	keywords = {Adult; Gambling; Humans; Impulsive Behavior; Neuropsychological Tests; Speech; Surveys and Questionnaires; Virtual Reality; adult; Article; Barratt Impulsiveness Scale; clinical protocol; construct validity; continuous performance test; controlled study; decision making; ecological validity; female; Go No Go task; human; impulsiveness; informed consent; machine learning; major clinical study; male; mental patient; neuropsychological test; neuropsychology; outcome assessment; outpatient; questionnaire; sample size; sensation seeking; speech analysis; suicidal ideation; task performance; university hospital; virtual reality; gambling; impulsiveness; psychology; questionnaire; speech},
	correspondence_address = {E. Baca-Garcia; Department of Psychiatry, Hospital Universitario Rey Juan Carlos, Mostoles, Spain; email: ebacgar2@yahoo.es},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35831051},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Shadbolt202228,
	author = {Shadbolt, Nigel},
	title = {“From So Simple a Beginning”: Species of Artificial Intelligence},
	year = {2022},
	journal = {Daedalus},
	volume = {151},
	number = {2},
	pages = {28 – 42},
	doi = {10.1162/DAED_a_01898},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129144833&doi=10.1162%2fDAED_a_01898&partnerID=40&md5=d22ef332fa06dee89d82cb4dd9388246},
	affiliations = {Principal of Jesus College, University of Oxford, United Kingdom},
	abstract = {Artificial intelligence has a decades-long history that exhibits alternating enthusiasm and disillusionment for the field’s scientific insights, technical accomplishments, and socioeconomic impact. Recent achievements have seen renewed claims for the transformative and disruptive effects of AI. Reviewing the history and current state of the art reveals a broad repertoire of methods and techniques developed by AI researchers. In particular, modern machine learning methods have enabled a series of AI systems to achieve superhuman performance. The exponential increases in computing power, open-source software, available data, and embedded services have been crucial to this success. At the same time, there is growing unease around whether the behavior of these systems can be rendered transparent, explainable, unbiased, and accountable. One consequence of recent AI accomplishments is a renaissance of interest around the ethics of such systems. More generally, our AI systems remain singular task-achieving architectures, often termed narrow AI. I will argue that artificial general intelligence–able to range across widely differing tasks and contexts–is unlikely to be developed, or emerge, any time soon. © 2022 by Nigel Shadbolt Published under a Creative Commons Attribution-NonCommercial 4.0 International (CC BY-NC 4.0) license.},
	publisher = {MIT Press Journals},
	issn = {00115266},
	language = {English},
	abbrev_source_title = {Daedalus},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Jili2022445,
	author = {Jili, Bulelani},
	title = {Africa: regulate surveillance technologies and personal data},
	year = {2022},
	journal = {Nature},
	volume = {607},
	number = {7919},
	pages = {445 – 448},
	doi = {10.1038/d41586-022-01949-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134384608&doi=10.1038%2fd41586-022-01949-9&partnerID=40&md5=2b03c972aaa3e205b6e6abed6482119e},
	abstract = {CCTV cameras and spyware are proliferating in the continent without checks and balances. Governments must legislate locally to prevent civil-rights abuses. © 2022, Springer Nature Limited.},
	author_keywords = {Databases; Ethics; Information technology; Machine learning; Policy},
	keywords = {Africa; Population Surveillance; Technology; algorithm; artificial intelligence; civil rights; computer security; corruption; data processing; decision making; employment; facial recognition; food insecurity; government; human; Kenya; law; Note; police; public sector; terrorism; Uganda; Africa; epidemiology; health survey; technology},
	correspondence_address = {B. Jili; email: bulelanijili@g.harvard.edu},
	publisher = {Nature Research},
	issn = {00280836},
	coden = {NATUA},
	pmid = {35851875},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Zhang2022,
	author = {Zhang, Chenchen and Zhao, Jing and Zhu, Zhe and Li, Yanxia and Li, Ke and Wang, Yuanping and Zheng, Yajuan},
	title = {Applications of Artificial Intelligence in Myopia: Current and Future Directions},
	year = {2022},
	journal = {Frontiers in Medicine},
	volume = {9},
	doi = {10.3389/fmed.2022.840498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127684470&doi=10.3389%2ffmed.2022.840498&partnerID=40&md5=04a59cdd0e5943c11b3b90a9e4b1b02d},
	affiliations = {Department of Ophthalmology, The Second Hospital of Jilin University, Changchun, China},
	abstract = {With the continuous development of computer technology, big data acquisition and imaging methods, the application of artificial intelligence (AI) in medical fields is expanding. The use of machine learning and deep learning in the diagnosis and treatment of ophthalmic diseases is becoming more widespread. As one of the main causes of visual impairment, myopia has a high global prevalence. Early screening or diagnosis of myopia, combined with other effective therapeutic interventions, is very important to maintain a patient's visual function and quality of life. Through the training of fundus photography, optical coherence tomography, and slit lamp images and through platforms provided by telemedicine, AI shows great application potential in the detection, diagnosis, progression prediction and treatment of myopia. In addition, AI models and wearable devices based on other forms of data also perform well in the behavioral intervention of myopia patients. Admittedly, there are still some challenges in the practical application of AI in myopia, such as the standardization of datasets; acceptance attitudes of users; and ethical, legal and regulatory issues. This paper reviews the clinical application status, potential challenges and future directions of AI in myopia and proposes that the establishment of an AI-integrated telemedicine platform will be a new direction for myopia management in the post-COVID-19 period. Copyright © 2022 Zhang, Zhao, Zhu, Li, Li, Wang and Zheng.},
	author_keywords = {artificial intelligence; deep learning; machine learning; myopia; telemedicine},
	keywords = {artificial intelligence; attitude to computers; calculation; coronavirus disease 2019; deep learning; disease burden; ethics; genetics; human; legal aspect; lens power; machine learning; myopia; nomenclature; prediction; preoperative evaluation; refraction error; refractive surgery; Review; screening; telemedicine},
	correspondence_address = {Y. Zheng; Department of Ophthalmology, The Second Hospital of Jilin University, Changchun, China; email: zhengyajuan124@126.com},
	publisher = {Frontiers Media S.A.},
	issn = {2296858X},
	language = {English},
	abbrev_source_title = {Front. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Penfornis2022,
	author = {Penfornis, Kristell M and Van Vliet, Milon H M and Meijer, Eline and Gebhardt, Winifred A},
	title = {Mapping the evidence on identity processes and identity-related interventions in the smoking and physical activity domains: a scoping review protocol},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {7},
	doi = {10.1136/bmjopen-2021-058405},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133981191&doi=10.1136%2fbmjopen-2021-058405&partnerID=40&md5=9b5f77494e03daae4bfd65d7cbff3378},
	affiliations = {Institute of Psychology, Unit Health, Medical & Neuropsychology, Leiden University, Leiden, Netherlands; Department of Cardiology, Leiden University Medical Center, Leiden, Netherlands; Public Health & Primary Care, Leiden University Medical Center, Leiden, Netherlands; National EHealth Living Lab, Leiden University Medical Center, Leiden, Netherlands},
	abstract = {Introduction Smoking and insufficient physical activity (PA), independently but especially in conjunction, often lead to disease and (premature) death. For this reason, there is need for effective smoking cessation and PA-increasing interventions. Identity-related interventions which aim to influence how people view themselves offer promising prospects, but an overview of the existing evidence is needed first. This is the protocol for a scoping review aiming to aggregate the evidence on identity processes and identity-related interventions in the smoking and physical activity domains. Methods The scoping review will be guided by an adaption by Levac et al of the 2005 Arksey and O'Malley methodological framework, the 2020 Preferred Reporting Items for Systematic Reviews and Meta-Analyses: Extension for Scoping Review (PRISMA-ScR) and the 2017 Joanna Briggs Institute guidelines. It will include scientific publications discussing identity (processes) and/or identity-related interventions in the context of smoking (cessation) and/or physical (in)activity, in individuals aged 12 and over. A systematic search will be carried out in multiple databases (eg, PubMed, Web of Science). Records will be independently screened against prepiloted inclusion/exclusion criteria by two reviewers, using the Active Learning for Systematic Reviews machine learning artificial intelligence and Rayyan QCRI, a screening assistant. A prepiloted charting table will be used to extract data from included full-text articles. Findings will be reported according to the PRISMA-ScR guidelines and include study quality assessment. Ethics and dissemination Ethical approval is not required for scoping reviews. Findings will aid the development of future identity-related interventions targeting smoking and physical inactivity. © Author(s) (or their employer(s)) 2022.},
	author_keywords = {Coronary heart disease; Protocols & guidelines; PUBLIC HEALTH; Substance misuse},
	keywords = {Artificial Intelligence; Delivery of Health Care; Exercise; Humans; Mass Screening; Research Design; Review Literature as Topic; Smoking; Systematic Reviews as Topic; adult; artificial intelligence; clinical assessment tool; eligibility criteria; evidence based practice; human; intervention study; machine learning; meta analysis; physical activity; practice guideline; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; publication; quality control; Review; smoking; systematic review; artificial intelligence; exercise; health care delivery; literature; mass screening; methodology; smoking; therapy},
	correspondence_address = {K.M. Penfornis; Institute of Psychology, Unit Health, Medical & Neuropsychology, Leiden University, Leiden, Netherlands; email: k.m.penfornis@fsw.leidenuniv.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35831054},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Altuntas2022,
	author = {Altuntas, Erkin and Gloor, Peter A. and Budner, Pascal},
	title = {Measuring Ethical Values with AI for Better Teamwork},
	year = {2022},
	journal = {Future Internet},
	volume = {14},
	number = {5},
	doi = {10.3390/fi14050133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131301574&doi=10.3390%2ffi14050133&partnerID=40&md5=f1cbc78c21dd7f39f86c6208f9dad0e2},
	affiliations = {Cologne Institute for Information Systems, University of Cologne, Pohligstrasse 1, Cologne, 50969, Germany; MIT Center for Collective Intelligence, 245 First Street, Cambridge, 02142, MA, United States},
	abstract = {Do employees with high ethical and moral values perform better? Comparing personality characteristics, moral values, and risk-taking behavior with individual and team performance has long been researched. Until now, these determinants of individual personality have been measured through surveys. However, individuals are notoriously bad at self-assessment. Combining machine learning (ML) with social network analysis (SNA) and natural language processing (NLP), this research draws on email conversations to predict the personal values of individuals. These values are then compared with the individual and team performance of employees. This prediction builds on a two-layered ML model. Building on features of social network structure, network dynamics, and network content derived from email conversations, we predict personality characteristics, moral values, and the risk-taking behavior of employees. In turn, we use these values to predict individual and team performance. Our results indicate that more conscientious and less extroverted team members increase the performance of their teams. Willingness to take social risks decreases the performance of innovation teams in a healthcare environment. Similarly, a focus on values such as power and self-enhancement increases the team performance of a global services provider. In sum, the contributions of this paper are twofold: it first introduces a novel approach to measuring personal values based on “honest signals” in emails. Second, these values are then used to build better teams by identifying ideal personality characteristics for a chosen task. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {business performance; email analysis; ethics; honest signals; machine learning; natural language processing; personality characteristics; social network analysis; time series analysis},
	keywords = {Behavioral research; Electronic mail; Forecasting; Learning algorithms; Machine learning; Natural language processing systems; Risk management; Social networking (online); Time series analysis; Business performance; E-mail analysis; Honest signal; Individual performance; Performance; Personality characteristic; Risk-taking behaviors; Social Network Analysis; Team performance; Time-series analysis; Philosophical aspects},
	correspondence_address = {P.A. Gloor; MIT Center for Collective Intelligence, Cambridge, 245 First Street, 02142, United States; email: pgloor@mit.edu},
	publisher = {MDPI},
	issn = {19995903},
	language = {English},
	abbrev_source_title = {Future Internet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Payne2022,
	author = {Payne, Cathy and Kondylakis, Haridimos and Koumakis, Lefteris},
	title = {Editorial: Digital Health for Palliative Care},
	year = {2022},
	journal = {Frontiers in Digital Health},
	volume = {4},
	doi = {10.3389/fdgth.2022.888419},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131257113&doi=10.3389%2ffdgth.2022.888419&partnerID=40&md5=ffe9fc0f2c28175e599a74f2b2eef9e1},
	affiliations = {European Association for Palliative Care, Vilvoorde, Belgium; Institute of Computer Science, Foundation for Research and Technology (FORTH), Heraklion, Greece},
	author_keywords = {decision support system; health informatics and information systems; MHealth (mobile health); palliative care; policy recommendations and future areas of research},
	keywords = {analgesia; anxiety; cancer palliative therapy; caregiver; cost control; cost effectiveness analysis; data protection; dyspnea; economic evaluation; Editorial; health care access; health care quality; health status; hematologic disease; hematologic malignancy; hospice care; human; machine learning; malignant neoplasm; medical ethics; palliative therapy; practice guideline; privacy; quality of life; telehealth; wellbeing},
	correspondence_address = {L. Koumakis; Institute of Computer Science, Foundation for Research and Technology (FORTH), Heraklion, Greece; email: koumakis@ics.forth.gr},
	publisher = {Frontiers Media S.A.},
	issn = {2673253X},
	language = {English},
	abbrev_source_title = {Front. Digit. Health},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{De Silva2022,
	author = {De Silva, Daswin and Alahakoon, Damminda},
	title = {An artificial intelligence life cycle: From conception to production},
	year = {2022},
	journal = {Patterns},
	volume = {3},
	number = {6},
	doi = {10.1016/j.patter.2022.100489},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131694043&doi=10.1016%2fj.patter.2022.100489&partnerID=40&md5=f4c75674be5e5b81beacf0b92f504cbd},
	affiliations = {Centre for Data, Analytics and Cognition (CDAC), La Trobe University, Bundoora, VIC, Australia},
	abstract = {This paper presents the “CDAC AI life cycle,” a comprehensive life cycle for the design, development, and deployment of artificial intelligence (AI) systems and solutions. It addresses the void of a practical and inclusive approach that spans beyond the technical constructs to also focus on the challenges of risk analysis of AI adoption, transferability of prebuilt models, increasing importance of ethics and governance, and the composition, skills, and knowledge of an AI team required for successful completion. The life cycle is presented as the progression of an AI solution through its distinct phases—design, develop, and deploy—and 19 constituent stages from conception to production as applicable to any AI initiative. This life cycle addresses several critical gaps in the literature where related work on approaches and methodologies are adapted and not designed specifically for AI. A technical and organizational taxonomy that synthesizes the functional value of AI is a further contribution of this article. © 2022 The Authors},
	author_keywords = {AI; AI deployment; AI design; AI development; AI life cycle; AI operationalization; artificial intelligence; DSML5: Mainstream: Data science output is well understood and (nearly) universally adopted; machine learning},
	keywords = {Machine learning; Risk analysis; Risk assessment; Artificial intelligence deployment; Artificial intelligence design; Artificial intelligence development; Artificial intelligence life cycle; Artificial intelligence operationalization; Artificial intelligence systems; Design development; DSML5: mainstream: data science output be well understand and (nearly) universally adopted; Intelligence life; Mainstream data; Life cycle},
	correspondence_address = {D. De Silva; Centre for Data, Analytics and Cognition (CDAC), La Trobe University, Bundoora, Australia; email: d.desilva@latrobe.edu.au},
	publisher = {Cell Press},
	issn = {26663899},
	language = {English},
	abbrev_source_title = {Patterns},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhang2022,
	author = {Zhang, Tianhao and Aftab, Waqas and Mihaylova, Lyudmila and Langran-Wheeler, Christian and Rigby, Samuel and Fletcher, David and Maddock, Steve and Bosworth, Garry},
	title = {Recent Advances in Video Analytics for Rail Network Surveillance for Security, Trespass and Suicide Prevention—A Survey},
	year = {2022},
	journal = {Sensors},
	volume = {22},
	number = {12},
	doi = {10.3390/s22124324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131304683&doi=10.3390%2fs22124324&partnerID=40&md5=8248934e25bdbd2bb9544ee032fd4986},
	affiliations = {The University of Sheffield, Sheffield, S1 3JD, United Kingdom; Network Rail, Milton Keynes, MK9 1EN, United Kingdom},
	abstract = {Railway networks systems are by design open and accessible to people, but this presents challenges in the prevention of events such as terrorism, trespass, and suicide fatalities. With the rapid advancement of machine learning, numerous computer vision methods have been developed in closed-circuit television (CCTV) surveillance systems for the purposes of managing public spaces. These methods are built based on multiple types of sensors and are designed to automatically detect static objects and unexpected events, monitor people, and prevent potential dangers. This survey focuses on recently developed CCTV surveillance methods for rail networks, discusses the challenges they face, their advantages and disadvantages and a vision for future railway surveillance systems. State-of-the-art methods for object detection and behaviour recognition applied to rail network surveillance systems are introduced, and the ethics of handling personal data and the use of automated systems are also considered. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {computer vision; image and video analytics; machine learning; rail network systems; sensors; surveillance; video anomaly detection},
	keywords = {Humans; Suicide; Surveys and Questionnaires; Television; Automation; Behavioral research; Computer vision; Machine learning; Monitoring; Object detection; Railroad transportation; Railroads; Rails; Security systems; Surveys; Anomaly detection; Closed circuit television; Image and video analytic; Network systems; Rail network system; Rail networks; Sensor; Surveillance systems; Video analytics; Video anomaly detection; human; questionnaire; suicide; television; Anomaly detection},
	correspondence_address = {L. Mihaylova; The University of Sheffield, Sheffield, S1 3JD, United Kingdom; email: l.s.mihaylova@sheffield.ac.uk},
	publisher = {MDPI},
	issn = {14248220},
	pmid = {35746103},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Huyut202260,
	author = {Huyut, Mehmet and Üstündaǧ, Hilal},
	title = {Prediction of diagnosis and prognosis of COVID-19 disease by blood gas parameters using decision trees machine learning model: a retrospective observational study},
	year = {2022},
	journal = {Medical Gas Research},
	volume = {12},
	number = {2},
	pages = {60 – 66},
	doi = {10.4103/2045-9912.326002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118221385&doi=10.4103%2f2045-9912.326002&partnerID=40&md5=32d9eecbf5d8987ef14455b9ea6ac7a7},
	affiliations = {Department of Biostatistics and Medical Informatics, Faculty of Medicine, Erzincan Binali Yildirim University, Erzincan, Turkey; Department of Physiology, Faculty of Medicine, Erzincan Binali Yildirim University, Erzincan, Turkey},
	abstract = {The coronavirus disease 2019 (COVID-19) epidemic went down in history as a pandemic caused by corona-viruses that emerged in 2019 and spread rapidly around the world. The different symptoms of COVID-19 made it difficult to understand which variables were more influential on the diagnosis, course and mortality of the disease. Machine learning models can accurately assess hidden patterns among risk factors by analyzing large-datasets to quickly predict diagnosis, prognosis and mortality of diseases. Because of this advantage, the use of machine learning models as decision support systems in health services is increasing. The aim of this study is to determine the diagnosis and prognosis of COVID-19 disease with blood-gas data using the Chi-squared Automatic Interaction Detector (CHAID) decision-tree-model, one of the machine learning methods, which is a subfield of artificial intelligence. This study was carried out on a total of 686 patients with COVID-19 (n = 343) and non-COVID-19 (n = 343) treated at Erzincan-Mengücek-Gazi-Training and Research-Hospital between April 1, 2020 and March 1, 2021. Arterial blood gas values of all patients were obtained from the hospital registry system. While the total-accuracyratio of the decision-tree-model was 65.0% in predicting the prognosis of the disease, it was 68.2% in the diagnosis of the disease. According to the results obtained, the low ionized-calcium value (< 1.10 mM) significantly predicted the need for intensive care of COVID-19 patients. At admission, low-carboxyhemoglobin (< 1.00%), high-pH (> 7.43), low-sodium (< 135.0 mM), hematocrit (< 40.0%), and methemoglobin (< 1.30%) values are important biomarkers in the diagnosis of COVID-19 and the results were promising. The findings in the study may aid in the early-diagnosis of the disease and the intensive-care treatment of patients who are severe. The study was approved by the Ministry of Health and Erzincan University Faculty of Medicine Clinical Research Ethics Committee. © 2021 EDP Sciences. All rights reserved.},
	author_keywords = {Arterial blood gases; Artificial intelligence; Carboxyhemoglobin; COVID-19; Decision trees; Ionized calcium; Machine learning models; SARS-CoV-2},
	keywords = {Artificial Intelligence; COVID-19; Decision Trees; Humans; Machine Learning; Prognosis; SARS-CoV-2; biological marker; calcium ion; carboxyhemoglobin; methemoglobin; sodium; aged; arterial gas; Article; artificial intelligence; blood gas parameters; cohort analysis; controlled study; coronavirus disease 2019; decision tree; diagnostic accuracy; disease exacerbation; disease registry; disease severity; early diagnosis; female; hematocrit; hospital admission; human; human cell; intensive care; learning algorithm; machine learning; major clinical study; male; observational study; pH; prediction; prognosis; retrospective study; artificial intelligence; decision tree; machine learning; prognosis},
	correspondence_address = {M. Huyut; Department of Biostatistics and Medical Informatics, Faculty of Medicine, Erzincan Binali Yildirim University, Erzincan, Turkey; email: tahir.huyut@erzincan.edu.tr.},
	publisher = {Wolters Kluwer Medknow Publications},
	issn = {20459912},
	pmid = {34677154},
	language = {English},
	abbrev_source_title = {Med. Gas Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@ARTICLE{Han2022,
	author = {Han, Jinpei and Davids, Joseph and Ashrafian, Hutan and Darzi, Ara and Elson, Daniel S. and Sodergren, Mikael},
	title = {A systematic review of robotic surgery: From supervised paradigms to fully autonomous robotic approaches},
	year = {2022},
	journal = {International Journal of Medical Robotics and Computer Assisted Surgery},
	volume = {18},
	number = {2},
	doi = {10.1002/rcs.2358},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122153599&doi=10.1002%2frcs.2358&partnerID=40&md5=4a2cff3347889dc7cd885db40106fb1e},
	affiliations = {Hamlyn Centre for Robotic Surgery and Artificial Intelligence, Imperial College London, London, United Kingdom; National Hospital for Neurology and Neurosurgery, London, United Kingdom},
	abstract = {Background: From traditional open surgery to laparoscopic surgery and robot-assisted surgery, advances in robotics, machine learning, and imaging are pushing the surgical approach to-wards better clinical outcomes. Pre-clinical and clinical evidence suggests that automation may standardise techniques, increase efficiency, and reduce clinical complications. Methods: A PRISMA-guided search was conducted across PubMed and OVID. Results: Of the 89 screened articles, 51 met the inclusion criteria, with 10 included in the final review. Automatic data segmentation, trajectory planning, intra-operative registration, trajectory drilling, and soft tissue robotic surgery were discussed. Conclusion: Although automated surgical systems remain conceptual, several research groups have developed supervised autonomous robotic surgical systems with increasing consideration for ethico-legal issues for automation. Automation paves the way for precision surgery and improved safety and opens new possibilities for deploying more robust artificial intelligence models, better imaging modalities and robotics to improve clinical outcomes. © 2021 John Wiley & Sons Ltd.},
	author_keywords = {robotic assisted surgery; robotic autonomy; supervised autonomous robotic surgery},
	keywords = {Artificial Intelligence; Humans; Laparoscopy; Machine Learning; Robotic Surgical Procedures; Robotics; Laparoscopy; Robot programming; Transplantation (surgical); Autonomous robotics; Clinical outcome; Laparoscopic robot; Laparoscopic surgery; Open surgery; Robotic assisted surgeries; Robotic autonomy; Robotics surgery; Supervised autonomous robotic surgery; Systematic Review; artificial intelligence; automation; human; legal aspect; medical ethics; outcome assessment; registration; Review; robot assisted surgery; safety; systematic review; laparoscopy; machine learning; procedures; robotics; Robotic surgery},
	correspondence_address = {J. Han; Hamlyn Centre for Robotic Surgery and Artificial Intelligence, Imperial College London, London, United Kingdom; email: jh2720@ic.ac.uk; J. Davids; Hamlyn Centre for Robotic Surgery and Artificial Intelligence, Imperial College London, London, United Kingdom; email: jdavids@ic.ac.uk},
	publisher = {John Wiley and Sons Ltd},
	issn = {14785951},
	pmid = {34953033},
	language = {English},
	abbrev_source_title = {Int. J. Med. Rob. Comput. Assisted Surg.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@ARTICLE{Scheerbaum2022,
	author = {Scheerbaum, Petra and Book, Stephanie and Jank, Michael and Hanslian, Etienne and Dello'ro, Melanie and Schneider, Julia and Scheuermann, Julia-Sophia and Bösl, Sophia and Jeitler, Michael and Kessler, Christian and Graessel, Elmar},
	title = {Computerised cognitive training tools and online nutritional group counselling for people with mild cognitive impairment: study protocol of a completely digital, randomised, controlled trial},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {7},
	doi = {10.1136/bmjopen-2021-060473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134083187&doi=10.1136%2fbmjopen-2021-060473&partnerID=40&md5=c52bbb0cd8bfa665a257eb0d3e54cdf2},
	affiliations = {Centre of Health Services Research in Medicine, Department of Psychiatry and Psychotherapy, Universitätsklinikum Erlangen, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; Genesis Mediware GmbH, Hersbruck, Germany; Institute of Social Medicine, Epidemiology and Health Economics, Charite University Hospital, Berlin, Germany},
	abstract = {Introduction People with mild cognitive impairment (MCI) are at increased risk of decreasing cognitive functioning. Computerised cognitive training (CCT) and nutrition have been shown to improve the cognitive capacities of people with MCI. For each variable, we developed two kinds of interventions specialised for people with MCI (CCT: € individualised' CCT; nutrition: a whole-food, plant-based diet). Additionally, there are two kinds of active control measures (CCT: € basic' CCT; nutrition: a healthy diet following the current guidelines of the German Nutrition Society). The aim of this study is to investigate the effects of the two interventions on cognition in people with MCI in a 2×2 randomised controlled trial with German participants. Methods and analysis Participants will be community-dwelling individuals with a psychometric diagnosis of MCI based on the Montreal Cognitive Assessment (MoCA) and Mini-Mental State Examination. With N=200, effects with an effect size of f≥0.24 (comparable to Cohen's d≥0.48) can be detected. Screening, baseline, t6 and t12 testing will be conducted via a videoconferencing assessment, telephone, and online survey. Participants will be randomly allocated to one of four groups and will receive a combination of CCT and online nutritional counselling. The CCT can be carried out independently at home on a computer, laptop, or tablet. Nutrition counselling includes 12 online group sessions every fortnight for 1.5 hours. The treatment phase is 6 months with follow-ups after six and 12 months after baseline. Ethics and dissemination All procedures were approved by the Friedrich-Alexander-Universität Erlangen-Nürnberg Ethics Committee (Ref. 21-318-1-B). Written informed consent will be obtained from all participants. Results will be published in peer-reviewed scientific journals, conference presentations. Trial registration number ISRCTN10560738. © 2022 BMJ Publishing Group. All rights reserved.},
	author_keywords = {Delirium & cognitive disorders; GERIATRIC MEDICINE; NUTRITION & DIETETICS; Old age psychiatry},
	keywords = {Cognition; Cognition Disorders; Cognitive Dysfunction; Counseling; Health Education; Humans; Randomized Controlled Trials as Topic; adult; Article; biostatistics; controlled study; daily life activity; data analysis software; data protection; data quality; degenerative disease; dementia; follow up; food frequency questionnaire; health insurance; healthy diet; human; information processing; informed consent; machine learning; mild cognitive impairment; Mini Mental State Examination; Montreal cognitive assessment; nutritional counseling; psychometry; randomized controlled trial; structured interview; study design; telehealth; videoconferencing; cognition; cognitive defect; counseling; health education; randomized controlled trial (topic)},
	correspondence_address = {P. Scheerbaum; Centre of Health Services Research in Medicine, Department of Psychiatry and Psychotherapy, Universitätsklinikum Erlangen, Friedrich-Alexander-Universität Erlangen-Nürnberg, Erlangen, Germany; email: petra.scheerbaum@uk-erlangen.de},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35777882},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Cooper2022726,
	author = {Cooper, A. Feder and Vidan, Gili},
	title = {Making the Unaccountable Internet: The Changing Meaning of Accounting in the Early ARPANET},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {726 – 742},
	doi = {10.1145/3531146.3533137},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132965795&doi=10.1145%2f3531146.3533137&partnerID=40&md5=ef3050e9737fb16cf6742aba9e210834},
	affiliations = {Department of Computer Science, Cornell University, Ithaca, NY, United States},
	abstract = {Contemporary concerns over the governance of technological systems often run up against narratives about the technical infeasibility of designing mechanisms for accountability. While in recent AI ethics literature these concerns have been deliberated predominantly in relation to machine learning, other instances in the history of computing also presented circumstances in which computer scientists needed to un-muddle what it means to design accountable systems. One such compelling narrative can frequently be found in canonical histories of the Internet that highlight how its original designers' commitment to the "End-to-End"architectural principle precluded other features from being implemented, resulting in the fast-growing, generative, but ultimately unaccountable network we have today. This paper offers a critique of such technologically essentialist notions of accountability and the characterization of the "unaccountable Internet"as an unintended consequence. It explores the changing meaning of accounting and its relationship to accountability in a selected corpus of requests for comments (RFCs) concerning the early Internet's design from the 1970s and 80s. We characterize four ways of conceptualizing accounting: as billing, as measurement, as management, and as policy, and demonstrate how an understanding of accountability was constituted through these shifting meanings. We link together the administrative and technical mechanisms of accounting for shared resources in a distributed system and an emerging notion of accountability as a social, political, and technical category, arguing that the former is constitutive of the latter. Recovering this history is not only important for understanding the processes that shaped the Internet, but also serves as a starting point for unpacking the complicated political choices that are involved in designing accountability mechanisms for other technological systems today. © 2022 ACM.},
	author_keywords = {Accountability; Accountable systems; Accounting; Internet governance; Resource sharing},
	keywords = {Accountability; Accountable system; Accounting; Computer scientists; End to end; History of computing; Internet governance; Machine-learning; Resources sharing; Technological system; Ethical technology},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210; All Open Access, Green Open Access}
}

@CONFERENCE{Hooper2022,
	author = {Hooper, Kerrie and Fletcher, Trina L.},
	title = {An Analysis of Engineering and Computing Students' Attitudes to AI and Ethics},
	year = {2022},
	journal = {ASEE Annual Conference and Exposition, Conference Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138247906&partnerID=40&md5=d602578786ffe74d69f2e2145579ac8f},
	affiliations = {Florida International University, United States},
	abstract = {The Artificial Intelligence (AI) revolution continues to engage with the engineering and computing education world. A machine learning algorithm, or AI application itself, does not always cater to human ideals or ethical considerations. There is a need to be aware of this lack of contextual knowledge in order to design models accordingly. When considering our modern world and striving for diversity, equity, and inclusion, it is essential to ensure that technology works for all. Even though there is an excitement for the advancement of AI, there is also a need to enhance our understanding and consideration of the ethical implications of AI to inform future generations and future AI technology. The education system has a significant role in molding the minds of future AI pioneers and engineers. Therefore, it is vital to understand the attitudes and beliefs of undergraduate and graduate students who will play a pivotal role in the ethical implications of AI advancements. This work-in-progress paper focuses on a survey analysis to examine engineering and computing students' perspectives on ethics in AI before and after taking a course that includes AI and ethics within the syllabus. The following research questions will guide this study: What are the attitudes of engineering and computing students before and after taking a course that covers AI and ethics? In addition, how do their attitudes vary by demographics such as age, gender, and experience? Our goal is to present our current research and survey instrument to the American Society for Engineering Education (ASEE) audience to receive insight and feedback before finalizing the Institutional Review Board (IRB) and distributing it on the target campus. This work-in-progress closes out with the next steps, future work, implications, and concluding thoughts. © American Society for Engineering Education, 2022.},
	author_keywords = {AI education; AI Ethics; Computing Students; Engineering},
	keywords = {Education computing; Engineering education; Learning algorithms; Machine learning; Philosophical aspects; Surveys; Artificial intelligence education; Artificial intelligence ethic; Computing education; Computing student; Contextual knowledge; Design models; Ethical considerations; Ethical implications; Machine learning algorithms; Student attitudes; Students},
	publisher = {American Society for Engineering Education},
	issn = {21535965},
	language = {English},
	abbrev_source_title = {ASEE Annu. Conf. Expos. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 129th ASEE Annual Conference and Exposition: Excellence Through Diversity, ASEE 2022; Conference date: 26 June 2022 through 29 June 2022; Conference code: 182495}
}

@ARTICLE{Michelson2022125,
	author = {Michelson, Kelly N. and Klugman, Craig M. and Kho, Abel N. and Gerke, Sara},
	title = {Ethical Considerations Related to Using Machine Learning-Based Prediction of Mortality in the Pediatric Intensive Care Unit},
	year = {2022},
	journal = {Journal of Pediatrics},
	volume = {247},
	pages = {125 – 128},
	doi = {10.1016/j.jpeds.2021.12.069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124236889&doi=10.1016%2fj.jpeds.2021.12.069&partnerID=40&md5=f3cceb8e7b4a0a2f6010fa6c26c2c939},
	affiliations = {Division of Pediatric Critical Care Medicine, Department of Pediatrics, Center for Bioethics and Medical Humanities, Institute for Augmented Intelligence in Medicine (I.AIM) and Institute for Public Health and Medicine (IPHAM), Chicago, IL; Department of Health Sciences, DePaul University, Chicago, IL; Departments of Medicine and Preventive Medicine, Center for Health Information Partnerships, Institute for Augmented Intelligence in Medicine (I.AIM) and Institute for Public Health and Medicine (IPHAM), Northwestern Feinberg School of Medicine, Chicago, IL; Penn State Dickinson Law, Carlisle, PA},
	author_keywords = {artificial intelligence; bioethics; intensive care medicine; machine learning; pediatrics; predictive analytics},
	keywords = {Child; Humans; Intensive Care Units; Intensive Care Units, Pediatric; Machine Learning; Article; child; health care delivery; health care organization; human; machine learning; medical ethics; medicolegal aspect; mortality; pediatric intensive care unit; prediction; risk benefit analysis; intensive care unit},
	correspondence_address = {K.N. Michelson; Chicago, 225 East Chicago Avenue, Box 73, 60611, United States; email: kmichelson@luriechildrens.org},
	publisher = {Elsevier Inc.},
	issn = {00223476},
	coden = {JOPDA},
	pmid = {35038439},
	language = {English},
	abbrev_source_title = {J. Pediatr.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Xu202232,
	author = {Xu, Fan and Zhiwei, Liu},
	title = {Design method of intangible cultural products based on pharma industries ethics education among educators},
	year = {2022},
	journal = {Journal of Commercial Biotechnology},
	volume = {27},
	number = {1},
	pages = {32 – 41},
	doi = {10.5912/jcb1035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136709369&doi=10.5912%2fjcb1035&partnerID=40&md5=6dff81f244ea6abe17ef2ada3f8b2015},
	affiliations = {School of Design & Innovation, Changzhou Vocational Institute of Mechatronic Technology, Changzhou, 213164, China},
	abstract = {A design technique for intangible cultural creative products based on pharma industries ethics education among educator's generation is suggested to address the issue of low image fusion caused by the high cost of clustering calculation in the design of such items. The intangible cultural heritage image is extracted and segmented. The image is divided into different regions according to the gray level of pixels, and the edge detection algorithm of images in different regions of the product is designed to make the region near the picture more fit. The fusion image of intangible cultural heritage features is generated based on pharma industries' ethical education with educators, so as to reduce the cost of clustering calculation and complete the splicing of artistic style. Build the design model of intangible cultural creative products, combine the design creativity, and realize the mutual integration of intangible culture and products. Construct four image sample sets of scenic spots and historic sites, religious beliefs, festival folk customs, and handmade, and test the fusion degree. Taking the festival folk custom image set as an example, the average fusion degree of this method is 0.773, which is 0.133 and 0.145 higher than the comparison method based on convolutional neural network and machine learning, respectively. Therefore, it has a good application effect. © 2022 ThinkBiotech LLC. All rights reserved.},
	author_keywords = {AI; creative products; ethical education among educators:; image generation; painting generation; Pharma industries; product design},
	keywords = {Convolutional neural networks; Image fusion; Philosophical aspects; Clusterings; Creative products; Design method; Ethical education among educator:; Ethics education; Folk customs; Image generations; Intangible cultural heritages; Painting generation; Pharma industry; article; calculation; convolutional neural network; creativity; edge detection; education; ethics; human; human experiment; inheritance; intermethod comparison; machine learning; painting; product design; religion; RNA splicing; Product design},
	publisher = {ThinkBiotech LLC},
	issn = {14628732},
	coden = {JCBOA},
	language = {English},
	abbrev_source_title = {J. Commer. Biotechnol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Daines2022,
	author = {Daines, Luke and Mulholland, Rachel H and Vasileiou, Eleftheria and Hammersley, Vicky and Weatherill, David and Katikireddi, Srinivasa Vittal and Kerr, Steven and Moore, Emily and Pesenti, Elisa and Quint, Jennifer K and Shah, Syed Ahmar and Shi, Ting and Simpson, Colin R and Robertson, Chris and Sheikh, Aziz},
	title = {Deriving and validating a risk prediction model for long COVID-19: protocol for an observational cohort study using linked Scottish data},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {7},
	doi = {10.1136/bmjopen-2021-059385},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133566150&doi=10.1136%2fbmjopen-2021-059385&partnerID=40&md5=fe8109ff666508f988f6314dfe07a40c},
	affiliations = {Usher Institute, The University of Edinburgh, Edinburgh, United Kingdom; MRC/CSO Social & Public Health Sciences Unit, University of Glasgow, Glasgow, United Kingdom; Public Health Scotland, Glasgow, United Kingdom; Institute of Cell Biology, University of Edinburgh, Edinburgh, United Kingdom; Faculty of Medicine, National Heart and Lung Institute, Imperial College London, London, United Kingdom; School of Health, Wellington Faculty of Health, Victoria University of Wellington, Wellington, New Zealand; Department of Mathematics and Statistics, University of Strathclyde, Glasgow, United Kingdom; Public Health Scotland, Edinburgh, United Kingdom},
	abstract = {Introduction COVID-19 is commonly experienced as an acute illness, yet some people continue to have symptoms that persist for weeks, or months (commonly referred to as € long-COVID'). It remains unclear which patients are at highest risk of developing long-COVID. In this protocol, we describe plans to develop a prediction model to identify individuals at risk of developing long-COVID. Methods and analysis We will use the national Early Pandemic Evaluation and Enhanced Surveillance of COVID-19 (EAVE II) platform, a population-level linked dataset of routine electronic healthcare data from 5.4 million individuals in Scotland. We will identify potential indicators for long-COVID by identifying patterns in primary care data linked to information from out-of-hours general practitioner encounters, accident and emergency visits, hospital admissions, outpatient visits, medication prescribing/dispensing and mortality. We will investigate the potential indicators of long-COVID by performing a matched analysis between those with a positive reverse transcriptase PCR (RT-PCR) test for SARS-CoV-2 infection and two control groups: (1) individuals with at least one negative RT-PCR test and never tested positive; (2) the general population (everyone who did not test positive) of Scotland. Cluster analysis will then be used to determine the final definition of the outcome measure for long-COVID. We will then derive, internally and externally validate a prediction model to identify the epidemiological risk factors associated with long-COVID. Ethics and dissemination The EAVE II study has obtained approvals from the Research Ethics Committee (reference: 12/SS/0201), and the Public Benefit and Privacy Panel for Health and Social Care (reference: 1920-0279). Study findings will be published in peer-reviewed journals and presented at conferences. Understanding the predictors for long-COVID and identifying the patient groups at greatest risk of persisting symptoms will inform future treatments and preventative strategies for long-COVID. © 2022 BMJ Publishing Group. All rights reserved.},
	author_keywords = {COVID-19; protocols & guidelines; public health},
	keywords = {Cohort Studies; COVID-19; Hospitalization; Humans; Observational Studies as Topic; SARS-CoV-2; adult; Article; clinical feature; clinical protocol; cohort analysis; COVID-19 testing; disease severity; general practitioner; health service; hospital admission; human; infection risk; long COVID; machine learning; major clinical study; morbidity; mortality rate; observational study; outpatient; predictive model; prescription; primary medical care; prospective study; reverse transcription polymerase chain reaction; risk assessment; risk factor; Scotsman; secondary health care; sociodemographics; telehealth; vaccination; complication; epidemiology; hospitalization},
	correspondence_address = {L. Daines; Usher Institute, The University of Edinburgh, Edinburgh, United Kingdom; email: luke.daines@ed.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35793922},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Alorwu2022681,
	author = {Alorwu, Andy and van Berkel, Niels and Goncalves, Jorge and Oppenlaender, Jonas and López, Miguel Bordallo and Seetharaman, Mahalakshmy and Hosio, Simo},
	title = {Crowdsourcing sensitive data using public displays—opportunities, challenges, and considerations},
	year = {2022},
	journal = {Personal and Ubiquitous Computing},
	volume = {26},
	number = {3},
	pages = {681 – 696},
	doi = {10.1007/s00779-020-01375-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082879092&doi=10.1007%2fs00779-020-01375-6&partnerID=40&md5=225c2f3b5132dabc61f3c96deea6628f},
	affiliations = {University of Oulu, Oulu, Finland; Aalborg University, Aalborg, Denmark; The University of Melbourne, Melbourne, Australia; VTT Technical Research Centre of Finland, Oulu, Finland},
	abstract = {Interactive public displays are versatile two-way interfaces between the digital world and passersby. They can convey information and harvest purposeful data from their users. Surprisingly little work has exploited public displays for collecting tagged data that might be useful beyond a single application. In this work, we set to fill this gap and present two studies: (1) a field study where we investigated collecting biometrically tagged video-selfies using public kiosk-sized screens, and (2) an online narrative transportation study that further elicited rich qualitative insights on key emerging aspects from the first study. In the first study, a 61-day deployment resulted in 199 video-selfies with consent to leverage the videos in any non-profit research. The field study indicates that people are willing to donate even highly sensitive data about themselves in public. The subsequent online narrative transportation study provides a deeper understanding of a variety of issues arising from the first study that can be leveraged in the future design of such systems. The two studies combined in this article pave the way forward towards a vision where volunteers can, should they so choose, ethically and serendipitously help unleash advances in data-driven areas such as computer vision and machine learning in health care. © 2020, The Author(s).},
	author_keywords = {Computer vision; Crowdsourcing; Ethics; Field study; Narrative transportation; Privacy; Public displays; Survey},
	keywords = {Computer privacy; Crowdsourcing; Data privacy; Ethical aspects; Medical computing; Online systems; Surveying; Data driven; Digital world; Field studies; Future designs; Interactive public displays; Narrative transportations; Public display; Sensitive datas; Computer vision},
	correspondence_address = {A. Alorwu; University of Oulu, Oulu, Finland; email: andy.alorwu@oulu.fi},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {16174909},
	language = {English},
	abbrev_source_title = {Pers. Ubiquitous Comp.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Schmidt20221523,
	author = {Schmidt, Ana Lucía and Rodriguez-Esteban, Raul and Gottowik, Juergen and Leddin, Mathias},
	title = {Applications of quantitative social media listening to patient-centric drug development},
	year = {2022},
	journal = {Drug Discovery Today},
	volume = {27},
	number = {5},
	pages = {1523 – 1530},
	doi = {10.1016/j.drudis.2022.01.015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124736958&doi=10.1016%2fj.drudis.2022.01.015&partnerID=40&md5=9635d58baa2d5c4a4abdf5d341d5c5a4},
	affiliations = {Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd, Grenzacherstrasse 124, Basel, 4070, Switzerland},
	abstract = {Social media listening has been increasingly acknowledged as a tool with applications in many stages of the drug development process. These applications were created to meet the need for patient-centric therapies that are fit-for-purpose and meaningful to patients. Such applications, however, require the leverage of new quantitative approaches and analytical methods that draw from developments in artificial intelligence and real-world data (RWD) analysis. Here, we review the state-of-the-art in quantitative social media listening (QSML) methods applied to drug discovery from the perspective of the pharmaceutical industry. © 2022 Elsevier Ltd},
	author_keywords = {Artificial intelligence; Natural language processing; Patient-centric drug discovery; Real-world data; Social media analysis; Social media listening},
	keywords = {Artificial Intelligence; Drug Development; Drug Industry; Humans; Patient-Centered Care; Social Media; artificial intelligence; coding; data collection method; data privacy; demographics; drug design; drug industry; extraction; human; information processing; machine learning; medical ethics; natural language processing; patient care; quantitative analysis; Review; social media; social media monitoring; drug development; social media},
	correspondence_address = {R. Rodriguez-Esteban; Roche Innovation Center Basel, F. Hoffmann-La Roche Ltd, Basel, Grenzacherstrasse 124, 4070, Switzerland; email: raul.rodriguez-esteban@roche.com},
	publisher = {Elsevier Ltd},
	issn = {13596446},
	coden = {DDTOF},
	pmid = {35114364},
	language = {English},
	abbrev_source_title = {Drug Discov. Today},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yom20221,
	author = {Yom, Sue S. and Deville, Curtiland and Boerma, Marjan and Carlson, David and Jabbour, Salma K. and Braverman, Lisa},
	title = {Evaluating the Generalizability and Reproducibility of Scientific Research},
	year = {2022},
	journal = {International Journal of Radiation Oncology Biology Physics},
	volume = {113},
	number = {1},
	pages = {1 – 4},
	doi = {10.1016/j.ijrobp.2022.02.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127551650&doi=10.1016%2fj.ijrobp.2022.02.002&partnerID=40&md5=c97394e42851bb0f1a2a069f07100d73},
	affiliations = {Editor-in-Chief; Department of Radiation Oncology, Johns Hopkins University, Maryland, Baltimore; Department of Radiation Oncology, University of Arkansas for Medical Sciences, Little Rock, AR, United States; Department of Radiation Oncology, University of Pennsylvania, Pennsylvania, Philadelphia; Department of Radiation Oncology, Rutgers University, New Brunswick, NJ, United States; American Society of Radiation Oncology},
	keywords = {Humans; Reproducibility of Results; Research Design; age distribution; economic inequality; Editorial; ethnic difference; generalizability; geographic distribution; human; machine learning; medical society; publication; quality control; race difference; reliability; reproducibility; research ethics; scientific literature; sex difference; social inequality; methodology; reproducibility},
	correspondence_address = {S.S. Yom; Editor-in-Chief; email: sue.yom@ucsf.edu},
	publisher = {Elsevier Inc.},
	issn = {03603016},
	coden = {IOBPD},
	pmid = {35427541},
	language = {English},
	abbrev_source_title = {Int. J. Radiat. Oncol. Biol. Phys.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{McIlroy-Young2022479,
	author = {McIlroy-Young, Reid and Kleinberg, Jon and Sen, Siddhartha and Barocas, Solon and Anderson, Ashton},
	title = {Mimetic models: Ethical implications of ai that acts like you},
	year = {2022},
	journal = {AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {479 – 490},
	doi = {10.1145/3514094.3534177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133863976&doi=10.1145%2f3514094.3534177&partnerID=40&md5=f84c01884b391190ee267335e18a6f46},
	affiliations = {Department of Computer Science, University of Toronto, Toronto, ON, Canada; Department of Computer Science, Cornell University, Ithaca, NY, United States; Microsoft Research, New York City, NY, United States; Microsoft Research and Cornell University, New York City, NY, United States},
	abstract = {An emerging theme in artificial intelligence research is the creation of models to simulate the decisions and behavior of specific people, in domains including game-playing, text generation, and artistic expression. These models go beyond earlier approaches in the way they are tailored to individuals, and the way they are designed for interaction rather than simply the reproduction of fixed, pre-computed behaviors. We refer to these as mimetic models, and in this paper we develop a framework for characterizing the ethical and social issues raised by their growing availability. Our framework includes a number of distinct scenarios for the use of such models, and considers the impacts on a range of different participants, including the target being modeled, the operator who deploys the model, and the entities that interact with it.  © 2022 ACM.},
	author_keywords = {artificial intelligence; ethics; generative models; machine learning; mimetic models},
	keywords = {Ethical technology; Machine learning; Artificial intelligence research; Ethical implications; Ethical issues; Game playing; Generative model; Machine-learning; Mimetic model; Mimetics; Social issues; Text generations; Cell proliferation},
	correspondence_address = {R. Mcilroy-Young; Department of Computer Science, University of Toronto, Toronto, Canada; email: reidmcy@cs.toronto.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039247-1},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2022; Conference date: 1 August 2022 through 3 August 2022; Conference code: 181805; All Open Access, Green Open Access}
}

@CONFERENCE{Fischer2022877,
	author = {Fischer, Maximilian T. and Hirsbrunner, Simon David and Jentner, Wolfgang and Miller, Matthias and Keim, Daniel A. and Helm, Paula},
	title = {Promoting Ethical Awareness in Communication Analysis: Investigating Potentials and Limits of Visual Analytics for Intelligence Applications},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {877 – 889},
	doi = {10.1145/3531146.3533151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132968553&doi=10.1145%2f3531146.3533151&partnerID=40&md5=062df6b2d98acfec87b28da3b3e3d3a9},
	affiliations = {University of Konstanz, Konstanz, Germany; International Center for Ethics in the Sciences (IZEW), University of Tübingen, Tübingen, Germany},
	abstract = {Digital systems for analyzing human communication data have become prevalent in recent years. This may be related to the increasing abundance of data that can be harnessed but can hardly be managed manually. Intelligence analysis of communications data in investigative journalism, criminal intelligence, and law present particularly interesting cases, as they must take into account the often highly sensitive properties of the underlying operations and data. At the same time, these are areas where increasingly automated, sophisticated approaches and tailored systems can be particularly useful and relevant, especially in terms of Big Data manageability. However, by the shifting of responsibilities, this also poses dangers. In addition to privacy concerns, these dangers relate to uncertain or poor data quality, leading to discrimination and potentially misleading insights. Other problems relate to a lack of transparency and traceability, making it difficult to accurately identify problems and determine appropriate remedial strategies. Visual analytics combines machine learning methods with interactive visual interfaces to enable human sense- and decision-making. This technique can be key for designing and operating meaningful interactive communication analysis systems that consider these ethical challenges. In this interdisciplinary work, a joint endeavor of computer scientists, ethicists, and scholars in Science & Technology Studies, we investigate and evaluate opportunities and risks involved in using Visual analytics approaches for communication analysis in intelligence applications in particular. We introduce, at first, the common technological systems used in communication analysis, with a special focus on intelligence analysis in criminal investigations, further discussing the domain-specific ethical implications, tensions, and risks involved. We then make the case of how tailored Visual Analytics approaches may reduce and mitigate the described problems, both theoretically and through practical examples. Offering interactive analysis capabilities and what-if explorations while facilitating guidance, provenance generation, and bias awareness (through nudges, for example) can improve analysts' understanding of their data, increasing trustworthiness, accountability, and generating knowledge. We show that finding Visual Analytics design solutions for ethical issues is not a mere optimization task with an ideal final solution. Design solutions for specific ethical problems (e.g., privacy) often trigger new ethical issues (e.g., accountability) in other areas. Balancing out and negotiating these trade-offs has, as we argue, to be an integral aspect of the system design process from the outset. Finally, our work identifies existing gaps and highlights research opportunities, further describing how our results can be transferred to other domains. With this contribution, we aim at informing more ethically-aware approaches to communication analysis in intelligence operations. © 2022 Owner/Author.},
	author_keywords = {Communication Analysis; Critical Algorithm Studies; Critical Data Studies; Ethic Awareness; Intelligence Analysis; Interdisciplinary Research; Machine Learning; Science & Technology Studies; Visual Analytics},
	keywords = {Balancing; Crime; Data communication systems; Economic and social effects; Ethical technology; Machine learning; Risk assessment; Visualization; Algorithm study; Communication analysis; Critical algorithm study; Critical data; Critical data study; Ethic awareness; Intelligence analysis; Interdisciplinary research; Machine-learning; Science & technology study; Science technologies; Visual analytics; Decision making},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Suresh2022667,
	author = {Suresh, Harini and Movva, Rajiv and Dogan, Amelia Lee and Bhargava, Rahul and Cruxen, Isadora and Cuba, Angeles Martinez and Taurino, Guilia and So, Wonyoung and D'Ignazio, Catherine},
	title = {Towards Intersectional Feminist and Participatory ML: A Case Study in Supporting Feminicide Counterdata Collection},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {667 – 678},
	doi = {10.1145/3531146.3533132},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132991050&doi=10.1145%2f3531146.3533132&partnerID=40&md5=296c6c5988d805a3a5fbb75be054cff5},
	affiliations = {Data + Feminism Lab, Massachusetts Institute of Technology, United States; School of Journalism, Northeastern University, United States; School of Business and Management, Queen Mary University of London, United Kingdom; Khoury College of Computer Sciences, Northeastern University, United States},
	abstract = {Data ethics and fairness have emerged as important areas of research in recent years. However, much work in this area focuses on retroactively auditing and "mitigating bias"in existing, potentially flawed systems, without interrogating the deeper structural inequalities underlying them. There are not yet examples of how to apply feminist and participatory methodologies from the start, to conceptualize and design machine learning-based tools that center and aim to challenge power inequalities. Our work targets this more prospective goal. Guided by the framework of data feminism, we co-design datasets and machine learning models to support the efforts of activists who collect and monitor data about feminicide - gender-based killings of women and girls. We describe how intersectional feminist goals and participatory processes shaped each stage of our approach, from problem conceptualization to data collection to model evaluation. We highlight several methodological contributions, including 1) an iterative data collection and annotation process that targets model weaknesses and interrogates framing concepts (such as who is included/excluded in "feminicide"), 2) models that explicitly focus on intersectional identities rather than statistical majorities, and 3) a multi-step evaluation process - with quantitative, qualitative and participatory steps - focused on context-specific relevance. We also distill insights and tensions that arise from bridging intersectional feminist goals with ML. These include reflections on how ML may challenge power, embrace pluralism, rethink binaries and consider context, as well as the inherent limitations of any technology-based solution to address durable structural inequalities. © 2022 Owner/Author.},
	keywords = {Ethical technology; Iterative methods; Machine learning; Case-studies; Co-designs; Data collection; Machine learning models; Machine-learning; Methodological contributions; Model evaluation; Participatory process; Power; Prospectives; Data acquisition},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Deutch20222544,
	author = {Deutch, Daniel and Malik, Tanu and Chapman, Adriane},
	title = {Theory and Practice of Provenance},
	year = {2022},
	journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
	pages = {2544 – 2545},
	doi = {10.1145/3514221.3524073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132721319&doi=10.1145%2f3514221.3524073&partnerID=40&md5=50c3035816f56667c00e1b0a5e4d4cf2},
	affiliations = {Tel Aviv University, Tel Aviv, Israel; DePaul University, Chicago, IL, United States; University of Southampton, Southampton, United Kingdom},
	abstract = {Provenance is metadata about the origin, history, or derivation of something; in computer science, provenance usually describes some informational artifact, such as a dataset, an executable program, a news article, or a chart or graph in a scientific publication. Notably, provenance is closely related to issues of explanation, accountability, transparency and ethics. Indeed, these and related issues are the subject of extensive investigation in multiple areas of research such as Scientific Workflows, Databases, Machine Learning and Artificial Intelligence. TaPP, the international workshop on Theory and Practice of Provenance, is widely considered to be the premier venue dedicated to provenance. In 2022, it is held for the first time in conjunction with ACM SIGMOD. © 2022 Owner/Author.},
	author_keywords = {Provenance},
	keywords = {Metadata; Executable programs; International workshops; Machine-learning; Multiple areas; News articles; Provenance; Scientific publications; Scientific workflows; Theory and practice; Artificial intelligence},
	publisher = {Association for Computing Machinery},
	issn = {07308078},
	isbn = {978-145039249-5},
	language = {English},
	abbrev_source_title = {Proc. ACM SIGMOD Int. Conf. Manage. Data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 ACM SIGMOD International Conference on the Management of Data, SIGMOD 2022; Conference date: 12 June 2022 through 17 June 2022; Conference code: 180006}
}

@CONFERENCE{Kenthapadi20224800,
	author = {Kenthapadi, Krishnaram and Lakkaraju, Himabindu and Natarajan, Pradeep and Sameki, Mehrnoosh},
	title = {Model Monitoring in Practice: Lessons Learned and Open Challenges},
	year = {2022},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {4800 – 4801},
	doi = {10.1145/3534678.3542617},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137144890&doi=10.1145%2f3534678.3542617&partnerID=40&md5=52e9e71a36a997099747894171cba4d5},
	affiliations = {Fiddler Ai, Palo Alto, CA, United States; Harvard University, Cambridge, MA, United States; Amazon Alexa Ai, Chicago, IL, United States; Microsoft Azure Ai, Boston, MA, United States},
	abstract = {Artificial Intelligence (AI) is increasingly playing an integral role in determining our day-to-day experiences. Increasingly, the applications of AI are no longer limited to search and recommendation systems, such as web search and movie and product recommendations, but AI is also being used in decisions and processes that are critical for individuals, businesses, and society. With AI based solutions in high-stakes domains such as hiring, lending, criminal justice, healthcare, and education, the resulting personal and professional implications of AI are far-reaching. Consequently, it becomes critical to ensure that these models are making accurate predictions, are robust to shifts in the data, are not relying on spurious features, and are not unduly discriminating against minority groups. To this end, several approaches spanning various areas such as explainability, fairness, and robustness have been proposed in recent literature, and many papers and tutorials on these topics have been presented in recent computer science conferences. However, there is relatively less attention on the need for monitoring machine learning (ML) models once they are deployed and the associated research challenges. In this tutorial, we first motivate the need for ML model monitoring[14], as part of a broader AI model governance[9] and responsible AI framework, from societal, legal, customer/end-user, and model developer perspectives, and provide a roadmap for thinking about model monitoring in practice. We then present findings and insights on model monitoring desiderata based on interviews with various ML practitioners spanning domains such as financial services, healthcare, hiring, online retail, computational advertising, and conversational assistants[15]. We then describe the technical considerations and challenges associated with realizing the above desiderata in practice. We provide an overview of techniques/tools for model monitoring (e.g., see [1, 1, 2, 5, 6, 8, 10-13, 18-21]. Then, we focus on the real-world application of model monitoring methods and tools [3, 4, 7, 11, 13, 16, 17], present practical challenges/guidelines for using such techniques effectively, and lessons learned from deploying model monitoring tools for several web-scale AI/ML applications. We present case studies across different companies, spanning application domains such as financial services, healthcare, hiring, conversational assistants, online retail, computational advertising, search and recommendation systems, and fraud detection. We hope that our tutorial will inform both researchers and practitioners, stimulate further research on model monitoring, and pave the way for building more reliable ML models and monitoring tools in the future.  © 2022 Owner/Author.},
	author_keywords = {case studies from industry; ethics in ai; model monitoring and model risk management; responsible ai},
	keywords = {Employment; Ethical technology; Health care; Learning systems; Monitoring; Recommender systems; Risk management; Sales; Case study from industry; Case-studies; Ethic in ai; Machine learning models; Model monitoring; Model monitoring and model risk management; Model risk management; Monitoring risks; Monitoring tools; Responsible ai; Artificial intelligence},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039385-0},
	language = {English},
	abbrev_source_title = {Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2022; Conference date: 14 August 2022 through 18 August 2022; Conference code: 181896}
}

@ARTICLE{Joshi2022,
	author = {Joshi, Praveen and Thapa, Chandra and Camtepe, Seyit and Hasanuzzaman, Mohammed and Scully, Ted and Afli, Haithem},
	title = {Performance and Information Leakage in Splitfed Learning and Multi-Head Split Learning in Healthcare Data and Beyond},
	year = {2022},
	journal = {Methods and Protocols},
	volume = {5},
	number = {4},
	doi = {10.3390/mps5040060},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136782235&doi=10.3390%2fmps5040060&partnerID=40&md5=1526a990ad9d47e46ab975d1b10d94ab},
	affiliations = {Department of Computer Sciences, Munster Technological University, MTU, Cork, T12 P928, Ireland; CSIRO Data61, Marsfield, 2122, NSW, Australia},
	abstract = {Machine learning (ML) in healthcare data analytics is attracting much attention because of the unprecedented power of ML to extract knowledge that improves the decision-making process. At the same time, laws and ethics codes drafted by countries to govern healthcare data are becoming stringent. Although healthcare practitioners are struggling with an enforced governance framework, we see the emergence of distributed learning-based frameworks disrupting traditional-ML-model development. Splitfed learning (SFL) is one of the recent developments in distributed machine learning that empowers healthcare practitioners to preserve the privacy of input data and enables them to train ML models. However, SFL has some extra communication and computation overheads at the client side due to the requirement of client-side model synchronization. For a resource-constrained client side (hospitals with limited computational powers), removing such conditions is required to gain efficiency in the learning. In this regard, this paper studies SFL without client-side model synchronization. The resulting architecture is known as multi-head split learning (MHSL). At the same time, it is important to investigate information leakage, which indicates how much information is gained by the server related to the raw data directly out of the smashed data—the output of the client-side model portion—passed to it by the client. Our empirical studies examine the Resnet-18 and Conv1-D architecture model on the ECG and HAM-10000 datasets under IID data distribution. The results find that SFL provides 1.81% and 2.36% better accuracy than MHSL on the ECG and HAM-10000 datasets, respectively (for cut-layer value set to 1). Analysis of experimentation with various client-side model portions demonstrates that it has an impact on the overall performance. With an increase in layers in the client-side model portion, SFL performance improves while MHSL performance degrades. Experiment results also demonstrate that information leakage provided by mutual information score values in SFL is more than MHSL for ECG and HAM-10000 datasets by (Formula presented.) and (Formula presented.), respectively. © 2022 by the authors.},
	author_keywords = {distributed collaborative machine learning; information leakage in distributed learning; multi-head split learning; parameter transmission-based distributed machine learning; privacy-preserving machine learning; split learning},
	correspondence_address = {P. Joshi; Department of Computer Sciences, Munster Technological University, MTU, Cork, T12 P928, Ireland; email: praveen.joshi@mycit.ie},
	publisher = {MDPI},
	issn = {24099279},
	language = {English},
	abbrev_source_title = {Methods Protoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Crisan2022427,
	author = {Crisan, Anamaria and Drouhard, Margaret and Vig, Jesse and Rajani, Nazneen},
	title = {Interactive Model Cards: A Human-Centered Approach to Model Documentation},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {427 – 439},
	doi = {10.1145/3531146.3533108},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133013496&doi=10.1145%2f3531146.3533108&partnerID=40&md5=a502578ced2e4c4e0bcb87533db02938},
	affiliations = {Tableau Research & User Research, Seattle, WA, United States; Tableau Software, Palo Alto, CA, United States; Salesforce Research, Palo Alto, United States},
	abstract = {Deep learning models for natural language processing (NLP) are increasingly adopted and deployed by analysts without formal training in NLP or machine learning (ML). However, the documentation intended to convey the model's details and appropriate use is tailored primarily to individuals with ML or NLP expertise. To address this gap, we conduct a design inquiry into interactive model cards, which augment traditionally static model cards with affordances for exploring model documentation and interacting with the models themselves. Our investigation consists of an initial conceptual study with experts in ML, NLP, and AI Ethics, followed by a separate evaluative study with non-expert analysts who use ML models in their work. Using a semi-structured interview format coupled with a think-aloud protocol, we collected feedback from a total of 30 participants who engaged with different versions of standard and interactive model cards. Through a thematic analysis of the collected data, we identified several conceptual dimensions that summarize the strengths and limitations of standard and interactive model cards, including: stakeholders; design; guidance; understandability & interpretability; sensemaking & skepticism; and trust & safety. Our findings demonstrate the importance of carefully considered design and interactivity for orienting and supporting non-expert analysts using deep learning models, along with a need for consideration of broader sociotechnical contexts and organizational dynamics. We have also identified design elements, such as language, visual cues, and warnings, among others, that support interactivity and make non-interactive content accessible. We summarize our findings as design guidelines and discuss their implications for a human-centered approach towards AI/ML documentation. © 2022 ACM.},
	author_keywords = {human centered design; interactive data visualization; model cards},
	keywords = {Deep learning; Human engineering; Learning algorithms; Learning systems; Natural language processing systems; Visual languages; Human-centred designs; Interactive data visualization; Interactive models; Language processing; Learning models; Machine-learning; Model card; Model documentations; Natural languages; Standard model; Data visualization},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210; All Open Access, Green Open Access}
}

@ARTICLE{Monlezun2022,
	author = {Monlezun, Dominique J. and Sinyavskiy, Oleg and Peters, Nathaniel and Steigner, Lorraine and Aksamit, Timothy and Girault, Maria Ines and Garcia, Alberto and Gallagher, Colleen and Iliescu, Cezar},
	title = {Artificial Intelligence-Augmented Propensity Score, Cost Effectiveness and Computational Ethical Analysis of Cardiac Arrest and Active Cancer with Novel Mortality Predictive Score},
	year = {2022},
	journal = {Medicina (Lithuania)},
	volume = {58},
	number = {8},
	doi = {10.3390/medicina58081039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136708028&doi=10.3390%2fmedicina58081039&partnerID=40&md5=f7e7194cf57deaedeef7bf453c023edd},
	affiliations = {Department of Cardiology, The University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States; UNESCO Chair in Bioethics Human Rights, Rome, 00163, Italy; School of Bioethics, Universidad Anahuac México, Mexico City, 52786, Mexico; Center for Artificial Intelligence and Health Equities, Global System Analytics Structures, New Orleans, 70112, LA, United States; Department of Public Health, Asfendiyarov Kazakh National Medical University, Almaty, 050000, Kazakhstan; Department of Pulmonary Medicine, Mayo Clinic, Rochester, 55905, MN, United States; Pontifical Academy for Life, Rome, 00193, Italy; Section of Integrated Ethics, The University of Texas MD Anderson Cancer Center, Houston, 77030, TX, United States},
	abstract = {Background and objectives: Little is known about outcome improvements and disparities in cardiac arrest and active cancer. We performed the first known AI and propensity score (PS)-augmented clinical, cost-effectiveness, and computational ethical analysis of cardio-oncology cardiac arrests including left heart catheterization (LHC)-related mortality reduction and related disparities. Materials and methods: A nationally representative cohort analysis was performed for mortality and cost by active cancer using the largest United States all-payer inpatient dataset, the National Inpatient Sample, from 2016 to 2018, using deep learning and machine learning augmented propensity score-adjusted (ML-PS) multivariable regression which informed cost-effectiveness and ethical analyses. The Cardiac Arrest Cardio-Oncology Score (CACOS) was then created for the above population and validated. The results informed the computational ethical analysis to determine ethical and related policy recommendations. Results: Of the 101,521,656 hospitalizations, 6,656,883 (6.56%) suffered cardiac arrest of whom 61,300 (0.92%) had active cancer. Patients with versus without active cancer were significantly less likely to receive an inpatient LHC (7.42% versus 20.79%, p < 0.001). In ML-PS regression in active cancer, post-arrest LHC significantly reduced mortality (OR 0.18, 95%CI 0.14–0.24, p < 0.001) which PS matching confirmed by up to 42.87% (95%CI 35.56–50.18, p < 0.001). The CACOS model included the predictors of no inpatient LHC, PEA initial rhythm, metastatic malignancy, and high-risk malignancy (leukemia, pancreas, liver, biliary, and lung). Cost-benefit analysis indicated 292 racial minorities and $2.16 billion could be saved annually by reducing racial disparities in LHC. Ethical analysis indicated the convergent consensus across diverse belief systems that such disparities should be eliminated to optimize just and equitable outcomes. Conclusions: This AI-guided empirical and ethical analysis provides a novel demonstration of LHC mortality reductions in cardio-oncology cardiac arrest and related disparities, along with an innovative predictive model that can be integrated within the digital ecosystem of modern healthcare systems to improve equitable clinical and public health outcomes. © 2022 by the authors.},
	author_keywords = {artificial intelligence; cardiac arrest; cardio-oncology; cost effectiveness; equity; ethics},
	keywords = {Artificial Intelligence; Cost-Benefit Analysis; Ecosystem; Ethical Analysis; Heart Arrest; Humans; Neoplasms; Propensity Score; United States; artificial intelligence; complication; cost benefit analysis; ecosystem; ethics; heart arrest; human; neoplasm; propensity score; United States},
	correspondence_address = {D.J. Monlezun; Department of Cardiology, The University of Texas MD Anderson Cancer Center, Houston, 77030, United States; email: dominique.j.monlezun@uth.tmc.edu},
	publisher = {MDPI},
	issn = {1010660X},
	pmid = {36013506},
	language = {English},
	abbrev_source_title = {Medicina},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Dong2022,
	author = {Dong, Weinan and Cheng, Will Ho Gi and Tse, Emily Tsui Yee and Mi, Yuqi and Wong, Carlos King Ho and Tang, Eric Ho Man and Yu, Esther Yee Tak and Chin, Weng Yee and Bedford, Laura Elizabeth and Ko, Welchie Wai Kit and Chao, David Vai Kiong and Tan, Kathryn Choon Beng and Lam, Cindy Lo Kuen},
	title = {Development and validation of a diabetes mellitus and prediabetes risk prediction function for case finding in primary care in Hong Kong: a cross-sectional study and a prospective study protocol paper},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {5},
	doi = {10.1136/bmjopen-2021-059430},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130913816&doi=10.1136%2fbmjopen-2021-059430&partnerID=40&md5=a4fe9cdc1a29df8347089bf23d5073dd},
	affiliations = {Department of Family Medicine and Primary Care, School of Clinical Medicine, Li Ka Shing Faculty of Medicine, University of Hong Kong, Hong Kong; Department of Family Medicine, University of Hong Kong Shenzhen Hospital, Shenzhen, China; Department of Pharmacology and Pharmacy, Li Ka Shing Faculty of Medicine, University of Hong Kong, Hong Kong; Family Medicine and Primary Healthcare Department, Queen Mary Hospital, Hong Kong West Cluster, Hospital Authority, Hong Kong; Department of Family Medicine and Primary Health Care, United Christian Hospital, Kowloon East Cluster, Hospital Authority, Hong Kong; Department of Family Medicine and Primary Health Care, Tseung Kwan O Hospital, Kowloon East Cluster, Hospital Authority, Hong Kong; Department of Medicine, School of Clinical Medicine, Li Ka Shing Faculty of Medicine, University of Hong Kong, Hong Kong},
	abstract = {Introduction Diabetes mellitus (DM) is a major non-communicable disease with an increasing prevalence. Undiagnosed DM is not uncommon and can lead to severe complications and mortality. Identifying high-risk individuals at an earlier disease stage, that is, pre-diabetes (pre-DM), is crucial in delaying progression. Existing risk models mainly rely on non-modifiable factors to predict only the DM risk, and few apply to Chinese people. This study aims to develop and validate a risk prediction function that incorporates modifiable lifestyle factors to detect DM and pre-DM in Chinese adults in primary care. Methods and analysis A cross-sectional study to develop DM/Pre-DM risk prediction functions using data from the Hong Kong's Population Health Survey (PHS) 2014/2015 and a 12-month prospective study to validate the functions in case finding of individuals with DM/pre-DM. Data of 1857 Chinese adults without self-reported DM/Pre-DM will be extracted from the PHS 2014/2015 to develop DM/Pre-DM risk models using logistic regression and machine learning methods. 1014 Chinese adults without a known history of DM/Pre-DM will be recruited from public and private primary care clinics in Hong Kong. They will complete a questionnaire on relevant risk factors and blood tests on Oral Glucose Tolerance Test (OGTT) and haemoglobin A1C (HbA1c) on recruitment and, if the first blood test is negative, at 12 months. A positive case is DM/pre-DM defined by OGTT or HbA1c in any blood test. Area under receiver operating characteristic curve, sensitivity, specificity, positive predictive value and negative predictive value of the models in detecting DM/pre-DM will be calculated. Ethics and dissemination Ethics approval has been received from The University of Hong Kong/Hong Kong Hospital Authority Hong Kong West Cluster (UW19-831) and Hong Kong Hospital Authority Kowloon Central/Kowloon East Cluster (REC(KC/KE)-21-0042/ER-3). The study results will be submitted for publication in a peer-reviewed journal. Trial registration number US ClinicalTrial.gov: NCT04881383; HKU clinical trials registry: HKUCTR-2808; Pre-results. © 2022 BMJ Publishing Group. All rights reserved.},
	author_keywords = {DIABETES & ENDOCRINOLOGY; PRIMARY CARE; STATISTICS & RESEARCH METHODS},
	keywords = {Adult; Cross-Sectional Studies; Diabetes Mellitus; Glycated Hemoglobin A; Hong Kong; Humans; Prediabetic State; Primary Health Care; Prospective Studies; hemoglobin A1c; glycosylated hemoglobin; adult; Article; case finding; cross-sectional study; diabetes mellitus; diabetic patient; Hong Kong; human; impaired glucose tolerance; lifestyle; major clinical study; oral glucose tolerance test; prediction; primary medical care; prospective study; receiver operating characteristic; risk assessment; risk model; self report; sensitivity and specificity; validation study; diabetes mellitus; Hong Kong; impaired glucose tolerance; primary health care},
	correspondence_address = {E.T.Y. Tse; Department of Family Medicine and Primary Care, School of Clinical Medicine, Li Ka Shing Faculty of Medicine, University of Hong Kong, Hong Kong; email: emilyht@hku.hk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35613775},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Gaikwad20224872,
	author = {Gaikwad, Snehalkumar 'Neil' and Iyer, Shankar and Lunga, Dalton and Yabe, Takahiro and Liang, Xiaofan and Ananthabhotla, Bhavani and Behari, Nikhil and Guggilam, Sreelekha and Chi, Guanghua},
	title = {Data-driven Humanitarian Mapping and Policymaking: Toward Planetary-Scale Resilience, Equity, and Sustainability},
	year = {2022},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {4872 – 4873},
	doi = {10.1145/3534678.3542918},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137140229&doi=10.1145%2f3534678.3542918&partnerID=40&md5=a745a7559589946e940075b918a63af6},
	affiliations = {Massachusetts Institute of Technology, Cambridge, MA, United States; Meta Research, Menlo Park, CA, United States; Oak Ridge National Laboratory, Oak Ridge, TN, United States; Georgia Institute of Technology, Atlanta, GA, United States; Harvard University, Cambridge, MA, United States},
	abstract = {Human civilization faces existential threats in the forms of climate change, food insecurity, pandemics, international conflicts, forced displacements, and environmental injustice. These overarching humanitarian challenges disproportionately impact historically marginalized communities worldwide. UN OCHA estimates that 274 million people will need humanitarian support in 2022. Despite growing perils to human and environmental well-being, there remains a paucity of publicly-engaged computing research to inform the design of interventions. Data science efforts exist, but they remain isolated from socioeconomic, environmental, cultural, and policy contexts at local and international scales. Moreover, biases and privacy infringements in data-driven methods further amplify existing inequalities. The result is that proclaimed benefits of data-driven innovations may remain inaccessible to policymakers, practitioners, and underserved communities whose lives they intend to transform. To address gaps in knowledge and improve the livelihood of marginalized populations, we have established the Data-driven Humanitarian Mapping and Policymaking, an interdisciplinary initiative.  © 2022 Owner/Author.},
	author_keywords = {algorithmic decision-making and ethics; climate crisis; community-based design; computational social science; data science and public policy; data-driven humanitarian action; fair and interpretable machine learning; human-centered data science; public policy; remote sensing.; social computing; sustainable development},
	keywords = {Behavioral research; Climate change; Machine learning; Mapping; Population statistics; Public policy; Remote sensing; Sustainable development; Algorithmic decision-making and ethic; Algorithmics; Climate crisis; Community-based; Community-based design; Computational social science; Data driven; Data science and public policy; Data-driven humanitarian action; Decisions makings; Fair and interpretable machine learning; Human-centered data science; Machine-learning; Remote sensing.; Remote-sensing; Science and public policy; Social computing; Decision making},
	correspondence_address = {S.'. Gaikwad; Massachusetts Institute of Technology, Cambridge, United States; email: gaikwad@mit.edu},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039385-0},
	language = {English},
	abbrev_source_title = {Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 28th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2022; Conference date: 14 August 2022 through 18 August 2022; Conference code: 181896; All Open Access, Green Open Access}
}

@ARTICLE{Sehly2022,
	author = {Sehly, Amro and Jaltotage, Biyanka and He, Albert and Maiorana, Andrew and Ihdayhid, Abdul Rahman and Rajwani, Adil and Dwivedi, Girish},
	title = {Artificial Intelligence in Echocardiography: The Time is Now},
	year = {2022},
	journal = {Reviews in Cardiovascular Medicine},
	volume = {23},
	number = {8},
	doi = {10.31083/j.rcm2308256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135896332&doi=10.31083%2fj.rcm2308256&partnerID=40&md5=18973c459a998623f531ae1ba2edce28},
	affiliations = {Department of Cardiology, Fiona Stanley Hospital, Murdoch, 6150, WA, Australia; Department of Allied Health, Fiona Stanley Hospital, Murdoch, 6150, WA, Australia; Curtin School of Allied Health, Curtin University, Bentley, 6102, WA, Australia; Harry Perkins Institute of Medical Research, Murdoch, 6150, WA, Australia; School of Medicine, The University of Western Australia, Crawley, 6009, WA, Australia; School of Medicine, Curtin University, Bentley, 6102, WA, Australia; Department of Cardiology, Royal Perth Hospital, Perth, 6000, WA, Australia},
	abstract = {Artificial Intelligence (AI) has impacted every aspect of clinical medicine, and is predicted to revolutionise diagnosis, treatment and patient care. Through novel machine learning (ML) and deep learning (DL) techniques, AI has made significant grounds in cardiology and cardiac investigations, including echocardiography. Echocardiography is a ubiquitous tool that remains first-line for the evaluation of many cardiovascular diseases, with large data sets, objective parameters, widespread availability and an excellent safety profile, it represents the perfect candidate for AI advancement. As such, AI has firmly made its stamp on echocardiography, showing great promise in training, image acquisition, interpretation and analysis, diagnostics, prognostication and phenotype development. However, there remain significant barriers in real-world clinical application and uptake of AI derived algorithms in echocardiography, most importantly being the lack of clinical outcome studies. While AI has been shown to match or even best its human counterparts, an improvement in real world outcomes remains to be established. There are also legal and ethical concerns that hinder its progress. Large outcome focused trials and a collaborative multi-disciplinary effort will be necessary to push AI into the clinical workspace. Despite this, current and emerging trials suggest that these systems will undoubtedly transform echocardiography, improving clinical utility, efficiency and training. Copyright: © 2022 The Author(s).},
	author_keywords = {artificial intelligence; deep learning; echocardiography; machine learning},
	keywords = {artificial intelligence; clinical outcome; deep learning; diagnostic value; echocardiography; health care utilization; heart left ventricle function; heart left ventricle strain; heart right ventricle function; hemodynamic parameters; human; image analysis; image processing; machine learning; medical education; medical ethics; medicolegal aspect; multidisciplinary team; patient safety; phenotype; prognosis; Review; stress echocardiography; systole},
	correspondence_address = {G. Dwivedi; Department of Cardiology, Fiona Stanley Hospital, Murdoch, 6150, Australia; email: girish.dwivedi@perkins.uwa.edu.au},
	publisher = {IMR Press Limited},
	issn = {15306550},
	coden = {RCMEC},
	language = {English},
	abbrev_source_title = {Rev. Cardiovasc. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Rodenburg2022,
	author = {Rodenburg, Kathleen and Rowan, Michael and Nixon, Andrew and Christensen Hughes, Julia},
	title = {The Misalignment of the FT50 with the Achievement of the UN’s SDGs: A Call for Responsible Research Assessment by Business Schools},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {15},
	doi = {10.3390/su14159598},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136274272&doi=10.3390%2fsu14159598&partnerID=40&md5=86c4e9d8ac9dd756e31694ccbb887d32},
	affiliations = {Gordon S. Lang School of Business and Economics, University of Guelph, Guelph, N1G 2W1, ON, Canada; Yorkville University, Toronto, L4K 4N1, ON, Canada},
	abstract = {Publication in the list of 50 journals endorsed by the Financial Times (i.e., the FT50) has become ‘institutionalized’ as a primary measure of research quality and prestige by business schools and faculty. This study investigated the extent to which this closed publication system is (mis)aligned with societal imperatives, in particular the United Nation’s 17 Sustainable Development Goals (SDGs). Research methods included both inductive and deductive analysis. Undergraduate and graduate student research assistants, enrolled in business-related programs, read all 4522 articles published by FT50 journals in 2019 and assessed their relevance to explicit and implicit concepts in the SDG framework. Additionally, potential biases that might stifle research innovation in support of the SDGs were explored. Findings included that 90% of articles were found to have no ‘explicit’ relationship to the SDGs, while only 17% were interpreted as having an implicit relationship. SDG-related articles were disproportionately from one journal-the Journal of Business Ethics (48.1%). There was also an over-representation of observed white male primary authors, who used North American (NA) data sets from NA institutions. A logistic regression model determined that the predicted probability of an SDG-related article increased with observed female primary authors, who used non-NA data sets and institutions. The next steps include comparing this methodological approach with machine learning techniques to find a more efficient and robust method for analyzing an article’s SDG content. Business Schools with sustainability as a core value are encouraged to move beyond FT50 publications for assessing research quality, including for tenure and promotion purposes, and place more focus on assessing research relevance and impact. © 2022 by the authors.},
	author_keywords = {anchoring bias; business school rankings; confirmation bias; explicit; Financial Times 50; implicit; perverse effects; selectivity bias; sustainability goals; United Nations 2030 agenda},
	keywords = {business; machine learning; research; Sustainable Development Goal; United Nations},
	correspondence_address = {K. Rodenburg; Gordon S. Lang School of Business and Economics, University of Guelph, Guelph, N1G 2W1, Canada; email: krodenbu@uoguelph.ca},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Zafar2022267,
	author = {Zafar, Sidra and Mahjoub, Heba and Mehta, Nitish and Domalpally, Amitha and Channa, Roomasa},
	title = {Artificial Intelligence Algorithms in Diabetic Retinopathy Screening},
	year = {2022},
	journal = {Current Diabetes Reports},
	volume = {22},
	number = {6},
	pages = {267 – 274},
	doi = {10.1007/s11892-022-01467-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128360844&doi=10.1007%2fs11892-022-01467-y&partnerID=40&md5=e09b825e5121fd17bd0fdd3381d43ed1},
	affiliations = {Wilmer Eye Institute, Johns Hopkins University School of Medicine, Johns Hopkins Hospital, Baltimore, MD, United States; Department of Ophthalmology, New York University School of Medicine, New York, NY, United States; Department of Ophthalmology and Visual Sciences, University of Wisconsin, Madison, WI, United States},
	abstract = {Purpose of Review: In this review, we focus on artificial intelligence (AI) algorithms for diabetic retinopathy (DR) screening and risk stratification and factors to consider when implementing AI algorithms in the clinic. Recent Findings: AI algorithms have been adopted, and have received regulatory approval, for automated detection of referable DR with clinically acceptable diagnostic performance. While these metrics are an important first step, performance metrics that go beyond measures of technical accuracy are needed to fully evaluate the impact of AI algorithm on patient outcomes. Summary: Recent advances in AI present an exciting opportunity to improve patient care. Using DR as an example, we have reviewed factors to consider in the implementation of AI algorithms in real-world clinical practice. These include real-world evaluation of safety, efficacy, and equity (bias); impact on patient outcomes; ethical, logistical, and regulatory factors. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Artificial intelligence; Deep learning; Diabetic retinopathy; Machine learning},
	keywords = {Algorithms; Artificial Intelligence; Benchmarking; Diabetes Mellitus; Diabetic Retinopathy; Humans; Mass Screening; algorithm; algorithm bias; artificial intelligence; clinical effectiveness; clinical practice; cost effectiveness analysis; deep learning; diabetic retinopathy; diagnostic accuracy; health care cost; health care delivery; health care quality; human; laboratory automation; machine learning; medical ethics; outcome assessment; patient care; patient safety; Review; risk assessment; sensitivity and specificity; algorithm; artificial intelligence; benchmarking; diabetes mellitus; diabetic retinopathy; mass screening},
	correspondence_address = {R. Channa; Department of Ophthalmology and Visual Sciences, University of Wisconsin, Madison, United States; email: rchanna@wisc.edu},
	publisher = {Springer},
	issn = {15344827},
	coden = {CDRUA},
	pmid = {35438458},
	language = {English},
	abbrev_source_title = {Curr. Diabetes Rep.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Mathews20222239,
	author = {Mathews, Debra J.H. and Balatbat, Celynne A. and Dzau, Victor J.},
	title = {Governance of Emerging Technologies in Health and Medicine - Creating a New Framework},
	year = {2022},
	journal = {New England Journal of Medicine},
	volume = {386},
	number = {23},
	pages = {2239 – 2242},
	doi = {10.1056/NEJMms2200907},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131771338&doi=10.1056%2fNEJMms2200907&partnerID=40&md5=68a65be24041ae150ba8eeadbb6d509a},
	affiliations = {Johns Hopkins Berman, Institute of Bioethics, Baltimore, United States; National Academy of Medicine, Washington, DC, United States},
	keywords = {Humans; Medicine; Article; community; conceptual framework; consensus; consumer; coronavirus disease 2019; ecosystem; encapsulation; ethics; funding; genetic screening; government; health; health care; health care policy; human; immigration; landscape; law; law enforcement; machine learning; medical technology; medicine; non profit organization; online system; pandemic; practice guideline; risk benefit analysis; technology; transcranial direct current stimulation; transcranial magnetic stimulation; transcutaneous electrical nerve stimulation; trust; volunteer; wellbeing; workforce},
	publisher = {Massachussetts Medical Society},
	issn = {00284793},
	coden = {NEJMA},
	pmid = {35417635},
	language = {English},
	abbrev_source_title = {New Engl. J. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Shoji2022,
	author = {Shoji, Fumihiro and Yamashita, Takanori and Kinoshita, Fumihiko and Takamori, Shinkichi and Fujishita, Takatoshi and Toyozawa, Ryo and Ito, Kensaku and Yamazaki, Koji and Nakashima, Naoki and Okamoto, Tatsuro},
	title = {Artificial intelligence-derived gut microbiome as a predictive biomarker for therapeutic response to immunotherapy in lung cancer: protocol for a multicentre, prospective, observational study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {6},
	doi = {10.1136/bmjopen-2022-061674},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131646147&doi=10.1136%2fbmjopen-2022-061674&partnerID=40&md5=9f52d1aaaf6f077ae06384bb1193f6ab},
	affiliations = {Department of Thoracic Oncology, National Kyushu Cancer Center, Fukuoka, Japan; Medical Information Center, Kyushu University, Fukuoka, Japan; Department of Thoracic Surgery, National Hospital Organisation Kyushu Medical Center, Fukuoka, Japan},
	abstract = {Introduction Immunotherapy is the fourth leading therapy for lung cancer following surgery, chemotherapy and radiotherapy. Recently, several studies have reported about the potential association between the gut microbiome and therapeutic response to immunotherapy. Nevertheless, the specific composition of the gut microbiome or combination of gut microbes that truly predict the efficacy of immunotherapy is not definitive. Methods and analysis The present multicentre, prospective, observational study aims to discover the specific composition of the gut microbiome or combination of gut microbes predicting the therapeutic response to immunotherapy in lung cancer using artificial intelligence. The main inclusion criteria are as follows: (1) pathologically or cytologically confirmed metastatic or postoperative recurrent lung cancer including non-small cell lung cancer and small cell lung cancer; (2) age≥20 years at the time of informed consent; (3) planned treatment with immunotherapy including combination therapy and monotherapy, as the first-line immunotherapy; and (4) ability to provide faecal samples. In total, 400 patients will be enrolled prospectively. Enrolment will begin in 2021, and the final analyses will be completed by 2024. Ethics and dissemination The study protocol was approved by the institutional review board of each participating centre in 2021 (Kyushu Cancer Center, IRB approved No. 2021-13, 8 June 2021 and Kyushu Medical Center, IRB approved No. 21-076, 31 August 2021). Study results will be disseminated through peer-reviewed journals and national and international conferences. Trial registration number UMIN000046428.  © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {respiratory medicine (see thoracic medicine); respiratory tract tumours; respiratory tract tumours},
	keywords = {Adult; Artificial Intelligence; Biomarkers; Carcinoma, Non-Small-Cell Lung; Gastrointestinal Microbiome; Humans; Immunotherapy; Lung Neoplasms; Multicenter Studies as Topic; Neoplasm Recurrence, Local; Observational Studies as Topic; Prospective Studies; Young Adult; atezolizumab; bevacizumab; biological marker; carboplatin; cisplatin; durvalumab; etoposide; ipilimumab; nivolumab; paclitaxel; pembrolizumab; pemetrexed; biological marker; adult; area under the curve; Article; artificial intelligence; cancer combination chemotherapy; cancer immunotherapy; clinical effectiveness; clinical protocol; combination chemotherapy; controlled study; data analysis; DNA extraction; feces analysis; female; gene amplification; human; informed consent; intestine flora; lung cancer; machine learning; major clinical study; male; monotherapy; multicenter study; multiple cycle treatment; non small cell lung cancer; nonhuman; observational study; predictive value; prospective study; sequence analysis; small cell lung cancer; treatment response; artificial intelligence; immunotherapy; lung tumor; multicenter study (topic); non small cell lung cancer; tumor recurrence; young adult},
	correspondence_address = {F. Shoji; Department of Thoracic Oncology, National Kyushu Cancer Center, Fukuoka, Japan; email: fumshojifumshoji@gmail.com},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35676015},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Adibi2022,
	author = {Adibi, Peyman and Ani, Alireza and Vaez, Ahmad and Hadizadeh, Fatemeh and Snieder, Harold and Roohafza, Hamidreza},
	title = {Multidisciplinary approach to functional somatic syndromes: study protocol for a population-based prospective cohort study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {7},
	doi = {10.1136/bmjopen-2021-048941},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134083446&doi=10.1136%2fbmjopen-2021-048941&partnerID=40&md5=367177fdd7457947dcaeb159a8a47bd2},
	affiliations = {Isfahan Gastroenterology and Hepatology Research Center, Isfahan University of Medical Sciences, Isfahan, Iran; Department of Internal Medicine, Isfahan University of Medical Sciences, Isfahan, Iran; Department of Epidemiology, University of Groningen, University Medical Center Groningen, Groningen, Netherlands; Department of Bioinformatics, Isfahan University of Medical Sciences, Isfahan, Iran; Cardiac Rehabilitation Research Center, Cardiovascular Research Institute, Isfahan University of Medical Sciences, Isfahan, Iran},
	abstract = {Introduction Isfahan functional disorders (ISFUN) cohort study aims to describe the interplay of genetic and environmental factors in shaping the characteristics of functional somatic syndromes (FSS). This study is primarily intended to investigate the epidemiology, risk factors, course and prognosis of FSSs in a sample of adult Iranian population. The other aim is to develop a new delimitation of FSSs based on an integrated multidisciplinary approach comprising of phenotypic and multiomics data. Methods and analysis ISFUN is a population-based prospective cohort study designed to follow a population of randomly selected seemingly healthy adults (18-65 years) through annual visits during a 4-year observation period. Structured questionnaires are used for data collection and clinical assessment of the participants. Questionnaire-based diagnosis of FSSs are validated in a medical interview. Human DNA genotyping, microbial amplicon sequencing and urine analysis is under progress for genomics, microbiota and metabolomics profiling, respectively. Enrolment began in September 2017, and study completion is expected in 2022. A total number of 1943 participants were initially recruited. Ethics and dissemination Ethical approval for data collection was granted by the National Research Ethics Committee of the Iranian Ministry of Health and Medical Education and the Research Ethics Committee of Isfahan University of Medical Sciences (IR.MUI.REC.1395.1.149). Following the description of the study procedure, we obtained written informed consent from all study participants. Study findings will be disseminated through peer-reviewed publications and presentations at scientific meetings.  © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {EPIDEMIOLOGY; Functional bowel disorders; Health informatics; INTERNAL MEDICINE},
	keywords = {Adult; Cohort Studies; Humans; Iran; Prospective Studies; Research Design; Syndrome; biological marker; genomic DNA; RNA 16S; adult; amplicon; anamnesis; Article; clinical assessment; clinical protocol; cohort analysis; controlled study; disease course; disease model; DNA sequencing; feces microflora; functional disease; genomics; genotyping; gold standard; human; information processing; interdisciplinary research; Iranian (citizen); Isfahan functional disorder; lifestyle; longitudinal study; machine learning; metabolomics; microorganism; multiomics; normal human; observational study; patient information; personalized medicine; phenotype; prevalence; prognosis; prospective study; psychological aspect; psychosomatic symptom; questionnaire; risk factor; sociodemographics; structured questionnaire; urinalysis; Iran; methodology; syndrome},
	correspondence_address = {A. Vaez; Department of Epidemiology, University of Groningen, University Medical Center Groningen, Groningen, Netherlands; email: a.vaez@umcg.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35777883},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{London2022,
	author = {London, Alex John},
	title = {Artificial intelligence in medicine: Overcoming or recapitulating structural challenges to improving patient care?},
	year = {2022},
	journal = {Cell Reports Medicine},
	volume = {3},
	number = {5},
	doi = {10.1016/j.xcrm.2022.100622},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130131366&doi=10.1016%2fj.xcrm.2022.100622&partnerID=40&md5=af71127476045298593c78d23903a3cb},
	affiliations = {Department of Philosophy and Center for Ethics and Policy, Carnegie Mellon University, Pittsburgh, 15228, PA, United States},
	abstract = {There is considerable enthusiasm about the prospect that artificial intelligence (AI) will help to improve the safety and efficacy of health services and the efficiency of health systems. To realize this potential, however, AI systems will have to overcome structural problems in the culture and practice of medicine and the organization of health systems that impact the data from which AI models are built, the environments into which they will be deployed, and the practices and incentives that structure their development. This perspective elaborates on some of these structural challenges and provides recommendations to address potential shortcomings. © 2022 The Author},
	author_keywords = {artificial intelligence; bias; bioethics; equity; healthcare; learning health systems; research ethics; social determinants of health; social value; structural injustice},
	keywords = {Artificial Intelligence; Humans; Medicine; Patient Care; artificial intelligence; clinical effectiveness; clinical practice; cultural anthropology; data analysis; ecosystem; health care organization; health care quality; health care system; health service; human; intervention study; knowledge; machine learning; medicine; patient care; patient safety; Review; social value; patient care},
	correspondence_address = {A.J. London; Department of Philosophy and Center for Ethics and Policy, Carnegie Mellon University, Pittsburgh, 15228, United States; email: ajlondon@andrew.cmu.edu},
	publisher = {Cell Press},
	issn = {26663791},
	pmid = {35584620},
	language = {English},
	abbrev_source_title = {Cell Rep. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Liu2022,
	author = {Liu, Jihong and Hung, Peiyin and Liang, Chen and Zhang, Jiajia and Qiao, Shan and Campbell, Berry A and Olatosi, Bankole and Torres, Myriam E and Hikmet, Neset and Li, Xiaoming},
	title = {Multilevel determinants of racial/ethnic disparities in severe maternal morbidity and mortality in the context of the COVID-19 pandemic in the USA: protocol for a concurrent triangulation, mixed-methods study},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {6},
	doi = {10.1136/bmjopen-2022-062294},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131903719&doi=10.1136%2fbmjopen-2022-062294&partnerID=40&md5=381f0046138ea80e5f8f929b32cee146},
	affiliations = {Department of Epidemiology & Biostatistics, University of South Carolina Arnold, School of Public Health, Columbia, SC, United States; Department of Health Services Policy & Management, University of South Carolina Arnold, School of Public Health, Columbia, SC, United States; Department of Health Promotion, Education, & Behavior, University of South Carolina Arnold, School of Public Health, Columbia, SC, United States; Department of Obstetrics and Gynecology, University of South Carolina, School of Medicine, Columbia, SC, United States; Department of Integrated Information Technology, University of South Carolina, College of Engineering and Computing, Columbia, SC, United States},
	abstract = {Introduction The COVID-19 pandemic has affected communities of colour the hardest. Non-Hispanic black and Hispanic pregnant women appear to have disproportionate SARS-CoV-2 infection and death rates. Methods and analysis We will use the socioecological framework and employ a concurrent triangulation, mixed-methods study design to achieve three specific aims: (1) examine the impacts of the COVID-19 pandemic on racial/ethnic disparities in severe maternal morbidity and mortality (SMMM); (2) explore how social contexts (eg, racial/ethnic residential segregation) have contributed to the widening of racial/ethnic disparities in SMMM during the pandemic and identify distinct mediating pathways through maternity care and mental health; and (3) determine the role of social contextual factors on racial/ethnic disparities in pregnancy-related morbidities using machine learning algorithms. We will leverage an existing South Carolina COVID-19 Cohort by creating a pregnancy cohort that links COVID-19 testing data, electronic health records (EHRs), vital records data, healthcare utilisation data and billing data for all births in South Carolina (SC) between 2018 and 2021 (>200 000 births). We will also conduct similar analyses using EHR data from the National COVID-19 Cohort Collaborative including >270 000 women who had a childbirth between 2018 and 2021 in the USA. We will use a convergent parallel design which includes a quantitative analysis of data from the 2018-2021 SC Pregnancy Risk Assessment and Monitoring System (unweighted n>2000) and in-depth interviews of 40 postpartum women and 10 maternal care providers to identify distinct mediating pathways. Ethics and dissemination The study was approved by institutional review boards at the University of SC (Pro00115169) and the SC Department of Health and Environmental Control (DHEC IRB.21-030). Informed consent will be provided by the participants in the in-depth interviews. Study findings will be disseminated with key stakeholders including patients, presented at academic conferences and published in peer-reviewed journals.  © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {COVID-19; EPIDEMIOLOGY; Health informatics; Maternal medicine; PERINATOLOGY; PUBLIC HEALTH},
	keywords = {COVID-19; COVID-19 Testing; Female; Humans; Maternal Health Services; Morbidity; Pandemics; Parturition; Pregnancy; SARS-CoV-2; United States; adult; African American; algorithm; Article; Black person; body mass; Caucasian; clinical protocol; cohort analysis; comorbidity; coronavirus disease 2019; disease severity; electronic health record; ethnic disparity; female; health care utilization; Hispanic; human; hypertension; ICD-10; machine learning; maternal care; maternal morbidity; maternal mortality; pandemic; parallel design; predictive model; pregnant woman; prepregnancy care; qualitative analysis; quantitative analysis; racial disparity; social determinants of health; social distancing; social environment; social inequality; social segregation; sociodemographics; South Carolina; triangulation; birth; epidemiology; maternal health service; morbidity; pandemic; pregnancy; United States},
	correspondence_address = {J. Liu; Department of Epidemiology & Biostatistics, University of South Carolina Arnold, School of Public Health, Columbia, United States; email: jliu@mailbox.sc.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35688597},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{2022,
	title = {CHI 2022 - Extended Abstracts of the 2022 CHI Conference on Human Factors in Computing Systems},
	year = {2022},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129721946&partnerID=40&md5=b4e36627f87e1451dcd4b69b18ef4b52},
	abstract = {The proceedings contain 491 papers. The topics discussed include: towards fair and pro-social employment of digital pieceworkers for sourcing machine learning training data; art is not research. Research is not art; the future of work is no work: a call to action for designers in the abolition of work; when virtuality surpasses reality: possible futures of ubiquitous XR; from sensable to sensible spaces: enhancing the sensibility of a home office using stress-aware deep reinforcement learning in virtual environments; calmbots: exploring possibilities of multiple insects with on-hand devices and flexible controls as creation interfaces; metaphorical visualization: mapping data to familiar concepts; share your values! community-driven embedding of ethics in research; a speculative ethics for designing with bodily fluids; design futuring for love, friendship, and kinships: five perspectives on intimacy; and interacting by drawing: introducing machine learning ideas to children at a K-9 science fair.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039156-6},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 CHI Conference on Human Factors in Computing Systems, CHI EA 2022; Conference date: 30 April 2022 through 5 May 2022; Conference code: 179030}
}

@ARTICLE{Horváth20221,
	author = {Horváth, Ildikó},
	title = {AI in interpreting: Ethical considerations},
	year = {2022},
	journal = {Across Languages and Cultures},
	volume = {23},
	number = {1},
	pages = {1 – 13},
	doi = {10.1556/084.2022.00108},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137753799&doi=10.1556%2f084.2022.00108&partnerID=40&md5=da61a6bd41d89d16f8907fde82f80125},
	affiliations = {Department of Translation and Interpreting, Elte University, Budapest, Hungary},
	abstract = {Artificial intelligence (AI) and machine learning technologies have impacted on the language mediation market with the spread of machine translation (MT) and the creation of sub-tasks such as text preparation for translation and post-editing. Up until this time, the impact of machine interpretation on the interpretation profession cannot be felt to the same extent as that of MT on the translation profession. Technological advances, however, have not come to an end and nowadays fully-automated machine interpretation and AI-based computer assisted interpreting (CAI) tools are increasingly common in the interpreting profession. However, the use of AI and big data in interpreting raises several ethical questions in terms of data protection and confidentiality. The earliest references to MT date back to the 1930s. Despite this long history ethical considerations in MT have rarely been discussed in Translation Studies, and to our knowledge, they have not been discussed at all in Interpreting Studies. This article first examines how AI can be used in interpreting as well as the various tools already available, then discusses the ethical considerations raised by the use of AI in general and in interpreting in particular.  © 2022 The Author(s).},
	author_keywords = {AI-based CAI; artificial intelligence; automated speech translation; ethics; interpreting; online interpreting delivery platforms},
	correspondence_address = {I. Horváth; Department of Translation and Interpreting, Elte University, Budapest, Hungary; email: horvath.ildiko0821@gmail.com},
	publisher = {Akademiai Kiado ZRt.},
	issn = {15851923},
	language = {English},
	abbrev_source_title = {Across Lang. Cult.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Simons2022,
	author = {Simons, Laura and Moayedi, Massieh and Coghill, Robert C and Stinson, Jennifer and Angst, Martin S and Aghaeepour, Nima and Gaudilliere, Brice and King, Christopher D and López-Solà, Marina and Hoeppli, Marie-Eve and Biggs, Emma and Ganio, Ed and Williams, Sara E and Goldschneider, Kenneth R and Campbell, Fiona and Ruskin, Danielle and Krane, Elliot J and Walker, Suellen and Rush, Gillian and Heirich, Marissa},
	title = {Signature for Pain Recovery IN Teens (SPRINT): protocol for a multisite prospective signature study in chronic musculoskeletal pain},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {6},
	doi = {10.1136/bmjopen-2022-061548},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131639857&doi=10.1136%2fbmjopen-2022-061548&partnerID=40&md5=8333db545845eace74920de0929f1863},
	affiliations = {Department of Anesthesiology, Perioperative and Pain Medicine, Stanford University School of Medicine, Stanford, CA, United States; Centre for Multimodal Sensorimotor and Pain Research, University of Toronto, Faculty of Dentistry, ON, Toronto, Canada; Centre for the Study of Pain, University of Toronto, ON, Toronto, Canada; Department of Pediatrics, University of Cincinnati, Cincinnati, OH, United States; Division of Behavioral Medicine and Clinical Psychology, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States; Pediatric Pain Research Center (PPRC), Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States; Department of Anesthesia and Pain Medicine, The Hospital for Sick Children, ON, Toronto, Canada; The Research Institute, The Hospital for Sick Children, ON, Toronto, Canada; Serra Hunter Programme, Department of Medicine, University of Barcelona, Barcelona, Spain; Department of Anesthesiology, Cincinnati Children's Hospital Medical Center, Cincinnati, OH, United States; Department of Psychology, The Hospital for Sick Children, ON, Toronto, Canada; Developmental Neurosciences Department, Ucl Gos Institute of Child Health, Ucl, London, United Kingdom},
	abstract = {Introduction Current treatments for chronic musculoskeletal (MSK) pain are suboptimal. Discovery of robust prognostic markers separating patients who recover from patients with persistent pain and disability is critical for developing patient-specific treatment strategies and conceiving novel approaches that benefit all patients. Given that chronic pain is a biopsychosocial process, this study aims to discover and validate a robust prognostic signature that measures across multiple dimensions in the same adolescent patient cohort with a computational analysis pipeline. This will facilitate risk stratification in adolescent patients with chronic MSK pain and more resourceful allocation of patients to costly and potentially burdensome multidisciplinary pain treatment approaches. Methods and analysis Here we describe a multi-institutional effort to collect, curate and analyse a high dimensional data set including epidemiological, psychometric, quantitative sensory, brain imaging and biological information collected over the course of 12 months. The aim of this effort is to derive a multivariate model with strong prognostic power regarding the clinical course of adolescent MSK pain and function. Ethics and dissemination The study complies with the National Institutes of Health policy on the use of a single internal review board (sIRB) for multisite research, with Cincinnati Children's Hospital Medical Center Review Board as the reviewing IRB. Stanford's IRB is a relying IRB within the sIRB. As foreign institutions, the University of Toronto and The Hospital for Sick Children (SickKids) are overseen by their respective ethics boards. All participants provide signed informed consent. We are committed to open-access publication, so that patients, clinicians and scientists have access to the study data and the signature(s) derived. After findings are published, we will upload a limited data set for sharing with other investigators on applicable repositories. Trial registration number NCT04285112.  © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {IMMUNOLOGY; Magnetic resonance imaging; Paediatric anaesthesia; Paediatric anaesthesia; PAIN MANAGEMENT; STATISTICS & RESEARCH METHODS},
	keywords = {Adolescent; Child; Chronic Pain; Humans; Musculoskeletal Pain; National Institutes of Health (U.S.); Pain Management; Prospective Studies; United States; interleukin 1beta; interleukin 2; interleukin 4; interleukin 6; adolescent; adult; aged; analgesia; Article; brain region; Brief Pain Inventory; caregiver; chronic pain; clinical protocol; cohort analysis; controlled study; demographics; diffusion weighted imaging; disease course; echo planar imaging; electronic medical record; female; flow cytometry; functional disability inventory; functional disease; functional magnetic resonance imaging; functional status assessment; gray matter; health care policy; hemodynamics; human; ICD-11; immunocompetent cell; machine learning; male; multicenter study; musculoskeletal function; musculoskeletal pain; nerve cell plasticity; neutrophil; nuclear magnetic resonance imaging; numeric rating scale; pain intensity; pressure pain threshold; prospective study; psychometry; quantitative analysis; quantitative sensory testing; questionnaire; resting state network; structural nuclear magnetic resonance imaging; visual analog scale; child; chronic pain; national health organization; United States},
	correspondence_address = {L. Simons; Department of Anesthesiology, Perioperative and Pain Medicine, Stanford University School of Medicine, Stanford, United States; email: lesimons@stanford.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35676017},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Rothschild2022,
	author = {Rothschild, Annabel and Booker, Justin and Davoll, Christa and Hill, Jessica and Ivey, Venise and Disalvo, Carl and Rydal Shapiro, Ben and Disalvo, Betsy},
	title = {Towards fair and pro-social employment of digital pieceworkers for sourcing machine learning training data},
	year = {2022},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3491101.3516384},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129741512&doi=10.1145%2f3491101.3516384&partnerID=40&md5=a1db4a6dc3420993175c92322a0f33cb},
	affiliations = {Georgia Institute of Technology, United States; DataWorks, Georgia Institute of Technology, United States},
	abstract = {This pieceworkers ("crowd collaborators") by reforming the handling of crowd-sourced labor in academic venues. With the rise in automation, crowd collaborators treatment requires special consideration, as the system often dehumanizes crowd collaborators as components of the "crowd"[41]. Building of eforts to (proxy-)unionize crowd workers and facilitate employment protections on digital piecework platforms, we focus on employers: academic requesters sourcing machine learning (ML) training data. We propose a cover sheet to accompany submission of work that engages crowd collaborators for sourcing (or labeling) ML training data. The guidelines are based on existing calls from worker organizations (e.g., Dynamo [28]); professional data workers in an alternative digital piecework organization; and lived experience as requesters and workers on digital piecework platforms. We seek feedback on the cover sheet from the ACM community. © 2022 Owner/Author.},
	author_keywords = {Amazon Mechanical Turk; computing ethics; crowd collaboration; crowd working; Platform labor},
	keywords = {Machine learning; Amazon's mechanical turks; Computing ethic; Crowd collaboration; Crowd working; Labelings; Platform labor; Training data; Workers'; E-learning},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039156-6},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 CHI Conference on Human Factors in Computing Systems, CHI EA 2022; Conference date: 30 April 2022 through 5 May 2022; Conference code: 179030}
}

@CONFERENCE{Kasirzadeh2022349,
	author = {Kasirzadeh, Atoosa},
	title = {Algorithmic Fairness and Structural Injustice: Insights from Feminist Political Philosophy},
	year = {2022},
	journal = {AIES 2022 - Proceedings of the 2022 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {349 – 356},
	doi = {10.1145/3514094.3534188},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137157991&doi=10.1145%2f3514094.3534188&partnerID=40&md5=4c177887c656c6316d29bfb7a873f73f},
	affiliations = {University of Edinburgh, Edinburgh, United Kingdom},
	abstract = {Data-driven predictive algorithms are widely used to automate and guide high-stake decision making such as bail and parole recommendation, medical resource distribution, and mortgage allocation. Nevertheless, harmful outcomes biased against vulnerable groups have been reported. The growing research field known as 'algorithmic fairness' aims to mitigate these harmful biases. Its primary methodology consists in proposing mathematical metrics to address the social harms resulting from an algorithm's biased outputs. The metrics are typically motivated by-or substantively rooted in-ideals of distributive justice, as formulated by political and legal philosophers. The perspectives of feminist political philosophers on social justice, by contrast, have been largely neglected. Some feminist philosophers have criticized the local scope of the paradigm of distributive justice and have proposed corrective amendments to surmount its limitations. The present paper brings some key insights of feminist political philosophy to algorithmic fairness. The paper has three goals. First, I show that algorithmic fairness does not accommodate structural injustices in its current scope. Second, I defend the relevance of structural injustices-as pioneered in the contemporary philosophical literature by Iris Marion Young-to algorithmic fairness. Third, I take some steps in developing the paradigm of 'responsible algorithmic fairness' to correct for errors in the current scope and implementation of algorithmic fairness. I close by some reflections of directions for future research.  © 2022 Owner/Author.},
	author_keywords = {algorithmic bias; algorithmic fairness; algorithmic justice; distributive justice; ethical machine learning; ethics of artificial intelligence; feminist philosophy; political philosophy; responsibility; structural injustice},
	keywords = {Decision making; Ethical technology; Algorithmic bias; Algorithmic fairness; Algorithmic justice; Algorithmics; Distributive justice; Ethic of artificial intelligence; Ethical machine learning; Feminist philosophy; Machine-learning; Political philosophy; Responsibility; Structural injustice; Machine learning},
	correspondence_address = {A. Kasirzadeh; University of Edinburgh, Edinburgh, United Kingdom; email: atoosa.kasirzadeh@ed.ac.uk},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039247-1},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 5th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2022; Conference date: 1 August 2022 through 3 August 2022; Conference code: 181805; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{John-Mathews2022945,
	author = {John-Mathews, Jean-Marie and Cardon, Dominique and Balagué, Christine},
	title = {From Reality to World. A Critical Perspective on AI Fairness},
	year = {2022},
	journal = {Journal of Business Ethics},
	volume = {178},
	number = {4},
	pages = {945 – 959},
	doi = {10.1007/s10551-022-05055-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125255555&doi=10.1007%2fs10551-022-05055-8&partnerID=40&md5=2111f3489e8e14ac3b5f26f9f1455e4e},
	affiliations = {Université Paris-Saclay, Univ Evry, IMT-BS, LITEM, Evry, Paris, 91025, France; médialab, Sciences Po, 27 rue Saint Guillaume, Paris, 75 011, France},
	abstract = {Fairness of Artificial Intelligence (AI) decisions has become a big challenge for governments, companies, and societies. We offer a theoretical contribution to consider AI ethics outside of high-level and top-down approaches, based on the distinction between “reality” and “world” from Luc Boltanski. To do so, we provide a new perspective on the debate on AI fairness and show that criticism of ML unfairness is “realist”, in other words, grounded in an already instituted reality based on demographic categories produced by institutions. Second, we show that the limits of “realist” fairness corrections lead to the elaboration of “radical responses” to fairness, that is, responses that radically change the format of data. Third, we show that fairness correction is shifting to a “domination regime” that absorbs criticism, and we provide some theoretical and practical avenues for further development in AI ethics. Using an ad hoc critical space stabilized by reality tests alongside the algorithm, we build a shared responsibility model which is compatible with the radical response to fairness issues. Finally, this paper shows the fundamental contribution of pragmatic sociology theories, insofar as they afford a social and political perspective on AI ethics by giving an active role to material actors such as database formats on ethical debates. In a context where data are increasingly numerous, granular, and behavioral, it is essential to renew our conception of AI ethics on algorithms in order to establish new models of responsibility for companies that take into account changes in the computing paradigm. © 2022, The Author(s).},
	author_keywords = {Artificial intelligence; Big data; Business ethics; Fairness; Machine learning; Pragmatic sociology; Responsibility model},
	correspondence_address = {J.-M. John-Mathews; Université Paris-Saclay, Univ Evry, IMT-BS, LITEM, Paris, Evry, 91025, France; email: jean-marie.john-mathews@imt-bs.eu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {01674544},
	language = {English},
	abbrev_source_title = {J. Bus. Ethics},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@ARTICLE{Chikhaoui2022717,
	author = {Chikhaoui, Emna and Alajmi, Alanoud and Larabi-Marie-sainte, Souad},
	title = {Artificial Intelligence Applications in Healthcare Sector: Ethical and Legal Challenges},
	year = {2022},
	journal = {Emerging Science Journal},
	volume = {6},
	number = {4},
	pages = {717 – 738},
	doi = {10.28991/ESJ-2022-06-04-05},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133166494&doi=10.28991%2fESJ-2022-06-04-05&partnerID=40&md5=b82ffd75e4fe406280ad4404b9db5f96},
	affiliations = {College of Law, Prince Sultan University, Riyadh, 11586, Saudi Arabia; Computer Science Department, College of Computer and Information Sciences, Prince Sultan University, Riyadh, 11586, Saudi Arabia},
	abstract = {Recently, artificial intelligence (AI) has been one of the hottest topics in the technological world. Although it is involved in many domains, it was recently involved in the healthcare sector. AI can be used for diagnostics, drug development, treatment personalization, gene editing, disease prediction, and many more. It helps to improve healthcare services by benefiting medical professionals, hospitals, and patients. Saudi Arabia has a particular interest in the healthcare sector, and it has a clear vision for the future, which points toward the development of AI-based technologies. Few studies investigated the use of AI in Saudi healthcare, and most of them focused on healthcare employees' perceptions. This study is beyond the focus of the existing works. It aims at: 1) presenting the main AI-based healthcare applications; 2) exploring the use of AI in the Saudi healthcare sector; 3) addressing their ethical and legal challenges, along with the policy questions in Saudi healthcare; 4) studying the benefits of these AI-based applications and the acceptance of professionals to use AI in daily practice; 5) introducing the new Personal Data Protection Law (PDPL) in Saudi Arabia; and 6) discussing the importance of AI to the future of Saudi healthcare. To this purpose, a survey was distributed among four main Saudi hospitals. The findings showed that AI should not only lead to better health but also save manpower and simplify the healthcare processes. The respondents agreed that AI helps reflect human intellectual competencies and pushes its limits. © 2022 by the authors.},
	author_keywords = {Artificial Intelligence; Data Protection; Data Transfer; Deep Learning; Ethics; Healthcare; Intellectual Property; Machine Learning; Privacy},
	correspondence_address = {S. Larabi-Marie-sainte; Computer Science Department, College of Computer and Information Sciences, Prince Sultan University, Riyadh, 11586, Saudi Arabia; email: slarabi@psu.edu.sa},
	publisher = {Ital Publication},
	issn = {26109182},
	language = {English},
	abbrev_source_title = {Emerg. Sci. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Bilal2022,
	author = {Bilal, Ayesha M and Fransson, Emma and Bränn, Emma and Eriksson, Allison and Zhong, Mengyu and Gidén, Karin and Elofsson, Ulf and Axfors, Cathrine and Skalkidou, Alkistis and Papadopoulos, Fotios C},
	title = {Predicting perinatal health outcomes using smartphone-based digital phenotyping and machine learning in a prospective Swedish cohort (Mom2B): Study protocol},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {4},
	doi = {10.1136/bmjopen-2021-059033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128935988&doi=10.1136%2fbmjopen-2021-059033&partnerID=40&md5=24eb720b2e68fca107570a25bfb8c0ed},
	affiliations = {Department of Medical Sciences, Uppsala University, Uppsala, Sweden; Centre for Women's Mental Health during the Reproductive Lifespan (Womher), Uppsala University, Uppsala, Sweden; Department of Women's and Children's Health, Uppsala University, Uppsala, Sweden; Centre for Translational Microbiome Research, Department of Microbiology, Tumor and Cell Biology, Karolinska Institute, Stockholm, Sweden; Department of Information Technology, Uppsala University, Uppsala, Sweden},
	abstract = {Introduction Perinatal complications, such as perinatal depression and preterm birth, are major causes of morbidity and mortality for the mother and the child. Prediction of high risk can allow for early delivery of existing interventions for prevention. This ongoing study aims to use digital phenotyping data from the Mom2B smartphone application to develop models to predict women at high risk for mental and somatic complications. Methods and analysis All Swedish-speaking women over 18 years, who are either pregnant or within 3 months postpartum are eligible to participate by downloading the Mom2B smartphone app. We aim to recruit at least 5000 participants with completed outcome measures. Throughout the pregnancy and within the first year postpartum, both active and passive data are collected via the app in an effort to establish a participant's digital phenotype. Active data collection consists of surveys related to participant background information, mental and physical health, lifestyle, and social circumstances, as well as voice recordings. Participants' general smartphone activity, geographical movement patterns, social media activity and cognitive patterns can be estimated through passive data collection from smartphone sensors and activity logs. The outcomes will be measured using surveys, such as the Edinburgh Postnatal Depression Scale, and through linkage to national registers, from where information on registered clinical diagnoses and received care, including prescribed medication, can be obtained. Advanced machine learning and deep learning techniques will be applied to these multimodal data in order to develop accurate algorithms for the prediction of perinatal depression and preterm birth. In this way, earlier intervention may be possible. Ethics and dissemination Ethical approval has been obtained from the Swedish Ethical Review Authority (dnr: 2019/01170, with amendments), and the project fully fulfils the General Data Protection Regulation (GDPR) requirements. All participants provide consent to participate and can withdraw their participation at any time. Results from this project will be disseminated in international peer-reviewed journals and presented in relevant conferences.  © 2022 Authors.},
	author_keywords = {anxiety disorders; depression & mood disorders; maternal medicine; mental health; perinatology; preventive medicine},
	keywords = {Female; Humans; Infant, Newborn; Machine Learning; Outcome Assessment, Health Care; Pregnancy; Premature Birth; Prospective Studies; Smartphone; Sweden; adult; Article; clinical assessment; clinical protocol; cognition; cohort analysis; computer model; deep learning; digital technology; Edinburgh Postnatal Depression Scale; feature selection; female; first trimester pregnancy; health status; high risk patient; high risk pregnancy; human; information processing; lifestyle modification; machine learning; major clinical study; maternal care; medical information; mental disease; mental health; metadata; mobile application; perinatal care; perinatal depression; pregnancy; premature labor; prospective study; psychosomatic disorder; puerperium; recording; social media; social psychology; speech; third trimester pregnancy; voice; machine learning; newborn; prematurity; smartphone; Sweden},
	correspondence_address = {A.M. Bilal; Department of Medical Sciences, Uppsala University, Uppsala, Sweden; email: ayesha.bilal@neuro.uu.se},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35477874},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gu20221018,
	author = {Gu, Tian-Long and Li, Long and Chang, Liang and Luo, Yi-Qin},
	title = {Fair Machine Learning: Concepts, Analysis, and Design; [公平机器学习:概念, 分析与设计]},
	year = {2022},
	journal = {Jisuanji Xuebao/Chinese Journal of Computers},
	volume = {45},
	number = {5},
	pages = {1018 – 1051},
	doi = {10.11897/SP.J.1016.2022.01018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129460719&doi=10.11897%2fSP.J.1016.2022.01018&partnerID=40&md5=df50d4e79879c6e1934f460befc5662a},
	affiliations = {College of Information Science and Technology, Jinan University, Guangzhou, 510632, China; Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, 541004, China},
	abstract = {With the development of artificial intelligence, machine learning techniques is increasingly used in many social domains to assist or replace humankinds in decision-making, especially in some critical areas, such as, credit rating, students' qualification evaluation, welfare resource allocation, clinical diagnosis, natural language processing, personalized information recommendation, criminal judgment, autonomous vehicles and so on. Due to the intrinsic and technical characteristics of machine learning itself, its prediction and decision-making will inevitably produce a certain degree of bias or unfairness, which has gradually attracted the attention of scientific research, industry practitioners and the public. How to ensure fair or unbiased decisions in machine learning?How to protect the interests of disadvantaged groups in these applications? These issues have important impacts on the society and the public's confidence in machine learning and affect the application of artificial intelligence technology and the deployment of artificial intelligence systems. Fairness has been one of the basic supporting capabilities of trustworthy artificial intelligence, and machine learning with fairness is referred to as fair machine learning. In this paper, the concepts of fairness, the methods of discovering unfair or biased discrimination and the design techniques of fair machine learning are reviewed and discussed. The detailed contents include the followings. Firstly, discrimination and bias are terminologies related to unfairness, and unfair behavior is known as biased behavior or discriminatory behavior. Since the taxonomy of discrimination and biases is helpful to understand and evaluate the fairness, direct discrimination, indirect discrimination, interpretable discrimination, uninterpretable discrimination, statistical discrimination and systematic discrimination are explained. In the framework of statistics, similarity and causal inference, the definitions and quantification of fairness in machine learning are categorized and explained. Secondly, the bias or prejudice is the main source of discrimination and unfairness. The training data and algorithms involved in machine learning can have biases that lead to unfair model predictions. From the perspectives of data, algorithm and human-computer interaction, the biases in the life cycle of machine learning are classified and discussed. The techniques to discover biases in machine learning, such as association rule mining, k-nearest neighbor classification, probabilistic causal network, and privacy attack and deep learning methods, are illustrated. Meanwhile, the design methodologies of fair machine learning have been undertaken roughly in three directions. On the view of specific applicable tasks, fair natural language processing, fair face recognition, fair recommendation system, fair classification, fair regression and fair clustering are elaborated. In light of particular machine learning algorithms, fair representation and fair adversarial learning are discoursed. From the life cycle of machine learning, preprocessing methods, intermediate processing methods and post-processing methods are expounded. Then, for the trustworthy artificial intelligence, the recent studies regarding anonymous protection, secure multi-party computing and security attack and defense for fair machine learning are promising works, which are briefly introduced. The explainability can help to discover algorithmic bias in machine learning models, on which some preliminary attempts are conducted, also being described. Finally, the main problems, challenges and hot topics in the research of fair machine learning, such as evaluation and testing of fair machine learning, novel modes of fair machine learning and ethically aligned machine learning, are presented. © 2022, Science Press. All right reserved.},
	author_keywords = {Artificial intelligence ethics; Fairness; Interpretability; Machine learning; Privacy protection},
	keywords = {Decision making; Deep learning; Diagnosis; Ethical technology; Face recognition; Human computer interaction; Life cycle; Natural language processing systems; Nearest neighbor search; Artificial intelligence ethic; Concept analysis; Concept designs; Decisions makings; Fairness; Interpretability; Machine learning techniques; Machine-learning; Privacy protection; Social domains; Learning algorithms},
	correspondence_address = {L. Li; College of Information Science and Technology, Jinan University, Guangzhou, 510632, China; email: lilong@guet.edu.cn; L. Li; Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, 541004, China; email: lilong@guet.edu.cn},
	publisher = {Science Press},
	issn = {02544164},
	coden = {JIXUD},
	language = {Chinese},
	abbrev_source_title = {Jisuanji Xuebao},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Thylstrup2022,
	author = {Thylstrup, Nanna Bonde and Hansen, Kristian Bondo and Flyverbom, Mikkel and Amoore, Louise},
	title = {Politics of data reuse in machine learning systems: Theorizing reuse entanglements},
	year = {2022},
	journal = {Big Data and Society},
	volume = {9},
	number = {2},
	doi = {10.1177/20539517221139785},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144219501&doi=10.1177%2f20539517221139785&partnerID=40&md5=e25b80258803781141201088a05cba34},
	affiliations = {Department of Management, Society and Communication, Copenhagen Business School, Frederiksberg, Denmark; Department of Geography, Durham University, Durham, United Kingdom},
	abstract = {Policy discussions and corporate strategies on machine learning are increasingly championing data reuse as a key element in digital transformations. These aspirations are often coupled with a focus on responsibility, ethics and transparency, as well as emergent forms of regulation that seek to set demands for corporate conduct and the protection of civic rights. And the Protective measures include methods of traceability and assessments of ‘good’ and ‘bad’ datasets and algorithms that are considered to be traceable, stable and contained. However, these ways of thinking about both technology and ethics obscure a fundamental issue, namely that machine learning systems entangle data, algorithms and more-than-human environments in ways that challenge a well-defined separation. This article investigates the fundamental fallacy of most data reuse strategies as well as their regulation and mitigation strategies that data can somehow be followed, contained and controlled in machine learning processes. Instead, the article argues that we need to understand the reuse of data as an inherently entangled phenomenon. To examine this tension between the discursive regimes and the realities of data reuse, we advance the notion of reuse entanglements as an analytical lens. The main contribution of the article is the conceptualization of reuse that places entanglements at its core and the articulation of its relevance using empirical illustrations. This is important, we argue, for our understanding of the nature of data and algorithms, for the practical uses of data and algorithms and our attitudes regarding ethics, responsibility and regulation. © The Author(s) 2022.},
	author_keywords = {algorithms; Data reuse; datasets; entanglements; ethics; machine learning},
	keywords = {Ethical technology; Learning algorithms; Learning systems; Corporate strategies; Data reuse; Dataset; Entanglement; Key elements; Machine learning systems; Machine-learning; On-machines; Policy discussion; Reuse; Machine learning},
	correspondence_address = {N.B. Thylstrup; Department of Management, Society and Communication, Copenhagen Business School, Frederiksberg, Denmark; email: nbt.msc@cbs.dk},
	publisher = {SAGE Publications Ltd},
	issn = {20539517},
	language = {English},
	abbrev_source_title = {Big Data  Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Schwöbel20222179,
	author = {Schwöbel, Pola and Remmers, Peter},
	title = {The Long Arc of Fairness: Formalisations and Ethical Discourse},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {2179 – 2188},
	doi = {10.1145/3531146.3534635},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133009354&doi=10.1145%2f3531146.3534635&partnerID=40&md5=5819b4749d97982efc762453ef274c79},
	affiliations = {Section for Cognitive Systems, Technical University of Denmark, Copenhagen, Denmark; Technische Universität Berlin, Berlin, Germany},
	abstract = {In recent years, the idea of formalising and modelling fairness for algorithmic decision making (ADM) has advanced to a point of sophisticated specialisation. However, the relations between technical (formalised) and ethical discourse on fairness are not always clear and productive. Arguing for an alternative perspective, we review existing fairness metrics and discuss some common issues. For instance, the fairness of procedures and distributions is often formalised and discussed statically, disregarding both structural preconditions of the status quo and downstream effects of a given intervention. We then introduce dynamic fairness modelling, a more comprehensive approach that realigns formal fairness metrics with arguments from the ethical discourse. A dynamic fairness model incorporates (1) ethical goals, (2) formal metrics to quantify decision procedures and outcomes and (3) mid-term or long-term downstream effects. By contextualising these elements of fairness-related processes, dynamic fairness modelling explicates formerly latent ethical aspects and thereby provides a helpful tool to navigate trade-offs between different fairness interventions. To illustrate the framework, we discuss an example application - the current European efforts to increase the number of women on company boards, e .g. via quota solutions - and present early technical work that fits within our framework. © 2022 ACM.},
	author_keywords = {algorithmic decision making; algorithmic fairness; dynamic fairness modelling; ethics of machine learning; fairness metrics},
	keywords = {Economic and social effects; Ethical technology; Machine learning; Algorithmic decision making; Algorithmic fairness; Algorithmics; Decisions makings; Dynamic fairness modeling; Ethic of machine learning; Fairness metric; Fairness model; Machine-learning; Decision making},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039352-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 5th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2022; Conference date: 21 June 2022 through 24 June 2022; Conference code: 180210; All Open Access, Green Open Access}
}

@CONFERENCE{Mashhadi2022,
	author = {Mashhadi, Afra and Zolyomi, Annuska and Quedado, Jay},
	title = {A Case Study of Integrating Fairness Visualization Tools in Machine Learning Education},
	year = {2022},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3491101.3503568},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129702990&doi=10.1145%2f3491101.3503568&partnerID=40&md5=9775e8a5ecb6ca3890505c9b23e320e2},
	affiliations = {Computing and Software Systems, University of Washington Bothell, Bothell, WA, United States},
	abstract = {As demonstrated by media attention and research, Artificial Intelligence systems are not adequately addressing issues of fairness and bias, and more education on these topics is needed in industry and higher education. Currently, computer science courses that cover AI fairness and bias focus on statistical analysis or, on the other hand, attempt to bring in philosophical perspectives that lack actionable takeaways for students. Based on long-standing pedagogical research demonstrating the importance of using tools and visualizations to reinforce student learning, this case study reports on the impacts of using publicly-available visualization tools used in HCI practice as a resource for students examining algorithmic fairness concepts. Through qualitative review and observations of four focus groups, we examined six open-source fairness tools that enable students to visualize, quantify and explore algorithmic biases. The findings of this study provide insights into the benefits, challenges, and opportunities of integrating fairness tools as part of machine learning education. © 2022 Owner/Author.},
	author_keywords = {Ethics; Fairness; Tools},
	keywords = {Education computing; Ethical technology; Machine learning; Visualization; Algorithmics; Artificial intelligence systems; Case-studies; Computer Science course; Fairness; High educations; Machine-learning; Media attention; Media research; Visualization tools; Students},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039156-6},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 CHI Conference on Human Factors in Computing Systems, CHI EA 2022; Conference date: 30 April 2022 through 5 May 2022; Conference code: 179030}
}

@ARTICLE{Crossnohere2022,
	author = {Crossnohere, Norah L. and Elsaid, Mohamed and Paskett, Jonathan and Bose-Brill, Seuli and Bridges, John F.P.},
	title = {Guidelines for Artificial Intelligence in Medicine: Literature Review and Content Analysis of Frameworks},
	year = {2022},
	journal = {Journal of Medical Internet Research},
	volume = {24},
	number = {8},
	doi = {10.2196/36823},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136869391&doi=10.2196%2f36823&partnerID=40&md5=0559532fba6a5725ee914ca5da4d9f8d},
	affiliations = {Department of Biomedical Informatics, The Ohio State University, College of Medicine, Columbus, OH, United States; Division of General Internal Medicine, Department of Internal Medicine, The Ohio State University, College of Medicine, Columbus, OH, United States},
	abstract = {Background: Artificial intelligence (AI) is rapidly expanding in medicine despite a lack of consensus on its application and evaluation. Objective: We sought to identify current frameworks guiding the application and evaluation of AI for predictive analytics in medicine and to describe the content of these frameworks. We also assessed what stages along the AI translational spectrum (ie, AI development, reporting, evaluation, implementation, and surveillance) the content of each framework has been discussed. Methods: We performed a literature review of frameworks regarding the oversight of AI in medicine. The search included key topics such as "artificial intelligence," "machine learning," "guidance as topic," and "translational science," and spanned the time period 2014-2022. Documents were included if they provided generalizable guidance regarding the use or evaluation of AI in medicine. Included frameworks are summarized descriptively and were subjected to content analysis. A novel evaluation matrix was developed and applied to appraise the frameworks' coverage of content areas across translational stages. Results: Fourteen frameworks are featured in the review, including six frameworks that provide descriptive guidance and eight that provide reporting checklists for medical applications of AI. Content analysis revealed five considerations related to the oversight of AI in medicine across frameworks: transparency, reproducibility, ethics, effectiveness, and engagement. All frameworks include discussions regarding transparency, reproducibility, ethics, and effectiveness, while only half of the frameworks discuss engagement. The evaluation matrix revealed that frameworks were most likely to report AI considerations for the translational stage of development and were least likely to report considerations for the translational stage of surveillance. Conclusions: Existing frameworks for the application and evaluation of AI in medicine notably offer less input on the role of engagement in oversight and regarding the translational stage of surveillance. Identifying and optimizing strategies for engagement are essential to ensure that AI can meaningfully benefit patients and other end users. © 2022 Journal of Medical Internet Research. All rights reserved.},
	author_keywords = {AI; artificial intelligence; effectiveness; engagement; ethics; health care; medicine; reproducibility; translational research; translational science; transparency},
	keywords = {Artificial Intelligence; Checklist; Humans; Machine Learning; Medicine; Reproducibility of Results; adult; artificial intelligence; checklist; content analysis; ethics; human; machine learning; practice guideline; reproducibility; review; translational research; translational science; medicine; reproducibility},
	correspondence_address = {N.L. Crossnohere; Department of Biomedical Informatics, The Ohio State University, College of Medicine, Columbus, 1800 Cannon Drive, 43210, United States; email: norah.crossnohere@osumc.edu},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {36006692},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hunt2022132,
	author = {Hunt, Cassandra and Montgomery, Sandra and Berkenpas, Joshua William and Sigafoos, Noel and Oakley, John Chris-Tian and Espinosa, Jacob and Justice, Nicola and Kishaba, Kiyomi and Hippe, Kyle and Si, Dong and Hou, Jie and Ding, Hui and Cao, Renzhi},
	title = {Recent Progress of Machine Learning in Gene Therapy},
	year = {2022},
	journal = {Current Gene Therapy},
	volume = {22},
	number = {2},
	pages = {132 – 143},
	doi = {10.2174/1566523221666210622164133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126830890&doi=10.2174%2f1566523221666210622164133&partnerID=40&md5=8e5bfe187166d96002a864473cf17427},
	affiliations = {Department of Computer Science, Pacific Lutheran University, Tacoma, WA, United States; Department of Physics, Pacific Lutheran University, Tacoma, WA, United States; Department of Mathematics, Pacific Lutheran University, Tacoma, WA, United States; Department of Humanities, Pacific Lutheran University, Tacoma, WA, United States; Di-vision of Computing Software Systems, University of Washington-Bothell, Bothell, WA, United States; Department of Computer Science, Saint Louis University, St. Louis, MO, United States; School of Life Science and Technology and Center for Informational Biology, University of Electronic Science and Technology of China, Chengdu, China},
	abstract = {With new developments in biomedical technology, it is now a viable therapeutic treatment to alter genes with techniques like CRISPR. At the same time, it is increasingly cheaper to perform whole genome sequencing, resulting in rapid advancement in gene therapy and editing in precision medicine. Understanding the current industry and academic applications of gene therapy provides an important backdrop to future scientific developments. Additionally, machine learning and artificial intelligence techniques allow for the reduction of time and money spent in the development of new gene therapy products and techniques. In this paper, we survey the current progress of gene therapy treatments for several diseases and explore machine learning applications in gene therapy. We also discuss the ethical implications of gene therapy and the use of machine learning in precision medicine. Machine learning and gene therapy are both topics gaining popularity in various publications, and we conclude that there is still room for continued research and application of machine learning techniques in the gene therapy field. © 2022 Bentham Science Publishers.},
	author_keywords = {cancer; cardiovascular disease; CRISPR; ethics; gene therapy; hemophilia; Machine learning; neurodegenerative disease},
	keywords = {Artificial Intelligence; Genetic Therapy; Machine Learning; Precision Medicine; antineoplastic agent; axicabtagene ciloleucel; azficel T; brexucabtagene autoleucel; clevecord; cord blood hematopoietic stem cell extract; gintuit; hpc; lisocabtagene maraleucel; membrane protein; messenger RNA; microRNA; onasemnogene abeparvovec; sipuleucel T; talimogene laherparepvec; TALON protein; tisagenlecleucel T; unclassified drug; valoctocogene roxaparvovec; voretigene neparvovec; zinc finger protein; acute lymphoblastic leukemia; artificial intelligence; bacteriophage; Bayes theorem; bioinformatics; cancer therapy; cardiovascular disease; clustered regularly interspaced short palindromic repeat; cord blood stem cell transplantation; cost effectiveness analysis; decision tree; diffuse large B cell lymphoma; DNA methylation; Food and Drug Administration; gene expression; gene mutation; gene sequence; gene therapy; genotype; gingivitis; hematopoietic system malignancy; hemophilia; hemophilia A; hemophilia B; human; k means clustering; k nearest neighbor; linear regression analysis; logistic regression analysis; machine learning; mantle cell lymphoma; melanoma; nasolabial fold; neoplasm; nerve cell network; personalized medicine; phenotype; prostate cancer; protein targeting; random forest; retina dystrophy; Review; spinal muscular atrophy; support vector machine; systematic review; whole genome sequencing; artificial intelligence; gene therapy},
	correspondence_address = {R. Cao; Department of Computer Science, Pacific Lutheran University, Tacoma, United States; email: caora@plu.edu},
	publisher = {Bentham Science Publishers},
	issn = {15665232},
	coden = {CGTUA},
	pmid = {34161210},
	language = {English},
	abbrev_source_title = {Curr. Gene Ther.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Aydin2022,
	author = {Aydin, Ezra and Weiss, Staci M and Glasgow, Kevin A and Barlow, Jane and Austin, Topun and Johnson, Mark H and Lloyd-Fox, Sarah},
	title = {COVID-19 in the context of pregnancy, infancy and parenting (CoCoPIP) study: protocol for a longitudinal study of parental mental health, social interactions, physical growth and cognitive development of infants during the pandemic},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {6},
	doi = {10.1136/bmjopen-2021-053800},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131337934&doi=10.1136%2fbmjopen-2021-053800&partnerID=40&md5=d5fe3ad5f16a3cb1e0c0de9790af6167},
	affiliations = {Department of Psychology, University of Cambridge, Cambridge, United Kingdom; Department of Psychiatry, Columbia University, New York City, NY, United States; Department of Education, University of Cambridge, Cambridge, United Kingdom; Department of Social Policy, University of Oxford, Oxfordshire, Oxford, United Kingdom; Rosie Hospital, Cambridgeshire, Cambridge, United Kingdom; Nihr Cambridge Biomedical Research Centre, Cambridgeshire, Cambridge, United Kingdom},
	abstract = {Introduction While the secondary impact of the COVID-19 pandemic on the psychological well-being of pregnant women and parents has become apparent over the past year, the impact of these changes on early social interactions, physical growth and cognitive development of their infants is unknown, as is the way in which a range of COVID-19-related changes have mediated this impact. This study (CoCoPIP) will investigate: (1) how parent's experiences of the social, medical and financial changes during the pandemic have impacted prenatal and postnatal parental mental health and parent-infant social interaction; and (2) the extent to which these COVID-19-related changes in parental prenatal and postnatal mental health and social interaction are associated with fetal and infant development. Methods and analysis The CoCoPIP study is a national online survey initiated in July 2020. This ongoing study (n=1700 families currently enrolled as of 6 May 2021) involves both quantitative and qualitative data being collected across pregnancy and infancy. It is designed to identify the longitudinal impact of the pandemic from pregnancy to 2 years of age as assessed using a range of parent- and self-report measures, with the aim of identifying if stress-associated moderators (ie, loss of income, COVID-19 illness, access to ante/postnatal support) appear to impact parental mental health, and in turn, infant development. In addition, we aim to document individual differences in social and cognitive development in toddlers who were born during restrictions intended to mitigate COVID-19 spread (eg, social distancing, national lockdowns). Ethics and dissemination Ethical approval was given by the University of Cambridge, Psychology Research Ethics Committee (PRE.2020.077). Findings will be made available via community engagement, public forums (eg, social media,) and to national (eg, NHS England) and local (Cambridge Universities Hospitals NHS Foundation Trust) healthcare partners. Results will be submitted for publication in peer-reviews journals. © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY. Published by BMJ.},
	author_keywords = {COVID-19; Fetal medicine; QUALITATIVE RESEARCH},
	keywords = {Cognition; Communicable Disease Control; COVID-19; Female; Humans; Infant; Longitudinal Studies; Mental Health; Pandemics; Parenting; Parents; Parturition; Pregnancy; Social Interaction; abdominal circumference; anxiety; Article; child; child development; child health; child parent relation; cognitive development; cohort analysis; coronavirus disease 2019; daily life activity; data analysis; emotional attachment; ethnicity; family income; female; femur length; fetus; fetus development; fetus growth; fetus weight; financial management; follow up; growth rate; head circumference; health care access; health status; health survey; household income; human; infant; infant behavior questionnaire; information dissemination; longitudinal study; machine learning; male; mental health; national lockdown; pandemic; parental attitude; personal experience; physiological stress; postnatal care; pregnancy; prenatal care; protocol compliance; qualitative research; quality control; second trimester pregnancy; self report; social behavior; social distancing; social interaction; social support; sound detection; third trimester pregnancy; visual stimulation; birth; child parent relation; cognition; communicable disease control; epidemiology; mental health; pandemic; psychology},
	correspondence_address = {E. Aydin; Department of Psychology, University of Cambridge, Cambridge, United Kingdom; email: ea420@cam.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35667736},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Adikari2022e054881,
	author = {Adikari, Dona and Gharleghi, Ramtin and Zhang, Shisheng and Jorm, Louisa and Sowmya, Arcot and Moses, Daniel and Ooi, Sze-Yuan and Beier, Susann},
	title = {A new and automated risk prediction of coronary artery disease using clinical endpoints and medical imaging-derived patient-specific insights: protocol for the retrospective GeoCAD cohort study},
	year = {2022},
	journal = {BMJ open},
	volume = {12},
	number = {6},
	pages = {e054881},
	doi = {10.1136/bmjopen-2021-054881},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132308033&doi=10.1136%2fbmjopen-2021-054881&partnerID=40&md5=d5df93eecace3800288ec0adf111e867},
	affiliations = {Faculty of Medicine, University of New South Wales, Sydney, NSW, Australia; Cardiology Department, Prince of Wales Hospital, Sydney, NSW, Australia; School of Mechanical and Manufacturing Engineering, University of New South Wales, Sydney, NSW, Australia; Centre for Big Data Research in Health, University of New South Wales, Sydney, NSW, Australia; School of Computer Science and Engineering, University of New South Wales, Sydney, NSW, Australia; Department of Medical Imaging, Prince of Wales Hospital, Sydney, NSW, Australia},
	abstract = {INTRODUCTION: Coronary artery disease (CAD) is the leading cause of death worldwide. More than a quarter of cardiovascular events are unexplained by current absolute cardiovascular disease risk calculators, and individuals without clinical risk factors have been shown to have worse outcomes. The 'anatomy of risk' hypothesis recognises that adverse anatomical features of coronary arteries enhance atherogenic haemodynamics, which in turn mediate the localisation and progression of plaques. We propose a new risk prediction method predicated on CT coronary angiography (CTCA) data and state-of-the-art machine learning methods based on a better understanding of anatomical risk for CAD. This may open new pathways in the early implementation of personalised preventive therapies in susceptible individuals as a potential key in addressing the growing burden of CAD. METHODS AND ANALYSIS: GeoCAD is a retrospective cohort study in 1000 adult patients who have undergone CTCA for investigation of suspected CAD. It is a proof-of-concept study to test the hypothesis that advanced image-derived patient-specific data can accurately predict long-term cardiovascular events. The objectives are to (1) profile CTCA images with respect to variations in anatomical shape and associated haemodynamic risk expressing, at least in part, an individual's CAD risk, (2) develop a machine-learning algorithm for the rapid assessment of anatomical risk directly from unprocessed CTCA images and (3) to build a novel CAD risk model combining traditional risk factors with these novel anatomical biomarkers to provide a higher accuracy CAD risk prediction tool. ETHICS AND DISSEMINATION: The study protocol has been approved by the St Vincent's Hospital Human Research Ethics Committee, Sydney-2020/ETH02127 and the NSW Population and Health Service Research Ethics Committee-2021/ETH00990. The project outcomes will be published in peer-reviewed and biomedical journals, scientific conferences and as a higher degree research thesis. © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {computed tomography; coronary heart disease; risk management},
	keywords = {Adult; Cohort Studies; Computed Tomography Angiography; Coronary Angiography; Coronary Artery Disease; Humans; Predictive Value of Tests; Retrospective Studies; adult; cohort analysis; computed tomographic angiography; coronary angiography; coronary artery disease; diagnostic imaging; human; predictive value; procedures; retrospective study},
	publisher = {NLM (Medline)},
	issn = {20446055},
	pmid = {35725256},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Domingo-Ferrer2022111,
	author = {Domingo-Ferrer, Josep},
	title = {Ethics by Design in Decentralized Computing},
	year = {2022},
	journal = {ACM International Conference Proceeding Series},
	pages = {111 – 113},
	doi = {10.1145/3528580.3535331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135294736&doi=10.1145%2f3528580.3535331&partnerID=40&md5=905604aa6e4a5f21a7a0b89e2a2745ef},
	affiliations = {Universitat Rovira i Virgili, Dept. of Computer Engineering and Mathematics, UNESCO Chair in Data Privacy, CYBERCAT-Center for Cybersecurity Research of Catalonia Tarragona, Catalonia, Spain},
	abstract = {In our days, decentralized computing is a marked trend. Beyond its advantages in terms of scalability and fault tolerance, it is better adapted to ethical constraints than centralized computation (where a single party enjoys dictatorial power). I will sketch an approach based on coutility to make ethical behavior the rational choice of participants. Next, I will describe some applications of this approach to problems in decentralized computing and decentralized machine learning.  © 2022 Owner/Author.},
	author_keywords = {Co-utility; Decentralized computing; Ethics; privacy; Security},
	keywords = {Ethical technology; Centralized computation; Co-utility; Decentralised; Decentralized computing; Ethical behavior; Machine-learning; Power; Privacy; Security; Fault tolerance},
	correspondence_address = {J. Domingo-Ferrer; Universitat Rovira i Virgili, Dept. of Computer Engineering and Mathematics, UNESCO Chair in Data Privacy, CYBERCAT-Center for Cybersecurity Research of Catalonia Tarragona, Catalonia, Spain; email: josep.domingo@urv.cat},
	publisher = {Association for Computing Machinery},
	isbn = {978-145039603-5},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 European Interdisciplinary Cybersecurity Conference, EICC 2022; Conference date: 15 June 2022 through 16 June 2022; Conference code: 181186}
}

@ARTICLE{Schmitz-Luhn2022,
	author = {Schmitz-Luhn, Bjoern and Chandler, Jennifer},
	title = {Ethical and Legal Aspects of Technology-Assisted Care in Neurodegenerative Disease},
	year = {2022},
	journal = {Journal of Personalized Medicine},
	volume = {12},
	number = {6},
	doi = {10.3390/jpm12061011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134046329&doi=10.3390%2fjpm12061011&partnerID=40&md5=36755dafbd7f4da7633988549992a3b4},
	affiliations = {Center for Life Ethics, Bonn University, Bonn, 53113, Germany; Centre for Health Law, Policy and Ethics, University of Ottawa, Ottawa, K1N 6N5, ON, Canada},
	abstract = {Technological solutions are increasingly seen as a way to respond to the demands of managing complex chronic conditions, especially neurodegenerative diseases such as Parkinson’s Disease. All of these new possibilities provide a variety of chances to improve the lives of affected persons and their families, friends, and caregivers. However, there are also a number of challenges that should be considered in order to safeguard the interests of affected persons. In this article, we discuss the ethical and legal considerations associated with the use of technology-assisted care in the context of neurodegenerative conditions. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {ethics and law of medicine and technology; liability; medical education; neurodegenerative diseases; technologyassisted care},
	keywords = {Article; caregiver; decision making; degenerative disease; ethics; health care; health care personnel; health care policy; health care system; human; informed consent; legal aspect; machine learning; medical education; medical staff; medical technology; physician; quality of life; technology assisted care},
	correspondence_address = {B. Schmitz-Luhn; Center for Life Ethics, Bonn University, Bonn, 53113, Germany; email: schmitz-luhn@uni-bonn.de},
	publisher = {MDPI},
	issn = {20754426},
	language = {English},
	abbrev_source_title = {J. Pers. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Chaffey20221,
	author = {Chaffey, Dave and Smith, P.R.},
	title = {Digital marketing excellence: Planning, optimizing and integrating online marketing},
	year = {2022},
	journal = {Digital Marketing Excellence: Planning, Optimizing and Integrating Online Marketing},
	pages = {1 – 638},
	doi = {10.4324/9781003009498},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151363687&doi=10.4324%2f9781003009498&partnerID=40&md5=6e2f5c3e1f7142c5bfce7da3504708cf},
	abstract = {Now in its sixth edition, the hugely popular Digital Marketing Excellence is a practical guide to creating and executing integrated digital marketing plans, combining established approaches to marketing planning with the creative use of new digital models and digital tools. Written by two highly experienced digital marketing consultants, the book shows you how to: Draw up an outline integrated digital marketing plan Evaluate and apply digital marketing principles and models Integrate online and offline communications Implement customer-driven digital marketing as part of digital transformation Reduce costly trial and error Measure and enhance your digital marketing Learn best practices for reaching and engaging your audiences using the key digital marketing platforms. This new edition has been streamlined to seamlessly integrate the latest developments in digital analytics, ethics and privacy, Predictive Analytics, Machine Learning and Artificial Intelligence. Including new international case studies and up-to-date examples throughout, this book cuts through the jargon to show marketers how to leverage data and digital technologies to their advantage. Offering a highly structured and accessible guide to a critical and far-reaching subject, Digital Marketing Excellence, 6th edition, provides a vital reference point for all digital marketing students, and managers involved in digital marketing strategy and implementation. Online resources have been fully updated for the new edition and include a new set of PowerPoint slides and a full test bank of questions and exercises. © 2023 Dave Chaffey and PR Smith. All rights reserved.},
	publisher = {Taylor and Francis},
	isbn = {978-100300949-8; 978-036744401-3},
	language = {English},
	abbrev_source_title = {Digit. Mark. Excell.: Plan., Optim. and Integrating Online Mark.},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Wang2022e047343,
	author = {Wang, Fang and Wen, Fang and Liu, Jingran and Yan, Junjuan and Yu, Liping and Li, Ying and Cui, Yonghua},
	title = {Classification of tic disorders based on functional MRI by machine learning: a study protocol},
	year = {2022},
	journal = {BMJ open},
	volume = {12},
	number = {5},
	pages = {e047343},
	doi = {10.1136/bmjopen-2020-047343},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130117015&doi=10.1136%2fbmjopen-2020-047343&partnerID=40&md5=f63c7e9131b2843979e5bead0b3fa87d},
	affiliations = {Department of Psychiatry, Beijing Children's Hospital, Beijing, China},
	abstract = {INTRODUCTION: Tic disorder (TD) is a common neurodevelopmental disorder in children, and it can be categorised into three subtypes: provisional tic disorder (PTD), chronic motor or vocal TD (CMT or CVT), and Tourette syndrome (TS). An early diagnostic classification among these subtypes is not possible based on a new-onset tic symptom. Machine learning tools have been widely used for early diagnostic classification based on functional MRI (fMRI). However, few machine learning models have been built for the diagnostic classification of patients with TD. Therefore, in the present study, we will provide a study protocol that uses the machine learning model to make early classifications of the three different types of TD. METHODS AND ANALYSIS: We planned to recruit 200 children aged 6-9 years with new-onset tic symptoms and 100 age-matched and sex-matched healthy controls under resting-state MRI scanning. Based on the neuroimaging data of resting-state fMRI, the support vector machine (SVM) model will be built. We planned to construct an SVM model based on functional connectivity for the early diagnosis classification of TD subtypes (including PTD, CMT/CVT, TS). ETHICS AND DISSEMINATION: This study was approved by the ethics committee of Beijing Children's Hospital. The trial results will be submitted to peer-reviewed journals for publication. TRIAL REGISTRATION NUMBER: ChiCTR2000033257. © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {Child & adolescent psychiatry; Protocols & guidelines; PSYCHIATRY},
	keywords = {Child; Humans; Machine Learning; Magnetic Resonance Imaging; Tic Disorders; Tics; Tourette Syndrome; child; diagnostic imaging; Gilles de la Tourette syndrome; human; machine learning; nuclear magnetic resonance imaging; tic},
	publisher = {NLM (Medline)},
	issn = {20446055},
	pmid = {35577466},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Guerra2022,
	author = {Guerra, Adalgisa and Negrão, Eduardo and Papanikolaou, Nickolas and Donato, Helena},
	title = {Machine learning in predicting extracapsular extension (ECE) of prostate cancer with MRI: a protocol for a systematic literature review},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {5},
	doi = {10.1136/bmjopen-2021-052342},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130005465&doi=10.1136%2fbmjopen-2021-052342&partnerID=40&md5=b97e068d1021b5d661f93911ba52f2a9},
	affiliations = {Radiology, Hospital Da Luz, Lisboa, Portugal; Radiology, Centro Hospitalar Universitário De São João, Porto, Portugal; Radiology, Royal Marsden Hospital Nhs Trust, London, United Kingdom; Documentation And Information Service, Centro Hospitalar E Universitario De Coimbra Epe, Coimbra, Portugal},
	abstract = {Introduction In patients with prostate cancer (PCa), the detection of extracapsular extension (ECE) and seminal vesicle invasion is not only important for selecting the appropriate therapy but also for preoperative planning and patient prognosis. It is of paramount importance to stage PCa correctly before surgery, in order to achieve better surgical and outcome results. Over the last years, MRI has been incorporated in the classical prostate staging nomograms with clinical improvement accuracy in detecting ECE, but with variability between studies and radiologist's experience. Methods and analysis The research question, based on patient, index test, comparator, outcome and study design criteria, was the following: what is the diagnostic performance of artificial intelligence algorithms for predicting ECE in PCa patients, when compared with that of histopathological results after radical prostatectomy. To answer this question, we will use databases (EMBASE, PUBMED, Web of Science and CENTRAL) to search for the different studies published in the literature and we use the QUADA tool to evaluate the quality of the research selection. Ethics and dissemination This systematic review does not require ethical approval. The results will be disseminated through publication in a peer-review journal, as a chapter of a doctoral thesis and through presentations at national and international conferences.  © 2022 Author(s) (or their employer(s)). Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {Genitourinary imaging; Genitourinary medicine; Health informatics; Information technology; Magnetic Resonance Imaging; Urological tumours},
	keywords = {Artificial Intelligence; Extranodal Extension; Humans; Machine Learning; Magnetic Resonance Imaging; Male; Neoplasm Invasiveness; Neoplasm Staging; Prostatectomy; Prostatic Neoplasms; Retrospective Studies; Systematic Reviews as Topic; algorithm; artificial intelligence; cancer patient; cancer surgery; diagnostic value; histopathology; human; information technology; machine learning; medical informatics; nuclear magnetic resonance imaging; outcome assessment; prostate cancer; prostatectomy; Review; cancer staging; diagnostic imaging; machine learning; male; nuclear magnetic resonance imaging; pathology; procedures; prostate tumor; retrospective study; tumor invasion},
	correspondence_address = {A. Guerra; Radiology, Hospital Da Luz, Lisboa, Portugal; email: gisaguerra@gmail.com},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35523484},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Bucea-Manea-țoniş2022,
	author = {Bucea-Manea-țoniş, Rocsana and Kuleto, Valentin and Gudei, Simona Corina Dobre and Lianu, Costin and Lianu, Cosmin and Ilić, Milena P. and Păun, Dan},
	title = {Artificial Intelligence Potential in Higher Education Institutions Enhanced Learning Environment in Romania and Serbia},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {10},
	doi = {10.3390/su14105842},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130542761&doi=10.3390%2fsu14105842&partnerID=40&md5=7b6dfab5016808d954e3ff0c31baf857},
	affiliations = {Doctoral School, National University of Physical Education and Sport, Bucharest, 060057, Romania; LINK Group Belgrade, Information Technology School ITS-Belgrade, Faculty of Contemporary Arts Belgrade, University Business Academy in Novi Sad, Belgrade, 11000, Serbia; Faculty of Economy and International Affairs, Academy of Economic Studies, Bucharest, 010374, Romania; USH Pro Business, Spiru Haret University, Bucharest, 004021, Romania; Faculty of Physical Education, Spiru Haret University, Bucharest, 004021, Romania},
	abstract = {In their struggle to offer a sustainable educational system and transversal competencies for market requests, significant transformations characterise the higher education system in Serbia and Romania. According to EU policy, these transformations are related to educational reforms and the introduction of new technology and methodologies in teaching and learning. They are expected to answer to the PISA requirements and to increase the DESI (Digital Economy and Society Index). They are also likely to mitigate the inequity of HEIs (higher education institutions), empowered by a structured, goal-oriented strategy towards agile management in HEIs that is also appropriate for new market demands. Our study is based on an exploratory survey applied to 139 Romanian and Serbian teachers from the Information Technology School—ITS, Belgrade, and Spiru Haret University, Romania. The survey let them provide their knowledge of AI or their perceptions of the difficulties and opportunities of these technologies in HEIs. Our study discovered how difficulties and opportunities associated with AI impact HEIs. This study aims to see how AI might assist higher education in Romania and Serbia. We also considered how they might be integrated with the educational system, and if instructors would utilise them. Developing creative and transversal skills is required to anticipate future breakthroughs and technological possibilitiesThe new methods of education focuses on ethics, values, problem-solving, and daily activities. Students’ learning material, how they might achieve critical abilities, and their educational changes must be addressed in the future. In this environment, colleges must create new digital skills in IA, machine learning, IoT, 5G, the cloud, big data, blockchain, data analysis, using MS Office and other applications, MOOCs, simulation applications, VR/AR, and gamification. They must also develop cross-disciplinary skills and a long-term mindset. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {artificial intelligence (AI); higher education institutions (HEI); transversal skills},
	keywords = {Belgrade; Romania; Serbia; Serbia; artificial intelligence; higher education; knowledge; learning; perception; student; teaching},
	correspondence_address = {R. Bucea-Manea-țoniş; Doctoral School, National University of Physical Education and Sport, Bucharest, 060057, Romania; email: rocsense39@yahoo.com; D. Păun; Faculty of Physical Education, Spiru Haret University, Bucharest, 004021, Romania; email: ushefs_paun.dan@spiruharet.ro},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@ARTICLE{Golder2022251,
	author = {Golder, Su and O'Connor, Karen and Wang, Yunwen and Stevens, Robin and Gonzalez-Hernandez, Graciela},
	title = {Best Practices on Big Data Analytics to Address Sex-Specific Biases in Our Understanding of the Etiology, Diagnosis, and Prognosis of Diseases},
	year = {2022},
	journal = {Annual Review of Biomedical Data Science},
	volume = {5},
	pages = {251 – 267},
	doi = {10.1146/annurev-biodatasci-122120-025806},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149155288&doi=10.1146%2fannurev-biodatasci-122120-025806&partnerID=40&md5=f8fabe9e0efb32b93d6d9091937e6aba},
	affiliations = {Department of Health Sciences, University of York, York, United Kingdom; Department of Biostatistics, Epidemiology and Informatics (DBEI), Perelman School of Medicine, The University of Pennsylvania, Philadelphia, PA, United States; Annenberg School for Communication and Journalism, University of Southern California, Los Angeles, CA, United States},
	abstract = {A bias in health research to favor understanding diseases as they present in men can have a grave impact on the health of women. This paper reports on a conceptual review of the literature on machine learning or natural language processing (NLP) techniques to interrogate big data for identifying sex-specific health disparities. We searched Ovid MEDLINE, Embase, and PsycINFO in October 2021 using synonyms and indexing terms for (a) "women," "men," or "sex" (b) "big data," "artificial intelligence," or "NLP" and (c) "disparities" or "differences." From 902 records, 22 studies met the inclusion criteria and were analyzed. Results demonstrate that the inclusion by sex is inconsistent and often unreported, although the inclusion of men in these studies is disproportionately less than women. Even though artificial intelligence and NLP techniques are widely applied in healthresearch, few studies use them to take advantage of unstructured text to investigate sex-related differences or disparities. Researchers are increasingly aware of sex-based data bias, but the process toward correction is slow. We reflect on best practices on using big data analytics to address sex-specific biases in understanding the etiology, diagnosis, and prognosis of diseases. © 2022 by Annual Reviews. All rights reserved.},
	author_keywords = {bias; ethics; gender disparities; health disparities; machine learning; natural language processing},
	keywords = {Artificial Intelligence; Big Data; Data Science; Female; Humans; Machine Learning; Male; Natural Language Processing; artificial intelligence; female; human; machine learning; male; natural language processing},
	publisher = {Annual Reviews Inc.},
	issn = {25743414},
	pmid = {35562851},
	language = {English},
	abbrev_source_title = {Annu. Rev. Biomed. Data Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}@ARTICLE{Kan2022,
	author = {Kan, Rebecca L.D. and Mak, Arthur D.P. and Chan, Sherry K.W. and Zhang, Bella B.B. and Fong, Kenneth N.K. and Kranz, Georg S.},
	title = {Protocol for a prospective open-label clinical trial to investigate the utility of concurrent TBS/fNIRS for antidepressant treatment optimisation},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {2},
	doi = {10.1136/bmjopen-2021-053896},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124447911&doi=10.1136%2fbmjopen-2021-053896&partnerID=40&md5=137918a10510924327d6a6fa2cdcd4a2},
	affiliations = {Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; Department of Psychiatry, The Chinese University of Hong Kong, Hong Kong, Hong Kong; Department of Psychiatry, Queen Mary Hospital, The University of Hong Kong, Hong Kong, Hong Kong; Department of Psychiatry and Psychotherapy, Medical University of Vienna, Wien, Austria; The State Key Laboratory of Brain and Cognitive Sciences, The University of Hong Kong, Hong Kong, Hong Kong},
	abstract = {Introduction Repetitive transcranial magnetic stimulation (rTMS) with theta burst stimulation (i.e. TBS) of the dorsolateral prefrontal cortex (DLPFC) is an innovative treatment for major depressive disorder (MDD). However, fewer than 50% of patients show sufficient response to this treatment; markers for response prediction are urgently needed. Research shows considerable individual variability in the brain responses to rTMS. However, whether differences in individual DLPFC modulation by rTMS can be used as a predictive marker for treatment response remains to be investigated. Here, we present a research programme that will exploit the combination of functional near-infrared spectroscopy (fNIRS) with brain stimulation. Concurrent TBS/fNIRS will allow us to systematically investigate TBS-induced modulation of blood oxygenation as a proxy for induced brain activity changes. The findings from this study will (1) elucidate the immediate effects of excitatory and inhibitory TBS on prefrontal activity in TBS treatment-naïve patients with MDD and (2) validate the potential utility of TBS-induced brain modulation at baseline for the prediction of antidepressant response to 4 weeks of daily TBS treatment. Methods and analysis Open-label, parallel-group experiment consisting of two parts. In part 1, 70 patients and 37 healthy controls will be subjected to concurrent TBS/fNIRS. Intermittent TBS (iTBS) and continuous TBS (cTBS) will be applied on the left and right DLPFC, respectively. fNIRS data will be acquired before, during and several minutes after stimulation. In part 2, patients who participated in part 1 will receive a 4 week iTBS treatment of the left DLPFC, performed daily for 5 days per week. Psychometric evaluation will be performed periodically and at 1 month treatment follow-up. Statistical analysis will include a conventional, as well as a machine learning approach. Ethics and dissemination Ethics approval was obtained from the Institutional Review Board. Findings will be disseminated through scientific journals, conferences and university courses. Trial registration number NCT04526002.  © },
	author_keywords = {clinical trials; depression & mood disorders; neurology},
	keywords = {Antidepressive Agents; Brain; Depressive Disorder, Major; Humans; Prospective Studies; Transcranial Magnetic Stimulation; antidepressant agent; lorazepam; antidepressant agent; adult; Article; blood oxygenation; BOLD signal; brain depth stimulation; clinical outcome; clinical protocol; controlled study; cortical excitability; electroencephalography; follow up; functional near-infrared spectroscopy; Hamilton Depression Rating Scale; health care utilization; human; image artifact; machine learning; major clinical study; major depression; Montgomery Asberg Depression Rating Scale; motor cortex; neuromodulation; open study; Patient Health Questionnaire 9; prediction; prefrontal cortex; prospective study; psychometry; quick inventory of depressive symptomatology; right handedness; seizure; self report; sensitivity and specificity; stimulation; theta burst stimulation; brain; diagnostic imaging; major depression; procedures; transcranial magnetic stimulation},
	correspondence_address = {G.S. Kranz; Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hong Kong, Hong Kong; email: georg.kranz@polyu.edu.hk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35144953},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ahmad2022,
	author = {Ahmad, Kashif and Maabreh, Majdi and Ghaly, Mohamed and Khan, Khalil and Qadir, Junaid and Al-Fuqaha, Ala},
	title = {Developing future human-centered smart cities: Critical analysis of smart city security, Data management, and Ethical challenges},
	year = {2022},
	journal = {Computer Science Review},
	volume = {43},
	doi = {10.1016/j.cosrev.2021.100452},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121968014&doi=10.1016%2fj.cosrev.2021.100452&partnerID=40&md5=203c708b33d037b72921c18a669803cd},
	affiliations = {Information and Computing Technology (ICT) Division, College of Science and Engineering (CSE), Hamad Bin Khalifa University, Doha, Qatar; Department of Information Technology, Faculty of Prince Al-Hussein Bin Abdallah II For Information Technology, The Hashemite University, P.O. Box 330127, Zarqa, 13133, Jordan; Research Center for Islamic Legislation & Ethics, College of Islamic Studies, Hamad Bin Khalifa University, Doha, Qatar; Department of Information Technology and Computer Science, Pak-Austria Fachhochschule: Institute of Applied Sciences and Technology, Haripur-KPK, Pakistan; Department of Computer Science and Engineering, Faculty of Engineering, Qatar University, Doha, Qatar; Department of Electrical Engineering, Information Technology University, Lahore, Pakistan},
	abstract = {As the globally increasing population drives rapid urbanization in various parts of the world, there is a great need to deliberate on the future of the cities worth living. In particular, as modern smart cities embrace more and more data-driven artificial intelligence services, it is worth remembering that (1) technology can facilitate prosperity, wellbeing, urban livability, or social justice, but only when it has the right analog complements (such as well-thought out policies, mature institutions, responsible governance); and (2) the ultimate objective of these smart cities is to facilitate and enhance human welfare and social flourishing. Researchers have shown that various technological business models and features can in fact contribute to social problems such as extremism, polarization, misinformation, and Internet addiction. In the light of these observations, addressing the philosophical and ethical questions involved in ensuring the security, safety, and interpretability of such AI algorithms that will form the technological bedrock of future cities assumes paramount importance. Globally there are calls for technology to be made more humane and human-centered. In this paper, we analyze and explore key challenges including security, robustness, interpretability, and ethical (data and algorithmic) challenges to a successful deployment of AI in human-centric applications, with a particular emphasis on the convergence of these concepts/challenges. We provide a detailed review of existing literature on these key challenges and analyze how one of these challenges may lead to others or help in solving other challenges. The paper also advises on the current limitations, pitfalls, and future directions of research in these domains, and how it can fill the current gaps and lead to better solutions. We believe such rigorous analysis will provide a baseline for future research in the domain. © 2021 Elsevier Inc.},
	author_keywords = {Adversarial attacks; AI ethics; Data auditing; Data bias; Data management; Data ownership; Evasion attacks; Explainability; Interpretability; Machine learning; Privacy; Security; Smart cities; Trojan attacks},
	keywords = {Digital storage; Ethical technology; Machine learning; Malware; Population statistics; Smart city; Adversarial attack; AI ethic; Data auditing; Data bias; Data ownership; Evasion attack; Explainability; Interpretability; Privacy; Security; Trojan attack; Trojans; Information management},
	correspondence_address = {K. Ahmad; Information and Computing Technology (ICT) Division, College of Science and Engineering (CSE), Hamad Bin Khalifa University, Doha, Qatar; email: kahmad@hbku.edu.qa},
	publisher = {Elsevier Ireland Ltd},
	issn = {15740137},
	language = {English},
	abbrev_source_title = {Comput. Sci. Rev.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@ARTICLE{Iqbal2022583,
	author = {Iqbal, Jeffrey David and Krauthammer, Michael and Biller-Andorno, Nikola},
	title = {The Use and Ethics of Digital Twins in Medicine},
	year = {2022},
	journal = {The Journal of law, medicine & ethics : a journal of the American Society of Law, Medicine & Ethics},
	volume = {50},
	number = {3},
	pages = {583 – 596},
	doi = {10.1017/jme.2022.97},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142132856&doi=10.1017%2fjme.2022.97&partnerID=40&md5=4add18e63555c7e447ea0edb35ee59a5},
	affiliations = {UNIVERSITY OF ZURICH, ZURICH, Switzerland},
	abstract = {Digital Health Technologies (DHTs) are currently the subject of much debate both in terms of their technological frontiers as well as their ethical, legal and societal implications (ELSI). Regulation of such technologies as medical devices currently lacks behind their level of adoption. Digital Twins are the next evolution step of such DHTs and provide an opportunity to anticipate and act on ELSI before adoption again leaps before the necessary review. This paper introduces the concept and use cases of digital twins in medicine, then frames the debate through the lens of related technologies, machine learning and personalized medicine, and maps ethical challenges stemming from those. Finally, we lay out how digital twins may change and challenge the future practice of medicine.},
	author_keywords = {Bioethics; Digital Avatar; Digital Health; Digital Twin; Metaverse; Virtual Twin},
	keywords = {Humans; Precision Medicine; human; personalized medicine},
	publisher = {NLM (Medline)},
	issn = {1748720X},
	pmid = {36398633},
	language = {English},
	abbrev_source_title = {J Law Med Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Bishara202215,
	author = {Bishara, Andrew and Maze, Elijah H. and Maze, Mervyn},
	title = {Considerations for the implementation of machine learning into acute care settings},
	year = {2022},
	journal = {British Medical Bulletin},
	volume = {141},
	number = {1},
	pages = {15 – 32},
	doi = {10.1093/bmb/ldac001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127729661&doi=10.1093%2fbmb%2fldac001&partnerID=40&md5=acdc004551d0566d5dce51fc95033202},
	affiliations = {Department of Anesthesia and Perioperative Care, University of California San Francisco, 1001 Potrero Avenue, San Francisco, 94110, CA, United States; Bakar Computational Health Sciences Institute, University of California San Francisco, 490 Illinois Street, San Francisco, 94143, CA, United States; Departments of Computer Science and Mathematics, University of Michigan, Bob and Betty Beyster Building, 2260 Hayward Street, Ann Arbor, 48109, MI, United States},
	abstract = {Introduction: Management of patients in the acute care setting requires accurate diagnosis and rapid initiation of validated treatments; therefore, this setting is likely to be an environment in which cognitive augmentation of the clinician's provision of care with technology rooted in artificial intelligence, such as machine learning (ML), is likely to eventuate. Sources of data: PubMed and Google Scholar with search terms that included ML, intensive/critical care unit, electronic health records (EHR), anesthesia information management systems and clinical decision support were the primary sources for this report. Areas of agreement: Different categories of learning of large clinical datasets, often contained in EHRs, are used for training in ML. Supervised learning uses algorithm-based models, including support vector machines, to pair patients' attributes with an expected outcome. Unsupervised learning uses clustering algorithms to define to which disease grouping a patient's attributes most closely approximates. Reinforcement learning algorithms use ongoing environmental feedback to deterministically pursue likely patient outcome. Areas of controversy: Application of ML can result in undesirable outcomes over concerns related to fairness, transparency, privacy and accountability. Whether these ML technologies irrevocably change the healthcare workforce remains unresolved. Growing points: Well-resourced Learning Health Systems are likely to exploit ML technology to gain the fullest benefits for their patients. How these clinical advantages can be extended to patients in health systems that are neither well-endowed, nor have the necessary data gathering technologies, needs to be urgently addressed to avoid further disparities in healthcare. © 2022 The Author(s) 2022. Published by Oxford University Press. All rights reserved. For Permissions, please email: journals.permissions@oup.com.},
	author_keywords = {acute care; algorithms; machine learning},
	keywords = {Algorithms; Artificial Intelligence; Critical Care; Electronic Health Records; Humans; Machine Learning; access to information; acute kidney failure; anesthesia induction; binary classification; cardiac anesthesia; causality; clinical assessment; clinical decision support system; clustering algorithm; decision support system; deep learning; electronic health record; emergency care; expert system; feedback system; health care; health equity; health workforce; human; image processing; information processing; information system; intensive care unit; k means clustering; learning algorithm; learning health system; logistic regression analysis; machine learning; medical care; medical decision making; medical decision support system; medical error; medical ethics; medical liability; nerve cell network; nonmaleficence; outcome assessment; patient autonomy; personalized medicine; privacy; reinforcement learning (machine learning); Review; safety procedure; social responsibility; supervised machine learning; support vector machine; treatment outcome; unsupervised machine learning; workforce; workplace; algorithm; artificial intelligence; intensive care},
	correspondence_address = {M. Maze; Department of Anesthesia and Perioperative Care, University of California, San Francisco and Zuckerberg San Francisco General, San Francisco, 1001 Potrero Avenue, 94110-3519, United States; email: mervyn.maze@UCSF.edu},
	publisher = {Oxford University Press},
	issn = {00071420},
	coden = {BMBUA},
	pmid = {35107127},
	language = {English},
	abbrev_source_title = {Br. Med. Bull.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Evans2022,
	author = {Evans, Jill and Hamilton, Rebecca I. and Biggs, Paul and Holt, Cathy and Elliott, Mark T.},
	title = {Data sharing across osteoarthritis research groups and disciplines: Opportunities and challenges},
	year = {2022},
	journal = {Osteoarthritis and Cartilage Open},
	volume = {4},
	number = {1},
	doi = {10.1016/j.ocarto.2022.100236},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162317919&doi=10.1016%2fj.ocarto.2022.100236&partnerID=40&md5=335bc6e785c16495a3eebe04dd30ce40},
	affiliations = {Institute of Digital Healthcare, WMG, University of Warwick, Coventry, CV4 7AL, UK, United Kingdom; Arthritis Research UK Biomechanics and Bioengineering Centre, Cardiff University, Cardiff, CF10 3AT, UK, United Kingdom},
	abstract = {Background: Osteoarthritis is a heterogeneous condition characterised by a wide variety of factors and represents a worldwide healthcare challenge. There are multiple clinical and research specialisms involved in the diagnosis, prognosis and treatment of osteoarthritis, and there may be opportunities to share or pool data which are currently not being utilised. However, there are challenges to doing so which require carefully structured solutions and partnership working. Methods: Interviews were conducted with nine experts from various fields within osteoarthritis research. A semi-structured approach was used, and thematic analysis applied to the results. Results: Generally, osteoarthritis researchers were supportive of data sharing, provided it is done responsibly and without impacting data integrity. Benefits identified included increasing typically low-powered data, the potential for machine learning opportunities, and the potential for improved patient outcomes. However, a number of challenges were identified, relating to: data security, data harmonisation, storage costs, ethical considerations and governance. Conclusions: There is clear support for increased data sharing and partnership working in osteoarthritis research. Further investigation will be required to navigate the complex issues identified; however, it is clear that collaborative opportunities should be better facilitated and there may be innovative ways to do this. It is also clear that nomenclature within different disciplines could be better streamlined, to improve existing opportunities to harmonise data. © 2022},
	author_keywords = {Data harmonisation; Data sharing; Osteoarthritis},
	keywords = {Article; consensus; data integrity; data processing; ethics; human; information security; information storage; interview; machine learning; medical expert; osteoarthritis; qualitative analysis; thematic analysis; treatment outcome},
	correspondence_address = {M.T. Elliott; Institute of Digital Healthcare, WMG, University of Warwick, Coventry, CV4 7AL, United Kingdom; email: m.t.elliott@warwick.ac.uk},
	publisher = {Elsevier Ltd},
	issn = {26659131},
	language = {English},
	abbrev_source_title = {Osteoarthritis Cartil. Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Vetter20221,
	author = {Vetter, Norman},
	title = {Ethics and antibiotic resistance and considerations for the implementation of machine learning into acute care settings},
	year = {2022},
	journal = {British Medical Bulletin},
	volume = {141},
	number = {1},
	pages = {1 – 2},
	doi = {10.1093/bmb/ldac006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127884209&doi=10.1093%2fbmb%2fldac006&partnerID=40&md5=77a5e6ed4fc9a9833fe681a0565ada7e},
	keywords = {antibiotic resistance; antimicrobial stewardship; artificial intelligence; autologous matrix induced chondrogenesis; brain injury; cartilage injury; chondrocyte implantation; combat sport; Editorial; emergency care; ethics; health care organization; health care personnel; health workforce; human; knee meniscus; knee surgery; machine learning; patient compliance; professional well-being; rotational acceleration; tragedy of the commons; traumatic brain injury},
	publisher = {Oxford University Press},
	issn = {00071420},
	coden = {BMBUA},
	language = {English},
	abbrev_source_title = {Br. Med. Bull.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Wang20221519,
	author = {Wang, Zhaoran and Keane, Pearse A. and Chiang, Michael and Cheung, Carol Y. and Wong, Tien Yin and Ting, Daniel Shu Wei},
	title = {Artificial Intelligence and Deep Learning in Ophthalmology},
	year = {2022},
	journal = {Artificial Intelligence in Medicine},
	pages = {1519 – 1552},
	doi = {10.1007/978-3-030-64573-1_200},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158977294&doi=10.1007%2f978-3-030-64573-1_200&partnerID=40&md5=28805af496132c74a7c578c4fa3cf0bb},
	affiliations = {Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; NIHR Biomedical Research Centre for Ophthalmology, Moorfields EyeHospitalNHSFoundation Trust, London, United Kingdom; Departments of Ophthalmology and Medical Informatics and Clinical Epidemiology, Casey Eye Institute, Oregon Health and Science University, Portland, OR, United States; Department of Ophthalmology and Visual Sciences, The Chinese University of Hong Kong, Hong Kong; Singapore Eye Research Institute, Singapore National Eye Center, Singapore, Singapore; Moorfields Eye Hospital, London, United Kingdom},
	abstract = {Artificial intelligence (AI), in particular deep learning (DL), has gained significant interest recently from healthcare systems. DL has been widely applied to detect and classify major diseases in ophthalmology, including diabetic retinopathy (DR), age-related macular degeneration (AMD), glaucoma, and retinopathy of prematurity based on fundus photographs; cataract and anterior segment diseases, glaucoma, and retinal diseases based on optical coherence tomography (OCT) scans; and glaucoma progression based on visual fields. The substantial progress of AI in ophthalmology has involved the identification of clear public health (e.g., DR screening) and clinical (e.g., prediction of the need to treat AMD) unmet needs, the targeted development of the AI algorithms using both retrospective and prospective clinical and imaging data, and designing the application interface for clinical deployment. In ophthalmology, there has also been significant experience of applying AI algorithms in “realworld” clinical situations, as well as the submission and approval by governmental regulatory agencies (e.g., Food and Drug Administration). Future research is warranted to address not only technical issues (e.g., explainability of the “black box”) but also a range of nontechnical challenges, such as increasing the awareness and acceptance of physician and patient, issues relating to global collaboration and data sharing, medical ethics, financial and reimbursement systems, and integration of AI algorithms in clinical settings with diverse electronic health records. © Springer Nature Switzerland AG 2022.},
	author_keywords = {Agerelated macular degeneration; Artificial intelligence; Deep learning; Diabetic retinopathy; Electronic health records; Fundus imaging; Glaucoma; Machine learning; Optical coherence tomography; Retinopathy of prematurity},
	correspondence_address = {D.S.W. Ting; Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; email: daniel.ting.s.w@singhealth.com.sg},
	publisher = {Springer International Publishing},
	isbn = {978-303064573-1; 978-303064572-4},
	language = {English},
	abbrev_source_title = {Artificial Intelligence in Medicine},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@BOOK{Geetha20221,
	author = {Geetha, T.V. and Sendhilkumar, S.},
	title = {Machine Learning: Concepts, Techniques and Applications},
	year = {2022},
	journal = {Machine Learning: Concepts, Techniques and Applications},
	pages = {1 – 455},
	doi = {10.1201/9781003290100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163419351&doi=10.1201%2f9781003290100&partnerID=40&md5=18964015bdc97bc61253ce36e20ed585},
	affiliations = {Department of Information Science and Technology, CEG, Anna University, India},
	abstract = {Machine Learning: Concepts, Techniques and Applications starts at the basic conceptual level of explaining machine learning and goes on to explain the basis of machine learning algorithms. The mathematical foundations required are outlined along with their associations to machine learning. The book then goes on to describe important machine learning algorithms along with appropriate use cases. This approach enables the readers to explore the applicability of each algorithm by understanding the differences between them. A comprehensive account of various aspects of ethical machine learning has been discussed. An outline of deep learning models is also included. The use cases, self-assessments, exercises, activities, numerical problems, and projects associated with each chapter aims to concretize the understanding. Features • Concepts of machine learning from basics to algorithms to implementation • Comparison of different machine learning algorithms—when to use them and why—for Application Developers and Researchers • Machine learning from an application perspective—general and machine learning for healthcare, education, business, and engineering applications • Ethics of machine learning including bias, fairness, trust, and responsibility • Basics of deep learning, important deep learning models, and applications • Plenty of objective questions, use cases, and activity and project based learning exercises The book aims to make the thinking of applications and problems in terms of machine learning possible for graduate students, researchers, and professionals so that they can formulate the problems, prepare data, decide features, select appropriate machine learning algorithms, and do appropriate performance evaluation. © 2023 T V Geetha and S Sendhilkumar.},
	publisher = {CRC Press},
	isbn = {978-100086716-9; 978-103226828-6},
	language = {English},
	abbrev_source_title = {Machine Learning: Concepts, Techniques and Applications},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Romero202275,
	author = {Romero, Romina A. and Young, Sean D.},
	title = {Public perceptions and implementation considerations on the use of artificial intelligence in health},
	year = {2022},
	journal = {Journal of Evaluation in Clinical Practice},
	volume = {28},
	number = {1},
	pages = {75 – 78},
	doi = {10.1111/jep.13580},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105453682&doi=10.1111%2fjep.13580&partnerID=40&md5=0661bb78d2aad93d0e9d01064e40bc6e},
	affiliations = {Department of Emergency Medicine, University of California, Irvine, Irvine, CA, United States; University of California Institute for Prediction Technology, Department of Informatics, University of California, Irvine, Irvine, CA, United States},
	keywords = {Artificial Intelligence; Humans; Public Opinion; artificial intelligence; disinformation; ethics; health care industry; human; implementation science; machine learning; misinformation; Note; perception; public health; public perception; public policy; regulatory mechanism; statistical bias; technology; public opinion},
	correspondence_address = {S.D. Young; Department of Emergency Medicine, University of California, Irvine, Irvine, United States; email: syoung5@hs.uci.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {13561294},
	coden = {JECPF},
	pmid = {33977613},
	language = {English},
	abbrev_source_title = {J. Eval. Clin. Pract.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Hu20222085,
	author = {Hu, Hao and Xiao, Dongsheng and Rhodin, Helge and Murphy, Timothy H.},
	title = {Towards a Visualizable, De-identified Synthetic Biomarker of Human Movement Disorders},
	year = {2022},
	journal = {Journal of Parkinson's Disease},
	volume = {12},
	number = {7},
	pages = {2085 – 2096},
	doi = {10.3233/JPD-223351},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142606007&doi=10.3233%2fJPD-223351&partnerID=40&md5=2e5b55dda56eaf24a9c24ed9aa1affc0},
	affiliations = {University of British Columbia, Department of Psychiatry, Kinsmen Laboratory of Neurological Research, Detwiller Pavilion, Vancouver, BC, Canada; Djavad Mowafaghian Centre for Brain Health, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science, University of British Columbia, Vancouver, BC, Canada},
	abstract = {Human motion analysis has been a common thread across modern and early medicine. While medicine evolves, analysis of movement disorders is mostly based on clinical presentation and trained observers making subjective assessments using clinical rating scales. Currently, the field of computer vision has seen exponential growth and successful medical applications. While this has been the case, neurology, for the most part, has not embraced digital movement analysis. There are many reasons for this including: the limited size of labeled datasets, accuracy and nontransparent nature of neural networks, and potential legal and ethical concerns. We hypothesize that a number of opportunities are made available by advancements in computer vision that will enable digitization of human form, movements, and will represent them synthetically in 3D. Representing human movements within synthetic body models will potentially pave the way towards objective standardized digital movement disorder diagnosis and building sharable open-source datasets from such processed videos. We provide a hypothesis of this emerging field and describe how clinicians and computer scientists can navigate this new space. Such digital movement capturing methods will be important for both machine learning-based diagnosis and computer vision-aided clinical assessment. It would also supplement face-to-face clinical visits and be used for longitudinal monitoring and remote diagnosis.  © 2022 - IOS Press. All rights reserved.},
	author_keywords = {Artificial intelligence; computer-assisted diagnosis; computer-assisted image processing; movement disorders; neural networks (computer); Parkinson's disease},
	keywords = {abnormal posture; Article; artificial neural network; body movement; body position; bradykinesia; clinical assessment; clinician; computer analysis; computer scientist; computer vision; digitization; human; information processing; machine learning; MDS-Unified Parkinson Disease Rating Scale; medical ethics; medicolegal aspect; model; motor dysfunction; Parkinson disease; remote sensing; standardization; telediagnosis; three-dimensional imaging; tremor; videorecording},
	correspondence_address = {T.H. Murphy; Vancouver, 2215 Wesbrook Mall, V6T 1Z3, Canada; email: thmurphy@mail.ubc.ca},
	publisher = {IOS Press BV},
	issn = {18777171},
	pmid = {36057831},
	language = {English},
	abbrev_source_title = {J. Parkinson's Dis.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2022116,
	author = {Li, Juan},
	title = {Machine Learning-Based Evaluation of Information Literacy Enhancement among College Teachers},
	year = {2022},
	journal = {International Journal of Emerging Technologies in Learning},
	volume = {17},
	number = {22},
	pages = {116 – 131},
	doi = {10.3991/ijet.v17i22.35117},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143782166&doi=10.3991%2fijet.v17i22.35117&partnerID=40&md5=85f955fbe7a0ac738be9b8db8f92dce7},
	affiliations = {School of Medicine, Hebi Polytechnic, Hebi, China},
	abstract = {To enhance the information literacy among college teachers, it is necessary to evaluate their existing information awareness, information ethics, information techniques and information competence. Existing studies qualitatively analysed the effective means of enhancing information literacy among college teachers, and the dimensions were too homogeneous. In response, this paper studies the machine learning-based evaluation of college teachers’ information literacy enhancement. Firstly, the paper presents a framework of predictive model on information literacy enhancement evaluation of college teachers, and the influencing factors of college teachers’ information technology usage behaviour (ITUB) from the authors’ viewpoint. Then the paper presents a framework diagram for extracting ITUB features, along with a detailed introduction to specific influencing factors. After that, the paper extracts the potential information in the content of information technology behaviour to be predicted. The content features of ITUB are characterised by two aspects: content similarity and data form features. Next, the paper shows a method for calculating the affective polarity of ITUB. It also constructs a predictive model for enhancing ITUB and shows the objective function of the model. The experimental results verify the validity of the constructed model. © 2022, International Journal of Emerging Technologies in Learning. All Rights Reserved.},
	author_keywords = {Classifier; College teachers; Information literacy; Literacy enhancement; Machine learning},
	keywords = {Classification (of information); Awareness information; College teachers; Information awareness; Information ethics; Information literacy; Information techniques; Information technology usages; Literacy enhancement; Machine-learning; Predictive models; Machine learning},
	correspondence_address = {J. Li; School of Medicine, Hebi Polytechnic, Hebi, China; email: zybh1212@outlook.com},
	publisher = {International Association of Online Engineering},
	issn = {18688799},
	language = {English},
	abbrev_source_title = {Int. J. Emerg. Technol. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@BOOK{Sipola20221,
	author = {Sipola, Tuomo and Kokkonen, Tero and Karjalainen, Mika},
	title = {Artificial Intelligence and Cybersecurity: Theory and Applications},
	year = {2022},
	journal = {Artificial Intelligence and Cybersecurity: Theory and Applications},
	pages = {1 – 301},
	doi = {10.1007/978-3-031-15030-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156248184&doi=10.1007%2f978-3-031-15030-2&partnerID=40&md5=111cb8d87c7bfe59b447ebbb4d898b59},
	affiliations = {JAMK University of Applied Sciences, Jyväskylä, Finland},
	abstract = {This book discusses artificial intelligence (AI) and cybersecurity from multiple points of view. The diverse chapters reveal modern trends and challenges related to the use of artificial intelligence when considering privacy, cyber-attacks and defense as well as applications from malware detection to radio signal intelligence. The chapters are contributed by an international team of renown researchers and professionals in the field of AI and cybersecurity. During the last few decades the rise of modern AI solutions that surpass humans in specific tasks has occurred. Moreover, these new technologies provide new methods of automating cybersecurity tasks. In addition to the privacy, ethics and cybersecurity concerns, the readers learn several new cutting edge applications of AI technologies. Researchers working in AI and cybersecurity as well as advanced level students studying computer science and electrical engineering with a focus on AI and Cybersecurity will find this book useful as a reference. Professionals working within these related fields will also want to purchase this book as a reference. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {adversarial attack; Android malware; applied mathematics; artificial intelligence; cyber threat; cybersecurity; cybersecurity training; deep learning; differential privacy; ethics; IT law; machine learning; malware detection; medical imaging; medical imaging; mission critical systems; quantile regression; radio signal intelligence; resilience engineering; security management},
	publisher = {Springer International Publishing},
	isbn = {978-303115030-2; 978-303115029-6},
	language = {English},
	abbrev_source_title = {Artificial Intelligence and Cybersecurity: Theory and Applications},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Martínez-García2022,
	author = {Martínez-García, Mireya and Hernández-Lemus, Enrique},
	title = {Data Integration Challenges for Machine Learning in Precision Medicine},
	year = {2022},
	journal = {Frontiers in Medicine},
	volume = {8},
	doi = {10.3389/fmed.2021.784455},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124270233&doi=10.3389%2ffmed.2021.784455&partnerID=40&md5=3d84d40f902ef2ab5b4069fe2d9f730e},
	affiliations = {Clinical Research Division, National Institute of Cardiology ‘Ignacio Chávez’, Mexico City, Mexico; Computational Genomics Division, National Institute of Genomic Medicine (INMEGEN), Mexico City, Mexico; Center for Complexity Sciences, Universidad Nacional Autnoma de Mexico, Mexico City, Mexico},
	abstract = {A main goal of Precision Medicine is that of incorporating and integrating the vast corpora on different databases about the molecular and environmental origins of disease, into analytic frameworks, allowing the development of individualized, context-dependent diagnostics, and therapeutic approaches. In this regard, artificial intelligence and machine learning approaches can be used to build analytical models of complex disease aimed at prediction of personalized health conditions and outcomes. Such models must handle the wide heterogeneity of individuals in both their genetic predisposition and their social and environmental determinants. Computational approaches to medicine need to be able to efficiently manage, visualize and integrate, large datasets combining structure, and unstructured formats. This needs to be done while constrained by different levels of confidentiality, ideally doing so within a unified analytical architecture. Efficient data integration and management is key to the successful application of computational intelligence approaches to medicine. A number of challenges arise in the design of successful designs to medical data analytics under currently demanding conditions of performance in personalized medicine, while also subject to time, computational power, and bioethical constraints. Here, we will review some of these constraints and discuss possible avenues to overcome current challenges. Copyright © 2022 Martínez-García and Hernández-Lemus.},
	author_keywords = {computational intelligence; data integration; machine learning; meta-data mining; precision medicine},
	keywords = {artificial intelligence; cloud computing; data analysis; data integration; human; learning algorithm; legal aspect; machine learning; medical ethics; metadata; personalized medicine; practice guideline; Review; standardization},
	correspondence_address = {E. Hernández-Lemus; Computational Genomics Division, National Institute of Genomic Medicine (INMEGEN), Mexico City, Mexico; email: ehernandez@inmegen.gob.mx},
	publisher = {Frontiers Media S.A.},
	issn = {2296858X},
	language = {English},
	abbrev_source_title = {Front. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Schneider2022243,
	author = {Schneider, Giulia},
	title = {Legal Challenges of AI Supported Legal Services: Bridging Principles and Markets},
	year = {2022},
	journal = {Italian Law Journal},
	volume = {8},
	number = {1},
	pages = {243 – 291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151541556&partnerID=40&md5=eb16bced8fc5e2c20b7b89648d2d471d},
	affiliations = {Law and Economics, Università Cattolica del Sacro Cuore, Faculty of Banking, Finance and Insurance Sciences, Milan, Italy},
	abstract = {In light of the persisting regulatory gaps in the field of artificial intelligence-driven legal services, this study questions which are the legal tools that are relevant to govern the current expansion of the correspondent market in a way that is consistent with ethical declarations. We move from the acknowledgment that machine learning models are being increasingly applied to textual data contained in legal materials for the prediction of outcomes regarding the legal position of citizens, in terms, for example, of discovery review, contract analytics and legal research. In this respect, the analysis gives account of ongoing transformations in the market of Artificial Intellinge (AI)-supported legal services, with the aim of rooting in the market reality the relevant regulatory framework. In our understanding, the analysis related to the risks connected to the employment of AI-driven legal decision-making tools delivered by the market triggers the question whether the applicable ethical-legal framework provides sufficient tools for addressing the current developments in the market of AI-assisted legal services or whether additional sector-specific solutions need to be introduced. The analysis identifies a gap it intends to fill between the blooming market reality and the ethical and legal perspectives. The uncertainties stemming from a vague ethical and legal framework must be overcome so as to better operationalise and protect fundamental ethical values and fundamental rights in the market of artificial intelligence-driven legal services. Against this backdrop, the study demonstrates how possible solutions against ethics/market mismatches are provided by the legal system, which can work as a bridge vehiculating into the market practice of AI-based legal decision-making tools declared ethical principles, while preventing eventual chilling effects on the market. It thus shows how these need to be adequately matched and integrated with legal design requirements to maximise the resulting positive synergies within the market and thus avoid risks of ethical dilution. In this respect, a layered regulatory regime is proposed for artificial intelligence-driven legal services, of both public and private destination. This framework is meant to operationalise general ethical values and fundamental legal liberties within the more specific regulatory framework given by the European data protection, the Open Data, the European competition framework and the European Commission’s newly proposed rules for artificial intelligence. © 2022 Edizioni Scientifiche Italiane SpA. All rights reserved.},
	publisher = {Edizioni Scientifiche Italiane SpA},
	issn = {24212156},
	language = {English},
	abbrev_source_title = {Italian Law J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Akgun20221373,
	author = {Akgun, Selin and Greenhow, Christine},
	title = {Artificial Intelligence (AI) in Education: Addressing Societal and Ethical Challenges in K-12 Settings},
	year = {2022},
	journal = {Proceedings of International Conference of the Learning Sciences, ICLS },
	pages = {1373 – 1376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145769545&partnerID=40&md5=d287892fb96fb12e17ad03a6138f275d},
	affiliations = {Michigan State University, United States},
	abstract = {Artificial intelligence (AI) incorporates the applications of algorithms, machine learning, and natural language processing within automated assessment and facial recognition systems, personalized learning tools and microblogging systems. These AI applications have the potential to increase capacity within education by supporting the social and cognitive development of students. Despite these affordances, AI applications pose critical ethical and societal drawbacks which are rarely considered in K-12 education. Integration of these algorithms in education may amplify societies' existing systemic biases and discrimination, perpetuate privacy, autonomy, and surveillance concerns for students from marginalized and underserved groups. In this paper, we interrogate applications of AI in K-12 education, highlighting their ethical risks. We introduce instructional resources to help educators navigate the challenges of integrating AI and advance students' understanding of AI and ethics. The paper concludes with recommendations for research. © ISLS.},
	author_keywords = {AI and ethics; artificial intelligence (AI) in education; teacher education},
	keywords = {E-learning; Face recognition; Learning algorithms; Learning systems; Machine learning; Natural language processing systems; Philosophical aspects; Application of algorithms; Artificial intelligence and ethic; Artificial intelligence in education; Automated assessment; K-12 education; Language processing; Learning languages; Machine-learning; Natural languages; Teacher education; Students},
	editor = {Chinn C. and Tan E. and Chan C. and Kali Y.},
	publisher = {International Society of the Learning Sciences (ISLS)},
	issn = {18149316},
	isbn = {978-173733065-3},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Learn. Sci., ICLS },
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 16th International Conference of the Learning Sciences, ICLS 2022; Conference date: 6 June 2022 through 10 June 2022; Conference code: 185192}
}

@BOOK{Behrends202258,
	author = {Behrends, Jeff and Basl, John},
	title = {Trolleys and Autonomous Vehicles: New Foundations for the Ethics of Machine Learning},
	year = {2022},
	journal = {Autonomous Vehicle Ethics: The Trolley Problem and Beyond},
	pages = {58 – 79},
	doi = {10.1093/oso/9780197639191.003.0004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142434428&doi=10.1093%2foso%2f9780197639191.003.0004&partnerID=40&md5=b241f3cb15b3ed52117dc8b5e78f12e4},
	affiliations = {Harvard University, United States; Edmond J. Safra Center for Ethics, United States; Northeastern University, United Kingdom; Northeastern’s Ethics Institute, United Kingdom},
	publisher = {Oxford University Press},
	isbn = {978-019763919-1; 978-019763921-4},
	language = {English},
	abbrev_source_title = {Autonomous Vehicle Ethics: The Trolley Problem and Beyond},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Mahon20221155,
	author = {Mahon, Joyce and Quille, Keith and Mac Namee, Brian and Becker, Brett A.},
	title = {A Novel Machine Learning and Artificial Intelligence Course for Secondary School Students},
	year = {2022},
	journal = {SIGCSE 2022 - Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V.2},
	pages = {1155},
	doi = {10.1145/3478432.3499073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127385229&doi=10.1145%2f3478432.3499073&partnerID=40&md5=bb02488965537bcd08f00d78894c82b0},
	affiliations = {University College Dublin, Dublin, Ireland; Technological University of Dublin, Dublin, Ireland},
	abstract = {We present an overview of a "Machine Learning and Artificial Intelligence"course that is part of a large online course platform for upper second level students. We take a novel approach to teaching fundamental AI concepts that does not require code, and assumes little prior knowledge including only basic mathematics. The design ethos is for students to gain an understanding of how algorithms can "learn". Many misconceptions exist about this term with respect to AI and can lead to confusion and more serious misconceptions, particularly for students who engage with AI-enabled tools regularly. This approach aims to provide insights into how AI actually works, to demystify and remove barriers to more advanced learning, and to emphasize the important roles of ethics and bias in AI. We took several steps to engage students, including videos narrated by a final-year second-level student (US 12th grade). We present design and logistics particulars on this course which is currently being taken by ∼7,000 students in Ireland. We believe this will be of value to other educators and the wider community. © 2022 Owner/Author.},
	author_keywords = {ai; artificial intelligence; computing education k-12; machine learning; outreach},
	keywords = {Curricula; Machine learning; Ai; Artificial intelligence course; Computing education; Computing education k-12; Machine-learning; Online course; Outreach; School students; Second level; Secondary schools; Students},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039071-2},
	language = {English},
	abbrev_source_title = {SIGCSE - Proc. ACM Tech. Symp. Comput. Sci. Educ. V},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 53rd Annual ACM Technical Symposium on Computer Science Education, SIGCSE 2022; Conference date: 3 March 2022 through 5 March 2022; Conference code: 177383}
}

@ARTICLE{Yang2022176,
	author = {Yang, Lixia and Liu, Jiao and Liu, Chaohong and Tian, Shaoqing},
	title = {Quality Evaluation of Order-Based Talent Training in Internationalized Enterprises Based on Machine Learning},
	year = {2022},
	journal = {International Journal of Emerging Technologies in Learning},
	volume = {17},
	number = {23},
	pages = {176 – 191},
	doi = {10.3991/ijet.v17i23.35935},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146702938&doi=10.3991%2fijet.v17i23.35935&partnerID=40&md5=0aced4779cb702c24ff3e0799ac421c3},
	affiliations = {School of International Trade, Hainan College of Economics and Business, Haikou, China; School of Applied Science and Technology, Hainan University, Haikou, China},
	abstract = {Internationalized enterprises conduct business and operation in more than one country. Their complex work processes raise a high demand for the work efficiency of employees. As a result, the enterprises in need of internationalization attach great importance to individual ability and quality when recruiting talents, and need to train talents based on orders. To improve the degree of specialization and employment quality of graduates, it is necessary to effectively evaluate the order-based talent training in internationalized enterprises, which helps to rationalize the training scheme and realize scientific education. However, there are very few studies that quantify the order-based talent training in internationalized enterprises. To fill the gap, this paper evaluates the quality of order-based talent training in internationalized enterprises based on machine learning. Section 2 summarizes the flow of order-based talent training in internationalized enterprises, and establishes an evaluation index system for the training quality, referring to the requirements of internationalized enterprises on the skills, cultural qualities, and professional ethics of talents. The feature data of the evaluation indies were preprocessed through principal component analysis (PCA), which reduces the computing load and increases the computing speed for the order-based talent training quality in internationalized enterprises. Section 3 optimizes the backpropagation (BP) neural network for prediction, and further reduces the dimensionality of the multi-dimensional data on the evaluation indices through locality preservation projection (LPP). The proposed model was proved effective through experiments © 2022, International Journal of Emerging Technologies in Learning.All Rights Reserved.},
	author_keywords = {Artificial neural network; Internationalized enterprises; Machine learning; Order-based talent training; Training quality evaluation},
	keywords = {Backpropagation; Principal component analysis; Quality control; High demand; Internationalized enterprise; Machine-learning; On-machines; Order-based talent training; Quality evaluation; Talent trainings; Training quality evaluation; Work efficiency; Work process; Neural networks},
	correspondence_address = {S. Tian; School of Applied Science and Technology, Hainan University, Haikou, China; email: 994011@hainanu.edu.cn},
	publisher = {International Association of Online Engineering},
	issn = {18688799},
	language = {English},
	abbrev_source_title = {Int. J. Emerg. Technol. Learn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Zhang2022,
	author = {Zhang, Zhengqing and Zhang, Chenggang and Li, Xiaomeng},
	title = {The Ethical Governance for the Vulnerability of Care Robots: Interactive-Distance-Oriented Flexible Design},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {4},
	doi = {10.3390/su14042303},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124953935&doi=10.3390%2fsu14042303&partnerID=40&md5=161e0615f1e7d196021309822023513a},
	affiliations = {School of Marxism, Beihang University, Beijing, 100191, China; Department of Sociology, Tsinghua University, Beijing, 100084, China},
	abstract = {The application of caring robots is currently a widely accepted solution to the problem of aging. However, for the elderly groups who live in gregarious residences and share intelligence devices, caring robots will cause intimacy and assistance dilemmas in the relationship between humans and non-human agencies. This is an information-assisted machine setting, with resulting design ethics issues brought about by the binary values of human and machine, body and mind. The “vulnerability” in risk ethics demonstrates that the ethical problems of human institutions stem from the increase of dependence and the obstruction of intimacy, which are essentially caused by the increased degree of ethical risk exposure and the restriction of agency. Based on value-sensitive design, caring ethics and machine ethics, this paper proposes a flexible design with the interaction-distance-oriented concept, and reprograms the ethical design of caring robots with intentional distance, representational distance and interpretive distance as indicators. The main purpose is to advocate a new type of human-machine interaction relationship emphasizing diversity and physical interaction. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Caring robots; Elderly health management; Flexible design; Human-machine relationship; Machine ethics; Vulnerability},
	keywords = {environmental risk; ethics; machine learning; vulnerability},
	correspondence_address = {C. Zhang; Department of Sociology, Tsinghua University, Beijing, 100084, China; email: zcgice@tsinghua.edu.cn},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Nyrup2022,
	author = {Nyrup, Rune and Robinson, Diana},
	title = {Explanatory pragmatism: a context-sensitive framework for explainable medical AI},
	year = {2022},
	journal = {Ethics and Information Technology},
	volume = {24},
	number = {1},
	doi = {10.1007/s10676-022-09632-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125618593&doi=10.1007%2fs10676-022-09632-3&partnerID=40&md5=ad8a3e06c2ac9fe503906b3b1c45a1ef},
	affiliations = {Leverhulme Centre for the Future of Intelligence, University of Cambridge, Cambridge, United Kingdom; Department of History and Philosophy of Science, University of Cambridge, Cambridge, United Kingdom; Department of Computer Science, University of Cambridge, Cambridge, United Kingdom; Microsoft Research, Cambridge, United Kingdom},
	abstract = {Explainable artificial intelligence (XAI) is an emerging, multidisciplinary field of research that seeks to develop methods and tools for making AI systems more explainable or interpretable. XAI researchers increasingly recognise explainability as a context-, audience- and purpose-sensitive phenomenon, rather than a single well-defined property that can be directly measured and optimised. However, since there is currently no overarching definition of explainability, this poses a risk of miscommunication between the many different researchers within this multidisciplinary space. This is the problem we seek to address in this paper. We outline a framework, called Explanatory Pragmatism, which we argue has two attractive features. First, it allows us to conceptualise explainability in explicitly context-, audience- and purpose-relative terms, while retaining a unified underlying definition of explainability. Second, it makes visible any normative disagreements that may underpin conflicting claims about explainability regarding the purposes for which explanations are sought. Third, it allows us to distinguish several dimensions of AI explainability. We illustrate this framework by applying it to a case study involving a machine learning model for predicting whether patients suffering disorders of consciousness were likely to recover consciousness. © 2022, The Author(s).},
	author_keywords = {Ethics of artificial intelligence; Explainable artificial intelligence; Explanation; Medical artificial intelligence; Understanding; XAI},
	keywords = {Ethical technology; AI systems; Context-sensitive; Ethic of artificial intelligence; Explainable artificial intelligence; Explanation; Medical artificial intelligence; Property; Single well; Understanding; XAI; Artificial intelligence},
	correspondence_address = {R. Nyrup; Leverhulme Centre for the Future of Intelligence, University of Cambridge, Cambridge, United Kingdom; email: rn330@cam.ac.uk},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Rathore2022330,
	author = {Rathore, Archit and Dev, Sunipa and Srikumar, Vivek and Phillips, Jeff M. and Zheng, Yan and Yeh, Michael and Wang, Junpeng and Zhang, Wei and Wang, Bei},
	title = {An Interactive Visual Demo of Bias Mitigation Techniques for Word Representations From a Geometric Perspective},
	year = {2022},
	journal = {Proceedings of Machine Learning Research},
	volume = {176},
	pages = {330 – 334},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163894726&partnerID=40&md5=158cfa60388b7e38e3effcb012a253d1},
	affiliations = {University of Utah, United States; University of California, Los Angeles, United States; VISA Research, United States},
	abstract = {Language representations are known to encode and propagate biases, i.e., stereotypical associations between words or groups of words that may cause representational harm. In this demo, we utilize interactive visualization to increase the interpretability of a number of state-of-the-art techniques that are designed to identify, mitigate, and attenuate these biases in word representations, in particular, from a geometric perspective. We provide an open source web-based visualization tool and offer hands-on experience in exploring the effects of these debiasing techniques on the geometry of high-dimensional word vectors. To help understand how various debiasing techniques change the underlying geometry, we decompose each technique into modular and interpretable sequences of primitive operations, and study their effect on the word vectors using dimensionality reduction and interactive visual exploration. This demo is primarily designed to aid natural language processing (NLP) practitioners and researchers working with fairness and ethics of machine learning systems. It can also be used to educate NLP novices in understanding the existence of and then mitigating biases in word embeddings. © 2022 A. Rathore, S. Dev, V. Srikumar, J.M. Phillips, Y. Zheng, M. Yeh, J. Wang, W. Zhang & B. Wang.},
	author_keywords = {debiasing; ethics; interactive data exploration and discovery; Visualization; word representations},
	keywords = {Data visualization; Geometry; Learning algorithms; Learning systems; Natural language processing systems; Philosophical aspects; Association between words; Data discovery; De-biasing; Interactive data exploration; Interactive data exploration and discovery; Language processing; Mitigation techniques; Natural languages; Word representations; Word vectors; Visualization},
	editor = {Kiela D. and Ciccone M. and Caputo B.},
	publisher = {ML Research Press},
	issn = {26403498},
	language = {English},
	abbrev_source_title = {Proc. Mach. Learn. Res.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 35th Conference on Neural Information Processing Systems, NeurIPS 2021; Conference date: 6 December 2021 through 14 December 2021; Conference code: 189710}
}

@ARTICLE{Middleton2022123,
	author = {Middleton, Alexandra},
	title = {The datafication of pain: trials and tribulations in measuring phantom limb pain},
	year = {2022},
	journal = {BioSocieties},
	volume = {17},
	number = {1},
	pages = {123 – 144},
	doi = {10.1057/s41292-020-00203-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091306188&doi=10.1057%2fs41292-020-00203-7&partnerID=40&md5=512d8a9dffbb9ae6fa897a8b763b694f},
	affiliations = {Department of Anthropology, Princeton University, Princeton, United States},
	abstract = {This article takes the phenomenon of phantom limb pain (PLP), and a therapeutic technology designed to treat it, as springboards to critically consider a transformation: from deeply subjective experiences into quantitative data. Drawing upon ethnographic fieldwork on neuroprosthetic development, I examine an international clinical trial coordinated in Sweden using neuromuscular activation, machine learning, and virtual reality to treat PLP. I excavate the trial’s underlying fundaments and tools, tracing how they define, produce and record changes in an individual’s pain along the course of treatment, a process I call the ‘datafication of pain.’ Moving beyond the representational problematic of pain as simultaneously subjective experience and object of medical intervention, I ask: What gets left out, in this process of datafication? And what gets created in the void it leaves? I argue that the experimental paradigm of datafication elides certain key dimensions of pain itself, particularly its relational dimensions, and surfaces new pain-experiences in-situ. The stakes of this elision and surfacing not only impact the data produced, but also the ethics of actual lived, embodied experiences of pain itself. In leaking out of the experimental apparatus, the excess of pain becomes an artifact of the experimental process, as opposed to merely its object. This article examines the relational dimensions—of both the experimental process and phantom limb pain at large—elided by the data-gathering apparatus itself. © 2020, Springer Nature Limited.},
	author_keywords = {Biomedical engineering; Clinical trials; Feminist studies of science and technology; Medical anthropology; Pain; Phantom limb pain},
	correspondence_address = {A. Middleton; Department of Anthropology, Princeton University, Princeton, United States; email: a.middleton@princeton.edu},
	publisher = {Palgrave Macmillan},
	issn = {17458552},
	language = {English},
	abbrev_source_title = {BioSocieties},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Jobson2022e1,
	author = {Jobson, Dale and Mar, Victoria and Freckelton, Ian},
	title = {Legal and ethical considerations of artificial intelligence in skin cancer diagnosis},
	year = {2022},
	journal = {Australasian Journal of Dermatology},
	volume = {63},
	number = {1},
	pages = {e1 – e5},
	doi = {10.1111/ajd.13690},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112760556&doi=10.1111%2fajd.13690&partnerID=40&md5=3dfb1a9ef9dec5f842a7417be5c5ae36},
	affiliations = {Victorian Melanoma Service, Alfred Hospital, Melbourne, VIC, Australia; School of Public Health and Preventive Medicine, Monash University, Melbourne, VIC, Australia; Victorian Bar, Melbourne, VIC, Australia; Law Faculty, Department of Psychiatry, University of Melbourne, Melbourne, VIC, Australia},
	abstract = {Artificial intelligence (AI) technology is becoming increasingly accurate and prevalent for the diagnosis of skin cancers. Commercially available AI diagnostic software is entering markets across the world posing new legal and ethical challenges for both clinicians and software companies. Australia has the highest rates of skin cancer in the world and is poised to be a significant benefactor and pioneer of the technology. This review describes the legal and ethical considerations raised by the emergence of artificial intelligence in skin cancer diagnosis and proposes recommendations for best practice. © 2021 The Australasian College of Dermatologists.},
	author_keywords = {apps; artificial intelligence; diagnosis; ethical; legal; skin cancer; smartphone},
	keywords = {Artificial Intelligence; Australia; Confidentiality; Diagnosis, Computer-Assisted; Humans; Informed Consent; Liability, Legal; Malpractice; Skin Neoplasms; Software; artificial intelligence; cancer diagnosis; cancer patient; clinician; diagnostic accuracy; diagnostic error; ethics; histopathology; human; legal aspect; machine learning; melanoma; negligence; photography; privacy; Review; skin cancer; software; artificial intelligence; Australia; computer assisted diagnosis; confidentiality; informed consent; legal aspect; legal liability; legislation and jurisprudence; malpractice; skin tumor},
	correspondence_address = {D. Jobson; Victorian Melanoma Service, Alfred Hospital, Melbourne, Australia; email: dalewjobson@gmail.com},
	publisher = {John Wiley and Sons Inc},
	issn = {00048380},
	coden = {AJDEB},
	pmid = {34407234},
	language = {English},
	abbrev_source_title = {Australas. J. Dermatol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@BOOK{Prainsack2022191,
	author = {Prainsack, Barbara and Steind, Elisabeth},
	title = {Legal and Ethical Aspects of Machine Learning: Who Owns the Data?},
	year = {2022},
	journal = {Artificial Intelligence/Machine Learning in Nuclear Medicine and Hybrid Imaging},
	pages = {191 – 202},
	doi = {10.1007/978-3-031-00119-2_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163428061&doi=10.1007%2f978-3-031-00119-2_14&partnerID=40&md5=95a637a3030fc2c8ca2b216647a43223},
	affiliations = {Department of Political Science, University of Vienna, Vienna, Austria; Department of Innovation and Digitalisation in Law, University of Vienna, Vienna, Austria},
	abstract = {This chapter starts with an overview of the key ethical issues that have been discussed in connection with artificial intelligence in general, and machine learning in particular, within the field of healthcare. We argue that, going forward, the deliberation and further development of ethics of AI and machine learning should be grounded more strongly in the field of data ethics than it is the case today. This is because of the specific nature of the digital data that enable machine learning and artificial intelligence. We then turn to the question of ownership, discussing what ownership means, and can mean, in the context of digital data, and who can legitimately own digital data used in and for imaging. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.},
	author_keywords = {Big data; Data ownership; Imaging; Machine learning},
	correspondence_address = {B. Prainsack; Department of Political Science, University of Vienna, Vienna, Austria; email: barbara.prainsack@univie.ac.at},
	publisher = {Springer International Publishing},
	isbn = {978-303100119-2; 978-303100118-5},
	language = {English},
	abbrev_source_title = {Artificial Intelligence/Machine Learning in Nuclear Medicine and Hybrid Imaging},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Buruk2022611,
	author = {Buruk, Banu and Akgök, Bengü and Güreş, Berzan and Güvenç, Irmak and Akpunar, Nurettin Can and Çavdar, Sıla and Karaca, Şenel},
	title = {A literature review on medical ethics issues regarding big data},
	year = {2022},
	journal = {Medicine and Law},
	volume = {41},
	number = {4},
	pages = {611 – 626},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153781101&partnerID=40&md5=3f07be401811428fdd6a600cff8424ec},
	affiliations = {TOBB ETU University School of Medicine, Department of History of Medicine and Ethics; TOBB ETU University School of Medicine},
	abstract = {The rapid development of artificial intelligence (AI) and machine learning techniques has created great hope for innovation in the field of health, as in many other fields. It is thought that clinical decisions will reach maximum optimization, especially with the medical use of Big Data. From the perspective from medical ethics, some challenges are encountered. This study includes a comprehensive review of the ethical discussions on Big Health Data, gathered under two headings. Firstly, the concerns about the anonymization, transparency, and trustworthiness of the data that are planned to be collected and used and the approaches to obtaining informed consent for this data were examined. Secondly, the problems that may arise in various phases of data management are detailed and the approaches to these problems are highlighted. © 2022, William S. Hein & Co., Inc.. All rights reserved.},
	author_keywords = {Big Data; Data Management; Informed Consent; Medical Ethics; Privacy},
	keywords = {anonymization; article; big data; health data; informed consent; privacy},
	correspondence_address = {B. Buruk; TOBB ETU University School of Medicine, Department of History of Medicine and Ethics; email: banuburuk@gmail.com},
	publisher = {William S. Hein & Co., Inc.},
	issn = {07231393},
	coden = {MELAD},
	language = {English},
	abbrev_source_title = {Med. Law},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kemell2022553,
	author = {Kemell, Kai-Kristian and Vakkuri, Ville and Halme, Erika},
	title = {Utilizing User Stories to Bring AI Ethics into Practice in Software Engineering},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13709 LNCS},
	pages = {553 – 558},
	doi = {10.1007/978-3-031-21388-5_41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142733183&doi=10.1007%2f978-3-031-21388-5_41&partnerID=40&md5=40f8ea5b0a5bcf58e891f05f6976dfcd},
	affiliations = {University of Helsinki, Helsinki, Finland; University of Vaasa, Vaasa, Finland; University of Jyväskylä, Jyväskylä, Finland},
	abstract = {AI ethics is a research area characterized by a prominent gap between research and practice. With most studies in the area being conceptual in nature or focused on technical ML (Machine Learning) solutions, the link between AI (Artificial Intelligence) ethics and SE (Software Engineering) practice remains thin. Establishing this link, we argue, is vital going forward. While conceptual discussion is required to define AI ethics, much progress has already been made in this regard. Similarly, though technical ML solutions are also required for practical implementation, ML systems are ultimately still software, and thus SE cannot be forgotten. In this paper, we propose one way of bringing AI ethics closer to conventional SE practice: utilizing user stories to implement AI ethics by means of Ethical User Stories (EUS). EUS can be used to formulate both functional and non-functional requirements, although an ethical framework is required produce them. By treating AI ethics as a part of the development process in this fashion, as opposed to a separate task, it can ideally become a part of SE for ML systems. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {AI ethics; Artificial Intelligence; Ethical tool; Ethical user story; User story},
	keywords = {Ethical technology; Software engineering; Artificial intelligence ethic; Ethical tool; Ethical user story; Machine learning systems; Machine-learning; Non-functional requirements; Research areas; Software engineering practices; User stories; Artificial intelligence},
	correspondence_address = {K.-K. Kemell; University of Helsinki, Helsinki, Finland; email: kai-kristian.kemell@helsinki.fi},
	editor = {Taibi D. and Kuhrmann M. and Mikkonen T. and Abrahamsson P. and Klünder J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303121387-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 23rd International Conference on Product-Focused Software Process Improvement, PROFES 2022; Conference date: 21 November 2022 through 23 November 2022; Conference code: 286329}
}

@CONFERENCE{Sengoz2022523,
	author = {Sengoz, Nilgun and Yigit, Tuncay},
	title = {Towards Third Generation AI: Explainable and Interpretable AI; [Ufuncu Nesil Yapay Zekaya Dogru: Afiklanabilir ve Yorumlanabilir Yapay Zeka]},
	year = {2022},
	journal = {Proceedings - 7th International Conference on Computer Science and Engineering, UBMK 2022},
	pages = {523 – 526},
	doi = {10.1109/UBMK55850.2022.9919510},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141869333&doi=10.1109%2fUBMK55850.2022.9919510&partnerID=40&md5=9ec04f0a49528268cd2c4302358a5626},
	affiliations = {Burdur Mehmet Akif Ersoy Üniversitesi, MAKÜ-BAKA Teknokent, Burdur, Turkey; Süleyman Demirel Üniversitesi, Bilgisayar Mühendisliǧi, Isparta, Turkey},
	abstract = {Today, artificial intelligence-based systems, especially machine learning and deep neural network algorithms, make decisions that directly affect people's lives, from health to autonomous vehicles and even to the defense sector. And yet, algorithms like deep neural networks that are high in performance accuracy but low in explainability and trust bring problems in ethics and interpretability. Explainable Artificial Intelligence (XAJD) is a branch of artificial intelligence that produces highquality interpretability, end-user-oriented understanding and explainable tools, techniques and algorithms. In this study, general information about XAI is given.  © 2022 IEEE.},
	author_keywords = {artifical intelligence; deep learning; XAI},
	keywords = {Artifical intelligence; Autonomous Vehicles; Deep learning; Defense sectors; Interpretability; Machine-learning; Neural networks algorithms; Performance; Third generation; XAI; Deep neural networks},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166547010-0},
	language = {Turkish},
	abbrev_source_title = {Proc. - Int. Conf. Comput. Sci. Eng., UBMK},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th International Conference on Computer Science and Engineering, UBMK 2022; Conference date: 14 September 2022 through 16 September 2022; Conference code: 183844}
}

@ARTICLE{Senent2022,
	author = {Senent, Rosa M. and Bueso, Diego},
	title = {The Banality of (Automated) Evil: Critical Reflections on the Concept of Forbidden Knowledge in Machine Learning Research; [La banalidad del mal (automatizado): reflexiones críticas sobre el conocimiento peligroso en la investigación del aprendizaje automático]},
	year = {2022},
	journal = {Recerca},
	volume = {27},
	number = {2},
	doi = {10.6035/recerca.6147},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148516608&doi=10.6035%2frecerca.6147&partnerID=40&md5=37b1a72faaae8a9d2c656d6c9d8203dc},
	affiliations = {Dublin City University, Ireland; Universitat de València, Spain},
	abstract = {The development of computer science has raised ethical concerns regarding the potential negative impact of machine learning tools on people and society. In this article, we provide three examples of automated evil: deepfake technology (ab)used by anonymous men to make digitally manipulated pornography to harm women; pattern recognition designed to try to uncover sexual orientation; and deep learning and extensive datasets used by private companies to influence democratic elections. We contend that the concept of ‘forbidden knowledge’ can help to inform a coherent ethical framework in the context of data and computer science research and contribute to tackle automated evil. We conclude that restricting generalised access to extensive data and limiting access to ready-to-use codes would mitigate potential harm caused by machine learning tools. In addition, we advocate that the notions of intersectionality and interdisciplinarity be systematically incorporated in data and computer science research. © 2022 Universitat Jaume I. All rights reserved.},
	author_keywords = {AI ethics; artificial intelligence; forbidden knowledge; gender; machine learning},
	correspondence_address = {R.M. Senent; Dublin City University, Ireland; email: rosa.senentjulian2@mail.dcu.ie},
	publisher = {Universitat Jaume I},
	issn = {11306149},
	language = {English},
	abbrev_source_title = {Recerca},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hrincu2022447,
	author = {Hrincu, Viorica and An, Zijian and Joseph, Kenneth and Jiang, Yu Fei and Robillard, Julie M. and Rosen, Allyson},
	title = {Dementia Research on Facebook and Twitter: Current Practice and Challenges},
	year = {2022},
	journal = {Journal of Alzheimer's Disease},
	volume = {90},
	number = {2},
	pages = {447 – 459},
	doi = {10.3233/JAD-220525},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141935596&doi=10.3233%2fJAD-220525&partnerID=40&md5=7c84fc0059761ab96bff66d806e11e85},
	affiliations = {Department of Medicine, Division of Neurology, University of British Columbia, Vancouver, BC, Canada; Department of Computer Science and Engineering, University at Buffalo, Buffalo, NY, United States; BC Children's and Women's Hospital, Vancouver, BC, Canada},
	abstract = {Background: Social media is a powerful tool for engaging diverse audiences in dementia research. However, there is little data summarizing current content exchange in this context. Objective: To inform ethical dementia research engagement on social media, we characterized current practices by analyzing public social media posts. Methods: We retrieved Facebook (2-year period, N = 7,896) and Twitter (1-year period, N = 9,323) posts containing dementia research-related keywords using manual and machine learning-based search strategies. We performed qualitative and quantitative content and sentiment analyses on random samples (10%) of the posts. Results: Top Facebook users were advocacy (45%) and health organizations (25%). On Twitter, academics/researchers were the largest user group. Prevention was the most frequently coded theme (Facebook 30%; Twitter 26%), followed by treatment (Facebook 15%; Twitter 18%). Diagnostics had the highest Facebook engagement. Sharing knowledge was the primary form of content exchange (Facebook 63%; Twitter 80%). Most shared journal articles were peer-reviewed and open access. Emotional tone was overall more positive on Facebook. Justice was a prominent ethics topic regarding inequalities related to identity and intersecting modes of marginalization in dementia research. Conclusion: The findings indicate the importance of social media as an engagement tool of current topics in health research and reveal areas of potential for increased engagement. These data can inform consensus-based best practices for ethical social media application in dementia research.  © 2022 - The authors. Published by IOS Press.},
	author_keywords = {Access to information; Alzheimer's disease; dementia; internet; qualitative research; social media},
	keywords = {Dementia; Humans; Social Media; access to information; advocacy group; Alzheimer disease; content analysis; controlled study; cross-sectional study; dementia; health care organization; human; Internet; justice; knowledge; machine learning; open access publishing; peer review; qualitative analysis; quantitative analysis; research ethics; Review; scientist; sentiment analysis; social inequality; social media; dementia},
	correspondence_address = {J.M. Robillard; Vancouver, B402 Shaughnessy, 4480 Oak Street, V6H 3N1, Canada; email: jrobilla@mail.ubc.ca},
	publisher = {IOS Press BV},
	issn = {13872877},
	coden = {JADIF},
	pmid = {36155513},
	language = {English},
	abbrev_source_title = {J. Alzheimer's Dis.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Giovanola2022,
	author = {Giovanola, Benedetta and Tiribelli, Simona},
	title = {Weapons of moral construction? On the value of fairness in algorithmic decision-making},
	year = {2022},
	journal = {Ethics and Information Technology},
	volume = {24},
	number = {1},
	doi = {10.1007/s10676-022-09622-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123996403&doi=10.1007%2fs10676-022-09622-5&partnerID=40&md5=8a6257be091475c1ab9eeba5028f9510},
	affiliations = {Department of Political Sciences, Communication, and International Relations, University of Macerata, Macerata, 62100, Italy; Department of Philosophy, Tufts University, 222 Miner Hall, Medford, 02155, MA, United States; Institute for Technology and Global Health, PathCheck Foundation, 955 Massachusetts Ave, Cambridge, 02139, MA, United States},
	abstract = {Fairness is one of the most prominent values in the Ethics and Artificial Intelligence (AI) debate and, specifically, in the discussion on algorithmic decision-making (ADM). However, while the need for fairness in ADM is widely acknowledged, the very concept of fairness has not been sufficiently explored so far. Our paper aims to fill this gap and claims that an ethically informed re-definition of fairness is needed to adequately investigate fairness in ADM. To achieve our goal, after an introductory section aimed at clarifying the aim and structure of the paper, in section “Fairness in algorithmic decision-making” we provide an overview of the state of the art of the discussion on fairness in ADM and show its shortcomings; in section “Fairness as an ethical value”, we pursue an ethical inquiry into the concept of fairness, drawing insights from accounts of fairness developed in moral philosophy, and define fairness as an ethical value. In particular, we argue that fairness is articulated in a distributive and socio-relational dimension; it comprises three main components: fair equality of opportunity, equal right to justification, and fair equality of relationship; these components are grounded in the need to respect persons both as persons and as particular individuals. In section “Fairness in algorithmic decision-making revised”, we analyze the implications of our redefinition of fairness as an ethical value on the discussion of fairness in ADM and show that each component of fairness has profound effects on the criteria that ADM ought to meet. Finally, in section “Concluding remarks”, we sketch some broader implications and conclude. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Algorithmic decision-making; Discrimination; Ethics of algorithms; Fairness; Machine learning; Respect},
	keywords = {Ethical technology; Machine learning; Algorithmic decision-making; Algorithmics; Decisions makings; Discrimination; Ethic of algorithm; Ethical values; Fairness; Moral philosophy; Respect; State of the art; Decision making},
	correspondence_address = {B. Giovanola; Department of Political Sciences, Communication, and International Relations, University of Macerata, Macerata, 62100, Italy; email: benedetta.giovanola@unimc.it},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Murray-Rust20221291,
	author = {Murray-Rust, Dave and Tsiakas, Konstantinos},
	title = {EthicAmanuensis: supporting machine learning practitioners making and recording ethical decisions},
	year = {2022},
	journal = {Proceedings - International Conference on Tools with Artificial Intelligence, ICTAI},
	volume = {2022-October},
	pages = {1291 – 1295},
	doi = {10.1109/ICTAI56018.2022.00195},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156120817&doi=10.1109%2fICTAI56018.2022.00195&partnerID=40&md5=c126d74f5bf923316f47ba4ada5d82c9},
	affiliations = {Industrial Design Engineering, Delft University of Technology, Netherlands},
	abstract = {Ethics should be a practice, not a checkbox. Data scientists want to answer questions about individuals and society using the vast torrent of data that flows around us. Machine learning practitioners want to develop and connect complex models of the world and use them safely in critical situations. Ethical issues can be seen as getting in the way of the core idea and form pain points around managing, using and learning from data, as well as designing human-centric and ethical systems. This is because there is a design gap around ethics in data science and machine learning: the tools that we use do not support ethical data use, which means that data scientists and machine learning practitioners, already engaged in technically complex, multidisciplinary work, must add another dimension to their thinking. This work proposes and outlines an infrastructure and framework that can support in-the-moment ethical decision making and recording, as well as post-hoc audits and ethical model deployment. © 2022 IEEE.},
	author_keywords = {Ethical AI; ethical annotations tool; fairness},
	keywords = {Ethical technology; Machine learning; Annotation tool; Complex model; Ethical AI; Ethical annotation tool; Ethical decision making; Ethical issues; Fairness; Human-centric; Machine-learning; Science learning; Decision making},
	editor = {Reformat M. and Zhang D. and Bourbakis N.G.},
	publisher = {IEEE Computer Society},
	issn = {10823409},
	isbn = {979-835039744-4},
	coden = {PCTIF},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Tools Artif. Intell. ICTAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 34th IEEE International Conference on Tools with Artificial Intelligence, ICTAI 2022; Conference date: 31 October 2022 through 2 November 2022; Conference code: 188065}
}

@ARTICLE{Tsamados2022215,
	author = {Tsamados, Andreas and Aggarwal, Nikita and Cowls, Josh and Morley, Jessica and Roberts, Huw and Taddeo, Mariarosaria and Floridi, Luciano},
	title = {The ethics of algorithms: key problems and solutions},
	year = {2022},
	journal = {AI and Society},
	volume = {37},
	number = {1},
	pages = {215 – 230},
	doi = {10.1007/s00146-021-01154-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101291085&doi=10.1007%2fs00146-021-01154-8&partnerID=40&md5=b3d1a4a1ed113754fd1bde8c7ca6c142},
	affiliations = {Oxford Internet Institute, University of Oxford, 1 St Giles’, Oxford, OX1 3JS, United Kingdom; Alan Turing Institute, British Library, 96 Euston Rd, London, NW1 2DB, United Kingdom; Faculty of Law, University of Oxford, St. Cross Building, St. Cross Road, Oxford, OX1 3UL, United Kingdom},
	abstract = {Research on the ethics of algorithms has grown substantially over the past decade. Alongside the exponential development and application of machine learning algorithms, new ethical problems and solutions relating to their ubiquitous use in society have been proposed. This article builds on a review of the ethics of algorithms published in 2016 (Mittelstadt et al. Big Data Soc 3(2), 2016). The goals are to contribute to the debate on the identification and analysis of the ethical implications of algorithms, to provide an updated analysis of epistemic and normative concerns, and to offer actionable guidance for the governance of the design, development and deployment of algorithms. © 2021, The Author(s).},
	author_keywords = {Algorithm; Artificial intelligence; Autonomy; Digital ethics; Explainability; Fairness; Machine learning; Privacy; Responsibility; Transparency; Trust},
	keywords = {Machine learning; Philosophical aspects; Development and applications; Ethical implications; Ethical problems; Problems and Solutions; Learning algorithms},
	correspondence_address = {L. Floridi; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles’, OX1 3JS, United Kingdom; email: luciano.floridi@oii.ox.ac.uk},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 79; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Song2022,
	author = {Song, Fei and Yeung, Shing Hay Felix},
	title = {A pluralist hybrid model for moral AIs},
	year = {2022},
	journal = {AI and Society},
	doi = {10.1007/s00146-022-01601-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142667938&doi=10.1007%2fs00146-022-01601-0&partnerID=40&md5=544ac276b1bdde7ef4677f6a909630fb},
	affiliations = {Department of Philosophy, Lingnan University, Tuen Mun, Hong Kong; Department of Philosophy, University of Hong Kong, Central and Western, Hong Kong},
	abstract = {With the increasing degrees AIs and machines, the need for implementing ethics in AIs is pressing. In this paper, we first survey current approaches to moral AIs and their inherent limitations. Then we propose the pluralist hybrid approach and show how these limitations of moral AIs can be partly alleviated by the pluralist hybrid approach. The core ethical decision-making capacity of an AI based on the pluralist hybrid approach consists of two systems. The first is a deterministic algorithm system that embraces different moral rules for making explicit moral decisions. The second is a machine learning system that accounts for calculating the value of the variables required by the application of moral principles. The pluralist hybrid system is better than the existing proposals as it better addresses the moral disagreement problem of the top-down approach by including distinct moral principles. Besides, the pluralist hybrid system reduces the opacity of ethical decision-making by implementing explicit moral principles for moral decision-making. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Hybrid system; Moral AIs; Moral disagreement problem; Opacity problem},
	keywords = {Decision making; Learning systems; Opacity; Philosophical aspects; Transparency; 'current; Deterministic algorithms; Ethical decision making; Hybrid approach; Hybrid model; Inherent limitations; Moral AI; Moral disagreement problem; Opacity problem; Pressung; Hybrid systems},
	correspondence_address = {F. Song; Department of Philosophy, Lingnan University, Tuen Mun, Hong Kong; email: feisong@ln.edu.hk},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Quinn2022,
	author = {Quinn, Thomas P. and Jacobs, Stephan and Senadeera, Manisha and Le, Vuong and Coghlan, Simon},
	title = {The three ghosts of medical AI: Can the black-box present deliver?},
	year = {2022},
	journal = {Artificial Intelligence in Medicine},
	volume = {124},
	doi = {10.1016/j.artmed.2021.102158},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114689820&doi=10.1016%2fj.artmed.2021.102158&partnerID=40&md5=f1ba72dc31548d041e35c35feafb046a},
	affiliations = {Applied Artificial Intelligence Institute, Deakin University, Geelong, Australia; Centre for AI and Digital Ethics, School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia},
	abstract = {Our title alludes to the three Christmas ghosts encountered by Ebenezer Scrooge in A Christmas Carol, who guide Ebenezer through the past, present, and future of Christmas holiday events. Similarly, our article takes readers through a journey of the past, present, and future of medical AI. In doing so, we focus on the crux of modern machine learning: the reliance on powerful but intrinsically opaque models. When applied to the healthcare domain, these models fail to meet the needs for transparency that their clinician and patient end-users require. We review the implications of this failure, and argue that opaque models (1) lack quality assurance, (2) fail to elicit trust, and (3) restrict physician-patient dialogue. We then discuss how upholding transparency in all aspects of model design and model validation can help ensure the reliability and success of medical AI. © 2021 Elsevier B.V.},
	author_keywords = {Autonomy; Black-box; Challenges; Ethics; Transparency; Xai},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Machine Learning; Reproducibility of Results; Trust; Quality assurance; Black boxes; Christmas; End users; Healthcare domains; Model design; Modern machines; adult; article; ethics; human; machine learning; quality control; reliability; trust; artificial intelligence; health care delivery; machine learning; reproducibility; Transparency},
	correspondence_address = {T.P. Quinn; Applied Artificial Intelligence Institute, Deakin University, Geelong, Australia; email: contacttomquinn@gmail.com},
	publisher = {Elsevier B.V.},
	issn = {09333657},
	coden = {AIMEE},
	pmid = {34511267},
	language = {English},
	abbrev_source_title = {Artif. Intell. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Green Open Access}
}

@ARTICLE{Drapkina202237,
	author = {Drapkina, Yulia S. and Kalinina, Elena A. and Makarova, Natalya P. and Milchakov, Kirill S. and Frankevich, Vladimir E.},
	title = {ARTIFICIAL INTELLIGENCE IN REPRODUCTIVE MEDICINE: ETHICAL AND CLINICAL ASPECTS},
	year = {2022},
	journal = {Akusherstvo i Ginekologiya (Russian Federation)},
	volume = {2022},
	number = {11},
	pages = {37 – 44},
	doi = {10.18565/aig.2022.11.37-44},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144475053&doi=10.18565%2faig.2022.11.37-44&partnerID=40&md5=e1c6ce194dd5cb3c2a36f268af275b00},
	affiliations = {Academician V.I. Kulakov National Medical Research Center of Obstetrics, Gynecology, and Perinatology, Ministry of Health of Russia, Academician Oparin str., 4, Moscow, 117997, Russian Federation; I.M. Sechenov First Moscow State Medical University (Sechenov University), Ministry of Health of Russia, Trubetskaya str., 8-2, Moscow, 119991, Russian Federation},
	abstract = {The introduction of artificial intelligence (AI) systems in medicine is one of the most important current trends in global healthcare. AI technologies can substantially update a diagnostic system and the design of new drugs and improve the quality of healthcare, by simultaneously reducing cost. Despite the obvious advantages of applying AI-based algorithms, there are a number of limitations in the implementation of these programs in healthcare. Among these problems, there is an ethical challenge in AI, as well as responsibility for programmed decision-making. Another important issue of the safe use of AI is the black box principle, when determining causal relationships between data, how the system has actually arrived at a derived conclusion cannot be determined exactly. At the moment, the major goal of AI studies should be to improve software accuracy. Conclusion: The review considers the main areas of AI application, different machine learning techniques, ethical restrictions, and prospects for introducing these programs into clinical practice, including those used in assisted reproductive technologies. © A group of authors, 2022.},
	author_keywords = {artificial intelligence; assisted reproductive technologies; decision support system; ethics; healthcare; machine learning; reproductive medicine},
	keywords = {Article; artificial intelligence; clinical decision making; clinical feature; clinical practice; infertility therapy; medical ethics; reproduction},
	publisher = {Bionika Media Ltd.},
	issn = {03009092},
	coden = {AKGIA},
	language = {Russian},
	abbrev_source_title = {Akush. Ginekol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Walson2022,
	author = {Walson, Judd and Berkley, James and Njunge, James M. and Tickell, Kirkby and Diallo, Abdoulaye Hama and Sayeem Bin Shahid, Abu Sadat Mohammad and Gazi, Md. Amran and Saleem, Ali and Kazi, Zaubina and Ali, Syed and Tigoi, Caroline and Mupere, Ezekiel and Lancioni, Christina L. and Yoshioka, Emily and Chisti, Mohammod Jobayer and Mburu, Moses and Ngari, Moses and Ngao, Narshion and Gichuki, Bonface and Omer, Elisha and Gumbi, Wilson and Singa, Benson and Bandsma, Robert and Ahmed, Tahmeed and Voskuijl, Wieger and Williams, Thomas N. and Macharia, Alex and Makale, Johnstone and Mitchel, Anna and Williams, Jessica and Gogain, Joe and Janjic, Nebojsa and Mandal, Rupasri and Wishart, David S. and Wu, Hang and Xia, Lei and Routledge, Michael and Gong, Yun Yun and Espinosa, Camilo and Aghaeepour, Nima and Liu, Jie and Houpt, Eric and Lawley, Trevor D. and Browne, Hilary and Shao, Yan and Rwigi, Doreen and Kariuki, Kevin and Kaburu, Timothy and Uhlig, Holm H. and Gartner, Lisa and Jones, Kelsey and Koulman, Albert},
	title = {The Childhood Acute Illness and Nutrition (CHAIN) network nested case-cohort study protocol: A multi-omics approach to understanding mortality among children in sub-Saharan Africa and South Asia},
	year = {2022},
	journal = {Gates Open Research},
	volume = {6},
	doi = {10.12688/gatesopenres.13635.2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141985804&doi=10.12688%2fgatesopenres.13635.2&partnerID=40&md5=0b048db0393743de7b1ef1810381ae0f},
	affiliations = {The Childhood Acute Illness and Nutrition Network, Nairobi, Kenya; KEMRI-Wellcome Trust Research Programme, Kilifi, Kenya; Global Health and Epidemiology, University of Washington, Seattle, Seattle, United States; Department of Public Health, Faculty of Health Sciences, University of Ouagadougou, Ouagadougou, Burkina Faso; Nutrition and Clinical Services Division, International Centre for Diarrhoeal Disease Research, Bangladesh (icddr, b), Dhaka, Bangladesh; Department of Pediatrics and Child Health, Aga Khan University Hospital, Karachi, Karachi, Pakistan; Department of Paediatrics and Child Health, College of Health Sciences, Makerere University, Kampala, Uganda; Department of Pediatrics, Oregon Health and Science University, Portland, OR, United States; Kenya Medical Research Institute, Nairobi, Kenya; Centre for Global Child Health, The Hospital for Sick Children, Toronto, ON, Canada; Department of Biomedical Sciences, University of Malawi College of Medicine, Blantyre, Malawi; Amsterdam UMC location, University of Amsterdam, Amsterdam, Netherlands; Amsterdam Centre for Global Child Health and Emma Children's Hospital, Amsterdam, Netherlands; Institute of Global Health Innovation, Department of Surgery and Cancer, Imperial College London, London, United Kingdom; SomaLogic, Boulder, CO, United States; Department of Biological Sciences, University of Alberta, Edmonton, Alberta, Canada; School of Food Science and Nutrition, University of Leeds, Leeds, United Kingdom; School of Food and Biological Engineering, Jiangsu University, Zhenjiang, China; Departments of Anesthesiology, Pain and Perioperative Medicine, Stanford University School of Medicine, Stanford, 94305, CA, United States; Department of Pediatrics, Stanford University School of Medicine, Stanford, 94305, CA, United States; Department of Biomedical Data Science, Stanford University School of Medicine, Stanford University School of Medicine, Stanford, 94305, CA, United States; Division of Infectious Diseases and International Health, University of Virginia, Charlottesville, VA, United States; Wellcome Sanger Institute, Hinxton, United Kingdom; The Centre for Microbiology Research, Kenya Medical Research Institute, Nairobi, Kenya; Translational Gastroenterology Unit, John Radcliffe Hospital, University of Oxford, Oxford, United Kingdom; Department of Paediatrics and Biomedical Research Centre, University of Oxford, Oxford, United Kingdom; Kennedy Institute of Rheumatology, University of Oxford, Oxford, United Kingdom; Gastroenterology Department, Great Ormond Street Hospital for Children, London, United Kingdom; MRC Epidemiology Unit, University of Cambridge, Cambridge, United Kingdom; NIHR BRC Nutritional Biomarker Laboratory, University of Cambridge, Cambridge, United Kingdom; Center for Tropical Medicine and Global Health, University of Oxford, Oxford, United Kingdom},
	abstract = {Introduction: Many acutely ill children in low- and middle-income settings have a high risk of mortality both during and after hospitalisation despite guideline-based care. Understanding the biological mechanisms underpinning mortality may suggest optimal pathways to target for interventions to further reduce mortality. The Childhood Acute Illness and Nutrition (CHAIN) Network ( www.chainnnetwork.org) Nested Case-Cohort Study (CNCC) aims to investigate biological mechanisms leading to inpatient and post-discharge mortality through an integrated multi-omic approach. Methods and analysis; The CNCC comprises a subset of participants from the CHAIN cohort (1278/3101 hospitalised participants, including 350 children who died and 658 survivors, and 270/1140 well community children of similar age and household location) from nine sites in six countries across sub-Saharan Africa and South Asia. Systemic proteome, metabolome, lipidome, lipopolysaccharides, haemoglobin variants, toxins, pathogens, intestinal microbiome and biomarkers of enteropathy will be determined. Computational systems biology analysis will include machine learning and multivariate predictive modelling with stacked generalization approaches accounting for the different characteristics of each biological modality. This systems approach is anticipated to yield mechanistic insights, show interactions and behaviours of the components of biological entities, and help develop interventions to reduce mortality among acutely ill children. Ethics and dissemination. The CHAIN Network cohort and CNCC was approved by institutional review boards of all partner sites. Results will be published in open access, peer reviewed scientific journals and presented to academic and policy stakeholders. Data will be made publicly available, including uploading to recognised omics databases. Trial registration NCT03208725. © 2022 Njunge JM et al.},
	author_keywords = {Case-Cohort; Children; LMIC; Mortality; Omics; Systems Biology},
	keywords = {aflatoxin; albumin; alpha 1 antitrypsin; biological marker; calgranulin; hemoglobin A; hemoglobin A2; hemoglobin F; hemoglobin S; lipidome; lipopolysaccharide; myeloperoxidase; proteome; toxin; acute disease; Africa south of the Sahara; analysis; Article; bacterial cell; behavior; beta thalassemia; case control study; child; child growth; Childhood Acute Illness and Nutrition  Network; clinical trial; cohort analysis; controlled study; DNA extraction; DNA microarray; dose response; dried blood spot testing; electrospray; elemental analysis; enzyme linked immunosorbent assay; Escherichia coli; high performance liquid chromatography; human; inductively coupled plasma mass spectrometry; infectious agent; ion exchange chromatography; liquid chromatography-mass spectrometry; machine learning; major clinical study; metabolome; metagenomic sequencing; microbiome; mortality; multiomics; multiple reaction monitoring; nonhuman; nutritional disorder; particle size; rectal swab; sequence analysis; sickle cell anemia; South Asia; systems biology; tandem mass spectrometry; ultra performance liquid chromatography},
	correspondence_address = {J. Walson; Global Health and Epidemiology, University of Washington, Seattle, Seattle, United States; email: walson@uw.edu; J. Berkley; The Childhood Acute Illness and Nutrition Network, Nairobi, Kenya; email: jberkley@kemri-wellcome.org},
	publisher = {F1000 Research Ltd},
	issn = {25724754},
	language = {English},
	abbrev_source_title = {Gates Open Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Landau2022576,
	author = {Landau, Aviv Y. and Ferrarello, Susi and Blanchard, Ashley and Cato, Kenrick and Atkins, Nia and Salazar, Stephanie and Patton, Desmond U. and Topaz, Maxim},
	title = {Developing machine learning-based models to help identify child abuse and neglect: key ethical challenges and recommended solutions},
	year = {2022},
	journal = {Journal of the American Medical Informatics Association},
	volume = {29},
	number = {3},
	pages = {576 – 580},
	doi = {10.1093/jamia/ocab286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123901001&doi=10.1093%2fjamia%2focab286&partnerID=40&md5=3de88beadd26ce800c212e5a1aacaf15},
	affiliations = {Columbia University Data Science Institute, Columbia University School of Nursing, Columbia University, New York, NY, United States; Department of Philosophy & Religious Studies, California State University, Hayward, CA, United States; New York Presbyterian Morgan Stanley Children's Hospital, Columbia University Irving Medical Center, New York, NY, United States; Department of Emergency Medicine, Columbia University School of Nursing, Columbia University, New York, NY, United States; Columbia College, New York, NY, United States; Columbia School of Social Work, Columbia University, New York, NY, United States; Columbia University Data Science Institute, Columbia School of Social Work, Columbia University, New York, NY, United States},
	abstract = {Child abuse and neglect are public health issues impacting communities throughout the United States. The broad adoption of electronic health records (EHR) in health care supports the development of machine learning-based models to help identify child abuse and neglect. Employing EHR data for child abuse and neglect detection raises several critical ethical considerations. This article applied a phenomenological approach to discuss and provide recommendations for key ethical issues related to machine learning-based risk models development and evaluation: (1) biases in the data; (2) clinical documentation system design issues; (3) lack of centralized evidence base for child abuse and neglect; (4) lack of "gold standard "in assessment and diagnosis of child abuse and neglect; (5) challenges in evaluation of risk prediction performance; (6) challenges in testing predictive models in practice; and (7) challenges in presentation of machine learning-based prediction to clinicians and patients. We provide recommended solutions to each of the 7 ethical challenges and identify several areas for further policy and research. © 2022 The Author(s).},
	author_keywords = {child abuse and neglect; electronic health records; machine learning-based risk models; pediatric emergency departments; phenomenological ethics},
	keywords = {Child; Child Abuse; Electronic Health Records; Humans; Machine Learning; Public Health; United States; adoption; adult; article; child abuse; documentation; electronic health record; emergency ward; ethics; gold standard; human; machine learning; neglect; prediction; predictive model; public health; risk assessment; risk model; United States; child; diagnosis; electronic health record; machine learning},
	correspondence_address = {A.Y. Landau; Data Science Institute, Columbia University, New York, Northwest Corner, 550 W 120th St #1401, 10027, United States; email: al4059@columbia.edu},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	pmid = {35024859},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@CONFERENCE{Kemper2022347,
	author = {Kemper, Bart},
	title = {AI and Stochastic Terrorism - Should it be done?},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Symposium on Software Reliability Engineering Workshops, ISSREW 2022},
	pages = {347 – 356},
	doi = {10.1109/ISSREW55968.2022.00091},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146331688&doi=10.1109%2fISSREW55968.2022.00091&partnerID=40&md5=0598fdf8be4e47c1b098ec07d80681d6},
	affiliations = {Kemper Engineering Services, Baton Rouge, LA, United States},
	abstract = {The use of Artificial Intelligence and Machine Learning technology may seem to be the tools needed to combat media-inspired 'lone wolf attacks' by implementing the concept of 'stochastic terrorism,' targeting harmful media influences. Machine Learning is in current use to sort through social media data to assess hate speech. Artificial Intelligence is in current use to interpret the data and trends processed by Machine Learning for tasks such as finding criminal networks. The question becomes 'can stochastic terrorism be proven' and 'should this be implemented.' Labeling someone as a 'terrorist,' regardless of any modifier for the term, tags the person or group for severe, potentially lethal, response by the government and the community. Criminal accusation cannot ethically be done casually or without sufficient cause. Due to documented problems with bias in all aspects of the issue, using these computational tools to establish legal causation between media statements by pundits, politicians, or others and the violence of 'lone wolf' actors would not meet the requirements of US jurisprudence or the ethical principles for Artificial Intelligence of being explainable, transparent, and responsible. © 2022 IEEE.},
	author_keywords = {artificial intelligence; bias; civil rights; due process; ethics; forensic; machine learning; stochastic terrorism; trust},
	keywords = {Ethical technology; Stochastic systems; Terrorism; 'current; Artificial intelligence learning; Bias; Civil rights; Due process; Forensic; Machine-learning; Stochastic terrorism; Stochastics; Trust; Machine learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166547679-9},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Symp. Softw. Reliab. Eng. Workshops, ISSREW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 33rd IEEE International Symposium on Software Reliability Engineering Workshops, ISSREW 2022; Conference date: 31 October 2022 through 3 November 2022; Conference code: 185583}
}

@ARTICLE{Krening202316853,
	author = {Krening, Samantha},
	title = {Q-learning as a model of utilitarianism in a human–machine team},
	year = {2023},
	journal = {Neural Computing and Applications},
	volume = {35},
	number = {23},
	pages = {16853 – 16864},
	doi = {10.1007/s00521-022-08063-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143206412&doi=10.1007%2fs00521-022-08063-x&partnerID=40&md5=4dd4a7bdfc6455ab75dce3a516728a01},
	affiliations = {Department of Integrated Systems Engineering, The Ohio State University, 1971 Neil Ave, Columbus, 43210, OH, United States},
	abstract = {This paper demonstrates that Q-learning can be used to model Utilitarian decision-making. Accurately modeling ethical theories from the field of moral philosophy is an important step in the development of ethical machine learning. Modeling Utilitarian decision-making with Q-learning is a step toward ethical human–machine teaming; the human and machine contribute according to their strengths to create a more accurate Utilitarian decision than either would make individually. The Utilitarian decision is output by the Q-learning agent, as well as the ranked order of sub-optimal actions to aid in explainability. Additionally, using RL to mathematically represent Utilitarianism solves the classic drawback of Utilitarianism concerning prohibitive computation. This model can also be used for cost-benefit analysis and business decisions. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Ethics; Human–machine teaming; Reinforcement learning; Utilitarianism},
	keywords = {Computation theory; Cost benefit analysis; Ethical technology; Learning systems; Reinforcement learning; Decisions makings; Ethical theories; Human-machine; Human–machine teaming; Machine-learning; Moral philosophy; Q-learning; Q-learning agents; Reinforcement learnings; Utilitarianism; Decision making},
	correspondence_address = {S. Krening; Department of Integrated Systems Engineering, The Ohio State University, Columbus, 1971 Neil Ave, 43210, United States; email: krening.2@osu.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09410643},
	language = {English},
	abbrev_source_title = {Neural Comput. Appl.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Avelar2022370,
	author = {Avelar, Pedro H. C. and Audibert, Rafael Baldasso and Lamb, Luís C.},
	title = {Measuring Ethics in AI with AI: A Methodology and Dataset Construction},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13653 LNAI},
	pages = {370 – 384},
	doi = {10.1007/978-3-031-21686-2_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144823243&doi=10.1007%2f978-3-031-21686-2_26&partnerID=40&md5=436dbf4e50e067a1978524f4a68eb25d},
	affiliations = {UFRGS, Instituto de Informática, RS, Porto Alegre, Brazil},
	abstract = {Recently, sound measures and metrics in Artificial Intelligence have become a focus of research and development in academia, government, and industry. Efforts towards measuring different phenomena have gained traction in the AI community, as illustrated by several influential field reports and policy documents. These metrics are designed to help decision-makers inform themselves about the fast-moving and impacting influences of key advances in Artificial Intelligence in general and Machine Learning in particular. In this paper, we propose to use such newfound capabilities of AI technologies to augment our AI measuring capabilities. We do so by training a model to classify publications related to ethical issues and concerns. Our methodology uses an expert, manually curated dataset as the training set and then evaluates an extensive collection of research papers. Finally, we highlight the implications of AI metrics, particularly their contribution towards developing trustful and fair AI-based tools and technologies. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	keywords = {Decision making; Ethical technology; AI Technologies; Decision makers; Ethical concerns; Ethical issues; Field report; Focus of researches; General learning; Machine-learning; Policy documents; Research and development; Artificial intelligence},
	correspondence_address = {L.C. Lamb; UFRGS, Instituto de Informática, Porto Alegre, RS, Brazil; email: lamb@inf.ufrgs.br},
	editor = {Xavier-Junior J.C. and Rios R.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303121685-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th Brazilian Conference on Intelligent Systems, BRACIS 2022; Conference date: 28 November 2022 through 1 December 2022; Conference code: 287259; All Open Access, Green Open Access}
}

@CONFERENCE{Ahmed2022,
	author = {Ahmed, Mohammed and Iqbal, Rahat and Amin, Saad and Alhabshneh, Obada and Garba, Abubakar},
	title = {Autonomous Vehicle and its Adoption: Challenges, Opportunities, and Future Implications},
	year = {2022},
	journal = {2022 International Conference on Emerging Trends in Computing and Engineering Applications, ETCEA 2022 - Proceedings},
	doi = {10.1109/ETCEA57049.2022.10009804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146960499&doi=10.1109%2fETCEA57049.2022.10009804&partnerID=40&md5=ae0cd46c346be7c79358b794c699e8e2},
	affiliations = {Coventry University, Future Transport and Cities, Coventry, United Kingdom; University of Dubai, College of Engineering and IT, Dubai, United Arab Emirates; Mutah University, Management Information Systems, Mutah, Jordan; Engineering Technical Reliability Methods Limited, Abuja, Nigeria},
	abstract = {The future of mobility and adoption by the public has become a matter of general concern for commuters, drivers, automotive industry and public authorities. Future transport is expected to be dominated by self-driving and autonomous vehicles. Our extensive studies on user adoption indicates that acceptance will be determined mainly by these concerns. In this paper, we investigated user adoption and acceptance of self-driving vehicles. Our study demonstrated that the future adoption of self-driving vehicles will be affected by several inherent concerns such as security, privacy, and trust by the public. Nevertheless, the results of our review revealed that the field of self-driving vehicles will continue to generate interest due to its impact on transport and mobility. Predicting user adoption of self-driving vehicles is a novel research subject which has recently begun to gather momentum; however, predictive accuracy remains a challenge using simple statistical methods. Machine learning modelling techniques can provide better understanding of data and non-linear relationships between decision variables. From our data, we were able to predict self-driving acceptance based on user preference and inherent concerns. We applied supervised learning algorithms namely, Naïve Bayes, Random Forest, and Fuzzy Logic to predict user adoption of self-driving vehicles. We used 6 independent variables namely safety, trust, security, ethics, cost, and privacy. We evaluated each algorithm by using 5-fold cross validation technique. The algorithms were compared based on 3 outcomes: accuracy, precision and recall. Fuzzy logic was found to outperform other algorithms followed by random forest while Naïve Bayes performed lower.  © 2022 IEEE.},
	author_keywords = {autonomous vehicles; fuzzy logic; predictive modelling; user acceptance},
	keywords = {Automotive industry; Autonomous vehicles; Classifiers; Computer circuits; Forecasting; Learning systems; Machine learning; Random forests; Autonomous Vehicles; Fuzzy-Logic; Naive bayes; Predictive models; Public authorities; Random forests; Security/privacy; Self drivings; User adoptions; Users' acceptance; Fuzzy logic},
	correspondence_address = {M. Ahmed; Coventry University, Future Transport and Cities, Coventry, United Kingdom; email: ae0716@coventry.ac.uk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166547709-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Emerg. Trends Comput. Eng. Appl., ETCEA - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 International Conference on Emerging Trends in Computing and Engineering Applications, ETCEA 2022; Conference date: 23 November 2022 through 25 November 2022; Conference code: 186022}
}

@BOOK{Vähäkainu20223,
	author = {Vähäkainu, Petri and Lehto, Martti},
	title = {Use of Artificial Intelligence in a Cybersecurity Environment},
	year = {2022},
	journal = {Artificial Intelligence and Cybersecurity: Theory and Applications},
	pages = {3 – 27},
	doi = {10.1007/978-3-031-15030-2_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160499939&doi=10.1007%2f978-3-031-15030-2_1&partnerID=40&md5=1eada13f9bed90e412f9c910cb617397},
	affiliations = {University of Jyväskylä, Jyväskylä, Finland},
	abstract = {Artificial Intelligence (AI) is the intelligence exhibited by machines. Any system that perceives its environment and takes actions to maximize its chance of succeeding in a goal can be defined as AI. When using digital sensor data, AI-based devices can be used to develop smart advisors, teachers, or assistants. The risks associated with the use of AI technology may be related to operating systems, hardware, algorithms, or system management. Ethics, liability and privacy can also be compromised. Research in this field focuses on the threats and risks of AI and how AI can help solve cybersecurity problems. This study uses the taxonomy classification principle to classify 12 of the most crucial cybersecurity areas. The research method was to gather 10 AI solutions, which were divided into seven different categories of crucial areas of cybersecurity. These AI solutions uses artificial intelligence to detect, predict and block security threats and anomalies. The purpose of the study is to classify the collected AI-based cybersecurity solutions and provide information on what they can offer in solving cybersecurity problems. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {Anomaly; Artificial Intelligence; Cognitive abilities; Cybersecurity; Supervised machine learning; Unsupervised machine learning},
	correspondence_address = {P. Vähäkainu; University of Jyväskylä, Jyväskylä, Finland; email: petri.vahakainu@jyu.fi},
	publisher = {Springer International Publishing},
	isbn = {978-303115030-2; 978-303115029-6},
	language = {English},
	abbrev_source_title = {Artificial Intelligence and Cybersecurity: Theory and Applications},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Brandão2022565,
	author = {Brandão, Rodrigo and Oliveira, Cristina and Peres, Sarajane Marques and da Silva Junior, Leôncio and Papp, Marco and Veiga, João Paulo Cândia and Beçak, Rubens and Camargo, Laura},
	title = {Artificial Intelligence, Algorithmic Transparency and Public Policies: The Case of Facial Recognition Technologies in the Public Transportation System of Large Brazilian Municipalities},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13653 LNAI},
	pages = {565 – 579},
	doi = {10.1007/978-3-031-21686-2_39},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144826182&doi=10.1007%2f978-3-031-21686-2_39&partnerID=40&md5=99c78847b65519cfd35588af1401fbd6},
	affiliations = {Universidade de São Paulo, São Paulo, Brazil; Center for Artificial Intelligence (C4AI-USP), São Paulo, Brazil},
	abstract = {Reports of errors committed in public contexts by facial recognition systems based on machine learning techniques have multiplied. Still, these systems have been increasingly used by the Brazilian public administration. Consequently, the following key problem is established: how can errors committed by facial recognition systems be prevented or mitigated when these systems are used for the elaboration and implementation of public policies? Guided by the understanding that algorithmic transparency is key to preventing and mitigating these errors, we empirically analysed whether, or not, the Brazilian General Data Protection Law (Lei Geral de Proteção de Dados Pessoais – LGPD, in the Portuguese acronym) has been used to promote this kind of transparency in situations in which facial recognition systems are employed. We circumscribed our study to the public transportation sector of 30 large Brazilian municipalities. To gather information, we sent a questionnaire to the municipal public agencies responsible for the public transportation system with questions about how the LGPD works in this public policy area. We used the Access to Information Law to do that. Upon legal analyses, we built an algorithmic transparency scale and found that, in the sector studied, the level of transparency is “Very Low” in most municipalities. This research finding indicates that the risk of lack of control over errors made by facial recognition systems is high. It suggests that the Brazilian public administration does not know how to use the systems in question ethically, and that this lack of knowledge may apply to other Artificial Intelligence systems. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Algorithmic transparency; Ethics; Public policy},
	keywords = {Artificial intelligence; Decision making; Face recognition; Learning systems; Public administration; Transparency; Algorithmic transparency; Algorithmics; Data protection laws; Facial recognition; Facial recognition systems; Machine learning techniques; On-machines; Public transportation; Public transportation systems; Transportation sector; Errors},
	correspondence_address = {R. Brandão; Universidade de São Paulo, São Paulo, Brazil; email: brandao-cs@usp.br},
	editor = {Xavier-Junior J.C. and Rios R.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303121685-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th Brazilian Conference on Intelligent Systems, BRACIS 2022; Conference date: 28 November 2022 through 1 December 2022; Conference code: 287259}
}

@ARTICLE{Hirsbrunner2022,
	author = {Hirsbrunner, Simon David and Tebbe, Michael and Müller-Birn, Claudia},
	title = {From critical technical practice to reflexive data science},
	year = {2022},
	journal = {Convergence},
	doi = {10.1177/13548565221132243},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142601340&doi=10.1177%2f13548565221132243&partnerID=40&md5=ab611d2e5303fd3c6dbed3093ef6b9a6},
	affiliations = {Freie Universität Berlin, Germany},
	abstract = {In this article, we reconsider elements of Agre’s critical technical practice approach (Agre, 1997) for critical technical practice approach for reflexive artificial intelligence (AI) research and explore ways and expansions to make it productive for an operationalization in contemporary data science. Drawing on Jörg Niewöhner’s co-laboration approach, we show how frictions within interdisciplinary work can be made productive for reflection. We then show how software development environments can be repurposed to infrastructure reflexivities and to make co-laborative engagement with AI-related technology possible and productive. We document our own co-laborative engagement with machine learning and highlight three exemplary critical technical practices that emerged out of the co-laboration: negotiating comparabilities, shifting contextual attention and challenging similarity and difference. We finally wrap up the conceptual and empirical elements and propose Reflexive Data Science (RDS) as a methodology for co-laborative engagement and infrastructured reflexivities in contemporary AI-related research. We come back to Agre’s ways of operationalizing reflexivity and introduce the building blocks of RDS: (1) organizing encounters of social contestation, (2) infrastructuring a network of anchoring devices enabling reflection, (3) negotiating timely matters of concern and (4) designing for reflection. With our research, we aim at contributing to the methodological underpinnings of epistemological and social reflection in contemporary AI research. © The Author(s) 2022.},
	author_keywords = {AI ethics; artificial intelligence; critical algorithm studies; critical data studies; data science; digital media research; human-centered computing; human-centered design; human–computer interaction; interdisciplinarity; machine learning; practice research; reflection; science & technology studies},
	correspondence_address = {S.D. Hirsbrunner; Freie Universität Berlin, Germany; email: simon.hirsbrunner@fu-berlin.de},
	publisher = {SAGE Publications Ltd},
	issn = {13548565},
	language = {English},
	abbrev_source_title = {Convergence},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Riola2022237,
	author = {Riola, Non Picart and Madden, Lindsay E. and Silverman, Earl D.},
	title = {Looking Back and Marching Forward: New Features in 2022},
	year = {2022},
	journal = {Journal of Rheumatology},
	volume = {49},
	number = {3},
	pages = {237 – 238},
	doi = {10.3899/jrheum.211412},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125565425&doi=10.3899%2fjrheum.211412&partnerID=40&md5=903a9b200534715123f20e33ef68bc82},
	affiliations = {The Journal of Rheumatology; The Hospital for Sick Children, Department of Paediatrics, University of Toronto, The Journal of Rheumatology, Toronto, ON, Canada},
	keywords = {caregiver; Editorial; ethics; genetics; health care personnel; human; imaging; interpersonal communication; machine learning; medical research; mucocutaneous lymph node syndrome; physician; rheumatic disease; rheumatology; scientific literature; scientist; society; statistics; training; work experience},
	correspondence_address = {E.D. Silverman; The Journal of Rheumatology, Toronto, 365 Bloor Street East, Suite 901, M4W 3L4, Canada; email: esilverman@jrheum.com},
	publisher = {Journal of Rheumatology},
	issn = {0315162X},
	coden = {JRHUA},
	pmid = {35232831},
	language = {English},
	abbrev_source_title = {J. Rheumatol.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Lin2022,
	author = {Lin, Eugenia and Uhler, Lauren M and Finley, Erin P and Jayakumar, Prakash and Rathouz, Paul J and Bozic, Kevin J and Tsevat, Joel},
	title = {Incorporating patient-reported outcomes into shared decision-making in the management of patients with osteoarthritis of the knee: a hybrid effectiveness-implementation study protocol},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {2},
	doi = {10.1136/bmjopen-2021-055933},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125157554&doi=10.1136%2fbmjopen-2021-055933&partnerID=40&md5=2c3a393566f043a0c65a8cdf9c0fd97c},
	affiliations = {Surgery and Perioperative Care, University of Texas, Austin Dell Medical School, Austin, TX, United States; Research Service, South Texas Veterans Health Care System, San Antonio, TX, United States; Center for Research to Advance Community Health, Joe R. and Teresa Lozano Long School of Medicine, University of Texas, Health Science Center at San Antonio, San Antonio, TX, United States; Division of General and Hospital Medicine, Department of Medicine, Joe R. and Teresa Lozano Long School of Medicine, University of Texas, Health Science Center at San Antonio, San Antonio, TX, United States; Population Health, University of Texas, Austin Dell Medical School, Austin, TX, United States},
	abstract = {Introduction Osteoarthritis (OA) is a major clinical and public health concern. The primary surgical treatment of knee OA is total knee replacement (TKR), a procedure that aims to alleviate pain and restore physical function. TKR is expensive, however, and based on professional guidelines, inappropriately performed in up to a third of patients. Patient-reported outcome measures (PROMs) help evaluate treatment options by quantifying health outcomes that matter to patients and can thus inform shared decision-making (SDM) between patients and health professionals. Methods and analysis This is a US-based 2-year, two-site hybrid type 1 study to assess clinical effectiveness and implementation of a machine learning-based patient decision aid (PDA) integrating patient-reported outcomes and clinical variables to support SDM for patients with knee OA considering TKR. Substudy 1: At one study site, a randomised controlled trial is evaluating the clinical effectiveness of the PDA and SDM process on decision quality as measured after the baseline consultation and treatment choice measured 3 and 6 months after the baseline visit among 200 patients with knee OA. Substudy 2: At a second study site, a qualitative assessment using principles of behaviour design and intervention mapping is evaluating the feasibility and acceptability of the PROMs, PDA and SDM process by interviewing seven health professionals and 25 patients before and 25 patients after PDA implementation. Ethics and dissemination Ethics approval has been obtained from The University of Texas at Austin Institutional Review Board (protocol number: 2018-11-0042). Informed consent will be obtained from all participants. Study results will be disseminated through conference presentations, publications and professional societies. Trial registration number NCT04805554.  © Author(s) (or their employer(s)) 2022.},
	author_keywords = {adult orthopaedics; health informatics; knee; orthopaedic & trauma surgery; qualitative research},
	keywords = {Arthroplasty, Replacement, Knee; Decision Making, Shared; Humans; Knee Joint; Osteoarthritis, Knee; Patient Reported Outcome Measures; Randomized Controlled Trials as Topic; adult; aged; Article; clinical effectiveness; controlled study; disease management; female; health practitioner; human; knee osteoarthritis; machine learning; major clinical study; male; middle aged; patient-reported outcome; questionnaire; randomized controlled trial; semi structured interview; shared decision making; total knee arthroplasty; knee; knee osteoarthritis; knee replacement; patient-reported outcome; randomized controlled trial (topic)},
	correspondence_address = {J. Tsevat; Center for Research to Advance Community Health, Joe R. and Teresa Lozano Long School of Medicine, University of Texas, Health Science Center at San Antonio, San Antonio, United States; email: tsevat@uthscsa.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35190439},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Srouji2022162,
	author = {Srouji, Joseph and Bellè, Stefano},
	title = {Artificial intelligence and automated decision making: The new frontier of privacy challenges and opportunities},
	year = {2022},
	journal = {Journal of Data Protection and Privacy},
	volume = {5},
	number = {2},
	pages = {162 – 172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137184224&partnerID=40&md5=ec8d35dd6d7a87289c883a077c4d60bb},
	affiliations = {University of Dayton, Srouji Avocats, 222 Boulevard Saint Germain, Paris, 75007, France; 383 rue de Vaugirard, Paris, 75015, France},
	abstract = {This paper addresses the privacy component of broader artificial intelligence (AI) ethical considerations. We begin with an overview of the regulatory landscape, or lack thereof, and then call out the specific provisions of EU data protection law applicable to AI while focusing on examples of country-specific approaches, including some recent regulatory action. This regulatory action is particularly insightful since it identifies the key challenges that companies face, or will eventually face, when adopting AI-based solutions. These challenges include how to anticipate and prevent bias in automated decision making (ADM) and how to provide transparency to data subjects, despite the complexity of machine learning processes, while protecting business secrets and know-how. © 2022, Henry Stewart Publications. All rights reserved.},
	author_keywords = {AI; artificial intelligence; Artificial Intelligence Act; automated decision making; data privacy; data protection; digital ethics; enforcement; European Union; GDPR; machine learning; regulations},
	publisher = {Henry Stewart Publications},
	issn = {23981679},
	language = {English},
	abbrev_source_title = {J. Data. Prot. Priv.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2022,
	title = {Proceeding - IEEE International Conference on Communication, Networks and Satellite, COMNETSAT 2022},
	year = {2022},
	journal = {Proceeding - IEEE International Conference on Communication, Networks and Satellite, COMNETSAT 2022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146661223&partnerID=40&md5=813b2aa6f8ac2cadb4ec346ef5cc4139},
	abstract = {The proceedings contain 81 papers. The topics discussed include: design and analysis of optical fiber network Jakarta - Singapore - Nusantara via Karimata strait; terahertz antenna-coupled microbolometer: impact of high heater resistance; energy efficient cooperative strategy over LEO satellite Internet of things; reversible data hiding using pixel-value-ordering and difference expansion in digital images; accuracy of machine learning for depression detection in social media; clickbait detection for internet news title with deep learning feed forward; a decision tree knowledge-based system for reviewing research ethics protocol; systematic literature review: comparison on collaborative filtering algorithms for recommendation systems; intrusion detection using support vector machine on Internet of things dataset; flood identification with fuzzy logic based on rainfall and weather for smart city implementation; and performance comparison of machine learning algorithms for student personality classification.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166546030-9},
	language = {English},
	abbrev_source_title = {Proceeding - IEEE Int. Conf. Commun., Networks Satell., COMNETSAT},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th IEEE International Conference on Communication, Networks and Satellite, COMNETSAT 2022; Conference date: 3 November 2022 through 5 November 2022; Conference code: 185811}
}

@ARTICLE{Wilson2022,
	author = {Wilson, Christopher and van der Velden, Maja},
	title = {Sustainable AI: An integrated model to guide public sector decision-making},
	year = {2022},
	journal = {Technology in Society},
	volume = {68},
	doi = {10.1016/j.techsoc.2022.101926},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124430028&doi=10.1016%2fj.techsoc.2022.101926&partnerID=40&md5=9405c8c44bc2d8a172cd9aa7d1520e91},
	affiliations = {University of Oslo, Norway},
	abstract = {Ethics, explainability, responsibility, and accountability are important concepts for questioning the societal impacts of artificial intelligence and machine learning (AI), but are insufficient to guide the public sector in regulating and implementing AI. Recent frameworks for AI governance help to operationalize these by identifying the processes and layers of governance in which they must be considered, but do not provide public sector workers with guidance on how they should be pursued or understood. This analysis explores how the concept of sustainable AI can help to fill this gap. It does so by reviewing how the concept has been used by the research community and aligning research on sustainable development with research on public sector AI. Doing so identifies the utility of boundary conditions that have been asserted for social sustainability according to the Framework for Strategic Sustainable Development, and which are here integrated with prominent concepts from the discourse on AI and society. This results in a conceptual model that integrates five boundary conditions to assist public sector decision-making about how to govern AI: Diversity, Capacity for learning, Capacity for self-organization Common meaning, and Trust. These are presented together with practical approaches for their presentation, and guiding questions to aid public sector workers in making the decisions that are required by other operational frameworks for ethical AI. © 2022},
	author_keywords = {AI governance; Artificial intelligence; Public administration; Social sustainability; Sustainability},
	keywords = {Artificial intelligence; Boundary conditions; Decision making; Ethical technology; Learning systems; Planning; Public administration; AI governance; Conceptual model; Decisions makings; Integrated modeling; Learning capacity; Public sector; Research communities; Social sustainability; Societal impacts; Workers'; artificial intelligence; boundary condition; decision making; ethics; machine learning; public administration; public sector; sustainability; sustainable development; Sustainable development},
	correspondence_address = {C. Wilson; University of Oslo, Norway; email: christbw@uio.no},
	publisher = {Elsevier Ltd},
	issn = {0160791X},
	language = {English},
	abbrev_source_title = {Technol. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Tornari2022236,
	author = {Tornari, Vivi},
	title = {A symmetry concept and significance of fringe patterns as a direct diagnostic tool in artwork conservation},
	year = {2022},
	journal = {Light: Advanced Manufacturing},
	volume = {3},
	number = {2},
	pages = {236 – 257},
	doi = {10.37188/lam.2022.018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152916424&doi=10.37188%2flam.2022.018&partnerID=40&md5=600d9b3bc9566a27afc6f32c80b67f76},
	affiliations = {Institute of Electronic Structure and Laser, Foundation for Research and Technology-Hellas, Nikolaou Plastira 100, Voutes, Crete, Heraklion, Greece},
	abstract = {Previous collaborative studies have shown the main fringe patterns and their typical classification with regard to defects. Nevertheless, the complexity of the results prevents defect detection automation based on a fringe pattern classification table. The use of fringe patterns for the structural diagnosis of artwork is important for conveying crucial detailed information and dense data sources that are unmatched compared to those obtained using other conventional or modern techniques. Hologram interferometry fringe patterns uniquely reveal existing and potential structural conditions independent of object shape, surface complexity, material inhomogeneity, multilayered and mixed media structures, without requiring contact and interaction with the precious surface. Thus, introducing a concept that from one hand allows fringe patterns to be considered as a powerful standalone physical tool for direct structural condition evaluation with a focus on artwork conservators' need for structural diagnosis while sets a conceptual basis for defect detection automation is crucial. The aim intensifies when the particularities of ethics and safety in the field of art conservation are considered. There are ways to obtain the advantages of fringe patterns even when specialized software and advanced analysis algorithms fail to convey usable information. Interactively treating the features of fringe patterns through step-wise reasoning provides direct diagnosis while formulates the knowledge basis to automate defect isolation and identification procedures for machine learning and artificial intelligence (AI) development. The transfer of understanding of the significance of fringe patterns through logical steps to an AI system is this work's ultimate technical aim. Research on topic is ongoing. © The Author(s) 2022.},
	author_keywords = {Artwork; Cultural heritage; Fringe patterns; Heritage science; Holographic interferometry; Holography; Speckle interferometry; Symmetry},
	correspondence_address = {V. Tornari; Institute of Electronic Structure and Laser, Foundation for Research and Technology-Hellas, Heraklion, Nikolaou Plastira 100, Voutes, Crete, Greece; email: vivitor@iesl.forth.gr},
	publisher = {Ji Hua Laboratory},
	issn = {26899620},
	language = {English},
	abbrev_source_title = {Light. Adv. Manuf.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{2022,
	title = {17th IFIP WG 9.4 International Conference on Implications of Information and Digital Technologies for Development, ICT4D 2022},
	year = {2022},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {657 IFIP},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145227983&partnerID=40&md5=62ccfb62cb5253f67f1364726704d235},
	abstract = {The proceedings contain 38 papers. The special focus in this conference is on Implications of Information and Digital Technologies for Development. The topics include: Including the Excluded: Achieving Representation Through Strengthening Health Information Systems in Lao PDR; Where There is No CISO; negotiating Inclusion and Digital Entrepreneurship in a Zambian Innovation Hub: A Post-colonial Perspective; leveraging Blockchain Technology for the Empowerment of Women Micro-entrepreneurs; digitalisation of Indigenous Finance Institutions in Sub-Saharan Africa: A Critical Discourse Analysis; Reimagining Socio-technical ICT4D Interventions: Nexus Between Context, Resilience, and Sustainability; the Use of a User-Centric Smart Mobile Application Prototype for Supporting Safety and Security in a City: A Design Science Method; building Digital Resilience to Combat Pandemics: Comparison of South Korea, Sri Lanka and Rwanda; Digital and Language Inequalities in Disseminating COVID-19-Related Health Campaigns in Uganda: The Effects of Confinement and Social Distancing Strategies; socioetechnical Factors that Shape E-Government Payment Portal Development in Ghana; exploring Notions of Resilience and Adaptability in the Context of Piloting a Mobile App for Risk Awareness During Covid-19; Artificial Intelligence for Quality Education: Successes and Challenges for AI in Meeting SDG4; machine Learning in Sub-Saharan Africa: A Critical Review of Selected Research Publications, 2010–2021; datafication, Dehumanisation and Participatory Development; Towards a Balanced Natural Language Processing: A Systematic Literature Review for the Contact Centre: Balancing the AI Triple Challenge of Opportunity, Ethics, and Opportunity Cost!; Understanding Evolution and Progress Towards Academic Maturity - A Review of Ten Years of ICT4D Research.},
	editor = {Zheng Y. and Abbott P. and Robles-Flores J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303119428-3},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 17th IFIP WG 9.4 International Conference on Implications of Information and Digital Technologies for Development, ICT4D 2022; Conference date: 25 May 2022 through 27 May 2022; Conference code: 287339}
}

@CONFERENCE{Davet202283,
	author = {Davet, Jeremy and Hamidzadeh, Babak and Franks, Patricia and Bunn, Jenny},
	title = {Tracking the Functions of AI as Paradata & Pursuing Archival Accountability},
	year = {2022},
	journal = {Archiving 2022: Expanding Connections Across Digital Cultural Heritage - Final Program and Proceedings},
	pages = {83 – 88},
	doi = {10.2352/issn.2168-3204.2022.19.1.17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141782623&doi=10.2352%2fissn.2168-3204.2022.19.1.17&partnerID=40&md5=5b4d3d55e9926c2227187f9833405df0},
	affiliations = {School of Information, University of British Columbia, Vancouver, Canada; College of Information Studies, University of Maryland, College Park, MD, United States; San Jose State University, San Jose, CA, United States; The National Archives, London, United Kingdom},
	abstract = {While a familiar term in fields like social science research and digital cultural heritage, 'paradata' has not yet been introduced conceptually into the archival realm. In response to an increasing number of experiments with machine learning and artificial intelligence, the InterPARES Trust AI research group proposes the definition of paradata as 'information about the procedure(s) and tools used to create and process information resources, along with information about the persons carrying out those procedures.' The utilization of this concept in archives can help to ensure that AI-driven systems are designed from the outset to honor the archival ethic, and to aid in the evaluation of off-the-shelf automation solutions. An evaluation of current AI experiments in archives highlights opportunities for paradata-conscious practice. © Crown copyright and are re-used under the terms of the Open Government Licence.},
	keywords = {Automation solutions; Digital cultural heritages; Driven system; In-field; Information resource; Machine-learning; Paradata; Process information; Research groups; Social science research; Artificial intelligence},
	publisher = {Society for Imaging Science and Technology},
	isbn = {978-089208358-9},
	language = {English},
	abbrev_source_title = {Arch.: Expand. Connect. Across Digit. Cult. Herit. - Final Program Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Archiving 2022: Expanding Connections Across Digital Cultural Heritage; Conference date: 7 June 2022 through 10 June 2022; Conference code: 183764; All Open Access, Bronze Open Access}
}

@CONFERENCE{Dusi2022164,
	author = {Dusi, Michele and Arici, Nicola and Gerevini, Alfonso E. and Putelli, Luca and Serina, Ivan},
	title = {Graphical Identification of Gender Bias in BERT with a Weakly Supervised Approach},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3287},
	pages = {164 – 176},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143254700&partnerID=40&md5=5fb6324f4007eaaf32c2257def7bf0e7},
	affiliations = {Università degli Studi di Brescia, Brescia, Italy},
	abstract = {Transformer-based algorithms such as BERT are typically trained with large corpora of documents, extracted directly from the Internet. As reported by several studies, these data can contain biases, stereotypes and other properties which are transferred also to the machine learning models, potentially leading them to a discriminatory behaviour which should be identified and corrected. A very intuitive technique for bias identification in NLP models is the visualization of word embeddings. Exploiting the concept of that a short distance between two word vectors means a semantic similarity between these two words; for instance, a closeness between the terms nurse and woman could be an indicator of gender bias in the model. These techniques however were designed for static word embedding algorithms such as Word2Vec. Instead, BERT does not guarantee the same relation between semantic similarity and short distance, making the visualization techniques more difficult to apply. In this work, we propose a weakly supervised approach, which only requires a list of gendered words that can be easily found in online lexical resources, for visualizing the gender bias present in the English base model of BERT. Our approach is based on a Linear Support Vector Classifier and Principal Component Analysis (PCA) and obtains better results with respect to standard PCA. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {BERT; Ethics; Fairness; Gender Bias; Model Interpretability},
	keywords = {Embeddings; Semantics; Visualization; BERT; Bias properties; Fairness; Gender bias; Interpretability; Large corpora; Model interpretability; Other properties; Principal-component analysis; Semantic similarity; Principal component analysis},
	correspondence_address = {M. Dusi; Università degli Studi di Brescia, Brescia, Italy; email: m.dusi007@studenti.unibs.it},
	editor = {Nozza D. and Passaro L.C. and Polignano M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th Workshop on Natural Language for Artificial Intelligence, NL4AI 2022; Conference date: 30 November 2022; Conference code: 184551}
}

@ARTICLE{Ratzki-Leewing2022,
	author = {Ratzki-Leewing, Alexandria and Ryan, Bridget L. and Zou, Guangyong and Webster-Bogaert, Susan and Black, Jason E. and Stirling, Kathryn and Timcevska, Kristina and Khan, Nadia and Buchenberger, John D. and Harris, Stewart B.},
	title = {Predicting Real-world Hypoglycemia Risk in American Adults With Type 1 or 2 Diabetes Mellitus Prescribed Insulin and/or Secretagogues: Protocol for a Prospective, 12-Wave Internet-Based Panel Survey With Email Support (the iNPHORM [Investigating Novel Predictions of Hypoglycemia Occurrence Using Real-world Models] Study)},
	year = {2022},
	journal = {JMIR Research Protocols},
	volume = {11},
	number = {2},
	doi = {10.2196/33726},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124976628&doi=10.2196%2f33726&partnerID=40&md5=6cfc1a86c48077a374da5cc46e375172},
	affiliations = {Department of Epidemiology and Biostatistics, Schulich School of Medicine and Dentistry, Western University, London, ON, Canada; Department of Family Medicine, Schulich School of Medicine and Dentistry, Western University, London, ON, Canada; Robarts Research Institute, Western University, London, ON, Canada; Ipsos Healthcare, New York, NY, United States},
	abstract = {Background: Hypoglycemia prognostic models contingent on prospective, self-reported survey data offer a powerful avenue for determining real-world event susceptibility and interventional targets. Objective: This protocol describes the design and implementation of the 1-year iNPHORM (Investigating Novel Predictions of Hypoglycemia Occurrence Using Real-world Models) study, which aims to measure real-world self-reported severe and nonsevere hypoglycemia incidence (daytime and nocturnal) in American adults with type 1 or 2 diabetes mellitus prescribed insulin and/or secretagogues, and develop and internally validate prognostic models for severe, nonsevere daytime, and nonsevere nocturnal hypoglycemia. As a secondary objective, iNPHORM aims to quantify the effects of different antihyperglycemics on hypoglycemia rates. Methods: iNPHORM is a prospective, 12-wave internet-based panel survey that was conducted across the United States. Americans (aged 18-90 years) with self-reported type 1 or 2 diabetes mellitus prescribed insulin and/or secretagogues were conveniently sampled via the web from a pre-existing, closed, probability-based internet panel (sample frame). A sample size of 521 baseline responders was calculated for this study. Prospective data on hypoglycemia and potential prognostic factors were self-assessed across 14 closed, fully automated questionnaires (screening, baseline, and 12 monthly follow-ups) that were piloted using semistructured interviews (n=3) before fielding; no face-to-face contact was required as part of the data collection. Participant responses will be analyzed using multivariable count regression and machine learning techniques to develop and internally validate prognostic models for 1-year severe and 30-day nonsevere daytime and nocturnal hypoglycemia. The causal effects of different antihyperglycemics on hypoglycemia rates will also be investigated. Results: Recruitment and data collection occurred between February 2020 and March 2021 (ethics approval was obtained on December 17, 2019). A total of 1694 participants completed the baseline questionnaire, of whom 1206 (71.19%) were followed up for 12 months. Most follow-up waves (10,470/14,472, 72.35%) were completed, translating to a participation rate of 179% relative to our target sample size. Over 70.98% (856/1206) completed wave 12. Analyses of sample characteristics, quality metrics, and hypoglycemia incidence and prognostication are currently underway with published results anticipated by fall 2022. Conclusions: iNPHORM is the first hypoglycemia prognostic study in the United States to leverage prospective, longitudinal self-reports. The results will contribute to improved real-world hypoglycemia risk estimation and potentially safer, more effective clinical diabetes management. © Alexandria Ratzki-Leewing, Bridget L Ryan, Guangyong Zou, Susan Webster-Bogaert, Jason E Black, Kathryn Stirling, Kristina Timcevska, Nadia Khan, John D Buchenberger, Stewart B Harris. Originally published in JMIR Research Protocols (https://www.researchprotocols.org), 11.02.2022. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR Research Protocols, is properly cited. The complete bibliographic information, a link to the original publication on https://www.researchprotocols.org, as well as this copyright and license information must be included.},
	author_keywords = {Adverse event; Diabetes; Hypoglycemia; Insulin; Internet survey; Model; Nonsevere hypoglycemia; Protocol; Real-world; Risk; Risk model; Risk prediction; Secretagogue; Severe hypoglycemia; Survey; Symptom; Type 1 diabetes mellitus; Type 2 diabetes mellitus},
	correspondence_address = {A. Ratzki-Leewing; Department of Epidemiology, Biostatistics Schulich School of Medicine, Dentistry Western University, London, 1151 Richmond St, N6A 3K7, Canada; email: alexandria.ratzkileewing@schulich.uwo.ca},
	publisher = {JMIR Publications Inc.},
	issn = {19290748},
	language = {English},
	abbrev_source_title = {JMIR Res. Prot.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Fisler20221049,
	author = {Fisler, Kathi and Friedler, Sorelle and Lin, Kevin and Venkatasubramanian, Suresh},
	title = {Approaches for Weaving Responsible Computing into Data Structures and Algorithms Courses},
	year = {2022},
	journal = {SIGCSE 2022 - Proceedings of the 53rd ACM Technical Symposium on Computer Science Education V.2},
	pages = {1049 – 1050},
	doi = {10.1145/3478432.3499222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127421951&doi=10.1145%2f3478432.3499222&partnerID=40&md5=136402bf299065d5bf4a6900f94d7f5d},
	affiliations = {Brown University, Providence, RI, United States; Haverford College, Haverford, PA, United States; University of Washington, Seattle, WA, United States},
	abstract = {Many efforts are underway to have computing curricula prepare students to anticipate adverse social impacts of computing. Much of the attention currently focuses on introductory CS courses and machine learning courses, often framed around bias that arises around algorithmic decision-making systems. The presenters on this panel have instead focused on ways to weave responsible-computing content into data structures and introductory algorithms courses. They have done so at different levels, ranging from second-semester introductory courses (so-called CS2) up through upper-undergraduate or early graduate courses. Each panelist will describe their perspective on how responsible computing fits into their course and present an illustrative assignment or lecture from their course. The goal of the session is to inspire other CS faculty to work similar content into corresponding courses at their own institutions, while also fostering a community of practice for responsible computing in core CS courses beyond machine learning. © 2022 Owner/Author.},
	author_keywords = {data structures and algorithms courses; ethics; responsible computing},
	keywords = {Curricula; Decision making; Machine learning; Algorithmics; Communities of Practice; Computing curricula; Data structure and algorithm course; Decision-making systems; Graduate course; Introductory course; Responsible computing; Social impact of computing; Data structures},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145039071-2},
	language = {English},
	abbrev_source_title = {SIGCSE - Proc. ACM Tech. Symp. Comput. Sci. Educ. V},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 53rd Annual ACM Technical Symposium on Computer Science Education, SIGCSE 2022; Conference date: 3 March 2022 through 5 March 2022; Conference code: 177383}
}

@BOOK{Montasari20221,
	author = {Montasari, Reza and Carroll, Fiona and Mitchell, Ian and Hara, Sukhvinder and Bolton-King, Rachel},
	title = {Privacy, security and forensics in the internet of things (IoT)},
	year = {2022},
	journal = {Privacy, Security And Forensics in The Internet of Things (IoT)},
	pages = {1 – 210},
	doi = {10.1007/978-3-030-91218-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85153996269&doi=10.1007%2f978-3-030-91218-5&partnerID=40&md5=e385e81ce1a8170e35938815dec6d124},
	affiliations = {Hillary Rodham Clinton School of Law, Swansea University, Swansea, United Kingdom; Cardiff School of Technologies, Cardiff Metropolitan University, Cardiff, United Kingdom; Computer Science, Middlesex University, London, United Kingdom},
	abstract = {This book provides the most recent security, privacy, technical and legal challenges in the IoT environments. This book offers a wide range of theoretical and technical solutions to address these challenges. Topics covered in this book include; IoT, privacy, ethics and security, the use of machine learning algorithms in classifying malicious websites, investigation of cases involving cryptocurrency, the challenges police and law enforcement face in policing cyberspace, the use of the IoT in modern terrorism and violent extremism, the challenges of the IoT in view of industrial control systems, and the impact of social media platforms on radicalisation to terrorism and violent extremism. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2022, corrected publication 2022. All rights reserved.},
	author_keywords = {Artificial intelligence; Cyber forensics; Cyber investigation; Cyber security; Cyber threats; Cybercrime; Digital forensics; Digital investigation; Legal challenges; Machine learning; Privacy; Security; Sensors; Smart homes; Smart nodes; Terrorism; The internet of things; Trust},
	publisher = {Springer International Publishing},
	isbn = {978-303091218-5; 978-303091217-8},
	language = {English},
	abbrev_source_title = {priv., secur. And Forensics in The Internet of Things (IoT)},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Draschner202253,
	author = {Draschner, Carsten Felix and Jabeen, Hajira and Lehmann, Jens},
	title = {Ethical and Sustainability Considerations for Knowledge Graph based Machine Learning},
	year = {2022},
	journal = {Proceedings - 2022 IEEE 5th International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2022},
	pages = {53 – 60},
	doi = {10.1109/AIKE55402.2022.00015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143081239&doi=10.1109%2fAIKE55402.2022.00015&partnerID=40&md5=94c4c7cfa95d4d18d717093cde089981},
	affiliations = {Information Systems and Artificial Intelligence, University of Bonn, Bonn, Germany; Big Data Analytics, Leibniz Gesis Institute, Cologne, Germany; Amazon, University of Bonn, Dresden, Germany},
	abstract = {Artificial Intelligence (AI) and Machine Learning (ML) are becoming common in our daily lives. The AI-driven processes significantly affect us as individuals and as a society, spanning across ethical dimensions like discrimination, misinformation, and fraud. Several of these AI & ML approaches rely on Knowledge Graph (KG) data. Due to the large volume and complexity of today's KG-driven approaches, enormous resources are spent to utilize the complex AI approaches. Efficient usage of the resources like hardware and power consumption is essential for sustainable KG-based ML technologies. This paper introduces the ethical and sustainability considerations, challenges, and optimizations in the context of KG-based ML. We have grouped the ethical and sustainability aspects according to the typical Research & Development (R&D) lifecycle: an initial investigation of the AI approach's responsibility dimensions; technical system setup; central KG data analytics and curating; model selection, training, and evaluation; and final technology deployment. We also describe significant trade-offs and alternative options for dedicated scenarios enriched through existing and reported ethical and sustainability issues in AIdriven approaches and research. These include, e.g., efficient hardware usage guidelines; or the trade-off between transparency and accessibility compared to the risk of manipulability and privacy-related data disclosure. In addition, we propose how biased data and barely explainable AI can result in discriminating ML predictions. This work supports researchers and developers in reflecting, evaluating, and optimizing dedicated KG-based ML approaches in the dimensions of ethics and sustainability.  © 2022 IEEE.},
	author_keywords = {AI Ethics; Explainable AI; Knowledge Graphs; Machine Learning; RDF; Semantic Processing; Sustainable Machine Learning},
	keywords = {Data Analytics; Economic and social effects; Energy efficiency; Ethical technology; Graphic methods; Life cycle; Machine learning; Resource Description Framework (RDF); Semantics; Sustainable development; Artificial intelligence ethic; Ethical considerations; Explainable artificial intelligence; Graph-based; Knowledge graphs; Machine-learning; RDF; Semantic processing; Sustainable machine learning; Knowledge graph},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166547120-6},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Artif. Intell. Knowl. Eng., AIKE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th IEEE International Conference on Artificial Intelligence and Knowledge Engineering, AIKE 2022; Conference date: 19 September 2022 through 21 September 2022; Conference code: 184256}
}

@ARTICLE{Sayibu2022,
	author = {Sayibu, Muhideen and Chu, Jianxun and Tosin Yinka, Akintunde and Rufai, Olayemi Hafeez and Shahani, Riffat and Jin, M.A.},
	title = {COVID-19 smart surveillance: Examination of Knowledge of Apps and mobile thermometer detectors (MTDs) in a high-risk society},
	year = {2022},
	journal = {Digital Health},
	volume = {8},
	doi = {10.1177/20552076221132092},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142377976&doi=10.1177%2f20552076221132092&partnerID=40&md5=1df096d798946ce80aced1400bb2ee6a},
	affiliations = {Department of Philosophy of Sciences and Technology, University of Science and Technology of China, Hefei-Anhui, China; Department of Social Work, Chinese University of Hong Kong, Sha Tin, Hong Kong; Department of medicine, Hefei First People's Hospital, The Third Affiliated Hospital of Anhui Medical University, China},
	abstract = {Background: Technological innovations gained momentum and supported COVID-19 intelligence surveillance among high-risk populations globally. We examined technology surveillance using mobile thermometer detectors (MTDs), knowledge of App, and self-efficacy as a means of sensing body temperature as a measure of COVID-19 risk mitigation. In a cross-sectional survey, we explored COVID-19 risk mitigation, mobile temperature detectable by network syndromic surveillance mobility, detachable from clinicians, and laboratory diagnoses to elucidate the magnitude of community monitoring. Materials and Methods: In a cross-sectional survey, we create in-depth comprehension of risk mitigation, mobile temperature Thermometer detector, and other variables for surveillance and monitoring among 850 university students and healthcare workers. An applied structural equation model was adopted for analysis with Amos v.24. We established that mobile usability knowledge of APP could effectively aid in COVID-19 intelligence risk mitigation. Moreover, both self-efficacy and mobile temperature positively strengthened data visualization for public health decision-making. Results: The algorithms utilize a validated point-of-center test to ascertain the HealthCode scanning system for a positive or negative COVID-19 notification. The MTD is an alternative personal self-testing procedure used to verify temperature rates based on previous SARS-CoV-2 and future mobility digital health. Personal self-care of MTD mobility and knowledge of mHealth apps can specifically manage COVID-19 mitigation in high or low terrestrial areas. We found mobile usability, mobile self-efficacy, and app knowledge were statistically significant to COVID-19 mitigation. Additionally, interaction strengthened the positive relationship between self-efficacy and COVID-19. Data aggregation is entrusted with government database agencies, using natural language processing and machine learning mechanisms to validate and analyze. Conclusion: The study shows that temperature thermometer detectors, mobile usability, and knowledge of App enhanced COVID-19 risk mitigation in a high or low-risk environment. The standardizing dataset is necessary to ensure privacy and security preservation of data ethics. © The Author(s) 2022.},
	author_keywords = {COVID-19 surveillance; knowledge of app; mobile intelligence; mobile thermometer detectors (MTD); risk mitigation},
	correspondence_address = {M. Sayibu; Department of Philosophy of Sciences and Technology, University of Science and Technology of China, Hefei-Anhui, China; email: deen2@mail.ustc.edu.cn; J. Chu; Department of Philosophy of Sciences and Technology, University of Science and Technology of China, Hefei-Anhui, China; email: majin0565@aliyun.com},
	publisher = {SAGE Publications Inc.},
	issn = {20552076},
	language = {English},
	abbrev_source_title = {Digit. Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Lee2022,
	author = {Lee, Benjamin D. and Gitter, Anthony and Greene, Casey S. and Raschka, Sebastian and Maguire, Finlay and Titus, Alexander J. and Kessler, Michael D. and Lee, Alexandra J. and Chevrette, Marc G. and Stewart, Paul Allen and Britto-Borges, Thiago and Cofer, Evan M. and Yu, Kun-Hsing and Carmona, Juan Jose and Fertig, Elana J. and Kalinin, Alexandr A. and Signal, Brandon and Lengerich, Benjamin J. and Triche, Timothy J. and Boca, Simina M.},
	title = {Ten quick tips for deep learning in biology},
	year = {2022},
	journal = {PLoS Computational Biology},
	volume = {18},
	number = {3},
	doi = {10.1371/journal.pcbi.1009803},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127019209&doi=10.1371%2fjournal.pcbi.1009803&partnerID=40&md5=b9855b65ebedcbf0098699571b294c5d},
	affiliations = {In-Q-Tel Labs, Arlington, VA, United States; School of Engineering and Applied Sciences, Harvard University, Cambridge, MA, United States; Department of Genetics, Harvard Medical School, Boston, MA, United States; Department of Biostatistics and Medical Informatics, University of Wisconsin-Madison, Madison, WI, United States; Morgridge Institute for Research, Madison, WI, United States; Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Department of Biochemistry and Molecular Genetics, University of Colorado, School of Medicine, Aurora, CO, United States; Center for Health AI, University of Colorado, School of Medicine, Aurora, CO, United States; Department of Statistics, University of Wisconsin-Madison, Madison, WI, United States; Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada; University of New Hampshire, Manchester, NH, United States; Bioeconomy. XYZ, Manchester, NH, United States; Department of Oncology, Johns Hopkins University, Baltimore, MD, United States; Institute for Genome Sciences, University of Maryland School of Medicine, Baltimore, MD, United States; Genomics and Computational Biology Graduate Program, University of Pennsylvania, Philadelphia, PA, United States; Wisconsin Institute for Discovery and Department of Plant Pathology, University of Wisconsin-Madison, Madison, WI, United States; Department of Biostatistics and Bioinformatics, Moffitt Cancer Center, Tampa, FL, United States; Section of Bioinformatics and Systems Cardiology, Klaus Tschira Institute for Integrative Computational Cardiology, University Hospital Heidelberg, Heidelberg, Germany; Department of Internal Medicine III (Cardiology, Angiology, and Pneumology), University Hospital Heidelberg, Heidelberg, Germany; Lewis-Sigler Institute for Integrative Genomics, Princeton University, Princeton, NJ, United States; Graduate Program in Quantitative and Computational Biology, Princeton University, Princeton, NJ, United States; Department of Biomedical Informatics, Harvard Medical School, Boston, MA, United States; Department of Pathology, Brigham and Women's Hospital, Boston, MA, United States; Philips Healthcare, Cambridge, MA, United States; Department of Biomedical Engineering, Department of Applied Mathematics and Statistics, Convergence Institute, Johns Hopkins University, Baltimore, MD, United States; Medical Big Data Group, Shenzhen Research Institute of Big Data, Shenzhen, China; Department of Computational Medicine and Bioinformatics, University of Michigan, Ann Arbor, MI, United States; School of Medicine, College of Health and Medicine, University of Tasmania, Hobart, Australia; Computer Science Department, Carnegie Mellon University, Pittsburgh, PA, United States; Center for Epigenetics, Van Andel Research Institute, Grand Rapids, MI, United States; Department of Pediatrics, College of Human Medicine, Michigan State University, East Lansing, MI, United States; Department of Translational Genomics, Keck School of Medicine, University of Southern California, Los Angeles, CA, United States; Innovation Center for Biomedical Informatics, Georgetown University Medical Center, DC, United States; Department of Oncology, Georgetown University Medical Center, Washington, DC, United States; Department of Biostatistics, Bioinformatics and Biomathematics, Georgetown University Medical Center, Washington, DC, United States; Cancer Prevention and Control Program, Lombardi Comprehensive Cancer Center, Washington, DC, United States},
	keywords = {Computational Biology; Deep Learning; Article; artificial neural network; Bayesian learning; biology; computer vision; convolutional neural network; data analysis; data privacy; data processing; data quality; deep learning; deep neural network; ethics; human; hyperparameter; information processing; k nearest neighbor; logistic regression analysis; medical research; natural language processing; problem solving; random forest; reinforcement learning (machine learning); reproducibility; research ethics; sample size; statistical parameters; support vector machine; Deep learning},
	correspondence_address = {B.D. Lee; In-Q-Tel Labs, Arlington, United States; email: benjamindlee@me.com},
	publisher = {Public Library of Science},
	issn = {1553734X},
	pmid = {35324884},
	language = {English},
	abbrev_source_title = {PLoS Comput. Biol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Michalowski2022113,
	author = {Michalowski, Martin and Park, Jung In},
	title = {Artificial Intelligence for Nursing and Healthcare: Potentials and Cautions},
	year = {2022},
	journal = {Nursing and Informatics for the 21st Century - Embracing a Digital World, 3rd Edition, Book 3: Innovation, Technology, and Applied Informatics for Nurses},
	pages = {113 – 129},
	doi = {10.4324/9781003281016-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142114942&doi=10.4324%2f9781003281016-7&partnerID=40&md5=df1f191c123037f56fdfc917cd656a5e},
	affiliations = {University of Minnesota, School of Nursing, United States; Sue and Bill Gross School of Nursing, University of California, United States},
	abstract = {Artificial Intelligence (AI) has been transformative for many public and private industries, and we are currently observing an AI-led revolution in healthcare. AI is a fundamental paradigm shift in healthcare that is already affecting nurses in their everyday work, and its impact will be even more pronounced in the future. AI is embedded in nurses’ daily life as algorithms, smart systems and in their education. Even though AI applications in healthcare date back to the late 1970s, technological advances in robotics and computing and the right social climate have created ideal conditions to take full advantage of what AI can contribute to improving the provision of care. Yet, healthcare constitutes a complex system that presents many challenges to AI’s adoption. Ethics, the ability to explain and justify models’ results, education of patients and providers, inherent biases and social equity are some of the non-technical issues that need to be addressed for AI solutions to be safely integrated into care delivery. In this chapter, we introduce four key sub-areas of AI (Robotics, Machine Learning, Mobile Technology and Virtual and Augmented Reality), describe their applications to nursing and discuss cautions that need to be considered in their implementation. © 2022 selection and editorial matter, Connie White Delaney, Charlotte A. Weaver, Joyce Sensmeier, Lisiane Pruinelli & Patrick Weber.},
	publisher = {Taylor and Francis},
	isbn = {978-100057349-7; 978-103224981-0},
	language = {English},
	abbrev_source_title = {Nursing and Informatics for the 21st Century - Embracing a Digital World, 3rd Edition, Book 3: Innovation, Technology, and Applied Informatics for Nurses},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Galati2022,
	author = {Galati, Salvatore and Di Stefano, Miriana and Martinelli, Elisa and Macchia, Marco and Martinelli, Adriano and Poli, Giulio and Tuccinardi, Tiziano},
	title = {VenomPred: A Machine Learning Based Platform for Molecular Toxicity Predictions},
	year = {2022},
	journal = {International Journal of Molecular Sciences},
	volume = {23},
	number = {4},
	doi = {10.3390/ijms23042105},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124494829&doi=10.3390%2fijms23042105&partnerID=40&md5=8bdd694987abb870c2c50146da6f115a},
	affiliations = {Department of Pharmacy, University of Pisa, Pisa, 56126, Italy; Department of Life Sciences, University of Siena, Siena, 53100, Italy; Center for Biotechnology, Sbarro Institute for Cancer Research and Molecular Medicine, College of Science and Technology, Temple University, Philadelphia, 19122, PA, United States},
	abstract = {The use of in silico toxicity prediction methods plays an important role in the selection of lead compounds and in ADMET studies since in vitro and in vivo methods are often limited by ethics, time, budget and other resources. In this context, we present our new web tool VenomPred, a user‐friendly platform for evaluating the potential mutagenic, hepatotoxic, carcinogenic and estrogenic effects of small molecules. VenomPred platform employs several in‐house Machine Learning (ML) models developed with datasets derived from VEGA QSAR, a software that includes a comprehensive collection of different toxicity models and has been used as a reference for building and evaluating our ML models. The results showed that our models achieved equal or better performance than those obtained with the reference models included in VEGA QSAR. In order to improve the predictive performance of our platform, we adopted a consensus approach combining the results of different ML models, which was able to predict chemical toxicity better than the single models. This improved method was thus implemented in the VenomPred platform, a freely accessible webserver that takes the SMILES (Simplified Molecular‐Input Line‐Entry System) strings of the compounds as input and sends the prediction results providing a probability score about their potential toxicity. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Artificial intelligence; Carcinogenicity; Estrogenicity; Hepatoxicity; In silico toxicity; Machine learning; Mutagenicity},
	keywords = {Carcinogens; Computer Simulation; Drug-Related Side Effects and Adverse Reactions; Machine Learning; Mutagenesis; Mutagens; Quantitative Structure-Activity Relationship; Small Molecule Libraries; Software; estrogen receptor; xenobiotic agent; carcinogen; mutagenic agent; algorithm; antitumorigenic activity; Article; artificial intelligence; computer model; estrogen activity; liver toxicity; machine learning; mutagenic activity; nerve cell; nonhuman; pharmacophore; prediction; statistical parameters; toxicity; adverse drug reaction; adverse event; chemistry; computer simulation; drug effect; machine learning; molecular library; mutagenesis; quantitative structure activity relation; software},
	correspondence_address = {G. Poli; Department of Pharmacy, University of Pisa, Pisa, 56126, Italy; email: giulio.poli@unipi.it},
	publisher = {MDPI},
	issn = {16616596},
	pmid = {35216217},
	language = {English},
	abbrev_source_title = {Int. J. Mol. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Rieder202251,
	author = {Rieder, Bernhard and Gordon, Geoff and Sileno, Giovanni},
	title = {Mapping Value(s) in AI: Methodological Directions for Examining Normativity in Complex Technical Systems},
	year = {2022},
	journal = {Sociologica},
	volume = {16},
	number = {3},
	pages = {51 – 83},
	doi = {10.6092/issn.1971-8853/15910},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85161326469&doi=10.6092%2fissn.1971-8853%2f15910&partnerID=40&md5=6a344c5dbc62c2cada5cd6a7e0e7cdce},
	affiliations = {Department of Media Studies, University of Amsterdam, Netherlands; Asser Institute, Netherlands; Informatics Institute, University of Amsterdam, Netherlands},
	abstract = {This paper seeks to develop a multidisciplinary methodological framework and research agenda for studying the broad array of 'ideas', 'norms', or 'values' incorporated and mobilized in systems relying on AI components. We focus on recommender systems as a broader field of technical practice and take YouTube as an example of a concrete artifact that raises many social concerns. To situate the conceptual perspective and rationale informing our approach, we briefly discuss investigations into normativity in technology more broadly and refer to 'descriptive ethics' and 'ethigraphy' as two approaches concerned with the empirical study of values and norms. Drawing on science and technology studies, we argue that normativity cannot be reduced to ethics, but requires paying attention to a wider range of elements, including the performativity of material objects themselves. The method of 'encircling' is presented as a way to deal with both the secrecy surrounding many commercial systems and the socio-technical and distributed character of normativity more broadly. The resulting investigation aims to draw from a series of approaches and methods to construct a much wider picture than what could result from one discipline only. The paper is then dedicated to developing this methodological framework organized into three layers that demarcate specific avenues for conceptual reflection and empirical research, moving from the more general to the more concrete: ambient technical knowledge, local design conditions, and materialized values. We conclude by arguing that deontological approaches to normativity in AI need to take into account the many different ways norms and values are embedded in technical systems. Copyright © 2022 Bernhard Rieder, Geoff Gordon, Giovanni Sileno.},
	author_keywords = {empirical ethics; machine learning; methodology; Normativity; YouTube},
	correspondence_address = {B. Rieder; Department of Media Studies, University of Amsterdam, Netherlands; email: b.rieder@uva.nl},
	publisher = {University of Bologna},
	issn = {19718853},
	language = {English},
	abbrev_source_title = {Sociologica},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Vedmurthy2022,
	author = {Vedmurthy, Pooja and Pinto, Anna L. R. and Lin, Doris D.M. and Comi, Anne M. and Ou, Yangming},
	title = {Study protocol: retrospectively mining multisite clinical data to presymptomatically predict seizure onset for individual patients with Sturge-Weber},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {2},
	doi = {10.1136/bmjopen-2021-053103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124173029&doi=10.1136%2fbmjopen-2021-053103&partnerID=40&md5=69fec3b2898d3d4e939c94236a47a188},
	affiliations = {Department of Neurology and Developmental Medicine, Hugo Moser Research Institute, Baltimore, MD, United States; Department of Neurology and Pediatrics, Kennedy Krieger Institute, Baltimore, MD, United States; Department of Neurology, Division of Epilepsy, Harvard Medical School, Boston, MA, United States; Neuroradiology, Johns Hopkins School of Medicine, Baltimore, MD, United States; Department of Neurology and Pediatrics, Johns Hopkins School of Medicine, Baltimore, MD, United States; Fetal-Neonatal Neuroimaging and Developmental Science Center, Boston Children's Hospital, Boston, MA, United States; Computational Health Informatics Program, Boston Children's Hospital, Boston, MA, United States; Department of Radiology, Boston Children's Hospital, Harvard Medical School, Boston, MA, United States},
	abstract = {IntroductionSecondary analysis of hospital-hosted clinical data can save time and cost compared with prospective clinical trials for neuroimaging biomarker development. We present such a study for Sturge-Weber syndrome (SWS), a rare neurovascular disorder that affects 1 in 20 000–50 000 newborns. Children with SWS are at risk for developing neurocognitive deficit by school age. A critical period for early intervention is before 2 years of age, but early diagnostic and prognostic biomarkers are lacking. We aim to retrospectively mine clinical data for SWS at two national centres to develop presymptomatic biomarkers.Methods and analysisWe will retrospectively collect clinical, MRI and neurocognitive outcome data for patients with SWS who underwent brain MRI before 2 years of age at two national SWS care centres. Expert review of clinical records and MRI quality control will be used to refine the cohort. The merged multisite data will be used to develop algorithms for abnormality detection, lesion-symptom mapping to identify neural substrate and machine learning to predict individual outcomes (presence or absence of seizures) by 2 years of age. Presymptomatic treatment in 0–2 years and before seizure onset may delay or prevent the onset of seizures by 2 years of age, and thereby improve neurocognitive outcomes. The proposed work, if successful, will be one of the largest and most comprehensive multisite databases for the presymptomatic phase of this rare disease.Ethics and disseminationThis study involves human participants and was approved by Boston Children’s Hospital Institutional Review Board: IRB-P00014482 and IRB-P00025916 Johns Hopkins School of Medicine Institutional Review Board: NA_00043846. Participants gave informed consent to participate in the study before taking part. The Institutional Review Boards at Kennedy Krieger Institute and Boston Children’s Hospital approval have been obtained at each site to retrospectively study this data. Results will be disseminated by presentations, publication and sharing of algorithms generated. © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {anti-epilepsy drugs; machine learning; neuroimaging biomarker; pre-symptomatic treatment; sturge-weber syndrome},
	keywords = {Child; Humans; Infant, Newborn; Neuroimaging; Prospective Studies; Retrospective Studies; Seizures; Sturge-Weber Syndrome; biological marker; algorithm; apparent diffusion coefficient; Article; brain mapping; child; clinical study; cognition; cohort analysis; comprehension; controlled study; deep learning; deformable registration algorithm; diagnostic test accuracy study; diffusion tensor imaging; diffusion weighted imaging; electronic health record; feature selection; feature selection algorithm; fluid-attenuated inversion recovery imaging; human; ICD-9; image registration; International Classification of Diseases; machine learning; major clinical study; nuclear magnetic resonance imaging; outcome assessment; preschool child; rare disease; retrospective study; seizure; sensitivity and specificity; Sturge Weber syndrome; susceptibility weighted imaging; voice recognition; white matter; complication; neuroimaging; newborn; prospective study; seizure; Sturge Weber syndrome},
	correspondence_address = {Y. Ou; Fetal-Neonatal Neuroimaging and Developmental Science Center, Boston Children's Hospital, Boston, United States; email: Yangming.Ou@childrens.harvard.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35121603},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Schneider20221,
	author = {Schneider, Patrick and Xhafa, Fatos},
	title = {Anomaly Detection and Complex Event Processing Over IoT Data Streams: With Application to eHealth and Patient Data Monitoring},
	year = {2022},
	journal = {Anomaly Detection and Complex Event Processing Over IoT Data Streams: With Application to eHealth and Patient Data Monitoring},
	pages = {1 – 381},
	doi = {10.1016/B978-0-12-823818-9.00002-X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126073968&doi=10.1016%2fB978-0-12-823818-9.00002-X&partnerID=40&md5=7a7336867639b58dfa4d2f7873ddfe1d},
	affiliations = {Universitat Oberta de Catalunya (UOC), Barcelona, Spain; Universitat Politècnica de Catalunya (UPC), Barcelona, Spain},
	abstract = {Anomaly Detection and Complex Event Processing over IoT Data Streams: With Application to eHealth and Patient Data Monitoring presents advanced processing techniques for IoT data streams and the anomaly detection algorithms over them. The book brings new advances and generalized techniques for processing IoT data streams, semantic data enrichment with contextual information at Edge, Fog and Cloud as well as complex event processing in IoT applications. The book comprises fundamental models, concepts and algorithms, architectures and technological solutions as well as their application to eHealth. Case studies, such as the bio-metric signals stream processing are presented -the massive amount of raw ECG signals from the sensors are processed dynamically across the data pipeline and classified with modern machine learning approaches including the Hierarchical Temporal Memory and Deep Learning algorithms. The book discusses adaptive solutions to IoT stream processing that can be extended to different use cases from different fields of eHealth, to enable a complex analysis of patient data in a historical, predictive and even prescriptive application scenarios. The book ends with a discussion on ethics, emerging research trends, issues and challenges of IoT data stream processing. © 2022 Elsevier Inc. All rights reserved.},
	publisher = {Elsevier},
	isbn = {978-012823819-6; 978-012823818-9},
	language = {English},
	abbrev_source_title = {Anomaly Det. and Complex Event Processing Over IoT Data Streams: With Appl. to eHealth and Patient Data Monit.},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Badaloni2022107,
	author = {Badaloni, Silvana and Rodà, Antonio},
	title = {Gender knowledge and Artificial Intelligence},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3319},
	pages = {107 – 112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146113018&partnerID=40&md5=654a727e9f1c39c3e85a99de2a786431},
	affiliations = {Department of Information Engineering, via Gradenigo, 6, Padova, 35131, Italy; Elena Cornaro Center on Gender Studies, University of Padova, Italy},
	abstract = {Among the various types of biases that can be recognised in the behaviour of algorithms learning from data, gender-related biases assume particular importance in certain contexts, such as the Italian one, traditionally linked to a patriarchal vision of society. This becomes even more true considering the context of university education, where there is a strong under-representation of female students in STEM Faculties, and, particularly, in Computer Science Courses. After a brief review of gender biases reported in Machine Learning-based systems, the experience of the teaching “Gender Knowledge and Ethics in Artificial Intelligence” active since A.Y. 2021-22 at the School of Engineering of the University of Padova is presented. © 2022 Copyright for this paper by its authors.},
	author_keywords = {artificial intelligence; fairness; gender bias; gendered innovation; machine learning},
	keywords = {Engineering education; Algorithm learning; Computer Science course; Fairness; Female students; Gender bias; Gendered innovation; Machine-learning; School of engineering; University education; Machine learning},
	correspondence_address = {A. Rodà; Department of Information Engineering, Padova, via Gradenigo, 6, 35131, Italy; email: antonio.roda@unipd.it},
	editor = {Boella G. and D'Asaro F.A. and Dyoub A. and Primiero G.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st Workshop on Bias, Ethical AI, Explainability and the Role of Logic and Logic Programming, BEWARE 2022; Conference date: 2 December 2022; Conference code: 185911}
}

@BOOK{D’antonoli2022113,
	author = {D’antonoli, Tugba Akinci},
	title = {Ethical and Legal Risks of Artificial Intelligence in Radiology},
	year = {2022},
	journal = {Integrity of Scientific Research: Fraud, Misconduct and Fake News in the Academic, Medical and Social Environment},
	pages = {113 – 122},
	doi = {10.1007/978-3-030-99680-2_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163519054&doi=10.1007%2f978-3-030-99680-2_12&partnerID=40&md5=a4e53414ad0a2c17482dfab584cd6d35},
	affiliations = {Department of Pediatric Radiology, University Children’s Hospital Basel, Basel, Switzerland},
	abstract = {In radiology, artificial intelligence is endowed with many potential practical applications, both at the individual level and considering the profession in general. However ethical and legal conflicts could exist, and attention to the patient rights are paramount in this context. Given the novelty of the field and the not yet fully mapped challenges ahead, it is essential to count with the continuing input of radiologists along with ethicists, as more and more domains are impacted by these valuable and even disruptive advances. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.},
	author_keywords = {Algorithm; Artificial intelligence; Ethics; Machine learning; Radiology},
	correspondence_address = {T.A. D’Antonoli; Department of Pediatric Radiology, University Children’s Hospital Basel, Basel, Switzerland; email: tugba.akincidantonoli@usb.ch},
	publisher = {Springer International Publishing},
	isbn = {978-303099680-2; 978-303099679-6},
	language = {English},
	abbrev_source_title = {Integr. of Scientific Research: Fraud, Misconduct and Fake News in the Academic, Med. and Soc. Environment},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Balcombe2022,
	author = {Balcombe, Luke and De Leo, Diego},
	title = {Human-Computer Interaction in Digital Mental Health},
	year = {2022},
	journal = {Informatics},
	volume = {9},
	number = {1},
	doi = {10.3390/informatics9010014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125225177&doi=10.3390%2finformatics9010014&partnerID=40&md5=4bab5cfc8af3ba55dfc7f087f83d92d7},
	affiliations = {Australian Institute for Suicide Research and Prevention, Department of Applied Psychology, Griffith University, Messines Ridge Road, Mount Gravatt, 4122, QLD, Australia},
	abstract = {Human-computer interaction (HCI) has contributed to the design and development of some efficient, user-friendly, cost-effective, and adaptable digital mental health solutions. But HCI has not been well-combined into technological developments resulting in quality and safety concerns. Digital platforms and artificial intelligence (AI) have a good potential to improve prediction, identification, coordination, and treatment by mental health care and suicide prevention services. AI is driving web-based and smartphone apps; mostly it is used for self-help and guided cognitive behavioral therapy (CBT) for anxiety and depression. Interactive AI may help real-time screening and treatment in outdated, strained or lacking mental healthcare systems. The barriers for using AI in mental healthcare include accessibility, efficacy, reliability, usability, safety, security, ethics, suitable education and training, and socio-cultural adaptability. Apps, real-time machine learning algorithms, immersive technologies, and digital phenotyping are notable prospects. Generally, there is a need for faster and better human factors in combination with machine interaction and automation, higher levels of effectiveness evaluation and the application of blended, hybrid or stepped care in an adjunct approach. HCI modeling may assist in the design and development of usable applications, and to effectively recognize, acknowledge, and address the inequities of mental health care and suicide prevention and assist in the digital therapeutic alliance. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Apps; Artificial intelligence; Digital phenotyping; Digital platforms; Digital therapeutic alliance; Human-centered design; Human-computer interaction; Immersive technologies; Mental health care; Suicide prevention},
	correspondence_address = {L. Balcombe; Australian Institute for Suicide Research and Prevention, Department of Applied Psychology, Griffith University, Mount Gravatt, Messines Ridge Road, 4122, Australia; email: lukebalcombe@gmail.com},
	publisher = {MDPI},
	issn = {22279709},
	language = {English},
	abbrev_source_title = {Informatics},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Halme2022631,
	author = {Halme, Erika},
	title = {Ethical Tools, Methods and Principles in Software Engineering and Development: Case Ethical User Stories},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13709 LNCS},
	pages = {631 – 637},
	doi = {10.1007/978-3-031-21388-5_48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85142721691&doi=10.1007%2f978-3-031-21388-5_48&partnerID=40&md5=67354db06ca31207b2559693484be837},
	affiliations = {University of Jyväskylä, PO Box 35, Jyväskylä, 40014, Finland},
	abstract = {The great leap with the development of Artificial Intelligence (AI) and Machine Learning (ML) technology has increased the range of different requirements for software quality, especially in terms of ethics. To implement high-level requirements, like ethical principles, into the workflow of software engineering, new requirements engineer tools are to be developed. Ethical User Stories (EUS) offers a simple way of implementing ethics in software development. This research has investigated the idea of using familiar requirements engineering artifacts, User Stories, to implement ethical principles, into the workflow of software engineering and operationalizing the studied phenomena of EUS. The preliminary results, found through two ongoing empirical studies with a data collection of 600+ EUS, show that EUS is a pressure-free, human-centric and accessible approach to Ethically Aligned Design (EAD) that intertwines with quality characteristics and relieves the developer from the heavy burden of ethical consideration to a smooth workflow of software engineering. An effective EUS is consistent throughout the user story and shares the idea that user-driven ethical motivation generates system functionality or benefits non-functional software design for quality assurance. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Agile software engineering; AI ethics; User stories},
	keywords = {Artificial intelligence; Computer software selection and evaluation; Ethical technology; Requirements engineering; Software design; Agile software engineering; Artificial intelligence ethic; Artificial intelligence learning; Development case; Ethical principles; Machine learning technology; Simple++; Software Quality; User stories; Work-flows; Quality assurance},
	correspondence_address = {E. Halme; University of Jyväskylä, Jyväskylä, PO Box 35, 40014, Finland; email: erika.a.halme@jyu.fi},
	editor = {Taibi D. and Kuhrmann M. and Mikkonen T. and Abrahamsson P. and Klünder J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303121387-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 23rd International Conference on Product-Focused Software Process Improvement, PROFES 2022; Conference date: 21 November 2022 through 23 November 2022; Conference code: 286329}
}

@ARTICLE{Garett2022,
	author = {Garett, Renee and Young, Sean D.},
	title = {The importance of diverse key stakeholders in deciding the role of artificial intelligence for HIV research and policy},
	year = {2022},
	journal = {Health Policy and Technology},
	volume = {11},
	number = {1},
	doi = {10.1016/j.hlpt.2022.100599},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122822947&doi=10.1016%2fj.hlpt.2022.100599&partnerID=40&md5=61f9291006cb6b13c47ef68d3e83c4e9},
	affiliations = {ElevateU, Irvine, California, United States; Department of Emergency Medicine, University of California, Irvine, California, United States; Department of Informatics, University of California, Irvine, California, United States},
	author_keywords = {Artificial intelligence; Ethics; HIV; Key stakeholders; Research},
	keywords = {Article; artificial intelligence; clinical decision making; clinical outcome; clinical practice; clinical trial (topic); epidemiological data; genetics; health care management; human; Human immunodeficiency virus; identifiable information; information processing; machine learning; medical care; medical ethics; medical research; methodology; patient selection; prevention study; professional standard; program cost effectiveness; public health service; risk reduction; social media; socioeconomics; stakeholder engagement},
	correspondence_address = {S.D. Young; Department of Emergency Medicine, University of California, Irvine, 333 City Boulevard West, Suite 640, Orange, 92868, United States; email: syoung5@hs.uci.edu},
	publisher = {Elsevier B.V.},
	issn = {22118837},
	language = {English},
	abbrev_source_title = {Health Policy Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@ARTICLE{Wan2022,
	author = {Wan, Yik-Ki Jacob and Del Fiol, Guilherme and McFarland, Mary M and Wright, Melanie C},
	title = {User interface approaches implemented with automated patient deterioration surveillance tools: Protocol for a scoping review},
	year = {2022},
	journal = {BMJ Open},
	volume = {12},
	number = {1},
	doi = {10.1136/bmjopen-2021-055525},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123568189&doi=10.1136%2fbmjopen-2021-055525&partnerID=40&md5=1ee44d5f588db5019786b2f80be38f5f},
	affiliations = {Department of Biomedical Informatics, University of Utah, Salt Lake City, UT, United States; Eccles Health Sciences Library, University of Utah, Salt Lake City, UT, United States; College of Pharmacy, Idaho State University, Pocatello, United States},
	abstract = {Introduction Early identification of patients who may suffer from unexpected adverse events (eg, sepsis, sudden cardiac arrest) gives bedside staff valuable lead time to care for these patients appropriately. Consequently, many machine learning algorithms have been developed to predict adverse events. However, little research focuses on how these systems are implemented and how system design impacts clinicians' decisions or patient outcomes. This protocol outlines the steps to review the designs of these tools. Methods and analysis We will use scoping review methods to explore how tools that leverage machine learning algorithms in predicting adverse events are designed to integrate into clinical practice. We will explore the types of user interfaces deployed, what information is displayed, and how clinical workflows are supported. Electronic sources include Medline, Embase, CINAHL Complete, Cochrane Library (including CENTRAL), and IEEE Xplore from 1 January 2009 to present. We will only review primary research articles that report findings from the implementation of patient deterioration surveillance tools for hospital clinicians. The articles must also include a description of the tool's user interface. Since our primary focus is on how the user interacts with automated tools driven by machine learning algorithms, electronic tools that do not extract data from clinical data documentation or recording systems such as an EHR or patient monitor, or otherwise require manual entry, will be excluded. Similarly, tools that do not synthesise information from more than one data variable will also be excluded. This review will be limited to English-language articles. Two reviewers will review the articles and extract the data. Findings from both researchers will be compared with minimise bias. The results will be quantified, synthesised and presented using appropriate formats. Ethics and dissemination Ethics review is not required for this scoping review. Findings will be disseminated through peer-reviewed publications. © Author(s) (or their employer(s)) 2022. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {general medicine (see internal medicine); health informatics; intensive & critical care; internal medicine},
	keywords = {Algorithms; Hospitals; Humans; Peer Review; Research Design; Review Literature as Topic; adult; automation; clinical decision making; clinical practice; clinical protocol; data extraction; deterioration; human; information processing; machine learning; medical documentation; outcome assessment; patient information; patient monitoring; predictive value; Review; workflow; algorithm; hospital; literature; methodology; peer review},
	correspondence_address = {M.C. Wright; College of Pharmacy, Idaho State University, Pocatello, United States; email: melaniewright2@isu.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {35027423},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Barron2022225,
	author = {Barron, Lee},
	title = {Smart cities, connected cars and autonomous vehicles: Design fiction and visions of smarter future urban mobility},
	year = {2022},
	journal = {Technoetic Arts},
	volume = {20},
	number = {3},
	pages = {225 – 240},
	doi = {10.1386/tear_00092_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159460025&doi=10.1386%2ftear_00092_1&partnerID=40&md5=d3191bd425a4eda3081f88d2ce8cc6a5},
	affiliations = {School of Design, Northumbria University, City Campus East 2, Newcastle upon Tyne, NE1 8ST, United Kingdom},
	abstract = {This article takes a speculative and design fiction approach to the critical analysis of the role of smart and autonomous vehicles (AVs) in the context of smart cities. The article explores arguments that these cars of the future will have decisive impacts on mobility, sustainability and road safety. The article examines the main parameters of smart city and smart car developments and then focuses on the visions of increasing AI-driven autonomy. The article demonstrates how these debates are linked to speculative design as full autonomy does not currently exist but takes a speculative position as to what the critical issues are that face smart/ autonomous city visions (enhanced surveillance and data mining) and considers the potentially hazardous ethical dilemmas that AVs may encounter once fully rolled out onto city roads. From a design fiction perspective, the article envisions the viability of AV prioritizing public rather than private transport as a means by which the 'techno-utopic' visions of smart city/AV integration can be realized and make positive impacts to enhance urban living in rendering future cities as more sustainable, efficiently mobile and safer urban spaces.  © 2022 Intellect Ltd Article.},
	author_keywords = {artificial intelligence (AI); automobiles; ethics; Internet of Things (IoT); machine learning; speculative design},
	correspondence_address = {L. Barron; School of Design, Northumbria University, Newcastle upon Tyne, City Campus East 2, NE1 8ST, United Kingdom; email: lee.barron@northumbria.ac.uk},
	publisher = {Intellect Ltd.},
	issn = {1477965X},
	language = {English},
	abbrev_source_title = {Technoetic Arts},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Kuksa202267,
	author = {Kuksa, Iryna and Skinner, Michael and Fisher, Tom and Kent, Tony},
	title = {Delivering personalised, digital experience},
	year = {2022},
	journal = {Understanding Personalisation: New Aspects of Design and Consumption},
	pages = {67 – 87},
	doi = {10.1016/B978-0-08-101987-0.00017-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85143100622&doi=10.1016%2fB978-0-08-101987-0.00017-5&partnerID=40&md5=a5f9d0c242a371a169070c87dd299aab},
	affiliations = {Nottingham School of Art and Design, Nottingham Trent University, United Kingdom},
	abstract = {Artificial intelligence, machine learning, unsupervised algorithms, data surveillance are realities of our current, social media dominated existence. The amount of personal data generated by every media-active individual is staggering, and it comes to define that person's online presence. What is even more overwhelming is users' powerlessness when it comes to navigating and making sense of the various privacy policies attached to every webpage they open for the first time. This brings into question the notion of informed consent when subscribing to a new online service or making a purchase; how ‘informed’ can it be? Despite recently introduced data protection laws in Europe and the United States, users remain vulnerable to online threats including misinformation and misuse of personal data, which can negatively affect their lives. This chapter outlines these current issues and explores public attitudes concerning data management in social networking sites, and the possible links between data harvesting and digital wellbeing. Following evaluation of the current landscape, we offer potential solutions, suggesting social media platforms could encompass person-centred design to resolve the issues identified. © 2023 Elsevier Ltd. All rights reserved.},
	author_keywords = {Artificial intelligence; Design; Digital wellbeing; Ethics; Personal data; Personalisation; Privacy; Social media},
	publisher = {Elsevier},
	isbn = {978-008101987-0; 978-008101988-7},
	language = {English},
	abbrev_source_title = {Underst. Personalisation: New Aspects of Design and Consum.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jones2022238,
	author = {Jones, David T. and Kerber, Kevin A.},
	title = {Artificial Intelligence and the Practice of Neurology in 2035: The Neurology Future Forecasting Series},
	year = {2022},
	journal = {Neurology},
	volume = {98},
	number = {6},
	pages = {238 – 245},
	doi = {10.1212/WNL.0000000000013200},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124316539&doi=10.1212%2fWNL.0000000000013200&partnerID=40&md5=31b89307280b8941a00d47cb9e0cfa1f},
	affiliations = {Department of Neurology and Diagnostic Radiology, Mayo Clinic, Rochester, MN, United States; Department of Neurology, University of Michigan Health System, Ann Arbor, MI, United States; Veterans Affairs Healthcare System, Ann Arbor, MI, United States},
	abstract = {High-quality health care delivery relies on a complex orchestration of the flow of patient data. Incorporating advanced artificial intelligence (AI) technologies into this delivery system has tremendous potential to improve health care, but also carries with it unique challenges. The nature of neurologic disease, and the current state of neurologic care delivery, makes this area of medicine well positioned for AI-driven innovation by 2035. Business, ethics, regulation, and medical education will need to evolve in concert. The information technology and data standards requirements for this potential transformation are underappreciated and will be a major driver of changes across the industry. Using AI on patient data to drive health care innovation to improve patients' lives as the primary goal will facilitate widespread acceptance and adoption of the practices required for a successful AI transformation in neurology. In planning the incorporation of AI into clinical practice, the tenets of rigorous research will need to be vigilantly applied to prevent unwarranted costs and inconveniences while promoting meaningful health outcomes.  © American Academy of Neurology.},
	keywords = {Artificial Intelligence; Delivery of Health Care; Forecasting; Humans; Neurology; Technology; Article; artificial general intelligence; artificial intelligence; clinical practice; commercial phenomena; electronic medical record; Food and Drug Administration; health care; health care delivery; health care quality; human; informatics standard; information technology; intelligence; knowledge; learning algorithm; machine learning; medical education; medical ethics; medical information; neurologic disease; neurology; patient care; patient coding; forecasting; technology},
	correspondence_address = {D.T. Jones; Department of Neurology and Diagnostic Radiology, Mayo Clinic, Rochester, United States; email: jones.david@mayo.edu},
	publisher = {Lippincott Williams and Wilkins},
	issn = {00283878},
	coden = {NEURA},
	pmid = {35131918},
	language = {English},
	abbrev_source_title = {Neurology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Bai2022,
	author = {Bai, Zijun},
	title = {Research on Application of Artificial Intelligence in Communication Network},
	year = {2022},
	journal = {Journal of Physics: Conference Series},
	volume = {2209},
	number = {1},
	doi = {10.1088/1742-6596/2209/1/012014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126376728&doi=10.1088%2f1742-6596%2f2209%2f1%2f012014&partnerID=40&md5=9d098171a4af36e8858627b19bf926ce},
	affiliations = {High School, Northeast Normal University, Changchun, 130000, China},
	abstract = {Artificial intelligence has been widely utilized in people's lives, especially in communication. The article provides a review of the recent research status of the application of artificial intelligence in communication, the usefulness of big data, machine learning, and cloud computation in this field. Several examples of how artificial intelligence is used to communicate are illustrated to discuss better and form a framework of modern artificial intelligence applications. The aspects of concern in ethics of using artificial intelligence are also mentioned, as ethics are the principles judging whether the technologies are suitable for humans to use or not. In order to predict the future development of communication, an introduction of previous progress in the field of communication is provided and sorted into categories of wireless communication, ethical concerns, and network monitor and control. This study confirms that the future development of artificial intelligence is mainly in two aspects: SDN (Software-defined network) and NFV (Network function visualization). AI will thus be used in enhancing communication efficiency.  © Published under licence by IOP Publishing Ltd.},
	keywords = {Ethical technology; Network function virtualization; Communications networks; Ethical concerns; Monitor and control; Network functions; Network monitors; Network-control; Recent researches; Research status; Software-defined networks; Wireless communications; Artificial intelligence},
	correspondence_address = {Z. Bai; High School, Northeast Normal University, Changchun, 130000, China; email: robbbertbai@163.com},
	publisher = {IOP Publishing Ltd},
	issn = {17426588},
	language = {English},
	abbrev_source_title = {J. Phys. Conf. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 International Conference on Electronic Communication, Computer Science and Technology, ECCST 2021; Conference date: 7 January 2022 through 9 January 2022; Conference code: 177426; All Open Access, Bronze Open Access}
}

@ARTICLE{Marsden2022,
	author = {Marsden, Teresa and McCartan, Neil and Brown, Louise and Rodriguez-Justo, Manuel and Syer, Tom and Brembilla, Giorgio and Van Hemelrijck, Mieke and Coolen, Ton and Attard, Gerhardt and Punwani, Shonit and Moore, Caroline M. and Ahmed, Hashim U. and Emberton, Mark},
	title = {The ReIMAGINE prostate cancer risk study protocol: A prospective cohort study in men with a suspicion of prostate cancer who are referred onto an MRI-based diagnostic pathway with donation of tissue, blood and urine for biomarker analyses.},
	year = {2022},
	journal = {PLoS ONE},
	volume = {17},
	number = {2 February},
	doi = {10.1371/journal.pone.0259672},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125306896&doi=10.1371%2fjournal.pone.0259672&partnerID=40&md5=62269849fa65f96adf57d7b2cc15730f},
	affiliations = {UCL Division of Surgical & Interventional Sciences, University College London, London, United Kingdom; Department of Urology, University College London Hospitals NHS Foundation Trust, London, United Kingdom; MRC Clinical Trials Unit, University College London, London, United Kingdom; Research Department of Pathology, University College London, London, United Kingdom; Department of Pathology, University College London Hospitals NHS Foundation Trust, London, United Kingdom; Centre for Medical Imaging, University College London, London, United Kingdom; School of Cancer and Pharmaceutical Sciences, Kings College London, London, United Kingdom; London Institute for Mathematical Sciences, London, United Kingdom; Cancer Institute, University College London, London, United Kingdom; Imperial Prostate, Division of Surgery, Department of Surgery and Cancer, Faculty of Medicine, Imperial College London, London, United Kingdom; Imperial Urology, Imperial College Healthcare NHS Trust, London, United Kingdom},
	abstract = {Introduction The ReIMAGINE Consortium was conceived to develop risk-stratification models that might incorporate the full range of novel prostate cancer (PCa) diagnostics (both commercial and academic). Methods ReIMAGINE Risk is an ethics approved (19/LO/1128) multicentre, prospective, observational cohort study which will recruit 1000 treatment-naive men undergoing a multi-parametric MRI (mpMRI) due to an elevated PSA (≤20ng/ml) or abnormal prostate examination who subsequently had a suspicious mpMRI (score≥3, stage ≤T3bN0M0). Primary outcomes include the detection of ≥Gleason 7 PCa at baseline and time to clinical progression, metastasis and death. Baseline blood, urine, and biopsy cores for fresh prostate tissue samples (2 targeted and 1 non-targeted) will be biobanked for future analysis. High-resolution scanning of pathology whole-slide imaging and MRI-DICOM images will be collected. Consortium partners will be granted access to data and biobanks to develop and validate biomarkers using correlation to mpMRI, biopsy-based disease status and long-term clinical outcomes. Results Recruitment began in September 2019(n = 533). A first site opened in September 2019 (n = 296), a second in November 2019 (n = 210) and a third in December 2020 (n = 27). Acceptance to the study has been 65% and a mean of 36.5ml(SD+/-10.0), 12.9ml(SD+/-3.7) and 2.8ml(SD+/-0.7) urine, plasma and serum donated for research, respectively. There are currently 4 academic and 15 commercial partners spanning imaging (~9 radiomics, artificial intelligence/machine learning), fluidic (~3 blood-based and ~2urine-based) and tissue-based (~1) biomarkers. Conclusion The consortium will develop, or adjust, risk models for PCa, and provide a platform for evaluating the role of novel diagnostics in the era of pre-biopsy MRI and targeted biopsy. Copyright: © 2022 Marsden et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Aged; Artificial Intelligence; Biomarkers, Tumor; Humans; Image-Guided Biopsy; Male; Middle Aged; Multiparametric Magnetic Resonance Imaging; Neoplasm Grading; Prostate; Prostatic Neoplasms; Risk Factors; Ultrasonography, Interventional; biological marker; prostate specific antigen; tumor marker; Article; artificial intelligence; blood sampling; cancer growth; cancer risk; cancer staging; clinical feature; cohort analysis; Gleason score; human; longitudinal study; machine learning; major clinical study; male; metastasis; multiparametric magnetic resonance imaging; nuclear magnetic resonance imaging; observational study; prospective study; prostate cancer; prostate tissue; radiomics; risk factor; urine sampling; aged; artificial intelligence; blood; cancer grading; clinical trial; diagnostic imaging; image guided biopsy; interventional ultrasonography; middle aged; multicenter study; multiparametric magnetic resonance imaging; pathology; prostate; prostate tumor; urine},
	correspondence_address = {T. Marsden; UCL Division of Surgical & Interventional Sciences, University College London, London, United Kingdom; email: teresa.marsden@ucl.ac.uk},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {35202397},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gupta20221,
	author = {Gupta, Mayank and Ramar, Dhanvendran and Vijayan, Rekha and Gupta, Nihit},
	title = {Artificial Intelligence Tools for Suicide Prevention in Adolescents and Young Adults},
	year = {2022},
	journal = {Adolescent Psychiatry},
	volume = {12},
	number = {1},
	pages = {1 – 10},
	doi = {10.2174/2210676612666220408095913},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147403553&doi=10.2174%2f2210676612666220408095913&partnerID=40&md5=ad97bd81b229e8ff83009cf3683a964b},
	affiliations = {Clarion Psychiatric Center, Clarion, 16214, PA, United States; Bellin Health Psychiatric Clinical Services, Medical College of Wisconsin, Green Bay, 54301, WI, United States; University of West Virginia, Reynolds Memorial Hospital, Glendale, 26038, WV, United States},
	abstract = {Background: Artificial Intelligence is making a significant transformation in human lives. Its application in the medical and healthcare field has also been observed to make an impact and improve overall outcomes. There has been a quest for similar processes in mental health due to the lack of observable changes in the areas of suicide prevention. In the last five years, there has been an emerging body of empirical research applying the technology of artificial intelligence (AI) and machine learning (ML) in mental health. Objective: To review the clinical applicability of the AI/ML-based tools in suicide prevention. Methods: The compelling question of predicting suicidality has been the focus of this research. We performed a broad literature search and then identified 36 articles relevant to meet the objectives of this review. We review the available evidence and provide a brief overview of the advances in this field. Conclusion: In the last five years, there has been more evidence supporting the implementation of these algorithms in clinical practice. Its current clinical utility is limited to using electronic health records and could be highly effective in conjunction with existing tools for suicide prevention. Other potential sources of relevant data include smart devices and social network sites. There are some serious questions about data privacy and ethics which need more attention while developing these new modalities in suicide research. © 2022 Bentham Science Publishers.},
	author_keywords = {adolescents and young adults; artificial intelligence; electronic health records; Machine learning; suicide prevention; suicide risk assessment},
	keywords = {adolescent; adult; artificial intelligence; electronic health record; human; machine learning; medical ethics; mental health; natural language processing; predictive model; Review; social media; suicide; young adult},
	correspondence_address = {M. Gupta; Clarion Psychiatric Center, Clarion, 16214, United States; email: mayank6nov@gmail.com},
	publisher = {Bentham Science Publishers},
	issn = {22106766},
	language = {English},
	abbrev_source_title = {Adolesc. Psychiatry},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Luk2022137,
	author = {Luk, Jeremy W. and Pruitt, Larry D. and Smolenski, Derek J. and Tucker, Jennifer and Workman, Don E. and Belsher, Bradley E.},
	title = {From everyday life predictions to suicide prevention: Clinical and ethical considerations in suicide predictive analytic tools},
	year = {2022},
	journal = {Journal of Clinical Psychology},
	volume = {78},
	number = {2},
	pages = {137 – 148},
	doi = {10.1002/jclp.23202},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108887226&doi=10.1002%2fjclp.23202&partnerID=40&md5=c44d130036ede9aa78750c193e3ef2cf},
	affiliations = {Psychological Health Center of Excellence, Defense Health Agency, Silver Spring, MD, United States; Department of Psychiatry and Behavioral Sciences, VA Puget Sound Healthcare System & University of Washington School of Medicine, Seattle, WA, United States},
	abstract = {Advances in artificial intelligence and machine learning have fueled growing interest in the application of predictive analytics to identify high-risk suicidal patients. Such application will require the aggregation of large-scale, sensitive patient data to help inform complex and potentially stigmatizing health care decisions. This paper provides a description of how suicide prediction is uniquely difficult by comparing it to nonmedical (weather and traffic forecasting) and medical predictions (cancer and human immunodeficiency virus risk), followed by clinical and ethical challenges presented within a risk-benefit conceptual framework. Because the misidentification of suicide risk may be associated with unintended negative consequences, clinicians and policymakers need to carefully weigh the risks and benefits of using suicide predictive analytics across health care populations. Practical recommendations are provided to strengthen the protection of patient rights and enhance the clinical utility of suicide predictive analytics tools. © 2021 Wiley Periodicals LLC},
	author_keywords = {artificial intelligence; big data; ethics; informed consent; machine learning; suicide},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Machine Learning; Risk Assessment; Suicide; artificial intelligence; health care delivery; human; machine learning; risk assessment; suicide},
	correspondence_address = {B.E. Belsher; Psychological Health Center of Excellence, Defense Health Agency, Silver Spring, United States; email: bradley.belsher@va.gov},
	publisher = {John Wiley and Sons Inc},
	issn = {00219762},
	coden = {JCPYA},
	pmid = {34195998},
	language = {English},
	abbrev_source_title = {J. Clin. Psychol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Birch2022229,
	author = {Birch, Jonathan and Creel, Kathleen A. and Jha, Abhinav K. and Plutynski, Anya},
	title = {Clinical decisions using AI must consider patient values},
	year = {2022},
	journal = {Nature Medicine},
	volume = {28},
	number = {2},
	pages = {229 – 232},
	doi = {10.1038/s41591-021-01624-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123941137&doi=10.1038%2fs41591-021-01624-y&partnerID=40&md5=f5ea37be2175c7e860e3e34df037f4d1},
	affiliations = {Centre for Philosophy of Natural and Social Science, London School of Economics and Political Science, London, United Kingdom; McCoy Family Center for Ethics in Society and the Institute for Human-Centered Artificial Intelligence, Stanford University, Stanford, CA, United States; Department of Biomedical Engineering and Mallinckrodt Institute of Radiology, Washington University in St. Louis, St. Louis, MO, United States; Department of Philosophy and Division of Biology and Biomedical Sciences, Washington University in St Louis, St Louis, MO, United States},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; artificial intelligence; breast cancer; cancer screening; clinical decision making; diagnostic imaging; ethical decision making; ethics; health risk assessment; human; machine learning; Note; patient attitude; patient care; probability; risk attitude; health care delivery},
	correspondence_address = {J. Birch; Centre for Philosophy of Natural and Social Science, London School of Economics and Political Science, London, United Kingdom; email: j.birch2@lse.ac.uk},
	publisher = {Nature Research},
	issn = {10788956},
	coden = {NAMEF},
	pmid = {35102337},
	language = {English},
	abbrev_source_title = {Nat. Med.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@ARTICLE{Abubaker Bagabir2022289,
	author = {Abubaker Bagabir, Sali and Ibrahim, Nahla Khamis and Abubaker Bagabir, Hala and Hashem Ateeq, Raghdah},
	title = {Covid-19 and Artificial Intelligence: Genome sequencing, drug development and vaccine discovery},
	year = {2022},
	journal = {Journal of Infection and Public Health},
	volume = {15},
	number = {2},
	pages = {289 – 296},
	doi = {10.1016/j.jiph.2022.01.011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123347359&doi=10.1016%2fj.jiph.2022.01.011&partnerID=40&md5=959a0401c032a279452183cb9ff2b56f},
	affiliations = {Medical Laboratory Technology Department, Faculty of Applied Medical Sciences, Jazan University, Jazan, Saudi Arabia; Community Medicine Department, Faculty of Medicine, King Abdulaziz University, Jeddah, Saudi Arabia; Epidemiology Department, High Institute of Public Health, Alexandria University, Alexandria, Egypt; Medical Physiology Department, Faculty of Medicine, King Abdulaziz University, Rabigh, Saudi Arabia; Faculty of Medicine, King Abdulaziz University, Jeddah, Saudi Arabia},
	abstract = {Objectives: To clarify the work done by using AI for identifying the genomic sequences, development of drugs and vaccines for COVID-19 and to recognize the advantages and challenges of using such technology. Methods: A non-systematic review was done. All articles published on Pub-Med, Medline, Google, and Google Scholar on AI or digital health regarding genomic sequencing, drug development, and vaccines of COVID-19 were scrutinized and summarized. Results: The sequence of SARS- CoV-2 was identified with the help of AI. It can help also in the prompt identification of variants of concern (VOC) as delta strains and Omicron. Furthermore, there are many drugs applied with the help of AI. These drugs included Atazanavir, Remdesivir, Efavirenz, Ritonavir, and Dolutegravir, PARP1 inhibitors (Olaparib and CVL218 which is Mefuparib hydrochloride), Abacavir, Roflumilast, Almitrine, and Mesylate. Many vaccines were developed utilizing the new technology of bioinformatics, databases, immune-informatics, machine learning, and reverse vaccinology to the whole SARS-CoV-2 proteomes or the structural proteins. Examples of these vaccines are the messenger RNA and viral vector vaccines. AI provides cost-saving and agility. However, the challenges of its usage are the difficulty of collecting data, the internal and external validation, ethical consideration, therapeutic effect, and the time needed for clinical trials after drug approval. Moreover, there is a common problem in the deep learning (DL) model which is the shortage of interpretability. Conclusion: The growth of AI techniques in health care opened a broad gate for discovering the genomic sequences of the COVID-19 virus and the VOC. AI helps also in the development of vaccines and drugs (including drug repurposing) to obtain potential preventive and therapeutic agents for controlling the COVID-19 pandemic. © 2022 The Author(s)},
	author_keywords = {Artificial Intelligence; Challenges; COVID-19; Drugs; Genome sequencing; Vaccines},
	keywords = {Artificial Intelligence; COVID-19; COVID-19 Vaccines; Drug Development; Humans; Pandemics; SARS-CoV-2; Viral Vaccines; abacavir; almitrine; atazanavir; dolutegravir; efavirenz; mefuparib hydrochloride; mesylic acid; nicotinamide adenine dinucleotide adenosine diphosphate ribosyltransferase inhibitor; olaparib; remdesivir; ritonavir; roflumilast; SARS-CoV-2 vaccine; unclassified drug; vector vaccine; virus vaccine; artificial intelligence; bioinformatics; clinical trial (topic); coronavirus disease 2019; cost control; deep learning; drug approval; drug development; external validity; human; information processing; internal validity; research ethics; Review; sequence analysis; Severe acute respiratory syndrome coronavirus 2; therapy effect; vaccine development; vaccinology; variant of concern; artificial intelligence; drug development; pandemic},
	correspondence_address = {N.K. Ibrahim; Community Medicine Department, KAU, Jeddah, Saudi Arabia; email: nibrahim@kau.edu.sa},
	publisher = {Elsevier Ltd},
	issn = {18760341},
	pmid = {35078755},
	language = {English},
	abbrev_source_title = {J. Infect. Public Health},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Farmer2022,
	author = {Farmer, Nicole and Osei Baah, Foster and Williams, Faustine and Ortiz-Chapparo, Erika and Mitchell, Valerie M and Jackson, Latifa and Collins, Billy and Graham, Lennox and Wallen, Gwenyth R and Powell-Wiley, Tiffany M and Johnson, Allan},
	title = {Use of a community advisory board to build equitable algorithms for participation in clinical trials: A protocol paper for HoPeNET},
	year = {2022},
	journal = {BMJ Health and Care Informatics},
	volume = {29},
	number = {1},
	doi = {10.1136/bmjhci-2021-100453},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125020712&doi=10.1136%2fbmjhci-2021-100453&partnerID=40&md5=f84ff73c6542edadf481d48508af4c84},
	affiliations = {Translational Biobehavioral and Health Disparities Branch, Nih Clinical Center, Bethesda, MD, United States; Social Determinants of Obesity and Cardiovascular Risk Laboratory, Cardiovascular Branch, Division of Intramural Research, Nhlbi, Bethesda, MD, United States; Intramural Research Program, Nimhd, Bethesda, MD, United States; Department of Pediatrics, Howard University, Washington, DC, United States; Department of Health Sciences and Management, College of Nursing and Allied Health Sciences, Howard Unversity, Washington, DC, United States; Department of Nurtritional Sciences, College of Nursing and Allied Health Sciences, Howard University, Washington, DC, United States},
	abstract = {Introduction Participation from racial and ethnic minorities in clinical trials has been burdened by issues surrounding mistrust and access to healthcare. There is emerging use of machine learning (ML) in clinical trial recruitment and evaluation. However, for individuals from groups who are recipients of societal biases, utilisation of ML can lead to the creation and use of biased algorithms. To minimise bias, the design of equitable ML tools that advance health equity could be guided by community engagement processes. The Howard University Partnership with the National Institutes of Health for Equitable Clinical Trial Participation for Racial/Ethnic Communities Underrepresented in Research (HoPeNET) seeks to create an ML-based infrastructure from community advisory board (CAB) experiences to enhance participation of African-Americans/Blacks in clinical trials. Methods and analysis This triphased cross-sectional study (24 months, n=56) will create a CAB of community members and research investigators. The three phases of the study include: (1) identification of perceived barriers/facilitators to clinical trial engagement through qualitative/quantitative methods and systems-based model building participation; (2) operation of CAB meetings and (3) development of a predictive ML tool and outcome evaluation. Identified predictors from the participant-derived systems-based map will be used for the ML tool development. Ethics and dissemination We anticipate minimum risk for participants. Institutional review board approval and informed consent has been obtained and patient confidentiality ensured.  © Authors 2022},
	author_keywords = {artificial intelligence; BMJ health informatics; health equity},
	keywords = {Algorithms; Confidentiality; Cross-Sectional Studies; Humans; Informed Consent; African American; algorithm bias; Article; cardiovascular disease; clinical trial; correlation analysis; cross-sectional study; decision tree; ethnicity; health equity; health survey; human; implicit bias; information processing; machine learning; major clinical study; medical informatics; natural language processing; obesity; participatory research; path analysis; patient participation; priority journal; qualitative research; quantitative study; regression model; social determinants of health; study design; algorithm; confidentiality; informed consent},
	correspondence_address = {T.M. Powell-Wiley; Social Determinants of Obesity and Cardiovascular Risk Laboratory, Cardiovascular Branch, Division of Intramural Research, Nhlbi, Bethesda, United States; email: tiffany.powell-wiley@nih.gov; A. Johnson; Department of Nurtritional Sciences, College of Nursing and Allied Health Sciences, Howard University, Washington, United States; email: ajohnson@howard.edu},
	publisher = {BMJ Publishing Group},
	issn = {26321009},
	pmid = {35185011},
	language = {English},
	abbrev_source_title = {BMJ Heal. care inf.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Barnes2022154,
	author = {Barnes, Robert},
	title = {The Social Ethics of Autonomous Vehicle Routing and Navigation: Spatial Recognition Technologies, Environment Mapping Algorithms, and Mobility Simulation Tools},
	year = {2022},
	journal = {Contemporary Readings in Law and Social Justice},
	volume = {14},
	number = {2},
	pages = {154 – 171},
	doi = {10.22381/CRLSJ14220229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145890843&doi=10.22381%2fCRLSJ14220229&partnerID=40&md5=0a274a44a0ef2d57f4413175dc00caff},
	affiliations = {Deep Learning-based Sensing Technologies Laboratory at ISBDA, Leicester, United Kingdom},
	abstract = {The objective of this paper is to systematically review connected vehicle data, spatial recognition technologies, and machine learning and computer vision algorithms. The findings and analyses highlight that autonomous mobility technologies leverage vehicle and pedestrian detection tools, road environment data, and environment mapping and predictive control algorithms. Throughout May 2022, a quantitative literature review of the Web of Science, Scopus, and ProQuest databases was performed, with search terms including “social ethics” + “autonomous vehicle routing and navigation” + “spatial recognition technologies,” “environment mapping algorithms,” and “mobility simulation tools.” As research published in 2022 was inspected, only 188 articles satisfied the eligibility criteria. By taking out controversial or ambiguous findings (insufficient/irrelevant data), outcomes unsubstantiated by replication, too general material, or studies with nearly identical titles, I selected 35 mainly empirical sources. Data visualization tools: Dimensions (biblio-metric mapping) and VOSviewer (layout algorithms). Reporting quality assessment tool: PRISMA. Methodological quality assessment tools include: AMSTAR, Dedoose, Distiller SR, and SRDR. © 2022, Addleton Academic Publishers. All rights reserved.},
	author_keywords = {autonomous vehicle; environment mapping algorithm; mobility simulation tool; navigation; routing; spatial recognition technology},
	correspondence_address = {R. Barnes; Deep Learning-based Sensing Technologies Laboratory at ISBDA, Leicester, United Kingdom; email: robert.barnes@aa-er.org},
	publisher = {Addleton Academic Publishers},
	issn = {19489137},
	language = {English},
	abbrev_source_title = {Contemp. Read. Law Soc. Justice},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Furiasse2022,
	author = {Furiasse, Amanda},
	title = {The Banality of Big Data: A Review of Discriminating Data},
	year = {2022},
	journal = {Digital Humanities Quarterly},
	volume = {16},
	number = {4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85162842058&partnerID=40&md5=c875722959e3d9695172726280517260},
	affiliations = {Nova Southeastern University, United States},
	abstract = {This review critically interrogates Wendy Chun’s book Discriminating Data: Correlation, Neighborhoods, and the New Politics of Recognition (MIT Press, 2021) from the perspective of the digital medical or health humanities. The monograph’s exploration of predictive machine learning and big data’s propensity to encode segregation through their default assumptions about correlation raises important questions about machine learning’s growing uses in fields, such as medicine and pharmacology, where the stakes of such digital experimentation are particularly high. Chun’s exploration of the predictive processes by which data analytics replicates 20th-century eugenics discourses makes an important contribution to the field of digital medical ethics and also offers unique insight into the mechanisms by which digital humanities scholars can disrupt and challenge the use and application of such predictive programs. © 2022, Alliance of Digital Humanities Organisations. All rights reserved.},
	correspondence_address = {A. Furiasse; Nova Southeastern University, United States; email: afuriasse@gmail.com},
	publisher = {Alliance of Digital Humanities Organisations},
	issn = {19384122},
	language = {English},
	abbrev_source_title = {Digit. Humanit. Q.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ursin2022143,
	author = {Ursin, Frank and Timmermann, Cristian and Steger, Florian},
	title = {Explicability of artificial intelligence in radiology: Is a fifth bioethical principle conceptually necessary?},
	year = {2022},
	journal = {Bioethics},
	volume = {36},
	number = {2},
	pages = {143 – 153},
	doi = {10.1111/bioe.12918},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109905232&doi=10.1111%2fbioe.12918&partnerID=40&md5=8d66031cebd5740c750df290322bf197},
	affiliations = {Institute of the History, Philosophy and Ethics of Medicine, Ulm University, Ulm, Germany},
	abstract = {Recent years have witnessed intensive efforts to specify which requirements ethical artificial intelligence (AI) must meet. General guidelines for ethical AI consider a varying number of principles important. A frequent novel element in these guidelines, that we have bundled together under the term explicability, aims to reduce the black-box character of machine learning algorithms. The centrality of this element invites reflection on the conceptual relation between explicability and the four bioethical principles. This is important because the application of general ethical frameworks to clinical decision-making entails conceptual questions: Is explicability a free-standing principle? Is it already covered by the well-established four bioethical principles? Or is it an independent value that needs to be recognized as such in medical practice? We discuss these questions in a conceptual-ethical analysis, which builds upon the findings of an empirical document analysis. On the example of the medical specialty of radiology, we analyze the position of radiological associations on the ethical use of medical AI. We address three questions: Are there references to explicability or a similar concept? What are the reasons for such inclusion? Which ethical concepts are referred to?. © 2021 The Authors. Bioethics published by John Wiley & Sons Ltd.},
	keywords = {Artificial Intelligence; Ethical Analysis; Humans; Morals; Radiology; article; artificial intelligence; clinical decision making; machine learning; medical ethics; medical practice; radiology; ethics; human; morality},
	correspondence_address = {F. Ursin; Institute of the History, Philosophy and Ethics of Medicine, Ulm University, Ulm, Germany; email: frank.ursin@uni-ulm.de},
	publisher = {John Wiley and Sons Inc},
	issn = {02699702},
	coden = {BIETE},
	pmid = {34251687},
	language = {English},
	abbrev_source_title = {Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@CONFERENCE{Washington20222846,
	author = {Washington, Anne L. and Rhue, Lauren A. and Nakamura, Lisa and Stevens, Robin},
	title = {Uncoupling Inequality: Reflections on the Ethics of Benchmarks for Digital Media},
	year = {2022},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2022-January},
	pages = {2846 – 2854},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152227570&partnerID=40&md5=1d7723e5d0601d7cce59da7e3a61370e},
	affiliations = {New York University, United States; Robert H. Smith School of Business, University of Maryland, United States; American Culture Department, University of Michigan, United States; Annenberg School for Communication & Journalism, University of Southern California, United States},
	abstract = {Our collaboration seeks to demonstrate shared interrogation by exploring the ethics of machine learning benchmarks from a socio-technical management perspective with insight from public health and ethnic studies. Benchmarks, such as ImageNet, are annotated open data sets for training algorithms. The COVID-19 pandemic reinforced the practical need for ethical information infrastructures to analyze digital and social media, especially related to medicine and race. Social media analysis that obscures Black teen mental health and ignores anti-Asian hate fails as information infrastructure. Despite inadequately handling non-dominant voices, machine learning benchmarks are the basis for analysis in operational systems. Turning to the management literature, we interrogate cross-cutting problems of benchmarks through the lens of coupling, or mutual interdependence between people, technologies, and environments. Uncoupling inequality from machine learning benchmarks may require conceptualizing the social dependencies that build structural barriers to inclusion. © 2022 IEEE Computer Society. All rights reserved.},
	keywords = {Machine learning; Open Data; Philosophical aspects; Social networking (online); Data set; Information infrastructures; Machine-learning; Open datum; Social media; Social media analysis; Sociotechnical; Technical management; Training algorithms; Uncouplings; Digital storage},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813315-7},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 55th Annual Hawaii International Conference on System Sciences, HICSS 2022; Conference date: 3 January 2022 through 7 January 2022; Conference code: 187534}
}

@ARTICLE{Aler Tubella2022,
	author = {Aler Tubella, Andrea and Barsotti, Flavia and Koçer, Rüya Gökhan and Mendez, Julian Alfredo},
	title = {Ethical implications of fairness interventions: what might be hidden behind engineering choices?},
	year = {2022},
	journal = {Ethics and Information Technology},
	volume = {24},
	number = {1},
	doi = {10.1007/s10676-022-09636-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125646943&doi=10.1007%2fs10676-022-09636-z&partnerID=40&md5=f93f05e1438471b3d090b73604fec9d5},
	affiliations = {Department of Computing Science, Umeå University, Umeå, Sweden; Strategy Office, ING Analytics, ING Bank, Amsterdam, Netherlands; Institute for Advanced Study (IAS), University of Amsterdam, Amsterdam, Netherlands},
	abstract = {The importance of fairness in machine learning models is widely acknowledged, and ongoing academic debate revolves around how to determine the appropriate fairness definition, and how to tackle the trade-off between fairness and model performance. In this paper we argue that besides these concerns, there can be ethical implications behind seemingly purely technical choices in fairness interventions in a typical model development pipeline. As an example we show that the technical choice between in-processing and post-processing is not necessarily value-free and may have serious implications in terms of who will be affected by the specific fairness intervention. The paper reveals how assessing the technical choices in terms of their ethical consequences can contribute to the design of fair models and to the related societal discussions. © 2022, The Author(s).},
	author_keywords = {AI Ethics; Bias mitigation; Fairness; Responsible AI},
	keywords = {Ethical technology; AI ethic; Bias mitigation; Ethical implications; Fairness; Fairness performance; Machine learning models; Modeling performance; Responsible AI; Trade off; Typical model; Economic and social effects},
	correspondence_address = {A. Aler Tubella; Department of Computing Science, Umeå University, Umeå, Sweden; email: andrea.aler@umu.se},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Blumenkranz2022e9,
	author = {Blumenkranz, Mark S. and Tarver, Michelle E. and Myung, David and Eydelman, Malvina B. and Abràmoff, Michael D. and Chew, Emily and Chiang, Michael F. and Lee, Aaron and Repka, Michael and Schuman, Joel S. and Shields, Carol},
	title = {The Collaborative Community on Ophthalmic Imaging: Accelerating Global Innovation and Clinical Utility},
	year = {2022},
	journal = {Ophthalmology},
	volume = {129},
	number = {2},
	pages = {e9 – e13},
	doi = {10.1016/j.ophtha.2021.10.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118978112&doi=10.1016%2fj.ophtha.2021.10.001&partnerID=40&md5=2d6bc2fdab451cdb8f5d7770ba3069a3},
	affiliations = {Palo Alto, California, United States; Silver Springs, MD, United States},
	keywords = {Biomedical Research; Community Health Services; Diagnostic Imaging; Diagnostic Techniques, Ophthalmological; Eye Diseases; Humans; Intersectoral Collaboration; Program Evaluation; artificial intelligence; coding; Editorial; ethics; eye care; Food and Drug Administration; human; imaging algorithm; information security; machine learning; medical society; ophthalmology; organizational structure; patient care; patient engagement; practice guideline; public health; public-private partnership; reimbursement; scientific literature; stakeholder engagement; telehealth; total quality management; web conferencing; community care; diagnostic imaging; eye disease; intersectoral collaboration; medical research; organization and management; program evaluation; visual system examination},
	correspondence_address = {M.B. Eydelman; Food and Drug Administration, Center for Devices and Radiological Health, Office of Product Evaluation and Quality, Office of Health Technology 1 | Ophthalmic, Anesthesia, Respiratory, ENT, & Dental Devices, Silver Spring, 20993, United States; email: malvina.eydelman@fda.hhs.gov},
	publisher = {Elsevier Inc.},
	issn = {01616420},
	coden = {OPHTD},
	pmid = {34774340},
	language = {English},
	abbrev_source_title = {Ophthalmology},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@BOOK{Hussain20221,
	author = {Hussain, Chaudhery Mustansar and Di Sia, Paolo},
	title = {Handbook of Smart Materials, Technologies, and Devices: Applications of Industry 4.0: Volume 1-3},
	year = {2022},
	journal = {Handbook of Smart Materials, Technologies, and Devices: Applications of Industry 4.0: Volume 1-3},
	volume = {1-3},
	pages = {1 – 2863},
	doi = {10.1007/978-3-030-84205-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156237019&doi=10.1007%2f978-3-030-84205-5&partnerID=40&md5=e12eb3fa6b659378f53ecfe2beb6c632},
	affiliations = {Department of Chemistry and Environmental Science, New Jersey Institute of Technology, Newark, NJ, United States; School of Science, University of Padova, Padova, Italy; School of Medicine, Department of Neurosciences, University of Padova, Padova, Italy},
	abstract = {This handbook brings together technical expertise, conceptual background, applications, and societal aspects of Industry 4.0: the evolution of automation and data exchange in fabrication technologies, materials processing, and device manufacturing at both experimental and theoretical model scales. The book assembles all the aspects of Industry 4.0, starting from the emergence of the concept to the consequences of its progression. Drawing on expert contributors from around the world, the volume details the technologies that sparked the fourth revolution and illustrates their characteristics, potential, and methods of use in the industrial and societal domains. In addition, important topics such as ethics, privacy and security are considered in a reality where all data is shared and saved remotely. The collection of contribution serve a very broad audience working in the fields of science and engineering, chemical engineering, materials science, nanotechnology, energy, environment, green chemistry, sustainability, electrical and electronic engineering, solid-state physics, surface science, aerosol technology, chemistry, colloid science, device engineering, and computer technology. This handbook ideal reference libraries in universities and industrial institutions, government and independent institutes, individual research groups and scientists. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.},
	author_keywords = {3D and 4D printing; Additive Manufacturing; Advanced Human-Machine Interface; Authentication and fraud detection; Cyber Physical System; IInternet of Services (IoS) architecture; Internet of Energy (IoE) structure; Internet of Things (IoT) Platform; Location detection technologies; Machine Learning; Mobile devices; Nanomaterial; Robotics; Smart sensors; Virtual and Augmented Reality; Wearable Devices},
	publisher = {Springer International Publishing},
	isbn = {978-303084205-5; 978-303084204-8},
	language = {English},
	abbrev_source_title = {Handb. of Smart Mater., Technologies, and Devices: Applications of Industry 4.0: Volume 1-3},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@BOOK{Gaur20221,
	author = {Gaur, Loveleen and Sahoo, Biswa Mohan},
	title = {Explainable Artificial Intelligence for Intelligent Transportation Systems: Ethics and Applications},
	year = {2022},
	journal = {Explainable Artificial Intelligence for Intelligent Transportation Systems: Ethics and Applications},
	pages = {1 – 90},
	doi = {10.1007/978-3-031-09644-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144611200&doi=10.1007%2f978-3-031-09644-0&partnerID=40&md5=e7e3333f5a575ff869b0dd46cb745f7c},
	affiliations = {Amity International Business School, Amity University, Noida, India; School of Computing and IT, Manipal University Jaipur, Jaipur, India},
	abstract = {Transportation typically entails crucial “life-death” choices, delegating crucial decisions to an AI algorithm without any explanation poses a serious threat. Hence, explainability and responsible AI is crucial in the context of intelligent transportation. In Intelligence Transportation System (ITS) implementations such as traffic management systems and autonomous driving applications, AI-based control mechanisms are gaining prominence. Explainable artificial intelligence for intelligent transportation system tackling certain challenges in the field of autonomous vehicle, traffic management system, data integration and analytics and monitor the surrounding environment. The book discusses and inform researchers on explainable Intelligent Transportation system. It also discusses prospective methods and techniques for enabling the interpretability of transportation systems. The book further focuses on ethical considerations apart from technical considerations. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.},
	author_keywords = {AI; Automatic Vehicle Location; Autonomous Vehicle; Ethics in transportation; Explainable Artificial Intelligence; Intelligent Transportation System; Machine Learning; Machine Learning; Shapley Additive Explanation; Transportation System; XAI},
	publisher = {Springer International Publishing},
	isbn = {978-303109644-0; 978-303109643-3},
	language = {English},
	abbrev_source_title = {Explainable Artificial Intelligence for Intell. Transportation Systems: Ethics and Applications},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Landers202236,
	author = {Landers, Richard N. and Behrend, Tara S.},
	title = {Auditing the AI Auditors: A Framework for Evaluating Fairness and Bias in High Stakes AI Predictive Models},
	year = {2022},
	journal = {American Psychologist},
	volume = {78},
	number = {1},
	pages = {36 – 49},
	doi = {10.1037/amp0000972},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125509681&doi=10.1037%2famp0000972&partnerID=40&md5=65e7d29a0d43371af2e2bad2b51f13ad},
	affiliations = {Department of Psychology, University of Minnesota, Twin Cities, United States; Department of Psychological Sciences, Purdue University, United States},
	abstract = {Researchers, governments, ethics watchdogs, and the public are increasingly voicing concerns about unfairness and bias in artificial intelligence (AI)-based decision tools. Psychology’s more-than-a-century of research on the measurement of psychological traits and the prediction of human behavior can benefit such conversations, yet psychological researchers often find themselves excluded due to mismatches in terminology, values, and goals across disciplines. In the present paper, we begin to build a shared interdisciplinary understanding of AI fairness and bias by first presenting three major lenses, which vary in focus and prototypicality by discipline, from which to consider relevant issues: (a) individual attitudes, (b) legality, ethicality, and morality, and (c) embedded meanings within technical domains. Using these lenses, we next present psychological audits as a standardized approach for evaluating the fairness and bias of AI systems that make predictions about humans across disciplinary perspectives. We present 12 crucial components to audits across three categories: (a) components related to AI models in terms of their source data, design, development, features, processes, and outputs, (b) components related to how information about models and their applications are presented, discussed, and understood from the perspectives of those employing the algorithm, those affected by decisions made using its predictions, and third-party observers, and (c) meta-components that must be considered across all other auditing components, including cultural context, respect for persons, and the integrity of individual research designs used to support all model developer claims © 2022 American Psychological Association},
	author_keywords = {Artificial intelligence; Audit; Bias; Machine learning; Psychology},
	keywords = {Artificial Intelligence; Humans; artificial intelligence; human},
	correspondence_address = {R.N. Landers; Department of Psychology, University of Minnesota, Twin Cities, United States; email: rlanders@umn.edu},
	publisher = {American Psychological Association},
	issn = {0003066X},
	coden = {AMPSA},
	pmid = {35157476},
	language = {English},
	abbrev_source_title = {Am. Psychol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Friedrich2022,
	author = {Friedrich, Annie B. and Mason, Jordan and Malone, Jay R.},
	title = {Rethinking explainability: toward a postphenomenology of black-box artificial intelligence in medicine},
	year = {2022},
	journal = {Ethics and Information Technology},
	volume = {24},
	number = {1},
	doi = {10.1007/s10676-022-09631-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124040843&doi=10.1007%2fs10676-022-09631-4&partnerID=40&md5=332747b6f3d55ba0df698c6a18367bbd},
	affiliations = {Bioethics Research Center, Washington University in St. Louis, St. Louis, MO, United States; Albert Gnaegi Center for Health Care Ethics, Saint Louis University, St. Louis, MO, United States; Department of Pediatrics and Critical Care Medicine, Washington University in St. Louis, St. Louis, MO, United States},
	abstract = {In recent years, increasingly advanced artificial intelligence (AI), and in particular machine learning, has shown great promise as a tool in various healthcare contexts. Yet as machine learning in medicine has become more useful and more widely adopted, concerns have arisen about the “black-box” nature of some of these AI models, or the inability to understand—and explain—the inner workings of the technology. Some critics argue that AI algorithms must be explainable to be responsibly used in the clinical encounter, while supporters of AI dismiss the importance of explainability and instead highlight the many benefits the application of this technology could have for medicine. However, this dichotomy fails to consider the particular ways in which machine learning technologies mediate relations in the clinical encounter, and in doing so, makes explainability more of a problem than it actually is. We argue that postphenomenology is a highly useful theoretical lens through which to examine black-box AI, because it helps us better understand the particular mediating effects this type of technology brings to clinical encounters and moves beyond the explainability stalemate. Using a postphenomenological approach, we argue that explainability is more of a concern for physicians than it is for patients, and that a lack of explainability does not introduce a novel concern to the physician–patient encounter. Explainability is just one feature of technological mediation and need not be the central concern on which the use of black-box AI hinges. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Artificial intelligence; Black-box; Ethics; Machine learning; Postphenomenology; Technological mediation},
	keywords = {Ethical technology; Artificial intelligence algorithms; Artificial intelligence in medicine; Black boxes; Intelligence models; Machine learning technology; Mediating effect; Postphenomenology; Technological mediations; Type of technology; Machine learning},
	correspondence_address = {A.B. Friedrich; Bioethics Research Center, Washington University in St. Louis, St. Louis, United States; email: annie.friedrich@wustl.edu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Kaasinen2022,
	author = {Kaasinen, Eija and Anttila, Anu-Hanna and Heikkilä, Päivi and Laarni, Jari and Koskinen, Hanna and Väätänen, Antti},
	title = {Smooth and Resilient Human–Machine Teamwork as an Industry 5.0 Design Challenge},
	year = {2022},
	journal = {Sustainability (Switzerland)},
	volume = {14},
	number = {5},
	doi = {10.3390/su14052773},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125756151&doi=10.3390%2fsu14052773&partnerID=40&md5=238b169aae4de0eb57e210f2e8abea3c},
	affiliations = {VTT Technical Research Centre of Finland, Tampere, 33101, Finland; Finnish Industrial Union, Helsinki, 00531, Finland},
	abstract = {Smart machine companions such as artificial intelligence (AI) assistants and collaborative robots are rapidly populating the factory floor. Future factory floor workers will work in teams that include both human co-workers and smart machine actors. The visions of Industry 5.0 describe sustainable, resilient, and human-centered future factories that will require smart and resilient capabilities both from next-generation manufacturing systems and human operators. What kinds of approaches can help design these kinds of resilient human–machine teams and collaborations within them? In this paper, we analyze this design challenge, and we propose basing the design on the joint cognitive systems approach. The established joint cognitive systems approach can be complemented with approaches that support human centricity in the early phases of design, as well as in the development of continuously co-evolving human–machine teams. We propose approaches to observing and analyzing the collaboration in human–machine teams, developing the concept of operations with relevant stakeholders, and including ethical aspects in the design and development. We base our work on the joint cognitive systems approach and propose complementary approaches and methods, namely: actor–network theory, the concept of operations and ethically aware design. We identify their possibilities and challenges in designing and developing smooth human–machine teams for Industry 5.0 manufacturing systems. © 2022 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Actor–network theory; Concept of operations; Ethics; Human–machine teams; Industry 5.0; Joint cognitive systems},
	keywords = {artificial intelligence; industrial technology; machine learning; manufacturing; robotics},
	correspondence_address = {E. Kaasinen; VTT Technical Research Centre of Finland, Tampere, 33101, Finland; email: eija.kaasinen@vtt.fi},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access}
}

@CONFERENCE{Ardeshir202210348,
	author = {Ardeshir, Shervin and Segalin, Cristina and Kallus, Nathan},
	title = {Estimating Structural Disparities for Face Models},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {10348 – 10357},
	doi = {10.1109/CVPR52688.2022.01011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85141747735&doi=10.1109%2fCVPR52688.2022.01011&partnerID=40&md5=eedd8261196a72ad80b6b99fd5086f70},
	affiliations = {Netflix, Los Gatos, CA, United States; Cornell University and Netflix, New York, NY, United States},
	abstract = {In machine learning, disparity metrics are often defined by measuring the difference in the performance or outcome of a model, across different sub-populations (groups) of datapoints. Thus, the inputs to disparity quantification consist of a model's predictions y, the ground-truth labels for the predictions y, and group labels g for the data points. Performance of the model for each group is calculated by comparing y and y for the datapoints within a specific group, and as a result, disparity of performance across the different groups can be calculated. In many real world scenarios however, group labels (g) may not be available at scale during training and validation time, or collecting them might not be feasible or desirable as they could often be sensitive information. As a result, evaluating disparity metrics across categorical groups would not be feasible. On the other hand, in many scenarios noisy groupings may be obtainable using some form of a proxy, which would allow measuring disparity metrics across sub-populations. Here we explore performing such analysis on computer vision models trained on human faces, and on tasks such as face attribute prediction and affect estimation. Our experiments indicate that embeddings resulting from an off-the-shelf face recognition model, could meaningfully serve as a proxy for such estimation. © 2022 IEEE.},
	author_keywords = {accountability; Face and gestures; fairness; privacy and ethics in vision; Transparency},
	keywords = {Computer vision; Face recognition; Accountability; Datapoints; Face and gesture; Face models; Fairness; Machine-learning; Model prediction; Performance; Privacy and ethic in vision; Sub-populations; Forecasting},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Xia2022112,
	author = {Xia, Ming and Xu, Tianyi and Jiang, Hong},
	title = {Progress and Perspective of Artificial Intelligence and Machine Learning of Prediction in Anesthesiology},
	year = {2022},
	journal = {Journal of Shanghai Jiaotong University (Science)},
	volume = {27},
	number = {1},
	pages = {112 – 120},
	doi = {10.1007/s12204-021-2331-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111693227&doi=10.1007%2fs12204-021-2331-3&partnerID=40&md5=ea8d75266abbb62a9fc78563cc185d4d},
	affiliations = {Department of Anesthesiology, Shanghai Ninth People’s Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, 200011, China},
	abstract = {Artificial intelligence (AI) has long been an attractive topic in medicine, especially in light of the rapid developments in digital and information technologies. AI has already provided some breakthroughs in medicine. With the assistance of AI, more precise models have been used for clinical predictions, diagnoses, and decision-making. This review defines the basic concepts of AI and machine learning (ML), and provides a simple introduction to certain frequently used algorithms in AI and ML. In addition, the review discusses the current common applications of AI and ML in the prediction of anesthesia conditions, including those for preoperative predictions of difficult airways, intraoperative predictions of adverse events and anesthetic effects, and postoperative predictions of vomiting and pain. The use of AI in anesthesiology remains in development, even without extensive promotion and clinical application; moreover, it has immense potential to maintain further development in the future. Finally, the limitations and challenges of AI development for anesthesia are also discussed, along with considerations regarding ethics and safety. © 2021, Shanghai Jiao Tong University and Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {A; anesthesiology; artificial intelligence (AI); machine learning (ML); prediction models; R 4; TP 181},
	keywords = {Anesthesiology; Decision making; Diagnosis; Forecasting; Predictive analytics; Adverse events; Applications of AI; Basic concepts; Clinical application; Intra-operative; Precise models; Machine learning},
	correspondence_address = {H. Jiang; Department of Anesthesiology, Shanghai Ninth People’s Hospital, Shanghai Jiao Tong University School of Medicine, Shanghai, 200011, China; email: jianghongjiuyuan@126.com},
	publisher = {Shanghai Jiaotong University},
	issn = {10071172},
	language = {English},
	abbrev_source_title = {J. Shanghai Jiaotong Univ. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Binza2022397,
	author = {Binza, Lungile and Budree, Adheesh},
	title = {Towards a Balanced Natural Language Processing: A Systematic Literature Review for the Contact Centre: Balancing the AI Triple Challenge of Opportunity, Ethics, and Opportunity Cost!},
	year = {2022},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {657 IFIP},
	pages = {397 – 420},
	doi = {10.1007/978-3-031-19429-0_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145221117&doi=10.1007%2f978-3-031-19429-0_24&partnerID=40&md5=eff65e9b22b074cdbf01eaffa61bdf21},
	affiliations = {Department of Information Systems, University of Cape Town, Cape Town, South Africa},
	abstract = {Artificial Intelligence (AI), which is the design, development, and utilisation of iterative and complex algorithmic systems that complete tasks which normally required human intelligence, is rapidly gaining momentum throughout the world. Through Machine Learning these AI systems automatically learn and adapt themselves so that they can offer an even more accurate outcome than humans and this offers many exciting benefits to most businesses and economies. But their introduction has raised ethical questions after some unethical conduct on their part like racism, biasness against women, unemployment (through intelligent automation), and inequality. After these incidents of unethical behaviour by some AI technologies around the globe most public, private, and even non-profit organisations embarked on initiatives to address the unethical conduct of AI systems. They produced a range of ethical AI frameworks, guidelines, and principles, but a properly balanced AI, where opportunity, ethics, and opportunity costs intersect, is still to be achieved or realised. Most AI Practitioners are pressured by their shareholders to prioritise commercial interests over ethical considerations. The findings from this Systematic Literature Review study, which used meta-analyses for qualitative synthesis, demonstrate that a Balanced Natural Language Processing (NLP) is possible. © 2022, IFIP International Federation for Information Processing.},
	author_keywords = {Artificial Intelligence; Balanced AI; Ethical AI; Machine Learning; Natural Language Processing; Systematic literature review},
	keywords = {Balancing; Ethical technology; Iterative methods; Learning algorithms; Natural language processing systems; Artificial intelligence systems; Balanced artificial intelligence; Ethical artificial intelligence; Language processing; Machine-learning; Natural language processing; Natural languages; Opportunity costs; Systematic literature review; Unethical conduct; Machine learning},
	correspondence_address = {L. Binza; Department of Information Systems, University of Cape Town, Cape Town, South Africa; email: bnzlun003@myuct.ac.za},
	editor = {Zheng Y. and Abbott P. and Robles-Flores J.A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303119428-3},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 17th IFIP WG 9.4 International Conference on Implications of Information and Digital Technologies for Development, ICT4D 2022; Conference date: 25 May 2022 through 27 May 2022; Conference code: 287339}
}

@ARTICLE{Liu2022,
	author = {Liu, Yibo and Li, Chengcheng and Jiang, Du and Chen, Baojia and Sun, Nannan and Cao, Yongcheng and Tao, Bo and Li, Gongfa},
	title = {Wrist angle prediction under different loads based on GA-ELM neural network and surface electromyography},
	year = {2022},
	journal = {Concurrency and Computation: Practice and Experience},
	volume = {34},
	number = {3},
	doi = {10.1002/cpe.6574},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114031558&doi=10.1002%2fcpe.6574&partnerID=40&md5=5a199beca3e8c04d0fe464060598a726},
	affiliations = {Key Laboratory of Metallurgical Equipment and Control Technology of Ministry of Education, Wuhan University of Science and Technology, Wuhan, China; Research Center for Biomimetic Robot and Intelligent Measurement and Control, Wuhan University of Science and Technology, Wuhan, China; Hubei Key Laboratory of Mechanical Transmission and Manufacturing Engineering, Wuhan University of Science and Technology, Wuhan, China; Hubei Key Laboratory of Hydroelectric Machinery Design and Maintenance, Three Gorges University, Yichang, China; Technology research and development, Huaxia Xingguang Industrial Design Jiangsu Co, Ltd, Suqian, China; Technology research and development, Hubei Jingmen Wusan Machinery Equipment Manufacturing Co, Ltd, Jingshan, China},
	abstract = {In sEMG (surface electromyography) pattern recognition, most of the research focuses on the static pattern recognition of different limbs, ignoring the importance of changing load intensity, and joint angle movement information. Traditional static qualitative pattern recognition cannot adjust the motion amplitude and load intensity, so it is of great significance to study the continuous prediction of wrist angle under different load intensities. Based on the correlation between the surface EMG signal and the joint angle signal, the article is based on the neural network to identify and predict the wrist angle under different loads continuously quantitatively. The sEMG signal in this article was collected with the approval and review of the Ethics Committee and the people's informed consent. Since qualitative pattern recognition cannot adjust the wrist movement range and the different load training intensity, the article establishes an angle prediction model based on a genetic algorithm to optimize the extreme learning machine (ELM). In addition, the article analyzes the influence of different loads on the continuous prediction accuracy of the wrist angle, realizes the continuous quantitative angle of the precise wrist prediction. Experimental analysis shows that the wrist joint angle predicted by the ELM optimized based on genetic algorithm is close to the actual angle, and the average error is about 5.96 degrees. © 2021 John Wiley & Sons, Ltd.},
	keywords = {Forecasting; Genetic algorithms; Joints (anatomy); Machine learning; Neural networks; Pattern recognition; Predictive analytics; Ethics committee; Experimental analysis; Extreme learning machine; Motion amplitudes; Prediction accuracy; Prediction model; Surface electromyography; Wrist joint angles; Biomedical signal processing},
	correspondence_address = {D. Jiang; Key Laboratory of Metallurgical Equipment and Control Technology of Ministry of Education, Wuhan University of Science and Technology, Wuhan, China; email: jiangdu@wust.edu.cn; G. Li; Key Laboratory of Metallurgical Equipment and Control Technology of Ministry of Education, Wuhan University of Science and Technology, Wuhan, China; email: ligongfa@wust.edu.cn},
	publisher = {John Wiley and Sons Ltd},
	issn = {15320626},
	coden = {CCPEB},
	language = {English},
	abbrev_source_title = {Concurr. Comput. Pract. Exper.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27}
}

@ARTICLE{Okolo2022,
	author = {Okolo, Chinasa T.},
	title = {Optimizing human-centered AI for healthcare in the Global South},
	year = {2022},
	journal = {Patterns},
	volume = {3},
	number = {2},
	doi = {10.1016/j.patter.2021.100421},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124290007&doi=10.1016%2fj.patter.2021.100421&partnerID=40&md5=fda6bc5d90f8a42fec8145bbe47191f9},
	affiliations = {Department of Computer Science, Cornell University, Ithaca, 14853, NY, United States},
	abstract = {Over the past 60 years, artificial intelligence (AI) has made significant progress, but most of its benefits have failed to make a significant impact within the Global South. Current practices that have led to biased systems will prevent AI from being actualized unless significant efforts are made to change them. As technical advances in AI and an interest in solving new problems lead researchers and tech companies to develop AI applications that target the health of marginalized communities, it is crucially important to study how AI can be used to empower those on the front lines in the Global South and how these tools can be optimally designed for marginalized communities. This perspective examines the landscape of AI for healthcare in the Global South and the evaluations of such systems and provides tangible recommendations for AI practitioners and human-centered researchers to incorporate in the development of AI systems for use with marginalized populations. © 2021 The Author(s)},
	author_keywords = {artificial intelligence; community health workers; DSML 1: Concept: Basic principles of a new data science output observed and reported; ethics; global health; human-centered AI; machine learning; ML; participatory design; technical evaluations},
	keywords = {Machine learning; Basic principles; Community Health Workers; Current practices; DSML 1: concept: basic principle of a new data science output observed and reported; Global health; Human-centered artificial intelligence; ML; Participatory design; Technical advances; Technical evaluation; Health care},
	correspondence_address = {C.T. Okolo; Department of Computer Science, Cornell University, Ithaca, 14853, United States; email: chinasa@cs.cornell.edu},
	publisher = {Cell Press},
	issn = {26663899},
	language = {English},
	abbrev_source_title = {Patterns},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Khakurel2022,
	author = {Khakurel, Utsab and Rawat, Danda B.},
	title = {Evaluating Explainable Artificial Intelligence (XAI): Algorithmic Explanations for Transparency and Trustworthiness of ML Algorithms and AI Systems},
	year = {2022},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {12113},
	doi = {10.1117/12.2620598},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146574992&doi=10.1117%2f12.2620598&partnerID=40&md5=39adb51707337f24ae20ec8346c4c483},
	affiliations = {Department of Electrical Engineering and Computer Science, Howard University, Washington, 20059, DC, United States},
	abstract = {Explainable Artificial Intelligence (XAI) is the capability of explaining the reasoning behind the choices made by the machine learning (ML) algorithm which can help understand and maintain the transparency of the decision-making capability of the ML algorithm. Humans make thousands of decisions every day in their lives. Every decision an individual makes, they can explain the reasons behind why they made the choices that they made. Nonetheless, it is not the same in the case of ML and AI systems. Furthermore, XAI was not wideley researched until suddenly the topic was brought forward and has been one of the most relevant topics in AI for trustworthy and transparent outcomes. XAI tries to provide maximum transparency to a ML algorithm by answering questions about how models effectively came up with the output. ML models with XAI will have the ability to explain the rationale behind the results, understand the weaknesses and strengths the learning models, and be able to see how the models will behave in the future. In this paper, we investigate XAI for algorithmic trustworthiness and transparency. We evaluate XAI using some example use cases and by using SHAP (SHapley Additive exPlanations) library and visualizing the effect of features individually and cumulatively in the prediction process. © 2022 SPIE.},
	author_keywords = {AI Ethics; Equitable AI; Explainable Artificial Intelligence; Transparency; Trustworthy AI; XAI},
	keywords = {Decision making; Ethical technology; Learning systems; Machine learning; AI ethic; AI systems; Algorithmics; Decisions makings; Equitable AI; Explainable artificial intelligence; Machine learning algorithms; Machine learning systems; Trustworthy AI; XAI; Transparency},
	editor = {Pham T. and Solomon L.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151065102-9},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Artificial Intelligence and Machine Learning for Multi-Domain Operations Applications IV 2022; Conference date: 6 June 2022 through 12 June 2022; Conference code: 185857}
}

@ARTICLE{Masic2022337,
	author = {Masic, Izet},
	title = {EFMI Inside - The Official Newsletter of the European Federation for Medical Informatics - 2022-1},
	year = {2022},
	journal = {Acta Informatica Medica},
	volume = {30},
	pages = {337},
	doi = {10.5455/AIM.2022.30.336-404},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144476901&doi=10.5455%2fAIM.2022.30.336-404&partnerID=40&md5=5bf389cbb73fe5bbff1ed8a07371ba51},
	keywords = {bioinformatics; clinical decision support system; clinical practice; clinical research; communication technology; consumer health informatics; coronavirus disease 2019; France; health care system; information technology; knowledge management; machine learning; medical ethics; medical informatics; medical information system; medical literature; natural language processing; Note; pandemic; privacy; publication},
	publisher = {Avicena Publishing},
	issn = {03538109},
	language = {English},
	abbrev_source_title = {Acta Inform. Med.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kim202275,
	author = {Kim, Tae Wan and Routledge, Bryan R.},
	title = {Why a Right to an Explanation of Algorithmic Decision-Making Should Exist: A Trust-Based Approach},
	year = {2022},
	journal = {Business Ethics Quarterly},
	volume = {32},
	number = {1},
	pages = {75 – 102},
	doi = {10.1017/beq.2021.3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124361768&doi=10.1017%2fbeq.2021.3&partnerID=40&md5=a5a9e9adcdf1328642346f15d0e4e280},
	affiliations = {Carnegie Mellon University, United States},
	abstract = {Businesses increasingly rely on algorithms that are data-trained sets of decision rules (i.e., the output of the processes often called machine learning) and implement decisions with little or no human intermediation. In this article, we provide a philosophical foundation for the claim that algorithmic decision-making gives rise to a right to explanation. It is often said that, in the digital era, informed consent is dead. This negative view originates from a rigid understanding that presumes informed consent is a static and complete transaction. Such a view is insufficient, especially when data are used in a secondary, noncontextual, and unpredictable manner - which is the inescapable nature of advanced artificial intelligence systems. We submit that an alternative view of informed consent - as an assurance of trust for incomplete transactions - allows for an understanding of why the rationale of informed consent already entails a right to ex post explanation.  © },
	author_keywords = {A right to explanation; Artificial intelligence ethics; California Consumer Privacy Act (CCPA); Explainable AI (XAI); General Data Protection Regulation (GDPR); Online privacy},
	correspondence_address = {T.W. Kim; Carnegie Mellon University, United States; email: twkim@andrew.cmu.edu},
	publisher = {Cambridge University Press},
	issn = {1052150X},
	language = {English},
	abbrev_source_title = {Bus. Ethics Q.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Fisher2022,
	author = {Fisher, Michael T. and Jurkenas, Dovydas and Jambajantsan, Amina and Jamsranjav, Bayarsaikhan and Nasan-Ochir, Eredene-Ochir and Gelegdorj, Eregzen and Chuluunbat, Munkhbayar and Petraglia, Michael and Boivin, Nicole},
	title = {Multidisciplinary digital methodologies for documentation and preservation of immovable Archaeological heritage in the Khovd River Valley, Western Mongolia},
	year = {2022},
	journal = {F1000Research},
	volume = {11},
	doi = {10.12688/f1000research.126740.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152858832&doi=10.12688%2ff1000research.126740.1&partnerID=40&md5=54372f723dc536c7f86e7bca6841fe39},
	affiliations = {Department of Archaeology, Max Planck Institute for Geoanthropology, Thuringen, Jena, 07743, Germany; National Museum of Mongolia, Ulaanbaatar, Ulaanbaatar, 14201, Mongolia; Institute of Archaeology, Mongolian Academy of Sciences, Ulaanbaatar, Ulaanbaatar, 13330, Mongolia; History and Social Sciences Department, Institute of Social and Human Sciences, Khovd State University, Khovd, Khovd, 84000, Mongolia; Australian Research Centre for Human Evolution, Griffith University, Brisbane, 4111, QLD, Australia; School of Social Science, University of Queensland, Brisbane, 4072, QLD, Australia; Department of Anthropology, National Museum of Natural History, Smithsonian Institution, Washington, 20560, DC, United States},
	abstract = {Background: The archaeological and ethnographic heritages of Mongolia reflect a multi-millennial continuity of typically mobile-pastoral occupations across sparsely populated, environmentally diverse landscapes, but the threats of modernisation and industrialisation to those heritages are nevertheless present and substantial. The construction of the Erdeneburen Hydroelectric Dam on the Khovd River in western Mongolia is planned to submerge hundreds of archaeological features and jeopardise at least another thousand. Methods: The Mongolian Archaeology Project: Surveying the Steppes, in collaboration with the Mongolian Institute of Archaeology, integrates a variety of digital techniques including GIS (geographic information systems), Machine Learning automated site detection, drone mapping, and Structure-from-Motion LiDAR scanning to document the endangered archaeology. This paper presents the resulting dataset of archaeological features across three different impact zones associated with the dam construction and evaluates the degree of efficacy of the initial data integration strategy through informal partner feedback and self-assessment. Results: While only approximately 20% of the documented sites fall within the planned flood zone, the remaining sites will be subjected to collateral threats such as industrial and infrastructural development that will necessitate extended monitoring, both temporally and spatially. In consideration of these results, this paper argues that a ‘responsive’ mode of heritage disaster intervention can bridge the gap between ‘reactive’ and ‘proactive’ modes, but requires development of an integrated (digital) methodology. Conclusions: The paper concludes by offering a new, more interconnected ‘transmethodology’ that addresses spatiality, sub-sampling, data reuse, and community input across multiple disciplines such as cultural heritage preservation, salvage archaeology, computer vision, and community archaeology. The authors developed this ‘transmethodology’ and the resulting workflows out of a theoretical framework that considers principles of Symmetrical Archaeology, Resilience Humanitarianism, and the CARE standard for inclusive data management (Collective benefit, Authority to control, Responsibility, and Ethics). Copyright: © 2022 Fisher MT et al.},
	author_keywords = {digital cultural heritage preservation; endangered archaeology; Erdeneburen Dam; GIS; landscape archaeology; Machine Learning; Mongolian archaeology; remote sensing; semantic data modelling; transmethodology},
	keywords = {archeology; article; comparative effectiveness; computer vision; conceptual framework; data integration; disaster; documentation; drug efficacy; ethics; geographic information system; inheritance; machine learning; Mongolia; motion; remote sensing; responsibility; river; self evaluation; steppe; workflow},
	correspondence_address = {M.T. Fisher; Department of Archaeology, Max Planck Institute for Geoanthropology, Jena, Thuringen, 07743, Germany; email: michael.fisher@shh.mpg.de},
	publisher = {F1000 Research Ltd},
	issn = {20461402},
	language = {English},
	abbrev_source_title = {F1000 Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}@CONFERENCE{Eusebi2022533,
	author = {Eusebi, Aliai and Vasek, Marie and Cockbain, Ella and Mariconti, Enrico},
	title = {The Ethics of Going Deep: Challenges in Machine Learning for Sensitive Security Domains},
	year = {2022},
	journal = {Proceedings - 7th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2022},
	pages = {533 – 537},
	doi = {10.1109/EuroSPW55150.2022.00063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134184082&doi=10.1109%2fEuroSPW55150.2022.00063&partnerID=40&md5=1a85ef475cf85eacfd31829131c690ea},
	affiliations = {UCL, London, United Kingdom},
	abstract = {Sometimes, machine learning models can determine the trajectory of human life, and a series of cascading ethical failures could be irreversible. Ethical concerns are nevertheless set to increase, in particular when the injection of algorithmic forms of decision-making occurs in highly sensitive security contexts. In cybercrime, there have been cases of algorithms that have not identified racist and hateful speeches, as well as missing the identification of Image Based Sexual Abuse cases. Hence, this paper intends to add a voice of caution on the vulnerabilities pervading the different stages of a machine learning development pipeline and the ethical challenges that these potentially nurture and perpetuate. To highlight both the issues and potential fixes in an adversarial environment, we use Child Sexual Exploitation and its implications on the Internet as a case study, being 2021 its worst year according to the Internet Watch Foundation. © 2022 IEEE.},
	author_keywords = {ethics; machine learning; online child sexual abuse; security},
	keywords = {Deep learning; E-learning; Ethical technology; Algorithmics; Decisions makings; Ethical concerns; Ethical failure; Human lives; Machine learning models; Machine-learning; Online child sexual abuse; Security; Security domains; Decision making},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166549560-8},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Eur. Symp. Secur. Priv. Workshops, Euro S PW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2022; Conference date: 6 June 2022 through 10 June 2022; Conference code: 180432; All Open Access, Green Open Access}
}

@CONFERENCE{Subías-Beltrán2022,
	author = {Subías-Beltrán, Paula and Pujol, Oriol and de Lecuona, Itziar},
	title = {The forgotten human autonomy in Machine Learning},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3221},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139924690&partnerID=40&md5=404a792dfbee3706e6c16360305e47c3},
	affiliations = {Eurecat, Centre Tecnològic de Catalunya, Unit of Digital Health, Barcelona, Spain; Bioethics and Law Observatory, UNESCO Chair in Bioethics, Universitat de Barcelona, Barcelona, Spain; Dept. de Matemàtiques i Informàtica, Universitat de Barcelona, Barcelona, Spain; Dept. of Medicine, Universitat de Barcelona, Barcelona, Spain},
	abstract = {There are many rights, freedoms, and principles that build our society and nourish it day after day. No right, freedom, or principle is absolute; they must always be balanced. Our starting point is the respect for internationally recognized human rights and we focus on the principle of autonomy, which is not being adequately treated and protected in the ever-changing algorithmic world. In this article we review some of the most influential bodies of knowledge and ethical recommendations in artificial intelligence, and analyze the extent to which they address the principle of autonomy. We ground the concept of autonomy in operational terms such as being well-informed and being able to make free decisions. Under these two different aspects, we analyze the technical and social risks and propose different ways in which artificial intelligence requires further exploration with the aim of preserving human autonomy. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)},
	author_keywords = {AI ethics; bioethics; human autonomy; human rights; machine learning},
	keywords = {Ethical technology; Social aspects; AI ethic; Algorithmics; Bioethic; Body of knowledge; Creative Commons; Human autonomy; Human rights; Machine-learning; Social risks; Technical risks; Machine learning},
	editor = {Dushi D. and Vrije Universiteit Brussel, Pleinlaan 2, Brussels and Naretto F. and Scuola Normale Superiore, Piazza dei Cavalieri 7, Pisa and Panigutti C. and European Commission - Joint Research Centre, Via Enrico Fermi 2749, Ispra and Pratesi F. and Institute of Information Science and Technologies - National Research Council of Italy, via G. Moruzzi 1, Pisa},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2022 Workshop on Imagining the AI Landscape after the AI Act, IAIL 2022; Conference date: 13 June 2022; Conference code: 182936}
}

@ARTICLE{Anderson2022W6,
	author = {Anderson, James A. and McCradden, Melissa D. and Stephenson, Elizabeth A.},
	title = {Response to Open Peer Commentaries: On Social Harms, Big Tech, and Institutional Accountability},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {10},
	pages = {W6 – W8},
	doi = {10.1080/15265161.2022.2075977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130960442&doi=10.1080%2f15265161.2022.2075977&partnerID=40&md5=3733d94ec3ec46db909947656e313565},
	affiliations = {University of Toronto, Canada; The Hospital for Sick Children, Canada; Peter Gilgan Centre for Research and Learning, Canada; Dalla Lana School of Public Health, Canada},
	keywords = {Delivery of Health Care; Ethics, Research; Humans; Machine Learning; Peer Group; Social Responsibility; health care delivery; human; machine learning; peer group; research ethics; social responsibility},
	correspondence_address = {M.D. McCradden; Department of Bioethics, The Hospital for Sick Children, Toronto, Canada; email: Mdmccradden@gmail.com},
	publisher = {Taylor and Francis Ltd.},
	issn = {15265161},
	pmid = {35593914},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Labanda-Jaramillo2022435,
	author = {Labanda-Jaramillo, Milton and Chamba-Eras, Luis and Erreyes-Pinzon, Daysi and Chamba-Eras, Irene and Orellana-Malla, Angel},
	title = {DIA4K12: Framework for Managing then Teaching-Learning of Artificial Intelligence at Early Ages},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {414 LNNS},
	pages = {435 – 447},
	doi = {10.1007/978-3-030-96293-7_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126199997&doi=10.1007%2f978-3-030-96293-7_36&partnerID=40&md5=c08db61e2267c32bb27544225f3f56fa},
	affiliations = {Universidad Nacional de Loja, Loja, 110101, Ecuador; Corporación Ecuatoriana para el Desarrollo de la Investigación y la Academia (CEDIA), Azuay, 010102, Ecuador; Ministerio de Educación, Loja, 110101, Ecuador},
	abstract = {Artificial Intelligence (AI) is intervening positively in educations. UNESCO considers as a new vision to involve AI not only as a didactic medium but also as a science in which children can develop their intellect, through workshops, courses, and curricula focused on the fundamentals of AI, allowing them to develop skills such as computational and critical thinking. This research aims to design the DIA4K12 framework, which proposes the structure to support the teaching-learning process of AI in primary and secondary education. The core of the framework consists of four phases: planning, execution, process, and development; three components: open educational resources, K-12 curriculum and active methodologies; five sublevels: logical reasoning, computational thinking, and disconnected artificial intelligence, mathematics for AI, programming and machine learning; and three transversal axes: communities (communities of practice), open license (creative commons) and ethics. Finally, the framework was applied to a case study in the context of the Ecuadorian General Basic Education curriculum for the subject of Mathematics, using three phases, three components, and two sublevels. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Computational thinking; Education; Information technology education; Machine learning; School curriculum},
	correspondence_address = {M. Labanda-Jaramillo; Universidad Nacional de Loja, Loja, 110101, Ecuador; email: miltonlab@unl.edu.ec},
	editor = {Rocha A. and Ferrás C. and Delgado E.J. and Porras A.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303096292-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: International Conference on Information Technology and Systems, ICITS 2022; Conference date: 9 February 2022 through 11 February 2022; Conference code: 274299}
}

@ARTICLE{Guembe2022265,
	author = {Guembe, Blessing and Azeta, Ambrose and Misra, Sanjay and Ahuja, Ravin},
	title = {Trustworthy Machine Learning Approaches for Cyberattack Detection: A Review},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13381 LNCS},
	pages = {265 – 278},
	doi = {10.1007/978-3-031-10548-7_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135883848&doi=10.1007%2f978-3-031-10548-7_20&partnerID=40&md5=a59861b4809d699ed77510ea60767082},
	affiliations = {Department of Computer and Information Sciences, Covenant University, Ogun, Ota, Nigeria; Department of Computer Science, Namibia University of Science and Technology, Windhoek, Namibia; Department of Computer Science and Communication, Ostfold University College, Halden, Norway; Delhi Skills and Entrepreneurship University, Delhi, India},
	abstract = {In recent years, machine learning techniques have been utilized in sensitive areas such as health, medical diagnosis, facial recognition, cybersecurity, etc. With this exponential growth comes potential large-scale ethical, safety, and social ramifications. With this enhanced ubiquity and sensitivity, concerns about ethics, trust, transparency, and accountability inevitably arise. Given the threat of sophisticated cyberattacks, it’s critical to establish cybersecurity trustworthy concepts and to develop methodologies and concepts for a wide range of explainable machine cybersecurity models that will assure reliable threat identification and detection, more research is needed. This survey examines a variety of explainable machine learning techniques that can be used to implement a reliable cybersecurity infrastructure in the cybersecurity domain. The main aim of this study is to execute an in-depth review and identification of existing explainable machine learning algorithms for cyberattack detection. This study employed the seven-step survey model to determine the research domain, implement search queries, and compile all retrieved articles from digital databases. This research looks at the literature on trustworthy machine learning algorithms for detecting cyberattacks. An extensive search of electronic databases such as ArXiv, Semantic Scholar, IEEE Xplore, Wiley Library, Scopus, Google Scholar, ACM, and Springer was carried out to find relevant literature in the subject domain. From 2016 to 2022, this study looked at white papers, conference papers, and journals. Only 25 research papers were chosen for this research paper describing trustworthy cybersecurity and explainable AI cybersecurity after we retrieved 800 articles from web databases. The study reveals that the decision tree technique outperforms other state-of-the-art machine learning models in terms of transparency and interpretability. Finally, this research suggests that incorporating explainable into machine learning cybersecurity models will help uncover the root causes of defensive failures, making it easier for cybersecurity experts to enhance both cybersecurity infrastructures and development, rather than just model results, policy, and management. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Machine learning; Trustworthiness; Trustworthy cybersecurity},
	keywords = {Database systems; Decision trees; Diagnosis; Digital libraries; Face recognition; Learning algorithms; Machine learning; Philosophical aspects; Semantics; Transparency; Cyber security; Cyber-attacks; Cyberattack detection; Machine learning algorithms; Machine learning approaches; Machine learning techniques; Machine-learning; Research papers; Trustworthiness; Trustworthy cybersecurity; Surveys},
	correspondence_address = {B. Guembe; Department of Computer and Information Sciences, Covenant University, Ota, Ogun, Nigeria; email: blessingodede@gmail.com},
	editor = {Gervasi O. and Murgante B. and Misra S. and Rocha A.M.A.C. and Garau C.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303110547-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 22nd International Conference on Computational Science and Its Applications , ICCSA 2022; Conference date: 4 July 2022 through 7 July 2022; Conference code: 281299}
}

@ARTICLE{Donnelly20221,
	author = {Donnelly, Dusty-Lee},
	title = {First Do No Harm: Legal Principles Regulating the Future of Artificial Intelligence in Health Care in South Africa},
	year = {2022},
	journal = {Potchefstroom Electronic Law Journal},
	volume = {25},
	pages = {1 – 43},
	doi = {10.17159/1727-3781/2022/V25IA11118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129907028&doi=10.17159%2f1727-3781%2f2022%2fV25IA11118&partnerID=40&md5=0815b1ffe6d1b72faf11c0194ec73c38},
	affiliations = {University of Kwa-Zulu Natal, South Africa},
	abstract = {What sets AI systems and AI-powered medical robots apart from all other forms of advanced medical technology is their ability to operate at least to some degree autonomously from the human health care practitioner and to use machine-learning to generate new, often unforeseen, analysis and predictions. This poses challenges under the current framework of laws, regulations, and ethical guidelines applicable to health care in South Africa. The article outlines these challenges and sets out guiding principles for a normative framework to regulate the use of AI in health care. The article examines three key areas for legal reform in relation to AI in health care. First, it proposes that the regulatory framework for the oversight of software as a medical device needs to be updated to develop frameworks for adequately regulating the use of such new technologies. Secondly, it argues that the present HPCSA guidelines for health care practitioners in South Africa adopt an unduly restrictive approach centred in the outmoded semantics of telemedicine. This may discourage technological innovation that could improve access to health care for all, and as such the guidelines are inconsistent with the national digital health strategy. Thirdly, it examines the common law principles of fault-based liability for medical negligence, which could prove inadequate to provide patients and users of new technologies with redress for harm where fault cannot clearly be attributed to the healthcare practitioner. It argues that consideration should be given to developing a statutory scheme for strict liability, together with mandatory insurance, and appropriate reform of product liability pertaining to technology developers and manufacturers. These legal reforms should not be undertaken without also developing a coherent, human-rights centred policy framework for the ethical use of AI, robotics, and related technologies in health care in South Africa. © 2022, North-West Unversity.},
	author_keywords = {Artificial intelligence; ethics; health care; health policies; machine learning},
	correspondence_address = {D.-L. Donnelly; School of Law, University of Kwa-Zulu Natal, South Africa; email: donnellyd@ukzn.ac.za},
	publisher = {North-West Unversity},
	issn = {17273781},
	language = {English},
	abbrev_source_title = {Potchefstroom Electron. Law J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Chellasamy2022397,
	author = {Chellasamy, Aarthy and Nagarathinam, Aishwarya},
	title = {An Overview of Augmenting AI Application in Healthcare},
	year = {2022},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {117},
	pages = {397 – 407},
	doi = {10.1007/978-981-19-0898-9_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130881004&doi=10.1007%2f978-981-19-0898-9_31&partnerID=40&md5=9cb56dab9c975680988f290aad889814},
	affiliations = {School of Business and Management, CHRIST University, Bangalore, India},
	abstract = {Artificial intelligence (AI) is showing a paradigm shift in all spheres of the world by mimicking human cognitive behavior. The application of AI in healthcare is noteworthy because of availability of voluminous data and mushrooming analytics techniques. The various applications of AI, especially, machine learning and neural networks are used across different areas in the healthcare industry. Healthcare disruptors are leveraging this opportunity and are innovating in various fields such as drug discovery, robotic surgery, medical imaging, and the like. The authors have discussed the application of AI techniques in a few areas like diagnosis, prediction, personal care, and surgeries. Usage of AI is noteworthy in this COVID-19 pandemic situation too where it assists physicians in resource allocation, predicting death rate, patient tracing, and life expectancy of patients. The other side of the coin is the ethical issues faced while using this technology like data transparency, bias, security, and privacy of data becomes unanswered. This can be handled better if strict policy measures are imposed for safe handling of data and educating the public about how treatment can be improved by using this technology which will tend to build trust factor in near future. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Artificial intelligence; COVID-19; Ethics; Healthcare; Neural networks},
	keywords = {Artificial intelligence; Behavioral research; Data privacy; Ethical technology; Intelligent robots; Medical imaging; Robotic surgery; Analytic technique; Artificial intelligence techniques; Cognitive behavior; COVID-19; Drug discovery; Healthcare industry; Neural-networks; Paradigm shifts; Robotics surgery; Voluminous data; Diagnosis},
	correspondence_address = {A. Nagarathinam; School of Business and Management, CHRIST University, Bangalore, India; email: aishwarya.n@christuniversity.in},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23674512},
	language = {English},
	abbrev_source_title = {Lecture. Notes. Data Eng. Commun. Tech.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lim2022,
	author = {Lim, Ji-Hun and Seo, Jeong-Eun and Kwon, Hun-Yeong},
	title = {The Role of Higher Education for the Ethical AI Society},
	year = {2022},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	volume = {35},
	doi = {10.32473/flairs.v35i.130609},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131142326&doi=10.32473%2fflairs.v35i.130609&partnerID=40&md5=68454e8fd375bdacb1016cc2501b8a65},
	affiliations = {School of Cybersecurity, Korea University, Seoul, South Korea},
	abstract = {AI is creating numerous ethical issues. In the upcoming AI society, we will have to deal with the Influence of AI correctly. To this end, ethical education is needed for experts who learn and develop AI technology. Above all, this is because their ethical capabilities lead to ethical AI technologies and services. Therefore, this study sought the role and direction of AI ethics education in the field of higher education that educates AI experts. © 2022 by the authors. All rights reserved.},
	author_keywords = {AI Ethics; Education},
	keywords = {Machine learning; AI ethic; AI Technologies; Ethical issues; Ethics education; High educations; Learn+; Ethical technology},
	editor = {Bartak R. and Franklin M. and Keshtkar F.},
	publisher = {Florida OJ},
	issn = {23340754},
	language = {English},
	abbrev_source_title = {Proc. Int. Fla. Artif. Intell. Res. Soc. Conf., FLAIRS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 35th International Florida Artificial Intelligence Research Society Conference, FLAIRS-35 2022; Conference date: 15 May 2022 through 18 May 2022; Conference code: 277889; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Agarwal202210358,
	author = {Agarwal, Chirag and D'Souza, Daniel and Hooker, Sara},
	title = {Estimating Example Difficulty using Variance of Gradients},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {10358 – 10368},
	doi = {10.1109/CVPR52688.2022.01012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136331507&doi=10.1109%2fCVPR52688.2022.01012&partnerID=40&md5=50ce9b301d3662ef388876b5ca172235},
	affiliations = {Adobe, MDSR Lab; ML Collective; Google Research},
	abstract = {In machine learning, a question of great interest is understanding what examples are challenging for a model to classify. Identifying atypical examples ensures the safe de-ployment of models, isolates samples that require further human inspection and provides interpretability into model behavior. In this work, we propose Variance of Gradients (VoG) as a valuable and efficient metric to rank data by difficulty and to surface a tractable subset of the most chal-lenging examples for human-in-the-loop auditing. We show that data points with high VoG scores are far more difficult for the model to learn and over-index on corrupted or mem-orized examples. Further, restricting the evaluation to the test set instances with the lowest VoG improves the model's generalization performance. Finally, we show that VoG is a valuable and efficient ranking for out-of-distribution detection. © 2022 IEEE.},
	author_keywords = {accountability; fairness; privacy and ethics in vision; Transparency},
	keywords = {Accountability; Atypicals; Datapoints; Fairness; Human-in-the-loop; Interpretability; Machine-learning; Modeling behaviour; Privacy and ethic in vision; Tractable subset},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Krinkin2022,
	author = {Krinkin, Kirill and Shichkina, Yulia and Ignatyev, Andrey},
	title = {Co-evolutionary hybrid intelligence is a key concept for the world intellectualization},
	year = {2022},
	journal = {Kybernetes},
	doi = {10.1108/K-03-2022-0472},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139970979&doi=10.1108%2fK-03-2022-0472&partnerID=40&md5=6e177ab56f4f344fb19961df94488f91},
	affiliations = {Department of Software Engineering and Computer Applications, Saint Petersburg Electrotechnical University LETI, Saint-Petersburg, Russian Federation; Faculty of Computer Science and Technology, Saint Petersburg Electrotechnical University LETI, Saint-Petersburg, Russian Federation; Center for Global IT Cooperation, MGIMO University, Moscow, Russian Federation},
	abstract = {Purpose: This study aims to show the inconsistency of the approach to the development of artificial intelligence as an independent tool (just one more tool that humans have developed); to describe the logic and concept of intelligence development regardless of its substrate: a human or a machine and to prove that the co-evolutionary hybridization of the machine and human intelligence will make it possible to reach a solution for the problems inaccessible to humanity so far (global climate monitoring and control, pandemics, etc.). Design/methodology/approach: The global trend for artificial intelligence development (has been) was set during the Dartmouth seminar in 1956. The main goal was to define characteristics and research directions for artificial intelligence comparable to or even outperforming human intelligence. It should be able to acquire and create new knowledge in a highly uncertain dynamic environment (the real-world environment is an example) and apply that knowledge to solving practical problems. Nowadays artificial intelligence overperforms human abilities (playing games, speech recognition, search, art generation, extracting patterns from data etc.), but all these examples show that developers have come to a dead end. Narrow artificial intelligence has no connection to real human intelligence and even cannot be successfully used in many cases due to lack of transparency, explainability, computational ineffectiveness and many other limits. A strong artificial intelligence development model can be discussed unrelated to the substrate development of intelligence and its general properties that are inherent in this development. Only then it is to be clarified which part of cognitive functions can be transferred to an artificial medium. The process of development of intelligence (as mutual development (co-development) of human and artificial intelligence) should correspond to the property of increasing cognitive interoperability. The degree of cognitive interoperability is arranged in the same way as the method of measuring the strength of intelligence. It is stronger if knowledge can be transferred between different domains on a higher level of abstraction (Chollet, 2018). Findings: The key factors behind the development of hybrid intelligence are interoperability – the ability to create a common ontology in the context of the problem being solved, plan and carry out joint activities; co-evolution – ensuring the growth of aggregate intellectual ability without the loss of subjectness by each of the substrates (human, machine). The rate of co-evolution depends on the rate of knowledge interchange and the manufacturability of this process. Research limitations/implications: Resistance to the idea of developing co-evolutionary hybrid intelligence can be expected from agents and developers who have bet on and invested in data-driven artificial intelligence and machine learning. Practical implications: Revision of the approach to intellectualization through the development of hybrid intelligence methods will help bridge the gap between the developers of specific solutions and those who apply them. Co-evolution of machine intelligence and human intelligence will ensure seamless integration of smart new solutions into the global division of labor and social institutions. Originality/value: The novelty of the research is connected with a new look at the principles of the development of machine and human intelligence in the co-evolution style. Also new is the statement that the development of intelligence should take place within the framework of integration of the following four domains: global challenges and tasks, concepts (general hybrid intelligence), technologies and products (specific applications that satisfy the needs of the market). © 2022, Emerald Publishing Limited.},
	author_keywords = {AI ethics; Artificial intelligence; Co-evolution; Cognitive functions; Division of labor; Human–machine hybridization; Hybrid intelligence},
	keywords = {Artificial intelligence; Brain; Cognitive systems; Computation theory; Interoperability; Speech recognition; AI ethic; Co-evolution; Co-evolutionary; Cognitive functions; Division of labor; Human intelligence; Human-machine; Human–machine hybridization; Hybrid intelligence; Hybridisation; Substrates},
	correspondence_address = {Y. Shichkina; Faculty of Computer Science and Technology, Saint Petersburg Electrotechnical University LETI, Saint-Petersburg, Russian Federation; email: shichkina@etu.ai},
	publisher = {Emerald Publishing},
	issn = {0368492X},
	language = {English},
	abbrev_source_title = {Kybernetes},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Zhang20221,
	author = {Zhang, Qingquan and Liu, Jialin and Zhang, Zeqi and Wen, Junyi and Mao, Bifei and Yao, Xin},
	title = {Mitigating Unfairness via Evolutionary Multi-objective Ensemble Learning},
	year = {2022},
	journal = {IEEE Transactions on Evolutionary Computation},
	pages = {1–1},
	doi = {10.1109/TEVC.2022.3209544},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139466200&doi=10.1109%2fTEVC.2022.3209544&partnerID=40&md5=619bc2bd6024140f0bd5c6696e85ff2c},
	affiliations = {Research Institute of Trustworthy Autonomous System, Southern University of Science and Technology, Shenzhen, China; Trustworthiness Theory Research Center, Huawei Technologies Co., Ltd, Shenzhen, China},
	abstract = {In the literature of mitigating unfairness in machine learning, many fairness measures are designed to evaluate predictions of learning models and also utilised to guide the training of fair models. It has been theoretically and empirically shown that there exist conflicts and inconsistencies among accuracy and multiple fairness measures. Optimising one or several fairness measures may sacrifice or deteriorate other measures. Two key questions should be considered, how to simultaneously optimise accuracy and multiple fairness measures, and how to optimise all the considered fairness measures more effectively. In this paper, we view the mitigating unfairness problem as a multi-objective learning problem considering the conflicts among fairness measures. A multi-objective evolutionary learning framework is used to simultaneously optimise several metrics (including accuracy and multiple fairness measures) of machine learning models. Then, ensembles are constructed based on the learning models in order to automatically balance different metrics. Empirical results on eight well-known datasets demonstrate that compared with the state-of-the-art approaches for mitigating unfairness, our proposed algorithm can provide decision-makers with better tradeoffs among accuracy and multiple fairness metrics. Furthermore, the high-quality models generated by the framework can be used to construct an ensemble to automatically achieve a better tradeoff among all the considered fairness metrics than other ensemble methods. Author},
	author_keywords = {AI ethics; Biological system modeling; Data models; Ensembles of learning machines; Fairness in machine learning; Fairness measures; Measurement; Multi-objective learning; Prediction algorithms; Predictive models; Training; Weight measurement},
	keywords = {Artificial intelligence; Biological systems; Decision making; Evolutionary algorithms; Learning systems; AI ethic; Biological system modeling; Ensembles of learning machines; Fairness in machine learning; Fairness measures; Learning models; Machine-learning; Multi-objective learning; Prediction algorithms; Predictive models; Weighing},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {1089778X},
	coden = {ITEVF},
	language = {English},
	abbrev_source_title = {IEEE Trans Evol Comput},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Al Kabi2022,
	author = {Al Kabi, Amin},
	title = {Challenges Encountered by Artificial Intelligence Applications in Today's Interconnected World},
	year = {2022},
	journal = {International Conference on Electrical, Computer, and Energy Technologies, ICECET 2022},
	doi = {10.1109/ICECET55527.2022.9873465},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138907212&doi=10.1109%2fICECET55527.2022.9873465&partnerID=40&md5=8e2920e3100da74fea6995ba6da1f92c},
	affiliations = {Australian University, Kuwait},
	abstract = {In recent years, technological and scientific advancements in artificial intelligence (AI), along with one of its key subcategories, i.e., machine learning (ML) are growing exponentially. For example, the remarkable achievements in artificial intelligence occurred in 2021 included an AI model that can meritoriously integrate natural language processing with computer vision to create images from textual captions, and an AI framework that can diagnose dementia in short time, besides other captivating inventions. This research work, AI and ML are investigated, and some key features are presented, including their relevant subfields, methods, industries, main stages, and most importantly the technical challenges that encounter the importantly the technical challenges that encounter the mainly on the current challenges encountered by artificial intelligence and machine learning applications, where the pair of intelligence and machine learning applications, where the pair of ethics and transparency in AI are highlighted in terms of their meanings, and their importance to AI/ML. Subsequently, a framework for AI design and implementation is introduced entitled 'PESTEL' which stands for Political, Economic, Social, Technological, Environmental, and Legal. It is predicted that the outcome of this research work will facilitate the incessant espousal of AI/ML in today's interconnected world.  © 2022 IEEE.},
	author_keywords = {Artificial Intelligience (AI); Internet of Things (IoT); Machine Learning (ML); Transparency},
	keywords = {Environmental regulations; Internet of things; Learning algorithms; Machine learning; Natural language processing systems; Artificial intelligience; Internet of thing; Key feature; Language processing; Machine learning; Machine learning applications; Machine-learning; Natural languages; Sub-field method; Technical challenges; Transparency},
	correspondence_address = {A. Al Kabi; Australian University, Kuwait; email: a.kabi@ack.edu.kw},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166547087-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Electr., Comput., Energy Technol., ICECET},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 IEEE International Conference on Electrical, Computer, and Energy Technologies, ICECET 2022; Conference date: 20 July 2022 through 22 July 2022; Conference code: 182630}
}

@CONFERENCE{Vellaiparambill2022137,
	author = {Vellaiparambill, Alan and Natchimuthu, Natchimuthu},
	title = {Ethical Tenets of Stock Price Prediction Using Machine Learning Techniques: A Sustainable Approach},
	year = {2022},
	journal = {ECS Transactions},
	volume = {107},
	number = {1},
	pages = {137 – 149},
	doi = {10.1149/10701.0137ecst},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130550434&doi=10.1149%2f10701.0137ecst&partnerID=40&md5=22066fec368614820c6a6bcdbc43dd87},
	affiliations = {Department of Commerce, Christ Deemed to be University, Bangalore, India},
	abstract = {The visible decline of ethics primarily gets reflected in financial markets, as it portrays human actions and sentiments in numerical terms than any sector. Accuracy in Stock market prediction remains inefficient due to many known and unknown variables. Academia and industry recently relied on ML at large to track the market and monetise the movements. The norms of fairness, accuracy, dependability, transparency in financing are left unattended in ML prediction models with assumptions far from reality. This study focuses on the ethical dimension of Machine Learning models and generates a sustainable framework for investors. Specifically, the Sustainable Development goals (SDG) can enhance the prediction models in ML with improved efficiency. Along with SDG, this research broadens the variables' horizon of prediction in ML of computer science domain with concepts of Socially responsible Investing (SRI), Environmental Social and Corporate Governance (ESG), and Carbon footprints. With One hundred fifteen articles reviewed, the proposed framework ensures sustainability in investments at the grassroots level. © The Electrochemical Society},
	keywords = {Carbon footprint; Commerce; Financial markets; Forecasting; Investments; Machine learning; Philosophical aspects; Corporate governance; Grass-root level; Human actions; Machine learning models; Machine learning techniques; Prediction modelling; Socially responsible investing; Stock market prediction; Stock price prediction; Sustainable development},
	publisher = {Institute of Physics},
	issn = {19386737},
	isbn = {978-160768539-5},
	language = {English},
	abbrev_source_title = {ECS Transactions},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Technologies for Smart Green Connected Society 2021, ICTSGS 2021; Conference date: 29 November 2021 through 30 November 2021; Conference code: 179026}
}

@CONFERENCE{Ruiz De Arcaute2022,
	author = {Ruiz De Arcaute, Gonzalo Martinez and Hernandez, Jose Alberto and Reviriego, Pedro},
	title = {Assessing the Impact of Membership Inference Attacks on Classical Machine Learning Algorithms},
	year = {2022},
	journal = {2022 18th International Conference on the Design of Reliable Communication Networks, DRCN 2022},
	doi = {10.1109/DRCN53993.2022.9758025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129596421&doi=10.1109%2fDRCN53993.2022.9758025&partnerID=40&md5=204662428dcce76b9354f4c28dc1b4a8},
	affiliations = {Universidad Carlos III de Madrid, Dept. Ingeniería Telemática, Spain},
	abstract = {In the last decade, machine learning has been widely adopted in many areas and the trend not only continues but accelerates. This has raised many issues ranging from ethics and security to privacy. In particular, it has been shown that in some settings an attacker can infer if a given element has been used to train a machine learning model. This is not acceptable in many applications that deal with sensitive data and thus designers need to take privacy into account when implementing machine learning based systems. In this paper, we study the impact of such membership inference attacks on traditional machine learning algorithms. Our goals are 1) to identify if there are some algorithms that are more vulnerable than others, and 2) if privacy can be guaranteed by selecting the algorithm parameters and if so at what cost on performance. Our results show that ensemble averaging models, especially Extra-Trees, are vulnerable to this attack. This information can be used by designers as an additional input to guide the machine learning algorithm selection process so that privacy is incorporated as a design goal from the beginning.  © 2022 IEEE.},
	author_keywords = {Machine Learning; Membership Inference Attacks; Privacy; Security},
	keywords = {Learning algorithms; Machine learning; Algorithm parameters; Inference attacks; Machine learning algorithms; Machine learning models; Machine-learning; Membership inference attack; Performance; Privacy; Security; Sensitive datas; Inference engines},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166540987-2},
	language = {English},
	abbrev_source_title = {Int. Conf. Des. Reliab. Commun. Networks, DRCN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 18th International Conference on the Design of Reliable Communication Networks, DRCN 2022; Conference date: 28 March 2022 through 31 March 2022; Conference code: 178907}
}

@ARTICLE{Weinberg202275,
	author = {Weinberg, Lindsay},
	title = {Rethinking Fairness: An Interdisciplinary Survey of Critiques of Hegemonic ML Fairness Approaches},
	year = {2022},
	journal = {Journal of Artificial Intelligence Research},
	volume = {74},
	pages = {75 – 109},
	doi = {10.1613/jair.1.13196},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132004762&doi=10.1613%2fjair.1.13196&partnerID=40&md5=7d7f4bb13e42782469d7b1a9dd36a4a3},
	affiliations = {Honors College, Purdue University, West Lafayette, 47906, IN, United States},
	abstract = {This survey article assesses and compares existing critiques of current fairness-enhancing technical interventions in machine learning (ML) that draw from a range of non-computing disciplines, including philosophy, feminist studies, critical race and ethnic studies, legal studies, anthropology, and science and technology studies. It bridges epistemic divides in order to offer an interdisciplinary understanding of the possibilities and limits of hegemonic computational approaches to ML fairness for producing just outcomes for society’s most marginalized. The article is organized according to nine major themes of critique wherein these different fields intersect: 1) how "fairness" in AI fairness research gets defined; 2) how problems for AI systems to address get formulated; 3) the impacts of abstraction on how AI tools function and its propensity to lead to technological solutionism; 4) how racial classification operates within AI fairness research; 5) the use of AI fairness measures to avoid regulation and engage in ethics washing; 6) an absence of participatory design and democratic deliberation in AI fairness considerations; 7) data collection practices that entrench “bias,” are non-consensual, and lack transparency; 8) the predatory inclusion of marginalized groups into AI systems; and 9) a lack of engagement with AI’s long-term social and ethical outcomes. Drawing from these critiques, the article concludes by imagining future ML fairness research directions that actively disrupt entrenched power dynamics and structural injustices in society. ©2022 AI Access Foundation. All rights reserved.},
	keywords = {Ethical technology; 'current; AI systems; Computational approach; Computing disciplines; Data collection; Fairness measures; Participatory design; Power dynamics; Science and technology studies; Surveys},
	correspondence_address = {L. Weinberg; Honors College, Purdue University, West Lafayette, 47906, United States; email: lweinber@purdue.edu},
	publisher = {AI Access Foundation},
	issn = {10769757},
	coden = {JAIRF},
	language = {English},
	abbrev_source_title = {J Artif Intell Res},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Bradley2022189,
	author = {Bradley, Fiona},
	title = {Representation of Libraries in Artificial Intelligence Regulations and Implications for Ethics and Practice},
	year = {2022},
	journal = {Journal of the Australian Library and Information Association},
	volume = {71},
	number = {3},
	pages = {189 – 200},
	doi = {10.1080/24750158.2022.2101911},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135832248&doi=10.1080%2f24750158.2022.2101911&partnerID=40&md5=1ff33093412d54d1b2d582fce4f4fe00},
	affiliations = {School of Social Sciences – Discipline of Political Science International Relations, University of Western Australia, Perth, Australia; University Library, UNSW Sydney, Sydney, Australia},
	abstract = {We are already living in an algorithmic society. AI policies and regulations are now emerging at the same time as more is learned about the implications of bias in machine learning sets, the surveillance risks of smart cities and facial recognition, and automated decision-making by government, among many other applications of AI and machine learning. Each of these issues raises concerns around ethics, privacy, and data protection. This paper introduces some of the key AI regulatory developments to date and engagement by libraries in these processes. While many AI applications are largely emergent and hypothetical in libraries, some mature examples can be identified in research literature searching, language tools for textual analysis, and access to collection data. The paper presents a summary of how library activities such as these are represented in national AI plans and ways that libraries have engaged with other aspects of AI regulation including the development of ethical frameworks. Based on the sector's expertise in related regulatory issues including copyright and data protection, the paper suggests further opportunities to contribute to the future of ethical, trustworthy, and transparent AI. © 2022 Fiona Bradley.},
	author_keywords = {artificial intelligence; governance; libraries; Regulation},
	correspondence_address = {F. Bradley; Political Science and International Relations, School of Social Sciences, University of Western Australia, Australia; email: f.bradley@unsw.edu.au},
	publisher = {Australian Library and Information Association},
	issn = {24750158},
	language = {English},
	abbrev_source_title = {J. Aust. Libr. Inf. Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Peng202213420,
	author = {Peng, Zirui and Li, Shaofeng and Chen, Guoxing and Zhang, Cheng and Zhu, Haojin and Xue, Minhui},
	title = {Fingerprinting Deep Neural Networks Globally via Universal Adversarial Perturbations},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {13420 – 13429},
	doi = {10.1109/CVPR52688.2022.01307},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140421428&doi=10.1109%2fCVPR52688.2022.01307&partnerID=40&md5=39cfd80d10588cbd617623a32580c455},
	affiliations = {Shanghai Jiao Tong University, China; The Ohio State University, United States; CSIRO's Data61; The University of Adelaide, Australia},
	abstract = {In this paper, we propose a novel and practical mechanism to enable the service provider to verify whether a suspect model is stolen from the victim model via model extraction attacks. Our key insight is that the profile of a DNN model's decision boundary can be uniquely characterized by its Universal Adversarial Perturbations (UAPs). UAPs belong to a low-dimensional subspace and piracy models' subspaces are more consistent with victim model's subspace compared with non-piracy model. Based on this, we propose a UAP fingerprinting method for DNN models and train an encoder via contrastive learning that takes fingerprints as inputs, outputs a similarity score. Extensive studies show that our framework can detect model Intellectual Property (IP) breaches with confidence > 99.99 % within only 20 fingerprints of the suspect model. It also has good generalizability across different model architectures and is robust against post-modifications on stolen models. © 2022 IEEE.},
	author_keywords = {accountability; fairness; Machine learning; privacy and ethics in vision; Self- & semi- & meta- & unsupervised learning; Transparency},
	keywords = {Crime; Learning systems; Accountability; Decision boundary; Fairness; Machine-learning; Model extraction; Modeling decisions; Privacy and ethic in vision; Self- & semi- & meta- & unsupervised learning; Service provider; Via modeling; Deep neural networks},
	correspondence_address = {G. Chen; Shanghai Jiao Tong University, China; email: guoxingchen@sjtu.edu.cn; H. Zhu; Shanghai Jiao Tong University, China; email: zhu-hj@sjtu.edu.cn},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@CONFERENCE{Lu2022241,
	author = {Lu, Qinghua and Zhu, Liming and Xu, Xiwei and Whittle, Jon and Douglas, David and Sanderson, Conrad},
	title = {Software engineering for Responsible AI: An empirical study and operationalised patterns},
	year = {2022},
	journal = {Proceedings - International Conference on Software Engineering},
	pages = {241 – 242},
	doi = {10.1109/ICSE-SEIP55303.2022.9793864},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132823818&doi=10.1109%2fICSE-SEIP55303.2022.9793864&partnerID=40&md5=08b040095394ccd2b2f8e2b2a1dc8a59},
	affiliations = {CSIRO, Australia},
	abstract = {AI ethics principles and guidelines are typically high-level and do not provide concrete guidance on how to develop responsible AI systems. To address this shortcoming, we perform an empirical study involving interviews with 21 scientists and engineers to understand the practitioners' views on AI ethics principles and their implementation. Our major findings are: (1) the current practice is often a done-once-and-forget type of ethical risk assessment at a particular development step, which is not sufficient for highly uncertain and continual learning AI systems; (2) ethical requirements are either omitted or mostly stated as high-level objectives, and not specified explicitly in verifiable way as system outputs or outcomes; (3) although ethical requirements have the characteristics of cross-cutting quality and non-functional requirements amenable to architecture and design analysis, system-level architecture and design are under-explored; (4) there is a strong desire for continuously monitoring and validating AI systems post deployment for ethical requirements but current operation practices provide limited guidance. To address these findings, we suggest a preliminary list of patterns to provide operationalised guidance for developing responsible AI systems.  © 2022 IEEE.},
	author_keywords = {AI; artificial intelligence; DevOps; ethics; machine learning; responsible AI; software architecture; software engineering},
	keywords = {Ethical technology; Learning systems; Machine learning; Risk assessment; AI systems; Continual learning; Cross-cutting; Current practices; Empirical studies; Machine-learning; Responsible AI; Risks assessments; Scientists and engineers; System output; Software architecture},
	publisher = {IEEE Computer Society},
	issn = {02705257},
	isbn = {978-166549590-5},
	coden = {PCSED},
	language = {English},
	abbrev_source_title = {Proc Int Conf Software Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 44th ACM/IEEE International Conference on Software Engineering: Software Engineering in Practice, ICSE-SEIP 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 180127; All Open Access, Green Open Access}
}

@ARTICLE{Shetty2022879,
	author = {Shetty, Anudeex and Raj, Nivesh},
	title = {A Study on Recent Advances in Artificial Intelligence and Future Prospects of Attaining Superintelligence},
	year = {2022},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {844},
	pages = {879 – 892},
	doi = {10.1007/978-981-16-8862-1_57},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127162294&doi=10.1007%2f978-981-16-8862-1_57&partnerID=40&md5=2dbdf14b54a610be073b60527e75f2a0},
	affiliations = {Computer Science and Engineering, Birla Institute of Technology, Ranchi, Mesra, India; Office of Sustainability, The Leadership 30, Mumbai, India},
	abstract = {By the year 2029, computers will be as intelligent as humans, and in 2045, computers will attain superintelligence and lead to the singularity, as per the futurist Ray Kurzweil. The same was echoed by Elon Musk, who predicted artificial intelligence to overtake the human race by 2025. Time travel between different points in space-time is through a time machine. Time machine bends space-time to invert timelines and form loops. Likewise, the machines can learn similarly to a child’s brain, i.e., by interacting with other objects in the environment and leveraging mental time travel and past experiences. This is feasible with the required hardware and appropriate programming. The computer acting as a time machine coupled with artificial intelligence (AI) might lead to superintelligence, and machines might take over humans. In this paper, we go through current and future AI systems coupled with time travel. We look at both recent and the path forward for software and hardware infrastructure progress. We also estimate the timeline when machines potentially could overtake humans (and performing almost all the work) by correlating AI market size and percentage of work done by machines along with experts’ opinion analysis. To conclude, we also provide few policies to avoid the potential AI apocalypse. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {AI ethics; Artificial intelligence; Machine learning; Moore’s law; Policy; Singularity; Special relativity; Superintelligence; Time machine; Time travel},
	keywords = {Computer hardware; Ethical technology; Machine learning; Artificial intelligence ethic; Future prospects; Human races; Moore’s law; Singularity; Spacetime; Special relativity; Superintelligence; Time machine; Time travel; Relativity},
	correspondence_address = {A. Shetty; Computer Science and Engineering, Birla Institute of Technology, Mesra, Ranchi, India; email: be10708.15@bitmesra.ac.in},
	editor = {Bindhu V. and Tavares J.M. and Du K.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18761100},
	isbn = {978-981168861-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Electr. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Communication, Computing and Electronics Systems, ICCCES 2021; Conference date: 28 October 2021 through 29 October 2021; Conference code: 275269}
}

@ARTICLE{Giloni20221,
	author = {Giloni, Amit and Grolman, Edita and Hagemann, Tanja and Fromm, Ronald and Fischer, Sebastian and Elovici, Yuval and Shabtai, Asaf},
	title = {BENN: Bias Estimation Using a Deep Neural Network},
	year = {2022},
	journal = {IEEE Transactions on Neural Networks and Learning Systems},
	pages = {1–15},
	doi = {10.1109/TNNLS.2022.3172365},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132518751&doi=10.1109%2fTNNLS.2022.3172365&partnerID=40&md5=e7475d311a833ca9561ded6f9e686d5f},
	affiliations = {Department of Software and Information Systems Engineering, Ben-Gurion University of the Negev, Be'er Sheva 8443944, Israel; Service Centric Networking Research Group, Technische Universit&#x00E4;t Berlin, 10623 Berlin, Germany; Deutsche Telekom AG, 10781 Bonn, Germany; Berlin School of Economics and Law, 10825 Berlin, Germany},
	abstract = {Utilizing existing methods for bias detection in machine learning (ML) models is challenging since each method: 1) explores a different ethical aspect of bias, which may result in contradictory output among the different methods; 2) provides output in a different range/scale and therefore cannot be compared with other methods; and 3) requires different input, thereby requiring a human expert's involvement to adjust each method according to the model examined. In this article, we present BENN, a novel bias estimation method that uses a pretrained unsupervised deep neural network. Given an ML model and data samples, BENN provides a bias estimation for every feature based on the examined model's predictions. We evaluated BENN using three benchmark datasets, one proprietary churn prediction model used by a European telecommunications company, and a synthetic dataset that includes both a biased feature and a fair one. BENN's results were compared with an ensemble of 21 existing bias estimation methods. The evaluation results show that BENN provides bias estimations that are aligned with those of the ensemble while offering significant advantages, including the fact that it is a generic approach (i.e., can be applied to any ML model) and does not require a domain expert. IEEE},
	author_keywords = {Bias estimation; Data models; deep neural network (DNN); Ethical aspects; Ethics; ethics; fairness estimation; Feature extraction; machine learning (ML); Maximum likelihood estimation; Neural networks; Predictive models; unsupervised learning.},
	keywords = {Estimation; Feature extraction; Maximum likelihood estimation; Philosophical aspects; Bias estimation; Deep neural network; Fairness estimation; Features extraction; Machine learning; Machine learning models; Maximum-likelihood estimation; Neural-networks; Predictive models; Unsupervised learning.; Deep neural networks},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {2162237X},
	language = {English},
	abbrev_source_title = {IEEE Trans. Neural Networks Learn. Sys.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Chatterjee2022719,
	author = {Chatterjee, Kausik and Buchanan, Alastair and Cottrell, Katy and Hughes, Sara and Day, Thomas W. and John, Nigel W.},
	title = {Immersive Virtual Reality for the Cognitive Rehabilitation of Stroke Survivors},
	year = {2022},
	journal = {IEEE Transactions on Neural Systems and Rehabilitation Engineering},
	volume = {30},
	pages = {719 – 728},
	doi = {10.1109/TNSRE.2022.3158731},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126277600&doi=10.1109%2fTNSRE.2022.3158731&partnerID=40&md5=f712e7ddedb42558215bbf82cce51302},
	affiliations = {Countess of Chester Hospital NHS Foundation Trust, Chester, CH2 1UL, United Kingdom; Cadscan Ltd., Chester, CH2 3AD, United Kingdom; Department of Computer Science, University of Chester, Chester, CH1 4BJ, United Kingdom},
	abstract = {We present the results of a double-blind phase 2b randomized control trial that used a custom built virtual reality environment for the cognitive rehabilitation of stroke survivors. A stroke causes damage to the brain and problem solving, memory and task sequencing are commonly affected. The brain can recover to some extent, however, and stroke patients have to relearn how to carry out activities of daily living. We have created an application called VIRTUE to enable such activities to be practiced using immersive virtual reality. Gamification techniques enhance the motivation of patients such as by making the level of difficulty of a task increase over time. The design and implementation of VIRTUE is described together with the results of the trial conducted within the Stroke Unit of a large hospital. We report on the safety and acceptability of VIRTUE. We have also observed particular benefits of VR treatment for stroke survivors that experienced more severe cognitive impairment, and an encouraging reduction in time spent in the hospital for all patients that received the VR treatment.  © 2001-2011 IEEE.},
	author_keywords = {cognitive rehabilitation; stroke recovery; Virtual reality},
	keywords = {Activities of Daily Living; Cognition; Humans; Stroke; Stroke Rehabilitation; Survivors; Virtual Reality; Virtual Reality Exposure Therapy; Brain; Job analysis; Patient rehabilitation; Patient treatment; Problem solving; Virtual reality; Cognitive rehabilitation; Game; Immersive virtual reality; Medical conditions; Resist; Sequential analysis; Stroke (medical condition); Stroke recovery; Stroke survivors; Task analysis; adult; aged; Article; automation; cerebrovascular accident; cognition; cognitive defect; cognitive rehabilitation; controlled study; double blind procedure; education; female; health care personnel; hospitalization; human; length of stay; machine learning; major clinical study; male; memory; nursing; pandemic; questionnaire; randomized controlled trial; sample size; sequence analysis; smoking; stroke rehabilitation; stroke survivor; stroke unit; structured questionnaire; terminal care; virtual reality; virtue ethics; visual acuity; cerebrovascular accident; daily life activity; procedures; psychology; stroke rehabilitation; survivor; virtual reality exposure therapy; Hospitals},
	correspondence_address = {N.W. John; Department of Computer Science, University of Chester, Chester, CH1 4BJ, United Kingdom; email: nigel.john@chester.ac.uk},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15344320},
	coden = {ITNSB},
	pmid = {35271448},
	language = {English},
	abbrev_source_title = {IEEE Trans. Neural Syst. Rehabil. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access}
}

@CONFERENCE{Mehta202210412,
	author = {Mehta, Ronak and Pal, Sourav and Singh, Vikas and Ravi, Sathya N.},
	title = {Deep Unlearning via Randomized Conditionally Independent Hessians},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {10412 – 10421},
	doi = {10.1109/CVPR52688.2022.01017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140409736&doi=10.1109%2fCVPR52688.2022.01017&partnerID=40&md5=a21d86d89b2cad1eb70646e639a2c22e},
	affiliations = {University of Wisconsin-Madison, United States; University of Illinois at Chicago, United States},
	abstract = {Recent legislation has led to interest in machine unlearning, i. e., removing specific training samples from a predictive model as if they never existed in the training dataset. Unlearning may also be required due to corrupted/adversarial data or simply a user's updated privacy requirement. For models which require no training (k-NN), simply deleting the closest original sample can be effective. But this idea is inapplicable to models which learn richer representations. Recent ideas leveraging optimization-based updates scale poorly with the model dimension d, due to inverting the Hessian of the loss function. We use a variant of a new conditional independence coefficient, L-CODEC, to identify a subset of the model parameters with the most semantic overlap on an individual sample level. Our approach completely avoids the need to invert a (possibly) huge matrix. By utilizing a Markov blanket selection, we premise that L-CODEC is also suitable for deep unlearning, as well as other applications in vision. Compared to alternatives, L-CODEC makes approximate unlearning possible in settings that would otherwise be infeasible, including vision models used for face recognition, person reidentification and NLP models that may require unlearning samples identified for exclusion. Code is available at https://github.com/vsingh-group/LCODEC-deep-unlearning © 2022 IEEE.},
	author_keywords = {accountability; fairness; Machine learning; Optimization methods; privacy and ethics in vision; Statistical methods; Transparency},
	keywords = {Face recognition; Nearest neighbor search; Accountability; Fairness; Machine-learning; Optimization method; Original sample; Predictive models; Privacy and ethic in vision; Privacy requirements; Training dataset; Training sample; Semantics},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Minoli2022121,
	author = {Minoli, Daniel and Koltun, Andrzej and Occhiogrosso, Benedict},
	title = {Situational Awareness for Law Enforcement and Public Safety Agencies Operating in Smart Cities – Part 1: Technologies},
	year = {2022},
	journal = {EAI/Springer Innovations in Communication and Computing},
	pages = {121 – 137},
	doi = {10.1007/978-3-030-84182-9_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131837645&doi=10.1007%2f978-3-030-84182-9_8&partnerID=40&md5=c6eea4c9639d3329f53d64d6bad6b3af},
	affiliations = {DVI Communications, New York, NY, United States},
	abstract = {This chapter and the one that follows discuss the use of Internet of Things (IoT) concepts, technologies, and processes, in support of situational awareness applications for law enforcement and public safety agencies operating in smart city environments. Situational awareness facilitates efficiently discerning the physical environment, knowing what is going on in the ecosystem under consideration. Typically, there are many actors, many events, many “moving parts,” many input sensors, and many stakeholders. Advanced analytics are needed to parse, analyze, and boil down, often in real time, the large dataset generated by the sensors, which often consists of extensive visual information of various types. Artificial intelligence methods are increasingly needed to enhance the cloud analytics’ ability to extract actionable information for law enforcement stakeholders within the timeframe of interest. Part 1 of this two-chapter set highlights a number of artificial intelligence methods that may be utilized by the situational awareness platforms that are being deployed at this time in the field. Part 2 of this two-chapter set discusses specific SA tool used by law enforcement and some practical challenges affecting the actual rollout of these platforms in urban and municipal police departments. Some ethics issues are also highlighted, along with a brief assessment of ongoing research in this fast-evolving field. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Always – on video; Analytics; Command center; Decision support; Deep learning; Machine learning; Situational awareness},
	keywords = {Decision support systems; Deep learning; Ethical technology; Internet of things; Large dataset; Smart city; Alway – on video; Analytic; Artificial intelligence methods; Command centres; Decision supports; Deep learning; Moving parts; Physical environments; Public safety agencies; Situational awareness; Law enforcement},
	correspondence_address = {D. Minoli; DVI Communications, New York, United States; email: daniel.minoli@dvicomm.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {25228595},
	language = {English},
	abbrev_source_title = {EAI/Springer Inno. Comm. Comp.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2022,
	title = {20th International Conference on Informatics in Economy, IE 2021},
	year = {2022},
	journal = {Smart Innovation, Systems and Technologies},
	volume = {276},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128966419&partnerID=40&md5=5478ec4b8360a1b774feb22d64c67d9d},
	abstract = {The proceedings contain 35 papers. The special focus in this conference is on Informatics in Economy. The topics include: Research on Data Analysis (Environmental, Social and Economic) in the Context of Implementing the Circular Economy; applying a Sustainable Vector Model to Generate Innovation; optimal Employment Contracts with Several Types of Agents; Labor Market Trends During the COVID-19 Pandemic; the Labor Market in Relation to Digitalization—Perspectives on the European Union; the Impact of Bitcoin in the Financial Market. A Cybernetics Approach; privacy-Preserving Framework for Deep Learning Cybersecurity Solutions; cyber Security Maturity Model for Critical Infrastructures; the Effectiveness of a Multimedia Mobile Application; A GIS-Based Approach in Support of Monitoring Sustainable Urban Consumption Variables; data Mining in Smart Agriculture; machine Learning and Data Mining Techniques for Human Resource Optimization Process—Employee Attrition; machine Learning Techniques for Network Intrusion Detection—A Systematic Analysis; web Scraping and Ethics in Automated Data Collection; classical Machine-Learning Classifiers to Predict Employee Turnover; assessing the Share of the Artificial Ad-Related Traffic: Some General Observations; experimental Results Regarding the Efficiency of Business Activities Through the Use of Chatbots; agile Perspectives in Higher Education; Digitalization of Business and Public Organizations—Communication Problems with IT Companies and Possible Solutions; an Analysis of Different Browser Attacks and Exploitation Techniques; an Assisted Instruction System Designed for Online Teaching and Learning; building Resilience Through Digital Transformation; visual Tool for Stimulating Employee Intelligent Attitude; management Information Systems in Knowledge Society; analyzing Business Performances with a Multicriteria Decision Method; a General Cost Model in a Cloud Data Center; preface.},
	editor = {Ciurea C. and Boja C. and Pocatilu P. and Doinea M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21903018},
	isbn = {978-981168865-2},
	language = {English},
	abbrev_source_title = {Smart Innov. Syst. Technol.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th International Conference on Informatics in Economy, IE 2021; Conference date: 14 May 2021 through 14 May 2021; Conference code: 276879}
}

@ARTICLE{Javed2022933,
	author = {Javed, Rana and Nasir, Osama and Borit, Melania and Vanhée, Loïs and Zea, Elias and Gupta, Shivam and Vinuesa, Ricardo and Qadir, Junaid},
	title = {Get out of the BAG! Silos in AI Ethics Education: Unsupervised Topic Modeling Analysis of Global AI Curricula},
	year = {2022},
	journal = {Journal of Artificial Intelligence Research},
	volume = {73},
	pages = {933 – 965},
	doi = {10.1613/jair.1.13550},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129577533&doi=10.1613%2fjair.1.13550&partnerID=40&md5=e92b95362ff6fee5a8faef2a0b1950c6},
	affiliations = {Information Technology University of the Punjab, Electrical Engineering Department, Arfa Software Technology Park, Ferozepur Road, Punjab, 142036, Pakistan; UiT the Arctic University of Norway, Norwegian College of Fisheries Science, Muninbakken 21, Tromsø, 9019, Norway; Umeå Universitet, Department of Computing Science, Linnaeus väg 49, Umeå, 907 36, Sweden; KTH Royal Institute of Technology, Department of Engineering Mechanics, Teknikringen 8, Stockholm, 100 44, Sweden; Bonn Alliance for Sustainability Research, University of Bonn, Regina-Pacis-Weg 3, Bonn, 53113, Germany; KTH Royal Institute of Technology, FLOW, Engineering Mechanics, Osquars backe 18, Stockholm, 100 44, Sweden; Computer Science and Engineering Department, Qatar University, Doha, 2713, Qatar},
	abstract = {The domain of Artificial Intelligence (AI) ethics is not new, with discussions going back at least 40 years. Teaching the principles and requirements of ethical AI to students is considered an essential part of this domain, with an increasing number of technical AI courses taught at several higher-education institutions around the globe including content related to ethics. By using Latent Dirichlet Allocation (LDA), a generative probabilistic topic model, this study uncovers topics in teaching ethics in AI courses and their trends related to where the courses are taught, by whom, and at what level of cognitive complexity and specificity according to Bloom's taxonomy. In this exploratory study based on unsupervised machine learning, we analyzed a total of 166 courses: 116 from North American universities, 11 from Asia, 36 from Europe, and 10 from other regions. Based on this analysis, we were able to synthesize a model of teaching approaches, which we call BAG (Build, Assess, and Govern), that combines specific cognitive levels, course content topics, and disciplines affiliated with the department(s) in charge of the course. We critically assess the implications of this teaching paradigm and provide suggestions about how to move away from these practices. We challenge teaching practitioners and program coordinators to reflect on their usual procedures so that they may expand their methodology beyond the confines of stereotypical thought and traditional biases regarding what disciplines should teach and how.  ©2022 AI Access Foundation. All rights reserved.},
	keywords = {Artificial intelligence; Curricula; Education computing; Statistics; Teaching; Artificial intelligence course; Bloom taxonomies; Cognitive complexity; Ethics education; Higher education institutions; Latent Dirichlet allocation; Modeling analyzes; Probabilistic topic models; Teaching ethics; Topic Modeling; Philosophical aspects},
	publisher = {AI Access Foundation},
	issn = {10769757},
	coden = {JAIRF},
	language = {English},
	abbrev_source_title = {J Artif Intell Res},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Hebbalaguppe202216060,
	author = {Hebbalaguppe, Ramya and Prakash, Jatin and Madan, Neelabh and Arora, Chetan},
	title = {A Stitch in Time Saves Nine: A Train-Time Regularizing Loss for Improved Neural Network Calibration},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {16060 – 16069},
	doi = {10.1109/CVPR52688.2022.01561},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139543511&doi=10.1109%2fCVPR52688.2022.01561&partnerID=40&md5=9bf3eb84caf28fd89a371977c493334d},
	affiliations = {Indian Institute of Technology Delhi, India; Tcs Research, India},
	abstract = {Deep Neural Networks (dnns) are known to make over-confident mistakes, which makes their use problematic in safety-critical applications. State-of-the-art (sota) calibration techniques improve on the confidence of predicted labels alone, and leave the confidence of non-max classes (e.g. top-2, top-5) uncalibrated. Such calibration is not suitable for label refinement using post-processing. Further, most sota techniques learn a few hyper-parameters post-hoc, leaving out the scope for image, or pixel specific calibration. This makes them unsuitable for calibration under domain shift, or for dense prediction tasks like semantic segmentation. In this paper, we argue for intervening at the train time itself, so as to directly produce calibrated dnn models. We propose a novel auxiliary loss function: Multi-class Difference in Confidence and Accuracy (mdca), to achieve the same. mdca can be used in conjunction with other application/task specific loss functions. We show that training with mdca leads to better calibrated models in terms of Expected Calibration Error (ece), and Static Calibration Error (sce) on image classification, and segmentation tasks. We report ece (sce) score of 0.72 (1.60) on the cifar 100 dataset, in comparison to 1.90 (1.71) by the sota. Under domain shift, a ResNet-18 model trained on pacs dataset using mdca gives a average ece (sce) score of 19.7 (9.7) across all domains, compared to 24.2 (11.8) by the sota. For segmentation task, we report a 2× reduction in calibration error on pascal-voc dataset in comparison to Focal Loss [32]. Finally, mdca training improves calibration even on imbalanced data, and for natural language classification tasks. © 2022 IEEE.},
	author_keywords = {accountability; fairness; Machine learning; privacy and ethics in vision; Representation learning; Transparency},
	keywords = {Computer vision; Deep neural networks; Errors; Safety engineering; Semantic Segmentation; A-train; Accountability; Calibration error; Fairness; Machine-learning; Neural-networks; Privacy and ethic in vision; Representation learning; State of the art; Static calibration; Semantics},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Xiao2022,
	author = {Xiao, Yineng},
	title = {Application of Machine Learning in Ethical Design of Autonomous Driving Crash Algorithms},
	year = {2022},
	journal = {Computational Intelligence and Neuroscience},
	volume = {2022},
	doi = {10.1155/2022/2938011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139481463&doi=10.1155%2f2022%2f2938011&partnerID=40&md5=36f5dfd6a62599f7f10c2d08ab915296},
	affiliations = {Advanced Institute of Information Technology, Peking University, Hangzhou, 311200, China},
	abstract = {The age of algorithms is here, and it is really changing people's lives. More and more ethical problems related to algorithms have attracted people's attention, but the related ethical research is still far behind the research of algorithms. As more intelligent algorithms emerge in an endless stream, there will also be a lot of algorithmic ethical issues. On the other hand, with the continuous improvement of the development level of the automobile industry, people have a stronger demand for the safety and stability of modern transportation, and more and more autonomous driving technology has been promoted and applied in the market. At present, most of the studies on the longitudinal collision avoidance system of vehicles use collision warning or emergency braking to avoid collision. However, when the vehicle is in a special situation such as high speed and slippery road, emergency steering is more effective. In order to further improve the vehicle safety and ethical algorithm design points, this article revolves around vehicle lateral active collision avoidance control method research, the collision avoidance decision-making, and path planning and collision avoidance transverse vehicle longitudinal motion control is analyzed, and based on automated driving simulation experiment, the tests carried out to verify the designed control strategy. The experimental results show that the proposed method not only has a good effect of preventing automatic driving collision but also can meet the requirements of algorithm ethics. This research can effectively guide the research of algorithmic ethics in the field of autonomous driving and effectively reduce the occurrence of traffic accidents.  © 2022 Yineng Xiao.},
	keywords = {Accidents, Traffic; Algorithms; Automobile Driving; Automobiles; Humans; Machine Learning; Accident prevention; Automobile drivers; Behavioral research; Collision avoidance; Decision making; Ethical technology; Machine learning; Motion planning; Vehicle safety; Algorithmics; Autonomous driving; Collisions avoidance; Continuous improvements; Ethical designs; Ethical issues; Ethical problems; Intelligent Algorithms; Machine-learning; Strong demand; algorithm; car; car driving; human; machine learning; prevention and control; traffic accident; Autonomous vehicles},
	correspondence_address = {Y. Xiao; Advanced Institute of Information Technology, Peking University, Hangzhou, 311200, China; email: xiaoyineng@pku.edu.cn},
	publisher = {Hindawi Limited},
	issn = {16875265},
	pmid = {36248938},
	language = {English},
	abbrev_source_title = {Comput. Intell. Neurosci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Ruiz20224135,
	author = {Ruiz, Nataniel and Kortylewski, Adam and Qiu, Weichao and Xie, Cihang and Bargal, Sarah Adel and Yuille, Alan and Sclaroff, Stan},
	title = {Simulated Adversarial Testing of Face Recognition Models},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {4135 – 4145},
	doi = {10.1109/CVPR52688.2022.00411},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130473612&doi=10.1109%2fCVPR52688.2022.00411&partnerID=40&md5=921b7e528f8a83064046e6f74b11b6fc},
	affiliations = {Boston University, United States; Johns Hopkins University, United States; Huawei; UC Santa Cruz, United States},
	abstract = {Most machine learning models are validated and tested on fixed datasets. This can give an incomplete picture of the capabilities and weaknesses of the model. Such weaknesses can be revealed at test time in the real world. The risks involved in such failures can be loss of profits, loss of time or even loss of life in certain critical applications. In order to alleviate this issue, simulators can be controlled in a finegrained manner using interpretable parameters to explore the semantic image manifold. In this work, we propose a framework for learning how to test machine learning algorithms using simulators in an adversarial manner in order to find weaknesses in the model before deploying it in critical scenarios. We apply this method in a face recognition setup. We show that certain weaknesses of models trained on real data can be discovered using simulated samples. Using our proposed method, we can find adversarial synthetic faces that fool contemporary face recognition models. This demonstrates the fact that these models have weaknesses that are not measured by commonly used validation datasets. We hypothesize that this type of adversarial examples are not isolated, but usually lie in connected spaces in the latent space of the simulator. We present a method to find these adversarial regions as opposed to the typical adversarial points found in the adversarial example literature. © 2022 IEEE.},
	author_keywords = {accountability; Adversarial attack and defense; Face and gestures; fairness; privacy and ethics in vision; Transparency},
	keywords = {Computer vision; Learning algorithms; Machine learning; Semantics; Simulators; Accountability; Adversarial attack and defense; Face and gesture; Fairness; Loss of time; Machine learning models; Privacy and ethic in vision; Real-world; Recognition models; Test time; Face recognition},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Jacob202257,
	author = {Jacob, Minu Susan and Selvi Rajendran, P.},
	title = {Deceptive Product Review Identification Framework Using Opinion Mining and Machine Learning},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {339},
	pages = {57 – 72},
	doi = {10.1007/978-981-16-7018-3_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126343624&doi=10.1007%2f978-981-16-7018-3_4&partnerID=40&md5=0e5800ce996553b2632a94da229d26a9},
	affiliations = {Department of Computer Science and Engineering, KCG College of Technology, Chennai, India},
	abstract = {Reviews of products are an integral part of the marketing and branding of online retailers. They help build trust and loyalty and generally define what separates the goods from others. The competition is so high that at times the company is forced to rely on the third party in producing deceptive reviews to influence readers’ opinions and hence to enhance the sales. This misleads the ethics and purpose of online shopping. This paper proposes a model to identify fake product reviews. The model uses Naive Bayes classifier and Support Vector Machine to classify the fake and genuine reviews. The model uses a set of parameters such as length of the review, usage of personal pronouns, nature of the review, verified purchase status, rating of the review and the type of the product to extract the features for the classification. The experimental results show that the model is working efficiently with a high classification accuracy rate. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Classification; Fake product review; Naive Bayes classifier; Opinion mining; Support vector machine},
	correspondence_address = {M.S. Jacob; Department of Computer Science and Engineering, KCG College of Technology, Chennai, India; email: minu.cse@kcgcollege.com},
	editor = {Marriwala N. and Tripathi C.C. and Jain S. and Kumar D.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-981167017-6},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2nd International Conference on Mobile Radio Communications and 5G Networks, MRCN 2021; Conference date: 10 June 2021 through 12 June 2021; Conference code: 274409}
}

@ARTICLE{Martinez-Martin202230,
	author = {Martinez-Martin, Nicole and Cho, Mildred K.},
	title = {Bridging the AI Chasm: Can EBM Address Representation and Fairness in Clinical Machine Learning?},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {30 – 32},
	doi = {10.1080/15265161.2022.2055212},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129030850&doi=10.1080%2f15265161.2022.2055212&partnerID=40&md5=44c967ee4ce1c15fb628353de786dd68},
	affiliations = {Stanford Center for Biomedical Ethics, United States; Stanford University, United States},
	keywords = {Delivery of Health Care; Ethics, Research; Health Facilities; Humans; Machine Learning; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {N. Martinez-Martin; Stanford, 1215 Welch Road, Modular A, 94305, United States; email: nicolemz@stanford.edu},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475967},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Lin202213719,
	author = {Lin, Wanyu and Lan, Hao and Wang, Hao and Li, Baochun},
	title = {OrphicX: A Causality-Inspired Latent Variable Model for Interpreting Graph Neural Networks},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {13719 – 13728},
	doi = {10.1109/CVPR52688.2022.01336},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139669080&doi=10.1109%2fCVPR52688.2022.01336&partnerID=40&md5=f6a4e638caef15840d8d513ea7cae98b},
	affiliations = {The Hong Kong Polytechnic University, Hong Kong; University of Toronto, Canada; Rutgers University, United States},
	abstract = {This paper proposes a new eXplanation framework, called OrphicX, for generating causal explanations for any graph neural networks (GNNs) based on learned latent causal factors. Specifically, we construct a distinct generative model and design an objective function that encourages the generative model to produce causal, compact, and faithful explanations. This is achieved by isolating the causal factors in the latent space of graphs by maximizing the information flow measurements. We theoretically analyze the cause-effect relationships in the proposed causal graph, identify node attributes as confounders between graphs and GNN predictions, and circumvent such confounder effect by leveraging the backdoor adjustment formula. Our framework is compatible with any GNNs, and it does not require access to the process by which the target GNN produces its predictions. In addition, it does not rely on the linear-independence assumption of the explained features, nor require prior knowledge on the graph learning tasks. We show a proof-of-concept of OrphicX on canonical classification problems on graph data. In particular, we analyze the explanatory subgraphs obtained from explanations for molecular graphs (i.e., Mutag) and quantitatively evaluate the explanation performance with frequently occurring subgraph patterns. Empirically, we show that OrphicX can effectively identify the causal semantics for generating causal explanations, significantly outperforming its alternatives11This project is supported by the Internal Research Fund at The Hong Kong Polytechnic University P0035763. HW is partially supported by NSF Grant IIS-2127918 and an Amazon Faculty Research Award.. © 2022 IEEE.},
	author_keywords = {accountability; Explainable computer vision; fairness; Machine learning; privacy and ethics in vision; Statistical methods; Transparency},
	keywords = {Computer vision; Data privacy; Flow graphs; Graph structures; Graphic methods; Semantics; Accountability; Causal explanations; Confounder; Explainable computer vision; Fairness; Generative model; Graph neural networks; Machine-learning; Privacy and ethic in vision; Subgraphs; Graph neural networks},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{2022,
	title = {45th German Conference on Artificial Intelligence, KI 2022},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13404 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138789199&partnerID=40&md5=219ff74856a79897c186aef913ed5260},
	abstract = {The proceedings contain 17 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Optimal Fixed-Premise Repairs of EL TBoxes; health and Habit: An Agent-based Approach; knowledge Graph Embeddings with Ontologies: Reification for Representing Arbitrary Relations; solving the Traveling Salesperson Problem with Precedence Constraints by Deep Reinforcement Learning; HanKA: Enriched Knowledge Used by an Adaptive Cooking Assistant; automated Kantian Ethics: A Faithful Implementation; PEBAM: A Profile-Based Evaluation Method for Bias Assessment on Mixed Datasets; leveraging Implicit Gaze-Based User Feedback for Interactive Machine Learning; the Randomness of Input Data Spaces is an A Priori Predictor for Generalization; communicating Safety of Planned Paths via Optimally-Simple Explanations; assessing the Performance Gain on Retail Article Categorization at the Expense of Explainability and Resource Efficiency; enabling Supervised Machine Learning Through Data Pooling: A Case Study with Small and Medium-Sized Enterprises in the Service Industry; unsupervised Alignment of Distributional Word Embeddings; NeuralPDE: Modelling Dynamical Systems from Data; deep Neural Networks for Geometric Shape Deformation.},
	editor = {Bergmann R. and Malburg L. and Rodermund S.C. and Timm I.J.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303115790-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 45th German Conference on Artificial Intelligence, KI 2022; Conference date: 19 September 2022 through 23 September 2022; Conference code: 283499}
}

@CONFERENCE{Sirotkin202210432,
	author = {Sirotkin, Kirill and Carballeira, Pablo and Escudero-Vinolo, Marcos},
	title = {A study on the distribution of social biases in self-supervised learning visual models},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {10432 – 10441},
	doi = {10.1109/CVPR52688.2022.01019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140399130&doi=10.1109%2fCVPR52688.2022.01019&partnerID=40&md5=b2a542b4f8f5c67fab30203087a81669},
	affiliations = {Univ. Autónoma de Madrid, Video Processing and Understanding Lab, Madrid, 28049, Spain},
	abstract = {Deep neural networks are efficient at learning the data distribution if it is sufficiently sampled. However, they can be strongly biased by non-relevant factors implicitly incorporated in the training data. These include operational biases, such as ineffective or uneven data sampling, but also ethical concerns, as the social biases are implicitly present - even inadvertently, in the training data or explicitly defined in unfair training schedules. In tasks having impact on human processes, the learning of social biases may produce discriminatory, unethical and untrustworthy consequences. It is often assumed that social biases stem from supervised learning on labelled data, and thus, Self-Supervised Learning (SSL) wrongly appears as an efficient and bias-free solution, as it does not require labelled data. However, it was recently proven that a popular SSL method also incorporates biases. In this paper, we study the biases of a varied set of SSL visual models, trained using ImageNet data, using a method and dataset designed by psychological experts to measure social biases. We show that there is a correlation between the type of the SSL model and the number of biases that it incorporates. Furthermore, the results also suggest that this number does not strictly depend on the model's accuracy and changes throughout the network. Finally, we conclude that a careful SSL model selection process can reduce the number of social biases in the deployed model, whilst keeping high performance. The code is available at https://github.com/vpulab/SB-SSL. © 2022 IEEE.},
	author_keywords = {accountability; Computer vision for social good; fairness; Machine learning; privacy and ethics in vision; Self- & semi- & meta- Transfer/low-shot/long-tail learning; Transparency},
	keywords = {Deep neural networks; Ethical technology; Supervised learning; Accountability; Computer vision for social good; Fairness; Labeled data; Long tail; Machine-learning; Privacy and ethic in vision; Self- & semi- & meta- transfer/low-shot/long-tail learning; Training data; Visual model; Computer vision},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{2022,
	title = {23rd IFIP WG 5.5 Working Conference on Virtual Enterprises, PRO-VE 2022},
	year = {2022},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {662 IFIP},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139063416&partnerID=40&md5=4f9027e4d4b77ba9ce45afe9bd3cbe9e},
	abstract = {The proceedings contain 55 papers. The special focus in this conference is on Virtual Enterprises. The topics include: The Business Ecosystem Perspective in Digital Strategies; improving Forecasting Capability and Capacity Utilization in Less Digitized Industries Through Participation in the Platform Economy; a Framework for Collaborative Virtual Power Plant Ecosystem; from Digitization to Digital Collaborative Service Designs: A Systematic Literature Review on the Categories, Concepts and Constructs of Industry 5.0; customer-Centric Service Design: Featuring Service Use in Life Practices; designing Smart Products for Industry 4.0 – An Information Systems Architecture Prototype; design of a Virtual Platform to Counter Economic Recession; enterprise Integration and Interoperability in the Footwear Industry: Challenges for Collaborative Digital Manufacturing Networks in Society 5.0; collaborative Management of Traffic Accidents Data for Social Impact Analytics; Knowledge-Driven Data Provision to Enhance Smart Manufacturing – A Case Study in Swedish Manufacturing SME; characterization of the Spatiotemporal Behavior of a Sweeping System Using Supervised Machine Learning Enhanced with Feature Engineering; using Evolutionary Algorithms to Promote Sustainable Collaboration Networks Through Partner Selection; Maturity of Artificial Intelligence in SMEs: Privacy and Ethics Dimensions; Process Wins and Losses in Dynamic Human-AI Interplay - A Socio-psychological Research Perspective on Collaborative Performance; collaborative System for Question Answering in German Case Law Documents; How Does the Implementation of AI Agents Affect Human Agents’ Job Profiles? Insights from Two Industrial Cases; The Social Perception of Robots Scale (SPRS): Developing and Testing a Scale for Successful Interaction Between Humans and Robots; a Semantic-Based Collaborative Ambient-Assisted Working Framework.},
	editor = {Camarinha-Matos L.M. and Ortiz A. and Boucher X. and Osório A.L.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303114843-9},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 23rd IFIP WG 5.5 Working Conference on Virtual Enterprises, PRO-VE 2022; Conference date: 19 September 2022 through 21 September 2022; Conference code: 283069}
}

@CONFERENCE{Yi202216661,
	author = {Yi, Li and Liu, Sheng and She, Qi and McLeod, A. Ian and Wang, Boyu},
	title = {On Learning Contrastive Representations for Learning with Noisy Labels},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {16661 – 16670},
	doi = {10.1109/CVPR52688.2022.01618},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134066868&doi=10.1109%2fCVPR52688.2022.01618&partnerID=40&md5=5243f0a14967852be84389ecc16c7642},
	affiliations = {University of Western Ontario, Canada; NYU Center for Data Science, United States; ByteDance Inc; Vector Institute},
	abstract = {Deep neural networks are able to memorize noisy labels easily with a softmax cross entropy (CE) loss. Previous studies attempted to address this issue focus on incorporating a noise-robust loss function to the CE loss. However, the memorization issue is alleviated but still remains due to the non-robust CE loss. To address this issue, we focus on learning robust contrastive representations of data on which the classifier is hard to memorize the label noise under the CE loss. We propose a novel contrastive regularization function to learn such representations over noisy data where label noise does not dominate the representation learning. By theoretically investigating the representations induced by the proposed regularization function, we reveal that the learned representations keep information related to true labels and discard information related to corrupted labels. Moreover, our theoretical results also indicate that the learned representations are robust to the label noise. The effectiveness of this method is demonstrated with experiments on benchmark datasets. © 2022 IEEE.},
	author_keywords = {accountability; Deep learning architectures and techniques; fairness; Machine learning; privacy and ethics in vision; Representation learning; Transparency},
	keywords = {Computer vision; Accountability; Cross entropy; Deep learning architecture and technique; Entropy loss; Fairness; Learning architectures; Learning techniques; Machine-learning; Privacy and ethic in vision; Representation learning; Deep neural networks},
	correspondence_address = {B. Wang; University of Western Ontario, Canada; email: bwang@csd.uwo.ca},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Cover2022609,
	author = {Cover, Rob},
	title = {Deepfake culture: the emergence of audio-video deception as an object of social anxiety and regulation},
	year = {2022},
	journal = {Continuum},
	volume = {36},
	number = {4},
	pages = {609 – 621},
	doi = {10.1080/10304312.2022.2084039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131626724&doi=10.1080%2f10304312.2022.2084039&partnerID=40&md5=b86ac295d6ddf6274db09406959b6572},
	affiliations = {School of Media and Communication, RMIT University, Melbourne,Sydney, Australia},
	abstract = {Deepfakes draw on algorithmic powers, machine learning and modern capabilities for processing information to allow users to insert the face, body, and visual information about a real-world person into a false setting, producing highly convincing videos that appear to be a ‘true’ record. Emerging on the scene in the past half-decade, deepfake applications have become an object of widespread social concern and calls for regulation, ostensibly to prevent electoral fraud, defamatory misuse, the pornographisation of public figures and to restore a sense of veracity to texts and communication. This paper addresses deepfakes from a cultural studies standpoint, asking what happens if we shift away from perceiving the technology as having a negative impact and, instead, appreciating it as a cultural technology constituted in widespread shifts in the cultural sense of texts, representation, play, co-creativity and pastiche. In doing so, the paper uses cultural theory to address three points: the cultivation of the deepfake in older communication practices, the ways in which it enters public debate as an object of social concern and, finally, how calls for the regulation of deepfake technologies and products misses an opportunity to reassess the cultural ethics of communication. © 2022 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {cultural technologies; Deepfake; media ethics; Raymond Williams; regulation},
	correspondence_address = {R. Cover; School of Media and Communication, RMIT University, Melbourne,Sydney, Australia; email: rob.cover@rmit.edu.au},
	publisher = {Routledge},
	issn = {10304312},
	language = {English},
	abbrev_source_title = {Continuum},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Xu2022,
	author = {Xu, Xin and Xiong, Feng and An, Zhe},
	title = {Using Machine Learning to Predict Corporate Fraud: Evidence Based on the GONE Framework},
	year = {2022},
	journal = {Journal of Business Ethics},
	doi = {10.1007/s10551-022-05120-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128702443&doi=10.1007%2fs10551-022-05120-2&partnerID=40&md5=13527ce937615219eac4b36b1a123bd8},
	affiliations = {Department of Accounting, School of Management, Xiamen University, Siming South Rd. 422, Fujian Province, Xiamen, 361005, China; Center for Accounting Studies of Xiamen University, Department of Accounting, School of Management, Xiamen University, Siming South Rd. 422, Fujian Province, Xiamen, 361005, China; Department of Banking and Finance, Monash Business School, Monash University, Melbourne, 3800, VIC, Australia},
	abstract = {This study focuses on a traditional business ethics question and aims to use advanced techniques to improve the performance of corporate fraud prediction. Based on the GONE framework, we adopt the machine learning model to predict the occurrence of corporate fraud in China. We first identify a comprehensive set of fraud-related variables and organize them into each category (i.e., Greed, Opportunity, Need, and Exposure) of the GONE framework. Among the six machine learning models tested, the Random Forest (RF) model outperforms the other five models in corporate fraud prediction. Based on the RF model, we show that Exposure variables play a more important role in predicting corporate fraud than other input variables. These results highlight the importance of Exposure variables in corporate fraud prediction and promote the practical use of the machine learning model in solving business ethics questions. © 2022, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Corporate Fraud; GONE; Machine Learning},
	correspondence_address = {F. Xiong; Center for Accounting Studies of Xiamen University, Department of Accounting, School of Management, Xiamen University, Xiamen, Siming South Rd. 422, Fujian Province, 361005, China; email: xiongfeng@xmu.edu.cn},
	publisher = {Springer Science and Business Media B.V.},
	issn = {01674544},
	language = {English},
	abbrev_source_title = {J. Bus. Ethics},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Refolo20226418,
	author = {Refolo, P. and Sacchini, D. and Raimondi, C. and Spagnolo, A.G.},
	title = {Ethics of digital therapeutics (DTx)},
	year = {2022},
	journal = {European Review for Medical and Pharmacological Sciences},
	volume = {26},
	number = {18},
	pages = {6418 – 6423},
	doi = {10.26355/eurrev_202209_29741},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139572950&doi=10.26355%2feurrev_202209_29741&partnerID=40&md5=367121b5e3aad3fe3f59d141767a338d},
	affiliations = {Fondazione Policlinico Universitario “A. Gemelli” IRCCS, Rome (Italy); Department of Healthcare Surveillance and Bioethics, Università Cattolica del Sacro Cuore, Rome, Italy},
	abstract = {Digital therapeutics (DTx) are a subset of digital health which are often coupled with artificial intelligence (A.I.) techniques and machine learning systems. DTx differ from common wellness apps or medication reminder tools in that they require “rigorous” clinical evidence. They are emerging as a new treatment option and are being applied in a variety of areas, including type II diabetes, hypertension, chronic respiratory problems, obesity, insomnia, Alzheimer’s disease, various types of dementia or addiction (smoking, alcohol, drugs), anxiety, depression, autism, learning disabilities, and attention deficits. Today, there are roughly 35 to 40 products on the market, 8 of which approved by regulatory agencies. The value of the global DTx market was estimated at USD 1.8 billion in 2018, and it is expected to reach USD 8.9 billion by 2027. Implementing DTx across healthcare systems raises a number of ethical concerns. The present article aims to provide an overview of the main ethical issues pertaining the assessment, implementation, and use of this emerging technology. The final purpose is to support and facilitate an open and transparent deliberation with regard to DTx. © 2022 Verduci Editore s.r.l. All rights reserved.},
	author_keywords = {Artificial intelligence; Decision-making; Deliberation; Digital therapeutic (DT); Ethics},
	keywords = {Anxiety; Artificial Intelligence; Delivery of Health Care; Diabetes Mellitus, Type 2; Humans; Hypertension; alcoholism; Alzheimer disease; anxiety disorder; Article; autism; chronic respiratory tract disease; decision making; dementia; depression; digital therapeutics; drug dependence; ethics; health care planning; health care system; human; hypertension; insomnia; learning disorder; market; non insulin dependent diabetes mellitus; obesity; technology; therapy; anxiety; artificial intelligence; health care delivery; hypertension; non insulin dependent diabetes mellitus},
	correspondence_address = {D. Sacchini; email: dario.sacchini@unicatt.it},
	publisher = {Verduci Editore s.r.l},
	issn = {11283602},
	coden = {RESFD},
	pmid = {36196692},
	language = {English},
	abbrev_source_title = {Eur. Rev. Med. Pharmacol. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Mirsky20221278,
	author = {Mirsky, Reuth and Baraka, Kim and Faulkner, Taylor Kessler and Hart, Justin and Yedidsion, Harel and Xiao, Xuesu},
	title = {Human-Interactive Robot Learning (HIRL)},
	year = {2022},
	journal = {ACM/IEEE International Conference on Human-Robot Interaction},
	volume = {2022-March},
	pages = {1278 – 1280},
	doi = {10.1109/HRI53351.2022.9889551},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140748905&doi=10.1109%2fHRI53351.2022.9889551&partnerID=40&md5=dedca1ee131d108edfb26c87c194c772},
	affiliations = {The University of Texas at Austin, United States; Bar Ilan University, Israel; Vrije Universiteit Amsterdam, Netherlands; Applied Materials, United States; X the Moonshot Factory, United States},
	abstract = {With robots poised to enter our daily environments, we conjecture that they will not only need to work for people, but also learn from them. An active area of investigation in the robotics, machine learning, and human-robot interaction communities is the design of teachable robotic agents that can learn interactively from human input. To refer to these research efforts, we use the umbrella term Human-Interactive Robot Learning (HIRL). While algorithmic solutions for robots learning from people have been investigated in a variety of ways, HIRL, as a fairly new research area, is still lacking: 1) a formal set of definitions to classify related but distinct research problems or solutions, 2) benchmark tasks, interactions, and metrics to evaluate the performance of HIRL algorithms and interactions, and 3) clear long-term research challenges to be addressed by different communities. The main goal of this workshop will be to consolidate relevant recent work falling under the HIRL umbrella into a coherent set of long, medium, and short-term research problems, and identify the most pressing future research goals in this area. As HIRL is a developing research area, this workshop is an opportunity to break the existing boundaries between relevant research communities by developing and sharing a diverse set of benchmark tasks and metrics for HIRL, inspired by other fields including neuroscience, biology, and ethics research. © 2022 IEEE.},
	author_keywords = {Interactive robot learning; Learning from human input; Socially intelligent robots; Socially interactive learning},
	keywords = {Benchmarking; Human robot interaction; Learning algorithms; Learning systems; Machine design; Human interactive robots; Interactive learning; Interactive robot; Interactive robot learning; Learn+; Learning from human input; Research areas; Research problems; Socially intelligent robot; Socially interactive learning; Intelligent robots},
	publisher = {IEEE Computer Society},
	issn = {21672148},
	isbn = {978-153868554-9},
	language = {English},
	abbrev_source_title = {ACM/IEEE Int. Conf. Hum.-Rob. Interact.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 17th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2022; Conference date: 7 March 2022 through 10 March 2022; Conference code: 183332}
}

@CONFERENCE{Pokrovskaia2022240,
	author = {Pokrovskaia, Nadezhda N.},
	title = {Sociocultural and Information Security Issues in the Implementation of Neural Network Technologies in Chat-bots Design},
	year = {2022},
	journal = {Proceedings of 2022 25th International Conference on Soft Computing and Measurements, SCM 2022},
	pages = {240 – 243},
	doi = {10.1109/SCM55405.2022.9794852},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133398730&doi=10.1109%2fSCM55405.2022.9794852&partnerID=40&md5=0e50e33aebd0652d4b58666471949976},
	affiliations = {Saint Petersburg Electrotechnical University LETI, Innovation Management Department, Saint Petersburg, Russian Federation},
	abstract = {Neural networks are trained on actual material. People in their communication use both socio-cultural rules of courtesy and good taste, and take into account threats to protect data, based on long-Term experience and long-Term risk prediction. Human behavior provides neural networks with examples of both appropriate behavior and manners with limited application depending on the context, as well as unacceptable and unacceptable behaviors, such as rude emotional discharge or information disclosure in associated metadata. Based on the analysis of several cases of the implementation and functioning of chatbots, the main groups of ethical problems and the main tasks in the field of information security are shown, key approaches to ensuring etiquette and data protection are identified, and proposals are formulated for procedures for machine learning in relation to chatbots in corporate ecosystems.  © 2022 IEEE.},
	author_keywords = {bot; chat bot; data protection; digital transformation; ecosystem; ethics; information security; neural network; procedures; regulation; sociocultural regulation},
	keywords = {Behavioral research; Data privacy; Ecosystems; Ethical technology; Network security; Bot; Chat bots; Chatbots; Digital transformation; Network technologies; Neural-networks; Procedure; Regulation; Security issues; Sociocultural regulation; Metadata},
	correspondence_address = {N.N. Pokrovskaia; Saint Petersburg Electrotechnical University LETI, Innovation Management Department, Saint Petersburg, Russian Federation; email: nnp@spbstu.ru},
	editor = {Shaposhnikov S. and Saint Petersburg Electrotechnical University "LETI", Prof. Popov Str. 5, Saint Petersburg},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166549669-8},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Soft Comput. Meas., SCM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 25th International Conference on Soft Computing and Measurements, SCM 2022; Conference date: 25 May 2022 through 27 May 2022; Conference code: 180133}
}

@ARTICLE{Ejaz2022,
	author = {Ejaz, Hamza and McGrath, Hari and Wong, Brian LH and Guise, Andrew and Vercauteren, Tom and Shapey, Jonathan},
	title = {Artificial intelligence and medical education: A global mixed-methods study of medical students’ perspectives},
	year = {2022},
	journal = {Digital Health},
	volume = {8},
	doi = {10.1177/20552076221089099},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129708141&doi=10.1177%2f20552076221089099&partnerID=40&md5=24cad2b29feb280821cc1f24a4cd1bb0},
	affiliations = {Norwich Medical School, University of East Anglia, United Kingdom; Psychological and Behavioural Sciences, London School of Economics, United Kingdom; GKT School of Medical Education, King’s College London, United Kingdom; Department of Neurosurgery, Yale University School of Medicine, New Haven, CT, United States; Department of International Health, Care and Public Health Research Institute, Maastricht University, Maastricht, Netherlands; Secretariat, the Lancet and Financial Times Commission on Governing Health Futures 2030, Global Health Centre, The Graduate Institute, Geneva, 1211, Switzerland; Steering Committee, Digital Health Section, European Public Health Association (EUPHA), Utrecht, Netherlands; School of Population Health and Environmental Sciences, King’s College London, United Kingdom; School of Biomedical Engineering and Imaging Sciences, King’s College London, United Kingdom; Department of Neurosurgery, King’s College Hospital, London, United Kingdom},
	abstract = {Objective: Medical students, as clinicians and healthcare leaders of the future, are key stakeholders in the clinical roll-out of artificial intelligence-driven technologies. The authors aim to provide the first report on the state of artificial intelligence in medical education globally by exploring the perspectives of medical students. Methods: The authors carried out a mixed-methods study of focus groups and surveys with 128 medical students from 48 countries. The study explored knowledge around artificial intelligence as well as what students wished to learn about artificial intelligence and how they wished to learn this. A combined qualitative and quantitative analysis was used. Results: Support for incorporating teaching on artificial intelligence into core curricula was ubiquitous across the globe, but few students had received teaching on artificial intelligence. Students showed knowledge on the applications of artificial intelligence in clinical medicine as well as on artificial intelligence ethics. They were interested in learning about clinical applications, algorithm development, coding and algorithm appraisal. Hackathon-style projects and multidisciplinary education involving computer science students were suggested for incorporation into the curriculum. Conclusions: Medical students from all countries should be provided teaching on artificial intelligence as part of their curriculum to develop skills and knowledge around artificial intelligence to ensure a patient-centred digital future in medicine. This teaching should focus on the applications of artificial intelligence in clinical medicine. Students should also be given the opportunity to be involved in algorithm development. Students in low- and middle-income countries require the foundational technology as well as robust teaching on artificial intelligence to ensure that they can drive innovation in their healthcare settings. © The Author(s) 2022.},
	author_keywords = {automation; Digital; education; machine learning; medicine},
	correspondence_address = {H. Ejaz; Norwich Medical School, University of East Anglia, United Kingdom; email: H.Ejaz@uea.ac.uk},
	publisher = {SAGE Publications Inc.},
	issn = {20552076},
	language = {English},
	abbrev_source_title = {Digit. Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Meier20224,
	author = {Meier, Lukas J. and Hein, Alice and Diepold, Klaus and Buyx, Alena},
	title = {Algorithms for Ethical Decision-Making in the Clinic: A Proof of Concept},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {7},
	pages = {4 – 20},
	doi = {10.1080/15265161.2022.2040647},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126689773&doi=10.1080%2f15265161.2022.2040647&partnerID=40&md5=2f398a28a3a6cd313c422549614e4349},
	affiliations = {Technical University of Munich, Germany; University of Cambridge, United Kingdom},
	abstract = {Machine intelligence already helps medical staff with a number of tasks. Ethical decision-making, however, has not been handed over to computers. In this proof-of-concept study, we show how an algorithm based on Beauchamp and Childress’ prima-facie principles could be employed to advise on a range of moral dilemma situations that occur in medical institutions. We explain why we chose fuzzy cognitive maps to set up the advisory system and how we utilized machine learning to train it. We report on the difficult task of operationalizing the principles of beneficence, non-maleficence and patient autonomy, and describe how we selected suitable input parameters that we extracted from a training dataset of clinical cases. The first performance results are promising, but an algorithmic approach to ethics also comes with several weaknesses and limitations. Should one really entrust the sensitive domain of clinical ethics to machine intelligence?. © 2022 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	author_keywords = {Algorithms; artificial intelligence; Beauchamp and Childress; clinical ethics; decision-making; machine learning},
	keywords = {Algorithms; Beneficence; Ethics, Clinical; Humans; Personal Autonomy; adult; algorithm; article; artificial intelligence; beneficence; cognitive map; decision making; ethical decision making; ethical dilemma; ethics; human; machine learning; nonmaleficence; patient autonomy; proof of concept; algorithm; beneficence; medical ethics; personal autonomy},
	correspondence_address = {L.J. Meier; Institute of History and Ethics in Medicine, Technical University of Munich, München, Ismaninger Strasse 22, 81675, Germany; email: ljm204@cam.ac.uk},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35293841},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Castelli202243,
	author = {Castelli, Maximilian and Moreau, Linda C.},
	title = {The Cycle of Trust and Responsibility in Outsourced AI},
	year = {2022},
	journal = {TrustNLP 2022 - 2nd Workshop on Trustworthy Natural Language Processing, Proceedings of the Workshop},
	pages = {43 – 48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139448020&partnerID=40&md5=8b41a6841d4b337f16b2c51609efcca8},
	affiliations = {Amazon, Herndon, VA, United States},
	abstract = {Artificial Intelligence (AI) and Machine Learning (ML) are rapidly becoming must-have capabilities. According to a 2019 Forbes Insights Report, “seventy-nine percent [of executives] agree that AI is already having a transformational impact on workflows and tools for knowledge workers, but only 5% of executives consider their companies to be industry-leading in terms of taking advantage of AI-powered processes.” (Forbes 2019) A major reason for this may be a shortage of on-staff expertise in AI/ML. This paper explores the intertwined issues of trust, adoption, training, and ethics of outsourcing AI development to a third party. We describe our experiences as a provider of outsourced natural language processing (NLP). We discuss how trust and accountability co-evolve as solutions mature from proof-of-concept to production-ready. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Learning algorithms; Natural language processing systems; Outsourcing; Artificial intelligence learning; Knowledge workers; Language processing; Machine-learning; Natural languages; Proof of concept; Third parties; Transformational impacts; Work-flows; Artificial intelligence},
	editor = {Verma A. and Pruksachatkun Y. and Chang K.-W. and Galstyan A. and Dhamala J. and Cao Y.T.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {978-195591778-0},
	language = {English},
	abbrev_source_title = {TrustNLP - Workshop Trustworthy Nat. Lang. Process., Proc. Workshop},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd Workshop on Trustworthy Natural Language Processing, TrustNLP 2022; Conference date: 14 July 2022; Conference code: 182705}
}

@ARTICLE{Gumusel2022185,
	author = {Gumusel, Ece and Malic, Vincent Quirante and Donaldson, Devan Ray and Ashley, Kevin and Liu, Xiaozhong},
	title = {An Annotation Schema for the Detection of Social Bias in Legal Text Corpora},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13192 LNCS},
	pages = {185 – 194},
	doi = {10.1007/978-3-030-96957-8_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126213057&doi=10.1007%2f978-3-030-96957-8_17&partnerID=40&md5=f5165c6f0934d46259bb913212c8b52b},
	affiliations = {Indiana University Bloomington, Bloomington, United States; University of Pittsburgh, Pittsburgh, United States},
	abstract = {The rapid advancement of artificial intelligence in recent years has led to an increase in its use in legal contexts. At the same time, a growing body of research has expressed concerns that AI trained on large datasets may learn and model undesirable social biases. In this paper, we investigate the extent to which such social biases are inherent in a real-world legal corpus. We train a word2vec word embedding model on case law data and find evidence that NLP methods make undesirable distinctions between legally equivalent entities that vary only by race. Since legal AI applications that model such distinctions risk perpetuating these inequalities when used, we argue that the development of such applications must incorporate a means to detect and mitigate such biases. To this end, we propose an annotation schema that identifies and categorizes deviations from legal equivalence, so that debiasing may be more systematically incorporated into legal AI development. Future directions for research are discussed. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Information ethics; Machine learning; Natural language processing},
	keywords = {Large dataset; Learning algorithms; Natural language processing systems; Embeddings; Growing bodies; Information ethics; Large datasets; Learn+; Legal contexts; Legal corpus; Legal texts; Real-world; Text corpora; Machine learning},
	correspondence_address = {E. Gumusel; Indiana University Bloomington, Bloomington, United States; email: egumusel@iu.edu},
	editor = {Smits M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303096956-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 17th International Conference on Information for a Better World: Shaping the Global Future, iConference 2022; Conference date: 28 February 2022 through 4 March 2022; Conference code: 273989}
}

@CONFERENCE{Zhang20225787,
	author = {Zhang, Baobao and Anderljung, Markus and Kahn, Lauren and Dreksler, Noemi and Horowitz, Michael C. and Dafoe, Allan},
	title = {Ethics and Governance of Artificial Intelligence: A Survey of Machine Learning Researchers (Extended Abstract)},
	year = {2022},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	pages = {5787 – 5791},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137851263&partnerID=40&md5=884dd21497a967c5a14d33889ac20351},
	affiliations = {Syracuse University, United States; Centre for the Governance of AI; Council on Foreign Relations; University of Pennsylvania, United States; DeepMind},
	abstract = {Machine learning (ML) and artificial intelligence (AI) researchers play an important role in the ethics and governance of AI, including through their work, advocacy, and choice of employment. Nevertheless, this influential group's attitudes are not well understood, undermining our ability to discern consensuses or disagreements between AI/ML researchers. To examine these researchers' views, we conducted a survey of those who published in two top AI/ML conferences (N = 524). We compare these results with those from a 2016 survey of AI/ML researchers and a 2018 survey of the US public. We find that AI/ML researchers place high levels of trust in international organizations and scientific organizations to shape the development and use of AI in the public interest; moderate trust in most Western tech companies; and low trust in national militaries, Chinese tech companies, and Facebook. While the respondents were overwhelmingly opposed to AI/ML researchers working on lethal autonomous weapons, they are less opposed to researchers working on other military applications of AI, particularly logistics algorithms. A strong majority of respondents think that AI safety research should be prioritized more and a majority that ML institutions should conduct pre-publication review to assess potential harms. Being closer to the technology itself, AI/ML researchers are well placed to highlight new risks and develop technical solutions, so this novel data has broad relevance. The findings should help to improve how researchers, private sector executives, and policymakers think about regulations, governance frameworks, guiding principles, and national and international governance strategies for AI. © 2022 International Joint Conferences on Artificial Intelligence. All rights reserved.},
	keywords = {Ethical technology; Machine learning; Military applications; Extended abstracts; Facebook; International organizations; Machine-learning; Policy makers; Potential harm; Private sectors; Public interest; Safety research; Technical solutions; Surveys},
	editor = {De Raedt L. and De Raedt L.},
	publisher = {International Joint Conferences on Artificial Intelligence},
	issn = {10450823},
	isbn = {978-195679200-3},
	language = {English},
	abbrev_source_title = {IJCAI Int. Joint Conf. Artif. Intell.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 31st International Joint Conference on Artificial Intelligence, IJCAI 2022; Conference date: 23 July 2022 through 29 July 2022; Conference code: 182301}
}

@ARTICLE{Nakashima2022,
	author = {Nakashima, Heitor Hoffman and Mantovani, Daielly and Machado Junior, Celso},
	title = {Users’ trust in black-box machine learning algorithms},
	year = {2022},
	journal = {Revista de Gestao},
	doi = {10.1108/REGE-06-2022-0100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140373510&doi=10.1108%2fREGE-06-2022-0100&partnerID=40&md5=567fab363c2330ceb412fa8a2cca51ab},
	affiliations = {Department of Management, University of São Paulo, São Paulo, Brazil; Business School, Universidade Municipal de São Caetano do Sul, São Caetano do Sul, Brazil; Department of Management, Universidade Paulista, São Paulo, Brazil},
	abstract = {Purpose: This paper aims to investigate whether professional data analysts’ trust of black-box systems is increased by explainability artifacts. Design/methodology/approach: The study was developed in two phases. First a black-box prediction model was estimated using artificial neural networks, and local explainability artifacts were estimated using local interpretable model-agnostic explanations (LIME) algorithms. In the second phase, the model and explainability outcomes were presented to a sample of data analysts from the financial market and their trust of the models was measured. Finally, interviews were conducted in order to understand their perceptions regarding black-box models. Findings: The data suggest that users’ trust of black-box systems is high and explainability artifacts do not influence this behavior. The interviews reveal that the nature and complexity of the problem a black-box model addresses influences the users’ perceptions, trust being reduced in situations that represent a threat (e.g. autonomous cars). Concerns about the models’ ethics were also mentioned by the interviewees. Research limitations/implications: The study considered a small sample of professional analysts from the financial market, which traditionally employs data analysis techniques for credit and risk analysis. Research with personnel in other sectors might reveal different perceptions. Originality/value: Other studies regarding trust in black-box models and explainability artifacts have focused on ordinary users, with little or no knowledge of data analysis. The present research focuses on expert users, which provides a different perspective and shows that, for them, trust is related to the quality of data and the nature of the problem being solved, as well as the practical consequences. Explanation of the algorithm mechanics itself is not significantly relevant. © 2022, Heitor Hoffman Nakashima, Daielly Mantovani and Celso Machado Junior.},
	author_keywords = {Artificial intelligence; Black-box systems; Explainability; Machine learning; Trust},
	correspondence_address = {D. Mantovani; Department of Management, University of São Paulo, São Paulo, Brazil; email: daielly@usp.br},
	publisher = {Emerald Publishing},
	issn = {18092276},
	language = {English},
	abbrev_source_title = {Rev. Gestao.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Vandemeulebroucke202233,
	author = {Vandemeulebroucke, Tijs and Denier, Yvonne and Gastmans, Chris},
	title = {The Need for a Global Approach to the Ethical Evaluation of Healthcare Machine Learning},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {33 – 35},
	doi = {10.1080/15265161.2022.2055207},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129065531&doi=10.1080%2f15265161.2022.2055207&partnerID=40&md5=e98fefecccd1b6859a88c2ea64f30134},
	affiliations = {Rheinische Friedrich-Wilhelms-Universität Bonn, Germany; KU Leuven, Belgium},
	keywords = {Delivery of Health Care; Ethics, Research; Health Facilities; Humans; Machine Learning; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {T. Vandemeulebroucke; Sustainable AI Lab, Institut für Wissenschaft und Ethik/Institute for Science and Ethics, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Bonner Talweg 57, 53113, Germany; email: tvandeme@uni-bonn.de},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475955},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Papalexopoulos2022,
	author = {Papalexopoulos, Theodore P and Bertsimas, Dimitris and Cohen, I. Glenn and Goff, Rebecca R and Stewart, Darren E and Trichakis, Nikolaos},
	title = {Ethics-by-design: Efficient, fair and inclusive resource allocation using machine learning},
	year = {2022},
	journal = {Journal of Law and the Biosciences},
	volume = {9},
	number = {1},
	doi = {10.1093/jlb/lsac012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131129430&doi=10.1093%2fjlb%2flsac012&partnerID=40&md5=65cc0d96ade0d3bc8ef137a6d7d5913e},
	affiliations = {Operations Research Center, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States; Harvard Law School, Harvard University, Cambridge, 02138, MA, United States; Research Department, United Network for Organ Sharing, Richmond, 23219, VA, United States},
	abstract = {The distribution of crucial medical goods and services in conditions of scarcity is among the most important, albeit contested, areas of public policy development. Policymakers must strike a balance between multiple efficiency and fairness objectives, while reconciling disparate value judgments from a diverse set of stakeholders. We present a general framework for combining ethical theory, data modeling, and stakeholder input in this process and illustrate through a case study on designing organ transplant allocation policies. We develop a novel analytical tool, based on machine learning and optimization, designed to facilitate efficient and wide-ranging exploration of policy outcomes across multiple objectives. Such a tool enables all stakeholders, regardless of their technical expertise, to more effectively engage in the policymaking process by developing evidence-based value judgments based on relevant tradeoffs.  © 2022 The Author(s) 2022. Published by Oxford University Press on behalf of Duke University School of Law, Harvard Law School, Oxford University Press, and Stanford Law School. All rights reserved.},
	author_keywords = {Analytics; ethics by design; machine learning; organ allocation; organ transplantation; resource allocation},
	correspondence_address = {D. Bertsimas; Operations Research Center, Massachusetts Institute of Technology, Cambridge, 02139, United States; email: dbertsim@mit.edu},
	publisher = {Oxford University Press},
	issn = {20539711},
	language = {English},
	abbrev_source_title = {J.  Law  Biosci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Char202239,
	author = {Char, Danton},
	title = {Challenges of Local Ethics Review in a Global Healthcare AI Market},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {39 – 41},
	doi = {10.1080/15265161.2022.2055214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128996687&doi=10.1080%2f15265161.2022.2055214&partnerID=40&md5=680d3d33bca5c3160f5ab04c1482345c},
	affiliations = {Stanford University School of Medicine, United States},
	keywords = {Delivery of Health Care; Ethics, Research; Health Care Sector; Health Facilities; Humans; Machine Learning; ethics; health care cost; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {D. Char; Department of Anesthesiology, Division of Pediatric Cardiac Anesthesia, Stanford University School of Medicine, Stanford, United States; email: dchar@stanford.edu},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475961},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{de Oliveira Ferreira Silva2022477,
	author = {de Oliveira Ferreira Silva, César},
	title = {The Challenge of Model Validation and Its (Hydrogeo)ethical Implications for Water Security},
	year = {2022},
	journal = {Studies in Computational Intelligence},
	volume = {1043},
	pages = {477 – 489},
	doi = {10.1007/978-981-19-2519-1_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134160917&doi=10.1007%2f978-981-19-2519-1_22&partnerID=40&md5=5819308418c1dee33464346e9fdde74a},
	affiliations = {StormGeo, SP, São Paulo, Brazil},
	abstract = {This essay presents a deeper look into the impacts of using modeling to support water management decision-making lies on potential periodic reconsiderations of conceptual and mathematical model premises. Geoethics brings a relationship between the geoscientists and modeling experts into the social responsibility of using modeling for water management and governance. The validation of those models is crucial to assess how trustworthy is the model applied for the decision making. Ready-to-go practices often do not help us to understand when we can call a model assessment as validation or not. This chapter suggests considering the validation process as an open question on water modeling which is more complex than merely calculating model assessment indexes. Current and future generations of geoscientists with expertise in artificial intelligence, machine learning, and/or geostatistics should clarify validation assumptions wherever possible. Thus, the model validity for its application can be harnessed by another one, resulting in a more flexible and creative usage, allowing the interaction increase between the geoscientist and the decision-makers. Geoethics is a tool that integrates ethics, geosciences, and human activities which are presented here into a new tool for a validation addressing of water modeling. © 2022, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Environmental education; Geoethics; Integrity on science; Sustainability},
	correspondence_address = {C. de Oliveira Ferreira Silva; StormGeo, São Paulo, SP, Brazil; email: cesaroliveira.f.silva@gmail.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {1860949X},
	language = {English},
	abbrev_source_title = {Stud. Comput. Intell.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{D'Aloisio2022291,
	author = {D'Aloisio, Giordano},
	title = {Quality-Driven Machine Learning-based Data Science Pipeline Realization: a software engineering approach},
	year = {2022},
	journal = {Proceedings - International Conference on Software Engineering},
	pages = {291 – 293},
	doi = {10.1109/ICSE-Companion55297.2022.9793779},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132385596&doi=10.1109%2fICSE-Companion55297.2022.9793779&partnerID=40&md5=11266e45156035ca1f2830d77ecce949},
	affiliations = {University of l'Aquila, Italy},
	abstract = {The recently wide adoption of data science approaches to decision making in several application domains (such as health, business and even education) open new challenges in engineering and implementation of this systems. Considering the big picture of data science, Machine learning is the wider used technique and due to its characteristics, we believe that a better engineering methodology and tools are needed to realize innovative data-driven systems able to satisfy the emerging quality attributes (such as, debias and fariness, explainability, privacy and ethics, sustainability). This research project will explore the following three pillars: i) identify key quality attributes, formalize them in the context of data science pipelines and study their relationships; ii) define a new software engineering approach for data-science systems development that assures compliance with quality requirements; iii) implement tools that guide IT professionals and researchers in the realization of ML-based data science pipelines since the requirement engineering. Moreover, in this paper we also presents some details of the project showing how the feature models and model-driven engineering can be leveraged to realize our project. © 2022 IEEE.},
	author_keywords = {machine learning; model-driven; pipelines; product-line architecture; software quality},
	keywords = {Computer software selection and evaluation; Data Science; Decision making; Engineering education; Engineering research; Pipelines; Applications domains; Data driven; Decisions makings; Engineering methodology; Engineering tools; Machine-learning; Model-driven; Product line architecture; Quality attributes; Software Quality; Machine learning},
	correspondence_address = {G. D'aloisio; University of l'Aquila, Italy; email: giordano.daloisio@graduate.univaq.it},
	publisher = {IEEE Computer Society},
	issn = {02705257},
	isbn = {978-166549598-1},
	coden = {PCSED},
	language = {English},
	abbrev_source_title = {Proc Int Conf Software Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 44th ACM/IEEE International Conference on Software Engineering: Companion, ICSE-Companion 2022; Conference date: 22 May 2022 through 27 May 2022; Conference code: 180124}
}

@ARTICLE{Yousefi20223,
	author = {Yousefi, Yasaman},
	title = {Notions of Fairness in Automated Decision Making: An Interdisciplinary Approach to Open Issues},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13429 LNCS},
	pages = {3 – 17},
	doi = {10.1007/978-3-031-12673-4_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135846595&doi=10.1007%2f978-3-031-12673-4_1&partnerID=40&md5=e90fb1430cdb5ae087f6af60c909ff2e},
	affiliations = {Department of Legal Studies, University of Bologna, Bologna, Italy},
	abstract = {Artificial Intelligence (AI) systems share complex characteristics including opacity, that often do not allow for transparent reasoning behind a given decision. As the use of Machine Leaning (ML) systems is exponentially increasing in decision-making contexts, not being able to understand why and how decisions were made, raises concerns regarding possible discriminatory outcomes that are not in line with the shared fundamental values. However, mitigating (human) discrimination through the application of the concept of fairness in ML systems leaves room for further studies in the field. This work gives an overview of the problem of discrimination in Automated Decision-Making (ADM) and assesses the existing literature for possible legal and technical solutions to defining fairness in ML systems. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {AI ethics; Automated Decision-Making; Fairness; Machine Learning},
	keywords = {Automation; Decision making; Ethical technology; Artificial intelligence ethic; Artificial intelligence systems; Automated decision making; Complex characteristics; Decisions makings; Fairness; Legal solutions; Machine leaning; Machine-learning; Technical solutions; Machine learning},
	correspondence_address = {Y. Yousefi; Department of Legal Studies, University of Bologna, Bologna, Italy; email: yasaman.yousefi3@unibo.it},
	editor = {Kő A. and Francesconi E. and Kotsis G. and Khalil I. and Tjoa A.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303112672-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 11th International Conference on Electronic Government and the Information Systems Perspective, EGOVIS 2022, collocated with the 33rd International Conference on Database and Expert Systems Applications, DEXA 2022; Conference date: 22 August 2022 through 24 August 2022; Conference code: 281499}
}

@CONFERENCE{Chakraborty20221,
	author = {Chakraborty, Joymallya and Majumder, Suvodeep and Tu, Huy},
	title = {Fair-SSL: Building fair ML Software with less data},
	year = {2022},
	journal = {Proceedings - International Workshop on Equitable Data and Technology, FairWare 2022},
	pages = {1 – 8},
	doi = {10.1145/3524491.3527305},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137654815&doi=10.1145%2f3524491.3527305&partnerID=40&md5=ca88494b7e90e4c0159664642ee4ddd7},
	affiliations = {North Carolina State University, Raleigh, United States},
	abstract = {Ethical bias in machine learning models has become a matter of concern in the software engineering community. Most of the prior software engineering works concentrated on finding ethical bias in models rather than fixing it. After finding bias, the next step is mitigation. Prior researchers mainly tried to use supervised approaches to achieve fairness. However, in the real world, getting data with trustworthy ground truth is challenging and also ground truth can contain human bias. Semi-supervised learning is a technique where, incrementally, labeled data is used to generate pseudo-labels for the rest of data (and then all that data is used for model training). In this work, we apply four popular semi-supervised techniques as pseudo-labelers to create fair classification models. Our framework, Fair-SSL, takes a very small amount (10%) of labeled data as input and generates pseudo-labels for the unlabeled data. We then synthetically generate new data points to balance the training data based on class and protected attribute as proposed by Chakraborty et al. in FSE 2021. Finally, classification model is trained on the balanced pseudo-labeled data and validated on test data. After experimenting on ten datasets and three learners, we find that Fair-SSL achieves similar performance as three state-of-the-art bias mitigation algorithms. That said, the clear advantage of Fair-SSL is that it requires only 10% of the labeled training data. To the best of our knowledge, this is the first SE work where semi-supervised techniques are used to fight against ethical bias in SE ML models. To facilitate open science and replication, all our source code and datasets are publicly available at https://github.com/joymallyac/FairSSL. © 2022 ACM.},
	author_keywords = {Ethics in Software Engineering; Machine Learning with and for SE},
	keywords = {Classification (of information); Ethical technology; Learning algorithms; Supervised learning; Classification models; Engineering community; Engineering works; Ethic in software engineering; Ground truth; Labeled data; Machine learning models; Machine learning with and for SE; Machine-learning; Semi-supervised; Software engineering},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-145039292-1},
	language = {English},
	abbrev_source_title = {Proc. - Int. Workshop Equitable Data Technol., FairWare},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd IEEE/ACM International Workshop on Equitable Data and Technology, FairWare 2022; Conference date: 9 May 2022; Conference code: 182040; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Etienne2022305,
	author = {Etienne, Hubert},
	title = {Solving moral dilemmas with AI: how it helps us address the social implications of the Covid-19 crisis and enhance human responsibility to tackle meta-dilemmas},
	year = {2022},
	journal = {Law, Innovation and Technology},
	volume = {14},
	number = {2},
	pages = {305 – 324},
	doi = {10.1080/17579961.2022.2113669},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139151647&doi=10.1080%2f17579961.2022.2113669&partnerID=40&md5=84700b128eab36ce8780b9216d484dfe},
	affiliations = {Department of Philosophy, ENS, Paris, France; Facebook AI research, Paris, France; Faculty of Sciences, Sorbonne University, Paris, France},
	abstract = {When combined with an appropriate level of human judgement, machine learning applications were crucial resources insupporting decision-making in the context of the Covid-19 crisis, resulting in more efficient and better-informed responses to ethicalissues. This paper focusses on four social dimensions (bioethical, political, psychological, and economic) from which the decisionstaken in the context of the Covid-19 crisis derived major ethical implications. On the one hand, I argue against the possibility ofaddressing these issues from a purely algorithmic approach, elaborating on two types of limitations for automated systems toaddress ethical issues. This leads me to discuss how different ethical situations call for different performance metrics with regards tothe ‘contextual explicability and performance issue’, as well as to enunciate a gold principle: ‘legitimacy trumps accuracy’. On the otherhand, I present practical examples of machine learning applications which enhance, instead of dilute, human moral agency in betteraddressing these issues. I also suggest a ‘moral perimeter’ framework to ensure the responsibility of algorithms-assisted decisionmakersfor critical decisions. The unique potential of AI to ‘solve’ moral dilemmas by intervening on their conditions of possibility thenprompts me to discuss a new type of moral situation: AI-generated meta-dilemmas. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {AI ethics; Artificial intelligence; coronavirus; Covid-19; meta-dilemmas; moral dilemmas},
	correspondence_address = {H. Etienne; Department of Philosophy, ENS, Paris, France; email: hubert.etienne@sciencespo.fr},
	publisher = {Taylor and Francis Ltd.},
	issn = {17579961},
	language = {English},
	abbrev_source_title = {Law Innov. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Thomopoulos2022305,
	author = {Thomopoulos, Rallou and Salliou, Nicolas and Taillandier, Patrick and Tonda, Alberto},
	title = {Consumers’ Motivations Towards Environment-Friendly Dietary Changes: An Assessment of Trends Related to the Consumption of Animal Products},
	year = {2022},
	journal = {Climate Change Management},
	pages = {305 – 319},
	doi = {10.1007/978-3-030-87934-1_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128936493&doi=10.1007%2f978-3-030-87934-1_17&partnerID=40&md5=2ff88f6a0117e9994201af7479709f1f},
	affiliations = {Univ Montpellier, INRAE, CIRAD, Montpellier SupAgro, INRIA, IATE, Montpellier, 34060, France; ETH Zurich, IRL, PLUS, Stefano-Franscini-Platz 5, Zurich, 8093, Switzerland; Univ Toulouse, INRAE, MIAT, Castanet-Tolosan, France; Universit ́e Paris-Saclay, INRAE, UMR 518 MIA, Paris, France},
	abstract = {In the context of global warming and environmental pressure, food chains must adapt to new production conditions while satisfying the evolving consumer demand. Livestock production is known for its negative ecological footprint, bringing forward the question of a possible transition towards more plant-based diets. Citizens’ demand evolves at different speeds and integrates these new environmental concerns sometimes mixed with health or ethical issues. We carried out a survey with 1,715 respondents in France, about their food choice priorities and preferences, as well as the drivers of change. Our results indicate that 40% of respondents claim that their current diet is not what they would ideally have and 98% of them would like to reduce their animal product consumption. Classification algorithms reveals several salient variables separating classes of individuals wishing to shift their food diet towards less animal products: the willingness to change is stronger for the youngest, hindrances to change are food pleasure, health and to a lesser extent social resistance and animal ethics. The less radical the animal products reduction is the more environmental concerns are the main motivation. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Classification; Consumer perception; Consumer survey; Ecological footprint of food diets; Levers of food diet change; Machine learning},
	correspondence_address = {R. Thomopoulos; Univ Montpellier, INRAE, CIRAD, Montpellier SupAgro, INRIA, IATE, Montpellier, 34060, France; email: rallou.thomopoulos@inrae.fr},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {16102002},
	language = {English},
	abbrev_source_title = {Climate Change Manag.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Al-Edresee202283,
	author = {Al-Edresee, Thamer},
	title = {Physician Acceptance of Machine Learning for Diagnostic Purposes: Caution, Bumpy Road Ahead!},
	year = {2022},
	journal = {Studies in Health Technology and Informatics},
	volume = {295},
	pages = {83 – 86},
	doi = {10.3233/SHTI220666},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133230440&doi=10.3233%2fSHTI220666&partnerID=40&md5=474537ca8d1b051ebd67f94e85e5bd0d},
	affiliations = {Department of Health Informatics, College of Public Health & Health Informatics, King Saud Bin Abdul-Aziz University for Health Sciences, Riyadh, Saudi Arabia},
	abstract = {This paper aims to explore physicians' adoption of Machine learning models in the healthcare process and barriers that may hinder it. A review of the literature about ML in healthcare included current and potentially beneficial clinical applications and clinicians' adoption and trust towards such applications. While some physicians are looking forward to using ML to improve their outcomes and reduce their load, we uncovered fear of unwanted outcomes and concerns about privacy of data, legal liability, and patient dissatisfaction. © 2022 The authors and IOS Press.},
	author_keywords = {Machine learning adoption by healthcare providers; machine learning ethics; Physician adoption of machine learning; physicians trust of machine learning},
	keywords = {Delivery of Health Care; Humans; Machine Learning; Physicians; Privacy; Trust; Data privacy; Ethical technology; Machine learning; Medical informatics; Health care providers; Machine learning adoption by healthcare provider; Machine learning ethic; Machine-learning; Physician adoption of machine learning; Physician adoptions; Physician trust of machine learning; adoption; adult; conference paper; ethics; fear; health care personnel; human; legal liability; machine learning; outcome assessment; physician; privacy; trust; health care delivery; machine learning; trust; Health care},
	correspondence_address = {T. Al-Edresee; Department of Health Informatics, College of Public Health & Health Informatics, King Saud Bin Abdul-Aziz University for Health Sciences, Riyadh, Saudi Arabia; email: Edreesit@ksau-hs.edu.sa},
	editor = {Mantas J. and Gallos P. and Zoulias E. and Hasman A. and Househ M.S. and Diomidous M. and Liaskos J. and Charalampidou M.},
	publisher = {IOS Press BV},
	issn = {09269630},
	isbn = {978-164368290-7},
	pmid = {35773812},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ortiz2022605,
	author = {Ortiz, Oswaldo and Fernández-Esparrach, Glòria and Daca, Maria and Pellisé, Maria},
	title = {Artificial intelligence in gastrointestinal endoscopy - Evolution to a new era},
	year = {2022},
	journal = {Revista Espanola de Enfermedades Digestivas},
	volume = {114},
	number = {10},
	pages = {605 – 615},
	doi = {10.17235/reed.2022.8961/2022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139880638&doi=10.17235%2freed.2022.8961%2f2022&partnerID=40&md5=2049a0cb7ff03e0757a93a269b83fcd0},
	affiliations = {Department of Gastroenterology, Hospital Clínic de Barcelona, Institut d'Investigacions Biomèdiques August Pi i Sunyer (IDIBAPS), Centro de Investigación Biomédica en Red de Enfermedades Hepáticas y Digestivas (CIBEREHD), Universitat de Barcelona, Barcelona, Spain},
	abstract = {Artificial intelligence (AI) systems based on machine learning have evolved in the last few years with increasing applicability in gastrointestinal endoscopy. Thanks to AI, an image (input) can be transformed into a clinical decision (output). Although AI systems have been studied mainly to improve detection (CADe) and characterization of colorectal polyps (CADx), other indications are being currently investigated, including detection of blind spots, scope guidance, and delineation/measurement of lesions. The objective of this review is to summarize the current evidence on the applicability of AI systems in gastrointestinal endoscopy, to highlight the strengths and limitations of the technology involved, and to review the relevant regulatory and ethical aspects for general implementation in gastrointestinal endoscopy. © 2022 ARAN Ediciones S.A.. All rights reserved.},
	author_keywords = {Artificial intelligence; Gastrointestinal endoscopy},
	keywords = {Artificial Intelligence; Endoscopy, Gastrointestinal; Humans; Machine Learning; artificial intelligence; ethics; gastrointestinal endoscopy; human; review; machine learning; procedures},
	correspondence_address = {M. Pellisé; Department of Gastroenterology, Hospital Clínic de Barcelona, Barcelona, C/ Villarroel 170, 08036, Spain; email: mpellise@clinic.cat},
	publisher = {ARAN Ediciones S.L},
	issn = {11300108},
	coden = {REDIE},
	pmid = {35770604},
	language = {English},
	abbrev_source_title = {Rev. Esp. Enferm. Dig.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Tao202223,
	author = {Tao, Mengjun and Jiang, Richard and Downs, Carolyn},
	title = {Ethics of Face Recognition in Smart Cities Toward Trustworthy AI},
	year = {2022},
	journal = {Advanced Sciences and Technologies for Security Applications},
	pages = {23 – 52},
	doi = {10.1007/978-3-031-04424-3_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138141093&doi=10.1007%2f978-3-031-04424-3_2&partnerID=40&md5=c2fcee94b9ab21bb3b53bfe208fd8f2b},
	affiliations = {LIRA Center, Lancaster University, Lancaster, LA1 4YW, United Kingdom},
	abstract = {In the past few decades, thanks to the continuous development of machine learning and deep learning algorithms, as well as the continuous improvement of computing power and databases, facial recognition technology (FRT) has developed rapidly. Widespread use of this technology can be seen in all fields of life, such as facepay, individual identification, smart-city surveillance, e-passport or even face to DNA identification. However, some experts believe that certain errors that commonly creep into its functionality and a few ethical considerations need to be addressed before its most elaborate applications can be realized. This article explores the ethical issues of FRT used in different scenarios, tries to examine some legal and regulatory issues that may be encountered during the use of FRT, and technically analyze how to build a trustworthy intelligent system. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {AI ethics; Face Recognition; Legislation},
	correspondence_address = {M. Tao; LIRA Center, Lancaster University, Lancaster, LA1 4YW, United Kingdom; email: m.tao2@lancaster.ac.uk},
	publisher = {Springer},
	issn = {16135113},
	language = {English},
	abbrev_source_title = {Adv. Sci. Tech. Sec. Appl.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Del Grosso202210389,
	author = {Del Grosso, Ganesh and Jalalzai, Hamid and Pichler, Georg and Palamidessi, Catuscia and Piantanida, Pablo},
	title = {Leveraging Adversarial Examples to Quantify Membership Information Leakage},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {10389 – 10399},
	doi = {10.1109/CVPR52688.2022.01015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136185024&doi=10.1109%2fCVPR52688.2022.01015&partnerID=40&md5=1403b6a6b4889e39f08aea0d247acb44},
	affiliations = {Inria, Laboratoire d'Informatique de l'École Polytechnique, France; Tu Wien, Austria; McGill-ETS, Mila, Cnrs, Université Paris-Saclay, CentraleSupélec, International Laboratory on Learning Systems (ILLS), Canada},
	abstract = {The use of personal data for training machine learning systems comes with a privacy threat and measuring the level of privacy of a model is one of the major challenges in machine learning today. Identifying training data based on a trained model is a standard way of measuring the privacy risks induced by the model. We develop a novel approach to address the problem of membership inference in pattern recognition models, relying on information provided by adversarial examples. The strategy we propose consists of measuring the magnitude of a perturbation necessary to build an adversarial example. Indeed, we argue that this quantity reflects the likelihood of belonging to the training data. Extensive numerical experiments on multivariate data and an array of state-of-the-art target models show that our method performs comparable or even outperforms state-of-the-art strategies, but without requiring any additional training samples. © 2022 IEEE.},
	author_keywords = {accountability; Adversarial attack and defense; fairness; Machine learning; privacy and ethics in vision; Transparency},
	keywords = {Data privacy; Machine learning; Numerical methods; Accountability; Adversarial attack and defense; Fairness; Information leakage; Machine-learning; Membership information; Privacy and ethic in vision; State of the art; Training data; Training machines; Pattern recognition},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@BOOK{Noble2022221,
	author = {Noble, Sean M. and Dubljević, Veljko},
	title = {Ethics of AI in organizations},
	year = {2022},
	journal = {Human-Centered Artificial Intelligence: Research and Applications},
	pages = {221 – 239},
	doi = {10.1016/B978-0-323-85648-5.00019-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137874151&doi=10.1016%2fB978-0-323-85648-5.00019-0&partnerID=40&md5=35477dddb0213516a6e46c3f188e83d9},
	affiliations = {Department of Psychology, North Carolina State University, Raleigh, NC, United States; Department of Philosophy and Religious Studies, North Carolina State University, Raleigh, NC, United States},
	abstract = {Artificial intelligence (AI) technologies are rapidly changing the way organizations operate. Applications of AI and machine learning (ML) are enabling big data insights that lead to increased organizational efficiency and efficacy. Despite its many advantages, AI also raises concerns about possible unintended consequences of wide-spread use as well as negative outcomes resulting from intentional misuse. Organizations, whether private, academic, or governmental, must therefore take caution to ensure that the use and creation of AI-based systems are done ethically. In this chapter, we identify existing ethical AI principles to establish nine key principles of ethical AI across three themes: avoiding undesired results, acting responsibly, and adding ethics in AI. Then, we identify existing organizational science theory that identifies similar concerns as these principles. We end by integrating these schools of thought and suggesting areas of alignment between them. © 2022 Elsevier Inc. All rights reserved.},
	author_keywords = {Artificial intelligence (AI); Corporate social responsibility (CSR); Ethics; Organizational justice; Public discourse; Public policy},
	publisher = {Elsevier Inc.},
	isbn = {978-032385648-5; 978-032385649-2},
	language = {English},
	abbrev_source_title = {Human-Centered Artificial Intelligence: Research and Applications},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Tak2022135,
	author = {Tak, Amit and Punjabi, Poonam and Yadav, Anuradha and Sankhla, Manisha and Mathur, Sandeep and Dave, Harsh S. and Patel, Vaishnavi and Chavhan, Tushar and Manisha and Mamta},
	title = {Prediction of Type 2 Diabetes Mellitus Using Soft Computing},
	year = {2022},
	journal = {Medicina Moderna},
	volume = {29},
	number = {2},
	pages = {135 – 143},
	doi = {10.31689/RMM.2021.29.2.135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133862415&doi=10.31689%2fRMM.2021.29.2.135&partnerID=40&md5=57ae736074a2ad5b8d112c2d091d5b71},
	affiliations = {RVRS Medical College, Rajasthan, Bhilwara, India; SMS Medical College, Rajasthan, Jaipur, India; SBKS Medical Institute and Research Centre, Gujarat, Vadodara, India; University of Perpetual Help System Dalta, Las Pinas, Philippines; Indian Institute of Technology, Patna, India; Banasthali Vidhyapith, Rajasthan, Jaipur, India; Mahatma Gandhi Medical College and Hospital, Rajasthan, Jaipur, India},
	abstract = {Background: Type 2 Diabetes Mellitus (DM) is another pandemic of 21 century, and its control is of immense importance. Researchers developed many predictor models using soft computing techniques. The present study developed a prediction model for Type 2 DM using machine learning classifiers. The analysis excludes plasma glucose concentration and insulin concentration as predictors to explore relationships with other predictors. Background: Methods: This cross-sectional study enrolled 108 participants aged 25 to 67 years from SMS Medical College, Jaipur (Rajasthan, India), after approval from the ethics committee. The study developed a prediction model using machine learning techniques. The classifiers used in the application include decision trees, support vector machines, K-nearest neighbors, and ensemble learning classifiers. A total of 25 predictors were collected and underwent feature reduction. The response levels include diabetes mellitus, prediabetes, and no diabetes mellitus. The models were run using three predictors and a response variable. The prediction model with the best accuracy and area under the receiver operator characteristic curve was selected. Results: The features that vary among the three groups include age, WHR, biceps skinfold thickness, total lipids, phospholipids, triglycerides, total cholesterol, LDL, VLDL, and serum creatinine, and family history of DM. After feature reduction, the age, biceps skinfold thickness, and serum creatinine were run on the Classification learner application to predict the diabetic category. The best model was subspace discriminant with accuracy, sensitivity, specificity, and AUC under the ROC curve was 62.4%, 74%, 94%, and 0.70, respectively. Conclusion: The present study concludes that age, biceps skinfold thickness, and serum creatinine combination have higher specificity in predicting type 2 DM. The study emphasized the selection of appropriate predictors along with newer machine learning algorithms. © 2022 Medicina Moderna. All rights reserved.},
	author_keywords = {biceps skinfold thickness; diabetes mellitus; machine learning; prediction models; soft computing},
	correspondence_address = {A. Tak; RVRS Medical College, Bhilwara, Rajasthan, India; email: dramittak@gmail.com},
	publisher = {Bucharest College of Physicians},
	issn = {12230472},
	language = {English},
	abbrev_source_title = {Med. Mod.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Blumenthal-Barby20221,
	author = {Blumenthal-Barby, Jennifer and Lang, Benjamin and Dorfman, Natalie and Kaplan, Holland and Hooper, William B. and Kostick-Quenet, Kristin},
	title = {Research on the Clinical Translation of Health Care Machine Learning: Ethicists Experiences on Lessons Learned},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {1 – 3},
	doi = {10.1080/15265161.2022.2059199},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129055962&doi=10.1080%2f15265161.2022.2059199&partnerID=40&md5=f16ab1b3bb01e2fd211489afcea2b6e2},
	affiliations = {Baylor College of Medicine, United States},
	keywords = {Delivery of Health Care; Ethicists; Ethics, Research; Health Facilities; Humans; Machine Learning; ethicist; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {J. Blumenthal-Barby; Baylor College of Medicine, Houston, United States; email: Jennifer.Blumenthal-Barby@bcm.edu},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475968},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{2022,
	title = {Media, Arts, and Design Artificial Intelligence conference, MADAI 2020},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {382},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126212627&partnerID=40&md5=2ddc6c6da3389562eee6c39eef050cc2},
	abstract = {The proceedings contain 13 papers. The special focus in this conference is on Media, Arts, and Design Artificial Intelligence. The topics include: Exploring Reinforcement Learning: A Case Study Applied to the Popular Snake Game; the Brokenness in Our Recommendation Systems: Computational Art for an Ethical Use of A.I.; training Social Skills in Virtual Reality Machine Learning as a Process of Co-Creation; Horizontal Scalability of Blockchain Games Using the GSP Model; an Approach Towards Architecture-Independent Output for Generative Networks: Texturing Aerial Town Maps for Roleplaying Games; soliNomic: A Self-modifying Smart Contract Game Exploring Reflexivity in Law; preface; algorithms, Ethics and Justice; a Criticism of the Technological Singularity; fairness by Design: The Fair Game and the Fair Price on a Blockchain-Based Marketplace; cryptogames as Drivers for Blockchain Application Development.},
	editor = {Dingli A. and Pfeiffer A. and Serada A. and Bugeja M. and Bezzina S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303093779-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Media, Arts, and Design Artificial Intelligence conference, MADAI 2020; Conference date: 19 June 2020 through 19 June 2020; Conference code: 274259}
}

@ARTICLE{Dinotola202273,
	author = {Dinotola, Sara},
	title = {Collection bias and data analysis: A model for the comparative study of LGBTQ + collections; [Bias delle collezioni e data analysis: un modello per lo studio comparato delle raccolte LGBTQ+]},
	year = {2022},
	journal = {AIB Studi},
	volume = {62},
	number = {1},
	pages = {73 – 103},
	doi = {10.2426/aibstudi-13394},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136308761&doi=10.2426%2faibstudi-13394&partnerID=40&md5=16f38335e50865295174836f784e6ded},
	affiliations = {Biblioteca Civica Cesare Battisti, Bolzano, Italy},
	abstract = {In the first partthe paperillustrates the results of an analysis ofthe Italian editorial production on LGBTQ+ issues, limited to non-fiction for adults published between 2016 and the first half of 2021. Subsequently, the analysis focuses on the representativeness of these publications within the collections of the library systems located in ten large Italian cities. A comparative study is carried out on various aspects: years of publication, publishers, DDC classes, Conspectus levels, usage data. Moreover, through interviews with librarians a qualitative survey is also conducted, to bring to light additional elements, including the reasons and criteria for the acquisition or the non-acquisition of LGBTQ+ titles. In conclusion, after a comparison with similar studies conducted in other geographical contexts,the author tries to understand whether cognitive biases are among the factors influencing the development of LGBTQ+ collections. Bringing out any bias is fundamental to make librarians more aware and to emphasize the professional ethics and the principles of plurality on which the concept of public library is based. This type of study also allows to obtain detailed information elements to be taken into account in projects aimed at implementing recommendation systems that exploitthe potential of Artificial Intelligence and, in particular, of machine learning: it should not be forgotten, in fact, that algorithmic biases reflect real-world biases. Copyright © 2022 Sara Dinotola.},
	correspondence_address = {S. Dinotola; Biblioteca Civica Cesare Battisti, Bolzano, Italy; email: sara.dinotola@comune.bolzano.it},
	publisher = {Associazione Italiana Biblioteche},
	issn = {22809112},
	language = {Italian},
	abbrev_source_title = {AIB Studi},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Koppikar2022373,
	author = {Koppikar, Unnati and Amashi, Radhika and Vijayalakshmi, M. and Kandakatla, Rohit and Baligar, Preethi},
	title = {Evaluation of First-Year Student's Learning of Engineering Ethics in a Blended PBL Course},
	year = {2022},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	volume = {2022-March},
	pages = {373 – 378},
	doi = {10.1109/EDUCON52537.2022.9766581},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130446252&doi=10.1109%2fEDUCON52537.2022.9766581&partnerID=40&md5=39a0c0368914a1b971b70e4991885954},
	affiliations = {Kle Technological University, Centre for Engineering Education Research, Hubballi, India; Kg Reddy College of Engineering and Technology, Department of Electronics and Communication, Hyderabad, India},
	abstract = {There has been a growing call to nurture and prepare current engineering graduates to think and act ethically as the products designed by engineers have both individual and societal implications. Engineering ethics revolves around the professional obligation of engineers to society, their employers, and the profession. Engineering codes of ethics commonly referred to as fundamental cannons form the base for engineering ethics education. It focuses on micro ethical issues, fundamental overarching responsibility to protect human health, welfare, and the environment or promote sustainable development. Engineering ethics was introduced to first-year engineering students as part of a PBL based course, which was taught in a blended mode due to the disruptions caused by the COVID19 pandemic. This study attempts to assess students' knowledge of engineering ethics and their ability to identify and resolve ethical dilemmas by applying the fundamental canons. When a module like engineering ethics was introduced to the first-year engineering students in a blended mode, it was essential to identify methods that would help assess students' understanding of engineering ethics. Students learn the concepts of engineering ethics through asynchronous videos. The module's primary objective was to develop students' ability to identify and resolve ethical dilemmas and map fundamental cannon. A discussion forum was set up, allotting students with a case study that had an ethical dilemma used as an instrument to assess the students. The results discuss mainly the cognitive levels that the students have reached in resolving an ethical dilemma. The analysis also predicted the areas where students found it challenging to understand the concepts. © 2022 IEEE.},
	author_keywords = {Discussion Forum; Engineering Ethics; Ethical Dilemma; Fundamental Canons; Machine Learning},
	keywords = {Curricula; Engineering education; Machine learning; Philosophical aspects; Professional aspects; Sustainable development; 'current; Discussion forum; Engineering ethics; Engineering graduates; Ethical dilemma; First year students; First-year engineering; Fundamental canon; Machine-learning; Student learning; Students},
	editor = {Jemni M. and Kallel I. and Akkari A.},
	publisher = {IEEE Computer Society},
	issn = {21659559},
	isbn = {978-166544434-7},
	language = {English},
	abbrev_source_title = {IEEE Global Eng. Edu. Conf., EDUCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 13th IEEE Global Engineering Education Conference, EDUCON 2022; Conference date: 28 March 2022 through 31 March 2022; Conference code: 179170}
}

@CONFERENCE{Munjal2022223,
	author = {Munjal, Prateek and Hayat, Nasir and Hayat, Munawar and Sourati, Jamshid and Khan, Shadab},
	title = {Towards Robust and Reproducible Active Learning using Neural Networks},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {223 – 232},
	doi = {10.1109/CVPR52688.2022.00032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140198622&doi=10.1109%2fCVPR52688.2022.00032&partnerID=40&md5=58e679957d9638a2bc06e4bf24c82d4a},
	affiliations = {G42 Healthcare, Abu Dhabi, United Arab Emirates; Nyuad, United Arab Emirates; Monash University, Australia; University of Chicago, Chicago, IL, United States},
	abstract = {Active learning (AL) is a promising ML paradigm that has the potential to parse through large unlabeled data and help reduce annotation cost in domains where labeling data can be prohibitive. Recently proposed neural network based AL methods use different heuristics to accomplish this goal. In this study, we demonstrate that under identical experimental settings, different types of AL algorithms (uncertainty based, diversity based, and committee based) produce an inconsistent gain over random sampling baseline. Through a variety of experiments, controlling for sources of stochasticity, we show that variance in performance metrics achieved by AL algorithms can lead to results that are not consistent with the previously reported results. We also found that under strong regularization, AL methods show marginal or no advantage over the random sampling baseline under a variety of experimental conditions. Finally, we conclude with a set of recommendations on how to assess the results using a new AL algorithm to ensure results are reproducible and robust under changes in experimental conditions. We share our codes to facilitate AL evaluations. We believe our findings and recommendations will help advance reproducible research in AL using neural networks. © 2022 IEEE.},
	author_keywords = {accountability; Efficient learning and inferences; fairness; Machine learning; privacy and ethics in vision; Transparency},
	keywords = {Accountability; Active Learning; Active learning methods; Active-learning algorithm; Efficient learning; Efficient learning and inference; Fairness; Machine-learning; Neural-networks; Privacy and ethic in vision; Heuristic methods},
	correspondence_address = {S. Khan; G42 Healthcare, Abu Dhabi, United Arab Emirates; email: skhan.shadab@gmail.com},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@CONFERENCE{Eluwole2022124,
	author = {Eluwole, Opeoluwa Tosin and Akande, Segun and Adegbola, Oluwole Abiodun},
	title = {Major threats to the continued adoption of Artificial Intelligence in today's hyperconnected world},
	year = {2022},
	journal = {2022 IEEE World AI IoT Congress, AIIoT 2022},
	pages = {124 – 130},
	doi = {10.1109/AIIoT54504.2022.9817247},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134875151&doi=10.1109%2fAIIoT54504.2022.9817247&partnerID=40&md5=5ba7708c57dbba2b5efaf368fc590314},
	affiliations = {Global Investment Innovation Incentives Deloitte LLP, London, United Kingdom; Computing Informatics Bournemouth University, Bournemouth, United Kingdom; Electronic and Electrical Engineering, Ladoke Akintola University of Technology, Ogbomoso, Nigeria},
	abstract = {From the golden era of science fiction which dates to the late 1930s, scientific and technological advances in artificial intelligence (AI), along with one of its key subsets, machine learning (ML) have been growing significantly, especially in recent years. In 2021 alone, notable feats included an AI program capable of creating images from seen or previously unseen textual captions, an AI model that effectively integrates computer vision and natural language processing, and a novel AI framework for diagnosing dementia in 24 hours with real-world feasibility underway amongst a host of other fascinating breakthroughs. This paper briefly delves into AI/ML and recaps some key essentials, covering AI and ML subfields, ML methods, industries where AI/ML finds relevance, key stages and the common technical challenges in ML development. Importantly, the paper shifts attention from the latter to underscore the duo of transparency and ethics in AI, highlighting specifically what these are and why they are important, subsequently positing a PESTEL (Political, Economic, Social, Technological, Environmental and Legal) framework for AI design, build and implementation. It is anticipated that the upshot of this would be the facilitation of continuous adoption and long-term sustainability of AI/ML.  © 2022 IEEE.},
	author_keywords = {AI; Ethics; ML; PESTEL; Transparency},
	keywords = {Artificial intelligence; Environmental regulations; Ethical technology; Learning algorithms; Natural language processing systems; Sustainable development; Artificial intelligence learning; Intelligence models; Language processing; Machine-learning; Natural languages; Political, economic, social, technological, environmental and legal; Real-world; Science fictions; Scientific advances; Technological advances; Transparency},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166548453-4},
	language = {English},
	abbrev_source_title = {IEEE World AI IoT Congr., AIIoT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 IEEE World AI IoT Congress, AIIoT 2022; Conference date: 6 June 2022 through 9 June 2022; Conference code: 180897}
}

@ARTICLE{Ferryman202229,
	author = {Ferryman, Kadija},
	title = {Rethinking the AI Chasm},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {29 – 30},
	doi = {10.1080/15265161.2022.2055218},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129106668&doi=10.1080%2f15265161.2022.2055218&partnerID=40&md5=a9476688d77212dd3547f95844fc6d74},
	affiliations = {Johns Hopkins University Bloomberg School of Public Health and Johns Hopkins Berman Institute of Bioethics, United States},
	keywords = {Delivery of Health Care; Ethics, Research; Health Facilities; Humans; Machine Learning; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {K. Ferryman; Department of Health Policy and Management, Johns Hopkins University Bloomberg School of Public Health, Baltimore, 1809 Ashland Ave, 21205-2103, United States; email: kadija.ferryman@jhu.edu},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475956},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Farina2022,
	author = {Farina, Mirko and Zhdanov, Petr and Karimov, Artur and Lavazza, Andrea},
	title = {AI and society: a virtue ethics approach},
	year = {2022},
	journal = {AI and Society},
	doi = {10.1007/s00146-022-01545-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137877053&doi=10.1007%2fs00146-022-01545-5&partnerID=40&md5=d8c22f1754387bc87f8704756d6dcd9e},
	affiliations = {Faculty of Humanities and Social Sciences, Innopolis University, Universitetskaya St 1, Republic of Tatarstan, Innopolis, 420500, Russian Federation; Department of Social Philosophy, Kazan Federal University, Kremlevskaya St., 18, Republic of Tatarstan, Kazan, 420008, Russian Federation; Centro Universitario Internazionale, Via Antonio Garbasso 42, AR, Arezzo, 52100, Italy},
	abstract = {Advances in artificial intelligence and robotics stand to change many aspects of our lives, including our values. If trends continue as expected, many industries will undergo automation in the near future, calling into question whether we can still value the sense of identity and security our occupations once provided us with. Likewise, the advent of social robots driven by AI, appears to be shifting the meaning of numerous, long-standing values associated with interpersonal relationships, like friendship. Furthermore, powerful actors’ and institutions’ increasing reliance on AI to make decisions that may affect how people live their lives may have a significant impact on privacy while also raising issues about algorithmic transparency and human control. In this paper, building and expanding on previous works, we will look at how the deployment of Artificial Intelligence technology may lead to changes in identity, security, and other crucial values (such as friendship, fairness, and privacy). We will discuss what challenges we may face in the process, while critically reflecting on whether such changes may be desirable. Finally, drawing on a series of considerations underlying virtue ethics, we will formulate a set of preliminary suggestions, which—we hope—can be used to more carefully guide the future roll out of AI technologies for human flourishing; that is, for social and moral good. © 2022, The Author(s), under exclusive licence to Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {AI technologies and applications; Human flourishing; Machine learning; Virtue ethics},
	keywords = {Engineering education; Ethical technology; AI applications; AI Technologies; Algorithmics; Human control; Human flourishing; Interpersonal relationship; Machine-learning; Social robots; Technologies and applications; Virtue ethics; Machine learning},
	correspondence_address = {M. Farina; Faculty of Humanities and Social Sciences, Innopolis University, Innopolis, Universitetskaya St 1, Republic of Tatarstan, 420500, Russian Federation; email: m.farina@innopolis.ru},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Barclay2022,
	author = {Barclay, Iain and Preece, Alun and Taylor, Ian and Radha, Swapna Krishnakumar and Nabrzyski, Jarek},
	title = {Providing assurance and scrutability on shared data and machine learning models with verifiable credentials},
	year = {2022},
	journal = {Concurrency and Computation: Practice and Experience},
	doi = {10.1002/cpe.6997},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127775023&doi=10.1002%2fcpe.6997&partnerID=40&md5=1a645e9df6520d4bff68e4e7e4e5dfec},
	affiliations = {Crime and Security Research Institute, Cardiff University, Cardiff, United Kingdom; Center for Research Computing, University of Notre Dame, Notre Dame, IN, United States},
	abstract = {Adopting shared data resources requires scientists to place trust in the originators of the data. When shared data is later used in the development of artificial intelligence (AI) systems or machine learning (ML) models, the trust lineage extends to the users of the system, typically practitioners in fields such as healthcare and finance. Practitioners rely on AI developers to have used relevant, trustworthy data, but may have limited insight and recourse. This article introduces a software architecture and implementation of a system based on design patterns from the field of self-sovereign identity. Scientists can issue signed credentials attesting to qualities of their data resources. Data contributions to ML models are recorded in a bill of materials (BOM), which is stored with the model as a verifiable credential. The BOM provides a traceable record of the supply chain for an AI system, which facilitates on-going scrutiny of the qualities of the contributing components. The verified BOM, and its linkage to certified data qualities, is used in the AI scrutineer, a web-based tool designed to offer practitioners insight into ML model constituents and highlight any problems with adopted datasets, should they be found to have biased data or be otherwise discredited. © 2022 John Wiley & Sons, Ltd.},
	author_keywords = {accountability; AI ethics; data provenance; explainable AI; self-sovereign identity},
	keywords = {Supply chains; Accountability; Artificial intelligence ethic; Artificial intelligence systems; Bill of materials; Data provenance; Data resources; Explainable artificial intelligence; Machine learning models; Self-sovereign identity; Shared data; Machine learning},
	correspondence_address = {I. Barclay; Crime and Security Research Institute, Cardiff University, Cardiff, United Kingdom; email: BarclayIS@cardiff.ac.uk},
	publisher = {John Wiley and Sons Ltd},
	issn = {15320626},
	coden = {CCPEB},
	language = {English},
	abbrev_source_title = {Concurr. Comput. Pract. Exper.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Shaw202242,
	author = {Shaw, James},
	title = {Emerging Paradigms for Ethical Review of Research Using Artificial Intelligence},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {42 – 44},
	doi = {10.1080/15265161.2022.2055206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129004717&doi=10.1080%2f15265161.2022.2055206&partnerID=40&md5=cb388f4b421da618e76a9558bdf1545d},
	affiliations = {University of Toronto, Canada},
	keywords = {Artificial Intelligence; Delivery of Health Care; Ethical Review; Ethics, Research; Humans; Machine Learning; artificial intelligence; ethics; health care delivery; human; machine learning; research ethics},
	correspondence_address = {J. Shaw; Joint Centre for Bioethics, University of Toronto, Toronto, 155 College Street, M5S 1A1, Canada; email: jay.shaw@wchospital.ca},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475953},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Fazelpour2022,
	author = {Fazelpour, Sina and De-Arteaga, Maria},
	title = {Diversity in sociotechnical machine learning systems},
	year = {2022},
	journal = {Big Data and Society},
	volume = {9},
	number = {1},
	doi = {10.1177/20539517221082027},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128230851&doi=10.1177%2f20539517221082027&partnerID=40&md5=1335ff8fdd1eaa026c572b1e569d4487},
	affiliations = {Northeastern University, United States; University of Texas at Austin, United States},
	abstract = {There has been a surge of recent interest in sociocultural diversity in machine learning research. Currently, however, there is a gap between discussions of measures and benefits of diversity in machine learning, on the one hand, and the broader research on the underlying concepts of diversity and the precise mechanisms of its functional benefits, on the other. This gap is problematic because diversity is not a monolithic concept. Rather, different concepts of diversity are based on distinct rationales that should inform how we measure diversity in a given context. Similarly, the lack of specificity about the precise mechanisms underpinning diversity’s potential benefits can result in uninformative generalities, invalid experimental designs, and illicit interpretations of findings. In this work, we draw on research in philosophy, psychology, and social and organizational sciences to make three contributions: First, we introduce a taxonomy of different diversity concepts from philosophy of science, and explicate the distinct epistemic and political rationales underlying these concepts. Second, we provide an overview of mechanisms by which diversity can benefit group performance. Third, we situate these taxonomies of concepts and mechanisms in the lifecycle of sociotechnical machine learning systems and make a case for their usefulness in fair and accountable machine learning. We do so by illustrating how they clarify the discourse around diversity in the context of machine learning systems, promote the formulation of more precise research questions about diversity’s impact, and provide conceptual tools to further advance research and practice. © The Author(s) 2022.},
	author_keywords = {AI ethics; algorithmic bias; Diversity; fair machine learning; responsible artificial intelligence; sociotechnical systems},
	correspondence_address = {S. Fazelpour; Northeastern University, United States; email: s.fazel-pour@northeastern.edu},
	publisher = {SAGE Publications Ltd},
	issn = {20539517},
	language = {English},
	abbrev_source_title = {Big Data  Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Karlan2022,
	author = {Karlan, Brett and Allen, Colin},
	title = {Engineered wisdom for learning machines},
	year = {2022},
	journal = {Journal of Experimental and Theoretical Artificial Intelligence},
	doi = {10.1080/0952813X.2022.2092559},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132751518&doi=10.1080%2f0952813X.2022.2092559&partnerID=40&md5=4ab24db01c254ac9af6e94241f086887},
	affiliations = {Department of History and Philosophy of Science, University of Pittsburgh, Pittsburgh, PA, United States},
	abstract = {We argue that the concept of practical wisdom is particularly useful for organising, understanding, and improving human-machine interactions. We consider the relationship between philosophical analysis of wisdom and psychological research into the development of wisdom. We adopt a practical orientation that suggests a conceptual engineering approach is needed, where philosophical work involves refinement of the concept in response to contributions by engineers and behavioural scientists. The former are tasked with encoding as much wise design as possible into machines themselves, as well as providing sandboxes or workspaces to help various stakeholders build practical wisdom in systems that are sufficiently realistic to aid transferring skills learned to real-world use. The latter are needed for the design of exercises and methods of evaluation within these workspaces, as well as ways of empirically assessing the transfer of wisdom from workspace to world. Systematic interaction between these three disciplines (and others) is the best approach to engineering wisdom for the machine age. © 2022 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Ethics; human-machine interaction; machine learning; wisdom},
	correspondence_address = {B. Karlan; Department of History and Philosophy of Science, University of Pittsburgh, Pittsburgh, United States; email: BAK108@pitt.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {0952813X},
	language = {English},
	abbrev_source_title = {J. Exp. Theor. Artif. Intell.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Ho202236,
	author = {Ho, Calvin Wai-Loon and Malpani, Rohit},
	title = {Scaling up the Research Ethics Framework for Healthcare Machine Learning as Global Health Ethics and Governance},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {36 – 38},
	doi = {10.1080/15265161.2022.2055209},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129096339&doi=10.1080%2f15265161.2022.2055209&partnerID=40&md5=cdb7f87e2b6510e7422e070798b17f8a},
	affiliations = {University of Hong Kong, Hong Kong; World Health Organization, Hong Kong},
	keywords = {Delivery of Health Care; Ethics, Research; Global Health; Health Facilities; Humans; Machine Learning; global health; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {C.W.-L. Ho; University of Hong Kong, Cheng Yu Yung Tower, Pokfulam, Centennial Campus, Hong Kong; email: cwlho@hku.hk},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475959},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Tutun2022,
	author = {Tutun, Salih and Harfouche, Antoine and Albizri, Abdullah and Johnson, Marina E. and He, Haiyue},
	title = {A Responsible AI Framework for Mitigating the Ramifications of the Organ Donation Crisis},
	year = {2022},
	journal = {Information Systems Frontiers},
	doi = {10.1007/s10796-022-10340-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139242567&doi=10.1007%2fs10796-022-10340-y&partnerID=40&md5=bdbec908d79ebecf94db07dc6ebacb53},
	affiliations = {Washington University in St. Louis, St. Louis, MO, United States; University Paris Nanterre, Nanterre, France; Montclair State University, Montclair, NJ, United States},
	abstract = {Thousands of people die while waiting for organ transplants due to a significant gap between demand and supply. This gap often leads to illegal activities and ethical issues such as illicit organ trade and auctions. Therefore, to increase the organ supply and procure more organs, organizations must understand the causes of families who refuse to consent to donate their loved one's organs. Furthermore, such organizations must better identify those families most likely to consent to organ donation. We propose a responsible AI framework that integrates network science and artificial intelligence to identify consent outcomes for organ donation. The proposed framework includes three phases: (1) collecting and pre-processing data, (2) creating new features and identifying root causes of family refusal, and (3) training and testing models to predict the probability of families granting consent for organ donation. The designed artifact included collaborative decisions and network measures, increasing explainability through network science. It integrated human reviews and assessment of risks which increases correct and interpretable predictions. Results can help encourage organ donations and reduce the illegal organ trade. The experimental results show that the designed artifact outperformed previous studies identifying factors affecting consent outcomes. This framework integrates network science and artificial intelligence to reduce maleficence, solve the lack of transparency (i.e., increase trustworthiness) and improve accountability of the model that aims to predict consent outcomes. © 2022, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {AI Ethics; Machine Learning; Network Analysis; Organ Donation; Responsible AI},
	keywords = {Commerce; Crime; Data handling; Forecasting; Philosophical aspects; Risk assessment; AI ethic; Demand and supply; Ethical issues; Illegal activities; Machine-learning; Most likely; Network science; Organ donations; Organ transplants; Responsible AI; Machine learning},
	correspondence_address = {A. Harfouche; University Paris Nanterre, Nanterre, France; email: antoine.h@parisnanterre.fr},
	publisher = {Springer},
	issn = {13873326},
	language = {English},
	abbrev_source_title = {Inf. Syst. Front.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{de Oliveira Carvalho2022130,
	author = {de Oliveira Carvalho, Niltemberg and Libório Sampaio, Andréia and de Vasconcelos, Davi Romero},
	title = {MoReXAI - A Model to Reason About the eXplanation Design in AI Systems},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13336 LNAI},
	pages = {130 – 148},
	doi = {10.1007/978-3-031-05643-7_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131119495&doi=10.1007%2f978-3-031-05643-7_9&partnerID=40&md5=44ecf8e426d7c358fe117d08b61b8291},
	affiliations = {Universidade Federal do Ceará, Campus de Quixadá, Ceará, Brazil},
	abstract = {The interest in systems that use machine learning has been growing in recent years. Some algorithms implemented in these intelligent systems hide their fundamental assumptions, input information and parameters in black box models that are not directly observable. The adoption of these systems in sensitive and large-scale application domains involves several ethical issues. One way to promote these ethics requirements is to improve the explainability of these models. However, explainability may have different goals and content according to the intended audience (developers, domain experts, and end-users. Some explanations does not always represent the requirements of the end-users, because developers and users do not share the same social meaning system, making it difficult to build more effective explanations. This paper proposes a conceptual model, based on Semiotic Engineering, which explores the problem of explanation as a communicative process, in which designers and users work together on requirements on explanations. A Model to Reason about the eXplanation design in Artificial Intelligence Systems (MoReXAI) is based on a structured conversation, with promotes reflection on subjects such as Privacy, Fairness, Accountability, Equity and Explainability, aiming to help end-users understand how the systems work and supporting the explanation design system. The model can work as an epistemic tool, given the reflections raised in the conversations related to the topics of ethical principles, which helped in the process of raising important requirements for the design of the explanation. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial Intelligence; Ethics; Explanations; Semiotic Engineering},
	keywords = {Design; Ethical technology; Semiotics; AI systems; Applications domains; Black box modelling; Domain experts; End-users; Ethical issues; Expert users; Explanation; Large-scale applications; Semiotic engineering; Intelligent systems},
	correspondence_address = {N. de Oliveira Carvalho; Universidade Federal do Ceará, Ceará, Campus de Quixadá, Brazil; email: niltemberg@gmail.com},
	editor = {Degen H. and Ntoa S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303105642-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Artificial Intelligence in HCI, AI-HCI 2022 Held as Part of the 24th HCI International Conference, HCII 2022; Conference date: 26 June 2022 through 1 July 2022; Conference code: 278009}
}

@ARTICLE{Rizinski202297531,
	author = {Rizinski, Maryan and Peshov, Hristijan and Mishev, Kostadin and Chitkushev, Lubomir T. and Vodenska, Irena and Trajanov, Dimitar},
	title = {Ethically Responsible Machine Learning in Fintech},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {97531 – 97554},
	doi = {10.1109/ACCESS.2022.3202889},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137611186&doi=10.1109%2fACCESS.2022.3202889&partnerID=40&md5=deefc92aa6326432d2a2dea1a6ade71b},
	affiliations = {Department of Computer Science, Metropolitan College, Boston University, Boston, 02215, MA, United States; Faculty of Computer Science and Engineering, Ss. Cyril and Methodius University, Skopje, 1000, North Macedonia; Laboratory for Interdisciplinary Finance and Economics (LIFE) Research, Administrative Sciences Department, Metropolitan College, Boston University, Boston, 02215, MA, United States},
	abstract = {Rapid technological developments in the last decade have contributed to using machine learning (ML) in various economic sectors. Financial institutions have embraced technology and have applied ML algorithms in trading, portfolio management, and investment advising. Large-scale automation capabilities and cost savings make the ML algorithms attractive for personal and corporate finance applications. Using ML applications in finance raises ethical issues that need to be carefully examined. We engage a group of experts in finance and ethics to evaluate the relationship between ethical principles of finance and ML. The paper compares the experts’ findings with the results obtained using natural language processing (NLP) transformer models, given their ability to capture the semantic text similarity. The results reveal that the finance principles of integrity and fairness have the most significant relationships with ML ethics. The study includes a use case with SHapley Additive exPlanations (SHAP) and Microsoft Responsible AI Widgets explainability tools for error analysis and visualization of ML models. It analyzes credit card approval data and demonstrates that the explainability tools can address ethical issues in fintech, and improve transparency, thereby increasing the overall trustworthiness of ML models. The results show that both humans and machines could err in approving credit card requests despite using their best judgment based on the available information. Hence, human-machine collaboration could contribute to improved decision-making in finance. We propose a conceptual framework for addressing ethical challenges in fintech such as bias, discrimination, differential pricing, conflict of interest, and data protection. © 2022 Institute of Electrical and Electronics Engineers Inc.. All rights reserved.},
	author_keywords = {Ethics; explainability; finance; financial services; fintech; machine learning},
	keywords = {Artificial intelligence; Biological systems; Decision making; Learning algorithms; Learning systems; Natural language processing systems; Philosophical aspects; Semantics; Biological system modeling; Code; Credit cards; Ethical issues; Explainability; Financial service; Machine learning algorithms; Machine-learning; Investments},
	correspondence_address = {M. Rizinski; Department of Computer Science, Metropolitan College, Boston University, Boston, 02215, United States; email: rizinski@bu.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@BOOK{Baumann20221,
	author = {Baumann, Sabine},
	title = {Introduction to the Handbook on Digital Business Ecosystems: Strategies, Platforms, Technologies, Governance and Societal Challenges},
	year = {2022},
	journal = {Handbook on Digital Business Ecosystems: Strategies, Platforms, Technologies, Governance and Societal Challenges},
	pages = {1 – 9},
	doi = {10.4337/9781839107191.00005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137502948&doi=10.4337%2f9781839107191.00005&partnerID=40&md5=f627b93bc0ef465a68734b537f082c6c},
	affiliations = {Jade University, Germany; OFFIS Institute for Information Technology, Germany},
	abstract = {Digital Business Ecosystems (DBEs) are networks of organizations that create and deliver a specific product or service in a partly or fully digital environment. The term "business ecosystem" conveys that, analogous to biological ecosystems, DBE actors establish a non-homogeneous community of self-interested entities that depend on each other for their survival. The Handbook on DBEs takes a diverse and interdisciplinary approach on the theory, practice, and organizational phenomena that constitute and exist in DBEs: technologies and their potential (e.g., IoT, AI, machine learning, blockchain); markets and business models (e.g., value creation through customer integration, data-driven business models, platforms, and multi-sided marketplaces); governance and management (e.g., strategic positioning in business ecosystems, inter-ecosystem competition, human resources and capability management, ecosystem maturity); societal challenges (e.g., ethics, sustainability, corporate digital responsibility); and broader industry implications. The Handbook is intended for researchers and students, but also for managers who have to navigate increasingly complex DBE. © Sabine Baumann 2022. All rights reserved.},
	publisher = {Edward Elgar Publishing Ltd.},
	isbn = {978-183910719-1; 978-183910718-4},
	language = {English},
	abbrev_source_title = {Handb. on Digital Bus. Ecosystems: Strategies, Platforms, Technologies, Gov. and Societal Challenges},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access}
}

@CONFERENCE{Hu20221544,
	author = {Hu, Brian and Vasu, Bhavan and Hoogs, Anthony},
	title = {X-MIR: EXplainable Medical Image Retrieval},
	year = {2022},
	journal = {Proceedings - 2022 IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022},
	pages = {1544 – 1554},
	doi = {10.1109/WACV51458.2022.00161},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126145910&doi=10.1109%2fWACV51458.2022.00161&partnerID=40&md5=985e9ba7816d8c002dfbbe35e3593b5e},
	affiliations = {Kitware, Inc., Clifton Park, NY, United States},
	abstract = {Despite significant progress in the past few years, machine learning systems are still often viewed as "black boxes, "which lack the ability to explain their output decisions. In high-stakes situations such as healthcare, there is a need for explainable AI (XAI) tools that can help open up this black box. In contrast to approaches which largely tackle classification problems in the medical imaging domain, we address the less-studied problem of explainable image retrieval. We test our approach on a COVID-19 chest X-ray dataset and the ISIC 2017 skin lesion dataset, showing that saliency maps help reveal the image features used by models to determine image similarity. We evaluated three different saliency algorithms, which were either occlusion-based, attention-based, or relied on a form of activation mapping. We also develop quantitative evaluation metrics that allow us to go beyond simple qualitative comparisons of the different saliency algorithms. Our results have the potential to aid clinicians when viewing medical images and addresses an urgent need for interventional tools in response to COVID-19. The source code is publicly available at: https://gitlab.kitware.com/brianhhu/x-mir.  © 2022 IEEE.},
	author_keywords = {Accountability; Explainable AI; Fairness; Privacy and Ethics in Vision Medical Imaging/Imaging for Bioinformatics/Biological and Cell Microscopy},
	keywords = {Bioinformatics; Image retrieval; Learning systems; Statistical tests; Accountability; Black boxes; Explainable AI; Fairness; Image features; Machine learning systems; Medical image retrieval; Privacy and ethic in vision medical imaging/imaging for bioinformatic/biological and cell microscopy; Saliency map; Skin lesion; Medical imaging},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166540915-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/CVF Winter Conf. Appl. Comput. Vis., WACV},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 22nd IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022; Conference date: 4 January 2022 through 8 January 2022; Conference code: 177326}
}

@CONFERENCE{Claure20221244,
	author = {Claure, Houston and Chang, Mai Lee and Kim, Seyun and Omeiza, Daniel and Brandao, Martim and Lee, Min Kyung and Jung, Malte},
	title = {Fairness and Transparency in Human-Robot Interaction},
	year = {2022},
	journal = {ACM/IEEE International Conference on Human-Robot Interaction},
	volume = {2022-March},
	pages = {1244 – 1246},
	doi = {10.1109/HRI53351.2022.9889421},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137164443&doi=10.1109%2fHRI53351.2022.9889421&partnerID=40&md5=fcfa6d55fdfccd4d23b611c73bd8bd5e},
	affiliations = {Cornell University, Mechanical Engineering, Ithaca, NY, United States; University of Texas at Austin Austin, Electrical and Computer Engineering, TX, United States; Human-Computer Interaction Institute, Carnegie Mellon University, Pittsburgh, PA, United States; University of Oxford, Department of Computer Science, Oxford, United Kingdom; King's College London, Department of Informatics, London, United Kingdom; School of Information, University of Texas at Austin, Austin, TX, United States; Cornell University, Information Science, Ithaca, NY, United States},
	abstract = {As robots become more ubiquitous across human spaces, it is becoming increasingly relevant for researchers to ask the question, 'how can we ensure that we are designing robots to be sufficiently equipped to treat people fairly?'. This workshop brings together researchers across the fields of Human-Robot Interaction (HRI), fairness in machine learning, design, and transparency in AI to shed light on the relevant methodological challenges surrounding issues of fairness and transparency in HRI. In our workshop, we will attempt to identify synergies between these various fields. In particular, we will focus on how HRI can leverage these existing rich body of work to guide the formalization of fairness metrics and methodologies. Another goal of the workshop is to foster a community of interdisciplinary researchers to encourage collaboration. The complexity in defining fairness lies in its context sensitive nature, as such we look to the influx of definitions from the field of fairness in artificial intelligence, design, and organizational psychology to derive a set of definitions that could serve as guidelines for researchers in HRI. © 2022 IEEE.},
	author_keywords = {Ethics in HRI; Fairness in HRI; Transparency in AI},
	keywords = {Ethical technology; Machine design; Man machine systems; Transparency; Context-sensitive; Ethic in human-robot interaction; Fairness in human-robot interaction; Formalisation; Humans-robot interactions; Learning designs; Machine-learning; Organizational psychology; Transparency in AI; Human robot interaction},
	publisher = {IEEE Computer Society},
	issn = {21672148},
	isbn = {978-153868554-9},
	language = {English},
	abbrev_source_title = {ACM/IEEE Int. Conf. Hum.-Rob. Interact.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 17th Annual ACM/IEEE International Conference on Human-Robot Interaction, HRI 2022; Conference date: 7 March 2022 through 10 March 2022; Conference code: 183332}
}

@CONFERENCE{Seo202216721,
	author = {Seo, Seonguk and Lee, Joon-Young and Han, Bohyung},
	title = {Unsupervised Learning of Debiased Representations with Pseudo-Attributes},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {16721 – 16730},
	doi = {10.1109/CVPR52688.2022.01624},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140363328&doi=10.1109%2fCVPR52688.2022.01624&partnerID=40&md5=a24e7d483769d4e139329e4277d386c6},
	affiliations = {Ece, Asri, Ipai, Seoul National University, South Korea; Ipai, Seoul National University, South Korea; Adobe Research},
	abstract = {Dataset bias is a critical challenge in machine learning since it often leads to a negative impact on a model due to the unintended decision rules captured by spurious correlations. Although existing works often handle this issue based on human supervision, the availability of the proper annotations is impractical and even unrealistic. To better tackle the limitation, we propose a simple but effective unsupervised debiasing technique. Specifically, we first identify pseudo-attributes based on the results from clustering performed in the feature embedding space even without an explicit bias attribute supervision. Then, we employ a novel cluster-wise reweighting scheme to learn debiased representation; the proposed method prevents minority groups from being discounted for minimizing the overall loss, which is desirable for worst-case generalization. The extensive experiments demonstrate the outstanding performance of our approach on multiple standard benchmarks, even achieving the competitive accuracy to the supervised counterpart. The source code is available at our project page11https://github.com/skynbe/pseudo-attributes. © 2022 IEEE.},
	author_keywords = {accountability; fairness; privacy and ethics in vision; Representation learning; Transparency},
	keywords = {Computer vision; Accountability; Critical challenges; De-biasing; Decision rules; Fairness; Human supervision; Machine-learning; Privacy and ethic in vision; Representation learning; Simple++; Benchmarking},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Taurino2022157,
	author = {Taurino, Giulia},
	title = {The Brokenness in Our Recommendation Systems: Computational Art for an Ethical Use of A.I.},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {382},
	pages = {157 – 168},
	doi = {10.1007/978-3-030-93780-5_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126180963&doi=10.1007%2f978-3-030-93780-5_11&partnerID=40&md5=39a7a900fa7e072b14c4e5c33a687940},
	affiliations = {Experiential AI Postdoctoral Fellow, Northeastern University, Boston, United States},
	abstract = {Online recommendation systems are information filtering systems that provide users with streams of prioritized content based on expected individual preferences. While they can be of different types—e.g. collaborative, content-based, or hybrid filtering, they typically share the use of machine learning as a type of artificial intelligence able to perform predictions and profile personal taste. Drawing upon previous research in critical algorithm studies, this paper tackles the limitations of predictive content personalization and automated sorting. It does so by taking as a case study the computational art project This Recommendation System is Broken, developed in collaboration with metaLAB (at) Harvard as part of Curatorial A(i)gents (2020–2022), a series of experiments at the Harvard Art Museums exploring the interplay between A.I. and curatorial practices. While advocating for the ethical design and use of artificial intelligence, I discuss creative coding (Maeda in Creative code, Thames & Hudson Inc., New York, 2004 [1]) as a mode of engagement for artists, designers, media practitioners to take action in the development of context-sensitive algorithms that promote speculative (Dunne and Raby in Speculative everything: design, fiction and social dreaming. The MIT Press, 2013 [2]) design practices and sustainable future-making (Yelavich and Adams in Design as future-making. Bloomsbury Academic, London, GB, 2014 [3]), rather than adopting predictive or statistical models. The art project presented here challenges us to consider the biases of automated decision-making in generating instances of visibility/invisibility on media platforms and other online environments. What we might call “brokenness” is ultimately an attempt to escape the illusory quest for certainty and artificial perfection. Even more so, it is about shaping an ethic of A.I. practice and understanding how information filtering systems are transforming contemporary media cultures. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {A.I. ethics; Algorithms; Computational art; Online platforms; Recommendation systems},
	correspondence_address = {G. Taurino; Experiential AI Postdoctoral Fellow, Northeastern University, Boston, United States; email: g.taurino@northeastern.edu},
	editor = {Dingli A. and Pfeiffer A. and Serada A. and Bugeja M. and Bezzina S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303093779-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Media, Arts, and Design Artificial Intelligence conference, MADAI 2020; Conference date: 19 June 2020 through 19 June 2020; Conference code: 274259}
}

@ARTICLE{Rousi2022464,
	author = {Rousi, Rebekah},
	title = {Will Robots Know That They Are Robots? The Ethics of Utilizing Learning Machines},
	year = {2022},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13324 LNCS},
	pages = {464 – 476},
	doi = {10.1007/978-3-031-05434-1_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133014762&doi=10.1007%2f978-3-031-05434-1_31&partnerID=40&md5=5f2c56f0901e15ed0ad0c830c7ff3ff2},
	affiliations = {School of Marketing and Communication, University of Vaasa, PO Box 700, Vaasa, 65101, Finland},
	abstract = {The aspirations for a global society of learning technology are high these days. Machine Learning (ML) and artificial intelligence (AI) are two key terms of any socio-political and technological discourse. Both terms however, are riddled with confusion both on practical and conceptual levels. Learning for one thing, assumes that an entity gains and develops their knowledge bank in ways that are meaningful to the entity’s existence. Intelligence entails not just computationality but flexibility of thought, problem-solving skills and creativity. At the heart of both concepts rests the philosophy and science of consciousness. For in order to meaningfully acquire information, or build upon knowledge, there should be a core or executive function that defines the concerns of the entity and what newly encountered information means in relation to its existence. A part of this definition of concerns is also the demarcation of the self in relation to others. This paper takes a socio-cognitive scientific approach to deconstructing the two currently overused terms of ML and AI by creating a design fiction of sorts. This design fiction serves to illustrate some complex problems of consciousness, identity and ethics in a potential future world of learning machines. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Black box; Consciousness; Ethics; Identity; Machine learning; Robots},
	keywords = {Ethical technology; Intelligent robots; Black boxes; Conceptual levels; Consciousness; Design fictions; Global society; Identity; Know-that; Learning machines; Learning technology; Machine-learning; Machine learning},
	correspondence_address = {R. Rousi; School of Marketing and Communication, University of Vaasa, Vaasa, PO Box 700, 65101, Finland; email: rebekah.rousi@uwasa.fi},
	editor = {Rauterberg M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303105433-4},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 10th International Conference on Culture and Computing, C and C 2022, Held as Part of the 24th HCI International Conference, HCII 2022; Conference date: 26 June 2022 through 1 July 2022; Conference code: 279259; All Open Access, Green Open Access}
}

@BOOK{Hampton20221,
	author = {Hampton, Andrew J. and DeFalco, Jeanine A.},
	title = {The Frontlines of Artificial Intelligence Ethics: Human-Centric Perspectives on Technology’s Advance},
	year = {2022},
	journal = {The Frontlines of Artificial Intelligence Ethics: Human-Centric Perspectives on Technology’s Advance},
	pages = {1 – 212},
	doi = {10.4324/9781003030928},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85140571639&doi=10.4324%2f9781003030928&partnerID=40&md5=370cb4210ee420538b68debaadd5959c},
	affiliations = {Behavioral Sciences Department, Christian Brothers University, United States; Transfx, Inc., United States},
	abstract = {This foundational text examines the intersection of AI, psychology, and ethics, laying the groundwork for the importance of ethical considerations in the design and implementation of technologically supported education, decision support, and leadership training. AI already affects our lives profoundly, in ways both mundane and sensational, obvious and opaque. Much academic and industrial effort has considered the implications of this AI revolution from technical and economic perspectives, but the more personal, humanistic impact of these changes has often been relegated to anecdotal evidence in service to a broader frame of reference. Offering a unique perspective on the emerging social relationships between people and AI agents and systems, Hampton and DeFalco present cutting-edge research from leading academics, professionals, and policy standards advocates on the psychological impact of the AI revolution. Structured into three parts, the book explores the history of data science, technology in education, and combatting machine learning bias, as well as future directions for the emerging field, bringing the research into the active consideration of those in positions of authority. Exploring how AI can support expert, creative, and ethical decision making in both people and virtual human agents, this is essential reading for students, researchers, and professionals in AI, psychology, ethics, engineering education, and leadership, particularly military leadership. © 2022 selection and editorial matter, Andrew J. Hampton and Jeanine A. DeFalco.},
	publisher = {Taylor and Francis},
	isbn = {978-100057613-9; 978-036746766-1},
	language = {English},
	abbrev_source_title = {The Frontlines of Artificial Intelligence Ethics: Human-Centric Perspectives on Technology’s Advance},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Vayena202223,
	author = {Vayena, Effy and Blasimme, Alessandro},
	title = {A Systemic Approach to the Oversight of Machine Learning Clinical Translation},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {23 – 25},
	doi = {10.1080/15265161.2022.2055216},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128997726&doi=10.1080%2f15265161.2022.2055216&partnerID=40&md5=e775380d2eb28c114bde11eb8f5d0f0b},
	affiliations = {Eidgenossische Technische Hochschule Zurich, Switzerland},
	keywords = {Delivery of Health Care; Ethics, Research; Health Facilities; Humans; Machine Learning; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {E. Vayena; Health Sciences and Technology, Eidgenossische Technische Hochschule Zurich, Zurich, 8001, Switzerland; email: effy.vayena@hest.ethz.ch},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475963},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Levi202226,
	author = {Levi, Margaret and Bernstein, Michael and Waeiss, Charla},
	title = {Broadening the Ethical Scope},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {26 – 28},
	doi = {10.1080/15265161.2022.2055219},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128996238&doi=10.1080%2f15265161.2022.2055219&partnerID=40&md5=1008a8ab69030ad0c7e4ee9ec1ce7fc5},
	affiliations = {Stanford University, United States},
	keywords = {Delivery of Health Care; Ethics, Research; Health Facilities; Humans; Machine Learning; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {M. Levi; Center for Advanced Study in the Behavioral Sciences, Stanford University, Stanford, 75 Alta Rd, 94305-8090, United States; email: mlevi@stanford.edu},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35475958},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Li20226960,
	author = {Li, Bolian and Han, Zongbo and Li, Haining and Fu, Huazhu and Zhang, Changqing},
	title = {Trustworthy Long-Tailed Classification},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {6960 – 6969},
	doi = {10.1109/CVPR52688.2022.00684},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135852335&doi=10.1109%2fCVPR52688.2022.00684&partnerID=40&md5=d95ea3652d26728f53bcd4261af9e369},
	affiliations = {Tianjin University, China; Xidian University, China; Ihpc, A*star, Singapore},
	abstract = {Classification on long-tailed distributed data is a challenging problem, which suffers from serious class-imbalance and accordingly unpromising performance es-pecially on tail classes. Recently, the ensembling based methods achieve the state-of-the-art performance and show great potential. However, there are two limitations for cur-rent methods. First, their predictions are not trustworthy for failure-sensitive applications. This is especially harmful for the tail classes where the wrong predictions is basically fre-quent. Second, they assign unified numbers of experts to all samples, which is redundant for easy samples with excessive computational cost. To address these issues, we propose a Trustworthy Long-tailed Classification (TLC) method to jointly conduct classification and uncertainty estimation to identify hard samples in a multi-expert framework. Our TLC obtains the evidence-based uncertainty (EvU) and ev-idence for each expert, and then combines these uncer-tainties and evidences under the Dempster-Shafer Evidence Theory (DST). Moreover, we propose a dynamic expert en-gagement to reduce the number of engaged experts for easy samples and achieve efficiency while maintaining promising performances. Finally, we conduct comprehensive ex-periments on the tasks of classification, tail detection, OOD detection and failure prediction. The experimental results show that the proposed TLC outperforms existing methods and is trustworthy with reliable uncertainty. © 2022 IEEE.},
	author_keywords = {accountability; fairness; Machine learning; privacy and ethics in vision; Transfer/low-shot/long-tail learning; Transparency},
	keywords = {Computation theory; Forecasting; Accountability; Class imbalance; Distributed data; Fairness; Long tail; Machine-learning; Performance; Privacy and ethic in vision; Transfer/low-shot/long-tail learning; Uncertainty; Machine learning},
	correspondence_address = {C. Zhang; Tianjin University, China; email: zhangchangqing@tju.edu.cn},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Prajapati2022531,
	author = {Prajapati, Jigna B. and Prajapati, Bhupendra G.},
	title = {Clinical Decision Support System Braced with Artificial Intelligence: A Review},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {514 LNNS},
	pages = {531 – 540},
	doi = {10.1007/978-3-031-12413-6_42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135873373&doi=10.1007%2f978-3-031-12413-6_42&partnerID=40&md5=6e168988b85441bdacd33f9224b56624},
	affiliations = {Acharya Motibhai Patel Institute of Computer Studies, Ganpat University, Gujarat, India; Shree S K Patel College of Pharmaceutical Education and Research, Ganpat University, Gujarat, India},
	abstract = {The Healthcare sector is one of the most vibrant & crucial sectors in any development toward smart city substantivity. The health sector is enabled techier faster & faster. Artificial Intelligence (AI) is affecting the massive upliftment of all health-related services. AI is used to improve human decision-making. It performs advanced decision-making with Rules-based expert systems (ES) and machine-learning (ML). ES & ML can be combined to assist clinical releasers in their diagnosis operations for more accurate and effective clinical decisions, reduce clinical errors, and improve safety & efficacy. AI in clinical support is effective to save money to increasing the overall system's quality & performance. This paper examines a variety of studies that used Artificial Intelligence techniques in clinical decision support systems in order to define basic criteria for the usage of intelligent techniques. The use of AI in clinical systems raises ethical concerns. We also discuss the ethical, economic, legal, and societal consequences of AI in clinical support systems. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; CDSS (Clinical decision support system); ES (Expert System); Ethics; Machine learning},
	correspondence_address = {J.B. Prajapati; Acharya Motibhai Patel Institute of Computer Studies, Ganpat University, Gujarat, India; email: jigna.prajapati@ganpatuniversity.ac.in},
	editor = {Chen J.I.-Z. and Tavares J.M.R.S. and Shi F.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303112412-9},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Image Processing and Capsule Networks, ICIPCN 2022; Conference date: 20 May 2022 through 21 May 2022; Conference code: 281489}
}

@ARTICLE{Zhang2022,
	author = {Zhang, Helen and Lee, Irene and Ali, Safinah and DiPaola, Daniella and Cheng, Yihong and Breazeal, Cynthia},
	title = {Integrating Ethics and Career Futures with Technical Learning to Promote AI Literacy for Middle School Students: An Exploratory Study},
	year = {2022},
	journal = {International Journal of Artificial Intelligence in Education},
	doi = {10.1007/s40593-022-00293-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129775591&doi=10.1007%2fs40593-022-00293-3&partnerID=40&md5=024b9d9c03d6ea5f2bb36a1ec877f382},
	affiliations = {Lynch School of Education and Human Development, Boston College, Chestnut Hill, MA, United States; MIT Scheller Teacher Education Program, Massachusetts Institute of Technology, Cambridge, MA, United States; MIT Media Lab, Massachusetts Institute of Technology, Cambridge, MA, United States},
	abstract = {The rapid expansion of artificial intelligence (AI) necessitates promoting AI education at the K-12 level. However, educating young learners to become AI literate citizens poses several challenges. The components of AI literacy are ill-defined and it is unclear to what extent middle school students can engage in learning about AI as a sociotechnical system with socio-political implications. In this paper we posit that students must learn three core domains of AI: technical concepts and processes, ethical and societal implications, and career futures in the AI era. This paper describes the design and implementation of the Developing AI Literacy (DAILy) workshop that aimed to integrate middle school students’ learning of the three domains. We found that after the workshop, most students developed a general understanding of AI concepts and processes (e.g., supervised learning and logic systems). More importantly, they were able to identify bias, describe ways to mitigate bias in machine learning, and start to consider how AI may impact their future lives and careers. At exit, nearly half of the students explained AI as not just a technical subject, but one that has personal, career, and societal implications. Overall, this finding suggests that the approach of incorporating ethics and career futures into AI education is age appropriate and effective for developing AI literacy among middle school students. This study contributes to the field of AI Education by presenting a model of integrating ethics into the teaching of AI that is appropriate for middle school students. © 2022, International Artificial Intelligence in Education Society.},
	author_keywords = {AI ethics; Bias; Career implications; Middle school education; Sociotechnical systems},
	keywords = {Education computing; Ethical technology; Machine learning; Artificial intelligence ethic; Bias; Career implication; Exploratory studies; Middle school educations; Middle school students; Political implications; Rapid expansion; Societal implications; Sociotechnical systems; Students},
	correspondence_address = {H. Zhang; Lynch School of Education and Human Development, Boston College, Chestnut Hill, United States; email: zhangzm@bc.edu},
	publisher = {Springer},
	issn = {15604292},
	language = {English},
	abbrev_source_title = {Int. J. Artif. Intell. Educ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Wang20223870,
	author = {Wang, Qian and Kurz, Daniel},
	title = {Reconstructing Training Data from Diverse ML Models by Ensemble Inversion},
	year = {2022},
	journal = {Proceedings - 2022 IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022},
	pages = {3870 – 3878},
	doi = {10.1109/WACV51458.2022.00392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126137503&doi=10.1109%2fWACV51458.2022.00392&partnerID=40&md5=d3da9765eb12b65c6cfe2495884e2e9b},
	affiliations = {Apple},
	abstract = {Model Inversion (MI), in which an adversary abuses access to a trained Machine Learning (ML) model attempting to infer sensitive information about its original training data, has attracted increasing research attention. During MI, the trained model under attack (MUA) is usually frozen and used to guide the training of a generator, such as a Generative Adversarial Network (GAN), to reconstruct the distribution of the original training data of that model. This might cause leakage of original training samples, and if successful, the privacy of dataset subjects will be at risk if the training data contains Personally Identifiable Information (PII). Therefore, an in-depth investigation of the potentials of MI techniques is crucial for the development of corresponding defense techniques. High-quality reconstruction of training data based on a single model is challenging. However, existing MI literature does not explore targeting multiple models jointly, which may provide additional information and diverse perspectives to the adversary.We propose the ensemble inversion technique that estimates the distribution of original training data by training a generator constrained by an ensemble (or set) of trained models with shared subjects or entities. This technique leads to noticeable improvements of the quality of the generated samples with distinguishable features of the dataset entities compared to MI of a single ML model. We achieve high quality results without any dataset and show how utilizing an auxiliary dataset that's similar to the presumed training data improves the results. The impact of model diversity in the ensemble is thoroughly investigated and additional constraints are utilized to encourage sharp predictions and high activations for the reconstructed samples, leading to more accurate reconstruction of training images.  © 2022 IEEE.},
	author_keywords = {Accountability; Adversarial Attack and Defense Methods; Adversarial Learning; Deep Learning; Explainable AI; Fairness; Privacy and Ethics in Vision Deep Learning; Security/Surveillance},
	keywords = {Computer vision; Data privacy; Deep learning; Image reconstruction; Network security; Accountability; Adversarial attack and defense method; Adversarial learning; Deep learning; Explainable AI; Fairness; Model inversion; Privacy and ethic in vision deep learning; Security surveillance; Training data; Generative adversarial networks},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166540915-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/CVF Winter Conf. Appl. Comput. Vis., WACV},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 22nd IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022; Conference date: 4 January 2022 through 8 January 2022; Conference code: 177326; All Open Access, Green Open Access}
}

@ARTICLE{McCradden20228,
	author = {McCradden, Melissa D and Anderson, James A and A. Stephenson, Elizabeth and Drysdale, Erik and Erdman, Lauren and Goldenberg, Anna and Zlotnik Shaul, Randi},
	title = {A Research Ethics Framework for the Clinical Translation of Healthcare Machine Learning},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {8 – 22},
	doi = {10.1080/15265161.2021.2013977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128910978&doi=10.1080%2f15265161.2021.2013977&partnerID=40&md5=06f0533d3494b851a6b3ec97041119fb},
	affiliations = {Department of Bioethics, The Hospital for Sick Children, Canada; Genetics and Genome Biology, The Hospital for Sick Children, Peter Gilgan Centre for Research and Learning, Canada; Division of Clinical & Public Health, Dalla Lana School of Public Health, Canada; Institute for Health Management Policy, & Evaluation, University of Toronto, Canada; Labatt Family Heart Centre, The Hospital for Sick Children, Canada; Department of Pediatrics, The Hospital for Sick Children, Canada; Vector Institute, Canada; Department of Computer Science, University of Toronto, Canada; CIFAR, Canada; Child Health Evaluative Sciences, The Hospital for Sick Children, Canada},
	abstract = {The application of artificial intelligence and machine learning (ML) technologies in healthcare have immense potential to improve the care of patients. While there are some emerging practices surrounding responsible ML as well as regulatory frameworks, the traditional role of research ethics oversight has been relatively unexplored regarding its relevance for clinical ML. In this paper, we provide a comprehensive research ethics framework that can apply to the systematic inquiry of ML research across its development cycle. The pathway consists of three stages: (1) exploratory, hypothesis-generating data access; (2) silent period evaluation; (3) prospective clinical evaluation. We connect each stage to its literature and ethical justification and suggest adaptations to traditional paradigms to suit ML while maintaining ethical rigor and the protection of individuals. This pathway can accommodate a multitude of research designs from observational to controlled trials, and the stages can apply individually to a variety of ML applications. © 2022 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	author_keywords = {Ethics committees; health care delivery; human subjects research; informed consent; IRB (Institutional Review Board); research ethics},
	keywords = {Artificial Intelligence; Delivery of Health Care; Ethics Committees, Research; Ethics, Research; Humans; Informed Consent; Machine Learning; Prospective Studies; artificial intelligence; health care delivery; human; informed consent; machine learning; professional standard; prospective study; research ethics},
	correspondence_address = {M.D. McCradden; Department of Bioethics, The Hospital for Sick Children, Toronto, Canada; email: melissa.mccradden@sickkids.ca},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35048782},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Peterson2022,
	author = {Peterson, Clayton and Hamrouni, Naïma},
	title = {Preliminary Thoughts on Defining f(x) for Ethical Machines},
	year = {2022},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	volume = {35},
	doi = {10.32473/flairs.v35i.130545},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131117520&doi=10.32473%2fflairs.v35i.130545&partnerID=40&md5=b0a456e4aa32f685bff92a34e220d94f},
	affiliations = {Université du Québec à Trois-Rivières, 3351 Bd des Forges, Trois-Rivières, G8Z 4M3, QC, Canada},
	abstract = {There is a growing literature in machine ethics attempting at creating ethical machines through AI and machine learning. Although many concerns with respect to such attempts have been raised, including the difficulties regarding the gathering of relevant contextual information as well as solving ethical dilemmas, it appears that many fundamental ethical notions have been overlooked in the implementation of normative theories to machines. This paper provides a preliminary analysis of important aspects that need to be taken into account in the attempt of defining so called ethical machines. © 2021 by the authors. All rights reserved.},
	keywords = {Philosophical aspects; Contextual information; Ethical dilemma; Normative theory; Preliminary analysis; Machine learning},
	editor = {Bartak R. and Franklin M. and Keshtkar F.},
	publisher = {Florida OJ},
	issn = {23340754},
	language = {English},
	abbrev_source_title = {Proc. Int. Fla. Artif. Intell. Res. Soc. Conf., FLAIRS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 35th International Florida Artificial Intelligence Research Society Conference, FLAIRS-35 2022; Conference date: 15 May 2022 through 18 May 2022; Conference code: 277889; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zhang20228014,
	author = {Zhang, Hanlin and Zhang, Yi-Fan and Liu, Weiyang and Weller, Adrian and Scholkopf, Bernhard and Xing, Eric P.},
	title = {Towards Principled Disentanglement for Domain Generalization},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {8014 – 8024},
	doi = {10.1109/CVPR52688.2022.00786},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139543422&doi=10.1109%2fCVPR52688.2022.00786&partnerID=40&md5=4479a3b34761f92add573741cfba14f7},
	affiliations = {Carnegie Mellon University, United States; Chinese Academy of Science, China; University of Cambridge, United Kingdom; Max Planck Institute for Intelligent Systems, Tübingen, Germany; Alan Turing Institute; MBZUAI},
	abstract = {A fundamental challenge for machine learning models is generalizing to out-of-distribution (OOD) data, in part due to spurious correlations. To tackle this challenge, we first formalize the OOD generalization problem as constrained optimization, called Disentanglement-constrained Domain Generalization (DDG). We relax this non-trivial constrained optimization problem to a tractable form with finite-dimensional parameterization and empirical approxi-mation. Then a theoretical analysis of the extent to which the above transformations deviates from the original problem is provided. Based on the transformation, we propose a primal-dual algorithm for joint representation disentanglement and domain generalization. In contrast to traditional approaches based on domain adversarial training and domain labels, DDG jointly learns semantic and variation encoders for disentanglement, enabling flexible manipulation and augmentation on training data. DDG aims to learn intrinsic representations of semantic concepts that are invariant to nuisance factors and generalizable across domains. Comprehensive experiments on popular benchmarks show that DDG can achieve competitive OOD performance and uncover interpretable salient structures within data. © 2022 IEEE.},
	author_keywords = {accountability; fairness; privacy and ethics in vision; Representation learning; Transfer/low-shot/long-tail learning; Transparency},
	keywords = {Benchmarking; Computer vision; Semantics; Accountability; Constrained domain; Fairness; Generalisation; Learn+; Long tail; Machine learning models; Privacy and ethic in vision; Representation learning; Transfer/low-shot/long-tail learning; Constrained optimization},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@ARTICLE{Spector-Bagdady20224,
	author = {Spector-Bagdady, Kayte and Rahimzadeh, Vasiliki and Jaffe, Kaitlyn and Moreno, Jonathan},
	title = {Promoting Ethical Deployment of Artificial Intelligence and Machine Learning in Healthcare},
	year = {2022},
	journal = {American Journal of Bioethics},
	volume = {22},
	number = {5},
	pages = {4 – 7},
	doi = {10.1080/15265161.2022.2059206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129069140&doi=10.1080%2f15265161.2022.2059206&partnerID=40&md5=15c79bfd0f54c23468012476c106f189},
	affiliations = {University of Michigan Medical School (USA), United States; Stanford University, United States; University of Pennsylvania, United States},
	keywords = {Artificial Intelligence; Delivery of Health Care; Ethics, Research; Health Facilities; Humans; Machine Learning; artificial intelligence; health care delivery; health care facility; human; machine learning; research ethics},
	correspondence_address = {K. Spector-Bagdady; Center for Bioethics and Social Sciences in Medicine, University of Michigan Medical School (USA), North Campus Research Complex, Ann Arbor, 2800 Plymouth Road, Bldg. 14, G016, 48109-2800,, United States; email: kaytesb@med.umich.edu},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {35499568},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Talat2022769,
	author = {Talat, Zeerak and Blix, Hagen and Valvoda, Josef and Ganesh, Maya Indira and Cotterell, Ryan and Williams, Adina},
	title = {On the Machine Learning of Ethical Judgments from Natural Language},
	year = {2022},
	journal = {NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
	pages = {769 – 779},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138415297&partnerID=40&md5=6b00a64c5f44ce518a568f968e425339},
	affiliations = {Digital Democracies Institute; New York University, United States; University of Cambridge, United Kingdom; ETH Zürich, Switzerland; Facebook AI Research},
	abstract = {Ethics is one of the longest standing intellectual endeavors of humanity. In recent years, the fields of AI and NLP have attempted to address ethical issues of harmful outcomes in machine learning systems that are made to interface with humans. One recent approach in this vein is the construction of NLP morality models that can take in arbitrary text and output a moral judgment about the situation described. In this work, we offer a critique of such NLP methods for automating ethical decision-making. Through an audit of recent work on computational approaches for predicting morality, we examine the broader issues that arise from such efforts. We conclude with a discussion of how machine ethics could usefully proceed in NLP, by focusing on current and near-future uses of technology, in a way that centers around transparency, democratic values, and allows for straightforward accountability. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Decision making; Ethical technology; Machine learning; Computational approach; Ethical decision making; Ethical issues; Ethical judgements; Machine learning systems; Machine-learning; Moral judgment; Natural languages; On currents; On-currents; Natural language processing systems},
	correspondence_address = {Z. Talat; Digital Democracies Institute; email: zeerak_talat@sfu.ca; H. Blix; New York University, United States; email: hagen.blix@nyu.edu},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {978-195591771-1},
	language = {English},
	abbrev_source_title = {NAACL - Conf. N. Am. Chapter Assoc. Comput. Linguist.: Hum. Lang. Technol., Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2022; Conference date: 10 July 2022 through 15 July 2022; Conference code: 182070}
}

@ARTICLE{Lorenzini2022,
	author = {Lorenzini, Giorgia and Shaw, David Martin and Arbelaez Ossa, Laura and Elger, Bernice Simone},
	title = {Machine learning applications in healthcare and the role of informed consent: Ethical and practical considerations},
	year = {2022},
	journal = {Clinical Ethics},
	doi = {10.1177/14777509221094476},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130041363&doi=10.1177%2f14777509221094476&partnerID=40&md5=687e21972467be5e54a7307b53556c76},
	affiliations = {Institute for Biomedical Ethics, Basel, Switzerland; Care and Public Health Research Institute, Maastricht University, Netherlands; Center for Legal Medicine (CURML), University of Geneva, Switzerland},
	abstract = {Informed consent is at the core of the clinical relationship. With the introduction of machine learning (ML) in healthcare, the role of informed consent is challenged. This paper addresses the issue of whether patients must be informed about medical ML applications and asked for consent. It aims to expose the discrepancy between ethical and practical considerations, while arguing that this polarization is a false dichotomy: in reality, ethics is applied to specific contexts and situations. Bridging this gap and considering the whole picture is essential for advancing the debate. In the light of the possible future developments of the situation and the technologies, as well as the benefits that informed consent for ML can bring to shared decision-making, the present analysis concludes that it is necessary to prepare the ground for a possible future requirement of informed consent for medical ML. © The Author(s) 2022.},
	author_keywords = {Ethics; healthcare; informed consent; machine learning; shared decision-making; transparency},
	correspondence_address = {G. Lorenzini; Institute for Biomedical Ethics, Basel, Switzerland; email: giorgia.lorenzini@unibas.ch},
	publisher = {SAGE Publications Ltd},
	issn = {14777509},
	language = {English},
	abbrev_source_title = {Clini. Ethics},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Lu2022101,
	author = {Lu, Qinghua and Zhu, Liming and Xu, Xiwei and Whittle, Jon and Xing, Zhenchang},
	title = {Towards a Roadmap on Software Engineering for Responsible AI},
	year = {2022},
	journal = {Proceedings - 1st International Conference on AI Engineering - Software Engineering for AI, CAIN 2022},
	pages = {101 – 112},
	doi = {10.1145/3522664.3528607},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133462466&doi=10.1145%2f3522664.3528607&partnerID=40&md5=5a115707c669f37f2d3c01f68ca3ae44},
	affiliations = {Data61, CSIRO, Australia},
	abstract = {Although AI is transforming the world, there are serious concerns about its ability to behave and make decisions responsibly. Many ethical regulations, principles, and frameworks for responsible AI have been issued recently. However, they are high level and difficult to put into practice. On the other hand, most AI researchers focus on algorithmic solutions, while the responsible AI challenges actually crosscut the entire engineering lifecycle and components of AI systems. To close the gap in operationalizing responsible AI, this paper aims to develop a roadmap on software engineering for responsible AI. The roadmap focuses on (i) establishing multi-level governance for responsible AI systems, (ii) setting up the development processes incorporating process-oriented practices for responsible AI systems, and (iii) building responsible-AI-by-design into AI systems through system-level architectural style, patterns and techniques. CCS CONCEPTS • Software and its engineering;  © 2022 ACM.},
	author_keywords = {AI; DevOps; ethics; machine learning; MLOps; requirement engineering; responsible AI; software architecture; software engineering},
	keywords = {Ethical technology; Laws and legislation; Machine learning; Software architecture; AI systems; Algorithmic solutions; Development process; Machine-learning; MLOp; Multi-level governance; Regulation principles; Requirement engineering; Responsible AI; Roadmap; Life cycle},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-145039275-4},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. AI Eng. - Softw. Eng. AI, CAIN},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 1st International Conference on AI Engineering - Software Engineering for AI, CAIN 2022; Conference date: 16 May 2022 through 17 May 2022; Conference code: 180165; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Bohle202210319,
	author = {Bohle, Moritz and Fritz, Mario and Schiele, Bernt},
	title = {B-cos Networks: Alignment is All We Need for Interpretability},
	year = {2022},
	journal = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
	volume = {2022-June},
	pages = {10319 – 10328},
	doi = {10.1109/CVPR52688.2022.01008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136328172&doi=10.1109%2fCVPR52688.2022.01008&partnerID=40&md5=8933c80b8746381882e83c031cf45f8b},
	affiliations = {Mpi for Informatics, Saarland Informatics Campus, Germany; CISPA Helmholtz Center for Information Security, Germany},
	abstract = {We present a new direction for increasing the interpretability of deep neural networks (DNNs) by promoting weight-input alignment during training. For this, we propose to replace the linear transforms in DNNs by our B-cos transform. As we show, a sequence (network) of such transforms induces a single linear transform that faithfully summarises the full model computations. Moreover, the B-cos transform introduces alignment pressure on the weights during optimisation. As a result, those induced linear transforms become highly interpretable and align with task-relevant features. Importantly, the B-cos transform is designed to be compatible with existing architectures and we show that it can easily be integrated into common models such as VGGs, ResNets, InceptionNets, and DenseNets, whilst maintaining similar performance on ImageNet. The resulting explanations are of high visual quality and perform well under quantitative metrics for interpretability. Code available at github.com/moboehle/B-cos. © 2022 IEEE.},
	author_keywords = {accountability; Computer vision theory; Deep learning architectures and techniques; Explainable computer vision; fairness; Machine learning; privacy and ethics in vision; Transparency; Visual reasoning},
	keywords = {Cobalt compounds; Data privacy; Deep neural networks; Network architecture; Accountability; Computer vision theory; Deep learning architecture and technique; Explainable computer vision; Fairness; Learning architectures; Learning techniques; Machine-learning; Privacy and ethic in vision; Vision theory; Visual reasoning; Computer vision},
	publisher = {IEEE Computer Society},
	issn = {10636919},
	isbn = {978-166546946-3},
	coden = {PIVRE},
	language = {English},
	abbrev_source_title = {Proc IEEE Comput Soc Conf Comput Vision Pattern Recognit},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition, CVPR 2022; Conference date: 19 June 2022 through 24 June 2022; Conference code: 183275; All Open Access, Green Open Access}
}

@CONFERENCE{Riley2022,
	author = {Riley, Patrick C. and Deshpande, Samir V. and Ince, Brian S. and Dereje, Ruth and Davidson, Charles E. and O'Donnell, Kyle P. and Hauck, Brian C.},
	title = {Interpreting Chemical Detection Alarms with Live Analysis of ML Algorithms},
	year = {2022},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {12116},
	doi = {10.1117/12.2619166},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132923377&doi=10.1117%2f12.2619166&partnerID=40&md5=f813ad3d1b8937ce600f4dd318f8f45e},
	affiliations = {U.S. Army Combat Capabilities Development Command Chemical Biological Center, Research & Technology Directorate, 8198 Blackhawk Rd, Aberdeen Proving Ground, 21010, MD, United States; Science and Technology Corporation, 111 Bata Blvd, Suite C, Belcamp, 21017, MD, United States},
	abstract = {Chemical Biological Radiological Nuclear and Explosive (CBRNE) sensing systems in the field provide alarms in the form of simple graphical representations, lights, vibrations, and alarm sounds to maximize the reaction time of the user in the event of a hazardous situation. Artificial Intelligence (AI) can be used to reduce the false alarms of chemical detectors, allowing users to react with confidence when an alarm does occurs. However, the Department of Defense's AI ethics standards states that technologies incorporating AI systems be traceable, reliable, and governable. Given the complex nature of AI and the difficulties of interpreting results, testing and evaluating AI systems poses a challenge for CBRNE sensing systems. To properly interpret and evaluate AI systems it is imperative graphical user interfaces (GUI) are designed to be simple interfaces that provide easy to interpret results. Presented here is an interpretable alarm GUI for orthogonal networked sensors (IAGOnet). IAGOnet provides real-time status of connected sensors utilizing a familiar replication of their onboard results, along with simple to understand graphical representations of confidence metrics from machine learning (ML) predictions. IAGOnet allows a user to compare the detector's original alarm state to current and previous predictions of classification algorithms, thereby reducing the false alarms. Our work demonstrates the practical nature of IAGOnet by utilizing data from an ion mobility spectrometry (IMS) based detector and a multi-gas detector. © 2022 SPIE},
	author_keywords = {Artificial Intelligence; Chemical Detection; False Alarms; GUI; Ion Mobility Spectrometry; Machine Learning; Python; Random Forest},
	keywords = {Alarm systems; Bioinformatics; Chemical detection; Decision trees; Errors; Graphic methods; Graphical user interfaces; Ion mobility spectrometers; Machine learning; Random forests; Artificial intelligence systems; Falsealarms; Graphical representations; Ion mobility spectrometry; Live-analysis; Machine-learning; Networked sensors; Random forests; Sensing systems; Simple++; Python},
	editor = {Guicheteau J.A. and Howle C.R.},
	publisher = {SPIE},
	issn = {0277786X},
	isbn = {978-151065108-1},
	coden = {PSISD},
	language = {English},
	abbrev_source_title = {Proc SPIE Int Soc Opt Eng},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Chemical, Biological, Radiological, Nuclear, and Explosives (CBRNE) Sensing XXIII 2022; Conference date: 6 June 2022 through 12 June 2022; Conference code: 180181}
}

@BOOK{Cortés2022219,
	author = {Cortés, Atia and Buslón, Nataly and Arroyo, Liliana},
	title = {Societal and ethical impact of technologies for health and biomedicine},
	year = {2022},
	journal = {Sex and Gender Bias in Technology and Artificial Intelligence: Biomedicine and Healthcare Applications},
	pages = {219 – 238},
	doi = {10.1016/B978-0-12-821392-6.00002-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137542917&doi=10.1016%2fB978-0-12-821392-6.00002-9&partnerID=40&md5=37e5074f878852828119cde61a5dd04e},
	affiliations = {Life Sciences—Social Link Analytics Life Sciences Group, Barcelona, Spain; Barcelona Supercomputing Center (BSC), Barcelona, Spain; Bioinfo4Women (B4W), Barcelona, Spain; Department of Society, Politics and Sustainability (ESADE)., Ramón Llull University, Barcelona, Spain},
	abstract = {The healthcare sector has been an early adopter of new technologies such as artificial intelligence, nanotechnology, or genome sequencing. They are expected to improve healthcare systems and augment practitioners’ skills. The deployment of wearable sensors and healthcare trackers are empowering individuals, making them self-aware of their wellbeing but also turning them into data donors. Personal data are essential to train machine learning models used to support healthcare professionals in decision making. However, it is extremely relevant to consider the power of the (mis-)represented population in the data analyzed. Artificial intelligent systems used in precision medicine need to be robust, not only technically but also socially by tackling gender imbalance, technology access, or other issues that may affect vulnerable groups in healthcare. This chapter offers an overview on the opportunities of digital health ecosystems while highlighting some social, ethical, and technical challenges. It also provides a review of the relation of the traditional ethical principles used in health and biomedicine and those defined for the design, deployment, and use of a trustworthy AI in Europe. © 2022 Elsevier Inc. All rights reserved.},
	author_keywords = {AI ethics; Artificial intelligence; Ethics; Health AI; Responsible AI; Social impact AI},
	publisher = {Elsevier},
	isbn = {978-012821392-6; 978-012821393-3},
	language = {English},
	abbrev_source_title = {Sex and Gend. Bias in Technology and Artificial Intelligence: Biomedicine and Healthc. Applications},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@ARTICLE{Herman20211466,
	author = {Herman, Daniel S. and Rhoads, Daniel D. and Schulz, Wade L. and Durant, Thomas J.S.},
	title = {Artificial Intelligence and Mapping a New Direction in Laboratory Medicine: A Review},
	year = {2021},
	journal = {Clinical Chemistry},
	volume = {67},
	number = {11},
	pages = {1466 – 1482},
	doi = {10.1093/clinchem/hvab165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121477210&doi=10.1093%2fclinchem%2fhvab165&partnerID=40&md5=37d9e8b4513e136b3a4941a1c0654b27},
	affiliations = {Department of Pathology and Laboratory Medicine, University of Pennsylvania, Philadelphia, PA, United States; Department of Laboratory Medicine, Cleveland Clinic, Cleveland, OH, United States; Department of Pathology, Cleveland Clinic Lerner College of Medicine, Case Western Reserve University, Cleveland, OH, United States; Department of Laboratory Medicine, Yale University, New Haven, CT, United States},
	abstract = {BACKGROUND: Modern artificial intelligence (AI) and machine learning (ML) methods are now capable of completing tasks with performance characteristics that are comparable to those of expert human operators. As a result, many areas throughout healthcare are incorporating these technologies, including in vitro diagnostics and, more broadly, laboratory medicine. However, there are limited literature reviews of the landscape, likely future, and challenges of the application of AI/ML in laboratory medicine. CONTENT: In this review, we begin with a brief introduction to AI and its subfield of ML. The ensuing sections describe ML systems that are currently in clinical laboratory practice or are being proposed for such use in recent literature, ML systems that use laboratory data outside the clinical laboratory, challenges to the adoption of ML, and future opportunities for ML in laboratory medicine. SUMMARY: AI and ML have and will continue to influence the practice and scope of laboratory medicine dramatically. This has been made possible by advancements in modern computing and the widespread digitization of health information. These technologies are being rapidly developed and described, but in comparison, their implementation thus far has been modest. To spur the implementation of reliable and sophisticated ML-based technologies, we need to establish best practices further and improve our information system and communication infrastructure. The participation of the clinical laboratory community is essential to ensure that laboratory data are sufficiently available and incorporated conscientiously into robust, safe, and clinically effective ML-supported clinical diagnostics. © American Association for Clinical Chemistry 2021. All rights reserved.},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Laboratories; Machine Learning; Medicine; artificial intelligence; bacteriology; clinical chemistry; clinical effectiveness; clinical immunology; clinical laboratory; clinical practice; concept mapping; data quality; digitization; ethics; human; information processing; information system; laboratory; machine learning; medical information; medicine; microscopy; polymerase chain reaction; Review; risk assessment; health care delivery; laboratory},
	correspondence_address = {T.J.S. Durant; New Haven, 20 York St/PS 535, 06510, United States; email: thomas.durant@yale.edu},
	publisher = {Oxford University Press},
	issn = {00099147},
	coden = {CLCHA},
	pmid = {34557917},
	language = {English},
	abbrev_source_title = {Clin. Chem.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Bronze Open Access}
}

@ARTICLE{Bonsón2021,
	author = {Bonsón, Enrique and Lavorato, Domenica and Lamboglia, Rita and Mancini, Daniela},
	title = {Artificial intelligence activities and ethical approaches in leading listed companies in the European Union},
	year = {2021},
	journal = {International Journal of Accounting Information Systems},
	volume = {43},
	doi = {10.1016/j.accinf.2021.100535},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116053592&doi=10.1016%2fj.accinf.2021.100535&partnerID=40&md5=d2bf91f56cff9524f63354eac7aebe1d},
	affiliations = {Department of Financial Economics and Accounting, University of Huelva, Plaza de la Merced, 11. 21001, Huelva, Spain; Department of Business and Economics, University of Naples “Parthenope”, Via Generale Parisi 12, Naples, 80132, Italy; Faculty of Law, University of Teramo, Via Renato Balzarini, 1, Teramo, 64100, Italy},
	abstract = {This study explores the information regarding Artificial Intelligence (AI) included by European listed companies in their annual and/or sustainability reports. The study mainly focuses on (1) the development and use of AI systems/projects reported by companies, (2) the extent to which companies disclose ethical principles or guidelines regarding AI and (3) the factors explaining these practices. The study analyses the reports of 200 companies listed in the major indexes of Germany, Sweden, Finland, France, Spain, and Italy, both from qualitative and quantitative perspectives. All reports are analysed, using content analysis methodology, to identify expressions such as ‘artificial intelligence’, ‘machine learning’, ‘deep learning’, and ‘big data’, and then classified accordingly. The study's findings suggest a growing interest in the above-mentioned technologies, although 41.5% of companies do not report any activity in the field of AI. The adoption of ethical approaches to AI is at a very preliminary stage, and<5% of companies report on that issue. The quantitative analysis shows that larger companies, companies in the Technology and Telecommunications industries, and companies based in Southern countries are more likely to disclose information on AI activity. The majority of companies that develop ethical principles are listed in the Northern region and belong to the Technology and Telecommunications industries. The study provides evidence of AI disclosure, a type of non-financial disclosure that has not been explored yet in the literature. Unlike existing studies, we propose a first definition of the topic and a taxonomy that can be used in further research on AI disclosure and can contribute to the development of KPIs in the field. Furthermore, this study provides a theoretical framework integrating some traditional theories, such as Voluntary disclosure theory, Signalling theory, and Legitimacy theory, specifically drawn to interpret AI disclosure practices, which can help with a further in-depth exploration of AI disclosure combining concurrent perspectives. The study's results may serve as a starting point for researchers and companies interested in the topic. © 2021 Elsevier Inc.},
	author_keywords = {Artificial Intelligence; Content analysis; Corporate ethics; Non-financial reporting; Voluntary disclosure theories},
	correspondence_address = {D. Lavorato; Department of Business and Economics, University of Naples “Parthenope”, Naples, Via Generale Parisi 12, 80132, Italy; email: domenica.lavorato@uniparthenope.it},
	publisher = {Elsevier Inc.},
	issn = {14670895},
	language = {English},
	abbrev_source_title = {Int. J. Account. Inf. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Campedelli2021503,
	author = {Campedelli, Gian Maria},
	title = {Where are we? Using Scopus to map the literature at the intersection between artificial intelligence and research on crime},
	year = {2021},
	journal = {Journal of Computational Social Science},
	volume = {4},
	number = {2},
	pages = {503 – 530},
	doi = {10.1007/s42001-020-00082-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124066092&doi=10.1007%2fs42001-020-00082-9&partnerID=40&md5=c227317fa840d294f06b496e81271d06},
	affiliations = {University of Trento, Trento, Italy},
	abstract = {Research on artificial intelligence (AI) applications has spread over many scientific disciplines. Scientists have tested the power of intelligent algorithms developed to predict (or learn from) natural, physical and social phenomena. This also applies to crime-related research problems. Nonetheless, studies that map the current state of the art at the intersection between AI and crime are lacking. What are the current research trends in terms of topics in this area? What is the structure of scientific collaboration when considering works investigating criminal issues using machine learning, deep learning, and AI in general? What are the most active countries in this specific scientific sphere? Using data retrieved from the Scopus database, this work quantitatively analyzes 692 published works at the intersection between AI and crime employing network science to respond to these questions. Results show that researchers are mainly focusing on cyber-related criminal topics and that relevant themes such as algorithmic discrimination, fairness, and ethics are considerably overlooked. Furthermore, data highlight the extremely disconnected structure of co-authorship networks. Such disconnectedness may represent a substantial obstacle to a more solid community of scientists interested in these topics. Additionally, the graph of scientific collaboration indicates that countries that are more prone to engage in international partnerships are generally less central in the network. This means that scholars working in highly productive countries (e.g. the United States, China) tend to mostly collaborate domestically. Finally, current issues and future developments within this scientific area are also discussed. © 2020, The Author(s).},
	author_keywords = {Artificial intelligence; Co-authorship networks; Computational social science; Criminology; Machine learning; Social network analysis},
	correspondence_address = {G.M. Campedelli; University of Trento, Trento, Italy; email: gianmaria.campedelli@unitn.it},
	publisher = {Springer},
	issn = {24322717},
	language = {English},
	abbrev_source_title = {J Comput Soc Sc},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Lauffenburger2021,
	author = {Lauffenburger, Julie C. and Yom-Tov, Elad and Keller, Punam A. and McDonnell, Marie E. and Bessette, Lily G. and Fontanet, Constance P. and Sears, Ellen S. and Kim, Erin and Hanken, Kaitlin and Joseph Buckley, J. and Barlev, Renee A. and Haff, Nancy and Choudhry, Niteesh K.},
	title = {REinforcement learning to improve non-adherence for diabetes treatments by Optimising Response and Customising Engagement (REINFORCE): Study protocol of a pragmatic randomised trial},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {12},
	doi = {10.1136/bmjopen-2021-052091},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121008254&doi=10.1136%2fbmjopen-2021-052091&partnerID=40&md5=1127131d0d2d8e167fbfd272c3bb7ff9},
	affiliations = {Center for Healthcare Delivery Sciences, Department of Medicine, Brigham and Women's Hospital and Harvard Medical School, Boston, MA, United States; Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States; Microsoft Research, Microsoft Herzeliya, Israel; Tuck School of Business, Dartmouth College, Hanover, NH, United States; Endocrinology, Diabetes and Hypertension, Department of Medicine, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States; Division of Sleep Medicine, Department of Medicine, Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States},
	abstract = {Introduction Achieving optimal diabetes control requires several daily self-management behaviours, especially adherence to medication. Evidence supports the use of text messages to support adherence, but there remains much opportunity to improve their effectiveness. One key limitation is that message content has been generic. By contrast, reinforcement learning is a machine learning method that can be used to identify individuals' patterns of responsiveness by observing their response to cues and then optimising them accordingly. Despite its demonstrated benefits outside of healthcare, its application to tailoring communication for patients has received limited attention. The objective of this trial is to test the impact of a reinforcement learning-based text messaging programme on adherence to medication for patients with type 2 diabetes. Methods and analysis In the REinforcement learning to Improve Non-adherence For diabetes treatments by Optimising Response and Customising Engagement (REINFORCE) trial, we are randomising 60 patients with suboptimal diabetes control treated with oral diabetes medications to receive a reinforcement learning intervention or control. Subjects in both arms will receive electronic pill bottles to use, and those in the intervention arm will receive up to daily text messages. The messages will be individually adapted using a reinforcement learning prediction algorithm based on daily adherence measurements from the pill bottles. The trial's primary outcome is average adherence to medication over the 6-month follow-up period. Secondary outcomes include diabetes control, measured by glycated haemoglobin A1c, and self-reported adherence. In sum, the REINFORCE trial will evaluate the effect of personalising the framing of text messages for patients to support medication adherence and provide insight into how this could be adapted at scale to improve other self-management interventions. Ethics and dissemination This study was approved by the Mass General Brigham Institutional Review Board (IRB) (USA). Findings will be disseminated through peer-reviewed journals, clinicaltrials.gov reporting and conferences. Trial registration number Clinicaltrials.gov (NCT04473326).  © },
	author_keywords = {clinical trials; diabetes & endocrinology; public health},
	keywords = {Diabetes Mellitus, Type 2; Glycated Hemoglobin A; Humans; Medication Adherence; Randomized Controlled Trials as Topic; Self-Management; Text Messaging; insulin; oral antidiabetic agent; glycosylated hemoglobin; adult; Article; clinical trial protocol; controlled study; diabetes control; electronic health record; feedback system; female; follow up; health behavior; human; insulin treatment; major clinical study; male; medication compliance; non insulin dependent diabetes mellitus; patient compliance; pragmatic trial; randomized controlled trial; reinforcement learning (machine learning); self care; self monitoring; self report; social reinforcement; text messaging; medication compliance; randomized controlled trial (topic); self care; text messaging},
	correspondence_address = {J.C. Lauffenburger; Center for Healthcare Delivery Sciences, Department of Medicine, Brigham and Women's Hospital and Harvard Medical School, Boston, United States; email: jlauffenburger@bwh.harvard.edu; J.C. Lauffenburger; Center for Healthcare Delivery Sciences, Department of Medicine, Brigham and Women's Hospital and Harvard Medical School, Boston, United States; email: jlauffenburger@bwh.harvard.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34862289},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Leeds2022156,
	author = {Leeds, Daniel D. and Zeng, Yue and Johnson, Brian R. and Foster, Craig A. and D’Lauro, Christopher},
	title = {Beliefs affecting concussion reporting among military cadets: advanced observations through machine learning},
	year = {2022},
	journal = {Brain Injury},
	volume = {36},
	number = {2},
	pages = {156 – 165},
	doi = {10.1080/02699052.2022.2034945},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124890321&doi=10.1080%2f02699052.2022.2034945&partnerID=40&md5=62e640135de69c250938f4af49c6b690},
	affiliations = {Computer and Information Science Department, Fordham University, Bronx, NY, United States; Center for Military Psychiatry and Neuroscience, Walter Reed Army Institute of Research, Silver Spring, MD, United States; Psychology Department for SUNY Cortland, State University of New York College at Cortland, Cortland, NY, United States; Department of Behavioral Science and Leadership, United States Air Force Academy, USAF, Colorado Springs, CO, United States},
	abstract = {Background: Untreated concussions are an important health concern. The number of concussions sustained each year is difficult to pinpoint due to diverse reporting routes and many people not reporting. A growing body of literature investigates the motivations for concussion under-reporting, proposing ties with knowledge of concussion outcomes and concussion culture. The present work employs machine learning to identify trends in knowledge and willingness to self-report concussions. Methods: 2,204 cadets completed a survey addressing athletic and pilot status, concussion symptoms and outcome beliefs, ethical beliefs, demographics, and reporting willingness. Results: Clustering and non-negative matrix analysis identified connections to self-report willingness within: knowledge of symptoms, ethical beliefs, reporting requirements, and belief of long-term concussion outcomes. Support vector machine classification of cadet reporting likelihood reveals symptom and outcome knowledge may be inversely related to reporting among those rating ethics considerations as low, while heightened ethics may predict higher reporting likeliness overall. Conclusions: Machine-learning analysis bolsters prior theories on the importance of concussion culture in reporting and indicate more symptom knowledge may decrease willingness to report. Uniquely, our analysis indicated importance of ethical behavior may be associated with general concussion reporting willingness, inviting further consideration from healthcare practitioners seeking increased reporting. © 2022 Taylor & Francis Group, LLC.},
	author_keywords = {automated classification; concussion beliefs; Concussion reporting; factor analysis; reporting intentions},
	keywords = {Athletes; Athletic Injuries; Brain Concussion; Humans; Machine Learning; Military Personnel; Self Report; adult; army; Article; clinical outcome; concussion; demographics; ethics; female; health care personnel; human; in vitro study; machine learning; major clinical study; male; support vector machine; athlete; brain concussion; complication; military personnel; self report; sport injury},
	correspondence_address = {D.D. Leeds; Computer and Information Science Department, Fordham University, Bronx, United States; email: dleeds@fordham.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {02699052},
	coden = {BRAIE},
	pmid = {35133926},
	language = {English},
	abbrev_source_title = {Brain Inj.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yam2021611,
	author = {Yam, Josephine and Skorburg, Joshua August},
	title = {From human resources to human rights: Impact assessments for hiring algorithms},
	year = {2021},
	journal = {Ethics and Information Technology},
	volume = {23},
	number = {4},
	pages = {611 – 623},
	doi = {10.1007/s10676-021-09599-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108828267&doi=10.1007%2fs10676-021-09599-7&partnerID=40&md5=4ccc1d1e0f38e26b5b6162abb57e93cb},
	affiliations = {Department of Philosophy, University of Guelph, 50 Stone Rd E, Guelph, N1G 2W1, ON, Canada},
	abstract = {Over the years, companies have adopted hiring algorithms because they promise wider job candidate pools, lower recruitment costs and less human bias. Despite these promises, they also bring perils. Using them can inflict unintentional harms on individual human rights. These include the five human rights to work, equality and nondiscrimination, privacy, free expression and free association. Despite the human rights harms of hiring algorithms, the AI ethics literature has predominantly focused on abstract ethical principles. This is problematic for two reasons. First, AI principles have been criticized for being vague and not actionable. Second, the use of vague ethical principles to discuss algorithmic risks does not provide any accountability. This lack of accountability creates an algorithmic accountability gap. Closing this gap is crucial because, without accountability, the use of hiring algorithms can lead to discrimination and unequal access to employment opportunities. This paper makes two contributions to the AI ethics literature. First, it frames the ethical risks of hiring algorithms using international human rights law as a universal standard for determining algorithmic accountability. Second, it evaluates four types of algorithmic impact assessments in terms of how effectively they address the five human rights of job applicants implicated in hiring algorithms. It determines which of the assessments can help companies audit their hiring algorithms and close the algorithmic accountability gap. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Algorithmic Audits; Artificial Intelligence; Human Resources; Impact Assessments; Machine Learning},
	keywords = {Employment; Philosophical aspects; Social aspects; Employment opportunities; Ethical principles; Free associations; Human bias; Human rights; Impact assessments; Job applicant; Privacy by design},
	correspondence_address = {J.A. Skorburg; Department of Philosophy, University of Guelph, Guelph, 50 Stone Rd E, N1G 2W1, Canada; email: skorburg@uoguelph.ca},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Hagendorff2021563,
	author = {Hagendorff, Thilo},
	title = {Linking Human And Machine Behavior: A New Approach to Evaluate Training Data Quality for Beneficial Machine Learning},
	year = {2021},
	journal = {Minds and Machines},
	volume = {31},
	number = {4},
	pages = {563 – 593},
	doi = {10.1007/s11023-021-09573-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115712872&doi=10.1007%2fs11023-021-09573-8&partnerID=40&md5=ef51f4f7a40d60aa95a12a31b114ad2d},
	affiliations = {Cluster of Excellence “Machine Learning - New Perspectives for Science”, University of Tuebingen, Tübingen, Germany},
	abstract = {Machine behavior that is based on learning algorithms can be significantly influenced by the exposure to data of different qualities. Up to now, those qualities are solely measured in technical terms, but not in ethical ones, despite the significant role of training and annotation data in supervised machine learning. This is the first study to fill this gap by describing new dimensions of data quality for supervised machine learning applications. Based on the rationale that different social and psychological backgrounds of individuals correlate in practice with different modes of human–computer-interaction, the paper describes from an ethical perspective how varying qualities of behavioral data that individuals leave behind while using digital technologies have socially relevant ramification for the development of machine learning applications. The specific objective of this study is to describe how training data can be selected according to ethical assessments of the behavior it originates from, establishing an innovative filter regime to transition from the big data rationale n = all to a more selective way of processing data for training sets in machine learning. The overarching aim of this research is to promote methods for achieving beneficial machine learning applications that could be widely useful for industry as well as academia. © 2021, The Author(s).},
	author_keywords = {Artificial intelligence; Data quality; Machine behavior; Machine learning; Technology ethics; Training data},
	keywords = {Behavioral research; Human computer interaction; Learning algorithms; Supervised learning; Data quality; Human behaviors; Machine behavior; Machine learning applications; Machine-learning; New approaches; Supervised machine learning; Technical terms; Technology ethic; Training data; Philosophical aspects},
	correspondence_address = {T. Hagendorff; Cluster of Excellence “Machine Learning - New Perspectives for Science”, University of Tuebingen, Tübingen, Germany; email: thilo.hagendorff@uni-tuebingen.de},
	publisher = {Springer Science and Business Media B.V.},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Johnson20219941,
	author = {Johnson, Gabbrielle M.},
	title = {Algorithmic bias: on the implicit biases of social technology},
	year = {2021},
	journal = {Synthese},
	volume = {198},
	number = {10},
	pages = {9941 – 9961},
	doi = {10.1007/s11229-020-02696-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087073834&doi=10.1007%2fs11229-020-02696-y&partnerID=40&md5=2245aaa2b1f030eb8496a978f4f7ab64},
	affiliations = {New York University, New York, United States},
	abstract = {Often machine learning programs inherit social patterns reflected in their training data without any directed effort by programmers to include such biases. Computer scientists call this algorithmic bias. This paper explores the relationship between machine bias and human cognitive bias. In it, I argue similarities between algorithmic and cognitive biases indicate a disconcerting sense in which sources of bias emerge out of seemingly innocuous patterns of information processing. The emergent nature of this bias obscures the existence of the bias itself, making it difficult to identify, mitigate, or evaluate using standard resources in epistemology and ethics. I demonstrate these points in the case of mitigation techniques by presenting what I call ‘the Proxy Problem’. One reason biases resist revision is that they rely on proxy attributes, seemingly innocuous attributes that correlate with socially-sensitive attributes, serving as proxies for the socially-sensitive attributes themselves. I argue that in both human and algorithmic domains, this problem presents a common dilemma for mitigation: attempts to discourage reliance on proxy attributes risk a tradeoff with judgement accuracy. This problem, I contend, admits of no purely algorithmic solution. © 2020, Springer Nature B.V.},
	author_keywords = {Algorithmic bias; Bias; Implicit bias; Machine bias; Social bias},
	correspondence_address = {G.M. Johnson; New York University, New York, United States; email: gmjohnson@nyu.edu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {00397857},
	language = {English},
	abbrev_source_title = {Synthese},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Green Open Access}
}

@ARTICLE{Parsons2021,
	author = {Parsons, Rex and Cramb, Susanna M and McPhail, Steven M},
	title = {Clinical prediction models for hospital falls: A scoping review protocol},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {9},
	doi = {10.1136/bmjopen-2021-051047},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115168633&doi=10.1136%2fbmjopen-2021-051047&partnerID=40&md5=088dadf089770886c8d00c1e7b854a66},
	affiliations = {Australian Centre for Health Services Innovation and Centre for Healthcare Translation, School of Public Health and Social Work, Queensland University of Technology, Kelvin Grove, Queensland, Australia; Jamieson Trauma Institute, Royal Brisbane and Women's Hospital, Metro North Health, Herston, Queensland, Australia; Clinical Informatics Directorate, Metro South Health, Woolloongabba, Queensland, Australia},
	abstract = {Introduction Falls remain one of the most prevalent adverse events in hospitals and are associated with substantial negative health impacts and costs. Approaches to assess patients' fall risk have been implemented in hospitals internationally, ranging from brief screening questions to multifactorial risk assessments and complex prediction models, despite a lack of clear evidence of effect in reducing falls in acute hospital environments. The increasing digitisation of hospital systems provides new opportunities to understand and predict falls using routinely recorded data, with potential to integrate fall prediction models into real-time or near-real-time computerised decision support for clinical teams seeking to mitigate fall risk. However, the use of non-traditional approaches to fall risk prediction, including machine learning using integrated electronic medical records, has not yet been reviewed relative to more traditional fall prediction models. This scoping review will summarise methodologies used to develop existing hospital fall prediction models, including reporting quality assessment. Methods and analysis This scoping review will follow the Arksey and O'Malley framework and its recent advances, and will be reported using Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews recommendations. Four electronic databases (CINAHL via EBSCOhost, PubMed, IEEE Xplore and Embase) will be initially searched for studies up to 12 November 2020, and searches may be updated prior to final reporting. Additional studies will be identified by reference list review and citation analysis of included studies. No restriction will be placed on the date or language of identified studies. Screening of search results and extraction of data will be performed by two independent reviewers. Reporting quality will be assessed by the adherence to the Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis. Ethics and dissemination Ethical approval is not required for this study. Findings will be disseminated through peer-reviewed publication and scientific conferences.  © 2021 BMJ Publishing Group. All rights reserved.},
	author_keywords = {geriatric medicine; health & safety; health informatics; quality in health care; risk management},
	keywords = {Hospitals; Humans; Models, Statistical; Peer Review; Prognosis; Research Design; Review Literature as Topic; Systematic Reviews as Topic; Cinahl; citation analysis; electronic medical record; Embase; extraction; fall risk; geriatrics; human; human experiment; language; machine learning; medical informatics; Medline; prediction; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; prognosis; quality control; review; risk management; systematic review; hospital; literature; methodology; peer review; statistical model},
	correspondence_address = {R. Parsons; Australian Centre for Health Services Innovation and Centre for Healthcare Translation, School of Public Health and Social Work, Queensland University of Technology, Kelvin Grove, Australia; email: rex.parsons@hdr.qut.edu.au},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34518271},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Li20214857,
	author = {Li, Yunqi and Ge, Yingqiang and Zhang, Yongfeng},
	title = {CIKM 2021 Tutorial on Fairness of Machine Learning in Recommender Systems},
	year = {2021},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {4857 – 4860},
	doi = {10.1145/3459637.3483280},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119169275&doi=10.1145%2f3459637.3483280&partnerID=40&md5=b8fc2004d40c9a44b0a2c2e12b2aaec8},
	affiliations = {Rutgers University, New Brunswick, United States},
	abstract = {Recently, there has been growing attention on fairness considerations in machine learning. As one of the most pervasive applications of machine learning, recommender systems are gaining increasing and critical impacts on human and society since a growing number of users use them for information seeking and decision making. Therefore, it is crucial to address the potential unfairness problems in recommendation, which may hurt users' or providers' satisfaction in recommender systems as well as the interests of the platforms. The tutorial focuses on the foundations and algorithms for fairness in recommendation. It also presents a brief introduction about fairness in basic machine learning tasks such as classification and ranking. The tutorial will introduce the taxonomies of current fairness definitions and evaluation metrics for fairness concerns. We will introduce previous works about fairness in recommendation and also put forward future fairness research directions. The tutorial aims at introducing and communicating fairness in recommendation methods to the community, as well as gathering researchers and practitioners interested in this research direction for discussions, idea communications, and research promotions. © 2021 ACM.},
	author_keywords = {AI ethics; fairness; machine learning; recommender systems},
	keywords = {Decision making; Machine learning; Philosophical aspects; 'current; AI ethic; Decisions makings; Evaluation metrics; Fairness; Fairness concerns; Information seeking; Machine-learning; Pervasive applications; Unfairness problem; Recommender systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038446-9},
	language = {English},
	abbrev_source_title = {Int Conf Inf Knowledge Manage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 30th ACM International Conference on Information and Knowledge Management, CIKM 2021; Conference date: 1 November 2021 through 5 November 2021; Conference code: 173355}
}

@ARTICLE{Abboud2021,
	author = {Abboud, Andrew and Nguonly, Austin and Bean, Asher and Brown, Kemar J. and Chen, Roy F. and Dudzinski, David and Fiseha, Neyat and Joice, Melvin and Kimaiyo, Davis and Martin, MacKenzie and Taylor, Christy and Wei, Kevin and Welch, Megan and Zlotoff, Daniel A. and Januzzi, James L. and Gaggin, Hanna K.},
	title = {Rationale and design of the preserved versus reduced ejection fraction biomarker registry and precision medicine database for ambulatory patients with heart failure (PREFER-HF) study},
	year = {2021},
	journal = {Open Heart},
	volume = {8},
	number = {2},
	doi = {10.1136/openhrt-2021-001704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117697854&doi=10.1136%2fopenhrt-2021-001704&partnerID=40&md5=9f531ca303d1061547cd34f0973f9fc3},
	affiliations = {Massachusetts General Hospital, Boston, MA, United States; Harvard Medical School, Boston, MA, United States; Department of Medicine, Columbia University Irving Medical Center, New York, NY, United States; Department of Medicine, Cardiology Division, Massachusetts General Hospital, Boston, MA, United States; Baim Institute for Clinical Research, Boston, MA, United States},
	abstract = {Introduction Patients with heart failure (HF) are classically categorised by left ventricular ejection fraction (LVEF). Efforts to predict outcomes and response to specific therapy among LVEF-based groups may be suboptimal, in part due to the underlying heterogeneity within clinical HF phenotypes. A multidimensional characterisation of ambulatory patients with and without HF across LVEF groups is needed to better understand and manage patients with HF in a more precise manner. Methods and analysis To date, the first cohort of 1313 out of total planned 3000 patients with and without HF has been enroled in this single-centre, longitudinal observational cohort study. Baseline and 1-year follow-up blood samples and clinical characteristics, the presence and duration of comorbidities, serial laboratory, echocardiographic data and images and therapy information will be obtained. HF diagnosis, aetiology of disease, symptom onset and clinical outcomes at 1 and 5 years will be adjudicated by a team of clinicians. Clinical outcomes of interest include all-cause mortality, cardiovascular mortality, all-cause hospitalisation, cardiovascular hospitalisation, HF hospitalisation, right-sided HF and acute kidney injury. Results from the Preserved versus Reduced Ejection Fraction Biomarker Registry and Precision Medicine Database for Ambulatory Patients with Heart Failure (PREFER-HF) trial will examine longitudinal clinical characteristics, proteomic, metabolomic, genomic and imaging data to better understand HF phenotypes, with the ultimate goal of improving precision medicine and clinical outcomes for patients with HF. Ethics and dissemination Information gathered in this research will be published in peer-reviewed journals. Written informed consent for PREFER-HF was obtained from all participants. All study procedures were approved by the Mass General Brigham Institutional Review Board in Boston, Massachusetts and performed in accordance with the Declaration of Helsinki (Protocol Number: 2016P000339). Trial registration number PREFER-HF ClinicalTrials.gov identifier: NCT03480633. © 2021 Author(s). Published by BMJ.},
	author_keywords = {biomarkers; computer simulation; heart failure; research design},
	keywords = {biological marker; growth differentiation factor 15; somatomedin binding protein 7; troponin T; unclassified drug; acute kidney failure; adult; all cause mortality; Article; blood sampling; cardiovascular magnetic resonance; cardiovascular mortality; clinical outcome; cohort analysis; comorbidity; controlled clinical trial (topic); controlled study; data base; echocardiography; female; follow up; genomics; heart catheterization; heart failure with preserved ejection fraction; heart failure with reduced ejection fraction; hospitalization; human; machine learning; major clinical study; male; metabolomics; observational study; personalized medicine; phenotype; prospective study; thorax radiography},
	correspondence_address = {H.K. Gaggin; Harvard Medical School, Boston, United States; email: hgaggin@mgh.harvard.edu; H.K. Gaggin; Department of Medicine, Cardiology Division, Massachusetts General Hospital, Boston, United States; email: hgaggin@mgh.harvard.edu},
	publisher = {BMJ Publishing Group},
	issn = {2398595X},
	language = {English},
	abbrev_source_title = {Open Heart},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Su2021,
	author = {Su, Zhaohui and Liang, Bin and Shi, Feng and Gelfond, J. and Šegalo, Sabina and Wang, Jing and Jia, Peng and Hao, Xiaoning},
	title = {Deep learning-based facial image analysis in medical research: A systematic review protocol},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {11},
	doi = {10.1136/bmjopen-2020-047549},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119880275&doi=10.1136%2fbmjopen-2020-047549&partnerID=40&md5=b89ff0c83ebf035e29df6ca8c9873688},
	affiliations = {Center on Smart and Connected Health Technologies, Mays Cancer Center, School of Nursing, UT Health San Antonio, San Antonio, TX, United States; Department of Radiation Oncology, Chinese Academy of Medical Sciences, Peking Union Medical College, Beijing, China; Department of Research and Development, Shanghai United Imaging Intelligence Co., Ltd., Shanghai, China; Epidemiology and Biostatistics, University of Texas Health Science Center at San Antonio, San Antonio, TX, United States; Department of Microbiology, University of Sarajevo, Sarajevo, Bosnia and Herzegovina; College of Nursing, Florida State University, Tallahassee, FL, United States; Department of Land Surveying and Geo-Informatics, University of Twente, Enschede, Netherlands; International Initiative on Spatial Lifecourse Epidemiology (ISLE), Enschede, Netherlands; Division of Health Security Research, National Health Commission of the People's Republic of China, Beijing, China},
	abstract = {Introduction Deep learning techniques are gaining momentum in medical research. Evidence shows that deep learning has advantages over humans in image identification and classification, such as facial image analysis in detecting people's medical conditions. While positive findings are available, little is known about the state-of-the-art of deep learning-based facial image analysis in the medical context. For the consideration of patients' welfare and the development of the practice, a timely understanding of the challenges and opportunities faced by research on deep-learning-based facial image analysis is needed. To address this gap, we aim to conduct a systematic review to identify the characteristics and effects of deep learning-based facial image analysis in medical research. Insights gained from this systematic review will provide a much-needed understanding of the characteristics, challenges, as well as opportunities in deep learning-based facial image analysis applied in the contexts of disease detection, diagnosis and prognosis. Methods Databases including PubMed, PsycINFO, CINAHL, IEEEXplore and Scopus will be searched for relevant studies published in English in September, 2021. Titles, abstracts and full-text articles will be screened to identify eligible articles. A manual search of the reference lists of the included articles will also be conducted. The Preferred Reporting Items for Systematic Reviews and Meta-Analyses framework was adopted to guide the systematic review process. Two reviewers will independently examine the citations and select studies for inclusion. Discrepancies will be resolved by group discussions till a consensus is reached. Data will be extracted based on the research objective and selection criteria adopted in this study. Ethics and dissemination As the study is a protocol for a systematic review, ethical approval is not required. The study findings will be disseminated via peer-reviewed publications and conference presentations. PROSPERO registration number CRD42020196473.  © },
	author_keywords = {biotechnology & bioinformatics; health informatics; information technology; public health; telemedicine},
	keywords = {Biomedical Research; Deep Learning; Delivery of Health Care; Humans; Research Design; Systematic Reviews as Topic; artificial intelligence; Cinahl; clinical protocol; convolutional neural network; data analysis; data extraction; data synthesis; deep learning; facial expression; human; image analysis; machine learning; medical research; Medline; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; prognosis; PsycINFO; Review; Scopus; systematic review; health care delivery; methodology},
	correspondence_address = {X. Hao; Division of Health Security Research, National Health Commission of the People's Republic of China, Beijing, China; email: haoxn@nhei.cn},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34764164},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Xu2021,
	author = {Xu, Lu and Sanders, Leslie and Li, Kay and Chow, James C.L.},
	title = {Chatbot for Health Care and Oncology Applications Using Artificial Intelligence and Machine Learning: Systematic Review},
	year = {2021},
	journal = {JMIR Cancer},
	volume = {7},
	number = {4},
	doi = {10.2196/27850},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122031869&doi=10.2196%2f27850&partnerID=40&md5=12e1282e36fde1f0b050c42c968c9850},
	affiliations = {Institute of Biomedical Engineering, University of Toronto, Toronto, ON, Canada; Department of Medical Biophysics, Western University, London, ON, Canada; Department of Humanities, York University, Toronto, ON, Canada; Department of English, York University, Toronto, ON, Canada; Department of Medical Physics, Radiation Medicine Program, Princess Margaret Cancer Centre, University Health Network, Toronto, ON, Canada; Department of Radiation Oncology, University of Toronto, Toronto, ON, Canada},
	abstract = {Background: Chatbot is a timely topic applied in various fields, including medicine and health care, for human-like knowledge transfer and communication. Machine learning, a subset of artificial intelligence, has been proven particularly applicable in health care, with the ability for complex dialog management and conversational flexibility. Objective: This review article aims to report on the recent advances and current trends in chatbot technology in medicine. A brief historical overview, along with the developmental progress and design characteristics, is first introduced. The focus will be on cancer therapy, with in-depth discussions and examples of diagnosis, treatment, monitoring, patient support, workflow efficiency, and health promotion. In addition, this paper will explore the limitations and areas of concern, highlighting ethical, moral, security, technical, and regulatory standards and evaluation issues to explain the hesitancy in implementation. Methods: A search of the literature published in the past 20 years was conducted using the IEEE Xplore, PubMed, Web of Science, Scopus, and OVID databases. The screening of chatbots was guided by the open-access Botlist directory for health care components and further divided according to the following criteria: diagnosis, treatment, monitoring, support, workflow, and health promotion. Results: Even after addressing these issues and establishing the safety or efficacy of chatbots, human elements in health care will not be replaceable. Therefore, chatbots have the potential to be integrated into clinical practice by working alongside health practitioners to reduce costs, refine workflow efficiencies, and improve patient outcomes. Other applications in pandemic support, global health, and education are yet to be fully explored. Conclusions: Further research and interdisciplinary collaboration could advance this technology to dramatically improve the quality of care for patients, rebalance the workload for clinicians, and revolutionize the practice of medicine. © Lu Xu, Leslie Sanders, Kay Li, James C L Chow.},
	author_keywords = {Artificial intelligence; Cancer therapy; Chatbot; Communication; Diagnosis; Ethics; Health; Machine learning; Medical biophysics; Medicine; Mobile phone},
	keywords = {Article; artificial intelligence; cancer regression; cancer therapy; clinician; counseling; diagnostic procedure; disease exacerbation; emotional support; global health; health care; health practitioner; health promotion; interpersonal communication; machine learning; meta analysis; oncology; pandemic; patient monitoring; screening; smoking cessation; systematic review; workflow; workload},
	correspondence_address = {J.C.L. Chow; Department of Medical Physics, Radiation Medicine Program, Princess Margaret Cancer Centre, University Health Network, Toronto, 7/F, 700 University Avenue, M5G 1X6, Canada; email: james.chow@rmp.uhn.ca},
	publisher = {JMIR Publications Inc.},
	issn = {23691999},
	language = {English},
	abbrev_source_title = {JMIR Cancer},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Leibowicz2021,
	author = {Leibowicz, Claire R. and Saltz, Emily and Coleman, Lia},
	title = {Creating AI Art Responsibly: A Field Guide for Artists; [Crear arte con IA de forma responsable: una guía de campo para artistas]},
	year = {2021},
	journal = {Disena},
	volume = {2021},
	number = {19},
	doi = {10.7764/disena.19.Article.5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144967213&doi=10.7764%2fdisena.19.Article.5&partnerID=40&md5=ce09af1315e3b5662c9c2c2713699395},
	affiliations = {Partnership on AI New York, United States; The New York Times, New York, United States; Rhode Island School of Design, Providence, United States},
	abstract = {A Machine learning tools for generating synthetic media enable creative expression, but they can also result in content that misleads and causes harm. The Responsible AI Art Field Guide offers a starting point for designers, artists, and other makers on how to responsibly use AI techniques and in a careful manner. We suggest that artists and designers using AI situate their work within the broader context of responsible AI, attending to the potentially unintended harmful consequences of their work as understood in domains like information security, misinformation, the environment, copyright, and biased and appropriative synthetic media. First, we describe the broader dynamics of generative media to emphasize how artists and designers using AI exist within a field with complex societal characteristics. We then describe our project, a guide focused on four key checkpoints in the lifecycle of AI creation: (1) dataset, (2) model code, (3) training resources, and (4) publishing and attribution. Ultimately, we emphasize the importance for artists and designers using AI to consider these checkpoints and provocations as a starting point for building out a creative AI field, attentive to the societal impacts of their work. © 2021, Pontificia Universidad Catolica de Chile. All rights reserved.},
	author_keywords = {AI art; AI ethics; Generative media; Responsible AI; Synthetic media},
	publisher = {Pontificia Universidad Catolica de Chile},
	issn = {07188447},
	language = {English},
	abbrev_source_title = {Disena.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kousa2022,
	author = {Kousa, Päivi and Niemi, Hannele},
	title = {AI ethics and learning: EdTech companies’ challenges and solutions},
	year = {2022},
	journal = {Interactive Learning Environments},
	doi = {10.1080/10494820.2022.2043908},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126018975&doi=10.1080%2f10494820.2022.2043908&partnerID=40&md5=150439a1372bf7d49df66fb32296b9de},
	affiliations = {Department of Educational Sciences, University of Helsinki, Helsinki, Finland},
	abstract = {The aim of this study is to identify the ethical challenges, solutions and needs of educational technology (EdTech) companies. Qualitative data was collected in interviews with seven experts from four companies, and the data was analysed using inductive content analysis. The four main areas of challenges were ambiguous regulations, inequalities in human learning, ethical dilemmas in machine learning (ML) and lack of ability to assess consequences in society. According to the studied companies, AI regulations are difficult to understand and implement. There is also much to be done in terms of reliability, transparency, and safety. Consequently, companies suggested that AI-based products should be more preventive, safe, explicable, and equally accessible. Sufficient information, multi-professional support also within company, global collaboration, sharing best practices, and general discussion were emphasised. The results show that EdTech companies are aware of their ethical challenges, and their responsibility as disseminators of information. However, translating information into practice is challenging because it is often very fragmented and difficult to understand. Companies hoped that everyone: themselves, consumers, educational institutions, researchers, funders, and decision-makers would do more together to overcome the ethical challenges of AI. © 2022 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Artificial intelligence; EdTech companies; ethical challenges and solutions; ethical sustainability; responsibility},
	correspondence_address = {P. Kousa; Department of Educational Sciences, University of Helsinki, Helsinki, Finland; email: paivi.kousa@helsinki.fi},
	publisher = {Routledge},
	issn = {10494820},
	language = {English},
	abbrev_source_title = {Interact. Learn. Environ.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Pepic2021,
	author = {Pepic, Ivana and Feldt, Robert and Ljungström, Lars and Torkar, Richard and Dalevi, Daniel and Maurin Söderholm, Hanna and Andersson, Lars-Magnus and Axelson-Fisk, Marina and Bohm, Katarina and Sjöqvist, Bengt Arne and Candefjord, Stefan},
	title = {Early detection of sepsis using artificial intelligence: a scoping review protocol},
	year = {2021},
	journal = {Systematic Reviews},
	volume = {10},
	number = {1},
	doi = {10.1186/s13643-020-01561-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100095303&doi=10.1186%2fs13643-020-01561-w&partnerID=40&md5=9518913aa9be9a787121e5161502bacb},
	affiliations = {Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, 412 96, Sweden; Department of Computer Science and Engineering, Chalmers University of Technology, Gothenburg, 412 96, Sweden; Department of Infectious Diseases, Institute of Biomedicine, Sahlgrenska Academy, Gothenburg University, Gothenburg, Sweden; Region Västra Götaland, Skaraborg Hospital, Department of Infectious Diseases, Skövde, Sweden; Aweria AB, Gothenburg, 411 18, Sweden; PreHospen Centre for Prehospital Research, University of Borås, Borås, 50 190, Sweden; Department of Mathematical Sciences, Chalmers University of Technology, Gothenburg, 412 96, Sweden; Karolinska Institute, Department of Clinical Science and Education, South General Hospital, Stockholm, Sweden; Department of Emergency medicine, South General Hospital, Stockholm, Sweden; MedTech West, Sahlgrenska University Hospital, Gothenburg, 413 45, Sweden},
	abstract = {Background: Sepsis is a life-threatening organ dysfunction caused by a dysregulated host response to infection. To decrease the high case fatality rates and morbidity for sepsis and septic shock, there is a need to increase the accuracy of early detection of suspected sepsis in prehospital and emergency department settings. This may be achieved by developing risk prediction decision support systems based on artificial intelligence. Methods: The overall aim of this scoping review is to summarize the literature on existing methods for early detection of sepsis using artificial intelligence. The review will be performed using the framework formulated by Arksey and O’Malley and further developed by Levac and colleagues. To identify primary studies and reviews that are suitable to answer our research questions, a comprehensive literature collection will be compiled by searching several sources. Constrictions regarding time and language will have to be implemented. Therefore, only studies published between 1 January 1990 and 31 December 2020 will be taken into consideration, and foreign language publications will not be considered, i.e., only papers with full text in English will be included. Databases/web search engines that will be used are PubMed, Web of Science Platform, Scopus, IEEE Xplore, Google Scholar, Cochrane Library, and ACM Digital Library. Furthermore, clinical studies that have completed patient recruitment and reported results found in the database ClinicalTrials.gov will be considered. The term artificial intelligence is viewed broadly, and a wide range of machine learning and mathematical models suitable as base for decision support will be evaluated. Two members of the team will test the framework on a sample of included studies to ensure that the coding framework is suitable and can be consistently applied. Analysis of collected data will provide a descriptive summary and thematic analysis. The reported results will convey knowledge about the state of current research and innovation for using artificial intelligence to detect sepsis in early phases of the medical care chain. Ethics and dissemination: The methodology used here is based on the use of publicly available information and does not need ethical approval. It aims at aiding further research towards digital solutions for disease detection and health innovation. Results will be extracted into a review report for submission to a peer-reviewed scientific journal. Results will be shared with relevant local and national authorities and disseminated in additional appropriate formats such as conferences, lectures, and press releases. © 2021, The Author(s).},
	author_keywords = {Artificial intelligence; Clinical decision support; Emergency department; Machine learning; Prehospital care; Sepsis},
	keywords = {Artificial Intelligence; Humans; Population Groups; Publications; Research Design; Review Literature as Topic; Shock, Septic; Article; artificial intelligence; data extraction; data processing; decision support system; diagnostic test accuracy study; electronic medical record; emergency care; emergency ward; human; intensive care unit; Internet; mathematical model; medical care; practice guideline; receiver operating characteristic; sensitivity and specificity; sepsis; septic shock; systematic review; validation study; literature; methodology; population group; publication; septic shock},
	correspondence_address = {S. Candefjord; Department of Electrical Engineering, Chalmers University of Technology, Gothenburg, 412 96, Sweden; email: stefan.candefjord@chalmers.se},
	publisher = {BioMed Central Ltd},
	issn = {20464053},
	pmid = {33453724},
	language = {English},
	abbrev_source_title = {Syst. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{De Kerckhove2021,
	author = {De Kerckhove, Derrick},
	title = {The personal digital twin, ethical considerations},
	year = {2021},
	journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
	volume = {379},
	number = {2207},
	doi = {10.1098/rsta.2020.0367},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113333011&doi=10.1098%2frsta.2020.0367&partnerID=40&md5=b30f060fbc3e6dddfd4f4e61f51367c9},
	affiliations = {School of Design, Politecnico di Milano, Lombardy, Milan, Italy},
	abstract = {The personal digital twin extends to individual persons, a concept that originated in engineering to twin complex machines with a digital simulation containing a model of its functions to monitor its past and present behaviour, and repair, correct, improve or otherwise ensure its optimal operation. Several independent trends in technological developments are seen to converge towards the elaboration of the digital replication of individual human data and life history, notably in health industries. Among the main ones, we consider the ubiquitous distribution of digital assistants, the rapid progress of machine learning concurrent with the exponential growth of 'personal' Big Data and the incipient interest in developing lifelogs. The core hypothesis here is that among the psychological effects of the digital transformation, the externalization of cognitive faculties such as memory, planning and judgement, the decision-making processes located within the human person are also emigrating to digital functions, perhaps as a prelude to a later re-integration within the person via brain-computer interfaces. The paper concludes with ethical considerations about these ongoing developments. This article is part of the theme issue 'Towards symbiotic autonomous systems'. © 2021 The Author(s).},
	author_keywords = {DA (digital assistant); digital transformation; ethics; externalization (of cognitive faculties); lifelog; PDT (personal digital twin)},
	keywords = {Brain computer interface; Decision making; Digital twin; Philosophical aspects; Autonomous systems; Decision making process; Digital simulation; Digital transformation; Ethical considerations; Exponential growth; Psychological effects; Technological development; Personal digital assistants},
	correspondence_address = {D. De Kerckhove; School of Design, Politecnico di Milano, Milan, Lombardy, Italy; email: dekerckh@gmail.com},
	publisher = {Royal Society Publishing},
	issn = {1364503X},
	pmid = {34398660},
	language = {English},
	abbrev_source_title = {Philos. Trans. R. Soc. A Math. Phys. Eng. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Bronze Open Access}
}

@ARTICLE{Lambrechts202211057,
	author = {Lambrechts, Wynand and Sinha, Saurabh and Mosoetsa, Sarah},
	title = {Colonization by Algorithms in the Fourth Industrial Revolution},
	year = {2022},
	journal = {IEEE Access},
	volume = {10},
	pages = {11057 – 11064},
	doi = {10.1109/ACCESS.2022.3145236},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123698617&doi=10.1109%2fACCESS.2022.3145236&partnerID=40&md5=80dcfa20b32e34cd682828245a642bd7},
	affiliations = {Faculty of Engineering and the Built Environment, University of Johannesburg, Johannesburg, South Africa; Deputy Vice-Chancellor: Research and Internationalisation, University of Johannesburg, Johannesburg, South Africa; National Institute for the Humanities and Social Sciences, Johannesburg, South Africa},
	abstract = {Data gathering and information processing have evolved to where it is almost unfathomable how much exists in digital form today. The generation thereof also no longer involves an explicit instruction from human to machine but can happen in real-time without human intervention. Artificial intelligence, machine learning, and cognitive computing are being utilized to mine data from a variety of sources. One such (profitable) source is human beings. Digital algorithms are designed to harness the power of technology to gather information. There has always been a sense of secrecy regarding some information (classified, top secret, confidential, etc.) but the Fourth Industrial Revolution has created the means to gather extremely large amounts of data, unknown to its sources. Anthropological value systems should become a fundamental foundation of digital algorithms. Such an approach could prevent software from exploiting its sources, especially minorities. Value systems together with ethics are guided by people's culture. In ethically aligned algorithm design, value systems and digital technologies intersect and govern how algorithms are developed, the way data is engaged, and further the discipline of digital humanities.  © 2013 IEEE.},
	author_keywords = {Artificial intelligence; COVID-19; digital algorithms; digital colonialization; ethically aligned design; invisible data},
	keywords = {Ethical technology; Industry 4.0; Social networking (online); Colonisation; COVID-19; Digital algorithms; Digital colonialization; Encyclopedia; Ethically aligned design; Invisible data; On-line service; Social networking (online); Value systems; Machine learning},
	correspondence_address = {W. Lambrechts; Faculty of Engineering and the Built Environment, University of Johannesburg, Johannesburg, South Africa; email: wynand.lambrechts@ieee.org},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Sharma2021,
	author = {Sharma, Kshitij and Giannakos, Michail},
	title = {Sensing technologies and child–computer interaction: Opportunities, challenges and ethical considerations},
	year = {2021},
	journal = {International Journal of Child-Computer Interaction},
	volume = {30},
	doi = {10.1016/j.ijcci.2021.100331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110179861&doi=10.1016%2fj.ijcci.2021.100331&partnerID=40&md5=e52c41b9d9f0d7cb5f56c4e75e5f3049},
	affiliations = {Norwegian University of Science and Technology, Trondheim, Norway},
	abstract = {This study presents the outcomes of a systematic literature review of empirical evidence on the capabilities of sensing technologies for child–computer interaction (CCI). This paper provides an overview of what and how sensing technologies have been used to explain, understand, and predict children's experiences with interactive devices and technologies and in what contexts. A search resulted in 44 papers that were included in the analysis. The results of the review depict the capabilities of sensing technologies for gauging children's performance, engagement, and experiences (while interacting with technology) and the ongoing advances and implications that emerge from the employment of sensors to capture and improve child behavior. In particular, we identified the four main objectives (i.e., engagement of children, recognition/prediction of special needs/behavior, explaining/understanding the behavior/attitude, and learning performance/experiences) that the CCI research has been focusing on with sensor data. We also summarize the implications derived from the reviewed articles and frame them within four thematic areas. Finally, this review stresses that future research should consider developing a framework that would enable sensor data capacities to be aligned with the ethical, social, and generalizability guidelines. These sensor capacities could also be utilized to advance theory and practice. Our findings set a baseline for supporting the adoption and democratization of sensor data within future interactive technology research and development for children. © 2021},
	author_keywords = {Child–computer interaction; Ethics; Machine learning; Sensing technologies; Systematic literature review},
	correspondence_address = {K. Sharma; Norwegian University of Science and Technology, Trondheim, Norway; email: kshitij.sharma@ntnu.no},
	publisher = {Elsevier B.V.},
	issn = {22128689},
	language = {English},
	abbrev_source_title = {Int. J. Child-Computer Interact.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Boyd2021,
	author = {Boyd, Karen L.},
	title = {Datasheets for Datasets help ML Engineers Notice and Understand Ethical Issues in Training Data},
	year = {2021},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	volume = {5},
	number = {CSCW2},
	doi = {10.1145/3479582},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117945020&doi=10.1145%2f3479582&partnerID=40&md5=f99c40437079acb85855fdcf5d5e3218},
	affiliations = {University of Michigan, Ann Arbor, MI, United States},
	abstract = {The social computing community has demonstrated interest in the ethical issues sometimes produced by machine learning (ML) models, like violations of privacy, fairness, and accountability. This paper discovers what kinds of ethical considerations machine learning engineers recognize, how they build understanding, and what decisions they make when working with a real-world dataset. In particular, it illustrates ways in which Datasheets for Datasets, an accountability intervention designed to help engineers explore unfamiliar training data, scaffolds the process of issue discovery, understanding, and ethical decision-making. Participants were asked to review an intentionally ethically problematic dataset and asked to think aloud as they used it to solve a given ML problem. Out of 23 participants, 11 were given a Datasheet they could use while completing the task. Participants were ethically sensitive enough to identify concerns in the dataset; participants who had a Datasheet did open and refer to it; and those with Datasheets mentioned ethical issues during the think-aloud earlier and more often than than those without. The think-aloud protocol offered a grounded description of how participants recognized, understood, and made a decision about ethical problems in an unfamiliar dataset. The method used in this study can test other interventions that claim to encourage recognition, promote understanding, and support decision-making among technologists.  © 2021 ACM.},
	author_keywords = {development practices; ethical sensitivity; ethics; machine learning; training data},
	keywords = {Decision making; Engineers; Machine learning; Personnel training; Scaffolds; Data sheets; Development practices; Ethical considerations; Ethical decision making; Ethical issues; Ethical sensitivity; Machine learning models; Real-world datasets; Think aloud; Training data; Philosophical aspects},
	publisher = {Association for Computing Machinery},
	issn = {25730142},
	language = {English},
	abbrev_source_title = {Proc. ACM Hum. Comput. Interact.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Mörch20211452,
	author = {Mörch, C.M. and Atsu, S. and Cai, W. and Li, X. and Madathil, S.A. and Liu, X. and Mai, V. and Tamimi, F. and Dilhac, M.A. and Ducret, M.},
	title = {Artificial Intelligence and Ethics in Dentistry: A Scoping Review},
	year = {2021},
	journal = {Journal of Dental Research},
	volume = {100},
	number = {13},
	pages = {1452 – 1460},
	doi = {10.1177/00220345211013808},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107187369&doi=10.1177%2f00220345211013808&partnerID=40&md5=cbb90cc804caf6a7d3fadeac6760e80d},
	affiliations = {Algora Lab, Université de Montréal, Montréal, QC, Canada; Mila–Institut Québécois d’Intelligence Artificielle, Montréal, QC, Canada; International Observatory on the Societal Impacts of Artificial Intelligence and Digital Technology (OBVIA), Québec, QC, Canada; University of Kırıkkale, Faculty of Dentistry, Kırıkkale, Turkey; McGill University, Montreal, QC, Canada; College of Dental Medicine, Qatar University, Doha, Qatar; Faculté d’Odontologie, Université de Lyon, Université Claude Bernard Lyon 1, Lyon, France; Laboratoire de Biologie Tissulaire et Ingénierie thérapeutique, UMR 5305, CNRS/Université Claude Bernard Lyon 1, Lyon, France; Hospices Civils de Lyon, PAM Odontologie, Lyon, France},
	abstract = {Dentistry increasingly integrates artificial intelligence (AI) to help improve the current state of clinical dental practice. However, this revolutionary technological field raises various complex ethical challenges. The objective of this systematic scoping review is to document the current uses of AI in dentistry and the ethical concerns or challenges they imply. Three health care databases (MEDLINE [PubMed], SciVerse Scopus, and Cochrane Library) and 2 computer science databases (ArXiv, IEEE Xplore) were searched. After identifying 1,553 records, the documents were filtered, and a full-text screening was performed. In total, 178 studies were retained and analyzed by 8 researchers specialized in dentistry, AI, and ethics. The team used Covidence for data extraction and Dedoose for the identification of ethics-related information. PRISMA guidelines were followed. Among the included studies, 130 (73.0%) studies were published after 2016, and 93 (52.2%) were published in journals specialized in computer sciences. The technologies used were neural learning techniques for 75 (42.1%), traditional learning techniques for 76 (42.7%), or a combination of several technologies for 20 (11.2%). Overall, 7 countries contributed to 109 (61.2%) studies. A total of 53 different applications of AI in dentistry were identified, involving most dental specialties. The use of initial data sets for internal validation was reported in 152 (85.4%) studies. Forty-five ethical issues (related to the use AI in dentistry) were reported in 22 (12.4%) studies around 6 principles: prudence (10 times), equity (8), privacy (8), responsibility (6), democratic participation (4), and solidarity (4). The ratio of studies mentioning AI-related ethical issues has remained similar in the past years, showing that there is no increasing interest in the field of dentistry on this topic. This study confirms the growing presence of AI in dentistry and highlights a current lack of information on the ethical challenges surrounding its use. In addition, the scarcity of studies sharing their code could prevent future replications. The authors formulate recommendations to contribute to a more responsible use of AI technologies in dentistry. © International & American Associations for Dental Research 2021.},
	author_keywords = {AI; deep learning; dental research; digital technology; machine learning; reproducibility of results},
	keywords = {Artificial Intelligence; Delivery of Health Care; Dentistry; Forecasting; artificial intelligence; Cochrane Library; data extraction; deep learning; dental research; dentistry; digital technology; ethics; human; Medline; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; privacy; reproducibility; responsibility; review; Scopus; solidarity; dentistry; forecasting; health care delivery},
	correspondence_address = {M. Ducret; McGill University, Montreal, Canada; email: maxime.ducret@univ-lyon1.fr},
	publisher = {SAGE Publications Inc.},
	issn = {00220345},
	coden = {JDREA},
	pmid = {34060359},
	language = {English},
	abbrev_source_title = {J. Dent. Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@ARTICLE{Pot2021,
	author = {Pot, Mirjam and Kieusseyan, Nathalie and Prainsack, Barbara},
	title = {Not all biases are bad: equitable and inequitable biases in machine learning and radiology},
	year = {2021},
	journal = {Insights into Imaging},
	volume = {12},
	number = {1},
	doi = {10.1186/s13244-020-00955-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101028235&doi=10.1186%2fs13244-020-00955-7&partnerID=40&md5=92c5e42445f65365f0adc9a0f12e8450},
	affiliations = {Department of Political Science, University of Vienna, Austria, Universitätsstraße 7, Wien, 1100, Austria; OLEA MEDICAL, 93 Ave. du Sorbiers, La Ciotat, 13600, France; Department of Global Health and Social Medicine, King’s College London, London, United Kingdom},
	abstract = {The application of machine learning (ML) technologies in medicine generally but also in radiology more specifically is hoped to improve clinical processes and the provision of healthcare. A central motivation in this regard is to advance patient treatment by reducing human error and increasing the accuracy of prognosis, diagnosis and therapy decisions. There is, however, also increasing awareness about bias in ML technologies and its potentially harmful consequences. Biases refer to systematic distortions of datasets, algorithms, or human decision making. These systematic distortions are understood to have negative effects on the quality of an outcome in terms of accuracy, fairness, or transparency. But biases are not only a technical problem that requires a technical solution. Because they often also have a social dimension, the ‘distorted’ outcomes they yield often have implications for equity. This paper assesses different types of biases that can emerge within applications of ML in radiology, and discusses in what cases such biases are problematic. Drawing upon theories of equity in healthcare, we argue that while some biases are harmful and should be acted upon, others might be unproblematic and even desirable—exactly because they can contribute to overcome inequities. © 2021, The Author(s).},
	author_keywords = {Bias; Equity; Ethics; Machine learning; Radiology},
	keywords = {decision making; drawing; ethics; human; human experiment; machine learning; radiology; review},
	correspondence_address = {B. Prainsack; Department of Political Science, University of Vienna, Austria, Wien, Universitätsstraße 7, 1100, Austria; email: Barbara.prainsack@univie.ac.at},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18694101},
	language = {English},
	abbrev_source_title = {Insights Imaging},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Rafanelli2022,
	author = {Rafanelli, Lucia M.},
	title = {Justice, injustice, and artificial intelligence: Lessons from political theory and philosophy},
	year = {2022},
	journal = {Big Data and Society},
	volume = {9},
	number = {1},
	doi = {10.1177/20539517221080676},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125787222&doi=10.1177%2f20539517221080676&partnerID=40&md5=37eac774c4ff311f44ab350da17380a2},
	affiliations = {The George Washington University, Washington, DC, United States},
	abstract = {Some recent uses of artificial intelligence for (for example) facial recognition, evaluating resumes, and sorting photographs by subject matter have revealed troubling disparities in performance or impact based on the demographic traits (like race and gender) of subject populations. These disparities raise pressing questions about how using artificial intelligence can work to promote justice or entrench injustice. Political theorists and philosophers have developed nuanced vocabularies and theoretical frameworks for understanding and adjudicating disputes about what justice requires and what constitutes injustice. The interdisciplinary community committed to understanding and conscientiously using big data could benefit from this work. Thus, in the spirit of encouraging cross-disciplinary dialogue and collaboration, this piece examines contemporary scholarship in political theory and philosophy to illustrate some of the vocabularies and frameworks political theorists and philosophers have developed for thinking about justice and injustice. It then draws on these frameworks to illuminate how the use of artificial intelligence can implicate questions of justice, with a focus on institutional discrimination, structural injustice, and epistemic injustice. Ultimately, the piece argues that the use of artificial intelligence—far from representing a decision to take power out of human hands—represents a novel way of harnessing human power, making questions of justice central to its conscientious undertaking. © The Author(s) 2022.},
	author_keywords = {artificial intelligence; ethics; fairness; machine learning; political philosophy; Political theory},
	correspondence_address = {L.M. Rafanelli; The George Washington University, Washington, United States; email: lmrafanelli@gwu.edu},
	publisher = {SAGE Publications Ltd},
	issn = {20539517},
	language = {English},
	abbrev_source_title = {Big Data  Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Zolotareva2021,
	author = {Zolotareva, Olga and Nasirigerdeh, Reza and Matschinske, Julian and Torkzadehmahani, Reihaneh and Bakhtiari, Mohammad and Frisch, Tobias and Späth, Julian and Blumenthal, David B. and Abbasinejad, Amir and Tieri, Paolo and Kaissis, Georgios and Rückert, Daniel and Wenke, Nina K. and List, Markus and Baumbach, Jan},
	title = {Flimma: a federated and privacy-aware tool for differential gene expression analysis},
	year = {2021},
	journal = {Genome Biology},
	volume = {22},
	number = {1},
	doi = {10.1186/s13059-021-02553-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121298480&doi=10.1186%2fs13059-021-02553-2&partnerID=40&md5=f0cf689a603bcc330d1b89f931a83e23},
	affiliations = {Chair of Experimental Bioinformatics, TUM School of Life Sciences, Technical University of Munich, Freising, Germany; Institute for Computational Systems Biology, University of Hamburg, Hamburg, Germany; AI in Medicine and Healthcare, Technical University of Munich, Munich, Germany; Department of Mathematics and Computer Science, University of Southern Denmark, Odense, Denmark; Department Artificial Intelligence in Biomedical Engineering, Friedrich-Alexander University Erlangen-Nürnberg, Erlangen, Germany; CNR National Research Council, IAC Institute for Applied Computing, Rome, Italy; Sapienza University of Rome, Rome, Italy; Klinikum rechts der Isar, Technical University of Munich, Munich, Germany; Biomedical Image Analysis Group, Imperial College London, London, United Kingdom; OpenMined, Oxford, United Kingdom},
	abstract = {Aggregating transcriptomics data across hospitals can increase sensitivity and robustness of differential expression analyses, yielding deeper clinical insights. As data exchange is often restricted by privacy legislation, meta-analyses are frequently employed to pool local results. However, the accuracy might drop if class labels are inhomogeneously distributed among cohorts. Flimma (https://exbio.wzw.tum.de/flimma/) addresses this issue by implementing the state-of-the-art workflow limma voom in a federated manner, i.e., patient data never leaves its source site. Flimma results are identical to those generated by limma voom on aggregated datasets even in imbalanced scenarios where meta-analysis approaches fail. © 2021, The Author(s).},
	author_keywords = {Differential expression analysis; Federated learning; Meta-analysis; Privacy of biomedical data},
	keywords = {Biomedical Research; Computer Communication Networks; Computer Security; Databases, Factual; Gene Expression; Genes; Government Regulation; Humans; Machine Learning; Privacy; adult; article; differential expression analysis; female; human; law; learning; male; meta analysis; patient coding; plant leaf; privacy; workflow; computer network; computer security; ethics; factual database; gene; gene expression; government regulation; legislation and jurisprudence; machine learning; medical research},
	correspondence_address = {O. Zolotareva; Chair of Experimental Bioinformatics, TUM School of Life Sciences, Technical University of Munich, Freising, Germany; email: olya.zolotareva@gmail.com},
	publisher = {BioMed Central Ltd},
	issn = {14747596},
	coden = {GNBLF},
	pmid = {34906207},
	language = {English},
	abbrev_source_title = {Genome Biol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Barron20212522,
	author = {Barron, Daniel S.},
	title = {Commentary: The ethical challenges of machine learning in psychiatry: A focus on data, diagnosis, and treatment},
	year = {2021},
	journal = {Psychological Medicine},
	volume = {51},
	number = {15},
	pages = {2522 – 2524},
	doi = {10.1017/S0033291721001008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105891337&doi=10.1017%2fS0033291721001008&partnerID=40&md5=e6415f5c0fc286f07e257a57120e284c},
	affiliations = {Department of Psychiatry, Yale University, New Haven, CT, United States; Department of Anesthesiology and Pain Medicine, University of Washington, Seattle, WA, United States; Department of Psychiatry, Brigham and Women's Hospital, Harvard University, Boston, MA, United States; Department of Anesthesiology and Pain Medicine, Brigham and Women's Hospital, Harvard University, Boston, MA, United States},
	author_keywords = {diagnosis; machine learning; Schizophrenia},
	keywords = {Diagnosis, Computer-Assisted; Humans; Interview, Psychological; Machine Learning; Psychiatry; Schizophrenia; computer assisted diagnosis; ethics; human; machine learning; procedures; psychiatry; psychological interview; schizophrenia},
	correspondence_address = {D.S. Barron; Department of Psychiatry, Yale University, New Haven, United States; email: daniel.s.barron@yale.edu},
	publisher = {Cambridge University Press},
	issn = {00332917},
	coden = {PSMDC},
	pmid = {33975655},
	language = {English},
	abbrev_source_title = {Psychol. Med.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Starke20212515,
	author = {Starke, Georg and De Clercq, Eva and Borgwardt, Stefan and Elger, Bernice Simone},
	title = {Computing schizophrenia: Ethical challenges for machine learning in psychiatry},
	year = {2021},
	journal = {Psychological Medicine},
	volume = {51},
	number = {15},
	pages = {2515 – 2521},
	doi = {10.1017/S0033291720001683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089458824&doi=10.1017%2fS0033291720001683&partnerID=40&md5=5a5d754f208fb82c3f9967fa6d94b24f},
	affiliations = {Institute for Biomedical Ethics, University of Basel, Basel, Switzerland; Department of Psychiatry, University of Basel, Basel, Switzerland; Department of Psychiatry and Psychotherapy, University of Lübeck, Lübeck, Germany; University Center of Legal Medicine, University of Geneva, Geneva, Switzerland},
	abstract = {Recent advances in machine learning (ML) promise far-reaching improvements across medical care, not least within psychiatry. While to date no psychiatric application of ML constitutes standard clinical practice, it seems crucial to get ahead of these developments and address their ethical challenges early on. Following a short general introduction concerning ML in psychiatry, we do so by focusing on schizophrenia as a paradigmatic case. Based on recent research employing ML to further the diagnosis, treatment, and prediction of schizophrenia, we discuss three hypothetical case studies of ML applications with view to their ethical dimensions. Throughout this discussion, we follow the principlist framework by Tom Beauchamp and James Childress to analyse potential problems in detail. In particular, we structure our analysis around their principles of beneficence, non-maleficence, respect for autonomy, and justice. We conclude with a call for cautious optimism concerning the implementation of ML in psychiatry if close attention is paid to the particular intricacies of psychiatric disorders and its success evaluated based on tangible clinical benefit for patients. Copyright © The Author(s), 2020. Published by Cambridge University Press.},
	author_keywords = {Artificial intelligence; bioethics; case studies; computational psychiatry; psychosis; research ethics},
	keywords = {Algorithms; Bioethics; Diagnosis, Computer-Assisted; Humans; Machine Learning; Psychiatry; Schizophrenia; algorithm; bioethics; computer assisted diagnosis; ethics; human; machine learning; procedures; psychiatry; schizophrenia},
	correspondence_address = {G. Starke; Institute for Biomedical Ethics, University of Basel, Basel, Switzerland; email: georg.starke@unibas.ch},
	publisher = {Cambridge University Press},
	issn = {00332917},
	coden = {PSMDC},
	pmid = {32536358},
	language = {English},
	abbrev_source_title = {Psychol. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Bronze Open Access}
}

@ARTICLE{Kernbach2022257,
	author = {Kernbach, Julius M. and Hakvoort, Karlijn and Ort, Jonas and Clusmann, Hans and Neuloh, Georg and Delev, Daniel},
	title = {The Artificial Intelligence Doctor: Considerations for the Clinical Implementation of Ethical AI},
	year = {2022},
	journal = {Acta Neurochirurgica, Supplementum},
	volume = {134},
	pages = {257 – 261},
	doi = {10.1007/978-3-030-85292-4_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120915852&doi=10.1007%2f978-3-030-85292-4_29&partnerID=40&md5=a42f048a902f413a26272ac15864a828},
	affiliations = {Neurosurgical Artificial Intelligence Laboratory Aachen (NAILA), RWTH Aachen University Hospital, Aachen, Germany; Department of Neurosurgery, Faculty of Medicine, RWTH Aachen University, Aachen, Germany},
	abstract = {The applications of artificial intelligence (AI) and machine learning (ML) in modern medicine are growing exponentially, and new developments are fast-paced. However, the lack of trust and appropriate legislation hinder its clinical implementation. Recently, there is a clear increase of directives and considerations on Ethical AI. However, most literature broadly deals with ethical tensions on a meta-level without offering hands-on advice in practice. In this article, we non-exhaustively cover basic practical guidelines regarding AI-specific ethical aspects, including transparency and explicability, equity and mitigation of biases, and lastly, liability. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Deep learning; Machine learning; Neurooncology; Neurosurgery},
	keywords = {Artificial Intelligence; Machine Learning; artificial intelligence; deep learning; ethics; human; law; neurosurgery; practice guideline; tension; trust; machine learning},
	correspondence_address = {J.M. Kernbach; Department of Neurosurgery, Faculty of Medicine, RWTH Aachen University, Aachen, Germany; email: jkernbach@ukaachen.de},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {00651419},
	coden = {ANCSB},
	pmid = {34862549},
	language = {English},
	abbrev_source_title = {Acta Neurochir. Suppl.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Khurana2021732,
	author = {Khurana, Vaishali and Gahalawat, Monika and Kumar, Pradeep and Roy, Partha Pratim and Dogra, Debi Prosad and Scheme, Erik and Soleymani, Mohammad},
	title = {A Survey on Neuromarketing Using EEG Signals},
	year = {2021},
	journal = {IEEE Transactions on Cognitive and Developmental Systems},
	volume = {13},
	number = {4},
	pages = {732 – 749},
	doi = {10.1109/TCDS.2021.3065200},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102682889&doi=10.1109%2fTCDS.2021.3065200&partnerID=40&md5=2e80cb9b3679499b15cbed54645892bd},
	affiliations = {Department of Computer Science and Engineering, Indian Institute of Technology Roorkee, Roorkee, 247667, India; Institute of Biomedical Engineering, University of New Brunswick, Fredericton, E3B 5A3, NB, Canada; School of Electrical Sciences, Indian Institute of Technology Bhubaneswar, Bhubaneswar, 752050, India; Institute for Creative Technologies, University of Southern California, Los Angeles, 90007, CA, United States},
	abstract = {Neuromarketing is the application of neuroscience to the understanding of consumer preferences toward products and services. As such, it studies the neural activity associated with preference and purchase intent. Neuromarketing is considered an emerging area of research, driven in part by the approximately 400 billion dollars spent annually on advertisement and promotion. Given the size of this market, even a slight improvement in performance can have an immense impact. Traditional approaches to marketing consider a posteriori user feedback in the form of questionnaires, product ratings, or review comments, but these approaches do not fully capture or explain the real-time decision-making process of consumers. Various physiological measurement techniques have been proposed to facilitate the recording of this crucial aspect of the decision-making process, including brain imaging techniques [functional magnetic resonance imaging (fMRI), electroencephalography (EEG), steady state topography (SST)], and various biometric sensors. The use of EEG in neuromarketing is especially promising. EEG detects the sequential changes of brain activity, without appreciable time delay, needed to assess both the unconscious reaction and sensory reaction of the customer. Several types of EEG devices are now available in the market, each with its own advantages and disadvantages. Researchers have conducted experiments using many of these devices, across different age groups and different categories of products. Because of the deep insights that can be gained, the field of neuromarketing research is carefully monitored by consumer and research protection groups to ensure that subjects are properly protected. This article surveys a range of considerations for EEG-based neuromarketing strategies, including the types of information that can be gathered, how marketing stimuli are presented to consumers, how such strategies may affect the consumer in terms of appeal and memory, machine learning techniques applied in the field, and the variety of challenges faced, including ethics, in this emerging field. © 2016 IEEE.},
	author_keywords = {E-commerce; electroencephalography (EEG); neuromarketing; neuroscience},
	keywords = {Brain; Brain mapping; Commerce; Consumer protection; Decision making; Electrophysiology; Learning systems; Magnetic resonance imaging; Marketing; Neurons; Surveys; Topography; Brain imaging techniques; Decision making process; Functional magnetic resonance imaging; Machine learning techniques; Physiological measurement; Products and services; Real time decision-making; Traditional approaches; Electroencephalography},
	correspondence_address = {P. Kumar; Institute of Biomedical Engineering, University of New Brunswick, Fredericton, E3B 5A3, Canada; email: pkumar1@unb.ca},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {23798920},
	language = {English},
	abbrev_source_title = {IEEE Trans. Cogn. Dev. Syst.  },
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17}
}

@ARTICLE{Mikdadi2022173,
	author = {Mikdadi, Dina and O'connell, Kyle A. and Meacham, Philip J. and Dugan, Madeleine A. and Ojiere, Michael O. and Carlson, Thaddeus B. and Klenk, Juergen A.},
	title = {Applications of artificial intelligence (AI) in ovarian cancer, pancreatic cancer, and image biomarker discovery},
	year = {2022},
	journal = {Cancer Biomarkers},
	volume = {33},
	number = {2},
	pages = {173 – 184},
	doi = {10.3233/CBM-210301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125548012&doi=10.3233%2fCBM-210301&partnerID=40&md5=126ec5e362889b47f9bde3a1d9e54779},
	affiliations = {Biomedical Data Science Lab, Deloitte Consulting LLP, Arlington, VA, United States; Department of Biology, George Washington University, Washington, DC, United States},
	abstract = {Background: Artificial intelligence (AI), including machine learning (ML) and deep learning, has the potential to revolutionize biomedical research. Defined as the ability to 'mimic' human intelligence by machines executing trained algorithms, AI methods are deployed for biomarker discovery. Objective: We detail the advancements and challenges in the use of AI for biomarker discovery in ovarian and pancreatic cancer. We also provide an overview of associated regulatory and ethical considerations. METHODS: We conducted a literature review using PubMed and Google Scholar to survey the published findings on the use of AI in ovarian cancer, pancreatic cancer, and cancer biomarkers. Results: Most AI models associated with ovarian and pancreatic cancer have yet to be applied in clinical settings, and imaging data in many studies are not publicly available. Low disease prevalence and asymptomatic disease limits data availability required for AI models. The FDA has yet to qualify imaging biomarkers as effective diagnostic tools for these cancers. Conclusions: Challenges associated with data availability, quality, bias, as well as AI transparency and explainability, will likely persist. Explainable and trustworthy AI efforts will need to continue so that the research community can better understand and construct effective models for biomarker discovery in rare cancers. © 2022 - IOS Press. All rights reserved.},
	author_keywords = {Artificial intelligence; bias; biomarkers; machine learning; rare cancer},
	keywords = {Artificial Intelligence; Bias; Biomarkers, Tumor; Early Detection of Cancer; Female; Humans; Machine Learning; Ovarian Neoplasms; Pancreatic Neoplasms; Prognosis; BRCA1 protein; BRCA2 protein; CA 125 antigen; microRNA; tumor marker; tumor marker; analysis; artificial intelligence; asymptomatic disease; cancer diagnosis; cancer prognosis; cancer screening; clinical practice; data availability; deep learning; early cancer diagnosis; ethnic group; female; Food and Drug Administration; human; image analysis; imaging; machine learning; medical ethics; medical research; ovary cancer; pancreas cancer; personalized medicine; prevalence; regulatory mechanism; Review; statistical bias; diagnostic imaging; ovary tumor; pancreas tumor; prognosis},
	correspondence_address = {J.A. Klenk; Federal Health, Deloitte Consulting LLP, Arlington, 1919 N. Lynn Street, 22209, United States; email: jklenk@deloitte.com},
	publisher = {IOS Press BV},
	issn = {15740153},
	pmid = {35213360},
	language = {English},
	abbrev_source_title = {Cancer Biomarkers},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Buhrmester2021966,
	author = {Buhrmester, Vanessa and Münch, David and Arens, Michael},
	title = {Analysis of Explainers of Black Box Deep Neural Networks for Computer Vision: A Survey},
	year = {2021},
	journal = {Machine Learning and Knowledge Extraction},
	volume = {3},
	number = {4},
	pages = {966 – 989},
	doi = {10.3390/make3040048},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122681870&doi=10.3390%2fmake3040048&partnerID=40&md5=c4e7eafb56ee94baba8f6a27b9c2b79a},
	affiliations = {Fraunhofer IOSB, Gutleuthausstraße 1, Ettlingen, 76275, Germany},
	abstract = {Deep Learning is a state-of-the-art technique to make inference on extensive or complex data. As a black box model due to their multilayer nonlinear structure, Deep Neural Networks are often criticized as being non-transparent and their predictions not traceable by humans. Furthermore, the models learn from artificially generated datasets, which often do not reflect reality. By basing decision-making algorithms on Deep Neural Networks, prejudice and unfairness may be promoted unknowingly due to a lack of transparency. Hence, several so-called explanators, or explainers, have been developed. Explainers try to give insight into the inner structure of machine learning black boxes by analyzing the connection between the input and output. In this survey, we present the mechanisms and properties of explaining systems for Deep Neural Networks for Computer Vision tasks. We give a comprehensive overview about the taxonomy of related studies and compare several survey papers that deal with explainability in general. We work out the drawbacks and gaps and summarize further research ideas. © 2021 by the authors.},
	author_keywords = {black box; Deep Neural Network; ethics; explainable AI; explainer; explanator; interpretability; trust},
	correspondence_address = {V. Buhrmester; Fraunhofer IOSB, Ettlingen, Gutleuthausstraße 1, 76275, Germany; email: vanessa.buhrmester@iosb.fraunhofer.de},
	publisher = {MDPI},
	issn = {25044990},
	language = {English},
	abbrev_source_title = {Mach. Learn. Knowl. Extr.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 56; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kirienko20213791,
	author = {Kirienko, Margarita and Sollini, Martina and Ninatti, Gaia and Loiacono, Daniele and Giacomello, Edoardo and Gozzi, Noemi and Amigoni, Francesco and Mainardi, Luca and Lanzi, Pier Luca and Chiti, Arturo},
	title = {Distributed learning: a reliable privacy-preserving strategy to change multicenter collaborations using AI},
	year = {2021},
	journal = {European Journal of Nuclear Medicine and Molecular Imaging},
	volume = {48},
	number = {12},
	pages = {3791 – 3804},
	doi = {10.1007/s00259-021-05339-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104617208&doi=10.1007%2fs00259-021-05339-7&partnerID=40&md5=0f5cf5161e4c2d9003c9af183fdaa6e3},
	affiliations = {Fondazione IRCCS Istituto Nazionale dei Tumori, Milan, Italy; Department of Biomedical Sciences, Humanitas University, Pieve Emanuele, Milan, Italy; IRCCS Humanitas Research Hospital, Rozzano, Milan, Italy; DEIB, Politecnico di Milano, Milan, Italy},
	abstract = {Purpose: The present scoping review aims to assess the non-inferiority of distributed learning over centrally and locally trained machine learning (ML) models in medical applications. Methods: We performed a literature search using the term “distributed learning” OR “federated learning” in the PubMed/MEDLINE and EMBASE databases. No start date limit was used, and the search was extended until July 21, 2020. We excluded articles outside the field of interest; guidelines or expert opinion, review articles and meta-analyses, editorials, letters or commentaries, and conference abstracts; articles not in the English language; and studies not using medical data. Selected studies were classified and analysed according to their aim(s). Results: We included 26 papers aimed at predicting one or more outcomes: namely risk, diagnosis, prognosis, and treatment side effect/adverse drug reaction. Distributed learning was compared to centralized or localized training in 21/26 and 14/26 selected papers, respectively. Regardless of the aim, the type of input, the method, and the classifier, distributed learning performed close to centralized training, but two experiments focused on diagnosis. In all but 2 cases, distributed learning outperformed locally trained models. Conclusion: Distributed learning resulted in a reliable strategy for model development; indeed, it performed equally to models trained on centralized datasets. Sensitive data can get preserved since they are not shared for model development. Distributed learning constitutes a promising solution for ML-based research and practice since large, diverse datasets are crucial for success. © 2021, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {Clinical trial; Distributed learning; Ethics; Federated learning; Machine learning; Privacy},
	keywords = {Algorithms; Databases, Factual; Humans; Machine Learning; Multicenter Studies as Topic; Privacy; Research Design; adverse drug reaction; artificial intelligence; classifier; clinical trial (topic); diagnostic test; Embase; English (language); human; intersectoral collaboration; learning; machine learning; Medline; multicenter study (topic); practice guideline; privacy; prognosis; research ethics; Review; risk assessment; algorithm; factual database; machine learning; methodology},
	correspondence_address = {M. Sollini; IRCCS Humanitas Research Hospital, Milan, Rozzano, Italy; email: martina.sollini@hunimed.eu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {16197070},
	coden = {EJNMA},
	pmid = {33847779},
	language = {English},
	abbrev_source_title = {Eur. J. Nucl. Med. Mol. Imaging},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Friedrichs2021,
	author = {Friedrichs, Juliane and Seide, Svenja and Vey, Johannes and Zimmermann, Samuel and Hardt, Julia and Kleeff, Jorg and Klose, Johannes and Michalski, Christoph W and Kieser, Meinhard and Pilz, Maximilian and Ronellenfitsch, Ulrich},
	title = {Interventions to reduce the incidence of surgical site infection in colorectal resections: systematic review with multicomponent network meta-analysis (INTRISSI): study protocol},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {11},
	doi = {10.1136/bmjopen-2021-057226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120710530&doi=10.1136%2fbmjopen-2021-057226&partnerID=40&md5=d6ee012d3467d4648f4756972f8bcf3f},
	affiliations = {Department of Visceral, Vascular and Endocrine Surgery, Medical Faculty, Martin Luther University Halle-Wittenberg, University Hospital Halle (Saale), Halle, Germany; Institute of Medical Biometry, University Hospital Heidelberg, Heidelberg, Germany; Department of Surgery, University Medical Centre Mannheim, Baden Mannheim Württemberg, Germany; Department of General and Visceral Surgery, University Hospital Ulm, Ulm, Germany},
	abstract = {Objective To assess the relative contribution of intravenous antibiotic prophylaxis, mechanical bowel preparation, oral antibiotic prophylaxis, and combinations thereof towards the reduction of surgical site infection (SSI) incidence in elective colorectal resections. Methods and analysis A systematic search of randomised controlled trials comparing interventions to reduce SSI incidence will be conducted with predefined search terms in the following databases: MEDLINE, LILACS, Cochrane Central Register of Controlled Trials (CENTRAL) and the Cochrane Database of Systematic Reviews (CDSR). Additionally, several online databases will be searched for ongoing trials, and conference proceedings and reference lists of retrieved articles will be hand searched. The title-abstract screening will be partly performed by means of a semiautomated supervised machine learning approach, which will be trained on a subset of the identified titles and abstracts identified through traditional screening methods. The primary analysis will be a multicomponent network meta-analysis, as we expect to identify studies that investigate combinations of interventions (eg, mechanical bowel preparation combined with oral antibiotics) as well as studies that focus on individual components (mechanical bowel preparation or oral antibiotics). By means of a multicomponent network meta-analysis, we aim at estimating the effects of the separate components along the effects of the observed combinations. To account for between-trial heterogeneity, a random-effect approach will be combined with inverse variance weighting for estimation of the treatment effects. Associated 95% CIs will be calculated as well as the ranking for each component in the network using P scores. Results will be visualised by network graphics and forest plots of the overall pairwise effect estimates. Comparison-adjusted funnel plots will be used to assess publication bias. Ethics and dissemination Ethical approval by the Ethical Committee of the Medical Faculty of the Martin-Luther-University Halle-Wittenberg (ID of approval: 2021-148). Results shall be disseminated directly to decision-makers (eg, surgeons, gastroenterologists, wound care specialists) by means of publication in peer-reviewed journals, presentation at conferences and through the media (eg, radio, TV, etc). PROSPERO registration number CRD42021267322.  © Author(s) (or their employer(s)) 2021.},
	author_keywords = {adverse events; colorectal surgery; statistics & research methods},
	keywords = {Colorectal Neoplasms; Humans; Incidence; Meta-Analysis as Topic; Network Meta-Analysis; Surgical Wound Infection; Systematic Reviews as Topic; antibiotic agent; antibiotic prophylaxis; colorectal surgery; controlled study; gastroenterologist; human; incidence; intestine preparation; medical school; meta analysis; network meta-analysis; postoperative complication; proctocolectomy; publication bias; Review; sensitivity analysis; supervised machine learning; surgical infection; systematic review; colorectal tumor; incidence; meta analysis (topic); surgical infection},
	correspondence_address = {U. Ronellenfitsch; Department of Visceral, Vascular and Endocrine Surgery, Medical Faculty, Martin Luther University Halle-Wittenberg, University Hospital Halle (Saale), Halle, Germany; email: ulrich.ronellenfitsch@uk-halle.de},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34824125},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Majumder2021481,
	author = {Majumder, Anusree and Sen, Debraj},
	title = {Artificial intelligence in cancer diagnostics and therapy: Current perspectives},
	year = {2021},
	journal = {Indian Journal of Cancer},
	volume = {58},
	number = {4},
	pages = {481 – 492},
	doi = {10.4103/ijc.IJC_399_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122688540&doi=10.4103%2fijc.IJC_399_20&partnerID=40&md5=127a1faa74f183c0447c83c4ce06aa0e},
	affiliations = {Department of Pathology, Armed Forces Medical College and Command Hospital (Southern Command), Maharashtra, Pune, India; Department of Radiodiagnosis, Armed Forces Medical College and Command Hospital (Southern Command), Maharashtra, Pune, India},
	abstract = {Artificial intelligence (AI) has found its way into every sphere of human life including the field of medicine. Detection of cancer might be AI's most altruistic and convoluted challenge to date in the field of medicine. Embedding AI into various aspects of cancer diagnostics would be of immense use in dealing with the tedious, repetitive, time-consuming job of lesion detection, remove opportunities for human error, and cut costs and time. This would be of great value in cancer screening programs. By using AI algorithms, data from digital images from radiology and pathology that are imperceptible to the human eye can be identified (radiomics and pathomics). Correlating radiomics and pathomics with clinico-demographic-therapy-morbidity-mortality profiles will lead to a greater understanding of cancers. Specific imaging phenotypes have been found to be associated with specific gene-determined molecular pathways involved in cancer pathogenesis (radiogenomics). All these developments would not only help to personalize oncologic practice but also lead to the development of new imaging biomarkers. AI algorithms in oncoimaging and oncopathology will broadly have the following uses: cancer screening (detection of lesions), characterization and grading of tumors, and clinical decision-making and prognostication. However, AI cannot be a foolproof panacea nor can it supplant the role of humans. It can however be a powerful and useful complement to human insights and deeper understanding. Multiple issues like standardization, validity, ethics, privacy, finances, legal liability, training, accreditation, etc., need to be overcome before the vast potential of AI in diagnostic oncology can be fully harnessed. © 2021 Indian Journal of Cancer | Published by Wolters Kluwer-Medknow.},
	author_keywords = {Artificial intelligence (AI); deep learning; diagnostics; machine learning; oncology; pathology; radiology},
	keywords = {Artificial Intelligence; Deep Learning; Humans; Machine Learning; Neoplasms; algorithm; artificial intelligence; artificial neural network; cancer diagnosis; cancer screening; cancer therapy; clinical decision making; deep learning; DNA methylation; histopathology; human; imaging; machine learning; oncoimaging; pathology; phenotype; radiogenomics; radiomics; Review; artificial intelligence; neoplasm},
	correspondence_address = {D. Sen; Department of Radiodiagnosis, Armed Forces Medical College and Command Hospital (Southern Command), Pune, Maharashtra, India; email: sendebraj@gmail.com},
	publisher = {Wolters Kluwer Medknow Publications},
	issn = {0019509X},
	coden = {IJCAA},
	pmid = {34975094},
	language = {English},
	abbrev_source_title = {Indian J. Cancer},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Heyen2021,
	author = {Heyen, Nils B. and Salloch, Sabine},
	title = {The ethics of machine learning-based clinical decision support: an analysis through the lens of professionalisation theory},
	year = {2021},
	journal = {BMC Medical Ethics},
	volume = {22},
	number = {1},
	doi = {10.1186/s12910-021-00679-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113153597&doi=10.1186%2fs12910-021-00679-3&partnerID=40&md5=4cfd6a9f50805e44307133d253c4b3b9},
	affiliations = {Competence Center Emerging Technologies, Fraunhofer Institute for Systems and Innovation Research ISI, Breslauer Str. 48, Karlsruhe, 76139, Germany; Institute of Ethics, History and Philosophy of Medicine, Hannover Medical School, Carl-Neuberg-Str. 1, Hannover, 30625, Germany},
	abstract = {Background: Machine learning-based clinical decision support systems (ML_CDSS) are increasingly employed in various sectors of health care aiming at supporting clinicians’ practice by matching the characteristics of individual patients with a computerised clinical knowledge base. Some studies even indicate that ML_CDSS may surpass physicians’ competencies regarding specific isolated tasks. From an ethical perspective, however, the usage of ML_CDSS in medical practice touches on a range of fundamental normative issues. This article aims to add to the ethical discussion by using professionalisation theory as an analytical lens for investigating how medical action at the micro level and the physician–patient relationship might be affected by the employment of ML_CDSS. Main text: Professionalisation theory, as a distinct sociological framework, provides an elaborated account of what constitutes client-related professional action, such as medical action, at its core and why it is more than pure expertise-based action. Professionalisation theory is introduced by presenting five general structural features of professionalised medical practice: (i) the patient has a concern; (ii) the physician deals with the patient’s concern; (iii) s/he gives assistance without patronising; (iv) s/he regards the patient in a holistic manner without building up a private relationship; and (v) s/he applies her/his general expertise to the particularities of the individual case. Each of these five key aspects are then analysed regarding the usage of ML_CDSS, thereby integrating the perspectives of professionalisation theory and medical ethics. Conclusions: Using ML_CDSS in medical practice requires the physician to pay special attention to those facts of the individual case that cannot be comprehensively considered by ML_CDSS, for example, the patient’s personality, life situation or cultural background. Moreover, the more routinized the use of ML_CDSS becomes in clinical practice, the more that physicians need to focus on the patient’s concern and strengthen patient autonomy, for instance, by adequately integrating digital decision support in shared decision-making. © 2021, The Author(s).},
	author_keywords = {Algorithms; Artificial intelligence; Clinical decision support systems; Ethics; Machine learning; Patient autonomy; Physicians; Physician–patient relationship; Profession; Professionalisation},
	keywords = {Decision Support Systems, Clinical; Ethics, Medical; Female; Humans; Machine Learning; Physician-Patient Relations; Physicians; adult; algorithm; article; artificial intelligence; attention; clinical decision support system; clinical practice; employment; female; human; knowledge base; life; machine learning; male; medical ethics; medical practice; patient autonomy; personality; shared decision making; theoretical study; touch; doctor patient relationship; machine learning; medical ethics; physician},
	correspondence_address = {S. Salloch; Institute of Ethics, History and Philosophy of Medicine, Hannover Medical School, Hannover, Carl-Neuberg-Str. 1, 30625, Germany; email: salloch.sabine@mh-hannover.de},
	publisher = {BioMed Central Ltd},
	issn = {14726939},
	pmid = {34412649},
	language = {English},
	abbrev_source_title = {BMC Med. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mühlhoff2021675,
	author = {Mühlhoff, Rainer},
	title = {Predictive privacy: towards an applied ethics of data analytics},
	year = {2021},
	journal = {Ethics and Information Technology},
	volume = {23},
	number = {4},
	pages = {675 – 690},
	doi = {10.1007/s10676-021-09606-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111545455&doi=10.1007%2fs10676-021-09606-x&partnerID=40&md5=11eb4a990b15fd33b4f274580feb8f41},
	affiliations = {Excellence Cluster Science of Intelligence, Technische Universität Berlin, Straße des 17. Juni 135, Berlin, 10623, Germany},
	abstract = {Data analytics and data-driven approaches in Machine Learning are now among the most hailed computing technologies in many industrial domains. One major application is predictive analytics, which is used to predict sensitive attributes, future behavior, or cost, risk and utility functions associated with target groups or individuals based on large sets of behavioral and usage data. This paper stresses the severe ethical and data protection implications of predictive analytics if it is used to predict sensitive information about single individuals or treat individuals differently based on the data many unrelated individuals provided. To tackle these concerns in an applied ethics, first, the paper introduces the concept of “predictive privacy” to formulate an ethical principle protecting individuals and groups against differential treatment based on Machine Learning and Big Data analytics. Secondly, it analyses the typical data processing cycle of predictive systems to provide a step-by-step discussion of ethical implications, locating occurrences of predictive privacy violations. Thirdly, the paper sheds light on what is qualitatively new in the way predictive analytics challenges ethical principles such as human dignity and the (liberal) notion of individual privacy. These new challenges arise when predictive systems transform statistical inferences, which provide knowledge about the cohort of training data donors, into individual predictions, thereby crossing what I call the “prediction gap”. Finally, the paper summarizes that data protection in the age of predictive analytics is a collective matter as we face situations where an individual’s (or group’s) privacy is violated using data other individuals provide about themselves, possibly even anonymously. © 2021, The Author(s).},
	author_keywords = {Automated decision making; Bias; Ethics of Big Data; Group privacy; Predictive analytics; Privacy},
	keywords = {Data Analytics; Data privacy; Forecasting; Machine learning; Philosophical aspects; Computing technology; Data-driven approach; Differential treatment; Ethical implications; Individual prediction; Sensitive attribute; Sensitive informations; Statistical inference; Predictive analytics},
	correspondence_address = {R. Mühlhoff; Excellence Cluster Science of Intelligence, Technische Universität Berlin, Berlin, Straße des 17. Juni 135, 10623, Germany; email: muehlhoff@tu-berlin.de},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Van Der Stouwe2021,
	author = {Van Der Stouwe, A. M. Madelein and Tuitert, Inge and Giotis, Ioannis and Calon, Joost and Gannamani, Rahul and Dalenberg, Jelle R. and Van Der Veen, Sterre and Klamer, Marrit R. and Telea, Alex C. and Tijssen, Marina A.J.},
	title = {Next move in movement disorders (NEMO): Developing a computer-aided classification tool for hyperkinetic movement disorders},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {10},
	doi = {10.1136/bmjopen-2021-055068},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117142424&doi=10.1136%2fbmjopen-2021-055068&partnerID=40&md5=72572476084cb67fdd10c875095d3c37},
	affiliations = {Department of Neurology, University Medical Centre Groningen, University of Groningen, Groningen, Netherlands; Expertise Centre Movement Disorders Groningen, University Medical Center Groningen, Groningen, Netherlands; ZiuZ Visual Intelligence BV, Gorredijk, Groningen, Netherlands; Department of Information and Computing Sciences, University of Utrecht, Utrecht, Netherlands},
	abstract = {Introduction Our aim is to develop a novel approach to hyperkinetic movement disorder classification, that combines clinical information, electromyography, accelerometry and video in a computer-aided classification tool. We see this as the next step towards rapid and accurate phenotype classification, the cornerstone of both the diagnostic and treatment process. Methods and analysis The Next Move in Movement Disorders (NEMO) study is a cross-sectional study at Expertise Centre Movement Disorders Groningen, University Medical Centre Groningen. It comprises patients with single and mixed phenotype movement disorders. Single phenotype groups will first include dystonia, myoclonus and tremor, and then chorea, tics, ataxia and spasticity. Mixed phenotypes are myoclonus-dystonia, dystonic tremor, myoclonus ataxia and jerky/tremulous functional movement disorders. Groups will contain 20 patients, or 40 healthy participants. The gold standard for inclusion consists of interobserver agreement on the phenotype among three independent clinical experts. Electromyography, accelerometry and three-dimensional video data will be recorded during performance of a set of movement tasks, chosen by a team of specialists to elicit movement disorders. These data will serve as input for the machine learning algorithm. Labels for supervised learning are provided by the expert-based classification, allowing the algorithm to learn to predict what the output label should be when given new input data. Methods using manually engineered features based on existing clinical knowledge will be used, as well as deep learning methods which can detect relevant and possibly new features. Finally, we will employ visual analytics to visualise how the classification algorithm arrives at its decision. Ethics and dissemination Ethical approval has been obtained from the relevant local ethics committee. The NEMO study is designed to pioneer the application of machine learning of movement disorders. We expect to publish articles in multiple related fields of research and patients will be informed of important results via patient associations and press releases.  © Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {adult neurology; neurology; neurophysiology},
	keywords = {Computers; Cross-Sectional Studies; Dystonic Disorders; Humans; Hyperkinesis; Movement Disorders; accelerometry; adult; Article; artificial intelligence; ataxia; chorea; classification algorithm; clinical article; computer aided design; controlled study; cross-sectional study; diagnostic test accuracy study; dystonia; electromyography; essential tremor; female; first-degree relative; Gilles de la Tourette syndrome; gold standard; human; hyperkinesia; informed consent; interrater reliability; machine learning; male; medical specialist; motor dysfunction; myoclonus; myoclonus dystonia; onset age; phenotype; prospective study; spasticity; supervised machine learning; task performance; tic; tremor; visual analog scale; computer; dystonic disorder; hyperkinesia},
	correspondence_address = {A.M.M. Van Der Stouwe; Department of Neurology, University Medical Centre Groningen, University of Groningen, Groningen, Netherlands; email: a.m.m.van.der.stouwe@umcg.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34635535},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gerdes2022,
	author = {Gerdes, Anne},
	title = {A participatory data-centric approach to AI Ethics by Design},
	year = {2022},
	journal = {Applied Artificial Intelligence},
	volume = {36},
	number = {1},
	doi = {10.1080/08839514.2021.2009222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121394933&doi=10.1080%2f08839514.2021.2009222&partnerID=40&md5=bae762ff03709aaf0fe7fc2212394421},
	affiliations = {Department of Design and Communication, University of Southern Denmark, Kolding, Denmark},
	abstract = {Data-driven artificial intelligence (AI) based on machine learning techniques (ML) has increasingly become an enabler in critical societal domains. However, the introduction of ML systems is often accompanied by unjustified, biased, and discriminated outcomes with severe consequences for the individuals affected. Consequently, in recent years value-based design methods have sought to anticipate and mitigate moral wrongdoing by drawing attention to ethical and epistemic challenges related to the design of AI systems. This article presents a participatory data-centric approach to AI Ethics by Design by promoting and refining insights from contributions within the family of value-sensitive design methods. The approach provides a practicable outlook on addressing epistemic and ethical issues related to data activities in early ML development project stages. Hence, the article seeks to enhance opportunities for ethically informed AI design by stressing the need for bridge building to cultivate a shared understanding among system developers and domain experts about a given data domain and its relatedness to a specific practice. © 2021 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	keywords = {Artificial intelligence; Bridges; Ethical technology; Learning systems; Artificial intelligence systems; Data driven; Data-centric approaches; Design method; Development programmes; Ethical issues; Machine learning techniques; Technique development; Value sensitive design; Value-based; Design},
	correspondence_address = {A. Gerdes; Department of Design and Communication, University of Southern Denmark, Kolding, Universitetsparken 1, DK-6000, Denmark; email: gerdes@sdu.dk},
	publisher = {Taylor and Francis Ltd.},
	issn = {08839514},
	coden = {AAINE},
	language = {English},
	abbrev_source_title = {Appl Artif Intell},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Gallastegui2021,
	author = {Gallastegui, Luis Miguel Garay and Forradellas, Ricardo Francisco Reier},
	title = {Business methodology for the application in university environments of predictive machine learning models based on an ethical taxonomy of the student’s digital twin},
	year = {2021},
	journal = {Administrative Sciences},
	volume = {11},
	number = {4},
	doi = {10.3390/admsci11040118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118405418&doi=10.3390%2fadmsci11040118&partnerID=40&md5=d4555e09b1d463dd2c0300aa9b84f6fd},
	affiliations = {Department of Marketing, ESIC University, Pozuelo de Alarcón, Madrid, 28223, Spain; DEKIS Research Group, Department of Economics, Catholic University of Ávila, Avila, 05005, Spain},
	abstract = {Educational institutions are undergoing an internal process of strategic transformation to adapt to the challenges caused by the growing impact of digitization and the continuous development of student and labor market expectations. Consequently, it is essential to obtain more accurate knowledge of students to improve their learning experience and their relationship with the educational institution, and in this way also contribute to evolving those students’ skills that will be useful in their next professional future. For this to happen, the entire academic community faces obstacles related to data capture, analysis, and subsequent activation. This article establishes a methodology to design, from a business point of view, the application in educational environments of predictive machine learning models based on Artificial Intelligence (AI), focusing on the student and their experience when interacting physically and emotionally with the educational ecosystem. This methodology focuses on the educational offer, relying on a taxonomy based on learning objects to automate the construction of analytical models. This methodology serves as a motivating backdrop to several challenges facing educational institutions, such as the exciting crossroads of data fusion and the ethics of data use. Our ultimate goal is to encourage education experts and practitioners to take full advantage of applying this methodology to make data-driven decisions without any preconceived bias due to the lack of contrasting information. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Competences; Higher education; Machine learning},
	correspondence_address = {L.M.G. Gallastegui; Department of Marketing, ESIC University, Madrid, Pozuelo de Alarcón, 28223, Spain; email: luismiguel.garay@esic.university; R.F.R. Forradellas; DEKIS Research Group, Department of Economics, Catholic University of Ávila, Avila, 05005, Spain; email: ricardo.reier@ucavila.es},
	publisher = {MDPI},
	issn = {20763387},
	language = {English},
	abbrev_source_title = {Adm. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Chakraborty2021,
	author = {Chakraborty, Mallinath and Rodrigues, Patrícia R S and Watkins, W John and Hayward, Angela and Sharma, Alok and Hayward, Rachel and Smit, Elisa and Jones, Rebekka and Goel, Nitin and Asokkumar, Amar and Calvert, Jennifer and Odd, David and Morris, Ian and Doherty, Cora and Elliott, Sian and Strang, Angela and Andrews, Robert and Zaher, Summia and Sharma, Simran and Bell, Sarah and Oruganti, Siva and Smith, Claire and Orme, Judith and Edkins, Sarah and Craigon, Marie and White, Daniel and Dantoft, Widad and Davies, Luke C and Moet, Linda and McLaren, James E and Clarkstone, Samantha and Watson, Gareth L and Hood, Kerenza and Kotecha, Sailesh and Morgan, B. Paul and O'Donnell, Valerie B and Ghazal, Peter},
	title = {NSeP: Immune and metabolic biomarkers for early detection of neonatal sepsis - Protocol for a prospective multicohort study},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {12},
	doi = {10.1136/bmjopen-2021-050100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122629926&doi=10.1136%2fbmjopen-2021-050100&partnerID=40&md5=c5e9c48d8e013fd05adfdd768e21f4ab},
	affiliations = {Regional Neonatal Intensive Care Unit, University Hospital of Wales, Cardiff, United Kingdom; Division of Infection and Immunity, School of Medicine, Cardiff University, Cardiff, United Kingdom; Department of Statistics, Division of Infection and Immunity, School of Medicine, Cardiff University, Cardiff, United Kingdom; Department of Obstetrics and Gynaecology, University Hospital of Wales, Cardiff, United Kingdom; Infection and Immunity, Cardiff University, Cardiff, United Kingdom; Women's Unit, Cardiff and Vale NHS Trust, Cardiff, United Kingdom; Department of Anaesthetics, University Hospital of Wales, Cardiff, United Kingdom; Simpsons Special Cary Baby Unit, Royal Infirmary of Edinburgh, Edinburgh, United Kingdom; Infection Medicine, Deanery of Biomedical Sciences, Edinburgh Medical School, The University of Edinburgh, Edinburgh, United Kingdom; Department of Child Health, Institute of Molecular and Experimental Medicine, Cardiff University, School of Medicine, Cardiff, United Kingdom; Department of Systems Medicine, Medical School, Cardiff University, Cardiff, United Kingdom},
	abstract = {Introduction Diagnosing neonatal sepsis is heavily dependent on clinical phenotyping as culture-positive body fluid has poor sensitivity, and existing blood biomarkers have poor specificity. A combination of machine learning, statistical and deep pathway biology analyses led to the identification of a tripartite panel of biologically connected immune and metabolic markers that showed greater than 99% accuracy for detecting bacterial infection with 100% sensitivity. The cohort study described here is designed as a large-scale clinical validation of this previous work. Methods and analysis This multicentre observational study will prospectively recruit a total of 1445 newborn infants (all gestations) - 1084 with suspected early - or late-onset sepsis, and 361 controls - over 4 years. A small volume of whole blood will be collected from infants with suspected sepsis at the time of presentation. This sample will be used for integrated transcriptomic, lipidomic and targeted proteomics profiling. In addition, a subset of samples will be subjected to cellular phenotype and proteomic analyses. A second sample from the same patient will be collected at 24 hours, with an opportunistic sampling for stool culture. For control infants, only one set of blood and stool sample will be collected to coincide with clinical blood sampling. Along with detailed clinical information, blood and stool samples will be analysed and the information will be used to identify and validate the efficacy of immune-metabolic networks in the diagnosis of bacterial neonatal sepsis and to identify new host biomarkers for viral sepsis. Ethics and dissemination The study has received research ethics committee approval from the Wales Research Ethics Committee 2 (reference 19/WA/0008) and operational approval from Health and Care Research Wales. Submission of study results for publication will involve making available all anonymised primary and processed data on public repository sites. Trial registration number NCT03777670. © Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {immunology; neonatal intensive & critical care; perinatology},
	keywords = {Biomarkers; Cohort Studies; Humans; Multicenter Studies as Topic; Neonatal Sepsis; Observational Studies as Topic; Prospective Studies; Proteomics; Sepsis; antibiotic agent; biological marker; biological marker; Article; blood sampling; blood volume; cohort analysis; controlled study; early diagnosis; feces analysis; feces culture; human; late onset disorder; lipidomics; major clinical study; multicenter study; newborn sepsis; observational study; proteomics; transcriptomics; microbiology; multicenter study (topic); newborn sepsis; prospective study; sepsis},
	correspondence_address = {M. Chakraborty; Regional Neonatal Intensive Care Unit, University Hospital of Wales, Cardiff, United Kingdom; email: chakrabortym@cardiff.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {37010923},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Turransky20211,
	author = {Turransky, Aaron and Amini, M. Hadi},
	title = {Artificial Intelligence and Cybersecurity: Tale of Healthcare Applications},
	year = {2021},
	journal = {Cyberphysical Smart Cities Infrastructures: Optimal Operation and Intelligent Decision Making},
	pages = {1 – 11},
	doi = {10.1002/9781119748342.ch1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85132268467&doi=10.1002%2f9781119748342.ch1&partnerID=40&md5=921e268234b61b30ba9d2489e16093ea},
	affiliations = {Knight Foundation School of Computing and Information Sciences, Florida International University, Miami, FL, United States},
	abstract = {According to J. Bryson and A. Winfield, standards set by consensus of a large group should include ethical implications and machine learning code, which powers artificial intelligence (AI), and should incorporate these ethics. While Bryson and Winfield discuss the importance of these ethical standards, they fail to discuss what these ethics should be, leaving it open to interpretation. This chapter examines this gap in effort to try to establish some status quo. Ethics and morality have a large impact on AI in healthcare. When considering the intersection of AI, cybersecurity, and healthcare industry, we have seen that a myriad of problems exist today, and there are more coming down the pipe in the future. Establishing partnerships between the federal government and academia is a great way to ensure that the future of AI remains bright. © 2022 John Wiley & Sons, Inc.},
	author_keywords = {Artificial intelligence; Cybersecurity; Ethical implications; Healthcare applications; Morality},
	publisher = {wiley},
	isbn = {978-111974834-2; 978-111974830-4},
	language = {English},
	abbrev_source_title = {Cyberphysical Smart Cities Infrastruct.: Optimal Operat. and Intell. Decis. Mak.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Gauld20212509,
	author = {Gauld, Christophe and Micoulaud-Franchi, Jean-Arthur and Dumas, Guillaume},
	title = {Comment on Starke et al.: 'Computing schizophrenia: Ethical challenges for machine learning in psychiatry': From machine learning to student learning: Pedagogical challenges for psychiatry},
	year = {2021},
	journal = {Psychological Medicine},
	volume = {51},
	number = {14},
	pages = {2509 – 2511},
	doi = {10.1017/S0033291720003906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094212672&doi=10.1017%2fS0033291720003906&partnerID=40&md5=357f8fd38596042af9e781d98b0ef206},
	affiliations = {Department of Psychiatry, University of Grenoble, Avenue du Maquis du Grésivaudan, Grenoble, 38 000, France; Umr Cnrs 8590 Ihpst, Sorbonne University, Paris 1, France; University Sleep Clinic, Services of Functional Exploration of the Nervous System, University Hospital of Bordeaux, Place Amélie Raba-Leon, Bordeaux, 33 076, France; Usr Cnrs 3413 Sanpsy, University Hospital Pellegrin, University of Bordeaux, Bordeaux, France; Precision Psychiatry and Social Physiology Laboratory, Chu Sainte-Justine Research Center, Department of Psychiatry, University of Montreal, Quebec, Canada; Human Brain and Behavior Laboratory, Center for Complex Systems and Brain Sciences, Florida Atlantic University, Boca Raton, FL, United States},
	author_keywords = {Artificial intelligence; computational psychiatry; education; epistemology; ethics; health care},
	keywords = {Humans; Machine Learning; Psychiatry; Schizophrenia; Students; human; machine learning; psychiatry; schizophrenia; student},
	correspondence_address = {C. Gauld; Department of Psychiatry, University of Grenoble, Grenoble, Avenue du Maquis du Grésivaudan, 38 000, France; email: gauldchristophe@gmail.com},
	publisher = {Cambridge University Press},
	issn = {00332917},
	coden = {PSMDC},
	pmid = {33087200},
	language = {English},
	abbrev_source_title = {Psychol. Med.},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access}
}

@ARTICLE{Boulos2021,
	author = {Boulos, Laura Joy and Mendes, Alexandre and Delmas, Alexandra and Chraibi Kaadoud, Ikram},
	title = {An Iterative and Collaborative End-to-End Methodology Applied to Digital Mental Health},
	year = {2021},
	journal = {Frontiers in Psychiatry},
	volume = {12},
	doi = {10.3389/fpsyt.2021.574440},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116749348&doi=10.3389%2ffpsyt.2021.574440&partnerID=40&md5=e4d4c2e62fd7966e34df3a5d3073f22d},
	affiliations = {Saint-Joseph University, Beirut, Lebanon; Groupe onepoint, Paris, France},
	abstract = {Artificial intelligence (AI) algorithms together with advances in data storage have recently made it possible to better characterize, predict, prevent, and treat a range of psychiatric illnesses. Amid the rapidly growing number of biological devices and the exponential accumulation of data in the mental health sector, the upcoming years are facing a need to homogenize research and development processes in academia as well as in the private sector and to centralize data into federalizing platforms. This has become even more important in light of the current global pandemic. Here, we propose an end-to-end methodology that optimizes and homogenizes digital research processes. Each step of the process is elaborated from project conception to knowledge extraction, with a focus on data analysis. The methodology is based on iterative processes, thus allowing an adaptation to the rate at which digital technologies evolve. The methodology also advocates for interdisciplinary (from mathematics to psychology) and intersectoral (from academia to the industry) collaborations to merge the gap between fundamental and applied research. We also pinpoint the ethical challenges and technical and human biases (from data recorded to the end user) associated with digital mental health. In conclusion, our work provides guidelines for upcoming digital mental health studies, which will accompany the translation of fundamental mental health research to digital technologies. © Copyright © 2021 Boulos, Mendes, Delmas and Chraibi Kaadoud.},
	author_keywords = {an end-to-end methodology; cognitive biases; digital mental health; ethics; human factors; interdisciplinar intersectoral collaborations; knowledge discovery data base (KDD); machine learning},
	keywords = {applied research; article; cognitive bias; conception; data analysis; digital technology; ethics; extraction; human; human experiment; intersectoral collaboration; knowledge discovery; mathematics; mental health research; practice guideline},
	correspondence_address = {L.J. Boulos; Saint-Joseph University, Beirut, Lebanon; email: laurajoyboulos@gmail.com; A. Mendes; Groupe onepoint, Paris, France; email: a.mendes@groupeonepoint.com; A. Delmas; Groupe onepoint, Paris, France; email: a.delmas@groupeonepoint.com; I. Chraibi Kaadoud; Groupe onepoint, Paris, France; email: ichraibik@outlook.fr},
	publisher = {Frontiers Media S.A.},
	issn = {16640640},
	language = {English},
	abbrev_source_title = {Front. Psychiatry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Weissler2021,
	author = {Weissler, E. Hope and Naumann, Tristan and Andersson, Tomas and Ranganath, Rajesh and Elemento, Olivier and Luo, Yuan and Freitag, Daniel F. and Benoit, James and Hughes, Michael C. and Khan, Faisal and Slater, Paul and Shameer, Khader and Roe, Matthew and Hutchison, Emmette and Kollins, Scott H. and Broedl, Uli and Meng, Zhaoling and Wong, Jennifer L. and Curtis, Lesley and Huang, Erich and Ghassemi, Marzyeh},
	title = {The role of machine learning in clinical research: transforming the future of evidence generation},
	year = {2021},
	journal = {Trials},
	volume = {22},
	number = {1},
	doi = {10.1186/s13063-021-05489-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112765226&doi=10.1186%2fs13063-021-05489-x&partnerID=40&md5=758cc350de52a2939966fafac77bdede},
	affiliations = {Duke Clinical Research Institute, Duke University School of Medicine, Box 2834, Durham, 27701, NC, United States; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States; Institute for Medical Engineering and Science, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States; CIFAR AI Chair, Vector Institute, Toronto, ON, Canada; Microsoft Research, Cambridge, MA, United States; AstraZeneca, Gothenburg, Sweden; Courant Institute of Mathematical Science, New York University, New York, NY, United States; Englander Institute for Precision Medicine, Weill Cornell Medical College, New York, NY, United States; Northwestern University Clinical and Translational Sciences Institute, Northwestern University, Chicago, IL, United States; Division Pharmaceuticals, Open Innovation and Digital Technologies, Bayer AG, Wuppertal, Germany; University of Alberta, Edmonton, AB, Canada; Department of Computer Science, Tufts University, Medford, MA, United States; Billion Minds, Inc., Seattle, WA, United States; Verana Health, San Francisco, CA, United States; Boehringer-Ingelheim, Burlington, Canada; Sanofi, Cambridge, MA, United States; Sanofi, Washington, DC, United States; Duke Forge, Durham, NC, United States; Vector Institute, University of Toronto, Toronto, ON, Canada},
	abstract = {Background: Interest in the application of machine learning (ML) to the design, conduct, and analysis of clinical trials has grown, but the evidence base for such applications has not been surveyed. This manuscript reviews the proceedings of a multi-stakeholder conference to discuss the current and future state of ML for clinical research. Key areas of clinical trial methodology in which ML holds particular promise and priority areas for further investigation are presented alongside a narrative review of evidence supporting the use of ML across the clinical trial spectrum. Results: Conference attendees included stakeholders, such as biomedical and ML researchers, representatives from the US Food and Drug Administration (FDA), artificial intelligence technology and data analytics companies, non-profit organizations, patient advocacy groups, and pharmaceutical companies. ML contributions to clinical research were highlighted in the pre-trial phase, cohort selection and participant management, and data collection and analysis. A particular focus was paid to the operational and philosophical barriers to ML in clinical research. Peer-reviewed evidence was noted to be lacking in several areas. Conclusions: ML holds great promise for improving the efficiency and quality of clinical research, but substantial barriers remain, the surmounting of which will require addressing significant gaps in evidence. © 2021, The Author(s).},
	author_keywords = {Artificial intelligence; Clinical trials as topic; Machine learning; Research design; Research ethics},
	keywords = {Artificial Intelligence; Humans; Machine Learning; United States; United States Food and Drug Administration; artificial intelligence; biotechnology; clinical research; data analysis; deep neural network; drug development; evidence based practice; human; information processing; language processing; machine learning; Note; process optimization; study design; validation process; artificial intelligence; Food and Drug Administration; United States},
	correspondence_address = {E.H. Weissler; Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, 02139, United States; email: Hope.weissler@duke.edu},
	publisher = {BioMed Central Ltd},
	issn = {17456215},
	pmid = {34399832},
	language = {English},
	abbrev_source_title = {Trials},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{da Silva2021,
	author = {da Silva, Daniela America and Louro, Henrique Duarte Borges and Goncalves, Gildarcio Sousa and Marques, Johnny Cardoso and Dias, Luiz Alberto Vieira and da Cunha, Adilson Marques and Tasinaffo, Paulo Marcelo},
	title = {Could a conversational ai identify offensive language?†},
	year = {2021},
	journal = {Information (Switzerland)},
	volume = {12},
	number = {10},
	doi = {10.3390/info12100418},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117762535&doi=10.3390%2finfo12100418&partnerID=40&md5=ad36849cde8e51a4218a897a52ba9500},
	affiliations = {Electronic and Computer Engineering Program, Informatics, Brazilian Aeronautics Institute of Technology, ITA, Sao Jose dos Campos, 12228-900, Brazil},
	abstract = {In recent years, we have seen a wide use of Artificial Intelligence (AI) applications in the Internet and everywhere. Natural Language Processing and Machine Learning are important sub-fields of AI that have made Chatbots and Conversational AI applications possible. Those algorithms are built based on historical data in order to create language models, however historical data could be intrinsically discriminatory. This article investigates whether a Conversational AI could identify offensive language and it will show how large language models often produce quite a bit of unethical behavior because of bias in the historical data. Our low-level proof-of-concept will present the challenges to detect offensive language in social media and it will discuss some steps to propitiate strong results in the detection of offensive language and unethical behavior using a Conversational AI. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {AI ethics; Dictionary; Fairness; Natural language; Offensive},
	keywords = {Artificial intelligence; Computational linguistics; Natural language processing systems; Artificial intelligence ethic; Chatbots; Fairness; Historical data; Language model; Machine-learning; Natural languages; Offensive; Offensive languages; Sub fields; Learning algorithms},
	correspondence_address = {D.A. da Silva; Electronic and Computer Engineering Program, Informatics, Brazilian Aeronautics Institute of Technology, ITA, Sao Jose dos Campos, 12228-900, Brazil; email: damerica@ita.br},
	publisher = {MDPI},
	issn = {20782489},
	language = {English},
	abbrev_source_title = {Information},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Zhou2021171,
	author = {Zhou, Liangliang},
	title = {Classification of legal articles based on bio ethics related to machine learning},
	year = {2021},
	journal = {Journal of Commercial Biotechnology},
	volume = {26},
	number = {4},
	pages = {171 – 178},
	doi = {10.5912/jcb1092},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135277818&doi=10.5912%2fjcb1092&partnerID=40&md5=5e04bc299d79a013538479758e694235},
	affiliations = {Department of policy and law, Party School of Cangzhou municipal Party committee of CPC, Cangzhou, 061000, China},
	abstract = {In order to solve the problem of long execution time of traditional legal text classification, this paper designs a legal text classification method based on machine learning. Based on the combination of support vector machine (SVM) and naive Bayes classifier in machine learning, the feature value of legal text is filtered, the legal text classification matrix is established, and the legal text classification results are accessed directly through embedded system to realize the legal text classification. The experimental results show that the implementation time of the design method is more than twice as fast as that of the control group, which can solve the problem of long implementation time of the traditional method. AI and machine learning have the potential to transform the delivery of healthcare. However, creating decision support systems based on machine learning requires more than just a technological undertaking. As a result, bioethical standards must be considered. As AI and machine learning progress, bioethical frameworks must be adapted to solve the difficulties that these growing systems may bring, and the creation of these automated systems also has to be tailored to embrace bioethical concepts. © 2021 ThinkBiotech LLC. All rights reserved.},
	author_keywords = {classification method; legal texts and articles; machine learning},
	keywords = {Classification (of information); Decision support systems; Learning systems; Support vector machines; Text processing; Classification methods; Feature values; Legal text and article; Legal texts; Machine-learning; Naive Bayes classifiers; On-machines; Support vectors machine; Text classification; Text classification methods; article; Bayesian learning; bioethics; classifier; controlled study; decision support system; health care delivery; machine learning; support vector machine; Automation},
	publisher = {ThinkBiotech LLC},
	issn = {14628732},
	coden = {JCBOA},
	language = {English},
	abbrev_source_title = {J. Commer. Biotechnol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ntlhakana2022,
	author = {Ntlhakana, Liepollo and Nelson, Gill and Khoza-Shangase, Katijah and Dorkin, Elton},
	title = {Occupational hearing loss for platinum miners in South Africa: A case study of data sharing practices and ethical challenges in the mining industry},
	year = {2022},
	journal = {International Journal of Environmental Research and Public Health},
	volume = {19},
	number = {1},
	doi = {10.3390/ijerph19010001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121377009&doi=10.3390%2fijerph19010001&partnerID=40&md5=953515520fa7bf8cc3fbde9cdf88bddc},
	affiliations = {Faculty of Health Sciences, School of Public Health, University of the Witwatersrand, Johannesburg, 2000, South Africa; Department of Speech Pathology and Audiology, Faculty of Humanities, School of Human and Community Development, University of the Witwatersrand, Johannesburg, 2050, South Africa; Anglo American, Johannesburg, 2091, South Africa},
	abstract = {Background: The relevant legislation ensures confidentiality and has paved the way for data handling and sharing. However, the industry remains uncertain regarding big data handling and sharing practices for improved healthcare delivery and medical research. Methods: A semi-qualitative cross-sectional study was used which entailed analysing miners’ personal health records from 2014 to 2018. Data were accessed from the audiometry medical surveillance database (n = 480), the hearing screening database (n = 24,321), and the occupational hygiene database (n = 15,769). Ethical principles were applied to demonstrate big data protection and sharing. Results: Some audiometry screening and occupational hygiene records were incomplete and/or inaccurate (N = 4675). The database containing medical disease and treatment records could not be accessed. Ethical challenges included a lack of clarity regarding permission rights when sharing big data, and no policy governing the divulgence of miners’ personal and medical records for research. Conclusion: This case study illustrates how research can be effectively, although not maliciously, obstructed by the strict protection of employee medical data. Clearly communicated company policies should be developed for the sharing of workers’ records in the mining industry to improve HCPs. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Audiometry; Electronic data; Ethical principles; Healthcare providers; Machine learning systems; Occupational exposures; Personal data},
	keywords = {Cross-Sectional Studies; Hearing Loss, Noise-Induced; Humans; Information Dissemination; Miners; Occupational Diseases; Platinum; South Africa; South Africa; platinum; platinum; ethics; health care; machine learning; mining industry; occupational exposure; access to information; Article; audiometry; beneficence; big data; case study; confidentiality; cross-sectional study; data accuracy; data protection; environmental exposure; health care personnel; human; identifiable information; industrial hygiene; information processing; justice; machine learning; medical ethics; medical record; miner; mining; occupational deafness; occupational exposure; periodic medical examination; South Africa; workers rights; information dissemination; noise injury; occupational disease; South Africa},
	correspondence_address = {L. Ntlhakana; Faculty of Health Sciences, School of Public Health, University of the Witwatersrand, Johannesburg, 2000, South Africa; email: Liepollo.Ntlhakana@wits.ac.za},
	publisher = {MDPI},
	issn = {16617827},
	pmid = {35010261},
	language = {English},
	abbrev_source_title = {Int. J. Environ. Res. Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Fu2021,
	author = {Fu, Yi-Kai and Liu, Hsueng-Mei and Lee, Li-Hsuan and Chen, Ying-Ju and Chien, Sheng-Hsuan and Lin, Jeong-Shi and Chen, Wen-Chun and Cheng, Ming-Hsuan and Lin, Po-Heng and Lai, Jheng-You and Chen, Chyong-Mei and Liu, Chun-Yu},
	title = {The tvgh-nycu thal-classifier: Development of a machine-learning classifier for differentiating thalassemia and non-thalassemia patients},
	year = {2021},
	journal = {Diagnostics},
	volume = {11},
	number = {9},
	doi = {10.3390/diagnostics11091725},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116699114&doi=10.3390%2fdiagnostics11091725&partnerID=40&md5=0d873c1577535653f6c4b3069bb21ce3},
	affiliations = {School of Medicine, Yangming Campus, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Department of Emergency Medicine, Far Eastern Memorial Hospital, New Taipei City, 220, Taiwan; Division of Transfusion Medicine, Department of Medicine, Taipei Veterans General Hospital, Taipei, 112, Taiwan; Institute of Clinical Medicine, Yangming Campus, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; Division of Hematology, Department of Medicine, Taipei Veterans General Hospital, Taipei, 112, Taiwan; Department of Ophthalmology, Taipei Veterans General Hospital, Taipei, 112, Taiwan; Department of Surgery, Kaohsiung Chang Gung Memorial Hospital, Kaohsiung, 833, Taiwan; Institute of Public Health, Yangming Campus, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan},
	abstract = {Thalassemia and iron deficiency are the most common etiologies for microcytic anemia and there are indices discriminating both from common laboratory simple automatic counters. In this study a new classifier for discriminating thalassemia and non-thalassemia microcytic anemia was generated via combination of exciting indices with machine-learning techniques. A total of 350 Taiwanese adult patients whose anemia diagnosis, complete blood cell counts, and hemoglobin gene profiles were retrospectively reviewed. Thirteen prior established indices were applied to current cohort and the sensitivity, specificity, positive and negative predictive values were calculated. A support vector machine (SVM) with Monte-Carlo cross-validation procedure was adopted to generate the classifier. The performance of our classifier was compared with original indices by calculating the average classification error rate and area under the curve (AUC) for the sampled datasets. The performance of this SVM model showed average AUC of 0.76 and average error rate of 0.26, which surpassed all other indices. In conclusion, we developed a convenient tool for primary-care physicians when deferential diagnosis contains thalassemia for the Taiwanese adult population. This approach needs to be validated in other studies or bigger database. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Machine-learning; Microcytic anemia; Supportive vector machine; Thalassemia},
	keywords = {genomic DNA; adult; area under the curve; Article; binary classification; blood cell count; controlled study; demography; diagnostic test accuracy study; female; general practitioner; genetic profile; human; informed consent; machine learning; major clinical study; male; medical ethics; microcytic anemia; Monte Carlo cross validation; practice guideline; predictive value; retrospective study; support vector machine; Taiwanese; thalassemia},
	correspondence_address = {C.-M. Chen; Institute of Public Health, Yangming Campus, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; email: cmchen2@nycu.edu.tw; C.-Y. Liu; School of Medicine, Yangming Campus, National Yang Ming Chiao Tung University, Taipei, 112, Taiwan; email: cyliu3@vghtpe.gov.tw},
	publisher = {MDPI},
	issn = {20754418},
	language = {English},
	abbrev_source_title = {Diagn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Dash20223879,
	author = {Dash, Saloni and Balasubramanian, Vineeth N. and Sharma, Amit},
	title = {Evaluating and Mitigating Bias in Image Classifiers: A Causal Perspective Using Counterfactuals},
	year = {2022},
	journal = {Proceedings - 2022 IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022},
	pages = {3879 – 3888},
	doi = {10.1109/WACV51458.2022.00393},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118832852&doi=10.1109%2fWACV51458.2022.00393&partnerID=40&md5=d0b2fd0efecda9def3d28c2132ee2af9},
	affiliations = {Microsoft Research India, Karnataka, Bangalore, India; Indian Institute of Technology, Telangana, Hyderabad, India},
	abstract = {Counterfactual examples for an input - perturbations that change specific features but not others - have been shown to be useful for evaluating bias of machine learning models, e.g., against specific demographic groups. However, generating counterfactual examples for images is nontrivial due to the underlying causal structure on the various features of an image. To be meaningful, generated perturbations need to satisfy constraints implied by the causal model. We present a method for generating counterfactuals by incorporating a structural causal model (SCM) in an improved variant of Adversarially Learned Inference (ALI), that generates counterfactuals in accordance with the causal relationships between attributes of an image. Based on the generated counterfactuals, we show how to explain a pre-trained machine learning classifier, evaluate its bias, and mitigate the bias using a counterfactual regularizer. On the Morpho-MNIST dataset, our method generates counterfactuals comparable in quality to prior work on SCM-based counterfactuals (DeepSCM), while on the more complex CelebA dataset our method outperforms DeepSCM in generating high-quality valid counterfactuals. Moreover, generated counterfactuals are indistinguishable from reconstructed images in a human evaluation experiment and we subsequently use them to evaluate the fairness of a standard classifier trained on CelebA data. We show that the classifier is biased w.r.t. skin and hair color, and how counterfactual regularization can remove those biases.  © 2022 IEEE.},
	author_keywords = {Accountability; Autoencoders; Deep Learning; Explainable AI; Fairness; GANs; Neural Generative Models; Privacy and Ethics in Vision Deep Learning},
	keywords = {Computer vision; Image classification; Image enhancement; Accountability; Auto encoders; Counterfactuals; Deep learning; Explainable AI; Fairness; GAN; Generative model; Neural generative model; Privacy and ethic in vision deep learning; Deep learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166540915-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/CVF Winter Conf. Appl. Comput. Vis., WACV},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 22nd IEEE/CVF Winter Conference on Applications of Computer Vision, WACV 2022; Conference date: 4 January 2022 through 8 January 2022; Conference code: 177326; All Open Access, Green Open Access}
}

@ARTICLE{Sawers2021,
	author = {Sawers, Nicholas and Bolster, Nigel and Bastawrous, Andrew},
	title = {The Contribution of Artificial Intelligence in Achieving the Sustainable Development Goals (SDGs): What Can Eye Health Can Learn From Commercial Industry and Early Lessons From the Application of Machine Learning in Eye Health Programmes},
	year = {2021},
	journal = {Frontiers in Public Health},
	volume = {9},
	doi = {10.3389/fpubh.2021.752049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122281837&doi=10.3389%2ffpubh.2021.752049&partnerID=40&md5=c7375b0a11a3840cf89deb94729e6c3a},
	affiliations = {The International Centre for Eye Health, London School of Hygiene and Tropical Medicine, London, United Kingdom; Peek Vision, London, United Kingdom},
	abstract = {Achieving The United Nations sustainable developments goals by 2030 will be a challenge. Researchers around the world are working toward this aim across the breadth of healthcare. Technology, and more especially artificial intelligence, has the ability to propel us forwards and support these goals but requires careful application. Artificial intelligence shows promise within healthcare and there has been fast development in ophthalmology, cardiology, diabetes, and oncology. Healthcare is starting to learn from commercial industry leaders who utilize fast and continuous testing algorithms to gain efficiency and find the optimum solutions. This article provides examples of how commercial industry is benefitting from utilizing AI and improving service delivery. The article then provides a specific example in eye health on how machine learning algorithms can be purposed to drive service delivery in a resource-limited setting by utilizing the novel study designs in response adaptive randomization. We then aim to provide six key considerations for researchers who wish to begin working with AI technology which include collaboration, adopting a fast-fail culture and developing a capacity in ethics and data science. Copyright © 2021 Sawers, Bolster and Bastawrous.},
	author_keywords = {artificial intelligence; eye health; m-Health; machine learning; public health research},
	keywords = {Algorithms; Artificial Intelligence; COVID-19; Humans; Machine Learning; Sustainable Development; algorithm; artificial intelligence; human; machine learning; sustainable development},
	correspondence_address = {A. Bastawrous; The International Centre for Eye Health, London School of Hygiene and Tropical Medicine, London, United Kingdom; email: andrew.bastawrous@lshtm.ac.uk},
	publisher = {Frontiers Media S.A.},
	issn = {22962565},
	pmid = {35004574},
	language = {English},
	abbrev_source_title = {Front. Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Leong2021,
	author = {Leong, Tze Ker Matthew and Lo, Wen Shern and Lee, Wei En Zen and Tan, Benedict and Lee, Xing Zhao and Lee, Li Wen Justina Nadia and Lee, Jia-Ying Joey and Suresh, Nivedita and Loo, Lit-Hsin and Szu, Evan and Yeong, Joe},
	title = {Leveraging advances in immunopathology and artificial intelligence to analyze in vitro tumor models in composition and space},
	year = {2021},
	journal = {Advanced Drug Delivery Reviews},
	volume = {177},
	doi = {10.1016/j.addr.2021.113959},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114730059&doi=10.1016%2fj.addr.2021.113959&partnerID=40&md5=805eb6d1aa416e71e18f58dd141f72f2},
	affiliations = {Lee Kong Chian School of Medicine, Nanyang Technological University, Headquarters & Clinical Sciences Building, 11 Mandalay Road, Singapore, 308232, Singapore; Institute of Molecular and Cell Biology (IMCB), Agency of Science, Technology and Research (A*STAR), 61 Biopolis Drive, Proteos, Singapore, 138673, Singapore; Arrive PTE LTD, 1 Maritime Square, Singapore, 099253, Singapore; Bioinformatics Institute, Agency of Science, Technology and Research (A*STAR), 30 Biopolis Street, Matrix, Singapore, 138671, Singapore; Department of Anatomical Pathology, Singapore General Hospital, 20 College Road, Academia, Level 10 Diagnostic Tower, Singapore, 169856, Singapore},
	abstract = {Cancer is the leading cause of death worldwide. Unfortunately, efforts to understand this disease are confounded by the complex, heterogenous tumor microenvironment (TME). Better understanding of the TME could lead to novel diagnostic, prognostic, and therapeutic discoveries. One way to achieve this involves in vitro tumor models that recapitulate the in vivo TME composition and spatial arrangement. Here, we review the potential of harnessing in vitro tumor models and artificial intelligence to delineate the TME. This includes (i) identification of novel features, (ii) investigation of higher-order relationships, and (iii) analysis and interpretation of multiomics data in a (iv) holistic, objective, reproducible, and efficient manner, which surpasses previous methods of TME analysis. We also discuss limitations of this approach, namely inadequate datasets, indeterminate biological correlations, ethical concerns, and logistical constraints; finally, we speculate on future avenues of research that could overcome these limitations, ultimately translating to improved clinical outcomes. © 2021 Elsevier B.V.},
	author_keywords = {Deep learning; Digital pathology; Immunohistochemistry; Machine learning; Tumor microenvironment; Tumor models},
	keywords = {Animals; Artificial Intelligence; Cell Culture Techniques; Humans; Immunohistochemistry; Models, Biological; Neoplasms; Tumor Microenvironment; Clinical research; Diagnosis; Tumors; Biological correlation; Clinical outcome; Ethical concerns; Immunopathology; In compositions; Novel diagnostics; Spatial arrangements; Tumor microenvironment; algorithm; analytic method; artificial intelligence; biological phenomena and functions concerning the entire organism; cell component; clinical feature; data analysis; disease association; ethics; genomics; histopathology; human; immunohistochemistry; immunopathology; in vitro study; multiomics; nonhuman; process development; program evaluation; proteomics; radiomics; reproducibility; Review; spatial analysis; three dimensional cell culture; tumor microenvironment; two dimensional cell culture; animal; biological model; cell culture technique; neoplasm; tumor microenvironment; Artificial intelligence},
	correspondence_address = {J. Yeong; Singapore, 61 Biopolis Drive, Proteos, 138673, Singapore; email: yeongps@imcb.a-star.edu.sg},
	publisher = {Elsevier B.V.},
	issn = {0169409X},
	coden = {ADDRE},
	pmid = {34481035},
	language = {English},
	abbrev_source_title = {Adv. Drug Deliv. Rev.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Agbese2021224,
	author = {Agbese, Mamia and Alanen, Hanna-Kaisa and Antikainen, Jani and Halme, Erika and Isomaki, Hannakaisa and Jantunen, Marianna and Kemell, Kai-Kristian and Rousi, Rebekah and Vainio-Pekka, Heidi and Vakkuri, Ville},
	title = {Governance of Ethical and Trustworthy Al Systems: Research Gaps in the ECCOLA Method},
	year = {2021},
	journal = {Proceedings of the IEEE International Conference on Requirements Engineering},
	volume = {2021-September},
	pages = {224 – 229},
	doi = {10.1109/REW53955.2021.00042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118439455&doi=10.1109%2fREW53955.2021.00042&partnerID=40&md5=2db0e5c98e63c8989a21ed22c48520f0},
	affiliations = {Faculty of Information Technology University of Jyväskylä, Jyväskylä, Finland},
	abstract = {Advances in machine learning (ML) technologies have greatly improved Artificial Intelligence (Al) systems. As a result, Al systems have become ubiquitous, with their application prevalent in virtually all sectors. However, Al systems have prompted ethical concerns, especially as their usage crosses boundaries in sensitive areas such as healthcare, transportation, and security. As a result, users are calling for better Al governance practices in ethical Al systems. Therefore, Al development methods are encouraged to foster these practices. This research analyzes the ECCOLA method for developing ethical and trustworthy Al systems to determine if it enables Al governance in development processes through ethical practices. The results demonstrate that while ECCOLA fully facilitates Al governance in corporate governance practices in all its processes, some of its practices do not fully foster data governance and information governance practices. This indicates that the method can be further improved.  © 2021 IEEE.},
	author_keywords = {Al; Al governance; ECCOLA; Ethical AI; Ethics; ML},
	keywords = {Artificial intelligence; Al; Al governance; Development method; ECCOLA; Ethical AI; Ethical concerns; Machine learning technology; Research gaps; Sensitive area; Systems research; Philosophical aspects},
	editor = {Yue T. and Mirakhorli M.},
	publisher = {IEEE Computer Society},
	issn = {1090705X},
	isbn = {978-166541898-0},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Requir. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 29th IEEE International Requirements Engineering Conference Workshops, REW 2021; Conference date: 20 September 2021 through 24 September 2021; Conference code: 173221; All Open Access, Green Open Access}
}

@ARTICLE{Hasani20221,
	author = {Hasani, Navid and Morris, Michael A. and Rhamim, Arman and Summers, Ronald M. and Jones, Elizabeth and Siegel, Eliot and Saboury, Babak},
	title = {Trustworthy Artificial Intelligence in Medical Imaging},
	year = {2022},
	journal = {PET Clinics},
	volume = {17},
	number = {1},
	pages = {1 – 12},
	doi = {10.1016/j.cpet.2021.09.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119435183&doi=10.1016%2fj.cpet.2021.09.007&partnerID=40&md5=4881fcdde163af8ebd0e97cfb0771a45},
	affiliations = {Department of Radiology and Imaging Sciences, Clinical Center, National Institutes of Health (NIH), 9000 Rockville Pike, Building 10, Room 1C455, Bethesda, 20892, MD, United States; University of Queensland Faculty of Medicine, Ochsner Clinical School, New Orleans, 70121, LA, United States; Department of Computer Science and Electrical Engineering, University of Maryland, Baltimore Country, Baltimore, MD, United States; Department of Radiology, BC Cancer Research Institute, University of British Columbia, 675 West 10th Avenue, Vancouver, V5Z 1L3, BC, Canada; Department of Physics, BC cancer Research Institute, University of British Columbia, Vancouver, BC, Canada; Department of Radiology and Nuclear Medicine, University of Maryland Medical Center, 655 W. Baltimore Street, Baltimore, 21201, MD, United States; Department of Radiology, Hospital of the University of Pennsylvania, Philadelphia, PA, United States},
	author_keywords = {Ethics of AI; Machine learning; Trustworthiness; Trustworthy artificial intelligence},
	keywords = {Artificial Intelligence; Diagnostic Imaging; Ecosystem; Humans; artificial intelligence; awareness; cultural diversity; cultural factor; data analysis; data privacy; decision making; diagnostic imaging; governmental organization; human; human relation; implementation science; legal service; machine learning; measurement accuracy; medical care; medical information; medication therapy management; nondiscrimination policy; patient attitude; patient care; patient harm; physician; prejudice; process technology; psychological aspect; reliability; Review; safety; social aspect; social behavior; social responsibility; social well-being; stakeholder engagement; trust; workflow; World Health Organization; diagnostic imaging; ecosystem},
	correspondence_address = {B. Saboury; Department of Radiology and Nuclear Medicine, University of Maryland Medical Center, 655 W. Baltimore Street, Baltimore, MD 21201, USA (E.S);, Department of Radiology and Imaging Sciences, Clinical Center, National Institutes of Health, Bethesda, 9000 Rockville Pike, Building 10, Room 1C455, 20892, United States; email: babak.saboury@nih.gov},
	publisher = {W.B. Saunders},
	issn = {15568598},
	pmid = {34809860},
	language = {English},
	abbrev_source_title = {PET Clin.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access}
}

@ARTICLE{Amodeo2021,
	author = {Amodeo, Ilaria and De Nunzio, Giorgio and Raffaeli, Genny and Borzani, Irene and Griggio, Alice and Conte, Luana and Macchini, Francesco and Condò, Valentina and Persico, Nicola and Fabietti, Isabella and Ghirardello, Stefano and Pierro, Maria and Tafuri, Benedetta and Como, Giuseppe and Cascio, Donato and Colnaghi, Mariarosa and Mosca, Fabio and Cavallaro, Giacomo},
	title = {A maChine and deep Learning Approach to predict pulmoNary hyperteNsIon in newbornS with congenital diaphragmatic Hernia (CLANNISH): Protocol for a retrospective study},
	year = {2021},
	journal = {PLoS ONE},
	volume = {16},
	number = {11 November},
	doi = {10.1371/journal.pone.0259724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118875450&doi=10.1371%2fjournal.pone.0259724&partnerID=40&md5=b029954e6985d2a0f739ab3338769c0a},
	affiliations = {NICU, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Milan, Italy; Department of Mathematics and Physics "E. De Giorgi", Laboratory of Biomedical Physics and Environment, Università del Salento, Lecce, Italy; Advanced Data Analysis in Medicine (ADAM), Laboratory of Interdisciplinary Research Applied to Medicine (DReAM), Università del Salento, Lecce, Italy; Azienda Sanitaria Locale (ASL), Lecce, Italy; Department of Clinical Sciences and Community Health, Università degli Studi di Milano, Milan, Italy; Pediatric Radiology Unit, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Milan, Italy; Monza and Brianza Mother and Child Foundation, San Gerardo Hospital, Università degli Studi di Milano-Bicocca, Monza, Italy; Department of Pediatric Surgery, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Milan, Italy; Department of Obstetrics and Gynecology, Fondazione IRCCS Ca' Granda, Ospedale Maggiore Policlinico, Milan, Italy; NICU, Bufalini Hospital, Azienda Unità Sanitaria Locale della Romagna, Cesena, Italy; Department of Physics and Chemistry, Università degli Studi di Palermo, Palermo, Italy},
	abstract = {Introduction Outcome predictions of patients with congenital diaphragmatic hernia (CDH) still have some limitations in the prenatal estimate of postnatal pulmonary hypertension (PH). We propose applying Machine Learning (ML), and Deep Learning (DL) approaches to fetuses and newborns with CDH to develop forecasting models in prenatal epoch, based on the integrated analysis of clinical data, to provide neonatal PH as the first outcome and, possibly: Favorable response to fetal endoscopic tracheal occlusion (FETO), need for Extracorporeal Membrane Oxygenation (ECMO), survival to ECMO, and death. Moreover, we plan to produce a (semi)automatic fetus lung segmentation system in Magnetic Resonance Imaging (MRI), which will be useful during project implementation but will also be an important tool itself to standardize lung volume measures for CDH fetuses. Methods and analytics Patients with isolated CDH from singleton pregnancies will be enrolled, whose prenatal checks were performed at the Fetal Surgery Unit of the Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico (Milan, Italy) from the 30th week of gestation. A retrospective data collection of clinical and radiological variables from newborns' and mothers' clinical records will be performed for eligible patients born between 01/01/2012 and 31/12/2020. The native sequences from fetal magnetic resonance imaging (MRI) will be collected. Data from different sources will be integrated and analyzed using ML and DL, and forecasting algorithms will be developed for each outcome. Methods of data augmentation and dimensionality reduction (feature selection and extraction) will be employed to increase sample size and avoid overfitting. A software system for automatic fetal lung volume segmentation in MRI based on the DL 3D U-NET approach will also be developed. Ethics and dissemination This retrospective study received approval from the local ethics committee (Milan Area 2, Italy). The development of predictive models in CDH outcomes will provide a key contribution in disease prediction, early targeted interventions, and personalized management, with an overall improvement in care quality, resource allocation, healthcare, and family savings. Our findings will be validated in a future prospective multicenter cohort study. © 2021 Amodeo et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Cohort Studies; Female; Hernias, Diaphragmatic, Congenital; Humans; Hypertension, Pulmonary; Infant, Newborn; Pregnancy; Retrospective Studies; clinical protocol; congenital diaphragm hernia; deep learning; extracorporeal oxygenation; fetal endoscopic tracheal occlusion; fetus; fetus lung; forecasting; human; image segmentation; lung; machine learning; newborn; newborn death; nuclear magnetic resonance imaging; outcome assessment; prediction; prediction and forecasting; pulmonary hypertension; retrospective study; Review; surgical technique; survival analysis; cohort analysis; congenital diaphragm hernia; female; pregnancy; pulmonary hypertension},
	correspondence_address = {G. Cavallaro; NICU, Fondazione IRCCS Ca' Granda Ospedale Maggiore Policlinico, Milan, Italy; email: giacomo.cavallaro@policlinico.mi.it},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {34752491},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Pietsch20221,
	author = {Pietsch, Wolfgang},
	title = {Introduction},
	year = {2022},
	journal = {Philosophical Studies Series},
	volume = {148},
	pages = {1 – 10},
	doi = {10.1007/978-3-030-86442-2_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121335728&doi=10.1007%2f978-3-030-86442-2_1&partnerID=40&md5=327b400f259ac909e7ed45ce82d4d245},
	affiliations = {Munich Center for Technology in Society, Technical University of Munich, München, Germany},
	abstract = {In this Chapter, I first introduce some basic terminology and then proceed to formulate ten theses about data science. First, data science, narrowly understood as the application of machine learning methods to large data sets, leads to the increasing predictability of complex phenomena, especially to more reliable short-term predictions. Second, the nature of modeling changes from heavily theory-laden approaches with little data to simple models using a lot of data. Third, conventional statistics is insufficient to deal with the data deluge, novel inductive methodology is necessary in order to account for data scientific practice. Fourth, new types of formal representation are required for modeling irreducibly complex phenomena. Fifth, there are strong analogies between exploratory experimentation and data science. Sixth, causality is the central concept for understanding why data-intensive approaches can be scientifically relevant, in particular why they can establish reliable predictions or allow for effective interventions. Seventh, the conceptual core of causality in data science consists in difference-making, i.e. that a change in circumstances produces a change in the examined phenomena. Eighth, data science provides explanations by specifying causes or at least proxies of causes, but not by referring to unifying principles. Ninth, the increasing automation of science fundamentally changes the role of scientific experts. Tenth, the ethics and epistemology of data science cannot be separated. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Big data; Causality; Data science; Difference making; Exploratory experimentation; Inductivism; Machine learning},
	correspondence_address = {W. Pietsch; Munich Center for Technology in Society, Technical University of Munich, München, Germany; email: wpietsch@gmx.de},
	publisher = {Springer Nature},
	issn = {09218599},
	language = {English},
	abbrev_source_title = {Philos. Stud. Ser.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wiljer2021,
	author = {Wiljer, David and Salhia, Mohammad and Dolatabadi, Elham and Dhalla, Azra and Gillan, Caitlin and Al-Mouaswas, Dalia and Jackson, Ethan and Waldorf, Jacqueline and Mattson, Jane and Clare, Megan and Lalani, Nadim and Charow, Rebecca and Balakumar, Sarmini and Younus, Sarah and Jeyakumar, Tharshini and Peteanu, Wanda and Tavares, Walter},
	title = {Accelerating the appropriate adoption of artificial intelligence in health care: Protocol for a multistepped approach},
	year = {2021},
	journal = {JMIR Research Protocols},
	volume = {10},
	number = {10},
	doi = {10.2196/30940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117111856&doi=10.2196%2f30940&partnerID=40&md5=81d04d0d58af9a2b83dcabf11d41df6c},
	affiliations = {University Health Network, Toronto, ON, Canada; Institute of Health Policy Management and Evaluation, Dalla Lana School of Public Health, University of Toronto, Toronto, ON, Canada; Faculty of Medicine, University of Toronto, Toronto, ON, Canada; Centre for Addictions and Mental Health, CAMH Education, Toronto, ON, Canada; Michener Institute of Education, University Health Network, Toronto, ON, Canada; Vector Institute, Toronto, ON, Canada; Wilson Centre, Toronto, ON, Canada},
	abstract = {Background: Significant investments and advances in health care technologies and practices have created a need for digital and data-literate health care providers. Artificial intelligence (AI) algorithms transform the analysis, diagnosis, and treatment of medical conditions. Complex and massive data sets are informing significant health care decisions and clinical practices. The ability to read, manage, and interpret large data sets to provide data-driven care and to protect patient privacy are increasingly critical skills for today's health care providers. Objective: The aim of this study is to accelerate the appropriate adoption of data-driven and AI-enhanced care by focusing on the mindsets, skillsets, and toolsets of point-of-care health providers and their leaders in the health system. Methods: To accelerate the adoption of AI and the need for organizational change at a national level, our multistepped approach includes creating awareness and capacity building, learning through innovation and adoption, developing appropriate and strategic partnerships, and building effective knowledge exchange initiatives. Education interventions designed to adapt knowledge to the local context and address any challenges to knowledge use include engagement activities to increase awareness, educational curricula for health care providers and leaders, and the development of a coaching and practice-based innovation hub. Framed by the Knowledge-to-Action framework, we are currently in the knowledge creation stage to inform the curricula for each deliverable. An environmental scan and scoping review were conducted to understand the current state of AI education programs as reported in the academic literature. Results: The environmental scan identified 24 AI-accredited programs specific to health providers, of which 11 were from the United States, 6 from Canada, 4 from the United Kingdom, and 3 from Asian countries. The most common curriculum topics across the environmental scan and scoping review included AI fundamentals, applications of AI, applied machine learning in health care, ethics, data science, and challenges to and opportunities for using AI. Conclusions: Technologies are advancing more rapidly than organizations, and professionals can adopt and adapt to them. To help shape AI practices, health care providers must have the skills and abilities to initiate change and shape the future of their discipline and practices for advancing high-quality care within the digital ecosystem. © 2021 Fundacion Instituto de Historia Social. All rights reserved.},
	author_keywords = {Adoption; Artificial intelligence; Education; Health care providers; Learning; MHealth; Patient care},
	correspondence_address = {D. Wiljer; University Health Network, Toronto, 190 Elizabeth Street, M5G 2C4, Canada; email: David.wiljer@uhn.ca},
	publisher = {JMIR Publications Inc.},
	issn = {19290748},
	language = {English},
	abbrev_source_title = {JMIR Res. Prot.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Langhammer2021,
	author = {Langhammer, Till and Hilbert, Kevin and Praxl, Berit and Kirschbaum, Clemens and Ertle, Andrea and Asbrand, Julia and Lueken, Ulrike},
	title = {Mental health trajectories of individuals and families following the COVID-19 pandemic: Study protocol of a longitudinal investigation and prevention program},
	year = {2021},
	journal = {Mental Health and Prevention},
	volume = {24},
	doi = {10.1016/j.mhp.2021.200221},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116925330&doi=10.1016%2fj.mhp.2021.200221&partnerID=40&md5=d2e7e1b02f995c92d917f894b2b3ccb1},
	affiliations = {Department of Psychology, Faculty of Life Sciences, Humboldt-Universität zu Berlin, Unter den Linden 6, Berlin, 10099, Germany; Department of Psychology, Technische Universität Dresden, Dresden, Germany},
	abstract = {Introduction: Many adults, adolescents and children are suffering from persistent stress symptoms in the face of the COVID-19 pandemic. This study aims to characterize long-term trajectories of mental health and to reduce the transition to manifest mental disorders by means of a stepped care program for indicated prevention. Methods and analysis: Using a prospective-longitudinal design, we will assess the mental strain of the pandemic using the Patient Health Questionnaire, Strength and Difficulties Questionnaire and Spence Child Anxiety Scale. Hair samples will be collected to assess cortisol as a biological stress marker of the previous months. Additionally, we will implement a stepped-care program with online- and face-to-face-interventions for adults, adolescents, and children. After that we will assess long-term trajectories of mental health at 6, 12, and 24 months follow-up. The primary outcome will be psychological distress (depression, anxiety and somatoform symptoms). Data will be analyzed with general linear model and machine learning. This study will contribute to the understanding of the impact of the COVID-19 pandemic on mental health. The evaluation of the stepped-care program and longitudinal investigation will inform clinicians and mental health stakeholders on populations at risk, disease trajectories and the sufficiency of indicated prevention to ameliorate the mental strain of the pandemic. Ethics and dissemination: The study is performed according to the Declaration of Helsinki and was approved by the Ethics Committee of the Department of Psychology at the Humboldt Universität zu Berlin (no. 2020-35). Trial registration number: DRKS00023220. © 2021 Elsevier GmbH},
	author_keywords = {Cortisol; COVID-19; Family transmission; Prediction; Stepped-care},
	correspondence_address = {T. Langhammer; Department of Psychology, Faculty of Life Sciences, Humboldt-Universität zu Berlin, Berlin, Unter den Linden 6, 10099, Germany; email: Till.Langhammer@hu-berlin.de},
	publisher = {Elsevier GmbH},
	issn = {22126570},
	language = {English},
	abbrev_source_title = {Mental Health Prev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Mazaheri2021554,
	author = {Mazaheri, Sina and Loya, Mohammed F. and Newsome, Janice and Lungren, Mathew and Gichoya, Judy Wawira},
	title = {Challenges of Implementing Artificial Intelligence in Interventional Radiology},
	year = {2021},
	journal = {Seminars in Interventional Radiology},
	volume = {38},
	number = {5},
	pages = {554 – 559},
	doi = {10.1055/s-0041-1736659},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120321340&doi=10.1055%2fs-0041-1736659&partnerID=40&md5=d8aa2df6145b6148d793ea3c961fe91d},
	affiliations = {Department of Radiology and Imaging Sciences, Emory University, School of Medicine, Atlanta, GA, United States; Department of Interventional Radiology, Emory University, School of Medicine, Atlanta, GA, United States; LPCH Pediatric Interventional Radiology, Stanford University, Stanford, CA, United States},
	abstract = {Artificial intelligence (AI) and deep learning (DL) remains a hot topic in medicine. DL is a subcategory of machine learning that takes advantage of multiple layers of interconnected neurons capable of analyzing immense amounts of data and learning patterns and offering predictions. It appears to be poised to fundamentally transform and help advance the field of diagnostic radiology, as heralded by numerous published use cases and number of FDA-cleared products. On the other hand, while multiple publications have touched upon many great hypothetical use cases of AI in interventional radiology (IR), the actual implementation of AI in IR clinical practice has been slow compared with the diagnostic world. In this article, we set out to examine a few challenges contributing to this scarcity of AI applications in IR, including inherent specialty challenges, regulatory hurdles, intellectual property, raising capital, and ethics. Owing to the complexities involved in implementing AI in IR, it is likely that IR will be one of the late beneficiaries of AI. In the meantime, it would be worthwhile to continuously engage in defining clinically relevant use cases and focus our limited resources on those that would benefit our patients the most. © 2021 Georg Thieme Verlag. All rights reserved.},
	author_keywords = {artificial intelligence; challenges; interventional radiology; machine learning; use cases},
	keywords = {adult; article; artificial intelligence; clinical practice; controlled study; ethics; human; interventional radiology; machine learning; patent},
	correspondence_address = {S. Mazaheri; Department of Radiology and Imaging Sciences, Emory University, School of Medicine, Atlanta, United States; email: sina.mazaheri@emory.edu},
	publisher = {Thieme Medical Publishers, Inc.},
	issn = {07399529},
	coden = {SIRAE},
	language = {English},
	abbrev_source_title = {Semin. Intervent. Radiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Li2021,
	author = {Li, Xiaoran and Xu, Chen and Yu, Yang and Guo, Yan and Sun, Hongzan},
	title = {Prediction of lymphovascular space invasion using a combination of tenascin-C, cox-2, and PET/CT radiomics in patients with early-stage cervical squamous cell carcinoma},
	year = {2021},
	journal = {BMC Cancer},
	volume = {21},
	number = {1},
	doi = {10.1186/s12885-021-08596-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111517484&doi=10.1186%2fs12885-021-08596-9&partnerID=40&md5=98ded4bc6b56ec691d364866705ee345},
	affiliations = {Department of Radiology, Shengjing Hospital of China Medical University, Shenyang, Liaoning, China; GE Healthcare, Shenyang, Liaoning, China},
	abstract = {Background: Lymphovascular space invasion is an independent prognostic factor in early-stage cervical cancer. However, there is a lack of non-invasive methods to detect lymphovascular space invasion. Some researchers found that Tenascin-C and Cyclooxygenase-2 was correlated with lymphovascular space invasion. Radiomics has been studied as an emerging tool for distinguishing tumor pathology stage, evaluating treatment response, and predicting prognosis. This study aimed to establish a machine learning model that combines radiomics based on PET imaging with tenascin-C (TNC) and cyclooxygenase-2 (COX-2) for predicting lymphovascular space invasion (LVSI) in patients with early-stage cervical cancer. Methods: One hundred and twelve patients with early-stage cervical squamous cell carcinoma who underwent PET/CT examination were retrospectively analyzed. Four hundred one radiomics features based on PET/CT images were extracted and integrated into radiomics score (Rad-score). Immunohistochemical analysis was performed to evaluate TNC and COX-2 expression. Mann-Whitney U test was used to distinguish differences in the Rad-score, TNC, and COX-2 between LVSI and non-LVSI groups. The correlations of characteristics were tested by Spearman analysis. Machine learning models including radiomics model, protein model and combined model were established by logistic regression algorithm and evaluated by ROC curve. Pairwise comparisons of ROC curves were tested by DeLong test. Results: The Rad-score of patients with LVSI was significantly higher than those without. A significant correlation was shown between LVSI and Rad-score (r = 0.631, p < 0.001). TNC was correlated to both the Rad-score (r = 0.244, p = 0.024) and COX-2 (r = 0.227, p = 0.036). The radiomics model had the best predictive performance among all models in training and external dataset (AUCs: 0.914, 0.806, respectively, p < 0.001). However, in testing dataset, the combined model had better efficiency for predicting LVSI than other models (AUCs: 0.801 vs. 0.756 and 0.801 vs. 0.631, respectively). Conclusion: The machine learning model of the combination of PET radiomics with COX-2 and TNC provides a new tool for detecting LVSI in patients with early-stage cervical cancer. In the future, multicentric studies on larger sample of patients will be used to test the model. Trial registration: This is a retrospective study and there is no experimental intervention on human participants. The Ethics Committee has confirmed that retrospectively registered is not required. © 2021, The Author(s).},
	author_keywords = {Cervical squamous cell carcinoma; Lymphovascular space invasion; Machine learning; PET/CT; Radiomics},
	keywords = {Adult; Aged; Biomarkers; Cyclooxygenase 2; Female; Fluorodeoxyglucose F18; Humans; Image Processing, Computer-Assisted; Immunohistochemistry; Lymphatic Metastasis; Machine Learning; Male; Middle Aged; Neoplasm Staging; Positron Emission Tomography Computed Tomography; Reproducibility of Results; Retrospective Studies; ROC Curve; Tenascin; Uterine Cervical Neoplasms; cyclooxygenase 2; fluorodeoxyglucose f 18; tenascin; biological marker; cyclooxygenase 2; tenascin; adult; aged; Article; cancer staging; cohort analysis; computer model; controlled study; female; human; human tissue; immunohistochemistry; logistic regression analysis; lymph vessel metastasis; lymphovascular space invasion; machine learning; major clinical study; medical examination; positron emission tomography-computed tomography; prediction; protein expression; protein model; radiomics; radiomics model; retrospective study; statistical model; uterine cervix cancer; cancer staging; image processing; lymph node metastasis; machine learning; male; metabolism; middle aged; pathology; positron emission tomography-computed tomography; procedures; receiver operating characteristic; reproducibility; uterine cervix tumor},
	correspondence_address = {H. Sun; Department of Radiology, Shengjing Hospital of China Medical University, Shenyang, China; email: sunhongzan@126.com},
	publisher = {BioMed Central Ltd},
	issn = {14712407},
	coden = {BCMAC},
	pmid = {34320931},
	language = {English},
	abbrev_source_title = {BMC Cancer},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Nguyen2022,
	author = {Nguyen, Binh and Torres, Andrei and Sim, Walter and Kenny, Deborah and Campbell, Douglas M. and Beavers, Lindsay and Lou, Wendy and Kapralos, Bill and Peter, Elizabeth and Dubrowski, Adam and Krishnan, Sridhar and Bhat, Venkat},
	title = {Digital Interventions to Reduce Distress Among Health Care Providers at the Frontline: Protocol for a Feasibility Trial},
	year = {2022},
	journal = {JMIR Research Protocols},
	volume = {11},
	number = {2},
	doi = {10.2196/32240},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124988601&doi=10.2196%2f32240&partnerID=40&md5=9de68455a2bd3a96abd675c600985a8e},
	affiliations = {Department of Electrical, Computer, and Biomedical Engineering, Ryerson University, Toronto, ON, Canada; maxSIMhealth Group, Ontario Tech University, Oshawa, ON, Canada; Interventional Psychiatry Program, St Michael’s Hospital, Unity Health Toronto, Toronto, ON, Canada; Department of Nursing, University of Colorado, Colorado Springs, CO, United States; Neonatal Intensive Care Unit, St Michael's Hospital, Unity Health Toronto, Toronto, ON, Canada; Allan Waters Family Simulation Program, St Michael's Hospital, Unity Health Toronto, Toronto, ON, Canada; Li Ka Shing Knowledge Institute, Unity Health Toronto, Toronto, ON, Canada; Department of Pediatrics, Faculty of Medicine, University of Toronto, Toronto, ON, Canada; Department of Physical Therapy, Temerty Faculty of Medicine, University of Toronto, Toronto, ON, Canada; Dalla Lana School of Public Health, University of Toronto, Toronto, ON, Canada; Lawrence S Bloomberg Faculty of Nursing, University of Toronto, Toronto, ON, Canada; Department of Psychiatry, University of Toronto, Toronto, ON, Canada},
	abstract = {Background: Stress, anxiety, distress, and depression are high among health care workers during the COVID-19 pandemic, and they have reported acting in ways that are contrary to their moral values and professional commitments that degrade their integrity. This creates moral distress and injury due to constraints they have encountered, such as limited resources. Objective: The purpose of this study is to develop and show the feasibility of digital platforms (a virtual reality and a mobile platform) to understand the causes and ultimately reduce the moral distress of health care providers during the COVID-19 pandemic. Methods: This will be a prospective, single cohort, pre- and posttest study examining the effect of a brief informative video describing moral distress on perceptual, psychological, and physiological indicators of stress and decision-making during a scenario known to potentially elicit moral distress. To accomplish this, we have developed a virtual reality simulation that will be used before and after the digital intervention for monitoring short-term impacts. The simulation involves an intensive care unit setting during the COVID-19 pandemic, and participants will be placed in morally challenging situations. The participants will be engaged in an educational intervention at the individual, team, and organizational levels. During each test, data will be collected for (1) physiological measures of stress and after each test, data will be collected regarding (2) thoughts, feelings and behaviors during a morally challenging situation, and (3) perceptual estimates of psychological stress. In addition, participants will continue to be monitored for moral distress and other psychological stresses for 8 weeks through our Digital intervention/intelligence Group mobile platform. Finally, a comparison will be conducted using machine learning and biostatistical techniques to analyze the short- and long-term impacts of the virtual reality intervention. Results: The study was funded in November 2020 and received research ethics board approval in March 2021. The study is ongoing. Conclusions: This project is a proof-of-concept integration to demonstrate viability over 6 months and guide future studies to develop these state-of-the-art technologies to help frontline health care workers work in complex moral contexts. In addition, the project will develop innovations that can be used for future pandemics and in other contexts prone to producing moral distress and injury. This project aims to demonstrate the feasibility of using digital platforms to understand the continuum of moral distress that can lead to moral injury. Demonstration of feasibility will lead to future studies to examine the efficacy of digital platforms to reduce moral distress. ©Binh Nguyen, Andrei Torres, Walter Sim, Deborah Kenny, Douglas M Campbell, Lindsay Beavers, Wendy Lou, Bill Kapralos, Elizabeth Peter, Adam Dubrowski, Sridhar Krishnan, Venkat Bhat.},
	author_keywords = {COVID-19; Mobile app; Moral distress; Moral injury; Simulation; Virtual reality},
	correspondence_address = {V. Bhat; Interventional Psychiatry Program, St Michael’s Hospital, Unity Health Toronto, Toronto, 193 Yonge Street, Suite 6-013, M5B 1M8, Canada; email: venkat.bhat@utoronto.ca},
	publisher = {JMIR Publications Inc.},
	issn = {19290748},
	language = {English},
	abbrev_source_title = {JMIR Res. Prot.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Lee2021S62,
	author = {Lee, Juehea and Wu, Annie Siyu and Li, David and Kulasegaram, Kulamakan (mahan)},
	title = {Artificial Intelligence in Undergraduate Medical Education: A Scoping Review},
	year = {2021},
	journal = {Academic Medicine},
	volume = {96},
	number = {11},
	pages = {S62 – S70},
	doi = {10.1097/ACM.0000000000004291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121061706&doi=10.1097%2fACM.0000000000004291&partnerID=40&md5=e9633c7ede68c42e615b224053de443b},
	affiliations = {University of Toronto, Temerty Faculty of Medicine, Toronto, ON, Canada; University of Ottawa, Faculty of Medicine, Ottawa, ON, Canada; Department of Family and Community Medicine, University of Toronto, The Wilson Centre, University Health Network, Toronto, ON, Canada},
	abstract = {Purpose Artificial intelligence (AI) is a rapidly growing phenomenon poised to instigate large-scale changes in medicine. However, medical education has not kept pace with the rapid advancements of AI. Despite several calls to action, the adoption of teaching on AI in undergraduate medical education (UME) has been limited. This scoping review aims to identify gaps and key themes in the peer-reviewed literature on AI training in UME. Method The scoping review was informed by Arksey and O'Malley's methodology. Seven electronic databases including MEDLINE and EMBASE were searched for articles discussing the inclusion of AI in UME between January 2000 and July 2020. A total of 4,299 articles were independently screened by 3 co-investigators and 22 full-text articles were included. Data were extracted using a standardized checklist. Themes were identified using iterative thematic analysis. Results The literature addressed: (1) a need for an AI curriculum in UME, (2) recommendations for AI curricular content including machine learning literacy and AI ethics, (3) suggestions for curriculum delivery, (4) an emphasis on cultivating "uniquely human skills" such as empathy in response to AI-driven changes, and (5) challenges with introducing an AI curriculum in UME. However, there was considerable heterogeneity and poor consensus across studies regarding AI curricular content and delivery. Conclusions Despite the large volume of literature, there is little consensus on what and how to teach AI in UME. Further research is needed to address these discrepancies and create a standardized framework of competencies that can facilitate greater adoption and implementation of a standardized AI curriculum in UME. © 2021 Lippincott Williams and Wilkins. All rights reserved.},
	keywords = {Artificial Intelligence; Education, Medical, Undergraduate; Humans; artificial intelligence; human; medical education},
	correspondence_address = {J. Lee; University of Toronto, Temerty Faculty of Medicine, Toronto, Canada; email: juehea.lee@mail.utoronto.ca},
	publisher = {Wolters Kluwer Health},
	issn = {10402446},
	coden = {ACMEE},
	pmid = {34348374},
	language = {English},
	abbrev_source_title = {Acad. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Bronze Open Access}
}

@ARTICLE{Kazim2021,
	author = {Kazim, Emre and Koshiyama, Adriano Soares},
	title = {A high-level overview of AI ethics},
	year = {2021},
	journal = {Patterns},
	volume = {2},
	number = {9},
	doi = {10.1016/j.patter.2021.100314},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115758605&doi=10.1016%2fj.patter.2021.100314&partnerID=40&md5=0755c31afd0ba37b456d5b766f935978},
	affiliations = {Computer Science, University College London, Gower St, London, WC1E 6EA, United Kingdom},
	abstract = {Artificial intelligence (AI) ethics is a field that has emerged as a response to the growing concern regarding the impact of AI. It can be read as a nascent field and as a subset of the wider field of digital ethics, which addresses concerns raised by the development and deployment of new digital technologies, such as AI, big data analytics, and blockchain technologies. The principle aim of this article is to provide a high-level conceptual discussion of the field by way of introducing basic concepts and sketching approaches and central themes in AI ethics. The first part introduces concepts by noting what is being referred to by “AI” and “ethics”, etc.; the second part explores some predecessors to AI ethics, namely engineering ethics, philosophy of technology, and science and technology studies; the third part discusses three current approaches to AI ethics namely, principles, processes, and ethical consciousness; and finally, the fourth part discusses central themes in translating ethics in to engineering practice. We conclude by summarizing and noting the inherent interdisciplinary future directions and debates in AI ethics. © 2021 The Authors},
	author_keywords = {AI ethics; artificial intelligence; governance; humane-AI; law; machine learning; philosophy; regulation; Trustworthy AI},
	keywords = {Data Analytics; Engineering education; Machine learning; Artificial intelligence ethic; Digital ethics; Digital technologies; Governance; Humane-artificial intelligence; Law; Nascent field; Regulation; Trustworthy artificial intelligence; Wide-field; Ethical technology},
	correspondence_address = {E. Kazim; Computer Science, University College London, London, Gower St, WC1E 6EA, United Kingdom; email: e.kazim@ucl.ac.uk; A.S. Koshiyama; Computer Science, University College London, London, Gower St, WC1E 6EA, United Kingdom; email: adriano.koshiyama.15@ucl.ac.uk},
	publisher = {Cell Press},
	issn = {26663899},
	language = {English},
	abbrev_source_title = {Patterns},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kushki20215067,
	author = {Kushki, Azadeh and Cardy, Robyn E and Panahandeh, Sina and Malihi, Mahan and Hammill, Christopher and Brian, Jessica and Iaboni, Alana and Taylor, Margot J and Schachar, Russell and Crosbie, Jennifer and Arnold, Paul and Kelley, Elizabeth and Ayub, Muhammad and Nicolson, Robert and Georgiades, Stelios and Lerch, Jason P and Anagnostou, Evdokia},
	title = {Cross-Diagnosis Structural Correlates of Autistic-Like Social Communication Differences},
	year = {2021},
	journal = {Cerebral Cortex},
	volume = {31},
	number = {11},
	pages = {5067 – 5076},
	doi = {10.1093/cercor/bhab142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113949312&doi=10.1093%2fcercor%2fbhab142&partnerID=40&md5=8fea728199be0f87e94d6547220e23fa},
	affiliations = {Autism Research Centre, Bloorview Research Institute, Holland Bloorview Kids Rehabilitation Hospital, Toronto, M4G 1R8, ON, Canada; University of Toronto, Institute of Biomedical Engineering, Toronto, M5S 3G9, ON, Canada; Mouse Imaging Centre, The Hospital for Sick Children, Toronto, M5T 3H7, ON, Canada; Department of Paediatrics, University of Toronto, Toronto, M5G 1X8, ON, Canada; Diagnostic Imaging, The Hospital for Sick Children, Toronto, M5G 1X8, ON, Canada; Department of Medical Imaging, University of Toronto, Toronto, M5T 1W7, Canada; Department of Psychiatry, University of Toronto, Toronto, M5T 1R8, ON, Canada; Department of Psychiatry, The Hospital for Sick Children, Toronto, M5G 1X8, ON, Canada; Hotchkiss Brain Institute, Departments of Psychiatry and Medical Genetics, University of Calgary, Calgary, T2N 4N1, AB, Canada; Department of Psychology, Centre for Neuroscience Studies, Queen's University, Kingston, K7L 3N6, ON, Canada; Department of Psychiatry, Queen's University, Kingston, K7L 7X3, ON, Canada; Department of Psychiatry, Western University, London, M6c 0A7, ON, Canada; Department of Psychiatry and Behavioural Neurosciences, McMaster University, Hamilton, L8S 4L8, ON, Canada; Program in Neuroscience and Mental Health, The Hospital for Sick Children, Department of Medical Biophysics, University of Toronto, Toronto, M5G 0A4, ON, Canada; Wellcome Centre for Integrative Neuroimaging, FMRIB, Nuffield Department of Clinical Neurosciences, University of Oxford, Oxford, OX3 9DU, United Kingdom},
	abstract = {Social communication differences are seen in autism spectrum disorder (ASD), attention-deficit/hyperactivity disorder (ADHD), and obsessive-compulsive disorder (OCD), but the brain mechanisms contributing to these differences remain largely unknown. To address this gap, we used a data-driven and diagnosis-agnostic approach to discover brain correlates of social communication differences in ASD, ADHD, and OCD, and subgroups of individuals who share similar patterns of brain-behavior associations. A machine learning pipeline (regression clustering) was used to discover the pattern of association between structural brain measures (volume, surface area, and cortical thickness) and social communication abilities. Participants (n = 416) included children with a diagnosis of ASD (n = 192, age = 12.0[5.6], 19% female), ADHD (n = 109, age = 11.1[4.1], 18% female), or OCD (n = 50, age = 12.3[4.2], 42% female), and typically developing controls (n = 65, age = 11.6[7.1], 48% female). The analyses revealed (1) associations with social communication abilities in distributed cortical and subcortical networks implicated in social behaviors, language, attention, memory, and executive functions, and (2) three data-driven, diagnosis-agnostic subgroups based on the patterns of association in the above networks. Our results suggest that different brain networks may contribute to social communication differences in subgroups that are not diagnosis-specific.  © 2021 The Author(s) 2021. Published by Oxford University Press.},
	author_keywords = {attention-deficit/hyperactivity disorder; autism spectrum disorder; obsessive-compulsive disorder},
	keywords = {Attention Deficit Disorder with Hyperactivity; Autism Spectrum Disorder; Autistic Disorder; Child; Female; Humans; Language; Male; Obsessive-Compulsive Disorder; adolescent; adult; Article; attention deficit disorder; autism; Autism Diagnostic Interview Revised; Autism Diagnostic Observation Schedule; child; Child Behavior Checklist; controlled study; executive function; expectation-maximization algorithm; female; genetic variability; hierarchical clustering; human; institutional ethics; interpersonal communication; machine learning; major clinical study; male; nerve cell network; nuclear magnetic resonance imaging; obsessive compulsive disorder; pipeline; Schedule for Affective Disorders and Schizophrenia; social behavior; social cognition; social interaction; superior temporal gyrus; Yale Brown Obsessive Compulsive Scale; attention deficit hyperactivity disorder; autism; complication; diagnostic imaging; language; obsessive compulsive disorder},
	correspondence_address = {A. Kushki; Autism Research Centre, Bloorview Research Institute, Holland Bloorview Kids Rehabilitation Hospital, Toronto, 150 Kilgour Road, M4G 1R8, Canada; email: akushki@hollandbloorview.ca},
	publisher = {Oxford University Press},
	issn = {10473211},
	coden = {CECOE},
	pmid = {34080611},
	language = {English},
	abbrev_source_title = {Cereb. Cortex},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Cainzos-Achirica202254,
	author = {Cainzos-Achirica, Miguel and Anugula, Dixitha and Mszar, Reed and Grandhi, Gowtham and Patel, Kershaw V. and Bittencourt, Marcio S. and Blankstein, Ron and Blaha, Michael J. and Blumenthal, Roger S. and Ray, Kausik K. and Bhatt, Deepak L. and Nasir, Khurram},
	title = {Rationale and pathways forward in the implementation of coronary artery calcium-based enrichment of randomized trials},
	year = {2022},
	journal = {American Heart Journal},
	volume = {243},
	pages = {54 – 65},
	doi = {10.1016/j.ahj.2021.09.006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122487953&doi=10.1016%2fj.ahj.2021.09.006&partnerID=40&md5=60fc2a52b22cf7b6fb81fe249ea7516e},
	affiliations = {Division of Cardiovascular Prevention and Wellness, Department of Cardiology, Houston Methodist DeBakey Heart & Vascular Center, Houston, TX; Center for Outcomes Research, Houston Methodist, Houston, TX; Department of Cardiology, Creighton University, Omaha, NE; Center for Outcomes Research and Evaluation, Yale New Haven Health, New Haven, CT; Department of Medicine, MedStar Union Memorial Hospital, Baltimore, MD; Center for Clinical and Epidemiological Research, University Hospital, University of Sao Paulo, Sao Paulo, Brazil; Brigham and Women's Hospital Heart and Vascular Center, Harvard Medical School, Boston, MA; Ciccarone Center for the Prevention of Cardiovascular Disease, Johns Hopkins University School of Medicine, Baltimore, MD; Welch Center for Prevention, Epidemiology and Clinical Research, Johns Hopkins University, Baltimore, MD; Imperial Centre for Cardiovascular Disease Prevention, Department of Primary Care and Public Health, Imperial College London, London, United Kingdom},
	abstract = {The Food and Drug Administration recommends prognostic enrichment of randomized controlled trials (RCTs), aimed at restricting the study population to participants most likely to have events and therefore derive benefit from a given intervention. The coronary artery calcium (CAC) score is powerful discriminator of cardiovascular risk, and in this review we discuss how CAC may be used to augment widely used prognostic enrichment paradigms of RCTs of add-on therapies in primary prevention. We describe recent studies in this space, with special attention to the ability of CAC to further stratify risk among guideline-recommended candidates for add-on risk-reduction therapies. Given the potential benefits in terms of sample size, cost reduction, and overall RCT feasibility of a CAC-based enrichment strategy, we discuss approaches that may help maximize its advantages while minimizing logistical barriers and other challenges. Specifically, use of already existing CAC data to avoid the need to re-scan participants with previously documented high CAC scores, use of increasingly available, large clinical CAC databases to facilitate the identification of potential RCT participants, and implementation of machine learning approaches to measure CAC in existing computed tomography images performed for other purposes, will most likely boost the implementation of a CAC-based enrichment paradigm in future RCTs. © 2021},
	keywords = {Calcium; Coronary Angiography; Coronary Artery Disease; Coronary Vessels; Humans; Randomized Controlled Trials as Topic; Risk Assessment; Risk Factors; hydroxymethylglutaryl coenzyme A reductase inhibitor; calcium; Agatston score; age; cardiovascular risk; computed tomographic angiography; computer assisted tomography; coronary angiography; coronary artery atherosclerosis; coronary artery calcium score; cost control; ethics; Food and Drug Administration; human; machine learning; primary prevention; prognosis; randomized controlled trial (topic); Review; risk assessment; risk reduction; sample size; simulation; coronary artery disease; coronary blood vessel; diagnostic imaging; procedures; randomized controlled trial (topic); risk factor},
	correspondence_address = {M. Cainzos-Achirica; Division of Cardiovascular Prevention and Wellness, Department of Cardiology, Houston Methodist DeBakey Heart & Vascular Center, Houston, 6565 Fannin St Brown Bldg. B5–019, 77030; email: mcainzosachirica@houstonmethodist.org},
	publisher = {Elsevier Inc.},
	issn = {00028703},
	coden = {AHJOA},
	pmid = {34587511},
	language = {English},
	abbrev_source_title = {Am. Heart J.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Hardy20217240,
	author = {Hardy, Niall Philip and Cahill, Ronan Ambrose},
	title = {Digital surgery for gastroenterological diseases},
	year = {2021},
	journal = {World Journal of Gastroenterology},
	volume = {27},
	number = {42},
	pages = {7240 – 7246},
	doi = {10.3748/wjg.v27.i42.7240},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119062556&doi=10.3748%2fwjg.v27.i42.7240&partnerID=40&md5=5c0862b187858dae174aa9914ad50a87},
	affiliations = {UCD Centre for Precision Surgery, University College Dublin, Dublin, D07 Y9AW, Ireland},
	abstract = {Advances in machine learning, computer vision and artificial intelligence methods, in combination with those in processing and cloud computing capability, portend the advent of true decision support during interventions in real-time and soon perhaps in automated surgical steps. Such capability, deployed alongside technology intraoperatively, is termed digital surgery and can be delivered without the need for high-end capital robotic investment. An area close to clinical usefulness right now harnesses advances in near infrared endolaparoscopy and fluorescence guidance for tissue characterisation through the use of biophysics-inspired algorithms. This represents a potential synergistic methodology for the deep learning methods currently advancing in ophthalmology, radiology, and recently gastroenterology via colonoscopy. As databanks of more general surgical videos are created, greater analytic insights can be derived across the operative spectrum of gastroenterological disease and operations (including instrumentation and operative step sequencing and recognition, followed over time by surgeon and instrument performance assessment) and linked to value-based outcomes. However, issues of legality, ethics and even morality need consideration, as do the limiting effects of monopolies, cartels and isolated data silos. Furthermore, the role of the surgeon, surgical societies and healthcare institutions in this evolving field needs active deliberation, as the default risks relegation to bystander or passive recipient. This editorial provides insight into this accelerating field by illuminating the near-future and next decade evolutionary steps towards widespread clinical integration for patient and societal benefit. ©The Author(s) 2021. Published by Baishideng Publishing Group Inc. All rights reserved.},
	author_keywords = {Artificial intelligence; Biophysics; Deep learning; Digital surgery; Fluorescence-guided surgery; Gastrointestinal disease},
	keywords = {Algorithms; Artificial Intelligence; Gastroenterology; Humans; Machine Learning; Robotics; artificial intelligence; biophysics; computer assisted surgery; deep learning; digital technology; disease management; fluorescence imaging; gastrointestinal disease; gastrointestinal surgery; health care; health care delivery; human; information storage; intraoperative period; legal aspect; medical decision making; medical ethics; morality; Review; algorithm; gastroenterology; machine learning; robotics},
	correspondence_address = {R.A. Cahill; UCD Centre for Precision Surgery, University College Dublin, Dublin, Eccles Street, D07 Y9AW, Ireland; email: ronan.cahill@ucd.ie},
	publisher = {Baishideng Publishing Group Co},
	issn = {10079327},
	coden = {WJGAF},
	pmid = {34876786},
	language = {English},
	abbrev_source_title = {World J. Gastroenterol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Christou20216191,
	author = {Christou, Chrysanthos D. and Tsoulfas, Georgios},
	title = {Challenges and opportunities in the application of artificial intelligence in gastroenterology and hepatology},
	year = {2021},
	journal = {World Journal of Gastroenterology},
	volume = {27},
	number = {37},
	pages = {6191 – 6223},
	doi = {10.3748/wjg.v27.i37.6191},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116606386&doi=10.3748%2fwjg.v27.i37.6191&partnerID=40&md5=f711b5f50fb41dfe5686ae1603bb80b1},
	affiliations = {Organ Transplant Unit, Hippokration General Hospital, Aristotle University of Thessaloniki, Thessaloniki, 54622, Greece},
	abstract = {Artificial intelligence (AI) is an umbrella term used to describe a cluster of interrelated fields. Machine learning (ML) refers to a model that learns from past data to predict future data. Medicine and particularly gastroenterology and hepatology, are data-rich fields with extensive data repositories, and therefore fruitful ground for AI/ML-based software applications. In this study, we comprehensively review the current applications of AI/ML-based models in these fields and the opportunities that arise from their application. Specifically, we refer to the applications of AI/ML-based models in prevention, diagnosis, management, and prognosis of gastrointestinal bleeding, inflammatory bowel diseases, gastrointestinal premalignant and malignant lesions, other nonmalignant gastrointestinal lesions and diseases, hepatitis B and C infection, chronic liver diseases, hepatocellular carcinoma, cholangiocarcinoma, and primary sclerosing cholangitis. At the same time, we identify the major challenges that restrain the widespread use of these models in healthcare in an effort to explore ways to overcome them. Notably, we elaborate on the concerns regarding intrinsic biases, data protection, cybersecurity, intellectual property, liability, ethical challenges, and transparency. Even at a slower pace than anticipated, AI is infiltrating the healthcare industry. AI in healthcare will become a reality, and every physician will have to engage with it by necessity. © The Author(s) 2021. Published by Baishideng Publishing Group Inc. All rights reserved.},
	author_keywords = {Artificial intelligence; Artificial neural networks; Gastroenterology; Hepatology; Machine learning; Support vector machine},
	keywords = {Artificial Intelligence; Gastroenterology; Humans; Liver Diseases; Machine Learning; Prognosis; artificial intelligence; artificial neural network; bile duct carcinoma; chronic liver disease; computer security; gastroenterology; gastrointestinal hemorrhage; hepatitis B; hepatitis C; inflammatory bowel disease; liver cell carcinoma; machine learning; medical ethics; patent; primary sclerosing cholangitis; prognosis; Review; support vector machine; artificial intelligence; gastroenterology; human; liver disease},
	correspondence_address = {G. Tsoulfas; Organ Transplant Unit, Hippokration General Hospital, Aristotle University of Thessaloniki, Thessaloniki, 66 Tsimiski Street, 54622, Greece; email: tsoulfasg@gmail.com},
	publisher = {Baishideng Publishing Group Inc},
	issn = {10079327},
	coden = {WJGAF},
	pmid = {34712027},
	language = {English},
	abbrev_source_title = {World J. Gastroenterol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Bossert2021,
	author = {Bossert, Leonie and Hagendorff, Thilo},
	title = {Animals and AI. The role of animals in AI research and application – An overview and ethical evaluation},
	year = {2021},
	journal = {Technology in Society},
	volume = {67},
	doi = {10.1016/j.techsoc.2021.101678},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111998662&doi=10.1016%2fj.techsoc.2021.101678&partnerID=40&md5=7b62d4c94984308dd601923bc86f7d15},
	affiliations = {University of Tuebingen, International Center for Ethics in the Sciences and Humanities, Germany; Tuebingen, Germany},
	abstract = {Artificial intelligence (AI) technologies and their fields of application are among the most debated developments of recent times. Although being widely discussed academically, publicly and in policy debates, certain aspects of their research, development and application are completely ignored, namely the impact AI has on animals. Animals are affected by the research on and development of this technology since it partially relies on animal testing. In addition, AI is also being applied to improve monitoring and marketing of animals in an agricultural context. We argue that it is insufficient to exclude these aspects from debates around AI. In addition to the surveillance-applications on animals, which can be evaluated as impacting them negatively, AI applications, from which individual animals can benefit, do exist. These can primarily be found in nature and wildlife conservation, as we point out at the end of the paper. By providing an overview on how these technologies are applied to animals and how this affects them, this paper aims to fill a previously existing research gap. © 2021 Elsevier Ltd},
	author_keywords = {AI for Conservation; Animal ethics; Animal experiments; Artificial intelligence; Machine learning},
	keywords = {Agricultural robots; Animals; Conservation; AI applications; Animal testing; Artificial intelligence technologies; Development and applications; Policy debates; Research and application; Surveillance applications; Wildlife conservation; artificial intelligence; ethics; machine learning; research; species conservation; Artificial intelligence},
	correspondence_address = {L. Bossert; University of Tuebingen, International Center for Ethics in the Sciences and Humanities, Germany; email: leonie.bossert@izew.uni-tuebingen.de},
	publisher = {Elsevier Ltd},
	issn = {0160791X},
	language = {English},
	abbrev_source_title = {Technol. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Morr2021,
	author = {Morr, Christo El and Maret, Pierre and Muhlenbach, Fabrice and Dharmalingam, Dhayananth and Tadesse, Rediet and Creighton, Alexandra and Kundi, Bushra and Buettgen, Alexis and Mgwigwi, Thumeka and Dinca-Panaitescu, Serban and Dua, Enakshi and Gorman, Rachel},
	title = {A virtual community for disability advocacy: Development of a searchable artificial intelligence-supported platform},
	year = {2021},
	journal = {JMIR Formative Research},
	volume = {5},
	number = {11},
	doi = {10.2196/33335},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118943335&doi=10.2196%2f33335&partnerID=40&md5=c4430429148b55aa0af4d3eb88b4800e},
	affiliations = {School of Health Policy and Management, Faculty of Health, York University, Toronto, ON, Canada; CNRS, UMR 5516, Laboratoire Hubert Curien, Université Jean Monnet Saint Etienne, Saint Etienne, France; Student Learning and Academic Success Department, York University Libraries, York University, Toronto, ON, Canada; School of Gender, Sexuality and Women's Studies, York University, Toronto, ON, Canada},
	abstract = {Background: The lack of availability of disability data has been identified as a major challenge hindering continuous disability equity monitoring. It is important to develop a platform that enables searching for disability data to expose systemic discrimination and social exclusion, which increase vulnerability to inequitable social conditions. Objective: Our project aims to create an accessible and multilingual pilot disability website that structures and integrates data about people with disabilities and provides data for national and international disability advocacy communities. The platform will be endowed with a document upload function with hybrid (automated and manual) paragraph tagging, while the querying function will involve an intelligent natural language search in the supported languages. Methods: We have designed and implemented a virtual community platform using Wikibase, Semantic Web, machine learning, and web programming tools to enable disability communities to upload and search for disability documents. The platform data model is based on an ontology we have designed following the United Nations Convention on the Rights of Persons with Disabilities (CRPD). The virtual community facilitates the uploading and sharing of validated information, and supports disability rights advocacy by enabling dissemination of knowledge. Results: Using health informatics and artificial intelligence techniques (namely Semantic Web, machine learning, and natural language processing techniques), we were able to develop a pilot virtual community that supports disability rights advocacy by facilitating uploading, sharing, and accessing disability data. The system consists of a website on top of a Wikibase (a Semantic Web-based datastore). The virtual community accepts 4 types of users: Information producers, information consumers, validators, and administrators. The virtual community enables the uploading of documents, semiautomatic tagging of their paragraphs with meaningful keywords, and validation of the process before uploading the data to the disability Wikibase. Once uploaded, public users (information consumers) can perform a semantic search using an intelligent and multilingual search engine (QAnswer). Further enhancements of the platform are planned. Conclusions: The platform ontology is flexible and can accommodate advocacy reports and disability policy and legislation from specific jurisdictions, which can be accessed in relation to the CRPD articles. The platform ontology can be expanded to fit international contexts. The virtual community supports information upload and search. Semiautomatic tagging and intelligent multilingual semantic search using natural language are enabled using artificial intelligence techniques, namely Semantic Web, machine learning, and natural language processing. © 2021 JMIR Publications Inc..},
	author_keywords = {Community; CRPD; Disability; Disability rights; Equity; Ethics; Health informatics; Human rights; Machine learning; Natural language processing; Pilot; Platform; Rights; Semantic Web; Virtual community; Web intelligence; Wikibase},
	correspondence_address = {C.E. Morr; School of Health Policy and Management, Faculty of Health, York University, Toronto, 4700 Keele St, M3J 1P3, Canada; email: elmorr@yorku.ca},
	publisher = {JMIR Publications Inc.},
	issn = {2561326X},
	language = {English},
	abbrev_source_title = {JMIR Form.  Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Xivuri2022335,
	author = {Xivuri, Khensani and Twinomurinzi, Hossana},
	title = {A Habermasian Approach to Fair Processes in AI Algorithms},
	year = {2022},
	journal = {Communications in Computer and Information Science},
	volume = {1551 CCIS},
	pages = {335 – 343},
	doi = {10.1007/978-3-030-95070-5_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125276339&doi=10.1007%2f978-3-030-95070-5_22&partnerID=40&md5=600975afbfdeee7914736337fe8dfb50},
	affiliations = {University of Johannesburg, Auckland Park, Johannesburg, South Africa},
	abstract = {The traditional emphasis of fairness in AI algorithms tends towards developing fair standards, even though the field of AI and its subfields advance rapidly and creatively, meaning that any AI fair standards could similarly become obsolete rapidly. This paper argues rather for an emphasis on fair processes that are adaptable to AI’s continuous creations and innovations. Specifically, we adapt Jurgen Habermas’ critical theory of communication, the lifeworld and meaning to develop a process framework for AI algorithmic fairness. The framework engages logical-semantic, procedural and performative rules that can be applied to avoid power imbalances and domination by any entity or individual before, during and after AI algorithm development. The framework is applied to the recent case of the biased Twitter image cropping algorithm, which focused on white faces and women’s chests but cropped out black faces. © 2022, Springer Nature Switzerland AG.},
	author_keywords = {Active learning algorithms; AI machine learning; Bias; Ethics; Fairness; Jürgen Habermas; Theory of communicative action},
	keywords = {Learning algorithms; Machine learning; Philosophical aspects; Active-learning algorithm; AI algorithms; AI machine learning; Bias; Communicative actions; Fairness; Habermas; Jurgen habermas; Subfields; Theory of communicative action; Semantics},
	correspondence_address = {K. Xivuri; University of Johannesburg, Johannesburg, Auckland Park, South Africa; email: KhensaniX@gmail.com},
	editor = {Jembere E. and Gerber A.J. and Viriri S. and Pillay A.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303095069-9},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd Southern African Conference on  Artificial Intelligence Research, SACAIR 2021; Conference date: 6 December 2021 through 10 December 2021; Conference code: 271859}
}

@ARTICLE{Lee2021,
	author = {Lee, Gihun and Kim, Mihui},
	title = {Deepfake detection using the rate of change between frames based on computer vision},
	year = {2021},
	journal = {Sensors},
	volume = {21},
	number = {21},
	doi = {10.3390/s21217367},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119254199&doi=10.3390%2fs21217367&partnerID=40&md5=120698cd4ce8181e2b568be9141a6668},
	affiliations = {Department of Computer Science & Engineering, Computer System Institute, Hankyong National University, Jungang-ro, Anseong-si, Gyeonggi-do, 17579, South Korea},
	abstract = {Recently, artificial intelligence has been successfully used in fields, such as computer vision, voice, and big data analysis. However, various problems, such as security, privacy, and ethics, also occur owing to the development of artificial intelligence. One such problem are deepfakes. Deepfake is a compound word for deep learning and fake. It refers to a fake video created using artificial intelligence technology or the production process itself. Deepfakes can be exploited for political abuse, pornography, and fake information. This paper proposes a method to determine integrity by analyzing the computer vision features of digital content. The proposed method extracts the rate of change in the computer vision features of adjacent frames and then checks whether the video is manipulated. The test demonstrated the highest detection rate of 97% compared to the existing method or machine learning method. It also maintained the highest detection rate of 96%, even for the test that manipulates the matrix of the image to avoid the convolutional neural network detection method. View Full-Text © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Computer vision; Deepfake; The rate of change},
	keywords = {Artificial Intelligence; Computers; Deception; Machine Learning; Neural Networks, Computer; Convolutional neural networks; Deep learning; Fake detection; Artificial intelligence technologies; Compound words; Deepfake; Frame-based; High detection rate; In-field; Security/privacy; The rate of change; Vision features; artificial intelligence; computer; deception; machine learning; Computer vision},
	correspondence_address = {M. Kim; Department of Computer Science & Engineering, Computer System Institute, Hankyong National University, Gyeonggi-do, Jungang-ro, Anseong-si, 17579, South Korea; email: mhkim@hknu.ac.kr},
	publisher = {MDPI},
	issn = {14248220},
	pmid = {34770675},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Trovato2021,
	author = {Trovato, Guglielmo and Russo, Matteo},
	title = {Artificial Intelligence (AI) and Lung Ultrasound in Infectious Pulmonary Disease},
	year = {2021},
	journal = {Frontiers in Medicine},
	volume = {8},
	doi = {10.3389/fmed.2021.706794},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120894422&doi=10.3389%2ffmed.2021.706794&partnerID=40&md5=1eb495c2777e44acac409c9b7b1462a1},
	affiliations = {The European Medical Association (EMA), Brussels, Belgium},
	author_keywords = {artificial intelligence; bullying in international settings; deep learning-artificial neural network (DL-ANN); ethics; lung imaging},
	keywords = {advertising; algorithm; Article; artificial intelligence; computer assisted tomography; coronavirus disease 2019; deep learning; diagnostic procedure; follow up; health practitioner; human; lung infection; machine learning; quantitative analysis; reliability; ultrasound; X ray},
	correspondence_address = {G. Trovato; The European Medical Association (EMA), Brussels, Belgium; email: trovato.eu@gmail.com; M. Russo; The European Medical Association (EMA), Brussels, Belgium; email: russo.matteo0801@gmail.com},
	publisher = {Frontiers Media S.A.},
	issn = {2296858X},
	language = {English},
	abbrev_source_title = {Front. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhao2021,
	author = {Zhao, Ivy Y. and Ma, Ye Xuan and Yu, Man Wai Cecilia and Liu, Jia and Dong, Wei Nan and Pang, Qin and Lu, Xiao Qin and Molassiotis, Alex and Holroyd, Eleanor and Wong, Chi Wai William},
	title = {Ethics, integrity, and retributions of digital detection surveillance systems for infectious diseases: Systematic literature review},
	year = {2021},
	journal = {Journal of Medical Internet Research},
	volume = {23},
	number = {10},
	doi = {10.2196/32328},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117902136&doi=10.2196%2f32328&partnerID=40&md5=d35f15d077f87a17b1c13a1a11590f11},
	affiliations = {WHO Collaborating Centre for Community Health Services, School of Nursing, The Hong Kong Polytechnic University, Hong Kong; Department of Family Medicine and Primary Care, Li Ka Shing Faculty of Medicine, The University of Hong Kong, Hong Kong; Shenzhen Institute of Advanced Technology, Chinese Academy of Sciences, Shenzhen, China; Department of Information Technology, University of Hong Kong-Shenzhen Hospital, Shenzhen, China; School of General Practice and Continuing Education, Capital Medical University, Beijing, China; School of Clinical Sciences, Auckland University of Technology, Auckland, New Zealand; Department of Family Medicine and Primary Care, University of Hong Kong-Shenzhen Hospital, Shenzhen, China},
	abstract = {Background: The COVID-19 pandemic has increased the importance of the deployment of digital detection surveillance systems to support early warning and monitoring of infectious diseases. These opportunities create a "double-edge sword," as the ethical governance of such approaches often lags behind technological achievements. Objective: The aim was to investigate ethical issues identified from utilizing artificial intelligence-augmented surveillance or early warning systems to monitor and detect common or novel infectious disease outbreaks. Methods: In a number of databases, we searched relevant articles that addressed ethical issues of using artificial intelligence, digital surveillance systems, early warning systems, and/or big data analytics technology for detecting, monitoring, or tracing infectious diseases according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, and further identified and analyzed them with a theoretical framework. Results: This systematic review identified 29 articles presented in 6 major themes clustered under individual, organizational, and societal levels, including awareness of implementing digital surveillance, digital integrity, trust, privacy and confidentiality, civil rights, and governance. While these measures were understandable during a pandemic, the public had concerns about receiving inadequate information; unclear governance frameworks; and lack of privacy protection, data integrity, and autonomy when utilizing infectious disease digital surveillance. The barriers to engagement could widen existing health care disparities or digital divides by underrepresenting vulnerable and at-risk populations, and patients' highly sensitive data, such as their movements and contacts, could be exposed to outside sources, impinging significantly upon basic human and civil rights. Conclusions: Our findings inform ethical considerations for service delivery models for medical practitioners and policymakers involved in the use of digital surveillance for infectious disease spread, and provide a basis for a global governance structure. © 2021 Journal of Medical Internet Research. All rights reserved.},
	author_keywords = {Artificial intelligence; Electronic medical records; Ethics; Infectious diseases; Machine learning},
	keywords = {Artificial Intelligence; Communicable Diseases; COVID-19; Humans; Pandemics; SARS-CoV-2; artificial intelligence; big data; civil rights; communicable disease; conceptual framework; confidentiality; data base; data integrity; digital divide; disease surveillance; ethics; health care delivery; health care disparity; high risk population; human; machine learning; pandemic; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; privacy; Review; risk assessment; trust; vulnerable population; communicable disease},
	correspondence_address = {C.W.W. Wong; Department of Family Medicine and Primary Care, Li Ka Shing Faculty of Medicine, The University of Hong Kong, Ap Lei Chau, 3/F, Ap Lei Chau Clinic, 161 Main Street, Hong Kong; email: wongwcw@hku.hk},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {34543228},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Suresh2021,
	author = {Suresh, Harini and Guttag, John},
	title = {A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3465416.3483305},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119301669&doi=10.1145%2f3465416.3483305&partnerID=40&md5=e2fb1ee6347028bb43964549dcc0243b},
	affiliations = {Massachusetts Institute of Technology, United States},
	abstract = {As machine learning (ML) increasingly affects people and society, awareness of its potential unwanted consequences has also grown. To anticipate, prevent, and mitigate undesirable downstream consequences, it is critical that we understand when and how harm might be introduced throughout the ML life cycle. In this paper, we provide a framework that identifies seven distinct potential sources of downstream harm in machine learning, spanning data collection, development, and deployment. In doing so, we aim to facilitate more productive and precise communication around these issues, as well as more direct, application-grounded ways to mitigate them.  © 2021 Owner/Author.},
	author_keywords = {AI ethics; algorithmic bias; allocative harm; fairness in machine learning; representational harm; societal implications of machine learning},
	keywords = {Ethical technology; Machine learning; AI ethic; Algorithmic bias; Algorithmics; Allocative harm; Down-stream; Fairness in machine learning; Machine-learning; Representational harm; Societal implication of machine learning; Societal implications; Life cycle},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038553-4},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40; Conference name: 2021 ACM Conference on Equity and Access in Algorithms, Mechanisms, and Optimization, EAAMO 2021; Conference date: 5 October 2021 through 9 October 2021; Conference code: 173501; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Serra Bragança2021,
	author = {Serra Bragança, F.M. and Broomé, S. and Rhodin, M. and Björnsdóttir, S. and Gunnarsson, V. and Voskamp, J.P. and Persson‑Sjodin, E. and Back, W. and Lindgren, G. and Novoa‑Bravo, M. and Gmel, A.I. and Roepstorff, C. and van der Zwaag, B.J. and Van Weeren, P.R. and Hernlund, E.},
	title = {Author Correction: Improving gait classification in horses by using inertial measurement unit (IMU) generated data and machine learning (Scientific Reports, (2020), 10, 1, (17785), 10.1038/s41598-020-73215-9)},
	year = {2021},
	journal = {Scientific Reports},
	volume = {11},
	number = {1},
	doi = {10.1038/s41598-021-88880-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104852110&doi=10.1038%2fs41598-021-88880-7&partnerID=40&md5=b6958725fa7ca4e11428b765da4db34a},
	affiliations = {Department of Clinical Sciences, Faculty of Veterinary Medicine, Utrecht University, 3584CM, Utrecht, Netherlands; Division of Robotics, Perception and Learning, KTH Royal Institute of Technology, Stockholm, Sweden; Department of Anatomy, Physiology and Biochemistry, Swedish University of Agricultural Sciences, Uppsala, Sweden; Agricultural University of Iceland, Hvanneyri, Borgarnes, Iceland; Department of Equine Science, Hólar University College, Hólar, Iceland; Department of Surgery and Anaesthesiology of Domestic Animals, Faculty of Veterinary Medicine, Ghent University, Merelbeke, 9820, Belgium; Department of Animal Breeding and Genetics, Swedish University of Agricultural Sciences, Uppsala, 75007, Sweden; Livestock Genetics, Department of Biosystems, KU Leuven, Leuven, 3001, Belgium; Genética Animal de Colombia Ltda, Bogotá, Colombia; Equine Department, Vetsuisse Faculty, University of Zurich, Winterthurerstrasse 260, Zurich, 8057, Switzerland; Inertia Technology B.V, Enschede, Netherlands; Agroscope – Swiss National Stud Farm, Les Longs-Prés, Avenches, 1580, Switzerland; Institute of Genetics, Vetsuisse Faculty, University of Bern, Bremgartenstrasse 109a, Bern, 3012, Switzerland},
	abstract = {The original version of this Article contained errors. A.I. Gmel was omitted from the author list. The Author Contributions section now reads: F.M.S.B., E.H., P.R.W., M.R., conceived the concept. F.M.S.B., E.H., M.R., S.Bj., V.G., M.N., J.V., E.M.P., C.R., A.I.G., carried out the data collection. F.M.S.B. and S.Br. conducted the data analysis. F.M.S.B., E.H., S.Br., G.L., B.J.v.d.Z, P.R.W. W.B. co-wrote the paper. All authors discussed the results and commented on the manuscript. Additionally, there was a repeated error in the naming of the horse breed “Franches-Montagnes” which was incorrectly given as “Franche Montagne.” As a result, in Figure 1C, the key describing “Franches Montagne” now reads “Franches-Montagnes.” The original Figure 1 and accompanying legend appear below. In the Methods, subheading “Data set”, “Data sets (Table 4) were collected for different research purposes, such as studying objective motion analysis methodology in sound speed-dependent motion patterns in warmblood riding horses and Franche Montagne horses and studying gaits and phenotype–genotype associations in gaited horse breeds (Icelandic horses and Colombian horse breeds).” now reads: “Data sets (Table 4) were collected for different research purposes, such as studying objective motion analysis methodology in sound speed-dependent motion patterns in warmblood riding horses and Franche-Montagnes horses and studying gaits and phenotype–genotype associations in gaited horse breeds (Icelandic horses and Colombian horse breeds).” Furthermore, in the same section, “For each data set (Table 4), the local Ethics Committee (The Icelandic Food and Veterinary Authority MAST; Ethics Committee for Animal Experiments in Uppsala; Animal Health and Welfare Commission of the canton of Zurich and the ethical committee of Utrecht University in the Netherlands IvD) approved the experimental protocol.” now reads: “For each data set (Table 4), the local Ethics Committee (The Icelandic Food and Veterinary Authority MAST; Ethics Committee for Animal Experiments in Uppsala; Animal Health and Welfare Commission of the canton of Vaud and the ethical committee of Utrecht University in the Netherlands IvD) approved the experimental protocol.” In Table 4, the “Breed” in column 1, “Franche montagne”. now reads: “Franches-Montagnes”. Lastly, the Acknowledgements section was incomplete. “The Pálmi Jónsson’s Nature Conservation Fund, the Swedish Norwegian foundation for Equine research (H-17- 47-303), the research council of Norway (grant number: HE 284171), and FORMAS (2018-00737 and 2016- 00947) funded this study. EquiMoves E 12304 Eurostars—The Eurostars Programme is powered by EUREKA and the European Community.” now reads: “The Pálmi Jónsson’s Nature Conservation Fund, the Swedish Norwegian foundation for Equine research (H-17- 47-303), the research council of Norway (grant number: HE 284171), and FORMAS (2018-00737 and 2016- 00947) funded this study. EquiMoves E! 12304 Eurostars—The Eurostars Programme is powered by EUREKA and the European Community. The Swiss federal Office for Agriculture funded the data collection for the Franches- Montagnes data under contract number 625000469. We thank all persons such as horse handlers, owners and technical staff involved in data collection.” These errors have now been corrected in the PDF and HTML versions of the Article. © 2021, The Author(s).},
	keywords = {erratum},
	correspondence_address = {F.M. Serra Bragança; Department of Clinical Sciences, Faculty of Veterinary Medicine, Utrecht University, Utrecht, 3584CM, Netherlands; email: f.m.serrabraganca@uu.nl},
	publisher = {Nature Research},
	issn = {20452322},
	pmid = {33903727},
	language = {English},
	abbrev_source_title = {Sci. Rep.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mulvenna20211945,
	author = {Mulvenna, Maurice D. and Bond, Raymond and Delaney, Jack and Dawoodbhoy, Fatema Mustansir and Boger, Jennifer and Potts, Courtney and Turkington, Robin},
	title = {Ethical Issues in Democratizing Digital Phenotypes and Machine Learning in the Next Generation of Digital Health Technologies},
	year = {2021},
	journal = {Philosophy and Technology},
	volume = {34},
	number = {4},
	pages = {1945 – 1960},
	doi = {10.1007/s13347-021-00445-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103176108&doi=10.1007%2fs13347-021-00445-8&partnerID=40&md5=1804621c9acf32165d8e06f7b6bf28cb},
	affiliations = {School of Computing, Ulster University, Shore Road, Newtownabbey, United Kingdom; Imperial College School of Medicine, Imperial College London, South Kensington, London, United Kingdom; Department of Systems Design Engineering, University of Waterloo, University Avenue West, Waterloo, Canada},
	abstract = {Digital phenotyping is the term given to the capturing and use of user log data from health and wellbeing technologies used in apps and cloud-based services. This paper explores ethical issues in making use of digital phenotype data in the arena of digital health interventions. Products and services based on digital wellbeing technologies typically include mobile device apps as well as browser-based apps to a lesser extent, and can include telephony-based services, text-based chatbots, and voice-activated chatbots. Many of these digital products and services are simultaneously available across many channels in order to maximize availability for users. Digital wellbeing technologies offer useful methods for real-time data capture of the interactions of users with the products and services. It is possible to design what data are recorded, how and where it may be stored, and, crucially, how it can be analyzed to reveal individual or collective usage patterns. The paper also examines digital phenotyping workflows, before enumerating the ethical concerns pertaining to different types of digital phenotype data, highlighting ethical considerations for collection, storage, and use of the data. A case study of a digital health app is used to illustrate the ethical issues. The case study explores the issues from a perspective of data prospecting and subsequent machine learning. The ethical use of machine learning and artificial intelligence on digital phenotype data and the broader issues in democratizing machine learning and artificial intelligence for digital phenotype data are then explored in detail. © 2021, The Author(s).},
	author_keywords = {Digital health; Digital phenotyping; Ecological momentary assessment; Ethics; Event log analysis; Experience sampling method; Unsupervised machine learning},
	correspondence_address = {M.D. Mulvenna; School of Computing, Ulster University, Newtownabbey, Shore Road, United Kingdom; email: md.mulvenna@ulster.ac.uk},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22105433},
	language = {English},
	abbrev_source_title = {Philos. Technol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Harvey20211075,
	author = {Harvey, Harlan Benjamin and Gowda, Vrushab},
	title = {Regulatory Issues and Challenges to Artificial Intelligence Adoption},
	year = {2021},
	journal = {Radiologic Clinics of North America},
	volume = {59},
	number = {6},
	pages = {1075 – 1083},
	doi = {10.1016/j.rcl.2021.07.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117592628&doi=10.1016%2fj.rcl.2021.07.007&partnerID=40&md5=3cecd98ef92fde3da3ea58655a8a4ca7},
	affiliations = {Radiology, Massachusetts General Hospital, Harvard Medical School, 175 Cambridge Street, Suite 200, Boston, 02114, MA, United States; Harvard Law School, 1563 Massachusetts Avenue, Cambridge, 02138, MA, United States},
	author_keywords = {AI; Health law; Liability; Regulatory issues; Risk management},
	keywords = {Artificial Intelligence; Diagnostic Imaging; Humans; Image Interpretation, Computer-Assisted; Radiology; United States; United States Food and Drug Administration; artificial intelligence; computer assisted diagnosis; confidentiality; deep learning; device approval; electronic health record; human; information security; learning algorithm; legal liability; machine learning; malpractice; mammography; medical device regulation; medical ethics; overdiagnosis; privacy; radiologist; Review; artificial intelligence; diagnostic imaging; Food and Drug Administration; legislation and jurisprudence; procedures; radiology; United States},
	correspondence_address = {H.B. Harvey; Radiology, Massachusetts General Hospital, Harvard Medical School, Boston, 175 Cambridge Street, Suite 200, 02114, United States; email: hbharvey@mgh.harvard.edu},
	publisher = {W.B. Saunders},
	issn = {00338389},
	coden = {RCNAA},
	pmid = {34689875},
	language = {English},
	abbrev_source_title = {Radiol. Clin. North Am.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Bernstein2021,
	author = {Bernstein, Michael S. and Levi, Margaret and Magnus, David and Rajala, Betsy A. and Satz, Debra and Waeiss, Charla},
	title = {Ethics and society review: Ethics reflection as a precondition to research funding},
	year = {2021},
	journal = {Proceedings of the National Academy of Sciences of the United States of America},
	volume = {118},
	number = {52},
	doi = {10.1073/pnas.2117261118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122570859&doi=10.1073%2fpnas.2117261118&partnerID=40&md5=dce10c837b18cdbf67d99c1a797cf815},
	affiliations = {Department of Computer Science, Stanford University, Stanford, 94305, CA, United States; Center for Advanced Study in the Behavioral Sciences, Stanford University, Stanford, 94305, CA, United States; Department of Political Science, Stanford University, Stanford, 94305, CA, United States; Department of Pediatrics, Stanford University, Stanford, 94305, CA, United States; Department of Philosophy, Stanford University, Stanford, 94305, CA, United States},
	abstract = {Researchers in areas as diverse as computer science and political science must increasingly navigate the possible risks of their research to society. However, the history of medical experiments on vulnerable individuals influencedmany research ethics reviews to focus exclusively on risks to human subjects rather than risks to human society. We describe an Ethics and Society Review board (ESR), which fills this moral gap by facilitating ethical and societal reflection as a requirement to access grant funding: Researchers cannot receive grant funding from participating programs until the researchers complete the ESR process for their proposal. Researchers author an initial statement describing their proposed research's risks to society, subgroups within society, and globally and commit to mitigation strategies for these risks. An interdisciplinary faculty panel iterates with the researchers to refine these risks and mitigation strategies. We describe a mixedmethod evaluation of the ESR over 1 y, in partnership with a large artificial intelligence grant program at our university. Surveys and interviews of researchers who interacted with the ESR found 100% (95% CI: 87 to 100%) were willing to continue submitting future projects to the ESR, and 58% (95% CI: 37 to 77%) felt that it had influenced the design of their research project. The ESR panel most commonly identified issues of harms to minority groups, inclusion of diverse stakeholders in the research plan, dual use, and representation in datasets. These principles, paired with possible mitigation strategies, offer scaffolding for future research designs. © 2021 National Academy of Sciences. All rights reserved.},
	author_keywords = {Computer science; Ethics; Machine learning; Societal consequences},
	keywords = {Article; artificial intelligence; controlled study; ethics; funding; health hazard; human; interview; machine learning; medical research; minority group; questionnaire; scientist; stakeholder engagement},
	correspondence_address = {M. Levi; Center for Advanced Study in the Behavioral Sciences, Stanford University, Stanford, 94305, United States; email: mlevi@stanford.edu},
	publisher = {National Academy of Sciences},
	issn = {00278424},
	coden = {PNASA},
	pmid = {34934006},
	language = {English},
	abbrev_source_title = {Proc. Natl. Acad. Sci. U. S. A.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Liu2021,
	author = {Liu, Christopher Weiyang and Chen, Lynn N and Anwar, Amalina and Lu Zhao, Boyu and Lai, Clin K Y and Ng, Wei Heng and Suhitharan, Thangavelautham and Ho, Vui Kian and Liu, Jean C J},
	title = {Comparing organ donation decisions for next-of-kin versus the self: Results of a national survey},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {11},
	doi = {10.1136/bmjopen-2021-051273},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119856131&doi=10.1136%2fbmjopen-2021-051273&partnerID=40&md5=7ec6025101a6d8424ece194298f27c58},
	affiliations = {Department of Pain Medicine, Singapore General Hospital, Singapore, Singapore; Anaesthesiology Academic Clinical Program, Duke-NUS Medical School, Singapore, Singapore; Yong Loo Lin School of Medicine, National University of Singapore, Singapore, Singapore; Department of Anesthesiology, Singapore General Hospital, Singapore, Singapore; Division of Social Sciences, Yale-NUS College, Singapore, Singapore; Department of Surgical Intensive Care, Singapore General Hospital, Singapore, Singapore; Neuroscience and Behavioral Disorders Programme, Duke-NUS Medical School, Singapore, Singapore},
	abstract = {Objectives Intensive care audits point to family refusal as a major barrier to organ donation. In this study, we sought to understand refusal by accounting for the decision-maker's mindset. This focused on: (1) how decisions compare when made on behalf of a relative (vs the self); and (2) confidence in decisions made for family members. Design Cross-sectional survey in Singapore. Setting Participants were recruited from community settings via door-to-door sampling and community eateries. Participants 973 adults who qualified as organ donors in Singapore. Results Although 68.1% of participants were willing to donate their own organs, only 51.8% were willing to donate a relative's organs. Using machine learning, we found that consistency was predicted by: (1) religion, and (2) fears about organ donation. Conversely, participants who were willing to donate their own organs but not their relative's were less driven by these factors, and may instead have resorted to heuristics in decision-making. Finally, we observed how individuals were overconfident in their decision-making abilities: although 78% had never discussed organ donation with their relatives, the large majority expressed high confidence that they would respect their relatives' wishes on death. Conclusions These findings underscore the distinct psychological processes involved when donation decisions are made for family members. Amidst a global shortage of organ donors, addressing the decision-maker's mindset (eg, overconfidence, the use of heuristics) may be key to actualizing potential donors identified in intensive care units.  © Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {health services administration & management; medical ethics; transplant surgery},
	keywords = {Adult; Cross-Sectional Studies; Decision Making; Family; Humans; Organ Transplantation; Tissue and Organ Procurement; Tissue Donors; adult; article; controlled study; female; heuristics; human; human tissue; intensive care unit; machine learning; major clinical study; male; medical ethics; organ donor; overconfidence; relative; religion; Singapore; surgery; transplantation; cross-sectional study; decision making; donor; family; organ transplantation},
	correspondence_address = {J.C.J. Liu; Division of Social Sciences, Yale-NUS College, Singapore, Singapore; email: jeanliu@yale-nus.edu.sg},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34785552},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Renn2021,
	author = {Renn, Brenna N. and Schurr, Matthew and Zaslavsky, Oleg and Pratap, Abhishek},
	title = {Artificial Intelligence: An Interprofessional Perspective on Implications for Geriatric Mental Health Research and Care},
	year = {2021},
	journal = {Frontiers in Psychiatry},
	volume = {12},
	doi = {10.3389/fpsyt.2021.734909},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120485288&doi=10.3389%2ffpsyt.2021.734909&partnerID=40&md5=7346b583516930e28a4e530e01287283},
	affiliations = {Department of Psychology, University of Nevada, Las Vegas, NV, United States; Department of Biobehavioral Nursing and Health Informatics, University of Washington, Seattle, WA, United States; Krembil Centre for Neuroinformatics, Centre for Addiction and Mental Health, Toronto, ON, Canada; Vector Institute for Artificial Intelligence, Toronto, ON, Canada; Department of Biomedical Informatics and Medical Education, University of Washington, Seattle, WA, United States; Institute of Psychiatry, Psychology Neuroscience, King's College London, London, United Kingdom},
	abstract = {Artificial intelligence (AI) in healthcare aims to learn patterns in large multimodal datasets within and across individuals. These patterns may either improve understanding of current clinical status or predict a future outcome. AI holds the potential to revolutionize geriatric mental health care and research by supporting diagnosis, treatment, and clinical decision-making. However, much of this momentum is driven by data and computer scientists and engineers and runs the risk of being disconnected from pragmatic issues in clinical practice. This interprofessional perspective bridges the experiences of clinical scientists and data science. We provide a brief overview of AI with the main focus on possible applications and challenges of using AI-based approaches for research and clinical care in geriatric mental health. We suggest future AI applications in geriatric mental health consider pragmatic considerations of clinical practice, methodological differences between data and clinical science, and address issues of ethics, privacy, and trust. Copyright © 2021 Renn, Schurr, Zaslavsky and Pratap.},
	author_keywords = {deep learning; depression; machine learning; natural language processing; older adults; personalized medicine/personalized health care; psychotherapy; technology},
	keywords = {adult; article; artificial intelligence; clinical decision making; clinical practice; computer scientist; data science; deep learning; ethics; female; human; human experiment; male; mental health care; mental health research; natural language processing; personalized medicine; privacy; psychotherapy; trust},
	correspondence_address = {B.N. Renn; Department of Psychology, University of Nevada, Las Vegas, United States; email: brenna.renn@unlv.edu},
	publisher = {Frontiers Media S.A.},
	issn = {16640640},
	language = {English},
	abbrev_source_title = {Front. Psychiatry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Barclay2021264,
	author = {Barclay, Iain and Abramson, Will},
	title = {Identifying Roles, Requirements and Responsibilitiesin Trustworthy AI Systems},
	year = {2021},
	journal = {UbiComp/ISWC 2021 - Adjunct Proceedings of the 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and Proceedings of the 2021 ACM International Symposium on Wearable Computers},
	pages = {264 – 271},
	doi = {10.1145/3460418.3479344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115948273&doi=10.1145%2f3460418.3479344&partnerID=40&md5=667e3fbfb482a502aa356095f005bd44},
	affiliations = {School of Computer Science and Informatics, Cardiff University, Cardiff, United Kingdom; Blockpass Id Lab, School of Computing, Edinburgh Napier University, Edinburgh, United Kingdom},
	abstract = {Artificial Intelligence (AI) systems are being deployed around the globe in critical fields such as healthcare and education. In some cases, expert practitioners in these domains are being tasked with introducing or using such systems, but have little or no insight into what data these complex systems are based on, or how they are put together. In this paper, we consider an AI system from the domain practitioner's perspective and identify key roles that are involved in system deployment. We consider the differing requirements and responsibilities of each role, and identify tensions between transparency and confidentiality that need to be addressed so that domain practitioners are able to intelligently assess whether a particular AI system is appropriate for use in their domain. © 2021 ACM.},
	author_keywords = {Artificial Intelligence; Assurance; Ethics; Machine Learning; Trust},
	keywords = {Requirements engineering; Artificial intelligence systems; Assurance; Critical fields; Machine-learning; System deployment; Trust; Machine learning},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038461-2},
	language = {English},
	abbrev_source_title = {UbiComp/ISWC - Adjun. Proc. ACM Int. Jt. Conf. Pervasive Ubiquitous Comput. Proc. ACM Int. Symp. Wearable Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2021 ACM International Joint Conference on Pervasive and Ubiquitous Computing and the 2021 ACM International Symposium on Wearable Computers, UbiComp/ISWC 2021; Conference date: 21 September 2021 through 25 September 2021; Conference code: 171865; All Open Access, Green Open Access}
}

@ARTICLE{Salazar2022,
	author = {Salazar, Luiz Henrique A. and Leithardt, Valderi R. Q. and Parreira, Wemerson Delcio and da Rocha Fernandes, Anita M. and Barbosa, Jorge Luis Victória and Correia, Sérgio Duarte},
	title = {Application of machine learning techniques to predict a patient’s no-show in the healthcare sector},
	year = {2022},
	journal = {Future Internet},
	volume = {14},
	number = {1},
	doi = {10.3390/fi14010003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121669063&doi=10.3390%2ffi14010003&partnerID=40&md5=388d33d2ae8291e9789859f83243b44f},
	affiliations = {Laboratory of Embedded and Distributed Systems, University of Vale do Itajai, Itajai, 88302-901, Brazil; VALORIZA, Research Center for Endogenous Resources Valorization, Instituto Politécnico de Portalegre, Portalegre, 7300-555, Portugal; COPELABS, Universidade Lusófona de Humanidades e Tecnologias, Lisbon, 1749-024, Portugal; Applied Computing Graduate Program, University of Vale do Rio dos Sinos, Av. Unisinos 950, Bairro Cristo Rei, Sao Leopoldo, 93022-750, Brazil},
	abstract = {The health sector faces a series of problems generated by patients who miss their scheduled appointments. The main challenge to this problem is to understand the patient’s profile and predict potential absences. The goal of this work is to explore the main causes that contribute to a patient’s no-show and develop a prediction model able to identify whether the patient will attend their scheduled appointment or not. The study was based on data from clinics that serve the Unified Health System (SUS) at the University of Vale do Itajaí in southern Brazil. The model obtained was tested on a real collected dataset with about 5000 samples. The best model result was performed by the Random Forest classifier. It had the best Recall Rate (0.91) and achieved an ROC curve rate of 0.969. This research was approved and authorized by the Ethics Committee of the University of Vale do Itajaí, under opinion 4270,234, contemplating the General Data Protection Law. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Artificial intelligence; Data science; Healthcare applications; Machine learning; Patient attitudes},
	keywords = {Data Science; Decision trees; Forecasting; Health care; Best model; Health care application; Health systems; Healthcare sectors; Machine learning techniques; Modeling results; Patient attitudes; Prediction modelling; Random forest classifier; Southern Brazil; Machine learning},
	correspondence_address = {W.D. Parreira; Laboratory of Embedded and Distributed Systems, University of Vale do Itajai, Itajai, 88302-901, Brazil; email: parreira@univali.br; A.M. da Rocha Fernandes; Laboratory of Embedded and Distributed Systems, University of Vale do Itajai, Itajai, 88302-901, Brazil; email: anita.fernandes@univali.br},
	publisher = {MDPI},
	issn = {19995903},
	language = {English},
	abbrev_source_title = {Future Internet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Nadarajah2021,
	author = {Nadarajah, Ramesh and Wu, Jianhua and Frangi, Alejandro F and Hogg, David and Cowan, Campbell and Gale, Chris},
	title = {Predicting patient-level new-onset atrial fibrillation from population-based nationwide electronic health records: Protocol of FIND-AF for developing a precision medicine prediction model using artificial intelligence},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {11},
	doi = {10.1136/bmjopen-2021-052887},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118995492&doi=10.1136%2fbmjopen-2021-052887&partnerID=40&md5=61f2e946bf0156e81b0b9c4f041a87e4},
	affiliations = {Leeds Institute for Data Analytics, University of Leeds, Leeds, United Kingdom; Leeds Institute of Cardiovascular and Metabolic Medicine, University of Leeds, Leeds, United Kingdom; Department of Cardiology, Leeds Teaching Hospitals Nhs Trust, Leeds, United Kingdom; School of Dentistry, University of Leeds, Leeds, United Kingdom; School of Computing, University of Leeds, Leeds, United Kingdom},
	abstract = {Introduction Atrial fibrillation (AF) is a major cardiovascular health problem: it is common, chronic and incurs substantial healthcare expenditure because of stroke. Oral anticoagulation reduces the risk of thromboembolic stroke in those at higher risk; but for a number of patients, stroke is the first manifestation of undetected AF. There is a rationale for the early diagnosis of AF, before the first complication occurs, but population-based screening is not recommended. Previous prediction models have been limited by their data sources and methodologies. An accurate model that uses existing routinely collected data is needed to inform clinicians of patient-level risk of AF, inform national screening policy and highlight predictors that may be amenable to primary prevention. Methods and analysis We will investigate the application of a range of deep learning techniques, including an adapted convolutional neural network, recurrent neural network and Transformer, on routinely collected primary care data to create a personalised model predicting the risk of new-onset AF over a range of time periods. The Clinical Practice Research Datalink (CPRD)-GOLD dataset will be used for derivation, and the CPRD-AURUM dataset will be used for external geographical validation. Both comprise a sizeable representative population and are linked at patient-level to secondary care databases. The performance of the deep learning models will be compared against classic machine learning and traditional statistical predictive modelling methods. We will only use risk factors accessible in primary care and endow the model with the ability to update risk prediction as it is presented with new data, to make the model more useful in clinical practice. Ethics and dissemination Permissions for CPRD-GOLD and CPRD-AURUM datasets were obtained from CPRD (ref no: 19_076). The CPRD ethical approval committee approved the study. The results will be submitted as a research paper for publication to a peer-reviewed journal and presented at peer-reviewed conferences. Trial registration details A systematic review to incorporate within the overall project was registered on PROSPERO (registration number CRD42021245093). The study was registered on ClinicalTrials.gov (NCT04657900).  © },
	author_keywords = {adult cardiology; cardiac epidemiology; health informatics; pacing & electrophysiology; primary care},
	keywords = {Artificial Intelligence; Atrial Fibrillation; Electronic Health Records; Humans; Precision Medicine; Stroke; Systematic Reviews as Topic; antidepressant agent; antihypertensive agent; anxiolytic agent; C reactive protein; creatinine; high density lipoprotein; hydroxymethylglutaryl coenzyme A reductase inhibitor; low density lipoprotein cholesterol; neuroleptic agent; triacylglycerol; alcohol consumption; anticoagulation; Article; artificial intelligence; artificial neural network; cardiovascular risk; clinical assessment; clinical practice; clinical protocol; convolutional neural network; deep learning; electronic health record; follow up; human; lifestyle modification; machine learning; medical record; natural language processing; new-onset atrial fibrillation; people by smoking status; personalized medicine; predictive value; primary medical care; primary prevention; recurrent neural network; risk factor; secondary health care; sedimentation; systematic review; time to treatment; artificial intelligence; atrial fibrillation; cerebrovascular accident; electronic health record; personalized medicine},
	correspondence_address = {R. Nadarajah; Leeds Institute for Data Analytics, University of Leeds, Leeds, United Kingdom; email: r.nadarajah@leeds.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34728455},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Goirand2021,
	author = {Goirand, Magali and Austin, Elizabeth and Clay-Williams, Robyn},
	title = {Implementing Ethics in Healthcare AI-Based Applications: A Scoping Review},
	year = {2021},
	journal = {Science and Engineering Ethics},
	volume = {27},
	number = {5},
	doi = {10.1007/s11948-021-00336-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114293903&doi=10.1007%2fs11948-021-00336-3&partnerID=40&md5=c1317e885f9c548f3004260ce7464678},
	affiliations = {Australian Institute of Health Innovation, Macquarie University, Sydney, Australia},
	abstract = {A number of Artificial Intelligence (AI) ethics frameworks have been published in the last 6 years in response to the growing concerns posed by the adoption of AI in different sectors, including healthcare. While there is a strong culture of medical ethics in healthcare applications, AI-based Healthcare Applications (AIHA) are challenging the existing ethics and regulatory frameworks. This scoping review explores how ethics frameworks have been implemented in AIHA, how these implementations have been evaluated and whether they have been successful. AI specific ethics frameworks in healthcare appear to have a limited adoption and they are mostly used in conjunction with other ethics frameworks. The operationalisation of ethics frameworks is a complex endeavour with challenges at different levels: ethics principles, design, technology, organisational, and regulatory. Strategies identified in this review are proactive, contextual, technological, checklist, organisational and/or evidence-based approaches. While interdisciplinary approaches show promises, how an ethics framework is implemented in an AI-based Healthcare Application is not widely reported, and there is a need for transparency for trustworthy AI. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {AI; Bioethics; Care robots; CDSS; Ethics; Healthcare; IAT; Machine learning},
	keywords = {Artificial Intelligence; Delivery of Health Care; Ethics, Medical; Organizations; Technology; artificial intelligence; health care delivery; medical ethics; organization; technology},
	correspondence_address = {M. Goirand; Australian Institute of Health Innovation, Macquarie University, Sydney, Australia; email: magali.goirandampaire@hdr.mq.edu.au},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13533452},
	pmid = {34480239},
	language = {English},
	abbrev_source_title = {Sci. Eng. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Sworna2021,
	author = {Sworna, Nabila Sabrin and Islam, A.K.M. Muzahidul and Shatabda, Swakkhar and Islam, Salekul},
	title = {Towards development of IoT-ML driven healthcare systems: A survey},
	year = {2021},
	journal = {Journal of Network and Computer Applications},
	volume = {196},
	doi = {10.1016/j.jnca.2021.103244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118509109&doi=10.1016%2fj.jnca.2021.103244&partnerID=40&md5=435c5b8dc68a45ac5c75a5b894058acf},
	affiliations = {United International University, United City, Madani Avenue, Badda, Dhaka, Dhaka, 1212, Bangladesh},
	abstract = {The impact of IoT-ML in the healthcare sector is very significant and it has helped us to change our view at the traditional treatment methods. In IoT-ML-based healthcare applications, the sensing layer is responsible for collecting information from humans and transferring it to the storage layer through communication technology. ML is implemented to make intelligent decisions for healthcare applications. This survey shows all the fields starting from the IoT sensor devices to the deployment of ML in the healthcare sector. We have conducted a comprehensive survey of the existing literature covering IoT and ML strategies from a healthcare perspective. We also provide insights into the different types of network storage and computing strategies used for other health-based applications. We believe that the presented work is innovative as no other survey is furnished in such manner. From this survey, researchers can get an overview of IoT-ML and cloud-based healthcare applications under the single system. We have proposed a unique taxonomy from an IoT-ML-based healthcare perspective where we have highlighted key steps in developing healthcare systems. We have culminated the most striking technologies in IoT, communications, network storage and computing, and ML for healthcare systems. Another contribution of our survey is that we have collected and discussed surveys and scientific literature based on the proposed taxonomy and their sub-taxonomy throughout this paper. Besides that we have reviewed several types of popularly used sensors, development boards in healthcare with various examples. We also show the mapping of communication technology with the protocols used by IoT sensors. In the ML section, we have shown an ML pipeline centering on healthcare application and discussed every step of it. Finally, we have identified a number of research challenges including exploration of Deep Learning based models, proper data acquisition and handling of data, privacy and ethics, security issues in WBAN, etc. These research challenges will provide the researchers the necessary future research directions while developing IoT-ML-based healthcare applications. © 2021 Elsevier Ltd},
	author_keywords = {Cloud computing; Communication; Healthcare applications; IoT; Machine learning; Taxonomy},
	keywords = {Data acquisition; Data handling; Deep learning; Digital storage; Health care; Internet of things; Surveys; Cloud-computing; Communicationtechnology; Health care application; Healthcare sectors; Healthcare systems; Network computing; Network storage; Research challenges; Sensing layers; Treatment methods; Taxonomies},
	correspondence_address = {A.K.M.M. Islam; United International University, United City, Dhaka, Madani Avenue, Badda, Dhaka, 1212, Bangladesh; email: muzahid@cse.uiu.ac.bd},
	publisher = {Academic Press},
	issn = {10848045},
	language = {English},
	abbrev_source_title = {J Network Comput Appl},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24}
}

@ARTICLE{Mathiesen2022251,
	author = {Mathiesen, Tiit and Broekman, Marike},
	title = {Machine Learning and Ethics},
	year = {2022},
	journal = {Acta Neurochirurgica, Supplementum},
	volume = {134},
	pages = {251 – 256},
	doi = {10.1007/978-3-030-85292-4_28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120918485&doi=10.1007%2f978-3-030-85292-4_28&partnerID=40&md5=ab68937b56d2b5e19e1cef0bba1f3630},
	affiliations = {Department of Neurosurgery, Copenhagen University Hospital, University of Copenhagen, Copenhagen, Denmark; Department of Clinical Medicine, Copenhagen University Hospital, University of Copenhagen, Copenhagen, Denmark; Department of Clinical Neuroscience, Karolinska Institutet, Stockholm, Stockholm, Sweden; Department of Neurosurgery, Leiden University Medical Center, Leiden, Zuid-Holland, Netherlands},
	abstract = {When new technology is introduced into healthcare, novel ethical dilemmas arise in the human-machine interface. As artificial intelligence (AI), machine learning (ML) and big data can exhaust human oversight and memory capacity, this will give rise to many of these new dilemmas. Technology has little if any ethical status but is inevitably interwoven with human activity and thus may serve to allow qualitative and quantitative disruption of human performance and interaction. We argue that personal integrity, justice of resource allocation and accountability of moral agency comprise three themes that characterize ethical dilemmas that arise with development and application of AI. These themes are important to address in parallel to further evolution of AI in health care for ethical practice of healthcare. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Ethics; Healthcare; Machine learning; Moral agency},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Machine Learning; Morals; Technology; artificial intelligence; clinical decision making; ethical dilemma; genetic code; health care delivery; health care management; human; identifiable information; information technology; investment; justice; machine learning; medical ethics; pattern recognition; professional ethics; resource allocation; sensitive personal information; social responsibility; treatment indication; morality; technology},
	correspondence_address = {T. Mathiesen; Department of Clinical Neuroscience, Karolinska Institutet, Stockholm, Stockholm, Sweden; email: tiit.illimar.mathiesen@regionh.dk},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {00651419},
	coden = {ANCSB},
	pmid = {34862548},
	language = {English},
	abbrev_source_title = {Acta Neurochir. Suppl.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Bellini20216963,
	author = {Bellini, Valentina and Valente, Marina and Rio, Paolo Del and Bignami, Elena},
	title = {Artificial intelligence in thoracic surgery: a narrative review},
	year = {2021},
	journal = {Journal of Thoracic Disease},
	volume = {13},
	number = {12},
	pages = {6963 – 6975},
	doi = {10.21037/jtd-21-761},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122582090&doi=10.21037%2fjtd-21-761&partnerID=40&md5=81f0543da214d937d5cab12319d2dcce},
	affiliations = {Anesthesiology, Critical Care and Pain Medicine Division, Department of Medicine and Surgery, University of Parma, Parma, Italy; General Surgery Unit, Department of Medicine and Surgery, University of Parma, Parma, Italy},
	abstract = {Objective: The aim of this article is to review the current applications of artificial intelligence in thoracic surgery, from diagnosis and pulmonary disease management, to preoperative risk-assessment, surgical planning, and outcomes prediction. Background: Artificial intelligence implementation in healthcare settings is rapidly growing, though its widespread use in clinical practice is still limited. The employment of machine learning algorithms in thoracic surgery is wide-ranging, including all steps of the clinical pathway. Methods: We performed a narrative review of the literature on Scopus, PubMed and Cochrane databases, including all the relevant studies published in the last ten years, until March 2021. Conclusion: Machine learning methods are promising encouraging results throughout the key issues of thoracic surgery, both clinical, organizational, and educational. Artificial intelligence-based technologies showed remarkable efficacy to improve the perioperative evaluation of the patient, to assist the decision-making process, to enhance the surgical performance, and to optimize the operating room scheduling. Still, some concern remains about data supply, protection, and transparency, thus further studies and specific consensus guidelines are needed to validate these technologies for daily common practice. © Journal of Thoracic Disease. All rights reserved.},
	author_keywords = {Artificial intelligence (AI); Lung resection; Machine learning; Perioperative medicine; Thoracic surgery},
	keywords = {artificial intelligence; clinical pathway; histopathology; human; legal aspect; lung nodule; lung resection; machine learning; medical ethics; outcome assessment; prediction; preoperative evaluation; prognosis; Review; risk assessment; thorax surgery; treatment planning},
	correspondence_address = {E. Bignami; Anesthesiology, Critical Care and Pain Medicine Division, Department of Medicine and Surgery, University of Parma, Parma, Viale Gramsci 14, 43126, Italy; email: elenagiovanna.bignami@unipr.it},
	publisher = {AME Publishing Company},
	issn = {20721439},
	language = {English},
	abbrev_source_title = {J. Thorac. Dis.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{McCradden2021e615,
	author = {McCradden, Melissa D and Chad, Lauren},
	title = {Screening for facial differences worldwide: equity and ethics},
	year = {2021},
	journal = {The Lancet Digital Health},
	volume = {3},
	number = {10},
	pages = {e615 – e616},
	doi = {10.1016/S2589-7500(21)00179-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117431571&doi=10.1016%2fS2589-7500%2821%2900179-5&partnerID=40&md5=6d1423afddc11e81964bbc452603b03f},
	affiliations = {Department of Bioethics, The Hospital for Sick Children, Toronto, ON, Canada; Division of Clinical and Metabolic Genetics, The Hospital for Sick Children, Toronto, ON, Canada; Division of Clinical & Public Health, Dalla Lana School of Public Health, Toronto, ON, Canada; Genetics & Genome Biology, Peter Gilgan Centre for Research and Learning, Toronto, ON, Canada; Department of Pediatrics, University of Toronto, ON, Canada},
	keywords = {Health Equity; Mass Screening; Research; African; artificial intelligence; Asian; consultation; diagnostic accuracy; diagnostic test; face malformation; genetic disorder; genetic screening; health care access; health equity; health promotion; Hispanic; human; machine learning; medical ethics; medical expert; medical technology; Note; phenotype; photography; population genetics; prediction; sensitivity and specificity; teratology; mass screening; research},
	publisher = {Elsevier Ltd},
	issn = {25897500},
	pmid = {34481766},
	language = {English},
	abbrev_source_title = {Lancet Digit. Heal.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Bright2021424,
	author = {Bright, Laura F. and Sussman, Kristen Leah and Wilcox, Gary B.},
	title = {Reaching the tipping point: A critical analysis of the #deletefacebook movement},
	year = {2021},
	journal = {Journal of Data Protection and Privacy},
	volume = {4},
	number = {4},
	pages = {424 – 435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128889739&partnerID=40&md5=e35fac0120e49cba84c24d21025d38fa},
	affiliations = {Stan Richards School of Advertising and Public Relations, Moody College of Communication, University Station, A1200, Austin, 78712, TX, United States},
	abstract = {Social media platforms have sustained increased scrutiny for their data management practices, spread of misinformation and the creation of consumer echo chambers. Chief among these platforms is Facebook. Yet, consumption of Facebook continues to grow. To understand this paradox, we use a dataset of unstructured text data to identify patterns within user-generated content (UGC) using the #deletefacebook hashtag. Nearly 1.5 million observations were used to identify themes and help paint a picture of the broader consumer concern relating to Facebook. The results show a continuing interest in the #deletefacebook topic as measured by volume over time. Using machine learning techniques, the text miner results identified topics which include privacy, consumer trust and wellbeing and politics of data security. Fear of missing out (FoMO) is provided as a theoretical explanation for why people continue using social media sites like Facebook. Themes related to social media fatigue, data management and ethics were also found in the UGC. © 2021, Henry Stewart Publications. All rights reserved.},
	author_keywords = {Computational social science; Facebook; Language; Natural language processing; Social media consumption; Social media usage; User-generated content},
	publisher = {Henry Stewart Publications},
	issn = {23981679},
	language = {English},
	abbrev_source_title = {J. Data. Prot. Priv.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rabbani2022381,
	author = {Rabbani, Mustafa Raza and Sarea, Adel and Khan, Shahnawaz and Abdullah, Yomna},
	title = {Ethical Concerns in Artificial Intelligence (AI): The Role of RegTech and Islamic Finance},
	year = {2022},
	journal = {Lecture Notes in Networks and Systems},
	volume = {423 LNNS},
	pages = {381 – 390},
	doi = {10.1007/978-3-030-93464-4_38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124120026&doi=10.1007%2f978-3-030-93464-4_38&partnerID=40&md5=ec89659d9f2f04242d45425741a7d924},
	affiliations = {College of Business Administration, University of Bahrain, Zallaq, Bahrain; Ahlia University, Manama, Bahrain; University College of Bahrain, Saar, Bahrain},
	abstract = {Artificial Intelligence (AI) is being applied across all areas of business and society. It is also one of the most researched topics during the current period. Banks and financial institutions nowadays are collecting large amounts of customer information which are imposed with AI and machine learning; however, the succeeding of all information remains unknown. This study attempts to identify the ethical issues in the application of Artificial intelligence and offers remedies from the Shariah principles. It also examines the role of Regulation technology (RegTech) in Islamic financial institutions. This study is exploratory in nature and used mainly primary data for the analysis purpose. The primary data is collected through the structured questionnaire obtained from the sharia scholars living in Gulf Cooperation Council (GCC) countries. The findings of the study suggest that the there is a significant relationship between ethical issues in AI implementation, role of RegTech and Islamic finance. The findings also suggest that the effective and intelligent utilization of RegTech and Islamic finance tools can reduce the ethical concern related to the AI implementation. © 2022, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Ethical issues; Ethics; Islamic finance},
	correspondence_address = {A. Sarea; Ahlia University, Manama, Bahrain; email: adelsarea@yahoo.com},
	editor = {Musleh Al-Sartawi A.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303093463-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: International Conference on Global Economic Revolutions, ICGER 2021; Conference date: 15 September 2021 through 16 September 2021; Conference code: 271469}
}

@ARTICLE{Maas20231493,
	author = {Maas, Jonne},
	title = {Machine learning and power relations},
	year = {2023},
	journal = {AI and Society},
	volume = {38},
	number = {4},
	pages = {1493 – 1500},
	doi = {10.1007/s00146-022-01400-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125251069&doi=10.1007%2fs00146-022-01400-7&partnerID=40&md5=b17546bf9d0efa84b7af18549b82c36b},
	affiliations = {Department: Technology, Policy, and Management, Delft University of Technology, Delft, Netherlands},
	abstract = {There has been an increased focus within the AI ethics literature on questions of power, reflected in the ideal of accountability supported by many Responsible AI guidelines. While this recent debate points towards the power asymmetry between those who shape AI systems and those affected by them, the literature lacks normative grounding and misses conceptual clarity on how these power dynamics take shape. In this paper, I develop a workable conceptualization of said power dynamics according to Cristiano Castelfranchi’s conceptual framework of power and argue that end-users depend on a system’s developers and users, because end-users rely on these systems to satisfy their goals, constituting a power asymmetry between developers, users and end-users. I ground my analysis in the neo-republican moral wrong of domination, drawing attention to legitimacy concerns of the power-dependence relation following from the current lack of accountability mechanisms. I illustrate my claims on the basis of a risk-prediction machine learning system, and propose institutional (external auditing) and project-specific solutions (increase contestability through design-for-values approaches) to mitigate domination. © 2022, The Author(s).},
	author_keywords = {AI design; Design-for-values; Domination; Machine learning; Power relations; Responsible AI},
	keywords = {Ethical technology; AI design; Design for values; Domination; End-users; Learning relations; Machine-learning; Power; Power dynamics; Power relations; Responsible AI; Machine learning},
	correspondence_address = {J. Maas; Department: Technology, Policy, and Management, Delft University of Technology, Delft, Netherlands; email: j.j.c.maas@tudelft.nl},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Valim2021,
	author = {Valim, Clarissa and Olatunji, Yekin Ajauoi and Isa, Yasir Shitu and Salaudeen, Rasheed and Golam, Sarwar and Knol, Edward F and Kanyi, Sheriffo and Jammeh, Abdoulie and Bassat, Quique and De Jager, Wilco and Diaz, Alejandro A and Wiegand, Roger C and Ramirez, Julio and Moses, Marsha A and D'Alessandro, Umberto and Hibberd, Patricia L and MacKenzie, Grant A},
	title = {Seeking diagnostic and prognostic biomarkers for childhood bacterial pneumonia in sub-Saharan Africa: Study protocol for an observational study},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {9},
	doi = {10.1136/bmjopen-2020-046590},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116545275&doi=10.1136%2fbmjopen-2020-046590&partnerID=40&md5=021e2aaa1c708ccdc46e7d07258e53ed},
	affiliations = {Department of Global Health, Boston University, School of Public Health, Boston, MA, United States; Medical Research Council Unit, Gambia at the London School of Hygiene and Tropical Medicine, Fajara, Gambia; Center of Translational Immunology, Department of Rheumatology and Clinical Immunology, University Medical Center Utrecht, Utrecht, Netherlands; Bansang Hospital, Bansang, Gambia; Basse Hospital, Basse, Gambia; Hospital Clínic, Universitat de Barcelona, ISGlobal, Barcelona, Spain; Centro de Investigação em Saúde de Manhiça (CISM), Maputo, Mozambique; Luminex Corp, Austin, TX, United States; Department of Medicine, Harvard Medical School, Boston, MA, United States; Division of Pulmonary and Critical Care Medicine, Brigham and Women's Hospital, Boston, MA, United States; Independent Researcher, Boston, MA, United States; Division of Infectious Diseases, University of Louisville, Louisville, KY, United States; Vascular Biology Program, Children's Hospital Boston, Boston, MA, United States; Department of Surgery, Harvard Medical School, Boston, MA, United States; Disease Elimination and Control, Medical Research Council Unit, Fajara, Gambia; London School of Hygiene and Tropical Medicine, London, United Kingdom; Boston University School of Public Health, Boston, MA, United States; Department of Disease Control, Faculty of Infectious and Tropical Diseases, London School of Hygiene and Tropical Medicine, London, United Kingdom},
	abstract = {Introduction Clinically diagnosed pneumonia in children is a leading cause of paediatric hospitalisation and mortality. The aetiology is usually bacterial or viral, but malaria can cause a syndrome indistinguishable from clinical pneumonia. There is no method with high sensitivity to detect a bacterial infection in these patients and, as result, antibiotics are frequently overprescribed. Conversely, unrecognised concomitant bacterial infection in patients with malarial infections occur with omission of antibiotic therapy from patients with bacterial infections. Previously, we identified two combinations of blood proteins with 96% sensitivity and 86% specificity for detecting bacterial disease. The current project aimed to validate and improve these combinations by evaluating additional biomarkers in paediatric patients with clinical pneumonia. Our goal was to describe combinations of a limited number of proteins with high sensitivity and specificity for bacterial infection to be incorporated in future point-of-care tests. Furthermore, we seek to explore signatures to prognosticate clinical pneumonia. Methods and analysis Patients (n=900) aged 2-59 months presenting with clinical pneumonia at two Gambian hospitals will be enrolled and classified according to criteria for definitive bacterial aetiology (based on microbiological tests and chest radiographs). We will measure proteins at admission using Luminex-based immunoassays in 90 children with definitive and 160 with probable bacterial aetiology, and 160 children classified according to the prognosis of their disease. Previously identified diagnostic signatures will be assessed through accuracy measures. Moreover, we will seek new diagnostic and prognostic signatures through machine learning methods, including support vector machine, penalised regression and classification trees. Ethics and dissemination Ethics approval has been obtained from the Gambia Government/Medical Research Council Unit The Gambia Joint Ethics Committee (protocol 1616) and the institutional review board of Boston University Medical Centre (STUDY00000958). Study results will be disseminated to the staff of the study hospitals, in scientific seminars and meetings, and in publications. Trial registration number H-38462.  © Author(s) (or their employer(s)) 2021.},
	author_keywords = {diagnostic microbiology; paediatric infectious disease & immunisation; paediatric thoracic medicine; respiratory infections},
	keywords = {Africa South of the Sahara; Anti-Bacterial Agents; Biomarkers; Child; Humans; Observational Studies as Topic; Pneumonia, Bacterial; Prognosis; biological marker; plasma protein; antiinfective agent; biological marker; Africa south of the Sahara; antibiotic therapy; bacterial pneumonia; child; childhood disease; classification; controlled study; deterioration; diagnosis related group; follow up; hospital admission; hospital readmission; human; immunoassay; infant; machine learning; major clinical study; malaria; observational study; oxygen saturation; oxygen therapy; point of care testing; prognosis; Review; sensitivity and specificity; support vector machine; thorax radiography; virus infection; bacterial pneumonia},
	correspondence_address = {C. Valim; Department of Global Health, Boston University, School of Public Health, Boston, United States; email: cvalim@bu.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34593486},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{de Boer2021245,
	author = {de Boer, Bas and Kudina, Olya},
	title = {What is morally at stake when using algorithms to make medical diagnoses? Expanding the discussion beyond risks and harms},
	year = {2021},
	journal = {Theoretical Medicine and Bioethics},
	volume = {42},
	number = {5-6},
	pages = {245 – 266},
	doi = {10.1007/s11017-021-09553-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122260005&doi=10.1007%2fs11017-021-09553-0&partnerID=40&md5=c9301c45ef13e0a5164f3868f832ceb4},
	affiliations = {University of Twente, Enschede, Netherlands; Technische Universiteit Delft, Delft, Netherlands},
	abstract = {In this paper, we examine the qualitative moral impact of machine learning-based clinical decision support systems in the process of medical diagnosis. To date, discussions about machine learning in this context have focused on problems that can be measured and assessed quantitatively, such as by estimating the extent of potential harm or calculating incurred risks. We maintain that such discussions neglect the qualitative moral impact of these technologies. Drawing on the philosophical approaches of technomoral change and technological mediation theory, which explore the interplay between technologies and morality, we present an analysis of concerns related to the adoption of machine learning-aided medical diagnosis. We analyze anticipated moral issues that machine learning systems pose for different stakeholders, such as bias and opacity in the way that models are trained to produce diagnoses, changes to how health care providers, patients, and developers understand their roles and professions, and challenges to existing forms of medical legislation. Albeit preliminary in nature, the insights offered by the technomoral change and the technological mediation approaches expand and enrich the current discussion about machine learning in diagnostic practices, bringing distinct and currently underexplored areas of concern to the forefront. These insights can contribute to a more encompassing and better informed decision-making process when adapting machine learning techniques to medical diagnosis, while acknowledging the interests of multiple stakeholders and the active role that technologies play in generating, perpetuating, and modifying ethical concerns in health care. © 2022, The Author(s).},
	author_keywords = {Algorithms; Ethics; Machine learning; Medical diagnosis; Technological mediation; Technomoral change},
	keywords = {adoption; adult; algorithm; article; clinical decision support system; diagnosis; drawing; ethics; health care personnel; human; machine learning; medicolegal aspect; morality; neglect; quantitative analysis; risk assessment; theoretical study},
	correspondence_address = {B. de Boer; University of Twente, Enschede, Netherlands; email: s.o.m.deboer@utwente.nl},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13867415},
	coden = {TMBIF},
	pmid = {34978638},
	language = {English},
	abbrev_source_title = {Theor. Med. Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Majam2021,
	author = {Majam, Mohammed and Phatsoane, Mothepane and Hanna, Keith and Faul, Charles and Arora, Lovkesh and Makthal, Sarvesh and Kumar, Akhil and Jois, Kashyap and Lalla-Edward, Samanta Tresha},
	title = {Utility of a machine-guided tool for assessing risk behavior associated with contracting HIV in three sites in South Africa: Protocol for an in-field evaluation},
	year = {2021},
	journal = {JMIR Research Protocols},
	volume = {10},
	number = {12},
	doi = {10.2196/30304},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120969347&doi=10.2196%2f30304&partnerID=40&md5=b9f1c712029838ce694f715d27f3500f},
	affiliations = {Ezintsha, Faculty of Health Sciences, University of Witswatersrand, Johannesburg, South Africa; IPRD Solutions, New York, NY, United States},
	abstract = {Background: Mobile technology has helped to advance health programs, and studies have shown that an automated risk prediction model can successfully be used to identify patients who exhibit a high probable risk of contracting human immunodeficiency virus (HIV). A machine-guided tool is an algorithm that takes a set of subjective and objective answers from a simple questionnaire and computes an HIV risk assessment score. Objective: The primary objective of this study is to establish that machine learning can be used to develop machine-guided tools and give us a deeper statistical understanding of the correlation between certain behavioral patterns and HIV. Methods: In total, 200 HIV-negative adult individuals across three South African study sites each (two semirural and one urban) will be recruited. Study processes will include (1) completing a series of questions (demographic, sexual behavior and history, personal, lifestyle, and symptoms) on an application system, unaided (assistance will only be provided upon user request); (2) two HIV tests (one per study visit) being performed by a nurse/counselor according to South African national guidelines (to evaluate the prediction accuracy of the tool); and (3) communicating test results and completing a user experience survey questionnaire. The output metrics for this study will be computed by using the participants’ risk assessment scores as “predictions” and the test results as the “ground truth.” Analyses will be completed after visit 1 and then again after visit 2. All risk assessment scores will be used to calculate the reliability of the machine-guided tool. Results: Ethical approval was received from the University of Witwatersrand Human Research Ethics Committee (HREC; ethics reference no. 200312) on August 20, 2020. This study is ongoing. Data collection has commenced and is expected to be completed in the second half of 2021. We will report on the machine-guided tool’s performance and usability, together with user satisfaction and recommendations for improvement. Conclusions: Machine-guided risk assessment tools can provide a cost-effective alternative to large-scale HIV screening and help in providing targeted counseling and testing to prevent the spread of HIV. Trial Registration: South African National Clinical Trial Registry DOH-27-042021-679; https://sanctr.samrc.ac.za/TrialDisplay.aspx?TrialID=5545 International Registered Report Identifier (IRRID): DERR1-10.2196/30304 ©Mohammed Majam, Mothepane Phatsoane, Keith Hanna, Charles Faul, Lovkesh Arora, Sarvesh Makthal, Akhil Kumar, Kashyap Jois, Samanta Tresha Lalla-Edward.},
	author_keywords = {Algorithm; HIV; HIV status; Machine learning; Modeling; Predictive risk; Risk assessment; South Africa},
	correspondence_address = {S.T. Lalla-Edward; Ezintsha Faculty of Health Sciences, University of Witswatersrand, Princess of Wales Terrace, Johannesburg, Sunnyside Office Park 31, 2193, South Africa; email: slallaedward@ezintsha.org},
	publisher = {JMIR Publications Inc.},
	issn = {19290748},
	language = {English},
	abbrev_source_title = {JMIR Res. Prot.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tozzo2021527,
	author = {Tozzo, P. and Angiola, F. and Gabbin, A. and Politi, C. and Caenazzo, L.},
	title = {The difficult role of Artificial Intelligence in Medical Liability: To err is not only human},
	year = {2021},
	journal = {Clinica Terapeutica},
	volume = {172},
	number = {6},
	pages = {527 – 528},
	doi = {10.7417/CT.2021.2372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121821493&doi=10.7417%2fCT.2021.2372&partnerID=40&md5=f24fa9fcd32dd03b1793a7a636bc959d},
	affiliations = {Department of Molecular Medicine, Legal Medicine Unit, University of Padova, Padova, Italy; Department of Cardiac Thoracic Vascular Sciences and Public Health, University of Padova, Padova, Italy},
	abstract = {The entrance of Artificial Intelligence (AI) as a new actor in the doctor-patient relationship has encouraged important legal and ethical considerations among the experts. On the one hand, there is the request to establish a new and dedicated legal background involving AI and AI-related technologies, while others believe there is no need to add new laws in the attempt to define AI's role in healthcare. The aim of this paper is to analyse the possible role of AI in civil liability in healthcare practice, underlining its limits of autonomy in a field where the attribution of liability cannot be uncertain. © 2021 Societa Editrice Universo. All rights reserved.},
	author_keywords = {Artificial Intelligence; Machine learning; Medical liability; Medical responsibility},
	keywords = {Artificial Intelligence; Humans; Liability, Legal; Physician-Patient Relations; article; artificial intelligence; health care practice; human; machine learning; medical ethics; medical liability; doctor patient relationship; legal liability},
	correspondence_address = {P. Tozzo; Department of Molecular Medicine, Legal Medicine Unit, University of Padova, Padova, Italy; email: pamela.tozzo@unipd.it},
	publisher = {Societa Editrice Universo},
	issn = {00099074},
	coden = {CLTEA},
	pmid = {34821346},
	language = {English},
	abbrev_source_title = {Clin. Ter.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Abdul Rashid2021,
	author = {Abdul Rashid, Nur Amirah and Martanto, Wijaya and Yang, Zixu and Wang, Xuancong and Heaukulani, Creighton and Vouk, Nikola and Buddhika, Thisum and Wei, Yuan and Verma, Swapna and Tang, Charmaine and Morris, Robert J T and Lee, Jimmy},
	title = {Evaluating the utility of digital phenotyping to predict health outcomes in schizophrenia: Protocol for the HOPE-S observational study},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {10},
	doi = {10.1136/bmjopen-2020-046552},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118274477&doi=10.1136%2fbmjopen-2020-046552&partnerID=40&md5=041681805639c6226b8fb6f5bb138816},
	affiliations = {Research Division, Institute of Mental Health, Singapore, Singapore; Office for Healthcare Transformation, Ministry of Health, Singapore, Singapore; Singapore Clinical Research Institute, Singapore, Singapore; East Region and Department of Psychosis, Institute of Mental Health, Singapore, Singapore; Duke-NUS Medical School, Singapore, Singapore; North Region and Department of Psychosis, Institute of Mental Health, Singapore, Singapore; Yong Loo Lin School of Medicine, National University of Singapore, Singapore, Singapore; Neuroscience and Mental Health, Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore, Singapore},
	abstract = {Introduction The course of schizophrenia illness is characterised by recurrent relapses which are associated with adverse clinical outcomes such as treatment-resistance, functional and cognitive decline. Early identification is essential and relapse prevention remains a primary treatment goal for long-term management of schizophrenia. With the ubiquity of devices such as smartphones, objective digital biomarkers can be harnessed and may offer alternative means for symptom monitoring and relapse prediction. The acceptability of digital sensors (smartphone and wrist-wearable device) and the association between the captured digital data with clinical and health outcomes in individuals with schizophrenia will be examined. Methods and analysis In this study, we aim to recruit 100 individuals with schizophrenia spectrum disorders who are recently discharged from the Institute of Mental Health (IMH), Singapore. Participants are followed up for 6 months, where digital, clinical, cognitive and functioning data are collected while health utilisation data are obtained at the 6 month and 1 year timepoint from study enrolment. Associations between digital, clinical and health outcomes data will be examined. A data-driven machine learning approach will be used to develop prediction algorithms to detect clinically significant outcomes. Study findings will inform the design, data collection procedures and protocol of future interventional randomised controlled trial, testing the effectiveness of digital phenotyping in clinical management of individuals with schizophrenia spectrum disorders. Ethics and dissemination Ethics approval has been granted by the National Healthcare Group (NHG) Domain Specific Review Board (DSRB Reference no.: 2019/00720). The results will be published in peer-reviewed journals and presented at conferences. Trial registration number NCT04230590. © Author(s) (or their employer(s)) 2021.},
	author_keywords = {mental health; psychiatry; schizophrenia & psychotic disorders},
	keywords = {Humans; Mental Health; Observational Studies as Topic; Outcome Assessment, Health Care; Schizophrenia; Smartphone; Wearable Electronic Devices; adult; Article; clinical effectiveness; clinical outcome; cognition; controlled study; female; follow up; geography; human; machine learning; major clinical study; male; observational study; phenotype; physical activity; randomized controlled trial; schizophrenia; Singapore; sleep; electronic device; mental health; smartphone},
	correspondence_address = {J. Lee; North Region and Department of Psychosis, Institute of Mental Health, Singapore, Singapore; email: jimmy_lee@imh.com.sg},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34670760},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Xu2022,
	author = {Xu, Zheng and Zhu, Guiyan and Metawa, Noura and Zhou, Qingyuan},
	title = {Machine learning based customer meta-combination brand equity analysis for marketing behavior evaluation},
	year = {2022},
	journal = {Information Processing and Management},
	volume = {59},
	number = {1},
	doi = {10.1016/j.ipm.2021.102800},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118151715&doi=10.1016%2fj.ipm.2021.102800&partnerID=40&md5=af8a9186024a3186c30d4aaba7802ba1},
	affiliations = {School of Computer and Information Engineering, Shanghai Polytechnic University, 2360 JinHai Road, Pudong District, 201209, Shanghai, China; School of Economics, Management and Law, Hubei Normal University, HuangshiHubei, 435002, China; College of Business Administration, University of Sharjah, Sharjah, United Arab Emirates; Faculty of Commerce, Mansoura University, Mansoura, Egypt; School of Economics and Management, Changzhou Vocational Institute of Mechatronic Technology, Changzhou, 213001, China; The Institute for Industrial Economy of Intelligent Manufacturing, Changzhou, 213001, China},
	abstract = {At present, the focus of marketing research is mostly on the influencing factors, composition, and measurement of brand equity. The meta-combined brand equity analysis is based on two main research perspectives: financial perspective and customer perspective. While the financial perspective is based on the incremental discounted future cash flows that would result from a branded product's revenue over the revenue of an unbranded product, the brand equity from the customer's perspective is the consumer's reaction to brand marketing behavior, the impact on brand knowledge. The decision-making of marketing behaviors often faces choices related to ethics. Therefore, once the moral value of a company through marketing behavior is recognized by consumers, the ethical behavior presented in this article through marketing behavior will make consumers feel more about the brand. How does the brand equity of your customer's products affect you? In this experiment, shopping groups with the same shopping experience were selected. During the survey process, all customers in different periods and the same time were selected as far as possible based on the practicability of the survey. The study survey covered 4 main aspects; customer satisfaction, overall overview of customer satisfaction; the advantages and disadvantages of marketing strategies through quantitative analysis and to put forward reasonable marketing strategy improvement opinions and suggestions to improve customer satisfaction. Using the technique of parameter prediction of the financial industry, the experiment proved that the non-standard promotion behavior, the integrity of the enterprise and the social responsibility are three aspects (P<0.05) that have an impact on the customer's brand equity among the corporate marketing components. It was a detailed study of the current state of brand marketing strategies and customer satisfaction, found key indicators of brands that could improve customer satisfaction, and presented corresponding suggestions for optimizing marketing strategies. It shows that. It has the importance of good guidance and references to improve customer satisfaction in the industry. © 2021},
	author_keywords = {Big Data; Brand equity; Brand marketing; Factor Analysis; Machine learning; Meta-combined approach},
	keywords = {Big data; Consumer behavior; Customer satisfaction; Decision making; Finance; Philosophical aspects; Sales; Strategic planning; Surveys; Behavior evaluations; Brand equity; Brand marketing; Customer perspectives; Customers' satisfaction; Equity analysis; Factors analysis; Marketing research; Marketing strategy; Meta-combined approach; Machine learning},
	correspondence_address = {G. Zhu; School of Economics, Management and Law, Hubei Normal University, HuangshiHubei, 435002, China; email: tom_zhu@alumni.hust.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {03064573},
	coden = {IPMAD},
	language = {English},
	abbrev_source_title = {Inf. Process. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 48}
}

@ARTICLE{Shelley2022,
	author = {Shelley, Cameron},
	title = {The Fairness Impact Assessment: Conceptualizing Problems of Fairness in Technological Design},
	year = {2022},
	journal = {International Journal of Technoethics},
	volume = {13},
	number = {1},
	doi = {10.4018/IJT.291554},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124670635&doi=10.4018%2fIJT.291554&partnerID=40&md5=48ca1b61645baf508528a33f481c57ef},
	affiliations = {University of Waterloo, Canada},
	abstract = {As modern life becomes ever more mediated by technology, technology assessment becomes ever more important. Tools that help to anticipate and evaluate social impacts of technological designs are crucial to understanding this relationship. This paper presents an assessment tool called the fairness impact assessment (FIA). For present purposes, fairness refers to conflicts of interest between social groups that result from the configuration of technological designs. In these situations, designs operate in a way such that advantages they provide to one social group impose disadvantages on another. The FIA helps to make clear the nature of these conflicts and possibilities for their resolution. As a broad, qualitative framework, the FIA can be applied more generally than specifically quantitative frameworks currently being explored in the field of machine learning. Though not a formula for solving difficult social issues, the FIA provides a systematic means for the investigation of fairness problems in technology design that are otherwise not always well understood or addressed. Copyright © 2022, IGI Global.},
	author_keywords = {Assessment; Design; Equity; Ethics; Fairness; Risk},
	keywords = {Economic and social effects; Ethical technology; Social aspects; Assessment; Assessment tool; Conflicts of interest; Equity; Fairness; Impact assessments; Situation design; Social groups; Social impact; Technology assessments; Risk assessment},
	publisher = {IGI Global},
	issn = {19473451},
	language = {English},
	abbrev_source_title = {Int. J. Technoethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Eickhoff20211140,
	author = {Eickhoff, Simon B. and Heinrichs, Bert},
	title = {The predictable human: Possibilities and risks of AI-based prediction of cognitive abilities, personality traits and mental illnesses; [Der vorhersagbare Mensch: Chancen und Risiken der KI-basierten Prädiktion von kognitiven Fähigkeiten, Persönlichkeitsmerkmalen und psychischen Erkrankungen]},
	year = {2021},
	journal = {Nervenarzt},
	volume = {92},
	number = {11},
	pages = {1140 – 1148},
	doi = {10.1007/s00115-021-01197-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116299012&doi=10.1007%2fs00115-021-01197-8&partnerID=40&md5=70c9ca7def72b4cd5374c9aaa274b1ce},
	affiliations = {Institut für Neurowissenschaften und Medizin: Gehirn und Verhalten (INM-7), Forschungszentrum Jülich, Jülich, 52425, Germany; Institut für Systemische Neurowissenschaften, Medizinische Fakultät, Heinrich-Heine-Universität Düsseldorf, Düsseldorf, Germany; Institut für Neurowissenschaften und Medizin: Ethik in den Neurowissenschaften (INM-8), Forschungszentrum Jülich, Jülich, 52425, Germany; Institut für Wissenschaft und Ethik (IWE), Universität Bonn, Bonner Talweg 57, Bonn, 53113, Germany},
	abstract = {New approaches to the use of artificial intelligence (AI) to analyze data from neuroimaging but also passively collected data from so-called wearables, such as smartphones or smartwatches, as well as data that can be extracted from social media and other online activities, already make it possible to predict cognitive abilities, personality traits, and mental illnesses, as well as to reveal acute mental states. In this article, we explain the methodological concepts behind these current developments, illuminate the possibilities and limitations, and address ethical and social aspects arising from the use. © 2021, Springer Medizin Verlag GmbH, ein Teil von Springer Nature.},
	author_keywords = {Biomarker; Ethics; Machine learning; Precision medicine; Prediction},
	keywords = {Artificial Intelligence; Cognition; Humans; Mental Disorders; Personality; Social Media; artificial intelligence; cognition; human; medical ethics; mental disease; personality; Review; risk assessment; social aspect; artificial intelligence; cognition; mental disease; personality; social media},
	correspondence_address = {S.B. Eickhoff; Institut für Neurowissenschaften und Medizin: Gehirn und Verhalten (INM-7), Forschungszentrum Jülich, Jülich, 52425, Germany; email: s.eickhoff@fz-juelich.de},
	publisher = {Springer Medizin},
	issn = {00282804},
	coden = {NERVA},
	pmid = {34608537},
	language = {German},
	abbrev_source_title = {Nervenarzt},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Kostick-Quenet202292,
	author = {Kostick-Quenet, Kristin M. and Cohen, I Glenn and Gerke, Sara and Lo, Bernard and Antaki, James and Movahedi, Faezah and Njah, Hasna and Schoen, Lauren and Estep, Jerry E. and Blumenthal-Barby, J.S.},
	title = {Mitigating Racial Bias in Machine Learning},
	year = {2022},
	journal = {The Journal of law, medicine & ethics : a journal of the American Society of Law, Medicine & Ethics},
	volume = {50},
	number = {1},
	pages = {92 – 100},
	doi = {10.1017/jme.2022.13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125692193&doi=10.1017%2fjme.2022.13&partnerID=40&md5=ec6f65880e088336a12290724f659d3e},
	abstract = {When applied in the health sector, AI-based applications raise not only ethical but legal and safety concerns, where algorithms trained on data from majority populations can generate less accurate or reliable results for minorities and other disadvantaged groups.},
	author_keywords = {Algorithmic Bias; Artificial Intelligence; Ethics; Machine Learning; Racial Bias},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Racism; artificial intelligence; human; machine learning; racism},
	publisher = {NLM (Medline)},
	issn = {1748720X},
	pmid = {35243993},
	language = {English},
	abbrev_source_title = {J Law Med Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Coghlan20211581,
	author = {Coghlan, Simon and Miller, Tim and Paterson, Jeannie},
	title = {Good Proctor or “Big Brother”? Ethics of Online Exam Supervision Technologies},
	year = {2021},
	journal = {Philosophy and Technology},
	volume = {34},
	number = {4},
	pages = {1581 – 1606},
	doi = {10.1007/s13347-021-00476-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114670734&doi=10.1007%2fs13347-021-00476-1&partnerID=40&md5=56da680d7338be9b519479c251adb531},
	affiliations = {School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia; Centre for AI and Digital Ethics (CAIDE), The University of Melbourne, Melbourne, Australia; Melbourne Law School, The University of Melbourne, Melbourne, Australia},
	abstract = {Online exam supervision technologies have recently generated significant controversy and concern. Their use is now booming due to growing demand for online courses and for off-campus assessment options amid COVID-19 lockdowns. Online proctoring technologies purport to effectively oversee students sitting online exams by using artificial intelligence (AI) systems supplemented by human invigilators. Such technologies have alarmed some students who see them as a “Big Brother-like” threat to liberty and privacy, and as potentially unfair and discriminatory. However, some universities and educators defend their judicious use. Critical ethical appraisal of online proctoring technologies is overdue. This essay provides one of the first sustained moral philosophical analyses of these technologies, focusing on ethical notions of academic integrity, fairness, non-maleficence, transparency, privacy, autonomy, liberty, and trust. Most of these concepts are prominent in the new field of AI ethics, and all are relevant to education. The essay discusses these ethical issues. It also offers suggestions for educational institutions and educators interested in the technologies about the kinds of inquiries they need to make and the governance and review processes they might need to adopt to justify and remain accountable for using online proctoring technologies. The rapid and contentious rise of proctoring software provides a fruitful ethical case study of how AI is infiltrating all areas of life. The social impacts and moral consequences of this digital technology warrant ongoing scrutiny and study. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {Artificial intelligence; Ethics; Machine learning; Online assessment; Proctoring; Universities},
	correspondence_address = {S. Coghlan; School of Computing and Information Systems, The University of Melbourne, Melbourne, Australia; email: simon.coghlan@unimelb.edu.au},
	publisher = {Springer Science and Business Media B.V.},
	issn = {22105433},
	language = {English},
	abbrev_source_title = {Philos. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Chen2021,
	author = {Chen, Xin and Ye, Guofang and Zhong, Yuxin and Jin, Ling and Liang, Xiaoling and Zeng, Yangfa and Zheng, Yingfeng and Lan, Morgan and Liu, Yizhi},
	title = {Prevalence, incidence, and risk factors for myopia among urban and rural children in southern China: Protocol for a school-based cohort study},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {11},
	doi = {10.1136/bmjopen-2021-049846},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118829909&doi=10.1136%2fbmjopen-2021-049846&partnerID=40&md5=ff1193ccc01a4ac948168ad724edf979},
	affiliations = {State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China; Guangzhou Regenerative Medicine and Health Guangdong Laboratory, Guangzhou, China; Sun Yat-Sen University Zhongshan Ophthalmic Center, Guangdong, Guangzhou, China; Australian National University Research School of Biological Sciences, RSBS, Canberra, ACT, Australia},
	abstract = {Introduction Myopia is the common cause of reduced uncorrected visual acuity among school-age children. It is more prevalent in urban than in rural areas. Although many myopia studies have focused on the effect of urbanisation, it remains unclear how visual experience in urban regions could affect childhood myopia. This study aims to investigate the incidence and prevalence of myopia among school-age children in urban and rural settings, thereby identifying the environmental factors that affect the onset and progression of myopia. Methods and analysis A school-based cohort study will be conducted. We will enroll all first-grade students from an urban (10 primary schools) and a rural (10 primary schools) regions of Zhaoqing city, China. Over 3-year follow-up period, students will receive detailed eye examinations annually and complete questionnaires about living habits and environment. In a 5% random subsample of the cohort, physical activity, light intensity and eye-tracking data will be obtained using wearable devices, and high-resolution macular images will be obtained by optical coherence tomography (OCT). The primary outcome is incident myopia, defined as myopia (spherical equivalent refractive of at least-0.5D) detected during follow-up among those without myopia at baseline. Ethics and dissemination Ethics approval was obtained from the ethics committee of the Zhongshan Ophthalmic Center (number: 2019KYPJ171). Study findings will be published in a peer-reviewed journal.  © 2021 Author(s). Published by BMJ.},
	author_keywords = {community child health; epidemiology; ophthalmology},
	keywords = {Child; China; Cohort Studies; Humans; Incidence; Myopia; Prevalence; Risk Factors; Schools; Article; child; China; clinical trial protocol; cohort analysis; controlled study; cumulative incidence; female; follow up; high resolution computer tomography; human; human impact (environment); incidence; light intensity; machine learning; major clinical study; male; myopia; optical coherence tomography; physical activity; prevalence; receiver operating characteristic; risk factor; rural population; school child; sensitivity and specificity; urban population; incidence; myopia; prevalence; risk factor; school},
	correspondence_address = {Y. Zeng; State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China; email: zhyfeng@mail.sysu.edu.cn; Y. Zheng; State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China; email: zhyfeng@mail.sysu.edu.cn; Y. Zheng; Guangzhou Regenerative Medicine and Health Guangdong Laboratory, Guangzhou, China; email: zhyfeng@mail.sysu.edu.cn},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34740929},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}@ARTICLE{Rebinsky2021,
	author = {Rebinsky, Reid and Anderson, Laura N and Morgenstern, Jason D},
	title = {Identifying non-Traditional electronic datasets for population-level surveillance and prevention of cardiometabolic diseases: A scoping review protocol},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {8},
	doi = {10.1136/bmjopen-2021-053485},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113396308&doi=10.1136%2fbmjopen-2021-053485&partnerID=40&md5=b096d499f5ead71da022f6a53e1be303},
	affiliations = {Michael G. DeGroote School of Medicine, McMaster University, Hamilton, ON, Canada; Health Research Methods, Evidence and Impact, McMaster University, Hamilton, ON, Canada},
	abstract = {Introduction Cardiometabolic diseases, including cardiovascular disease, obesity and diabetes, are leading causes of death and disability worldwide. Modern advances in population-level disease surveillance are necessary and may inform novel opportunities for precision public health approaches to disease prevention. Electronic data sources, such as social media and consumer rewards points systems, have expanded dramatically in recent decades. These non-Traditional datasets may enhance traditional clinical and public health datasets and inform cardiometabolic disease surveillance and population health interventions. However, the scope of non-Traditional electronic datasets and their use for cardiometabolic disease surveillance and population health interventions has not been previously reviewed. The primary objective of this review is to describe the scope of non-Traditional electronic datasets, and how they are being used for cardiometabolic disease surveillance and to inform interventions. The secondary objective is to describe the methods, such as machine learning and natural language processing, that have been applied to leverage these datasets. Methods and analysis We will conduct a scoping review following recommended methodology. Search terms will be based on the three central concepts of non-Traditional electronic datasets, cardiometabolic diseases and population health. We will search EMBASE, MEDLINE, CINAHL, Scopus, Web of Science and Cochrane Library peer-reviewed databases and will also conduct a grey literature search. Articles published from 2000 to present will be independently screened by two reviewers for inclusion at abstract and full-Text stages, and conflicts will be resolved by a separate reviewer. We will report this data as per the Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews. Ethics and dissemination No ethics approval is required for this protocol and scoping review, as data will be used only from published studies with appropriate ethics approval. Results will be disseminated in a peer-reviewed publication. © },
	author_keywords = {general diabetes; hypertension; information technology; ischaemic heart disease; lipid disorders; public health},
	keywords = {Cardiovascular Diseases; Delivery of Health Care; Electronics; Humans; Peer Review; Research Design; Review Literature as Topic; Systematic Reviews as Topic; cardiovascular disease; diabetes mellitus; disease surveillance; disorders of lipid metabolism; electronic medical record; grey literature; human; hypertension; information processing; information technology; ischemic heart disease; machine learning; medical ethics; metabolic disorder; natural language processing; population health; Review; cardiovascular disease; electronics; health care delivery; literature; methodology; peer review},
	correspondence_address = {R. Rebinsky; Michael G. DeGroote School of Medicine, McMaster University, Hamilton, Canada; email: reid.rebinsky@medportal.ca},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34408061},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Maclure2021421,
	author = {Maclure, Jocelyn},
	title = {AI, Explainability and Public Reason: The Argument from the Limitations of the Human Mind},
	year = {2021},
	journal = {Minds and Machines},
	volume = {31},
	number = {3},
	pages = {421 – 438},
	doi = {10.1007/s11023-021-09570-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113731658&doi=10.1007%2fs11023-021-09570-x&partnerID=40&md5=7daa63c293e1f693816e911ce0d25877},
	affiliations = {Department of Philosophy, McGill University, Montreal, QC, Canada},
	abstract = {Machine learning-based AI algorithms lack transparency. In this article, I offer an interpretation of AI’s explainability problem and highlight its ethical saliency. I try to make the case for the legal enforcement of a strong explainability requirement: human organizations which decide to automate decision-making should be legally obliged to demonstrate the capacity to explain and justify the algorithmic decisions that have an impact on the wellbeing, rights, and opportunities of those affected by the decisions. This legal duty can be derived from the demands of Rawlsian public reason. In the second part of the paper, I try to show that the argument from the limitations of human cognition fails to get AI off the hook of public reason. Against a growing trend in AI ethics, my main argument is that the analogy between human minds and artificial neural networks fails because it suffers from an atomistic bias which makes it blind to the social and institutional dimension of human reasoning processes. I suggest that developing interpretive AI algorithms is not the only possible answer to the explainability problem; social and institutional answers are also available and in many cases more trustworthy than techno-scientific ones. © 2021, The Author(s), under exclusive licence to Springer Nature B.V.},
	author_keywords = {AI ethics; Artificial intelligence; Cognitive biases; Explainability; Machine learning; Public reason},
	keywords = {Decision making; Neural networks; Philosophical aspects; AI algorithms; Human cognition; Human mind; Human reasoning; Legal duties; Legal enforcement; Wellbeing; Machine learning},
	correspondence_address = {J. Maclure; Department of Philosophy, McGill University, Montreal, Canada; email: Jocelyn.maclure@mcgill.ca},
	publisher = {Springer Science and Business Media B.V.},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Nanayakkara2021795,
	author = {Nanayakkara, Priyanka and Hullman, Jessica and Diakopoulos, Nicholas},
	title = {Unpacking the Expressed Consequences of AI Research in Broader Impact Statements},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {795 – 806},
	doi = {10.1145/3461702.3462608},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108284452&doi=10.1145%2f3461702.3462608&partnerID=40&md5=85a8b5f30fdc5bc01878b7663116a179},
	affiliations = {Northwestern University, Evanston, IL, United States},
	abstract = {The computer science research community and the broader public have become increasingly aware of negative consequences of algorithmic systems. In response, the top-tier Neural Information Processing Systems (NeurIPS) conference for machine learning and artificial intelligence research required that authors include a statement of broader impact to reflect on potential positive and negative consequences of their work. We present the results of a qualitative thematic analysis of a sample of statements written for the 2020 conference. The themes we identify broadly fall into categories related to how consequences are expressed (e.g., valence, specificity, uncertainty), areas of impacts expressed (e.g., bias, the environment, labor, privacy), and researchers' recommendations for mitigating negative consequences in the future. In light of our results, we offer perspectives on how the broader impact statement can be implemented in future iterations to better align with potential goals. © 2021 ACM.},
	author_keywords = {ai ethics; anticipatory governance; broader impacts; thematic analysis},
	keywords = {Philosophical aspects; Privacy by design; Artificial intelligence research; Broader impacts; Computer science research; Neural information processing systems; On potentials; Thematic analysis; Artificial intelligence},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685; All Open Access, Green Open Access}
}

@CONFERENCE{Berendt2021202,
	author = {Berendt, Bettina and Karadeniz, Özgür and Mertens, Stefan and D'Haenens, Leen},
	title = {Fairness beyond "equal": The diversity searcher as a tool to detect and enhance the representation of socio-political actors in news media},
	year = {2021},
	journal = {The Web Conference 2021 - Companion of the World Wide Web Conference, WWW 2021},
	pages = {202 – 212},
	doi = {10.1145/3442442.3452303},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107652037&doi=10.1145%2f3442442.3452303&partnerID=40&md5=5413488b025b9e5eb5c5e6b5fc5331bf},
	affiliations = {TU Berlin, Weizenbaum Institute, Germany; Dept. Computer Science, KU Leuven, Belgium; Institute for Media Studies, KU Leuven, Belgium; KU Leuven, Belgium},
	abstract = {"Fairness"is a multi-faceted concept that is contested within and across disciplines. In machine learning, it usually denotes some form of equality of measurable outcomes of algorithmic decision making. In this paper, we start from a viewpoint of sociology and media studies, which highlights that to even claim fair treatment, individuals and groups first have to be visible. We draw on a notion and a quantitative measure of diversity that expresses this wider requirement. We used the measure to design and build the Diversity Searcher, a Web-based tool to detect and enhance the representation of socio-political actors in news media. We show how the tool's combination of natural language processing and a rich user interface can help news producers and consumers detect and understand diversity-relevant aspects of representation, which can ultimately contribute to enhancing diversity and fairness in media. We comment on our observation that, through interactions with target users during the construction of the tool, NLP results and interface questions became increasingly important, such that the formal measure of diversity has become a catalyst for functionality, but in itself less important. © 2021 ACM.},
	author_keywords = {accountability; Fairness-Aware recommender systems and diversity in recommendation, Innovative methods for studying/analyzing the fairness; transparency and ethics of web platforms, Usability challenges of machine learning},
	keywords = {Decision making; Machine learning; Natural language processing systems; Sociology; World Wide Web; Design and build; NAtural language processing; News media; Quantitative measures; Web-based tools; User interfaces},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038313-4},
	language = {English},
	abbrev_source_title = {Web Conf. - Companion World Wide Web Conf., WWW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 30th World Wide Web Conference, WWW 2021; Conference date: 19 April 2021 through 23 April 2021; Conference code: 169373; All Open Access, Green Open Access}
}

@CONFERENCE{Ahmad20214023,
	author = {Ahmad, Muhammad Aurangzeb and Overman, Steve and Allen, Christine and Kumar, Vikas and Teredesai, Ankur and Eckert, Carly},
	title = {Software as a Medical Device: Regulating AI in Healthcare via Responsible AI},
	year = {2021},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {4023 – 4024},
	doi = {10.1145/3447548.3470823},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114920107&doi=10.1145%2f3447548.3470823&partnerID=40&md5=f86306856ae50d26b6172ce216587531},
	affiliations = {University of Washington - Bothell and KenSci Inc., Bothell, WA, United States; KenSci Inc., Seattle, WA, United States},
	abstract = {With the increased adoption of AI in healthcare, there is a growing recognition and demand to regulate AI in healthcare to avoid potential harm and unfair bias against vulnerable populations. Around a hundred governmental bodies and commissions as well as leaders in the tech sector have proposed principles to create responsible AI systems. However, most of these proposals are short on specifics which has led to charges of ethics washing. In this tutorial we offer a guide to help navigate through complex governmental regulations and explain the various constituent practical elements of a responsible AI system in healthcare in the light of proposed regulations. Additionally, we breakdown and emphasize that the recommendations from regulatory bodies like FDA or the EU are necessary but not sufficient elements of creating a responsible AI system. We elucidate how regulations and guidelines often focus on epistemic concerns to the detriment of practical concerns e.g., requirement for fairness without explicating what fairness constitutes for a use case. FDA's Software as a medical device document and EU's GDPR among other AI governance documents talk about the need for implementing sufficiently good machine learning practices. In this tutorial we elucidate what that would mean from a practical perspective for real world use cases in healthcare throughout the machine learning cycle i.e., Data Management, Data Specification, Feature Engineering, Model Evaluation, Model Specification, Model Explainability, Model Fairness, Reproducibility, checks for data leakage and model leakage. We note that conceptualizing responsible AI as a process rather than an end goal accords well with how AI systems are used in practice. We also discuss how a domain centric stakeholder perspective translates into balancing requirements for multiple competing optimization criteria.  © 2021 Owner/Author.},
	author_keywords = {ai in healthcare; explainable ai; fairness in machine learning; interpretable machine learning; responsible ai; xai},
	keywords = {Balancing; Health care; Information management; Machine learning; Privacy by design; Specifications; Balancing requirements; Data specifications; Feature engineerings; Governmental regulations; Model specifications; Optimization criteria; Regulatory bodies; Reproducibilities; Data mining},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038332-5},
	language = {English},
	abbrev_source_title = {Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2021; Conference date: 14 August 2021 through 18 August 2021; Conference code: 171623}
}

@ARTICLE{Eguchi2021153,
	author = {Eguchi, Amy and Okada, Hiroyuki and Muto, Yumiko},
	title = {Contextualizing AI Education for K-12 Students to Enhance Their Learning of AI Literacy Through Culturally Responsive Approaches},
	year = {2021},
	journal = {KI - Kunstliche Intelligenz},
	volume = {35},
	number = {2},
	pages = {153 – 161},
	doi = {10.1007/s13218-021-00737-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112598010&doi=10.1007%2fs13218-021-00737-3&partnerID=40&md5=e5941ba7ea40e917498d60f584db10e3},
	affiliations = {Department of Education Studies, University of California San Diego, 9500 Gilman Drive #0070, La Jolla, 92093-0070, CA, United States; Brain Science Institute, Graduate School of Engineering, Graduate School of Brain Sciences, Tamagawa University, 6-1-1 Tamagawagakuen, Machida, Tokyo, 194-8610, Japan; Brain Research institute, Tamagawa University, 6-1-1 Tamagawagakuen, Machida, Tokyo, 194-8610, Japan},
	abstract = {AI has become ubiquitous in our society, accelerated by the speed of the development of machine learning algorithms and voice and facial recognition technologies used in our everyday lives. Furthermore, AI-enhanced technologies and tools are no strangers in the field of education. It is more evident that it is important to prepare K-12 population of students for their future professions as well as citizens capable of understanding and utilizing AI-enhanced technologies in the future. In response to such needs, the authors started a collaborative project aiming to provide a K-12 AI curriculum for Japanese students. However, the authors soon realized that it is important to contextualize the learning experience for the targeted K-12 students. The paper aims at introducing the idea of contextualizing AI education and learning experience of K-12 students with examples and tips using the work-in-progress version of the contextualized curriculum using culturally responsive approaches to promote the awareness and understanding of AI ethics among middle school students. © 2021, Gesellschaft für Informatik e.V. and Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {AI literacy; Contextualization; Cultural context; Culturally responsive pedagogy; K-12 AI education},
	keywords = {Curricula; Face recognition; Learning algorithms; Machine learning; AI literacy; Collaborative programs; Contextualization; Contextualize; Cultural context; Culturally responsive pedagogy; Facial recognition; K-12 AI education; Learning experiences; Machine learning algorithms; Students},
	correspondence_address = {A. Eguchi; Department of Education Studies, University of California San Diego, La Jolla, 9500 Gilman Drive #0070, 92093-0070, United States; email: a2eguchi@ucsd.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09331875},
	language = {English},
	abbrev_source_title = {KI - Kunstl. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Uusitalo2021478,
	author = {Uusitalo, Susanne and Tuominen, Jarno and Arstila, Valtteri},
	title = {Mapping out the philosophical questions of AI and clinical practice in diagnosing and treating mental disorders},
	year = {2021},
	journal = {Journal of Evaluation in Clinical Practice},
	volume = {27},
	number = {3},
	pages = {478 – 484},
	doi = {10.1111/jep.13485},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091687496&doi=10.1111%2fjep.13485&partnerID=40&md5=15dce18464137d85cae35e257bda86f7},
	affiliations = {Turku Institute for Advanced Studies, University of Turku, Turku, Finland; Department of Philosophy, Contemporary History and Political Science/Philosophy, University of Turku, Turku, Finland; Department of Psychology and Speech-Language Pathology, University of Turku, Turku, Finland; Faculty of Social Sciences, University of Helsinki, Helsinki, Finland; Department of Philosophy, History, Art and Culture Studies, University of Helsinki, Helsinki, Finland},
	abstract = {How to classify the human condition? This is one of the main problems psychiatry has struggled with since the first diagnostic systems. The furore over the recent editions of the diagnostic systems DSM-5 and ICD-11 has evidenced it to still pose a wicked problem. Recent advances in techniques and methods of artificial intelligence and computing power which allows for the analysis of large data sets have been proposed as a possible solution for this and other problems in classification, diagnosing, and treating mental disorders. However, mental disorders contain some specific inherent features, which require critical consideration and analysis. The promises of AI for mental disorders are threatened by the unmeasurable aspects of mental disorders, and for this reason the use of AI may lead to ethically and practically undesirable consequences in its effective processing. We consider such novel and unique questions AI presents for mental health disorders in detail and evaluate potential novel, AI-specific, ethical implications. © 2020 John Wiley & Sons Ltd},
	author_keywords = {diagnosis; medical ethics; philosophy of medicine; progress},
	keywords = {Artificial Intelligence; Diagnostic and Statistical Manual of Mental Disorders; Humans; International Classification of Diseases; Mental Disorders; Psychiatry; artificial intelligence; big data; bipolar disorder; brain function; clinical feature; clinical outcome; clinical practice; Conference Paper; data analysis; data privacy; distress syndrome; DSM-5; environmental factor; gender dysphoria; health care utilization; human; ICD-11; learning algorithm; machine learning; medical ethics; mental disease; mental health; mentalization; patient counseling; patient monitoring; philosophy of medicine; psychosocial withdrawal; psychotherapy; reliability; social aspect; social isolation; stigma; virtual reality; artificial intelligence; Diagnostic and Statistical Manual of Mental Disorders; International Classification of Diseases; psychiatry},
	correspondence_address = {S. Uusitalo; Turku Institute for Advanced Studies, University of Turku, Turku, Finland; email: susuus@utu.fi},
	publisher = {John Wiley and Sons Inc},
	issn = {13561294},
	coden = {JECPF},
	pmid = {32996664},
	language = {English},
	abbrev_source_title = {J. Eval. Clin. Pract.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Bragg2021,
	author = {Bragg, Danielle and Caselli, Naomi and Hochgesang, Julie A. and Huenerfauth, Matt and Katz-Hernandez, Leah and Koller, Oscar and Kushalnagar, Raja and Vogler, Christian and Ladner, Richard E.},
	title = {The FATE Landscape of Sign Language AI Datasets: An Interdisciplinary Perspective},
	year = {2021},
	journal = {ACM Transactions on Accessible Computing},
	volume = {14},
	number = {2},
	doi = {10.1145/3436996},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111620729&doi=10.1145%2f3436996&partnerID=40&md5=4fd0359263968bc5997a5e01acae68cd},
	affiliations = {Microsoft Research, 1 Memorial Drive, Cambridge, 02142, MA, United States; Boston University, 621 Commonwealth Ave, Boston, 02215, MA, United States; Gallaudet University, 800 Florida Ave NE, Washington, 20002, DC, United States; Rochester Institute of Technology, 1 Lomb Memorial Drive, Rochester, NY, United States; Microsoft, One Microsoft Way, Redmond, WA, United States; Microsoft, Gewürzmühlstraße 11, Munich, 80538, Germany; Gallaudet University, 800 Florida Ave NE, Washington, 20002, DC, United States; Gallaudet University, 800 Florida Ave NE, TAP-SLCC 1116, Washington, 20002, DC, United States; University of Washington, Address 3, Seattle, 98195, WA, United States},
	abstract = {Sign language datasets are essential to developing many sign language technologies. In particular, datasets are required for training artificial intelligence (AI) and machine learning (ML) systems. Though the idea of using AI/ML for sign languages is not new, technology has now advanced to a point where developing such sign language technologies is becoming increasingly tractable. This critical juncture provides an opportunity to be thoughtful about an array of Fairness, Accountability, Transparency, and Ethics (FATE) considerations. Sign language datasets typically contain recordings of people signing, which is highly personal. The rights and responsibilities of the parties involved in data collection and storage are also complex and involve individual data contributors, data collectors or owners, and data users who may interact through a variety of exchange and access mechanisms. Deaf community members (and signers, more generally) are also central stakeholders in any end applications of sign language data. The centrality of sign language to deaf culture identity, coupled with a history of oppression, makes usage by technologists particularly sensitive. This piece presents many of these issues that characterize working with sign language AI datasets, based on the authors' experiences living, working, and studying in this space.  © 2021 ACM.},
	author_keywords = {Artificial intelligence (AI); Dataset; Fairness, accountability, and ethics (FATE); Machine learning (ML); Sign language; Transparency},
	keywords = {Digital storage; History; Access mechanism; Culture identities; Data collection; Data collectors; Data contributors; Data users; Rights and responsibilities; Sign language; Artificial intelligence},
	publisher = {Association for Computing Machinery},
	issn = {19367228},
	language = {English},
	abbrev_source_title = {ACM Trans. Accessible Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Bronze Open Access}
}

@ARTICLE{Matthews2021742,
	author = {Matthews, Jeffrey B.},
	title = {Truth and truthiness: evidence, experience and clinical judgement in surgery},
	year = {2021},
	journal = {British Journal of Surgery},
	volume = {108},
	number = {7},
	pages = {742 – 744},
	doi = {10.1093/bjs/znab087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112486097&doi=10.1093%2fbjs%2fznab087&partnerID=40&md5=8732cdf640e9264a5fb740c9c626b766},
	affiliations = {Department of Surgery, The University of Chicago, Chicago, IL, United States},
	keywords = {Clinical Decision-Making; Clinical Reasoning; General Surgery; History, 15th Century; History, 16th Century; History, 17th Century; History, 18th Century; History, 19th Century; History, 20th Century; History, 21st Century; History, Ancient; History, Medieval; Humans; Judgment; Truth Disclosure; Article; artificial intelligence; clinical practice; conceptual framework; decision making; human; interdisciplinary education; machine learning; morbidity; mortality; surgical technique; clinical decision making; decision making; ethics; general surgery; history; interpersonal communication},
	correspondence_address = {J.B. Matthews; Department of Surgery, The University of Chicago, Chicago, 5841 S. Maryland Ave., 60611, United States; email: jmatthews@uchicago.edu},
	publisher = {Oxford University Press},
	issn = {00071323},
	coden = {BJSUA},
	pmid = {34136914},
	language = {English},
	abbrev_source_title = {Br. J. Surg.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Nawabi2021,
	author = {Nawabi, Jawed and Kniep, Helge and Kabiri, Reza and Broocks, Gabriel and Faizy, Tobias D. and Thaler, Christian and Schön, Gerhard and Fiehler, Jens and Hanning, Uta},
	title = {Corrigendum: Neoplastic and Non-neoplastic Acute Intracerebral Hemorrhage in CT Brain Scans: Machine Learning-Based Prediction Using Radiomic Image Features (Front. Neurol, (2020), 11, (285), 10.3389/fneur.2020.00285)},
	year = {2021},
	journal = {Frontiers in Neurology},
	volume = {12},
	doi = {10.3389/fneur.2021.687610},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107557710&doi=10.3389%2ffneur.2021.687610&partnerID=40&md5=480188bb50eff5754f851374a3e2b5e4},
	affiliations = {Department of Diagnostic and Interventional Neuroradiology, University Medical Center Hamburg-Eppendorf, Hamburg, Germany; Institute of Medical Biometry and Epidemiology, University Medical Center Hamburg-Eppendorf, Hamburg, Germany},
	abstract = {In the original article, there was an error. The article erroneously states that “The data that support the findings of this study are available from the corresponding author upon reasonable request.” Unfortunately, we are unable to provide the full raw data scan set due to the recent implementation of stricter data security regulations by our institution. A correction has been made to Methods, Paragraph 1. The corrected paragraph is shown below. This single-center retrospective study was approved by the ethics committee (Ethik- Kommission der Ärztekammer Hamburg, WF-054/19), and written informed consent was waived according to paragraph 9 section 2 of theHamburg federal state legislation and paragraph 15 section 1 of the medical association’s professional code of conduct in Hamburg. All study protocols and procedures were conducted in accordance with the Declaration of Helsinki. The data that support the findings of this study are available, upon reasonable request from the corresponding author, if in accordance with the institution’s data security regulations. The Data Availability Statement has also been updated, as shown below. DATA AVAILABILITY STATEMENT The data that support the findings of this study are available, upon reasonable request from the corresponding author, if in accordance with the institution’s data security regulations. The authors apologize for this error and state that this does not change the scientific conclusions of the article in any way. The original article has been updated. Copyright © 2021 Nawabi, Kniep, Kabiri, Broocks, Faizy, Thaler, Schön, Fiehler and Hanning.},
	author_keywords = {artificial intelligence; intracerebral hemorrhage; machine learning; neoplastic hemorrhage; radiomics},
	keywords = {erratum},
	correspondence_address = {J. Nawabi; Department of Diagnostic and Interventional Neuroradiology, University Medical Center Hamburg-Eppendorf, Hamburg, Germany; email: jawed.nawabi@charite.de},
	publisher = {Frontiers Media S.A.},
	issn = {16642295},
	language = {English},
	abbrev_source_title = {Front. Neurol.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Henriksen2021574,
	author = {Henriksen, Anne and Enni, Simon and Bechmann, Anja},
	title = {Situated Accountability: Ethical Principles, Certification Standards, and Explanation Methods in Applied AI},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {574 – 585},
	doi = {10.1145/3461702.3462564},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112462721&doi=10.1145%2f3461702.3462564&partnerID=40&md5=671b14c6ba997a948a5be4d1cac6d0ef},
	affiliations = {Aarhus University, Aarhus, Denmark},
	abstract = {Artificial intelligence (AI) has the potential to benefit humans and society by its employment in important sectors. However, the risks of negative consequences have underscored the importance of accountability for AI systems, their outcomes, and the users of such systems. In recent years, various accountability mechanisms have been put forward in pursuit of the responsible design, development, and use of AI. In this article, we provide an in-depth study of three such mechanisms, as we analyze Scandinavian AI developers' encounter with (1) ethical principles, (2) certification standards, and (3) explanation methods. By doing so, we contribute to closing a gap in the literature between discussions of accountability on the research and policy level, and accountability as a responsibility put on the shoulders of developers in practice. Our study illustrates important flaws in the current enactment of accountability as an ethical and social value which, if left unchecked, risks undermining the pursuit of responsible AI. By bringing attention to these flaws, the article signals where further work is needed in order to build effective accountability systems for AI. © 2021 ACM.},
	author_keywords = {accountability; AI; AI ethics; algorithmic systems; case study; certification; ethnography; explainable AI; machine learning; responsible AI},
	keywords = {Philosophical aspects; Accountability systems; AI systems; Certification standards; Ethical principles; Further works; In-depth study; Policy level; Social values; Artificial intelligence},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685}
}

@CONFERENCE{Zhang20212677,
	author = {Zhang, Yongfeng and Chen, Xu and Zhang, Yi and Chen, Xianjie},
	title = {CSR 2021: The 1st International Workshop on Causality in Search and Recommendation},
	year = {2021},
	journal = {SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {2677 – 2680},
	doi = {10.1145/3404835.3462817},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111704804&doi=10.1145%2f3404835.3462817&partnerID=40&md5=ad815c0927b75be1a661cbae3c97c3f9},
	affiliations = {Rutgers University; Renmin Univ. of China; Uc Santa Cruz; Facebook Ai Research},
	abstract = {Most of the current machine learning approaches to IR - -including search and recommendation tasks - -are mostly designed based on the basic idea of matching, which work from the perceptual and similarity learning perspective. This include both the learning of features from data such as representation learning, and the learning of similarity matching functions from data such as neural function learning. Though many models have been widely used in practical ranking systems such as search and recommendation, their design philosophy limits the models to the correlative signals in data. However, advancing from correlative learning to causal learning in search and recommendation is an important problem, because causal modeling can help us to think outside of the observational data for representation learning and ranking. More specially, causal learning can bring benefits to the IR community on various dimensions, including but not limited to Explainable IR models, Unbiased IR models, Fairness-aware IR models, Robust IR models and Cognitive Reasoning IR models. This workshop focuses on the research and application of causal modeling in search, recommendation and a broader scope of IR tasks. The workshop will gather both researchers and practitioners in the field for discussions, idea communications, and research promotions. It will also generate insightful debates about the recent regulations on AI Ethics, to a broader community including but not limited to IR, machine learning, AI, Data Science, and beyond. Workshop homepage is available online at https://csr21.github.io/. © 2021 ACM.},
	author_keywords = {causal learning; causality; counterfactual learning; information retrieval; recommendation; search},
	keywords = {Data Science; Information retrieval; Learning to rank; Search engines; Cognitive reasoning; Correlative learning; International workshops; Learning and rankings; Machine learning approaches; Research and application; Similarity learning; Similarity-matching; Learning systems},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038037-9},
	language = {English},
	abbrev_source_title = {SIGIR - Proc. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2021; Conference date: 11 July 2021 through 15 July 2021; Conference code: 170067}
}

@ARTICLE{Morley2021239,
	author = {Morley, Jessica and Elhalal, Anat and Garcia, Francesca and Kinsey, Libby and Mökander, Jakob and Floridi, Luciano},
	title = {Ethics as a Service: A Pragmatic Operationalisation of AI Ethics},
	year = {2021},
	journal = {Minds and Machines},
	volume = {31},
	number = {2},
	pages = {239 – 256},
	doi = {10.1007/s11023-021-09563-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108377488&doi=10.1007%2fs11023-021-09563-w&partnerID=40&md5=39fcdcd33f27500c91d92d994d0a5967},
	affiliations = {Oxford Internet Institute, University of Oxford, 1 St Giles’, Oxford, OX1 3JS, United Kingdom; Digital Catapult, 101 Euston Rd, London, NW1 2RA, United Kingdom; Alan Turing Institute, The British Library, 2QR, 96 Euston Rd, London, NW1 2DB, United Kingdom},
	abstract = {As the range of potential uses for Artificial Intelligence (AI), in particular machine learning (ML), has increased, so has awareness of the associated ethical issues. This increased awareness has led to the realisation that existing legislation and regulation provides insufficient protection to individuals, groups, society, and the environment from AI harms. In response to this realisation, there has been a proliferation of principle-based ethics codes, guidelines and frameworks. However, it has become increasingly clear that a significant gap exists between the theory of AI ethics principles and the practical design of AI systems. In previous work, we analysed whether it is possible to close this gap between the ‘what’ and the ‘how’ of AI ethics through the use of tools and methods designed to help AI developers, engineers, and designers translate principles into practice. We concluded that this method of closure is currently ineffective as almost all existing translational tools and methods are either too flexible (and thus vulnerable to ethics washing) or too strict (unresponsive to context). This raised the question: if, even with technical guidance, AI ethics is challenging to embed in the process of algorithmic design, is the entire pro-ethical design endeavour rendered futile? And, if no, then how can AI ethics be made useful for AI practitioners? This is the question we seek to address here by exploring why principles and technical translational tools are still needed even if they are limited, and how these limitations can be potentially overcome by providing theoretical grounding of a concept that has been termed ‘Ethics as a Service.’ © 2021, The Author(s).},
	author_keywords = {Applied ethics; Artificial Intelligence; Business ethics; Data ethics; Machine learning},
	keywords = {Laws and legislation; Object oriented programming; Philosophical aspects; AI systems; Algorithmic design; Ethical designs; Ethical issues; Technical guidances; Tools and methods; Artificial intelligence},
	correspondence_address = {J. Morley; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles’, OX1 3JS, United Kingdom; email: jessica.morley@oii.ox.ac.uk},
	publisher = {Springer Science and Business Media B.V.},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Hurtado2021,
	author = {Hurtado, Juana Valeria and Londoño, Laura and Valada, Abhinav},
	title = {From Learning to Relearning: A Framework for Diminishing Bias in Social Robot Navigation},
	year = {2021},
	journal = {Frontiers in Robotics and AI},
	volume = {8},
	doi = {10.3389/frobt.2021.650325},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103838222&doi=10.3389%2ffrobt.2021.650325&partnerID=40&md5=d110cc4998a8d03cf3bcc2f45ddf056a},
	affiliations = {Department of Computer Science, University of Freiburg, Freiburg im Breisgau, Germany},
	abstract = {The exponentially increasing advances in robotics and machine learning are facilitating the transition of robots from being confined to controlled industrial spaces to performing novel everyday tasks in domestic and urban environments. In order to make the presence of robots safe as well as comfortable for humans, and to facilitate their acceptance in public environments, they are often equipped with social abilities for navigation and interaction. Socially compliant robot navigation is increasingly being learned from human observations or demonstrations. We argue that these techniques that typically aim to mimic human behavior do not guarantee fair behavior. As a consequence, social navigation models can replicate, promote, and amplify societal unfairness, such as discrimination and segregation. In this work, we investigate a framework for diminishing bias in social robot navigation models so that robots are equipped with the capability to plan as well as adapt their paths based on both physical and social demands. Our proposed framework consists of two components: learning which incorporates social context into the learning process to account for safety and comfort, and relearning to detect and correct potentially harmful outcomes before the onset. We provide both technological and societal analysis using three diverse case studies in different social scenarios of interaction. Moreover, we present ethical implications of deploying robots in social environments and propose potential solutions. Through this study, we highlight the importance and advocate for fairness in human-robot interactions in order to promote more equitable social relationships, roles, and dynamics and consequently positively influence our society. © Copyright © 2021 Hurtado, Londoño and Valada.},
	author_keywords = {algorithmic fairness; ethics; fairness-aware learning; responsible innovation; robot learning; social robot navigation},
	correspondence_address = {J.V. Hurtado; Department of Computer Science, University of Freiburg, Freiburg im Breisgau, Germany; email: hurtadoj@cs.uni-freiburg.de},
	publisher = {Frontiers Media S.A.},
	issn = {22969144},
	language = {English},
	abbrev_source_title = {Front. Robot.  AI},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Steele2021,
	author = {Steele, Robert W.},
	title = {Pediatric quality measures: The leap from process to outcomes},
	year = {2021},
	journal = {Current Problems in Pediatric and Adolescent Health Care},
	volume = {51},
	number = {8},
	doi = {10.1016/j.cppeds.2021.101065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114745467&doi=10.1016%2fj.cppeds.2021.101065&partnerID=40&md5=b598a1d1d8fe62a6a1d9db12d4c8614c},
	affiliations = {EVP/Chief Strategy and Innovation Officer, Children's Mercy Kansas City, United States},
	abstract = {Value-based reimbursement arrangements tie financial incentives to achieving quality measures to ensure savings are not from withholding care. For patients and their families, the delivery of high-quality care is simply the expectation. Defining and measuring pediatric quality, however, is not standardized which has led to a large proliferation of metrics across multiple stakeholders. The majority of these measures are process rather than outcomes metrics often chosen for the ease at which the data can be obtained. In order to drive greater value, outcomes measures should be preferentially selected. However, measuring outcomes in children presents multiple unique challenges. Compared to adults, children are generally healthier, their outcomes may take more time to manifest, and their clinical variability is greater. Another challenge is the amount of healthcare data being generated by providers, provider networks, payors, government agencies, and many others. This should help in understanding pediatric quality outcomes, but the massive volume of data requires new analytic tools. Artificial intelligence techniques such as machine learning offer faster, more precise, and larger scale evaluation of quality outcomes. Its implementation necessitates identifying expertise in the way of data scientists as well as additional infrastructure components to evaluate data governance, security, regulatory compliance, and ethics. Despite these prerequisites, much progress is being made in outcome insights that drive value benefiting children and families. © 2021},
	keywords = {Adult; Artificial Intelligence; Child; Delivery of Health Care; Humans; Quality of Health Care; adult; adult child; article; artificial intelligence; cell proliferation; child; economic incentive; ethics; expectation; government; health data; human; machine learning; reimbursement; artificial intelligence; health care delivery; health care quality},
	publisher = {Elsevier Inc.},
	issn = {15385442},
	coden = {CPPAC},
	pmid = {34518131},
	language = {English},
	abbrev_source_title = {Curr. Probl. Pediatr. Adolesc. Health Care},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Deike-Hofmann2021320,
	author = {Deike-Hofmann, Katerina and Dancs, Dorottya and Paech, Daniel and Schlemmer, Heinz-Peter and Maier-Hein, Klaus and Bäumer, Philipp and Radbruch, Alexander and Götz, Michael},
	title = {Pre-examinations Improve Automated Metastases Detection on Cranial MRI},
	year = {2021},
	journal = {Investigative Radiology},
	volume = {56},
	number = {5},
	pages = {320 – 327},
	doi = {10.1097/RLI.0000000000000745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103993646&doi=10.1097%2fRLI.0000000000000745&partnerID=40&md5=53cf38fc6a2584c6a188d2e2488bcee5},
	affiliations = {Department of Radiology, German Cancer Research Center, Heidelberg, Germany; Department of Neuroradiology, Bonn University Clinic, Bonn, Germany; Department for Medical Image Computing, German Cancer Research Center, Heidelberg, Germany},
	abstract = {Objective The aim of this study was to assess the diagnostic value of inclusion of prediagnosis magnetic resonance imaging (MRI) and different MRI sequences when training a convolutional neural network (CNN) in detection of metastases from malignant melanoma (MM) on an annotated real-life cranial MRI dataset. Diagnostic performance was challenged by extracerebral-intracranial MM and by inclusion of MRI with varying sequence parameters. Materials and Methods Our local ethics committee approved this retrospective monocenter study. First, a dual-time approach was assessed, for which the CNN was provided sequences of the MRI that initially depicted new MM (diagnosis MRI) as well as of a prediagnosis MRI: inclusion of only contrast-enhanced T1-weighted images (CNNdual_ce) was compared with inclusion of also the native T1-weighted images, T2-weighted images, and FLAIR sequences of both time points (CNNdual_all). Second, results were compared with the corresponding single time approaches, in which the CNN was provided exclusively the respective sequences of the diagnosis MRI. Casewise diagnostic performance parameters were calculated from 5-fold cross-validation. Results In total, 94 cases with 494 MMs were included. Overall, the highest diagnostic performance was achieved by inclusion of only the contrast-enhanced T1-weighted images of the diagnosis and of a prediagnosis MRI (CNNdual_ce, sensitivity = 73%, PPV = 25%, F1-score = 36%). Using exclusively contrast-enhanced T1-weighted images as input resulted in significantly less false-positives (FPs) compared with inclusion of further sequences beyond contrast-enhanced T1-weighted images (FPs = 5/7 for CNNdual_ce/CNNdual_all, P < 1e-5). Comparison of contrast-enhanced dual and mono time approaches revealed that exclusion of prediagnosis MRI significantly increased FPs (FPs = 5/10 for CNNdual_ce/CNNce, P < 1e-9). Approaches with only native sequences were clearly inferior to CNNs that were provided contrast-enhanced sequences. Conclusions Automated MM detection on contrast-enhanced T1-weighted images performed with high sensitivity. Frequent FPs due to artifacts and vessels were significantly reduced by additional inclusion of prediagnosis MRI, but not by inclusion of further sequences beyond contrast-enhanced T1-weighted images. Future studies might investigate different change detection architectures for computer-aided detection.  © Wolters Kluwer Health, Inc. All rights reserved.},
	author_keywords = {brain metastases; computer-aided detection; fully convolutional neural network; machine learning; malignant melanoma},
	keywords = {Artifacts; Contrast Media; Magnetic Resonance Imaging; Retrospective Studies; Sensitivity and Specificity; gadoterate meglumine; contrast medium; Article; artificial neural network; brain metastasis; contrast enhancement; controlled study; convolutional neural network; cross validation; diagnostic test accuracy study; fluid-attenuated inversion recovery imaging; human; image segmentation; machine learning; major clinical study; melanoma; metastasis; nuclear magnetic resonance imaging; predictive value; retrospective study; sensitivity and specificity; T1 weighted imaging; T2 weighted imaging; artifact},
	correspondence_address = {A. Radbruch; Clinic for Diagnostic and Interventional Neuroradiology, Venusberg Campus 1, Bonn, 53127, Germany; email: alexander.radbruch@ukbonn.de},
	publisher = {Lippincott Williams and Wilkins},
	issn = {00209996},
	coden = {INVRA},
	pmid = {33259442},
	language = {English},
	abbrev_source_title = {Invest. Radiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{2021150,
	title = {Erratum (Cardiovascular Digital Health Journal (2020) 1(1) (9–10), (S2666693620300086), (10.1016/j.cvdhj.2020.06.004))},
	year = {2021},
	journal = {Cardiovascular Digital Health Journal},
	volume = {2},
	number = {2},
	pages = {150 – 151},
	doi = {10.1016/j.cvdhj.2021.03.006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139232554&doi=10.1016%2fj.cvdhj.2021.03.006&partnerID=40&md5=517c2aa9542d6803556af1e65b0ad662},
	abstract = {Disclosure/disclaimer and/or guidelines/ethics statements were not included in the published version of the following articles that appeared in previous issues of Cardiovascular Digital Health Journal. The appropriate disclosure/disclaimer and/or guidelines/ethics statements, provided by the Authors, are included below. 1. “Digital health innovation in cardiology” [Cardiovascular Digital health Journal, 2020; 1 (1): 6-8] https://doi.org/10.1016/j.cvdhj.2020.07.003 Disclaimer: Given his role as Section Editor, Zachia Attia had no involvement in the peer review of this article and has no access to information regarding its peer review.2. “When smartwatches contribute to health anxiety in patients with atrial fibrillation” [Cardiovascular Digital health Journal, 2020; 1 (1): 9-10] https://doi.org/10.1016/j.cvdhj.2020.06.004 Ethics/guidelines clarification: Written informed consent was obtained from the patient for publication of this case report. The study followed the CARE case report guidelines.3. “Discriminating electrocardiographic responses to His-bundle pacing using machine learning” [Cardiovascular Digital health Journal, 2020; 1 (1): 11-20] https://doi.org/10.1016/j.cvdhj.2020.07.001 Ethics/guidelines clarification: The study only used information from individuals that provided consent to use of their anonymized records for research.4. “Survey of current perspectives on consumer-available digital health devices for detecting atrial fibrillation” [Cardiovascular Digital health Journal, 2020; 1 (1): 21-29] https://doi.org/10.1016/j.cvdhj.2020.06.002 Disclaimer: Given his role as Editor-in-Chief, David McManus had no involvement in the peer review of this article and has no access to information regarding its peer review. Full responsibility for the editorial process for this article was delegated to David J. Slotwiner.Disclaimer: Given their role as Associate Editors and Section Editor, Hamid Ghanbari, Nassir F. Marrouche and Zachi Attia had no involvement in the peer review of this article and has no access to information regarding its peer review.5. “Comparative analysis between convolutional neural network learned and engineered features: A case study on cardiac arrhythmia detection” [Cardiovascular Digital health Journal, 2020; 1 (1): 37-44] https://doi.org/10.1016/j.cvdhj.2020.04.001 Ethics/guidelines clarification: The study was conducted according to Systematic reviews and meta-analyses: PRISMA guidelines.6. “Digital health for primary prevention of cardiovascular disease: Promise to practice” [Cardiovascular Digital health Journal, 2020; 1 (2): 59-61] https://doi.org/10.1016/j.cvdhj.2020.09.002 Disclaimer: Given his role as Associate Editor, Pradeep Natarajan had no involvement in the peer review of this article and has no access to information regarding its peer review.7. “A comprehensive artificial intelligence–enabled electrocardiogram interpretation program” [Cardiovascular Digital health Journal, 2020; 1 (2): 62-70] https://doi.org/10.1016/j.cvdhj.2020.08.005 Disclaimer: Given his role as Section Editor, Zachia Attia had no involvement in the peer review of this article and has no access to information regarding its peer review.8. “Utilizing electronic health data and machine learning for the prediction of 30-day unplanned readmission or all-cause mortality in heart failure” [Cardiovascular Digital health Journal, 2020; 1 (2): 71-79] https://doi.org/10.1016/j.cvdhj.2020.07.004 Ethics/guidelines clarification: The study was a retrospective chart review. Consent would be impossible or impracticable to obtain for such research so was waived by the research ethics committee. The study was conducted according to the principles of the Declaration of Helsinki.9. “Does sex modify an association of electrophysiological substrate with sudden cardiac death? The Atherosclerosis Risk in Communities (ARIC) study” [Cardiovascular Digital health Journal, 2020; 1 (2): 80-88] https://doi.org/10.1016/j.cvdhj.2020.08.003 Ethics/guidelines clarification: The research reported in this paper conforms to the guidelines set out in CONSORT. The study was conducted according to the principles of the Declaration of Helsinki. All study participants provided written informed consent before entering the ARIC study. This study was approved by the Oregon Health & Science University Institutional Review Board. All procedures performed in studies involving human participants were in accordance with the ethical standards of the Institutional Review Board and the 1964 Helsinki declaration and its later amendments or comparable ethical standards.10. “Performance of an automated photoplethysmography-based artificial intelligence algorithm to detect atrial fibrillation” [Cardiovascular Digital health Journal, 2020; 1 (2): 107-110] https://doi.org/10.1016/j.cvdhj.2020.08.004 Ethics/guidelines clarification: Our research was performed in full accordance to the principles of the Declaration of Helsinki as revised in October 2013.11. “Incidence, duration, pattern, and burden of de novo atrial arrhythmias detected by continuous ECG monitoring using an implantable loop recorder following ablation of the cavotricuspid isthmus” [Cardiovascular Digital health Journal, 2020; 1 (3): 114-122] https://doi.org/10.1016/j.cvdhj.2020.10.003 Disclaimer: Given his role as Associate Editor, Suneet Mittal had no involvement in the peer review of this article and has no access to information regarding its peer review.12. “COVID-19 testing and infection surveillance: Is a combined digital contact-tracing and mass-testing solution feasible in the United States?” [Cardiovascular Digital health Journal, 2020; 1 (3): 149-159 https://doi.org/10.1016/j.cvdhj.2020.09.004 Ethics/Guidelines clarification: The research reported in this paper conforms to the guidelines set out in PRISMA.13. “The impact of direct-to-consumer wearables in pediatric electrophysiology telehealth clinics: A real-world case series” [Cardiovascular Digital health Journal, 2020; 1 (3): 169-171] https://doi.org/10.1016/j.cvdhj.2020.09.005 Ethics/guidelines clarification: Informed consent was obtained from all study participants.14. “The use of a traditional nonlooping event monitor versus a loan-based program with a smartphone ECG device in the pediatric cardiology clinic” [Cardiovascular Digital health Journal, 2020; 2 (1): 71-75] https://doi.org/10.1016/j.cvdhj.2020.11.008 Ethics/guidelines clarification: Informed consent was obtained from all study participants that were provided the Kardia monitor for inclusion in the study.15. “2021 ISHNE/HRS/EHRA/APHRS Collaborative Statement on mHealth in Arrhythmia Management: Digital Medical Tools for Heart Rhythm Professionals” [Cardiovascular Digital health Journal, 2020; 2 (1): 4-54] https://doi.org/10.1016/j.cvdhj.2020.11.004 Disclaimer: Editorial review for this article was done by the participating societies and the Cardiovascular Digital Health Journal Editor-in-Chief. Section Editor David Slotwiner had no involvement in peer review for acceptance to this journal.16. “Smartwatch diagnosis of atrial fibrillation in patient with embolic stroke of unknown source: A case report” [Cardiovascular Digital health Journal, 2020; 2 (1): 84-87] https://doi.org/10.1016/j.cvdhj.2021.01.001 Ethics/Guidelines clarification: Informed consent was given by the Patient. This case report conforms to the CARE guidelines. © 2021},
	keywords = {erratum; Erratum},
	publisher = {Elsevier Inc.},
	issn = {26666936},
	language = {English},
	abbrev_source_title = {Cardiovasc. Digit. Health. J.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{O'Brien202132,
	author = {O'Brien, Roxanne L. and O'Brien, Matt W.},
	title = {CE: Nursing Orientation to Data Science and Machine Learning},
	year = {2021},
	journal = {American Journal of Nursing},
	volume = {121},
	number = {4},
	pages = {32 – 39},
	doi = {10.1097/01.NAJ.0000742064.59610.28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103474635&doi=10.1097%2f01.NAJ.0000742064.59610.28&partnerID=40&md5=ee6328f325e65b94c21905b82ac722fc},
	affiliations = {The School Of Nursing, California State University, Fullerton, United States; The Center For Digital Health Innovation, University Of California, San Francisco, United States},
	abstract = {Nurses collect, use, and produce data every day in countless ways, such as when assessing and treating patients, performing administrative functions, and engaging in strategic planning in their organizations and communities. These data are aggregated into large data sets in health care systems, public and private databases, and academic research settings. In recent years the machines used in this work (computer hardware) have become increasingly able to analyze large data sets, or "big data," at high speed. Data scientists use machine learning tools to aid in analyzing this big data, such as data amassed from large numbers of electronic health records. In health care, predictions for patient outcomes has become a focus of research using machine learning. It's important for nurses and nurse administrators to understand how machine learning has changed our ways of thinking about data and turning data into knowledge that can improve patient care. This article provides an orientation to machine learning and data science, offers an understanding of current challenges and opportunities, and describes the nursing implications for nurses in various roles. © 2021 Lippincott Williams and Wilkins. All rights reserved.},
	author_keywords = {algorithm; bias; big data; data science; electronic health record; ethics; evidence-based practice; machine learning},
	keywords = {Adult; Curriculum; Data Science; Education, Nursing, Continuing; Female; Humans; Inservice Training; Machine Learning; Male; Middle Aged; Nursing Staff, Hospital; adult; curriculum; education; female; human; in service training; machine learning; male; middle aged; nursing education; nursing staff; procedures},
	correspondence_address = {R.L. O'brien; The School Of Nursing, California State University, Fullerton, United States; email: roxanne.obrien@gmail.com},
	publisher = {Lippincott Williams and Wilkins},
	issn = {0002936X},
	coden = {AJNUA},
	pmid = {33735115},
	language = {English},
	abbrev_source_title = {Am. J. Nurs.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Cohen2021605,
	author = {Cohen, Alan B.},
	title = {In the September 2021 Issue of the Quarterly},
	year = {2021},
	journal = {Milbank Quarterly},
	volume = {99},
	number = {3},
	pages = {605 – 609},
	doi = {10.1111/1468-0009.12541},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115125070&doi=10.1111%2f1468-0009.12541&partnerID=40&md5=383af66f81588c997709bcee1414ac7b},
	keywords = {Artificial Intelligence; COVID-19; Drugs, Generic; Health Policy; Humans; Life Expectancy; Mental Disorders; Nurse Practitioners; Pandemics; Politics; Primary Health Care; SARS-CoV-2; Social Determinants of Health; State Medicine; Taxes; Trans Fatty Acids; United States; generic drug; trans fatty acid; generic drug; trans fatty acid; abortion; artificial intelligence; coronavirus disease 2019; drug cost; Editorial; food; health care access; health care policy; health disparity; health insurance; homelessness; human; immigrant; income; infection rate; life expectancy; machine learning; malpractice; medicaid; medical ethics; mental disease; nurse practitioner; prenatal care; prescription; SARS-CoV-2 Delta; social care; social prescribing; tax; vaccine hesitancy; Willingness To Pay; epidemiology; health care policy; mental disease; national health service; pandemic; politics; primary health care; social determinants of health; United States},
	publisher = {John Wiley and Sons Inc},
	issn = {0887378X},
	coden = {MIQUE},
	pmid = {34543461},
	language = {English},
	abbrev_source_title = {Milbank Q.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Geppert2021,
	author = {Geppert, Cynthia M. A. and Brendel, Rebecca Weintraub and Trachsel, Manuel},
	title = {Editorial: Ethics in Psychiatry and Psychotherapy},
	year = {2021},
	journal = {Frontiers in Psychiatry},
	volume = {12},
	doi = {10.3389/fpsyt.2021.742218},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113557907&doi=10.3389%2ffpsyt.2021.742218&partnerID=40&md5=fe8a2779ffccfc54d489e19ed04c5076},
	affiliations = {University of New Mexico School of Medicine, Albuquerque, NM, United States; Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States; Center for Bioethics, Harvard Medical School, Boston, MA, United States; Institute of Biomedical Ethics and History of Medicine, University of Zurich, Zurich, Switzerland; Clinical Ethics Unit, University Hospital Basel and University Psychiatric Clinics, Basel, Switzerland},
	author_keywords = {autonomy; coercion; decision-making capacity; digitalization; ethics; informed consent; psychiatry; psychotherapy},
	keywords = {antidepressant agent; antisocial personality disorder; brain depth stimulation; coercion; cognitive remediation therapy; confidentiality; decision making; DSM-5; eating disorder; Editorial; ethics; health care system; human; ICD-10; machine learning; mental disease; mental health; neuroscience; patient autonomy; pedophilia; phenotype; psychiatrist; psychiatry; psychotherapist; psychotherapy; schizoaffective psychosis},
	correspondence_address = {M. Trachsel; Institute of Biomedical Ethics and History of Medicine, University of Zurich, Zurich, Switzerland; email: manuel.trachsel@uzh.ch},
	publisher = {Frontiers Media S.A.},
	issn = {16640640},
	language = {English},
	abbrev_source_title = {Front. Psychiatry},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Afnan2021316,
	author = {Afnan, Michael Anis Mihdi and Rudin, Cynthia and Conitzer, Vincent and Savulescu, Julian and Mishra, Abhishek and Liu, Yanhe and Afnan, Masoud},
	title = {Ethical Implementation of Artificial Intelligence to Select Embryos in in Vitro Fertilization},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {316 – 326},
	doi = {10.1145/3461702.3462589},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112411784&doi=10.1145%2f3461702.3462589&partnerID=40&md5=5144fb80c994288f7ef24a084a9459bc},
	affiliations = {Imperial College London, London, United Kingdom; Duke University, Durham, United States; Duke University and Oxford University, Durham, NC, United States; Oxford University and Oxford University, Royal Children's Hospital, Oxford, United Kingdom},
	abstract = {AI has the potential to revolutionize many areas of healthcare. Radiology, dermatology, and ophthalmology are some of the areas most likely to be impacted in the near future, and they have received significant attention from the broader research community. But AI techniques are now also starting to be used in in vitro fertilization (IVF), in particular for selecting which embryos to transfer to the woman. The contribution of AI to IVF is potentially significant, but must be done carefully and transparently, as the ethical issues are significant, in part because this field involves creating new people. We first give a brief introduction to IVF and review the use of AI for embryo selection. We discuss concerns with the interpretation of the reported results from scientific and practical perspectives. We then consider the broader ethical issues involved. We discuss in detail the problems that result from the use of black-box methods in this context and advocate strongly for the use of interpretable models. Importantly, there have been no published trials of clinical effectiveness, a problem in both the AI and IVF communities, and we therefore argue that clinical implementation at this point would be premature. Finally, we discuss ways for the broader AI community to become involved to ensure scientifically sound and ethically responsible development of AI in IVF. © 2021 ACM.},
	author_keywords = {AI; artificial intelligence; black-box; embryo selection; ethics; in vitro fertilization; interpretable; IVF; machine learning; randomised controlled trials; RCT},
	keywords = {Philosophical aspects; AI techniques; Black box method; Clinical effectiveness; Ethical issues; In-vitro; Most likely; Research communities; Artificial intelligence},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685; All Open Access, Green Open Access}
}

@ARTICLE{Heidel2021,
	author = {Heidel, Alexandra and Hagist, Christian and Schlereth, Christian},
	title = {Pricing through health apps generated data- Digital dividend as a game changer: Discrete choice experiment},
	year = {2021},
	journal = {PLoS ONE},
	volume = {16},
	number = {7 July},
	doi = {10.1371/journal.pone.0254786},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111180150&doi=10.1371%2fjournal.pone.0254786&partnerID=40&md5=ad10cb6674c0df6ba175f975fb5fe43f},
	affiliations = {Whu -Otto Beisheim School of Management, Chair of Economic and Social Policy, Vallendar, Germany; Whu -Otto Beisheim School of Management, Chair of Economic and Social Policy, Vallendar, Germany},
	abstract = {Objectives The objective of this paper is to study under which circumstances wearable and health app users would accept a compensation payment, namely a digital dividend, to share their selftracked health data. Methods We conducted a discrete choice experiment alternative, a separated adaptive dual response. We chose this approach to reduce extreme response behavior, considering the emotionally-charged topic of health data sales, and to measure willingness to accept. Previous experiments in lab settings led to demands for high monetary compensation. After a first online survey and two pre-studies, we validated four attributes for the final online study: monthly bonus payment, stakeholder handling the data (e.g., health insurer, pharmaceutical or medical device companies, universities), type of data, and data sales to third parties. We used a random utility framework to evaluate individual choice preferences. To test the expected prices of the main study for robustness, we assigned respondents randomly to one of two identical questionnaires with varying price ranges. © 2021 Public Library of Science. All rights reserved.},
	keywords = {COVID-19; Health Records, Personal; Humans; Information Dissemination; Mobile Applications; Models, Econometric; Surveys and Questionnaires; Wearable Electronic Devices; Article; bioinformatics; compensation; decision making; drug cost; econometric model; health care cost; health care policy; health data; health education; health insurance; human; human experiment; machine learning; mathematical model; medical student; medicare; qualitative research; questionnaire; reimbursement; stakeholder engagement; economics; electronic device; ethics; information dissemination; medical record; mobile application; psychology; statistical model},
	correspondence_address = {A. Heidel; Whu -Otto Beisheim School of Management, Chair of Economic and Social Policy, Vallendar, Germany; email: alexandra.heidel@whu.edu},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {34310618},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tellier2021,
	author = {Tellier, Laurent C. A. M. and Eccles, Jennifer and Treff, Nathan R. and Lello, Louis and Fishel, Simon and Hsu, Stephen},
	title = {Embryo screening for polygenic disease risk: Recent advances and ethical considerations},
	year = {2021},
	journal = {Genes},
	volume = {12},
	number = {8},
	doi = {10.3390/genes12081105},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111442474&doi=10.3390%2fgenes12081105&partnerID=40&md5=03d69ce628195248cacc7659bb6cd2ce},
	affiliations = {Department of Physics and Astronomy, Michigan State University, East Lansing, 48824, MI, United States; Genomic Prediction, Inc, North Brunswick, 08902, NJ, United States; CARE Fertility Group, Nottingham, NG8 6PZ, United Kingdom; School of Pharmacy and Biomolecular Sciences, Liverpool John Moores University, Liverpool, L2 2QP, United Kingdom},
	abstract = {Machine learning methods applied to large genomic datasets (such as those used in GWAS) have led to the creation of polygenic risk scores (PRSs) that can be used identify individuals who are at highly elevated risk for important disease conditions, such as coronary artery disease (CAD), diabetes, hypertension, breast cancer, and many more. PRSs have been validated in large population groups across multiple continents and are under evaluation for widespread clinical use in adult health. It has been shown that PRSs can be used to identify which of two individuals is at a lower disease risk, even when these two individuals are siblings from a shared family environment. The relative risk reduction (RRR) from choosing an embryo with a lower PRS (with respect to one chosen at random) can be quantified by using these sibling results. New technology for precise embryo genotyping allows more sophisticated preimplantation ranking with better results than the current method of selection that is based on morphology. We review the advances described above and discuss related ethical considerations. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Complex trait prediction; Genetic engineering; Genomics; In vitro fertilization; PRS},
	keywords = {Embryo, Mammalian; Genetic Predisposition to Disease; Genetic Testing; Humans; Multifactorial Inheritance; accuracy; Article; clinical practice; embryo development; genetic disorder; genetic risk; genetic risk score; genetic screening; genotype; human; in vitro fertilization; longevity; multifactorial inheritance; pleiotropy; preimplantation genetic screening; risk factor; risk reduction; whole genome sequencing; ethics; genetic predisposition; genetic screening; mammalian embryo; procedures},
	correspondence_address = {L. Lello; Department of Physics and Astronomy, Michigan State University, East Lansing, 48824, United States; email: lellolou@msu.edu},
	publisher = {MDPI AG},
	issn = {20734425},
	pmid = {34440279},
	language = {English},
	abbrev_source_title = {Genes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Richardson2021,
	author = {Richardson, Brianna and Garcia-Gathright, Jean and Way, Samuel F.},
	title = {Towards fairness in practice: A practitioner-oriented rubric for evaluating fair ml toolkits},
	year = {2021},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3411764.3445604},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106723058&doi=10.1145%2f3411764.3445604&partnerID=40&md5=854ca068252ebfb362efafdd5ef07e63},
	affiliations = {Spotify},
	abstract = {In order to support fairness-forward thinking by machine learning (ML) practitioners, fairness researchers have created toolkits that aim to transform state-of-the-art research contributions into easily-accessible APIs. Despite these eforts, recent research indicates a disconnect between the needs of practitioners and the tools ofered by fairness research. By engaging 20 ML practitioners in a simulated scenario in which they utilize fairness toolkits to make critical decisions, this work aims to utilize practitioner feedback to inform recommendations for the design and creation of fair ML toolkits. Through the use of survey and interview data, our results indicate that though fair ML toolkits are incredibly impactful on users' decision-making, there is much to be desired in the design and demonstration of fairness results. To support the future development and evaluation of toolkits, this work ofers a rubric that can be used to identify critical components of Fair ML toolkits. © 2021 ACM.},
	author_keywords = {Ai; Algorithmic bias; Ethics; Fairness; Machine learning fairness; Ml; User-centric evaluation},
	keywords = {Decision making; Human engineering; Critical component; Recent researches; State of the art; Surveys},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038096-6},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; Conference name: 2021 CHI Conference on Human Factors in Computing Systems: Making Waves, Combining Strengths, CHI 2021; Conference date: 8 May 2021 through 13 May 2021; Conference code: 168790}
}

@CONFERENCE{Castro2021446,
	author = {Castro, Clinton and O'Brien, David and Schwan, Ben},
	title = {Fairness and Machine Fairness},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {446},
	doi = {10.1145/3461702.3462577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112466377&doi=10.1145%2f3461702.3462577&partnerID=40&md5=d0a84b1e5577ca3b1b0f001578b32ea0},
	affiliations = {Florida International University, Miami, FL, United States; Tulane University, New Orleans, LA, United States; Case Western Reserve University, Cleveland, OH, United States},
	abstract = {Prediction-based decisions, which are often made by utilizing the tools of machine learning, influence nearly all facets of modern life. Ethical concerns about this widespread practice have given rise to the field of fair machine learning and a number of fairness measures, mathematically precise definitions of fairness that purport to determine whether a given prediction-based decision system is fair. Following Reuben Binns (2017), we take "fairness"in this context to be a placeholder for a variety of normative egalitarian considerations. We explore a few fairness measures to suss out their egalitarian roots and evaluate them, both as formalizations of egalitarian ideas and as assertions of what fairness demands of predictive systems. We pay special attention to a recent and popular fairness measure, counterfactual fairness, which holds that a prediction about an individual is fair if it is the same in the actual world and any counterfactual world where the individual belongs to a different demographic group (cf. Kusner et al. 2018). © 2021 Owner/Author.},
	author_keywords = {fair machine learning; fairness; technology ethics},
	keywords = {Machine learning; Philosophical aspects; Decision systems; Demographic groups; Ethical concerns; Fairness measures; Precise definition; Prediction-based; Predictive systems; Forecasting},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685}
}

@ARTICLE{Mysona2021292,
	author = {Mysona, David Pierce and Kapp, Daniel S. and Rohatgi, Atharva and Lee, Danny and Mann, Amandeep K. and Tran, Paul and Tran, Lynn and She, Jin-Xiong and Chan, John K.},
	title = {Applying artificial intelligence to gynecologic oncology: A review},
	year = {2021},
	journal = {Obstetrical and Gynecological Survey},
	volume = {76},
	number = {5},
	pages = {292 – 301},
	doi = {10.1097/ogx.0000000000000902},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106879944&doi=10.1097%2fogx.0000000000000902&partnerID=40&md5=d545bf6c205224c4cf696eea6a88269e},
	affiliations = {University of North Carolina, Chapel Hill, NC, United States; Department of Radiation Oncology, Stanford University School of Medicine, Stanford, CA, United States; University of California-Davis, Davis, CA, United States; University of California-Berkeley, Berkeley, CA, United States; Quantitative Research Analyst, Palo Alto Medical Foundation Research Institute, Palo Alto, CA, United States; Center for Biotechnology and Genomic Medicine, Medical College of Georgia, Augusta, GA, United States; Director of Gynecologic Oncology, Palo Alto Medical Foundation Research Institute, Palo Alto, CA, United States},
	abstract = {Importance: Artificial intelligence (AI) will play an increasing role in health care. In gynecologic oncology, it can advance tailored screening, precision surgery, and personalized targeted therapies. Objective: The aim of this study was to review the role of AI in gynecologic oncology. Evidence Acquisition: Artificial intelligence publications in gynecologic oncology were identified by searching “gynecologic oncology AND artificial intelligence” in the PubMed database. A review of the literature was performed on the history of AI, its fundamentals, and current applications as related to diagnosis and treatment of cervical, uterine, and ovarian cancers. Results: A PubMed literature search since the year 2000 showed a significant increase in oncology publications related to AI and oncology. Early studies focused on using AI to interrogate electronic health records in order to improve clinical outcome and facilitate clinical research. In cervical cancer, AI algorithms can enhance image analysis of cytology and visual inspection with acetic acid or colposcopy. In uterine cancers, AI can improve the diagnostic accuracies of radiologic imaging and predictive/prognostic capabilities of clinicopathologic characteristics. Artificial intelligence has also been used to better detect early-stage ovarian cancer and predict surgical outcomes and treatment response. Conclusions and Relevance: Artificial intelligence has been shown to enhance diagnosis, refine clinical decision making, and advance personalized therapies in gynecologic cancers. The rapid adoption of AI in gynecologic oncology will depend on overcoming the challenges related to data transparency, quality, and interpretation. Artificial intelligence is rapidly transforming health care. However, many physicians are unaware that this technology is being used in their practices and could benefit from a better understanding of the statistics and computer science behind these algorithms. This review provides a summary of AI, its applicability, and its limitations in gynecologic oncology. Target Audience: Obstetricians and gynecologists, family physicians Learning Objectives: After completing this CME activity, physicians should be better able to describe the basic functions of AI algorithms; explain the potential applications of machine learning in diagnosis, treatment, and prognostication of cervical, endometrial, and ovarian cancers; and identify the ethical concerns and limitations of the use of AI in the management of gynecologic cancer patients. © 2021 Lippincott Williams and Wilkins. All rights reserved.},
	keywords = {Algorithms; Artificial Intelligence; Female; Humans; Mass Screening; Medical Oncology; Uterine Cervical Neoplasms; acetic acid; artificial intelligence; artificial neural network; Bayesian learning; cancer prognosis; cancer recurrence; clinical decision making; clinical outcome; clinical research; colposcopy; diagnostic accuracy; electronic medical record; endometrium cancer; female genital tract cancer; human; hysteroscopy; image analysis; machine learning; medical ethics; natural language processing; nuclear magnetic resonance imaging; ovary cancer; personalized medicine; predictive value; publication; random forest; Review; supervised machine learning; support vector machine; unsupervised machine learning; uterine cervix cancer; uterine cervix cytology; uterus cancer; algorithm; female; mass screening; oncology; uterine cervix tumor},
	publisher = {Lippincott Williams and Wilkins},
	issn = {00297828},
	coden = {OGSUA},
	pmid = {34032861},
	language = {English},
	abbrev_source_title = {Obstet. Gynecol. Surv.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Rassy2021,
	author = {Rassy, Jessica and Bardon, Cécile and Dargis, Luc and Côté, Louis-Philippe and Corthésy-Blondin, Laurent and Mörch, Carl-Maria and Labelle, Réal},
	title = {Information and communication technology use in suicide prevention: Scoping review},
	year = {2021},
	journal = {Journal of Medical Internet Research},
	volume = {23},
	number = {5},
	doi = {10.2196/25288},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105392093&doi=10.2196%2f25288&partnerID=40&md5=e563ce6387b0d76495d2cdc05a8bfc83},
	affiliations = {Center for Research and Intervention on Suicide, Ethical Issues and End-of-Life Practices, Université du Québec à Montréal, Montréal, QC, Canada; Research Center, Institut Universitaire en santé mentale de Montréal, Montréal, QC, Canada; School of Nursing, Université de Sherbrooke, Longueuil, QC, Canada; Quebec Network on Nursing Intervention Research, Montréal, QC, Canada; Department of Psychology, Université du Québec à Montréal, Montréal, QC, Canada; Algora Lab, Université de Montréal, Montréal, QC, Canada; Mila, Quebec Artificial Intelligence Institute, Montréal, QC, Canada; Department of Psychiatry, Université de Montréal, Montréal, QC, Canada},
	abstract = {Background: The use of information and communication technology (ICT) in suicide prevention has progressed rapidly over the past decade. ICT plays a major role in suicide prevention, but research on best and promising practices has been slow. Objective: This paper aims to explore the existing literature on ICT use in suicide prevention to answer the following question: what are the best and most promising ICT practices for suicide prevention? Methods: A scoping search was conducted using the following databases: PubMed, PsycINFO, Sociological Abstracts, and IEEE Xplore. These databases were searched for articles published between January 1, 2013, and December 31, 2018. The five stages of the scoping review process were as follows: identifying research questions; targeting relevant studies; selecting studies; charting data; and collating, summarizing, and reporting the results. The World Health Organization suicide prevention model was used according to the continuum of universal, selective, and indicated prevention. Results: Of the 3848 studies identified, 115 (2.99%) were selected. Of these, 10 regarded the use of ICT in universal suicide prevention, 53 referred to the use of ICT in selective suicide prevention, and 52 dealt with the use of ICT in indicated suicide prevention. Conclusions: The use of ICT plays a major role in suicide prevention, and many promising programs were identified through this scoping review. However, large-scale evaluation studies are needed to further examine the effectiveness of these programs and strategies. In addition, safety and ethics protocols for ICT-based interventions are recommended. © Jessica Rassy, Cécile Bardon, Luc Dargis, Louis-Philippe Côté, Laurent Corthésy-Blondin, Carl-Maria Mörch, Réal Labelle. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 04.05.2021. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.},
	author_keywords = {Information and communication technology; Mobile phone; Scoping review; Suicide prevention},
	keywords = {Communication; Humans; Information Technology; Suicide; Technology; adolescent; adult; artificial intelligence; autoanalysis; crisis intervention; education; emergency health service; health promotion; human; information technology; Internet; machine learning; psychoeducation; Review; risk assessment; self care; social media; social network; suicide; systematic review; text messaging; web-based intervention; World Health Organization; young adult; interpersonal communication; technology},
	correspondence_address = {R. Labelle; Department of Psychology, Université du Québec à Montréal, Montréal, CP 8888, succ Centre-Ville, H3C 3P8, Canada; email: labelle.real@uqam.ca},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {33820754},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Elliott2021,
	author = {Elliott, Catherine and Alexander, Caroline and Salt, Alison and Spittle, Alicia J and Boyd, Roslyn N and Badawi, Nadia and Morgan, Catherine and Silva, Desiree and Geelhoed, Elizabeth and Ware, Robert S and Ali, Alishum and McKenzie, Anne and Bloom, David and Sharp, Mary and Ward, Roslyn and Bora, Samudragupta and Prescott, Susan and Woolfenden, Susan and Le, Vuong and Davidson, Sue-Anne and Thornton, Ashleigh and Finlay-Jones, Amy and Jensen, Lynn and Amery, Natasha and Valentine, Jane},
	title = {Early Moves: A Protocol for A Population-Based Prospective Cohort Study to Establish General Movements As An Early Biomarker of Cognitive Impairment in Infants},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {4},
	doi = {10.1136/bmjopen-2020-041695},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104066879&doi=10.1136%2fbmjopen-2020-041695&partnerID=40&md5=5ad76c135385b6834b7e1f8d137c1f5e},
	affiliations = {Curtin University, Perth, WA, Australia; Telethon Kids Institute, Nedlands, WA, Australia; Perth Children's Hospital, Perth, WA, Australia; University of Melbourne, Melbourne, VIC, Australia; The University of Queensland, Brisbane, QLD, Australia; Cerebral Palsy Alliance Research Institute, Sydney, NSW, Australia; Grace Centre for Newborn Intestive Care, The Childrens Hospital at Westmead, Sydney, NSW, Australia; University of Sydney, Sydney, NSW, Australia; University of Western Australia, Perth, WA, Australia; Menzies Health Institute Queensland, Griffith University, Southport, QLD, Australia; Harvard University, Cambridge, MA, United States; University of Notre Dame, Perth, WA, Australia; Mothers, Babies and Women's Health Program, Mater Research Institute, Brisbane, QLD, Australia; University of New South Wales, Kensington, NSW, Australia; Deakin University, Geelong, VIC, Australia; University of Western Australia, Perth, WA, Australia},
	abstract = {Introduction The current diagnostic pathways for cognitive impairment rarely identify babies at risk before 2 years of age. Very early detection and timely targeted intervention has potential to improve outcomes for these children and support them to reach their full life potential. Early Moves aims to identify early biomarkers, including general movements (GMs), for babies at risk of cognitive impairment, allowing early intervention within critical developmental windows to enable these children to have the best possible start to life. Method and analysis Early Moves is a double-masked prospective cohort study that will recruit 3000 term and preterm babies from a secondary care setting. Early Moves will determine the diagnostic value of abnormal GMs (at writhing and fidgety age) for mild, moderate and severe cognitive delay at 2 years measured by the Bayley-4. Parents will use the Baby Moves smartphone application to video their babies' GMs. Trained GMs assessors will be masked to any risk factors and assessors of the primary outcome will be masked to the GMs result. Automated scoring of GMs will be developed through applying machine-based learning to the data and the predictive value for an abnormal GM will be investigated. Screening algorithms for identification of children at risk of cognitive impairment, using the GM assessment (GMA), and routinely collected social and environmental profile data will be developed to allow more accurate prediction of cognitive outcome at 2 years. A cost evaluation for GMA implementation in preparation for national implementation will be undertaken including exploring the relationship between cognitive status and healthcare utilisation, medical costs, health-related quality of life and caregiver burden. Ethics and dissemination Ethics approval has been granted by the Medical Research Ethics Committee of Joondalup Health Services and the Health Service Human Research Ethics Committee (1902) of Curtin University (HRE2019-0739). Trial registration number ACTRN12619001422112.  © },
	author_keywords = {community child health; developmental neurology & neurodisability; paediatrics},
	keywords = {Biomarkers; Child; Child, Preschool; Cognitive Dysfunction; Cohort Studies; Humans; Infant; Infant, Newborn; Prospective Studies; Quality of Life; biological marker; Article; caregiver burden; cognitive defect; cohort analysis; controlled study; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; double blind procedure; female; health care cost; health care utilization; human; infant; machine learning; major clinical study; male; motor dysfunction; population research; predictive value; prematurity; prospective study; quality of life; screening; secondary health care; videorecording; child; newborn; preschool child; quality of life},
	correspondence_address = {J. Valentine; Perth Children's Hospital, Perth, Australia; email: jane.valentine@health.wa.gov.au},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33837094},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ma2021,
	author = {Ma, Huijing and Ye, Qinghao and Ding, Weiping and Jiang, Yinghui and Wang, Minhao and Niu, Zhangming and Zhou, Xi and Gao, Yuan and Wang, Chengjia and Menpes-Smith, Wade and Fang, Evandro Fei and Shao, Jianbo and Xia, Jun and Yang, Guang},
	title = {Can Clinical Symptoms and Laboratory Results Predict CT Abnormality? Initial Findings Using Novel Machine Learning Techniques in Children With COVID-19 Infections},
	year = {2021},
	journal = {Frontiers in Medicine},
	volume = {8},
	doi = {10.3389/fmed.2021.699984},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109042588&doi=10.3389%2ffmed.2021.699984&partnerID=40&md5=57743fa4570cfffd1ad0c792e011b331},
	affiliations = {Imaging Center, Tongji Medical College, Wuhan Children's Hospital (Wuhan Maternal and Child Healthcare Hospital), Huazhong University of Science Technology, Wuhan, China; Hangzhou Ocean's Smart Boya Co., Ltd, Hangzhou, China; Mind Rank Ltd, Hong Kong; School of Information Science and Technology, Nantong University, Nantong, China; Institute of Biomedical Engineering, University of Oxford, Oxford, United Kingdom; Department of Radiology, Shenzhen Second People's Hospital, Hospital of Shenzhen University Health Science Center, Shenzhen, China; Aladdin Healthcare Technologies Ltd, London, United Kingdom; British Heart Foundation (BHF) Centre for Cardiovascular Science, University of Edinburgh, Edinburgh, United Kingdom; Department of Clinical Molecular Biology, University of Oslo, Oslo, Norway; COVID-19 Specialist Team, Wuhan Children's Hospital, Tongji Medical College, Huazhong University of Science Technology, Wuhan, China; Cardiovascular Research Centre, Royal Brompton Hospital, London, United Kingdom; National Heart and Lung Institute, Imperial College London, London, United Kingdom},
	abstract = {The rapid spread of coronavirus 2019 disease (COVID-19) has manifested a global public health crisis, and chest CT has been proven to be a powerful tool for screening, triage, evaluation and prognosis in COVID-19 patients. However, CT is not only costly but also associated with an increased incidence of cancer, in particular for children. This study will question whether clinical symptoms and laboratory results can predict the CT outcomes for the pediatric patients with positive RT-PCR testing results in order to determine the necessity of CT for such a vulnerable group. Clinical data were collected from 244 consecutive pediatric patients (16 years of age and under) treated at Wuhan Children's Hospital with positive RT-PCR testing, and the chest CT were performed within 3 days of clinical data collection, from January 21 to March 8, 2020. This study was approved by the local ethics committee of Wuhan Children's Hospital. Advanced decision tree based machine learning models were developed for the prediction of CT outcomes. Results have shown that age, lymphocyte, neutrophils, ferritin and C-reactive protein are the most related clinical indicators for predicting CT outcomes for pediatric patients with positive RT-PCR testing. Our decision support system has managed to achieve an AUC of 0.84 with 0.82 accuracy and 0.84 sensitivity for predicting CT outcomes. Our model can effectively predict CT outcomes, and our findings have indicated that the use of CT should be reconsidered for pediatric patients, as it may not be indispensable. © Copyright © 2021 Ma, Ye, Ding, Jiang, Wang, Niu, Zhou, Gao, Wang, Menpes-Smith, Fang, Shao, Xia and Yang.},
	author_keywords = {artificial intelligence; COVID-19; decision trees; machine learning; pediatric; RT-PCR—polymerase chain reaction with reverse transcription},
	keywords = {C reactive protein; ferritin; adolescent; age; area under the curve; Article; artificial intelligence; child; clinical indicator; coronavirus disease 2019; decision tree; feature extraction; female; human; human cell; lymphocyte; machine learning; major clinical study; male; neutrophil; outcome assessment; pediatric patient; reverse transcription polymerase chain reaction; sensitivity and specificity; symptomatology; x-ray computed tomography},
	correspondence_address = {J. Xia; Department of Radiology, Shenzhen Second People's Hospital, Hospital of Shenzhen University Health Science Center, Shenzhen, China; email: xiajun@email.szu.edu.cn; J. Shao; COVID-19 Specialist Team, Wuhan Children's Hospital, Tongji Medical College, Huazhong University of Science Technology, Wuhan, China; email: drshaojb@sina.com; G. Yang; Cardiovascular Research Centre, Royal Brompton Hospital, London, United Kingdom; email: g.yang@imperial.ac.uk},
	publisher = {Frontiers Media S.A.},
	issn = {2296858X},
	language = {English},
	abbrev_source_title = {Front. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Martinez-Martin2021,
	author = {Martinez-Martin, Nicole and Greely, Henry T. and Cho, Mildred K.},
	title = {Ethical development of digital phenotyping tools for mental health applications: Delphi study},
	year = {2021},
	journal = {JMIR mHealth and uHealth},
	volume = {9},
	number = {7},
	doi = {10.2196/27343},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111624017&doi=10.2196%2f27343&partnerID=40&md5=321edf9b5bfc3e0a4c99f9c091955705},
	affiliations = {Center for Biomedical Ethics, School of Medicine, Stanford University, Stanford, CA, United States; Stanford Law School, Stanford, CA, United States},
	abstract = {Background: Digital phenotyping (also known as personal sensing, intelligent sensing, or body computing) involves the collection of biometric and personal data in situ from digital devices, such as smartphones, wearables, or social media, to measure behavior or other health indicators. The collected data are analyzed to generate moment-by-moment quantification of a person's mental state and potentially predict future mental states. Digital phenotyping projects incorporate data from multiple sources, such as electronic health records, biometric scans, or genetic testing. As digital phenotyping tools can be used to study and predict behavior, they are of increasing interest for a range of consumer, government, and health care applications. In clinical care, digital phenotyping is expected to improve mental health diagnoses and treatment. At the same time, mental health applications of digital phenotyping present significant areas of ethical concern, particularly in terms of privacy and data protection, consent, bias, and accountability. Objective: This study aims to develop consensus statements regarding key areas of ethical guidance for mental health applications of digital phenotyping in the United States. Methods: We used a modified Delphi technique to identify the emerging ethical challenges posed by digital phenotyping for mental health applications and to formulate guidance for addressing these challenges. Experts in digital phenotyping, data science, mental health, law, and ethics participated as panelists in the study. The panel arrived at consensus recommendations through an iterative process involving interviews and surveys. The panelists focused primarily on clinical applications for digital phenotyping for mental health but also included recommendations regarding transparency and data protection to address potential areas of misuse of digital phenotyping data outside of the health care domain. Results: The findings of this study showed strong agreement related to these ethical issues in the development of mental health applications of digital phenotyping: privacy, transparency, consent, accountability, and fairness. Consensus regarding the recommendation statements was strongest when the guidance was stated broadly enough to accommodate a range of potential applications. The privacy and data protection issues that the Delphi participants found particularly critical to address related to the perceived inadequacies of current regulations and frameworks for protecting sensitive personal information and the potential for sale and analysis of personal data outside of health systems. Conclusions: The Delphi study found agreement on a number of ethical issues to prioritize in the development of digital phenotyping for mental health applications. The Delphi consensus statements identified general recommendations and principles regarding the ethical application of digital phenotyping to mental health. As digital phenotyping for mental health is implemented in clinical care, there remains a need for empirical research and consultation with relevant stakeholders to further understand and address relevant ethical issues. © Nicole Martinez-Martin, Henry T Greely, Mildred K Cho. Originally published in JMIR mHealth and uHealth (https://mhealth.jmir.org), 28.07.2021. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in JMIR mHealth and uHealth, is properly cited. The complete bibliographic information, a link to the original publication on https://mhealth.jmir.org/, as well as this copyright and license information must be included.},
	author_keywords = {Artificial intelligence; Delphi study; Digital mental health; Digital phenotyping; Ethics; Machine learning; Mental health; Mobile phone; Neuroethics},
	keywords = {Delphi Technique; Electronic Health Records; Humans; Mental Health; Privacy; Smartphone; United States; Delphi study; electronic health record; human; mental health; privacy; smartphone; United States},
	correspondence_address = {N. Martinez-Martin; Center for Biomedical Ethics, School of Medicine, Stanford University, Modular A Stanford, 1215 Welch Road, 94305, United States; email: nicolemz@stanford.edu},
	publisher = {JMIR Publications Inc.},
	issn = {22915222},
	pmid = {34319252},
	language = {English},
	abbrev_source_title = {JMIR mHealth uHealth},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Holst202169,
	author = {Holst, Jonas},
	title = {Ethical rationality in AI: On the prospect of becoming a full ethical agent},
	year = {2021},
	journal = {Machine Law, Ethics, and Morality in the Age of Artificial Intelligence},
	pages = {69 – 84},
	doi = {10.4018/978-1-7998-4894-3.ch005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123951968&doi=10.4018%2f978-1-7998-4894-3.ch005&partnerID=40&md5=f9036eb0cba322e9ca73874e7aaeea72},
	affiliations = {San Jorge University, Spain},
	abstract = {Taking its starting point in a discussion of the concept of intelligence, the chapter develops a philosophical understanding of ethical rationality and discusses its role and implications for two ethical problems within AI: Firstly, the so-called "black box problem," which is widely discussed in the AI community, and secondly, another more complex one which will be addressed as the "Tin Man problem. " The first problem has to do with opacity, bias, and explainability in the design and development of advanced machine learning systems, such as artificial neural networks, whereas the second problem is more directly associated with the prospect for humans and AI of becoming full ethical agents. Based on Aristotelian virtue ethics, it will be argued that intelligence in human and artificial forms should approximate ethical rationality, which entails a well-balanced synthesis of reason and emotion. © 2021, IGI Global.},
	publisher = {IGI Global},
	isbn = {978-179984895-0; 978-179984894-3},
	language = {English},
	abbrev_source_title = {Mach. Law, Ethics, and Moral. in the Age of Artif. Intell.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Quinn2021890,
	author = {Quinn, Thomas P. and Senadeera, Manisha and Jacobs, Stephan and Coghlan, Simon and Le, Vuong},
	title = {Trust and medical AI: the challenges we face and the expertise needed to overcome them},
	year = {2021},
	journal = {Journal of the American Medical Informatics Association},
	volume = {28},
	number = {4},
	pages = {890 – 894},
	doi = {10.1093/jamia/ocaa268},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103226535&doi=10.1093%2fjamia%2focaa268&partnerID=40&md5=7a51ccaf18c931a892a12243cec3f387},
	affiliations = {Applied Artificial Intelligence Institute, Deakin University, Geelong, VIC, Australia; Centre for AI and Digital Ethics, School of Computing and Information Systems, University of Melbourne, Melbourne, VIC, Australia},
	abstract = {Artificial intelligence (AI) is increasingly of tremendous interest in the medical field. How-ever, failures of medical AI could have serious consequences for both clinical outcomes and the patient experience. These consequences could erode public trust in AI, which could in turn undermine trust in our healthcare institutions. This article makes 2 contributions. First, it describes the major conceptual, technical, and humanistic challenges in medical AI. Second, it proposes a solution that hinges on the education and accreditation of new expert groups who specialize in the development, verification, and operation of medical AI technologies. These groups will be required to maintain trust in our healthcare institutions. © 2020 The Author(s).},
	author_keywords = {AI; challenges; ethics; machine learning},
	keywords = {Accreditation; Algorithms; Artificial Intelligence; Attitude to Computers; Attitude to Health; Humans; Medical Informatics; Trust; accreditation; adult; article; artificial intelligence; clinical outcome; education; ethics; human; machine learning; outcome assessment; trust; algorithm; attitude to computers; attitude to health; education; ethics; medical informatics},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	pmid = {33340404},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Green Open Access}
}

@ARTICLE{Ligo2021,
	author = {Ligo, Alexandre K. and Rand, Krista and Bassett, Jason and Galaitsi, S.E. and Trump, Benjamin D. and Jayabalasingham, Bamini and Collins, Thomas and Linkov, Igor},
	title = {Comparing the Emergence of Technical and Social Sciences Research in Artificial Intelligence},
	year = {2021},
	journal = {Frontiers in Computer Science},
	volume = {3},
	doi = {10.3389/fcomp.2021.653235},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116056049&doi=10.3389%2ffcomp.2021.653235&partnerID=40&md5=c3c329573a2fe2034eab6ce143a9d901},
	affiliations = {US Army Corps of Engineers, Engineer Research and Development Center, Environmental Laboratory, Concord, MA, United States; Department of Engineering Systems and Environment, University of Virginia, Charlottesville, VA, United States; Max Planck Institute for Human Development, Berlin, Germany; Elsevier, New York, NY, United States; Department of Engineering and Public Policy, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {Applications of Artificial Intelligence (AI) can be examined from perspectives of different disciplines and research areas ranging from computer science and security, engineering, policymaking, and sociology. The technical scholarship of emerging technologies usually precedes the discussion of their societal implications but can benefit from social science insight in scientific development. Therefore, there is an urgent need for scientists and engineers developing AI algorithms and applications to actively engage with scholars in the social sciences. Without collaborative engagement, developers may encounter resistance to the approval and adoption of their technological advancements. This paper reviews a dataset, collected by Elsevier from the Scopus database, of papers on AI application published between 1997 and 2018, and examines how the co-development of technical and social science communities has grown throughout AI's earliest to latest stages of development. Thus far, more AI research exists that combines social science and technical explorations than AI scholarship of social sciences alone, and both categories are dwarfed by technical research. Moreover, we identify a relative absence of AI research related to its societal implications such as governance, ethics, or moral implications of the technology. The future of AI scholarship will benefit from both technical and social science examinations of the discipline's risk assessment, governance, and public engagement needs, to foster advances in AI that are sustainable, risk-informed, and societally beneficial. © Copyright © 2021 Ligo, Rand, Bassett, Galaitsi, Trump, Jayabalasingham, Collins and Linkov.},
	author_keywords = {AI; machine learning; review – systematic; risk; taxonomy},
	correspondence_address = {I. Linkov; US Army Corps of Engineers, Engineer Research and Development Center, Environmental Laboratory, Concord, United States; email: igor.linkov@usace.army.mil},
	publisher = {Frontiers Media S.A.},
	issn = {26249898},
	language = {English},
	abbrev_source_title = {Frontier. Comput. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Grässler2021,
	author = {Grässler, Bernhard and Herold, Fabian and Dordevic, Milos and Gujar, Tariq Ali and Darius, Sabine and Böckelmann, Irina and Müller, Notger G and Hökelmann, Anita},
	title = {Multimodal measurement approach to identify individuals with mild cognitive impairment: Study protocol for a cross-sectional trial},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {5},
	doi = {10.1136/bmjopen-2020-046879},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106954402&doi=10.1136%2fbmjopen-2020-046879&partnerID=40&md5=39b1876ef94c4f1528886ac6275f50df},
	affiliations = {Institute of Sport Science, Faculty of Humanities, Otto von Guericke University Magdeburg, Magdeburg, Germany; Department of Neuroprotection, German Centre for Neurodegenerative Diseases Site Magdeburg, Magdeburg, Germany; Occupational Medicine, Otto von Guericke University Medical Faculty, Magdeburg, Germany; Department of Neurology, Otto von Guericke University Medical Faculty, Magdeburg, Germany},
	abstract = {Introduction The diagnosis of mild cognitive impairment (MCI), that is, the transitory phase between normal age-related cognitive decline and dementia, remains a challenging task. It was observed that a multimodal approach (simultaneous analysis of several complementary modalities) can improve the classification accuracy. We will combine three noninvasive measurement modalities: functional near-infrared spectroscopy (fNIRS), electroencephalography and heart rate variability via ECG. Our aim is to explore neurophysiological correlates of cognitive performance and whether our multimodal approach can aid in early identification of individuals with MCI. Methods and analysis This study will be a cross-sectional with patients with MCI and healthy controls (HC). The neurophysiological signals will be measured during rest and while performing cognitive tasks: (1) Stroop, (2) N-back and (3) verbal fluency test (VFT). Main aims of statistical analysis are to (1) determine the differences in neurophysiological responses of HC and MCI, (2) investigate relationships between measures of cognitive performance and neurophysiological responses and (3) investigate whether the classification accuracy can be improved by using our multimodal approach. To meet these targets, statistical analysis will include machine learning approaches. This is, to the best of our knowledge, the first study that applies simultaneously these three modalities in MCI and HC. We hypothesise that the multimodal approach improves the classification accuracy between HC and MCI as compared with a unimodal approach. If our hypothesis is verified, this study paves the way for additional research on multimodal approaches for dementia research and fosters the exploration of new biomarkers for an early detection of nonphysiological age-related cognitive decline. Ethics and dissemination Ethics approval was obtained from the local Ethics Committee (reference: 83/19). Data will be shared with the scientific community no more than 1 year following completion of study and data assembly. Trial registration number ClinicalTrials.gov, NCT04427436, registered on 10 June 2020, https://clinicaltrials.gov/ct2/show/study/NCT04427436.  © 2021 BMJ Publishing Group. All rights reserved.},
	author_keywords = {cardiology; dementia; mental health; neurophysiology; physiology},
	keywords = {Cognitive Dysfunction; Cross-Sectional Studies; Early Diagnosis; Humans; Machine Learning; Rest; adult; aged; Article; clinical trial protocol; cognitive function test; controlled clinical trial; controlled study; cross-sectional study; diagnostic accuracy; diagnostic test accuracy study; disease classification; electrocardiogram; electroencephalogram; exploratory research; female; functional near-infrared spectroscopy; heart rate variability; human; information processing; machine learning; major clinical study; male; mild cognitive impairment; multidisciplinary team; n-back test; neurophysiological monitoring; rest; Stroop test; task performance; verbal fluency test; cognitive defect; early diagnosis},
	correspondence_address = {N.G. Müller; Department of Neurology, Otto von Guericke University Medical Faculty, Magdeburg, Germany; email: bernhard.graessler@ovgu.de},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34035103},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Benjdir2021,
	author = {Benjdir, Manon and Audureau, Étienne and Beresniak, Ariel and Coll, Patrice and Epaud, Ralph and Fiedler, Kristina and Jacquemin, Bénédicte and Niddam, Laurent and Pandis, Spyros N. and Pohlmann, Gerhard and Sandanger, Torkjel M. and Simmons, Kai and Sørensen, Mette and Wagner, Patrick and Lanone, Sophie},
	title = {Assessing the impact of exposome on the course of chronic obstructive pulmonary disease and cystc fibrosis: The REMEDIA European Project Approach},
	year = {2021},
	journal = {Environmental Epidemiology},
	volume = {5},
	number = {4},
	doi = {10.1097/EE9.0000000000000165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113732607&doi=10.1097%2fEE9.0000000000000165&partnerID=40&md5=0dfb7dfc25cfe672df7bb9cc99e1f8f0},
	affiliations = {University Paris-Est Créteil, INSERM, IMRB, Creteil, France; Public Health Department, Clinical Research Unit (URC), Hôpital Henri-Mondor, Assistance Publique Hôpitaux de Paris (APHP), Créteil, France; Data Mining International SA, Geneva, Switzerland; Laboratoire Interuniversitaire des Systèmes Atmosphériques, UMR CNRS 7583, Université de Paris et Université Paris-Est Créteil, Institut Pierre Simon Laplace, Créteil, France; Department of General Pediatrics, Centre Hospitalier Intercommunal de Créteil, Créteil, France; Center for Rare Lung Diseases (RESPIRARE), Créteil, France; INSERM Transfert, Paris, France; Université Rennes 1, INSERM, EHESP, Irset (Institut de Recherche en Santé, Environnement et Travail) - UMR_S 1085, Rennes, France; Wellspring Kft, Budapest, Hungary; Institute of Chemical Engineering Sciences, FORTH, Patras, Greece; Department of Chemical Engineering, University of Patras, Patras, Greece; Fraunhofer Institute for Toxicology and Experimental Medicine, Hannover, Germany; Department of Community Medicine, Health Faculty, UiT, The Arctic University of Norway, Tromsø, Norway; Lipotype GmbH, Dresden, Germany; Max Planck Institute of Molecular Cell Biology and Genetics, Dresden, Germany; Diet, Genes and Environment, Danish Cancer Society Research Center, Copenhagen, Denmark; Department of Natural Science and Environment, Roskilde University, Roskilde, Denmark; KU Leuven, Laboratory for Soft Matter and Biophysics, Leuven, Belgium},
	abstract = {Because of the direct interaction of lungs with the environment, respiratory diseases are among the leading causes of environment-related deaths in the world. Chronic obstructive pulmonary disease (COPD) and cystic fibrosis (CF) are two highly debilitating diseases that are of particular interest in the context of environmental studies; they both are characterized by a similar progressive loss of lung function with small bronchi alterations, and a high phenotypic variability of unknown origin, which prevents a good therapeutic efficacy. In the last years, there has been an evolution in the apprehension of the study of diseases going from a restricted "one exposure, one disease" approach to a broader concept with other associating factors, the exposome. The overall objective of the REMEDIA project is to extend the understanding of the contribution of the exposome to COPD and CF diseases. To achieve our aim, we will (1) exploit data from existing cohorts and population registries to create a unified global database gathering phenotype and exposome information; (2) develop a flexible individual sensor device combining environmental and biomarker toolkits; (3) use a versatile atmospheric simulation chamber to simulate the health effects of complex exposomes; (4) use machine learning supervised analyses and causal inference models to identify relevant risk factors; and (5) develop econometric and cost-effectiveness models to assess the costs, performance, and cost-effectiveness of a selection of prevention strategies. The results will be used to develop guidelines to better predict disease risks and constitute the elements of the REMEDIA toolbox. The multidisciplinary approach carried out by the REMEDIA European project should represent a major breakthrough in reducing the morbidity and mortality associated with COPD and CF diseases. © 2021 Wolters Kluwer Health. All rights reserved.},
	author_keywords = {Chronic ostructive pulmonary disease; Cystic fibrosis; Exposome},
	keywords = {3 nitrotyrosine; acetylene; aptamer; benzene; biological marker; carbon monoxide; ethane; ethylbenzene; hexanal; meta xylene; molecularly imprinted polymer; nitric oxide; nitrous acid; organic carbon; ortho xylene; ozone; para xylene; pentane; toluene; aerosol; anxiety; Article; biologist; chemist (profession); chronic obstructive lung disease; cohort analysis; coronavirus disease 2019; cost; cost effectiveness analysis; cost effectiveness model; cystic fibrosis; data base; data integration; disease course; disease exacerbation; dust; economist; engineer; environmental impact assessment; environmental parameters; epidemiologist; ethics; experience; experiment; exposome; hospital; human; impedance spectroscopy; inflammation; knowledge; lockdown; lung function; lung specialist; machine learning; major clinical study; management; medical specialist; model; multinational corporation; normal human; occupation; organization; pandemic; particulate matter; patient care; patient compliance; pediatrician; performance; phenotype; physiological stress; pollutant; population register; practice guideline; predictive model; proof of concept; public health specialist; quantitative analysis; questionnaire; relative humidity; research; retention time; risk assessment; risk factor; simulation; solar radiation; soot; technology; temperature},
	correspondence_address = {S. Lanone; INSERM U955, Institut Mondor de Recherche Biomédicale, Faculté de Santé, Créteil, 8 rue du Général Sarrail, 94010, France; email: sophie.lanone@inserm.fr},
	publisher = {Wolters Kluwer Health},
	issn = {24747882},
	language = {English},
	abbrev_source_title = {Environ.  Epidemiology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sawhney20211497,
	author = {Sawhney, Ramit and Joshi, Harshit and Gandhi, Saumya and Jin, Di and Shah, Rajiv Ratn},
	title = {Robust suicide risk assessment on social media via deep adversarial learning},
	year = {2021},
	journal = {Journal of the American Medical Informatics Association},
	volume = {28},
	number = {7},
	pages = {1497 – 1506},
	doi = {10.1093/jamia/ocab031},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112125142&doi=10.1093%2fjamia%2focab031&partnerID=40&md5=a86e54d7607b8112c0fcc06fa868c0ef},
	affiliations = {MIDAS, IIIT Delhi, Okhla Industrial Estate, Phase III, New Delhi, 110020, India; Cluster Innovation Centre, University of Delhi, New Delhi, India; Computer Science, Visvesvaraya National Institute of Technology, Nagpur, India; Computer Science and Artificial Intelligence Lab, Massachussetts Institute of Technology, Cambridge, MA, United States},
	abstract = {Objective: The prevalence of social media for sharing personal thoughts makes it a viable platform for the assessment of suicide risk. However, deep learning models are not able to capture the diverse nature of linguistic choices and temporal patterns that can be exhibited by a suicidal user on social media and end up overfitting on specific cues that are not generally applicable. We propose Adversarial Suicide assessment Hierarchical Attention (ASHA), a hierarchical attention model that employs adversarial learning for improving the generalization ability of the model. Material and Methods: We assess the suicide risk of a social media user across 5 levels of increasing severity of risk. ASHA leverages a transformer-based architecture to learn the semantic nature of social media posts and a temporal attention-based long short-term memory architecture for the sequential modeling of a user's historical posts. We dynamically generate adversarial examples by adding perturbations to actual examples that can simulate the stochasticity in historical posts, thereby making the model robust. Results: Through extensive experiments, we establish the face-value of ASHA and show that it significantly outperforms existing baselines, with the F1 score of 64%. This is a 2% and a 4% increase over the ContextBERT and ContextCNN baselines, respectively. Finally, we discuss the practical applicability and ethical aspects of our work pertaining to ASHA, as a human-in-the-loop framework. Discussion and Conclusions: Adversarial samples can be helpful in capturing the diverse nature of suicidal ideation. Through ASHA, we hope to form a component in a larger human-in-the-loop infrastructure for suicide risk assessment on social media. © 2021 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.},
	author_keywords = {adversarial learning; machine learning; ordinal regression; social media; suicidal ideation},
	keywords = {Data Collection; Humans; Risk Assessment; Semantics; Social Media; Suicidal Ideation; Article; comparative study; controlled study; deep adversarial learning; deep learning; embedding; human; identifiable information; medical ethics; mental health; predictor variable; probability; qualitative analysis; risk assessment; short term memory; social media; suicidal ideation; suicide; transfer of learning; information processing; risk assessment; semantics},
	correspondence_address = {R. Sawhney; MIDAS, IIIT Delhi, New Delhi, Okhla Industrial Estate, Phase III, 110020, India; email: ramits@iiitd.ac.in},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	pmid = {33779728},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@CONFERENCE{Abid2021298,
	author = {Abid, Abubakar and Farooqi, Maheen and Zou, James},
	title = {Persistent Anti-Muslim Bias in Large Language Models},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {298 – 306},
	doi = {10.1145/3461702.3462624},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112473369&doi=10.1145%2f3461702.3462624&partnerID=40&md5=946d60647e36720c4e16d86afe3dd05a},
	affiliations = {Stanford University, Stanford, CA, United States},
	abstract = {It has been observed that large-scale language models capture undesirable societal biases, e.g. relating to race and gender; yet religious bias has been relatively unexplored. We demonstrate that GPT-3, a state-of-the-art contextual language model, captures persistent Muslim-violence bias. We probe GPT-3 in various ways, including prompt completion, analogical reasoning, and story generation, to understand this anti-Muslim bias, demonstrating that it appears consistently and creatively in different uses of the model and that it is severe even compared to biases about other religious groups. For instance, Muslim is analogized to terrorist in 23% of test cases, while Jewish is mapped to its most common stereotype, money, in 5% of test cases. We quantify the positive distraction needed to overcome this bias with adversarial text prompts, and find that use of the most positive 6 adjectives reduces violent completions for Muslims from 66% to 20%, but which is still higher than for other religious groups. © 2021 ACM.},
	author_keywords = {bias; ethics; language models; machine learning; stereotypes},
	keywords = {Computational linguistics; Philosophical aspects; Analogical reasoning; Language model; Religious groups; State of the art; Story generations; Test case; Artificial intelligence},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685; All Open Access, Green Open Access}
}

@ARTICLE{Utts20211,
	author = {Utts, Jessica},
	title = {Enhancing Data Science Ethics Through Statistical Education and Practice},
	year = {2021},
	journal = {International Statistical Review},
	volume = {89},
	number = {1},
	pages = {1 – 17},
	doi = {10.1111/insr.12446},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102624847&doi=10.1111%2finsr.12446&partnerID=40&md5=b81140a3aaf75a19da8da6515ec60261},
	affiliations = {University of California, Irvine, CA, United States},
	abstract = {As sources of data become more plentiful and massive datasets are easier to acquire, new ethical issues arise involving data quality and privacy, and the analysis, interpretation and dissemination of data-driven decisions. There are numerous anecdotes involving abuses of complex data analyses and algorithms, and the impact they have had on society. In this paper, we discuss what statisticians can do to help enhance data science ethics in practice and what statistics educators can do to instil sound ethical behaviour in our students. We have opportunities to practice and teach ethical conduct relevant to all stages of the data life cycle. This paper discusses issues impacting ethical data science, with a focus on how statisticians can help raise awareness and encourage implementation of ethical best practices. © 2021 International Statistical Institute.},
	author_keywords = {data literacy; Data science ethics; ethical guidelines for statisticians; machine learning ethics; statistical education; statistical literacy},
	correspondence_address = {J. Utts; University of California, Irvine, United States; email: jutts@uci.edu},
	publisher = {International Statistical Institute},
	issn = {03067734},
	language = {English},
	abbrev_source_title = {Int. Stat. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{De Zulueta2021420,
	author = {De Zulueta, Paquita},
	title = {Confidentiality, privacy, and general practice: GPDPR and the brave new world of 'big data'},
	year = {2021},
	journal = {British Journal of General Practice},
	volume = {71},
	number = {710},
	pages = {420 – 421},
	doi = {10.3399/bjgp21X717017},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113995033&doi=10.3399%2fbjgp21X717017&partnerID=40&md5=f71b178e5e7c4db81f4917332224bd84},
	keywords = {Big Data; Confidentiality; Family Practice; General Practice; Humans; Privacy; anonymised data; Article; big data; clinical research; confidentiality; data analysis; data extraction; data privacy; data protection; decision making; general practice; general practitioner; health care management; health care planning; health data; human; information processing; informed consent; legal aspect; machine learning; medical ethics; national health service; patient care; trust; confidentiality; general practice; privacy},
	publisher = {Royal College of General Practitioners},
	issn = {09601643},
	coden = {BJGPE},
	pmid = {34446416},
	language = {English},
	abbrev_source_title = {Br. J. Gen. Pract.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Bloom2021863,
	author = {Bloom, Bruce},
	title = {Building the future of drug discovery},
	year = {2021},
	journal = {Drug Discovery Today},
	volume = {26},
	number = {4},
	pages = {863 – 864},
	doi = {10.1016/j.drudis.2021.01.032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100536877&doi=10.1016%2fj.drudis.2021.01.032&partnerID=40&md5=0ab9b82ce76ad2d5edb25b35da7bea21},
	affiliations = {Healx, United Kingdom},
	keywords = {Artificial Intelligence; Drug Development; Drug Discovery; Drug Industry; Humans; Machine Learning; Rare Diseases; Technology, Pharmaceutical; dexamethasone; new drug; sildenafil; tocilizumab; accuracy; artificial intelligence; coronavirus disease 2019; critically ill patient; drug development; drug industry; drug repositioning; Editorial; futurology; human; machine learning; patient safety; pharmaceutical care; rare disease; risk reduction; drug industry; ethics; pharmaceutics; procedures; rare disease},
	publisher = {Elsevier Ltd},
	issn = {13596446},
	coden = {DDTOF},
	pmid = {33548463},
	language = {English},
	abbrev_source_title = {Drug Discov. Today},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Taylor2021,
	author = {Taylor, Anna and Lowe, David J. and McDowell, Grace and Lua, Stephanie and Burns, Shane and McGinness, Paul and Carlin, Christopher M.},
	title = {Remote-Management of COPD: Evaluating the Implementation of Digital Innovation to Enable Routine Care (RECEIVER): The protocol for a feasibility and service adoption observational cohort study},
	year = {2021},
	journal = {BMJ Open Respiratory Research},
	volume = {8},
	number = {1},
	doi = {10.1136/bmjresp-2021-000905},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114245775&doi=10.1136%2fbmjresp-2021-000905&partnerID=40&md5=df9654b5fd3b16b72880fb866b37c654},
	affiliations = {Respiratory Medicine, Queen Elizabeth University Hospital, Glasgow, United Kingdom; Emergency Medicine, Queen Elizabeth University Hospital, Glasgow, United Kingdom; Lenus Digital Health, StormID, Edinburgh, United Kingdom},
	abstract = {Introduction Reductions in exacerbation and hospitalisations are the outcomes rated as most important by people with chronic obstructive pulmonary disease (COPD). Most COPD management is currently based on a reactive approach, and delays in recognising treatable opportunities underpin COPD care quality gaps. Innovations that empower COPD self-management, facilitate integrated clinical care and support delivery of evidence-based treatment interventions are urgently required. Methods and analysis The Remote-Management of COPD: Evaluating the Implementation of Digital Innovation to Enable Routine Care trial is a prospective observational cohort hybrid implementation and effectiveness study that will explore the adoption of a digital service model for people with â € high-risk' COPD and evaluate the feasibility of this approach versus current standards of care. People with COPD, who have had recent severe exacerbation and/or COPD-obstructive sleep apnoea overlap or chronic hypercapnic respiratory failure requiring home non-invasive ventilation (NIV) or continuous positive airway pressure (CPAP), with internet access will be recruited into the study and enrolled into the digital service. Study endpoints will examine participant utilisation, clinical service impact and clinical outcomes compared with historical and contemporary control patient data. The digital infrastructure will also provide a foundation to explore the feasibility of approaches to predict outcomes and exacerbation in people with COPD through machine learning analysis. Ethics and dissemination Ethical approval for this clinical trial has been obtained from the West of Scotland Research Ethics Service. The trial will commence in September 2019 for a duration of 2 years. Results will be presented at local, national and international meetings, as well as submission for publication to peer-reviewed journals.  © Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY. Published by BMJ.},
	author_keywords = {COPD exacerbations; emphysema; non invasive ventilation},
	keywords = {Cohort Studies; Feasibility Studies; Humans; Noninvasive Ventilation; Observational Studies as Topic; Pulmonary Disease, Chronic Obstructive; Quality of Life; bronchodilating agent; adoption; adult; airway pressure; Article; breathing rate; Charlson Comorbidity Index; chronic hypercapnic respiratory failure; chronic obstructive lung disease; cohort analysis; comorbidity; continuous positive airway pressure; dyspnea; electromyography; electronic health record; emphysema; eosinophil count; feasibility study; female; follow up; heart rate; heart rate variability; hospitalization; human; information storage; internet access; length of stay; lung function test; machine learning; male; mobile application; noninvasive ventilation; observational study; oscillometry; outcome assessment; patient coding; pharmacist; pilot study; pulmonary rehabilitation; quality of life; questionnaire; respiration control; respiratory failure; self care; semi structured interview; spirometry; thematic analysis; tidal volume; vaccination; chronic obstructive lung disease; feasibility study; noninvasive ventilation},
	correspondence_address = {A. Taylor; Respiratory Medicine, Queen Elizabeth University Hospital, Glasgow, United Kingdom; email: Anna.Taylor@ggc.scot.nhs.uk; C.M. Carlin; Respiratory Medicine, Queen Elizabeth University Hospital, Glasgow, United Kingdom; email: Christopher.Carlin@ggc.scot.nhs.uk},
	publisher = {BMJ Publishing Group},
	issn = {20524439},
	pmid = {34462271},
	language = {English},
	abbrev_source_title = {BMJ Open Respir. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Bogner202164,
	author = {Bogner, Justus and Verdecchia, Roberto and Gerostathopoulos, Ilias},
	title = {Characterizing Technical Debt and Antipatterns in AI-Based Systems: A Systematic Mapping Study},
	year = {2021},
	journal = {Proceedings - 2021 IEEE/ACM International Conference on Technical Debt, TechDebt 2021},
	pages = {64 – 73},
	doi = {10.1109/TechDebt52882.2021.00016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114832074&doi=10.1109%2fTechDebt52882.2021.00016&partnerID=40&md5=d2a18c8a42af690521e2a1a5b47df62c},
	affiliations = {Institute of Software Engineering, University of Stuttgart, Stuttgart, Germany; Vrije Universiteit Amsterdam, Department of Computer Science, Amsterdam, Netherlands},
	abstract = {Background: With the rising popularity of Artificial Intelligence (AI), there is a growing need to build large and complex AI-based systems in a cost-effective and manageable way. Like with traditional software, Technical Debt (TD) will emerge naturally over time in these systems, therefore leading to challenges and risks if not managed appropriately. The influence of data science and the stochastic nature of AI-based systems may also lead to new types of TD or antipatterns, which are not yet fully understood by researchers and practitioners. Objective: The goal of our study is to provide a clear overview and characterization of the types of TD (both established and new ones) that appear in AI-based systems, as well as the antipatterns and related solutions that have been proposed. Method: Following the process of a systematic mapping study, 21 primary studies are identified and analyzed. Results: Our results show that (i) established TD types, variations of them, and four new TD types (data, model, configuration, and ethics debt) are present in AI-based systems, (ii) 72 antipatterns are discussed in the literature, the majority related to data and model deficiencies, and (iii) 46 solutions have been proposed, either to address specific TD types, antipatterns, or TD in general. Conclusions: Our results can support AI professionals with reasoning about and communicating aspects of TD present in their systems. Additionally, they can serve as a foundation for future research to further our understanding of TD in AI-based systems.  © 2021 IEEE.},
	author_keywords = {Antipatterns; Artificial Intelligence; Machine Learning; Systematic Mapping Study; Technical Debt},
	keywords = {Cost effectiveness; Data Science; Mapping; Stochastic systems; Anti-patterns; Cost effective; Stochastic nature; Systematic mapping studies; Technical debts; Artificial intelligence},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166541405-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/ACM Int. Conf. Tech. Debt, TechDebt},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 4th IEEE/ACM International Conference on Technical Debt, TechDebt 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 171165; All Open Access, Green Open Access}
}

@ARTICLE{Chen2021123,
	author = {Chen, Irene Y. and Pierson, Emma and Rose, Sherri and Joshi, Shalmali and Ferryman, Kadija and Ghassemi, Marzyeh},
	title = {Ethical Machine Learning in Healthcare},
	year = {2021},
	journal = {Annual Review of Biomedical Data Science},
	volume = {4},
	pages = {123 – 144},
	doi = {10.1146/annurev-biodatasci-092820-114757},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128742260&doi=10.1146%2fannurev-biodatasci-092820-114757&partnerID=40&md5=d50d318508bdc047f1111df4715d6e49},
	affiliations = {Department of Electrical Engineering and Computer Science, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States; Microsoft Research, Cambridge, 02143, MA, United States; Center for Health Policy and Center for Primary Care and Outcomes Research, Stanford University, Stanford, 94305, CA, United States; Vector Institute, Toronto, M5G 1M1, ON, Canada; Department of Technology, Culture, and Society, Tandon School of Engineering, New York University, Brooklyn, 11201, NY, United States; Institute for Medical and Evaluative Sciences, Massachusetts Institute of Technology, Cambridge, 02139, MA, United States},
	abstract = {The use of machine learning (ML) in healthcare raises numerous ethical concerns, especially as models can amplify existing health inequities. Here, we outline ethical considerations for equitable ML in the advancement of healthcare. Specifically, we frame ethics of ML in healthcare through the lens of social justice. We describe ongoing efforts and outline challenges in a proposed pipeline of ethical ML in health, ranging from problem selection to postdeployment considerations. We close by summarizing recommendations to address these challenges. © 2020 by Annual Reviews. All rights reserved.},
	author_keywords = {bias; ethics; health; health disparities; healthcare; machine learning},
	keywords = {Delivery of Health Care; Health Facilities; Machine Learning; Morals; Social Justice; health care delivery; health care facility; machine learning; morality; social justice},
	publisher = {Annual Reviews Inc.},
	issn = {25743414},
	pmid = {34396058},
	language = {English},
	abbrev_source_title = {Annu. Rev. Biomed. Data Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 85; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Khamisy-Farah2021,
	author = {Khamisy-Farah, Rola and Gilbey, Peter and Furstenau, Leonardo B. and Sott, Michele Kremer and Farah, Raymond and Viviani, Maurizio and Bisogni, Maurizio and Kong, Jude Dzevela and Ciliberti, Rosagemma and Bragazzi, Nicola Luigi},
	title = {Big data for biomedical education with a focus on the covid-19 era: An integrative review of the literature},
	year = {2021},
	journal = {International Journal of Environmental Research and Public Health},
	volume = {18},
	number = {17},
	doi = {10.3390/ijerph18178989},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113546517&doi=10.3390%2fijerph18178989&partnerID=40&md5=d9dcc718aa0b917324d63a4b1f8d88c9},
	affiliations = {Clalit Health Service, Akko, Azrieli Faculty of Medicine, Bar-Ilan University, Safed, 13100, Israel; Azrieli Faculty of medicine, Bar Ilan University, Safed, 13100, Israel; Department of Industrial Engineering, Federal University of Rio Grande do Sul, Porto Alegre, 90035-190, Brazil; Business School, Unisinos University, Porto Alegre, 91330-002, Brazil; Department of Internal Medicine B, Ziv Medical Center, Azrieli Faculty of Medicine, Bar-Ilan University, Safed, 13100, Israel; TransHumanGene, MedicaSwiss, Cham, Zug, 6330, Switzerland; Laboratory for Industrial and Applied Mathematics (LIAM), Department of Mathematics and Statistics, York University, Toronto, M3J 1P3, ON, Canada; Section of History of Medicine and Bioethics, Department of Health Sciences (DISSAL), University of Genoa, Genoa, 16132, Italy},
	abstract = {Medical education refers to education and training delivered to medical students in order to become a practitioner. In recent decades, medicine has been radically transformed by scientific and computational/digital advances—including the introduction of new information and communication technologies, the discovery of DNA, and the birth of genomics and post-genomics super-specialties (transcriptomics, proteomics, interactomics, and metabolomics/metabonomics, among others)—which contribute to the generation of an unprecedented amount of data, so-called ‘big data’. While these are well-studied in fields such as medical research and methodology, translational medicine, and clinical practice, they remain overlooked and understudied in the field of medical education. For this purpose, we carried out an integrative review of the literature. Twenty-nine studies were retrieved and synthesized in the present review. Included studies were published between 2012 and 2021. Eleven studies were performed in North America: specifically, nine were conducted in the USA and two studies in Canada. Six studies were carried out in Europe: two in France, two in Germany, one in Italy, and one in several European countries. One additional study was conducted in China. Eight papers were commentaries/theoretical or perspective articles, while five were designed as a case study. Five investigations exploited large databases and datasets, while five additional studies were surveys. Two papers employed visual data analytical/data mining tech-niques. Finally, other two papers were technical papers, describing the development of software, computational tools and/or learning environments/platforms, while two additional studies were literature reviews (one of which being systematic and bibliometric).The following nine sub-topics could be identified: (I) knowledge and awareness of big data among medical students; (II) difficul-ties and challenges in integrating and implementing big data teaching into the medical syllabus; (III) exploiting big data to review, improve and enhance medical school curriculum; (IV) exploiting big data to monitor the effectiveness of web-based learning environments among medical students; (V) exploiting big data to capture the determinants and signatures of successful academic performance and counteract/prevent drop-out; (VI) exploiting big data to promote equity, inclusion, and diversity; (VII) exploiting big data to enhance integrity and ethics, avoiding plagiarism and dupli-cation rate; (VIII) empowering medical students, improving and enhancing medical practice; and, (IX) exploiting big data in continuous medical education and learning. These sub-themes were sub-sequently grouped in the following four major themes/topics: namely, (I) big data and medical cur-ricula; (II) big data and medical academic performance; (III) big data and societal/bioethical issues in biomedical education; and (IV) big data and medical career. Despite the increasing importance of big data in biomedicine, current medical curricula and syllabuses appear inadequate to prepare future medical professionals and practitioners that can leverage on big data in their daily clinical prac-tice. Challenges in integrating, incorporating, and implementing big data teaching into medical school need to be overcome to facilitate the training of the next generation of medical professionals. Finally, in the present integrative review, state-of-art and future potential uses of big data in the field of biomedical discussion are envisaged, with a focus on the still ongoing “Coronavirus Disease 2019” (COVID-19) pandemic, which has been acting as a catalyst for innovation and digitalization. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Big data; COVID-19; Curriculum; Integrative review; Medical education},
	keywords = {Big Data; COVID-19; Curriculum; Humans; Learning; SARS-CoV-2; Canada; China; France; Germany; Italy; United States; Coronavirus; Varanidae; academic performance; COVID-19; curriculum; data set; health education; literature review; medicine; training; algorithm; Article; awareness; bioethics; bioinformatics; clinical practice; computer analysis; coronavirus disease 2019; data analysis; decision making; genomics; health disparity; human; image analysis; learning environment; machine learning; medical education; metabolomics; microarray analysis; outcome assessment; pandemic; personalized medicine; plagiarism; proteomics; questionnaire; Raynaud phenomenon; training; transcriptomics; curriculum; learning},
	correspondence_address = {N.L. Bragazzi; Laboratory for Industrial and Applied Mathematics (LIAM), Department of Mathematics and Statistics, York University, Toronto, M3J 1P3, Canada; email: robertobragazzi@gmail.com},
	publisher = {MDPI},
	issn = {16617827},
	pmid = {34501581},
	language = {English},
	abbrev_source_title = {Int. J. Environ. Res. Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Cao20212681,
	author = {Cao, Bo and Zhang, Ke-Cheng and Wei, Bo and Chen, Lin},
	title = {Status quo and future prospects of artificial neural network from the perspective of gastroenterologists},
	year = {2021},
	journal = {World Journal of Gastroenterology},
	volume = {27},
	number = {21},
	pages = {2681 – 2709},
	doi = {10.3748/wjg.v27.i21.2681},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106735723&doi=10.3748%2fwjg.v27.i21.2681&partnerID=40&md5=21536e3418123584152fa98e2aeb1ac5},
	affiliations = {Department of General Surgery, Institute of General Surgery, Chinese People’s Liberation Army General Hospital, No. 28 Fuxing Road, Beijing, 100853, China},
	abstract = {Artificial neural networks (ANNs) are one of the primary types of artificial intelligence and have been rapidly developed and used in many fields. In recent years, there has been a sharp increase in research concerning ANNs in gastrointestinal (GI) diseases. This state-of-the-art technique exhibits excellent performance in diagnosis, prognostic prediction, and treatment. Competitions between ANNs and GI experts suggest that efficiency and accuracy might be compatible in virtue of technique advancements. However, the shortcomings of ANNs are not negligible and may induce alterations in many aspects of medical practice. In this review, we introduce basic knowledge about ANNs and summarize the current achievements of ANNs in GI diseases from the perspective of gastroenterologists. Existing limitations and future directions are also proposed to optimize ANN’s clinical potential. In consideration of barriers to interdisciplinary knowledge, sophisticated concepts are discussed using plain words and metaphors to make this review more easily understood by medical practitioners and the general public. © The Author(s) 2021. Published by Baishideng Publishing Group Inc. All rights reserved.},
	author_keywords = {Artificial neural network; Diagnosis; Endoscopy; Gastrointestinal disease; Prognosis; Treatment},
	keywords = {Artificial Intelligence; Gastroenterologists; Humans; Neural Networks, Computer; Prognosis; artificial neural network; back propagation neural network; Bayesian network; clinical decision making; clinical decision support system; convolutional neural network; digestive system cancer; feed forward neural network; feedback neural network; gastroenterologist; gastrointestinal disease; gastrointestinal endoscopy; health legislation; histopathology; human; immunohistochemistry; interdisciplinary education; machine learning; medical ethics; physician attitude; radiodiagnosis; recurrent neural network; Review; risk assessment; survival prediction; unsupervised machine learning; artificial intelligence; prognosis},
	correspondence_address = {L. Chen; Department of General Surgery, Institute of General Surgery, Chinese People’s Liberation Army General Hospital, Beijing, No. 28 Fuxing Road, 100853, China; email: chenlin@301hospital.com.cn},
	publisher = {Baishideng Publishing Group Co},
	issn = {10079327},
	coden = {WJGAF},
	pmid = {34135549},
	language = {English},
	abbrev_source_title = {World J. Gastroenterol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Abdullah2021289,
	author = {Abdullah, Yasser Ibraheem and Schuman, Joel S. and Shabsigh, Ridwan and Caplan, Arthur and Al-Aswad, Lama A.},
	title = {Ethics of Artificial Intelligence in Medicine and Ophthalmology},
	year = {2021},
	journal = {Asia-Pacific Journal of Ophthalmology},
	volume = {10},
	number = {3},
	pages = {289 – 298},
	doi = {10.1097/APO.0000000000000397},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114109272&doi=10.1097%2fAPO.0000000000000397&partnerID=40&md5=b2b776a89af1871da4bc963e1067c395},
	affiliations = {Department of Ophthalmology, NYU Langone Health, NYU Grossman School of Medicine, New York, NY, United States; Department of Biomedical Engineering, NYU Tandon School of Engineering, Brooklyn, NY, United States; Department of Electrical and Computer Engineering, NYU Tandon School of Engineering, Brooklyn, NY, United States; Department of Physiology and Neuroscience, NYU Langone Health, NYU Grossman School of Medicine, New York, NY, United States; Center for Neural Science, NYU College of Arts and Science, New York, NY, United States; SBH Health System and Weill Cornell Medical College, New York, NY, United States; Department of Population Health, NYU Langone Health, NYU Grossman School of Medicine, New York, NY, United States},
	abstract = {Background:This review explores the bioethical implementation of artificial intelligence (AI) in medicine and in ophthalmology. AI, which was first introduced in the 1950s, is defined as "the machine simulation of human mental reasoning, decision making, and behavior". The increased power of computing, expansion of storage capacity, and compilation of medical big data helped the AI implementation surge in medical practice and research. Ophthalmology is a leading medical specialty in applying AI in screening, diagnosis, and treatment. The first Food and Drug Administration approved autonomous diagnostic system served to diagnose and classify diabetic retinopathy. Other ophthalmic conditions such as age-related macular degeneration, glaucoma, retinopathy of prematurity, and congenital cataract, among others, implemented AI too.Purpose:To review the contemporary literature of the bioethical issues of AI in medicine and ophthalmology, classify ethical issues in medical AI, and suggest possible standardizations of ethical frameworks for AI implementation.Methods:Keywords were searched on Google Scholar and PubMed between October 2019 and April 2020. The results were reviewed, cross-referenced, and summarized. A total of 284 references including articles, books, book chapters, and regulatory reports and statements were reviewed, and those that were relevant were cited in the paper.Results:Most sources that studied the use of AI in medicine explored the ethical aspects. Bioethical challenges of AI implementation in medicine were categorized into 6 main categories. These include machine training ethics, machine accuracy ethics, patient-related ethics, physician-related ethics, shared ethics, and roles of regulators.Conclusions:There are multiple stakeholders in the ethical issues surrounding AI in medicine and ophthalmology. Attention to the various aspects of ethics related to AI is important especially with the expanding use of AI. Solutions of ethical problems are envisioned to be multifactorial. © 2021 Asia-Pacific Academy of Ophthalmology. All rights reserved.},
	author_keywords = {algorithms; artificial intelligence; bioethics; deep learning; machine learning},
	keywords = {Artificial Intelligence; Diabetic Retinopathy; Glaucoma; Humans; Ophthalmology; artificial intelligence; diabetic retinopathy; glaucoma; human; ophthalmology},
	correspondence_address = {L.A. Al-Aswad; NYU Langone Eye Center, New York, 222 E 41ST, Suite 4-092, 10017, United States; email: Lama.al-aswad@nyulangone.org},
	publisher = {Lippincott Williams and Wilkins},
	issn = {21620989},
	pmid = {34383720},
	language = {English},
	abbrev_source_title = {Asia-Pacific J. Ophthalmol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Fletcher2021,
	author = {Fletcher, Richard Ribón and Nakeshimana, Audace and Olubeko, Olusubomi},
	title = {Addressing Fairness, Bias, and Appropriate Use of Artificial Intelligence and Machine Learning in Global Health},
	year = {2021},
	journal = {Frontiers in Artificial Intelligence},
	volume = {3},
	doi = {10.3389/frai.2020.561802},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117669635&doi=10.3389%2ffrai.2020.561802&partnerID=40&md5=d0cd81336ae8d56c1dc826c111687cab},
	affiliations = {Massachusetts Institute of Technology, Cambridge, MA, United States; University of Massachusetts Medical School, Worcester, MA, United States},
	abstract = {In Low- and Middle- Income Countries (LMICs), machine learning (ML) and artificial intelligence (AI) offer attractive solutions to address the shortage of health care resources and improve the capacity of the local health care infrastructure. However, AI and ML should also be used cautiously, due to potential issues of fairness and algorithmic bias that may arise if not applied properly. Furthermore, populations in LMICs can be particularly vulnerable to bias and fairness in AI algorithms, due to a lack of technical capacity, existing social bias against minority groups, and a lack of legal protections. In order to address the need for better guidance within the context of global health, we describe three basic criteria (Appropriateness, Fairness, and Bias) that can be used to help evaluate the use of machine learning and AI systems: 1) APPROPRIATENESS is the process of deciding how the algorithm should be used in the local context, and properly matching the machine learning model to the target population; 2) BIAS is a systematic tendency in a model to favor one demographic group vs another, which can be mitigated but can lead to unfairness; and 3) FAIRNESS involves examining the impact on various demographic groups and choosing one of several mathematical definitions of group fairness that will adequately satisfy the desired set of legal, cultural, and ethical requirements. Finally, we illustrate how these principles can be applied using a case study of machine learning applied to the diagnosis and screening of pulmonary disease in Pune, India. We hope that these methods and principles can help guide researchers and organizations working in global health who are considering the use of machine learning and artificial intelligence. © Copyright © 2021 Fletcher, Nakeshimana and Olubeko.},
	author_keywords = {appropriate use; artificial intelligence; bias; ethics; fairness; global health; machine learning; medicine},
	correspondence_address = {R.R. Fletcher; Massachusetts Institute of Technology, Cambridge, United States; email: fletcher@media.mit.edu},
	publisher = {Frontiers Media S.A.},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Neves2021,
	author = {Neves, Ana Luisa and Pereira Rodrigues, Pedro and Mulla, Abdulrahim and Glampson, Ben and Willis, Tony and Darzi, Ara and Mayer, Erik},
	title = {Using electronic health records to develop and validate a machine-learning tool to predict type 2 diabetes outcomes: A study protocol},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {7},
	doi = {10.1136/bmjopen-2020-046716},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111717369&doi=10.1136%2fbmjopen-2020-046716&partnerID=40&md5=2cc8585182bf85ac3b6b27313b5f07b7},
	affiliations = {Nihr Imperial Patient Safety Translational Research Centre, Imperial College London, London, United Kingdom; Center for Health Technology and Services Research, Faculty of Medicine, University of Porto, Porto, Portugal; Imperial College Healthcare Nhs Trust, London, United Kingdom; North West London Diabetes Transformation Programme, North West London Health and Care Partnership, London, United Kingdom},
	abstract = {Introduction Type 2 diabetes mellitus (T2DM) is a major cause of blindness, kidney failure, myocardial infarction, stroke and lower limb amputation. We are still unable, however, to accurately predict or identify which patients are at a higher risk of deterioration. Most risk stratification tools do not account for novel factors such as sociodemographic determinants, self-management ability or access to healthcare. Additionally, most tools are based in clinical trials, with limited external generalisability. Objective The aim of this work is to design and validate a machine learning-based tool to identify patients with T2DM at high risk of clinical deterioration, based on a comprehensive set of patient-level characteristics retrieved from a population health linked dataset. Sample and design Retrospective cohort study of patients with diagnosis of T2DM on 1 January 2015, with a 5-year follow-up. Anonymised electronic healthcare records from the Whole System Integrated Care (WSIC) database will be used. Preliminary outcomes Outcome variables of clinical deterioration will include retinopathy, chronic renal disease, myocardial infarction, stroke, peripheral arterial disease or death. Predictor variables will include sociodemographic and geographic data, patients' ability to self-manage disease, clinical and metabolic parameters and healthcare service usage. Prognostic models will be defined using multidependence Bayesian networks. The derivation cohort, comprising 80% of the patients, will be used to define the prognostic models. Model parameters will be internally validated by comparing the area under the receiver operating characteristic curve in the derivation cohort with those calculated from a leave-one-out and a 10 times twofold cross-validation. Ethics and dissemination The study has received approvals from the Information Governance Committee at the WSIC. Results will be made available to people with T2DM, their caregivers, the funders, diabetes care societies and other researchers.  © Authors 2021},
	author_keywords = {diabetes & endocrinology; health & safety; health informatics},
	keywords = {Bayes Theorem; Diabetes Mellitus, Type 2; Electronic Health Records; Humans; Machine Learning; Retrospective Studies; hemoglobin A1c; adult; Article; Bayesian network; cerebrovascular accident; chronic kidney failure; clinical feature; clinical outcome; cohort analysis; controlled study; cross validation; demography; deterioration; early intervention; electronic health record; female; geography; health service; heart infarction; hemoglobin blood level; high risk patient; human; major clinical study; male; metabolic parameters; non insulin dependent diabetes mellitus; peripheral occlusive artery disease; population health; prediction; predictor variable; prognosis; receiver operating characteristic; retinopathy; retrospective study; self care; Bayes theorem; electronic health record; machine learning},
	correspondence_address = {A.L. Neves; Nihr Imperial Patient Safety Translational Research Centre, Imperial College London, London, United Kingdom; email: ana.luisa.neves14@imperial.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34330856},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Hannan2021555,
	author = {Hannan, Jacqueline and Chen, Huei-Yen Winnie and Joseph, Kenneth},
	title = {Who Gets What, According to Whom? An Analysis of Fairness Perceptions in Service Allocation},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {555 – 565},
	doi = {10.1145/3461702.3462568},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112400761&doi=10.1145%2f3461702.3462568&partnerID=40&md5=11e0c072a38891c112e0ee2c6e782211},
	affiliations = {University at Buffalo, Buffalo, NY, United States},
	abstract = {Algorithmic fairness research has traditionally been linked to the disciplines of philosophy, ethics, and economics, where notions of fairness are prescriptive and seek objectivity. Increasingly, however, scholars are turning to the study of what different people perceive to be fair, and how these perceptions can or should help to shape the design of machine learning, particularly in the policy realm. The present work experimentally explores five novel research questions at the intersection of the "Who,""What,"and "How"of fairness perceptions. Specifically, we present the results of a multi-factor conjoint analysis study that quantifies the effects of the specific context in which a question is asked, the framing of the given question, and who is answering it. Our results broadly suggest that the "Who"and "What,"at least, matter in ways that are 1) not easily explained by any one theoretical perspective, 2) have critical implications for how perceptions of fairness should be measured and/or integrated into algorithmic decision-making systems. © 2021 ACM.},
	author_keywords = {conjoint analysis; fairness; fairness perceptions; service allocation; survey experiment},
	keywords = {Behavioral research; Decision making; Philosophical aspects; Conjoint analysis; Decision-making systems; Multi factors; Research questions; Service allocations; Artificial intelligence},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Gaikwad20214125,
	author = {Gaikwad, Snehalkumar 'Neil'S. and Iyer, Shankar and Lunga, Dalton and Bondi, Elizabeth},
	title = {Data-driven Humanitarian Mapping: Harnessing Human-Machine Intelligence for High-Stake Public Policy and Resilience Planning},
	year = {2021},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {4125 – 4126},
	doi = {10.1145/3447548.3469461},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114911376&doi=10.1145%2f3447548.3469461&partnerID=40&md5=5d9cb026e112d38d70dac2df155ca8af},
	affiliations = {Massachusetts Institute of Technology, Cambridge, MA, United States},
	author_keywords = {algorithmic decision making and ethics; computational social science; data-driven humanitarian actions; fair and interpretable machine learning; human-centered data science; public policy; remote sensing; social computing; sustainable development},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038332-5},
	language = {English},
	abbrev_source_title = {Proc. ACM SIGKDD Int. Conf. Knowl. Discov. Data Min.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 27th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2021; Conference date: 14 August 2021 through 18 August 2021; Conference code: 171623; All Open Access, Green Open Access}
}

@CONFERENCE{Li20212654,
	author = {Li, Yunqi and Ge, Yingqiang and Zhang, Yongfeng},
	title = {Tutorial on Fairness of Machine Learning in Recommender Systems},
	year = {2021},
	journal = {SIGIR 2021 - Proceedings of the 44th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {2654 – 2657},
	doi = {10.1145/3404835.3462814},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111628712&doi=10.1145%2f3404835.3462814&partnerID=40&md5=a70d4e41e7096f14476c13fa3b921d6e},
	affiliations = {Department of Computer Science, Rutgers University, NJ, United States},
	abstract = {Recently, there has been growing attention on fairness considerations in machine learning. As one of the most pervasive applications of machine learning, recommender systems are gaining increasing and critical impacts on human and society since a growing number of users use them for information seeking and decision making. Therefore, it is crucial to address the potential unfairness problems in recommendation, which may hurt users' or providers' satisfaction in recommender systems as well as the interests of the platforms. The tutorial focuses on the foundations and algorithms for fairness in recommendation. It also presents a brief introduction about fairness in basic machine learning tasks such as classification and ranking. The tutorial will introduce the taxonomies of current fairness definitions and evaluation metrics for fairness concerns. We will introduce previous works about fairness in recommendation and also put forward future fairness research directions. The tutorial aims at introducing and communicating fairness in recommendation methods to the community, as well as gathering researchers and practitioners interested in this research direction for discussions, idea communications, and research promotions. © 2021 ACM.},
	author_keywords = {AI ethics; fairness; machine learning; recommender systems},
	keywords = {Decision making; Machine learning; Evaluation metrics; Fairness concerns; Information seeking; Pervasive applications; Recommendation methods; Unfairness problem; Recommender systems},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038037-9},
	language = {English},
	abbrev_source_title = {SIGIR - Proc. Int. ACM SIGIR Conf. Res. Dev. Inf. Retr.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: 44th International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR 2021; Conference date: 11 July 2021 through 15 July 2021; Conference code: 170067}
}

@ARTICLE{Dan2021,
	author = {Dan, Bernard},
	title = {New Ethical Issues in Cerebral Palsy},
	year = {2021},
	journal = {Frontiers in Neurology},
	volume = {12},
	doi = {10.3389/fneur.2021.650653},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103787968&doi=10.3389%2ffneur.2021.650653&partnerID=40&md5=89a38aab28fdd507a2126b721e5da505},
	affiliations = {Université libre de Bruxelles, Brussels, Belgium; Inkendaal Rehabilitation Hospital, Vlezenbeek, Belgium},
	abstract = {Current societal and technological changes have added to the ethical issues faced by people with cerebral palsy. These include new representations of disability, and the current International Classification of Functioning, Disability, and Health, changes in legislation and international conventions, as well as applications of possibilities offered by robotics, brain–computer interface devices, muscles and brain stimulation techniques, wearable sensors, artificial intelligence, genetics, and more for diagnostic, therapeutic, or other purposes. These developments have changed the way we approach diagnosis, set goals for intervention, and create new opportunities. This review examines those influences on clinical practice from an ethical perspective and highlights how a principled approach to clinical bioethics can help the clinician to address ethical dilemmas that occur in practice. It also points to implications of those changes on research priorities. © Copyright © 2021 Dan.},
	author_keywords = {bioethics; cerebral palsy; disability; human enhancement; ICF; machine learning},
	keywords = {attitude to health; bioethics; cerebral palsy; clinical evaluation; clinical practice; clinician; counseling; disease association; ethics; human; medical research; medical society; perception; practice guideline; Review; risk factor; shared decision making; social determinants of health; technology; wellbeing},
	correspondence_address = {B. Dan; Université libre de Bruxelles, Brussels, Belgium; email: bernard.dan@ulb.be; B. Dan; Inkendaal Rehabilitation Hospital, Vlezenbeek, Belgium; email: bernard.dan@ulb.be},
	publisher = {Frontiers Media S.A.},
	issn = {16642295},
	language = {English},
	abbrev_source_title = {Front. Neurol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kundu20211328,
	author = {Kundu, Shinjini},
	title = {AI in medicine must be explainable},
	year = {2021},
	journal = {Nature Medicine},
	volume = {27},
	number = {8},
	pages = {1328},
	doi = {10.1038/s41591-021-01461-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111623365&doi=10.1038%2fs41591-021-01461-z&partnerID=40&md5=d9d440552da8f20cc0259bd2d78a7e64},
	affiliations = {The Johns Hopkins Hospital, Baltimore, MD, United States},
	keywords = {Artificial Intelligence; Humans; Medicine; Prognosis; algorithm; algorithm bias; Article; artificial intelligence; diagnosis; doctor patient relationship; European Union; evidence based medicine; health care; health care cost; human; informed consent; machine learning; medical ethics; osteoarthritis; patient satisfaction; prognosis; reaction time; surgeon; devices; medicine; prognosis},
	correspondence_address = {S. Kundu; The Johns Hopkins Hospital, Baltimore, United States; email: skundu2@jhmi.edu},
	publisher = {Nature Research},
	issn = {10788956},
	coden = {NAMEF},
	pmid = {34326551},
	language = {English},
	abbrev_source_title = {Nat. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 69}
}

@ARTICLE{Elliott2021179,
	author = {Elliott, Karen and Price, Rob and Shaw, Patricia and Spiliotopoulos, Tasos and Ng, Magdalene and Coopamootoo, Kovila and van Moorsel, Aad},
	title = {Towards an Equitable Digital Society: Artificial Intelligence (AI) and Corporate Digital Responsibility (CDR)},
	year = {2021},
	journal = {Society},
	volume = {58},
	number = {3},
	pages = {179 – 188},
	doi = {10.1007/s12115-021-00594-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107844506&doi=10.1007%2fs12115-021-00594-8&partnerID=40&md5=6b2d166bf2ae59db4f8f93b436b566e1},
	affiliations = {School of Computing & Business School, Newcastle University, 1 Science Square, The Helix, Newcastle upon Tyne, NE4 5TG, United Kingdom; http://CorporateDigitalResponsibility.net (CDR), Alchemmy, 52-54 High Holborn, London, WC1V 6RL, United Kingdom; Beyond Reach Consulting Ltd, 139 Furlong Road, Bolton-Upon-Dearne, Rotherham, S63 8HD, United Kingdom},
	abstract = {In the digital era, we witness the increasing use of artificial intelligence (AI) to solve problems, while improving productivity and efficiency. Yet, inevitably costs are involved with delegating power to algorithmically based systems, some of whose workings are opaque and unobservable and thus termed the “black box”. Central to understanding the “black box” is to acknowledge that the algorithm is not mendaciously undertaking this action; it is simply using the recombination afforded to scaled computable machine learning algorithms. But an algorithm with arbitrary precision can easily reconstruct those characteristics and make life-changing decisions, particularly in financial services (credit scoring, risk assessment, etc.), and it could be difficult to reconstruct, if this was done in a fair manner reflecting the values of society. If we permit AI to make life-changing decisions, what are the opportunity costs, data trade-offs, and implications for social, economic, technical, legal, and environmental systems? We find that over 160 ethical AI principles exist, advocating organisations to act responsibly to avoid causing digital societal harms. This maelstrom of guidance, none of which is compulsory, serves to confuse, as opposed to guide. We need to think carefully about how we implement these algorithms, the delegation of decisions and data usage, in the absence of human oversight and AI governance. The paper seeks to harmonise and align approaches, illustrating the opportunities and threats of AI, while raising awareness of Corporate Digital Responsibility (CDR) as a potential collaborative mechanism to demystify governance complexity and to establish an equitable digital society. © 2021, The Author(s).},
	author_keywords = {Artificial intelligence (AI) governance; Complexity; Corporate Digital Responsibility; Digital ethics and trust; Equitable digital society; Financial technology (FinTech)},
	correspondence_address = {K. Elliott; School of Computing & Business School, Newcastle University, Newcastle upon Tyne, 1 Science Square, The Helix, NE4 5TG, United Kingdom; email: karen.elliott@newcastle.ac.uk},
	publisher = {Springer},
	issn = {01472011},
	language = {English},
	abbrev_source_title = {Society},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ho2021282,
	author = {Ho, Calvin Wai-Loon and Caals, Karel},
	title = {A Call for an Ethics and Governance Action Plan to Harness the Power of Artificial Intelligence and Digitalization in Nephrology},
	year = {2021},
	journal = {Seminars in Nephrology},
	volume = {41},
	number = {3},
	pages = {282 – 293},
	doi = {10.1016/j.semnephrol.2021.05.009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107851318&doi=10.1016%2fj.semnephrol.2021.05.009&partnerID=40&md5=f99dd23b49bdc9d2fe9fdf54edecd241},
	affiliations = {Centre for Medical Ethics and Law, Department of Law, The University of Hong Kong, Hong Kong; Centre for Biomedical Ethics, Yong Loo Lin School of Medicine, National University of Singapore, Singapore},
	abstract = {Summary: Digitalization in nephrology has progressed in a manner that is disparate and siloed, even though learning (under a broader Learning Health System initiative) has been manifested in all the main areas of clinical application. Most applications based on artificial intelligence/machine learning (AI/ML) are still in the initial developmental stages and are yet to be adequately validated and shown to contribute to positive patient outcomes. There is also no consistent or comprehensive digitalization plan, and insufficient data are a limiting factor across all of these areas. In this article, we first consider how digitalization along nephrology care pathways relates to the Learning Health System initiative. We then consider the current state of AI/ML-based software and devices in nephrology and the ethical and regulatory challenges in scaling them up toward broader clinical application. We conclude with our proposal to establish a dedicated ethics and governance framework that is centered around health care providers in nephrology and the AI/ML-based software to which their work relates. This framework should help to integrate ethical and regulatory values and considerations, involve a wide range of stakeholders, and apply across normative domains that are conventionally demarcated as clinical, research, and public health. © 2021 The Author(s)},
	author_keywords = {Artificial intelligence; big data; digitalization; ethics; governance; learning health system; regulation},
	keywords = {Artificial Intelligence; Humans; Nephrology; Public Health; artificial intelligence; big data; clinical research; developmental stage; ethics; health care personnel; human; learning health system; machine learning; nephrology; review; software; public health},
	correspondence_address = {C.W.-L. Ho; Centre for Medical Ethics and Law, Department of Law, Cheng Yu Tung Tower, Centennial Campus, The University of Hong Kong, Pokfulam, Hong Kong; email: cwlho@hku.hk},
	publisher = {W.B. Saunders},
	issn = {02709295},
	coden = {SNEPD},
	pmid = {34330368},
	language = {English},
	abbrev_source_title = {Semin. Nephrol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Hybrid Gold Open Access}
}

@BOOK{Saxena2021639,
	author = {Saxena, Deepak and Lamest, Markus and Bansal, Veena},
	title = {Responsible machine learning for ethical artificial intelligence in business and industry},
	year = {2021},
	journal = {Handbook of Research on Applied Data Science and Artificial Intelligence in Business and Industry},
	pages = {639 – 653},
	doi = {10.4018/978-1-7998-6985-6.ch030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128126888&doi=10.4018%2f978-1-7998-6985-6.ch030&partnerID=40&md5=c4c3b757c215e359d02e68a26271fba5},
	affiliations = {Birla Institute of Technology and Science, Pilani, India; Trinity College Dublin, Ireland; Indian Institute of Technology, Kanpur, India},
	abstract = {Artificial intelligence (AI) systems have become a new reality of modern life. They have become ubiquitous to virtually all socio-economic activities in business and industry. With the extent of AI's influence on our lives, it is an imperative to focus our attention on the ethics of AI. While humans develop their moral and ethical framework via self-awareness and reflection, the current generation of AI lacks these abilities. Drawing from the concept of human-AI hybrid, this chapter offers managerial and developers' action towards responsible machine learning for ethical artificial intelligence. The actions consist of privacy by design, development of explainable AI, identification and removal of inherent biases, and most importantly, using AI as a moral enabler. Application of these action would not only help towards ethical AI; it would also help in supporting moral development of human-AI hybrid. © 2021, IGI Global.},
	publisher = {IGI Global},
	isbn = {978-179986986-3; 978-179986985-6},
	language = {English},
	abbrev_source_title = {Handb. of Res. on Appl. Data Sci. and Artif. Intell. in Bus. and Ind.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Gooding2021,
	author = {Gooding, Piers and Kariotis, Timothy},
	title = {Ethics and law in research on algorithmic and data-driven technology in mental health care: Scoping review},
	year = {2021},
	journal = {JMIR Mental Health},
	volume = {8},
	number = {6},
	doi = {10.2196/24668},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107865843&doi=10.2196%2f24668&partnerID=40&md5=05812f677cc6890cdfcdce4ebb2760ec},
	affiliations = {Melbourne Law School, University of Melbourne, Melbourne, VIC, Australia; Mozilla Foundation, Mountain View, CA, United States; Melbourne School of Government, University of Melbourne, Melbourne, VIC, Australia},
	abstract = {Background: Uncertainty surrounds the ethical and legal implications of algorithmic and data-driven technologies in the mental health context, including technologies characterized as artificial intelligence, machine learning, deep learning, and other forms of automation. Objective: This study aims to survey empirical scholarly literature on the application of algorithmic and data-driven technologies in mental health initiatives to identify the legal and ethical issues that have been raised. Methods: We searched for peer-reviewed empirical studies on the application of algorithmic technologies in mental health care in the Scopus, Embase, and Association for Computing Machinery databases. A total of 1078 relevant peer-reviewed applied studies were identified, which were narrowed to 132 empirical research papers for review based on selection criteria. Conventional content analysis was undertaken to address our aims, and this was supplemented by a keyword-in-context analysis. Results: We grouped the findings into the following five categories of technology: social media (53/132, 40.1%), smartphones (37/132, 28%), sensing technology (20/132, 15.1%), chatbots (5/132, 3.8%), and miscellaneous (17/132, 12.9%). Most initiatives were directed toward detection and diagnosis. Most papers discussed privacy, mainly in terms of respecting the privacy of research participants. There was relatively little discussion of privacy in this context. A small number of studies discussed ethics directly (10/132, 7.6%) and indirectly (10/132, 7.6%). Legal issues were not substantively discussed in any studies, although some legal issues were discussed in passing (7/132, 5.3%), such as the rights of user subjects and privacy law compliance. Conclusions: Ethical and legal issues tend to not be explicitly addressed in empirical studies on algorithmic and data-driven technologies in mental health initiatives. Scholars may have considered ethical or legal matters at the ethics committee or institutional review board stage. If so, this consideration seldom appears in published materials in applied research in any detail. The form itself of peer-reviewed papers that detail applied research in this field may well preclude a substantial focus on ethics and law. Regardless, we identified several concerns, including the near-complete lack of involvement of mental health service users, the scant consideration of algorithmic accountability, and the potential for overmedicalization and techno-solutionism. Most papers were published in the computer science field at the pilot or exploratory stages. Thus, these technologies could be appropriated into practice in rarely acknowledged ways, with serious legal and ethical implications. © 2021 JMIR Publications Inc. All rights reserved.},
	author_keywords = {Algorithmic technology; Artificial intelligence; Data-driven technology; Digital mental health; Digital psychiatry; Ethics; Law; Machine learning; Mobile phone; Regulation},
	keywords = {algorithm; artificial intelligence; content analysis; data privacy; data science; deep learning; ethics; human; law; legal aspect; machine learning; medical research; mental health care; mental health service; remote sensing; Review; social media},
	publisher = {JMIR Publications Inc.},
	issn = {23687959},
	language = {English},
	abbrev_source_title = {JMIR Ment. Heal.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Bellini20211052,
	author = {Bellini, Valentina and Montomoli, Jonathan and Bignami, Elena},
	title = {Poor quality data, privacy, lack of certifications: the lethal triad of new technologies in intensive care},
	year = {2021},
	journal = {Intensive Care Medicine},
	volume = {47},
	number = {9},
	pages = {1052 – 1053},
	doi = {10.1007/s00134-021-06473-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110155901&doi=10.1007%2fs00134-021-06473-4&partnerID=40&md5=baf0c85617275f9ce34e48d03fceda3e},
	affiliations = {Anesthesiology, Critical Care and Pain Medicine Division, Department of Medicine and Surgery, University of Parma, Viale Gramsci 14, Parma, 43126, Italy; Department of Anaesthesia and Intensive Care, Infermi Hospital, AUSL Della Romagna, Rimini, Italy},
	keywords = {Certification; Critical Care; Data Accuracy; Humans; Privacy; anesthesist; artificial intelligence; automation; certification; clinical decision support system; clinical practice; computer model; computer scientist; data privacy; data processing; data quality; human; information storage; intensive care unit; intensivist; legal aspect; Letter; machine learning; medical education; research ethics; intensive care; measurement accuracy; privacy},
	correspondence_address = {E. Bignami; Anesthesiology, Critical Care and Pain Medicine Division, Department of Medicine and Surgery, University of Parma, Parma, Viale Gramsci 14, 43126, Italy; email: elenagiovanna.bignami@unipr.it},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03424642},
	coden = {ICMED},
	pmid = {34264366},
	language = {English},
	abbrev_source_title = {Intensive Care Med.},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Cao202181,
	author = {Cao, Longbing and Yang, Qiang and Yu, Philip S.},
	title = {Data science and AI in FinTech: an overview},
	year = {2021},
	journal = {International Journal of Data Science and Analytics},
	volume = {12},
	number = {2},
	pages = {81 – 99},
	doi = {10.1007/s41060-021-00278-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111933595&doi=10.1007%2fs41060-021-00278-w&partnerID=40&md5=603bb6d45c20e457a9c1de4fe4525d5d},
	affiliations = {University of Technology Sydney, Sydney, Australia; Hongkong University of Science and Technology, Hong Kong; University of Illinois at Chicago, Chicago, United States},
	abstract = {Financial technology (FinTech) has been playing an increasingly critical role in driving modern economies, society, technology, and many other areas. Smart FinTech is the new-generation FinTech, largely inspired and empowered by data science and artificial intelligence (DSAI) techniques. Smart FinTech synthesizes broad DSAI and transforms finance and economies to drive intelligent, automated, whole-of-business and personalized economic and financial businesses, services and systems. The research on data science and AI in FinTech involves many latest progress made in smart FinTech for BankingTech, TradeTech, LendTech, InsurTech, WealthTech, PayTech, RiskTech, cryptocurrencies, and blockchain, and the DSAI techniques including complex system methods, quantitative methods, intelligent interactions, recognition and responses, data analytics, deep learning, federated learning, privacy-preserving processing, augmentation, optimization, and system intelligence enhancement. Here, we present a highly dense research overview of smart financial businesses and their challenges, the smart FinTech ecosystem, the DSAI techniques to enable smart FinTech, and some research directions of smart FinTech futures to the DSAI communities. © 2021, The Author(s), under exclusive licence to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence (AI); Blockchain; Data science; Deep learning; Economics; Ethics; Federated learning; Finance; Financial service; Financial technology; FinTech; Intelligent systems; Machine learning; Mathematics; Modeling; Privacy-preserving; Smart FinTech; Statistics},
	correspondence_address = {L. Cao; University of Technology Sydney, Sydney, Australia; email: longbing.cao@uts.edu.au},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {2364415X},
	language = {English},
	abbrev_source_title = {Int. J. Data Sci. Anal.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Ball2021271,
	author = {Ball, Helen Callie},
	title = {Improving Healthcare Cost, Quality, and Access Through Artificial Intelligence and Machine Learning Applications},
	year = {2021},
	journal = {Journal of Healthcare Management},
	volume = {66},
	number = {4},
	pages = {271 – 279},
	doi = {10.1097/JHM-D-21-00149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85110979381&doi=10.1097%2fJHM-D-21-00149&partnerID=40&md5=c820f00c89e09dbf154eabaa2d9418a4},
	affiliations = {Health Administration, College of Health Professions, Texas State University, San Marcos, TX, United States},
	abstract = {Since the early 1970s, technology has increasingly become integrated into the healthcare field. Today, artificial intelligence (AI) and machine learning (ML, a set of learning techniques used by AI) have the capacity to revolutionize the delivery of patient care. This essay examines the mechanics and processes of machine learning through discussion of deep learning and natural language processing and then discusses the application of these learning techniques in pattern recognition of malignant tumors in comparison to present methods of diagnostic imaging assessment. The discussion also covers the implications of AI assistive technology more broadly regarding ethical policy making, patient autonomy, and the healthcare Iron Triangle of cost, quality, and access. It concludes with the idea that failure to incorporate AI and ML techniques in healthcare may be malpractice. © 2021 Lippincott Williams and Wilkins. All rights reserved.},
	keywords = {Artificial Intelligence; Delivery of Health Care; Health Care Costs; Humans; Machine Learning; Technology; Article; artificial intelligence; artificial neural network; comparative study; deep learning; diagnostic imaging; diagnostic value; doctor patient relationship; health care access; health care cost; health care delivery; health care policy; health care quality; health care system; human; machine learning; malignant neoplasm; malpractice; medical ethics; medical liability; natural language processing; patient autonomy; health care cost; technology},
	correspondence_address = {H.C. Ball; Health Administration, College of Health Professions, Texas State University, San Marcos, United States; email: hcball203@gmail.com},
	publisher = {Lippincott Williams and Wilkins},
	issn = {10969012},
	coden = {JHMAF},
	pmid = {34228686},
	language = {English},
	abbrev_source_title = {J. Healthc. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Sun20211254,
	author = {Sun, Zhenan and He, Ran and Wang, Liang and Kan, Meina and Feng, Jianjiang and Zheng, Fang and Zheng, Weishi and Zuo, Wangmeng and Kang, Wenxiong and Deng, Weihong and Zhang, Jie and Han, Hu and Shan, Shiguang and Wang, Yunlong and Ru, Yiwei and Zhu, Yuhao and Liu, Yunfan and He, Yong},
	title = {Overview of biometrics research; [生物特征识别学科发展报告]},
	year = {2021},
	journal = {Journal of Image and Graphics},
	volume = {26},
	number = {6},
	pages = {1254 – 1329},
	doi = {10.11834/jig.210078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109048071&doi=10.11834%2fjig.210078&partnerID=40&md5=eb0dbc689b6bba7959f5830c70f1ebd3},
	affiliations = {Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; Institute of Computing Technology, Chinese Academy of Sciences, Beijing, 100190, China; Tsinghua University, Beijing, 100084, China; School of Computer Science and Engineering, Sun Yat-sen University, Guangzhou, 510275, China; School of Computer Science and Technology, Harbin Institute of Technology, Harbin, 150006, China; School of Automation Science and Engineering, South China University of Technology, Guangzhou, 510006, China; School of Information and Communication Engineering, Beijing University of Posts and Telecommunications, Beijing, 100876, China},
	abstract = {Biometrics, such as face, iris, and fingerprint recognition, have become digital identity proof for people to enter the "Internet of Everything". For example, one may be asked to present the biometric identifier for unlocking mobile phones, passing access control at airports, rail stations, and paying at supermarkets or restaurants. Biometric recognition empowers a machine to automatically detect, capture, process, analyze, and recognize digital physiological or behavioral signals with advanced intelligence. Thus, biometrics requires interdisciplinary research of science and technology involving optical engineering, mechanical engineering, electronic engineering, machine learning, pattern recognition, computer vision, digital image processing, signal analysis, cognitive science, neuroscience, human-computer interaction, and information security. Biometrics is a typical and complex pattern recognition problem, which is a frontier research direction of artificial intelligence. In addition, biometric identification is a key development area of Chinese strategies, such as the Development Plan on the New Generation of Artificial Intelligence and the "Internet Plus" Action Plan. The development of biometric identification involves public interest, privacy, ethics, and law issues; thus, it has also attracted widespread attention from the society. This article systematically reviews the development status, emerging directions, existing problems, and feasible ideas of biometrics and comprehensively summarizes the research progress of face, iris, fingerprint, palm print, finger/palm vein, voiceprint, gait recognition, person reidentification, and multimodal biometric fusion. The overview of face recognition includes face detection, facial landmark localization, 2D face feature extraction and recognition, 3D face feature extraction and recognition, facial liveness detection, and face video based biological signal measurement. The overview of iris recognition includes iris image acquisition, iris segmentation and localization, iris liveness detection, iris image quality assessment, iris feature extraction, heterogeneous iris recognition, fusion of iris and other modalities, security problems of iris biometrics, and future trends of iris recognition. The overview of fingerprint recognition includes latent fingerprint recognition, fingerprint liveness detection, distorted fingerprint recognition, 3D fingerprint capturing, and challenges and trends of fingerprint biometrics. The overview of palm print recognition mainly introduces databases, feature models, matching strategies, and open problems of palm print biometrics. The overview of vein biometrics introduces main datasets and algorithms for finger vein, dorsal hand vein, and palm vein, and then points out the remaining unsolved problems and development trend of vein recognition. The overview of gait recognition introduces model-based and model-free methods for gait feature extraction and matching. The overview of person reidentification introduces research progress of new methods under supervised, unsupervised and weakly supervised conditions, gait database virtualization, generative gait models, and new problems, such as clothes changing, black clothes, and partial occlusions. The overview of voiceprint recognition introduces the history of speaker recognition, robustness of voiceprint, spoofing attacks, and antispoofing methods. The overview of multibiometrics introduces image-level, feature-level, score-level, and decision-level information fusion methods and deep learning based fusion approaches. Taking face as the exemplar biometric modality, new research directions that have received great attentions in the field of biometric recognition in recent years, i.e., adversarial attack and defense as well as Deepfake and anti-Deepfake, are also introduced. Finally, we analyze and summarize the three major challenges in the field of biometric recognition-"the blind spot of biometric sensors", "the decision errors of biometric algorithms" and "the red zone of biometric security". Therefore, the sensing, cognition, and security mechanisms of biometrics are necessary to achieve a fundamental breakthrough in the academic research and technologies applications of biometrics in complex scenarios to address the shortcomings of the existing biometric technologies and to move towards the overall goal of developing a new generation of "perceptible", "robust", and "trustworthy" biometric identification technology. © 2021, Editorial Office of Journal of Image and Graphics. All right reserved.},
	author_keywords = {Biometrics; Face; Fingerprint; Gait; Iris; Multi-modal; Palmprint; Person re-identification; Vein; Voiceprint},
	correspondence_address = {Z. Sun; Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China; email: znsun@nlpr.ia.ac.cn},
	publisher = {Editorial and Publishing Board of JIG},
	issn = {10068961},
	language = {Chinese},
	abbrev_source_title = {J. Image and Graphics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Clement2021,
	author = {Clement, Jeffrey and Maldonado, Angela Q.},
	title = {Augmenting the Transplant Team With Artificial Intelligence: Toward Meaningful AI Use in Solid Organ Transplant},
	year = {2021},
	journal = {Frontiers in Immunology},
	volume = {12},
	doi = {10.3389/fimmu.2021.694222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108940528&doi=10.3389%2ffimmu.2021.694222&partnerID=40&md5=57270608e62fdc19bff9cb4553a256ca},
	affiliations = {Information and Decision Sciences, Carlson School of Management, University of Minnesota, Minneapolis, MN, United States; Scientific Affairs, Hansa Biopharma AB, Lund, Sweden},
	abstract = {Advances in systems immunology, such as new biomarkers, offer the potential for highly personalized immunosuppression regimens that could improve patient outcomes. In the future, integrating all of this information with other patient history data will likely have to rely on artificial intelligence (AI). AI agents can help augment transplant decision making by discovering patterns and making predictions for specific patients that are not covered in the literature or in ways that are impossible for humans to anticipate by integrating vast amounts of data (e.g. trending across numerous biomarkers). Similar to other clinical decision support systems, AI may help overcome human biases or judgment errors. However, AI is not widely utilized in transplant to date. In this rapid review, we survey the methods employed in recent research in transplant-related AI applications and identify concerns related to implementing these tools. We identify three key challenges (bias/accuracy, clinical decision process/AI explainability, AI acceptability criteria) holding back AI in transplant. We also identify steps that can be taken in the near term to help advance meaningful use of AI in transplant (forming a Transplant AI Team at each center, establishing clinical and ethical acceptability criteria, and incorporating AI into the Shared Decision Making Model). © Copyright © 2021 Clement and Maldonado.},
	author_keywords = {artificial intelligence; decision making; ethics; immunosuppression; machine learning; natural language processing; shared decision model; transplant},
	keywords = {Artificial Intelligence; Clinical Decision-Making; Data Mining; Decision Support Techniques; Humans; Meaningful Use; Organ Transplantation; Patient Care Team; Pattern Recognition, Automated; Reproducibility of Results; Therapy, Computer-Assisted; artificial intelligence; clinical decision support system; ethics; human; immunosuppressive treatment; machine learning; meaningful use criteria; natural language processing; review; shared decision making; adverse event; automated pattern recognition; clinical decision making; computer assisted therapy; data mining; decision support system; organ transplantation; patient care; reproducibility},
	publisher = {Frontiers Media S.A.},
	issn = {16643224},
	pmid = {34177958},
	language = {English},
	abbrev_source_title = {Front. Immunol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Rodriguez-León2021,
	author = {Rodriguez-León, Ciro and Villalonga, Claudia and Munoz-Torres, Manuel and Ruiz, Jonatan R. and Banos, Oresti},
	title = {Mobile and wearable technology for the monitoring of diabetes-related parameters: Systematic review},
	year = {2021},
	journal = {JMIR mHealth and uHealth},
	volume = {9},
	number = {6},
	doi = {10.2196/25138},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107402358&doi=10.2196%2f25138&partnerID=40&md5=d78ab1d02694400c871fd1f659118f8d},
	affiliations = {Research Center for Information and Communication Technologies, University of Granada, Granada, Spain; Department of Computer Science, University of Cienfuegos, Cienfuegos, Cuba; Departament of Medicine, University of Granada, Granada, Spain; Endocrinology and Nutrition Unit, Hospital Universitario Clinico San Cecilio, Granada, Spain; Centro de Investigación Biomédica en Red sobre Fragilidad y Envejecimiento Saludable, Instituto de Salud Carlos III, Madrid, Spain; PROmoting FITness and Health through Physical Activity Research Group, Department of Physical Education and Sports, University of Granada, Granada, Spain},
	abstract = {Background: Diabetes mellitus is a metabolic disorder that affects hundreds of millions of people worldwide and causes several million deaths every year. Such a dramatic scenario puts some pressure on administrations, care services, and the scientific community to seek novel solutions that may help control and deal effectively with this condition and its consequences. Objective: This study aims to review the literature on the use of modern mobile and wearable technology for monitoring parameters that condition the development or evolution of diabetes mellitus. Methods: A systematic review of articles published between January 2010 and July 2020 was performed according to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines. Manuscripts were identified through searching the databases Web of Science, Scopus, and PubMed as well as through hand searching. Manuscripts were included if they involved the measurement of diabetes-related parameters such as blood glucose level, performed physical activity, or feet condition via wearable or mobile devices. The quality of the included studies was assessed using the Newcastle-Ottawa Scale. Results: The search yielded 1981 articles. A total of 26 publications met the eligibility criteria and were included in the review. Studies predominantly used wearable devices to monitor diabetes-related parameters. The accelerometer was by far the most used sensor, followed by the glucose monitor and heart rate monitor. Most studies applied some type of processing to the collected data, mainly consisting of statistical analysis or machine learning for activity recognition, finding associations among health outcomes, and diagnosing conditions related to diabetes. Few studies have focused on type 2 diabetes, even when this is the most prevalent type and the only preventable one. None of the studies focused on common diabetes complications. Clinical trials were fairly limited or nonexistent in most of the studies, with a common lack of detail about cohorts and case selection, comparability, and outcomes. Explicit endorsement by ethics committees or review boards was missing in most studies. Privacy or security issues were seldom addressed, and even if they were addressed, they were addressed at a rather insufficient level. Conclusions: The use of mobile and wearable devices for the monitoring of diabetes-related parameters shows early promise. Its development can benefit patients with diabetes, health care professionals, and researchers. However, this field is still in its early stages. Future work must pay special attention to privacy and security issues, the use of new emerging sensor technologies, the combination of mobile and clinical data, and the development of validated clinical trials. ©Ciro Rodriguez-León, Claudia Villalonga, Manuel Munoz-Torres, Jonatan R Ruiz, Oresti Banos.},
	author_keywords = {Diabetes; Mobile phone; Monitoring; Passive sensing; Smartphone; Wearable},
	keywords = {Blood Glucose; Diabetes Mellitus, Type 2; Exercise; Humans; Monitoring, Physiologic; Wearable Electronic Devices; electronic device; exercise; glucose blood level; human; non insulin dependent diabetes mellitus; physiologic monitoring},
	correspondence_address = {O. Banos; Research Center for Information and Communication Technologies, University of Granada, Granada, C/ Periodista Rafael Gomez, 2, 18071, Spain; email: oresti@ugr.es},
	publisher = {JMIR Publications Inc.},
	issn = {22915222},
	pmid = {34081010},
	language = {English},
	abbrev_source_title = {JMIR mHealth uHealth},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{McInnes2021535,
	author = {McInnes, Gregory and Sharo, Andrew G. and Koleske, Megan L. and Brown, Julia E.H. and Norstad, Matthew and Adhikari, Aashish N. and Wang, Sheng and Brenner, Steven E. and Halpern, Jodi and Koenig, Barbara A. and Magnus, David C. and Gallagher, Renata C. and Giacomini, Kathleen M. and Altman, Russ B.},
	title = {Opportunities and challenges for the computational interpretation of rare variation in clinically important genes},
	year = {2021},
	journal = {American Journal of Human Genetics},
	volume = {108},
	number = {4},
	pages = {535 – 548},
	doi = {10.1016/j.ajhg.2021.03.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103406760&doi=10.1016%2fj.ajhg.2021.03.003&partnerID=40&md5=59df8886d5793d07918a1c219a738a8a},
	affiliations = {Biomedical Informatics Training Program, Stanford University, Stanford, 94305, CA, United States; Biophysics Graduate Group, University of California, Berkeley, Berkeley, 94720, CA, United States; Department of Bioengineering and Therapeutics, University of California, San Francisco, San Francisco, 94143, CA, United States; Program in Bioethics, University of California, San Francisco, San Francisco, 94143, CA, United States; Institute for Health & Aging, University of California, San Francisco, San Francisco, 94143, CA, United States; Institute for Human Genetics, University of California, San Francisco, San Francisco, 94143, CA, United States; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, 98195, WA, United States; Department of Plant and Microbial Biology, University of California, Berkeley, Berkeley, 94720, CA, United States; Illumina, Inc., Foster City, 94404, CA, United States; UCSF-UCB Joint Medical Program, School of Public Health, University of California, Berkeley, Berkeley, 94720, CA, United States; Department of Social & Behavioral Sciences, University of California, San Francisco, San Francisco, 94143, CA, United States; Department of Humanities & Social Sciences, University of California, San Francisco, San Francisco, 94143, CA, United States; Stanford Center for Biomedical Ethics, Stanford University School of Medicine, Stanford, 94305, CA, United States; Department of Pediatrics, University of California, San Francisco, San Francisco, 94143, CA, United States; Departments of Bioengineering & Genetics, Stanford University, Stanford, 94305, CA, United States},
	abstract = {Genome sequencing is enabling precision medicine—tailoring treatment to the unique constellation of variants in an individual's genome. The impact of recurrent pathogenic variants is often understood, however there is a long tail of rare genetic variants that are uncharacterized. The problem of uncharacterized rare variation is especially acute when it occurs in genes of known clinical importance with functionally consequential variants and associated mechanisms. Variants of uncertain significance (VUSs) in these genes are discovered at a rate that outpaces current ability to classify them with databases of previous cases, experimental evaluation, and computational predictors. Clinicians are thus left without guidance about the significance of variants that may have actionable consequences. Computational prediction of the impact of rare genetic variation is increasingly becoming an important capability. In this paper, we review the technical and ethical challenges of interpreting the function of rare variants in two settings: inborn errors of metabolism in newborns and pharmacogenomics. We propose a framework for a genomic learning healthcare system with an initial focus on early-onset treatable disease in newborns and actionable pharmacogenomics. We argue that (1) a genomic learning healthcare system must allow for continuous collection and assessment of rare variants, (2) emerging machine learning methods will enable algorithms to predict the clinical impact of rare variants on protein function, and (3) ethical considerations must inform the construction and deployment of all rare-variation triage strategies, particularly with respect to health disparities arising from unbalanced ancestry representation.; Genome sequencing is enabling precision medicine—tailoring treatment to the unique constellation of variants in an individual's genome. The impact of recurrent pathogenic variants is often understood, leaving a long tail of rare genetic variants that are uncharacterized. The problem of uncharacterized rare variation is especially acute when it occurs in genes of known clinical importance with functionally consequential variants and associated mechanisms. Variants of uncertain significance (VUSs) in these genes are discovered at a rate that outpaces current ability to classify them with databases of previous cases, experimental evaluation, and computational predictors. Clinicians are thus left without guidance about the significance of variants that may have actionable consequences. Computational prediction of the impact of rare genetic variation is increasingly becoming an important capability. In this paper, we review the technical and ethical challenges of interpreting the function of rare variants in two settings: inborn errors of metabolism in newborns and pharmacogenomics. We propose a framework for a genomic learning healthcare system with an initial focus on early-onset treatable disease in newborns and actionable pharmacogenomics. We argue that (1) a genomic learning healthcare system must allow for continuous collection and assessment of rare variants, (2) emerging machine learning methods will enable algorithms to predict the clinical impact of rare variants on protein function, and (3) ethical considerations must inform the construction and deployment of all rare-variation triage strategies, particularly with respect to health disparities arising from unbalanced ancestry representation. © 2021 The Author(s)},
	keywords = {Genetic Variation; Genetics, Medical; Genome, Human; Genomics; Humans; Infant, Newborn; Machine Learning; Metabolism, Inborn Errors; Pharmacogenetics; Precision Medicine; algorithm; ancestry group; bioinformatics; clinical practice; deep learning; deep neural network; gene sequence; genetic database; genetic variation; health care system; health disparity; human; inborn error of metabolism; medical ethics; nonhuman; pharmacogenomics; prediction; priority journal; protein function; Review; single nucleotide polymorphism; social justice; transfer of learning; genetic variation; genetics; genomics; human genome; machine learning; medical genetics; newborn; personalized medicine; pharmacogenetics},
	correspondence_address = {R.B. Altman; Departments of Bioengineering & Genetics, Stanford University, Stanford, 94305, United States; email: rbaltman@stanford.edu},
	publisher = {Cell Press},
	issn = {00029297},
	coden = {AJHGA},
	pmid = {33798442},
	language = {English},
	abbrev_source_title = {Am. J. Hum. Genet.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Hodson2021S1,
	author = {Hodson, Richard},
	title = {Sports science},
	year = {2021},
	journal = {Nature},
	volume = {592},
	number = {7852},
	pages = {S1},
	doi = {10.1038/d41586-021-00814-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103745338&doi=10.1038%2fd41586-021-00814-5&partnerID=40&md5=6fd5f4229077ab5d97cefd783f45f7a9},
	author_keywords = {Cell biology; Ethics; Machine learning; Physiology},
	keywords = {Athletes; Athletic Injuries; Extreme Heat; Female; Gastrointestinal Microbiome; Humans; Mitochondria; Neurosciences; Physiology; Running; Sports; Sports Medicine; Swimming; Tokyo; Virtual Reality; Wearable Electronic Devices; adverse event; athlete; electronic device; female; heat; human; intestine flora; Japan; metabolism; mitochondrion; neuroscience; pathophysiology; physiology; psychology; running; sport; sport injury; sports medicine; swimming; virtual reality},
	publisher = {NLM (Medline)},
	issn = {14764687},
	pmid = {33790453},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{2021166,
	title = {Am I arguing with a machine? AI debaters highlight need for transparency},
	year = {2021},
	journal = {Nature},
	volume = {592},
	number = {7853},
	pages = {166},
	doi = {10.1038/d41586-021-00867-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103615753&doi=10.1038%2fd41586-021-00867-6&partnerID=40&md5=bc1a34ba1548c418f408c1479807d8fc},
	abstract = {With artificial intelligence starting to take part in debates with humans, more oversight is needed to avoid manipulation and harm. [Figure not available: see fulltext.] © 2021, Nature.},
	author_keywords = {Computer science; Ethics; Machine learning; Society; Technology},
	keywords = {Artificial Intelligence; Machine Learning; artificial intelligence; Editorial; emotion; human; interpersonal communication; language; machine learning; priority journal; technology; machine learning},
	publisher = {Nature Research},
	issn = {00280836},
	coden = {NATUA},
	pmid = {33828323},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kasirzadeh2021618,
	author = {Kasirzadeh, Atoosa and Klein, Colin},
	title = {The Ethical Gravity Thesis: Marrian Levels and the Persistence of Bias in Automated Decision-making Systems},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {618 – 626},
	doi = {10.1145/3461702.3462606},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112456654&doi=10.1145%2f3461702.3462606&partnerID=40&md5=27deae7352434f4774fb07996c8e9b08},
	affiliations = {University of Toronto and Australian National University, Canberra, Australia; Australian National University, Canberra, Australia},
	abstract = {Computers are used to make decisions in an increasing number of domains. There is widespread agreement that some of these uses are ethically problematic. Far less clear is where ethical problems arise, and what might be done about them. This paper expands and defends the Ethical Gravity Thesis: ethical problems that arise at higher levels of analysis of an automated decision-making system are inherited by lower levels of analysis. Particular instantiations of systems can add new problems, but not ameliorate more general ones. We defend this thesis by adapting Marr's famous 1982 framework for understanding information-processing systems. We show how this framework allows one to situate ethical problems at the appropriate level of abstraction, which in turn can be used to target appropriate interventions. © 2021 Owner/Author.},
	author_keywords = {algorithmic bias; algorithmic fairness; ethical artificial intelligence; ethical machine learning; ethics of artificial intelligence; justice; philosophy of artificial intelligence; politics of artificial intelligence},
	keywords = {Artificial intelligence; Decision making; Automated decision making systems; Ethical problems; Information processing systems; Level of abstraction; Levels of analysis; Philosophical aspects},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Thoral2021E563,
	author = {Thoral, Patrick J. and Peppink, Jan M. and Driessen, Ronald H. and Sijbrands, Eric J. G. and Kompanje, Erwin J. O. and Kaplan, Lewis and Bailey, Heatherlee and Kesecioglu, Jozef and Cecconi, Maurizio and Churpek, Matthew and Clermont, Gilles and Van Der Schaar, Mihaela and Ercole, Ari and Girbes, Armand R. J. and Elbers, Paul W. G.},
	title = {Sharing ICU Patient Data Responsibly Under the Society of Critical Care Medicine/European Society of Intensive Care Medicine Joint Data Science Collaboration: The Amsterdam University Medical Centers Database (AmsterdamUMCdb) Example∗},
	year = {2021},
	journal = {Critical Care Medicine},
	volume = {49},
	number = {6},
	pages = {E563 – E577},
	doi = {10.1097/CCM.0000000000004916},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104572371&doi=10.1097%2fCCM.0000000000004916&partnerID=40&md5=31ef7e7296d71364603f1c798577042b},
	affiliations = {Department Of Intensive Care Medicine, Amsterdam Medical Data Science (AMDS), Amsterdam Cardiovascular Sciences (ACS), Amsterdam Infection And Immunity Institute (AI&II), Amsterdam Umc, Vrije Universiteit, Universiteit Van Amsterdam, Amsterdam, Netherlands; Department Of Internal Medicine, Erasmus Mc, Rotterdam, Netherlands; Department Of Intensive Care Medicine, Erasmus Mc, Rotterdam, Netherlands; Division Of Trauma, Surgical Critical Care And Emergency Surgery, Perelman School Of Medicine, University Of Pennsylvania, Philadelphia, PA, United States; Department Of Emergency Medicine, Durham Va Medical Center, Durham, NC, United States; Executive Committee, Society Of Critical Care Medicine, Mount Prospect, IL, United States; Department Of Intensive Care Medicine, University Medical Center Utrecht, Utrecht University, Utrecht, Netherlands; Executive Committee, European Society Of Intensive Care Medicine, Brussels, Belgium; Department Of Anaesthesia And Intensive Care, Humanitas Research Hospital, Humanitas University, Milan, Italy; Department Of Medicine, University Of Wisconsin, Madison, WI, United States; Department Of Critical Care Medicine, Crisma Laboratory, University Of Pittsburgh, Pittsburgh, PA, United States; University Of Cambridge, Cambridge, United Kingdom; Alan Turing Institute, London, United Kingdom; Division Of Anaesthesia, University Of Cambridge, Cambridge, United Kingdom; Data Science Section, European Society Of Intensive Care Medicine, Brussels, Belgium},
	abstract = {OBJECTIVES: Critical care medicine is a natural environment for machine learning approaches to improve outcomes for critically ill patients as admissions to ICUs generate vast amounts of data. However, technical, legal, ethical, and privacy concerns have so far limited the critical care medicine community from making these data readily available. The Society of Critical Care Medicine and the European Society of Intensive Care Medicine have identified ICU patient data sharing as one of the priorities under their Joint Data Science Collaboration. To encourage ICUs worldwide to share their patient data responsibly, we now describe the development and release of Amsterdam University Medical Centers Database (AmsterdamUMCdb), the first freely available critical care database in full compliance with privacy laws from both the United States and Europe, as an example of the feasibility of sharing complex critical care data. SETTING: University hospital ICU. SUBJECTS: Data from ICU patients admitted between 2003 and 2016. INTERVENTIONS: We used a risk-based deidentification strategy to maintain data utility while preserving privacy. In addition, we implemented contractual and governance processes, and a communication strategy. Patient organizations, supporting hospitals, and experts on ethics and privacy audited these processes and the database. MEASUREMENTS AND MAIN RESULTS: AmsterdamUMCdb contains approximately 1 billion clinical data points from 23,106 admissions of 20,109 patients. The privacy audit concluded that reidentification is not reasonably likely, and AmsterdamUMCdb can therefore be considered as anonymous information, both in the context of the U.S. Health Insurance Portability and Accountability Act and the European General Data Protection Regulation. The ethics audit concluded that responsible data sharing imposes minimal burden, whereas the potential benefit is tremendous. CONCLUSIONS: Technical, legal, ethical, and privacy challenges related to responsible data sharing can be addressed using a multidisciplinary approach. A risk-based deidentification strategy, that complies with both U.S. and European privacy regulations, should be the preferred approach to releasing ICU patient data. This supports the shared Society of Critical Care Medicine and European Society of Intensive Care Medicine vision to improve critical care outcomes through scientific inquiry of vast and combined ICU datasets.  Copyright © 2021 The Author(s).},
	author_keywords = {artificial intelligence; big data; data anonymization; data science; database; General Data Protection Regulation; Health Insurance Portability and Accountability Act; machine learning},
	keywords = {Confidentiality; Databases, Factual; Health Information Exchange; Health Insurance Portability and Accountability Act; Hospitals, University; Humans; Intensive Care Units; Netherlands; Societies, Medical; United States; adult; anonymised data; anonymization; article; artificial intelligence; big data; critical care outcome; data science; ethics; Europe; feasibility study; female; health insurance; human; intensive care medicine; machine learning; major clinical study; male; organization; patient coding; privacy; university hospital; confidentiality; factual database; health insurance; intensive care unit; legislation and jurisprudence; medical information system; medical society; Netherlands; organization and management; United States; university hospital},
	correspondence_address = {P.J. Thoral; Department Of Intensive Care Medicine, Amsterdam Medical Data Science (AMDS), Amsterdam Cardiovascular Sciences (ACS), Amsterdam Infection And Immunity Institute (AI&II), Amsterdam Umc, Vrije Universiteit, Universiteit Van Amsterdam, Amsterdam, Netherlands; email: p.thoral@amsterdamumc.nl},
	publisher = {Lippincott Williams and Wilkins},
	issn = {00903493},
	coden = {CCMDC},
	pmid = {33625129},
	language = {English},
	abbrev_source_title = {Crit. Care Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 51; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Quadrianto2021,
	author = {Quadrianto, Novi and Schuller, Björn W. and Lattimore, Finnian Rachel},
	title = {Editorial: Ethical Machine Learning and Artificial Intelligence},
	year = {2021},
	journal = {Frontiers in Big Data},
	volume = {4},
	doi = {10.3389/fdata.2021.742589},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113529116&doi=10.3389%2ffdata.2021.742589&partnerID=40&md5=6da18b150f266cb321dc64f50429c0c2},
	affiliations = {PAL – Predictive Analytics Lab, University of Sussex, Brighton, United Kingdom; BCAM, Severo Ochoa Strategic Lab on Trustworthy Machine Learning, Bilbao, Spain; GLAM – Group on Language, Audio, Music, Imperial College London, London, United Kingdom; EIHW – Chair of Embedded Intelligence for Health Care and Wellbeing, University of Augsburg, Augsburg, Germany; Gradient Institute, Sydney, NSW, Australia},
	author_keywords = {accountability; artificial intelligence; ethics; fairness; General Data Protection Regulation; machine learning; transparency; trustworthiness},
	correspondence_address = {B.W. Schuller; GLAM – Group on Language, Audio, Music, Imperial College London, London, United Kingdom; email: schuller@ieee.org},
	publisher = {Frontiers Media S.A.},
	issn = {2624909X},
	language = {English},
	abbrev_source_title = {Frontiers. Big. Data.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Cave2021,
	author = {Cave, Stephen and Whittlestone, Jess and Nyrup, Rune and Heigeartaigh, Sean O. and Calvo, Rafael A.},
	title = {Using AI ethically to tackle covid-19},
	year = {2021},
	journal = {The BMJ},
	volume = {372},
	doi = {10.1136/bmj.n364},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102865553&doi=10.1136%2fbmj.n364&partnerID=40&md5=1ba247153d017d94e396b50ba2f8994c},
	affiliations = {Leverhulme Centre for the Future of Intelligence, University of Cambridge, Cambridge, United Kingdom; Dyson School of Design Engineering, Imperial College London, United Kingdom},
	keywords = {Artificial Intelligence; Beneficence; COVID-19; Ethics, Medical; Humans; Personal Autonomy; SARS-CoV-2; Social Justice; Stakeholder Participation; access to information; algorithm; Article; artificial intelligence; automation; coronavirus disease 2019; data base; decision making; ethnic group; facial recognition; fatality; government; health care personnel; health survey; high risk population; home quarantine; information processing; information security; justice; machine learning; medical ethics; medical expert; nonmaleficence; pandemic; prediction; priority journal; race; risk factor; software; technology; uncertainty; artificial intelligence; beneficence; ethics; human; personal autonomy; social justice; stakeholder engagement},
	correspondence_address = {S. Cave; Leverhulme Centre for the Future of Intelligence, University of Cambridge, Cambridge, United Kingdom; email: sjc53@cam.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {09598146},
	coden = {BMJOA},
	pmid = {33722807},
	language = {English},
	abbrev_source_title = {BMJ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zidaru20211072,
	author = {Zidaru, Teodor and Morrow, Elizabeth M. and Stockley, Rich},
	title = {Ensuring patient and public involvement in the transition to AI-assisted mental health care: A systematic scoping review and agenda for design justice},
	year = {2021},
	journal = {Health Expectations},
	volume = {24},
	number = {4},
	pages = {1072 – 1124},
	doi = {10.1111/hex.13299},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107627300&doi=10.1111%2fhex.13299&partnerID=40&md5=d92dfcdb3c2fefed6511344438236d95},
	affiliations = {Department of Anthropology, London School of Economics and Political Science (LSE), London, United Kingdom; Research Support NI, Belfast, United Kingdom; Surrey Heartlands Health and Care Partnership, Guildford and Waverley CCG, Guildford, United Kingdom; Insight and Feedback Team, Nursing Directorate, NHS England and NHS Improvement, London, United Kingdom; Surrey County Council, Kingston upon Thames, United Kingdom},
	abstract = {Background: Machine-learning algorithms and big data analytics, popularly known as ‘artificial intelligence’ (AI), are being developed and taken up globally. Patient and public involvement (PPI) in the transition to AI-assisted health care is essential for design justice based on diverse patient needs. Objective: To inform the future development of PPI in AI-assisted health care by exploring public engagement in the conceptualization, design, development, testing, implementation, use and evaluation of AI technologies for mental health. Methods: Systematic scoping review drawing on design justice principles, and (i) structured searches of Web of Science (all databases) and Ovid (MEDLINE, PsycINFO, Global Health and Embase); (ii) handsearching (reference and citation tracking); (iii) grey literature; and (iv) inductive thematic analysis, tested at a workshop with health researchers. Results: The review identified 144 articles that met inclusion criteria. Three main themes reflect the challenges and opportunities associated with PPI in AI-assisted mental health care: (a) applications of AI technologies in mental health care; (b) ethics of public engagement in AI-assisted care; and (c) public engagement in the planning, development, implementation, evaluation and diffusion of AI technologies. Conclusion: The new data-rich health landscape creates multiple ethical issues and opportunities for the development of PPI in relation to AI technologies. Further research is needed to understand effective modes of public engagement in the context of AI technologies, to examine pressing ethical and safety issues and to develop new methods of PPI at every stage, from concept design to the final review of technology in practice. Principles of design justice can guide this agenda. © 2021 The Authors. Health Expectations published by John Wiley & Sons Ltd.},
	author_keywords = {artificial intelligence; big data; design justice; digital health technology; machine learning; mental health; patient and public involvement; public engagement; scoping review},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Mental Health; Morals; Social Justice; adult; artificial intelligence; big data; diffusion; drawing; drug safety; Embase; ethics; female; global health; grey literature; human; justice; machine learning; male; Medline; mental health care; PsycINFO; review; systematic review; thematic analysis; Web of Science; health care delivery; mental health; morality; social justice},
	correspondence_address = {T. Zidaru; Department of Anthropology, London School of Economics and Political Science (LSE), London, United Kingdom; email: t.m.zidaru-barbulescu@lse.ac.uk},
	publisher = {John Wiley and Sons Inc},
	issn = {13696513},
	coden = {HEHPF},
	pmid = {34118185},
	language = {English},
	abbrev_source_title = {Health Expect.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@ARTICLE{Meszaros2021,
	author = {Meszaros, Janos and Ho, Chih-hsing},
	title = {AI research and data protection: Can the same rules apply for commercial and academic research under the GDPR?},
	year = {2021},
	journal = {Computer Law and Security Review},
	volume = {41},
	doi = {10.1016/j.clsr.2021.105532},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104134727&doi=10.1016%2fj.clsr.2021.105532&partnerID=40&md5=5c9b9e81242d4dd49615a6371ddafca2},
	affiliations = {Academia Sinica, Taiwan},
	abstract = {The paper examines how the EU General Data Protection Regulation (GDPR) is applied to the development of AI products and services, drawing attention to the differences between academic and commercial research. The GDPR aims to encourage innovation by providing several exemptions from its strict rules for scientific research. Still, the GDPR defines scientific research in a broad manner, which includes academic and commercial research. However, corporations conducting commercial research might not have in place a similar level of ethical and institutional safeguards as academic researchers. Furthermore, corporate secrecy and opaque algorithms in AI research might pose barriers to oversight. The aim of this paper is to stress the limits of the GDPR research exemption and to find the proper balance between privacy and innovation. The paper argues that commercial AI research should not benefit from the GDPR research exemption unless there is a public interest and has similar safeguards to academic research, such as review by research ethics committees. Since the GDPR provides this broad exemption, it is crucial to clarify the limits and requirements of scientific research, before the application of AI drastically transforms this field. © 2021 The Authors},
	author_keywords = {AI; Artificial intelligence; Commercial research; Computer science; GDPR; Machine learning; Scientific research},
	keywords = {Philosophical aspects; Academic research; General data protection regulations; Products and services; Public interest; Research ethics; Research exemption; Scientific researches; Privacy by design},
	correspondence_address = {C.-H. Ho; Institute of European and American Studies, Academia Sinica, Taipei, 128, Sec 2, Academia Road, 115, Taiwan; email: chihho@sinica.edu.tw},
	publisher = {Elsevier Ltd},
	issn = {02673649},
	coden = {CLSRE},
	language = {English},
	abbrev_source_title = {Comput Law Secur. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Reisach2021906,
	author = {Reisach, Ulrike},
	title = {The responsibility of social media in times of societal and political manipulation},
	year = {2021},
	journal = {European Journal of Operational Research},
	volume = {291},
	number = {3},
	pages = {906 – 917},
	doi = {10.1016/j.ejor.2020.09.020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094573545&doi=10.1016%2fj.ejor.2020.09.020&partnerID=40&md5=14b6b29d8a579d89f382b50f3ea4f116},
	affiliations = {Department of Information Management, Prof. Dr. Ulrike Reisach, Neu-Ulm University of Applied Sciences, Wiley-Street 1, Neu-Ulm, D-89231, Germany},
	abstract = {The way electorates were influenced to vote for the Brexit referendum, and in presidential elections both in Brazil and the USA, has accelerated a debate about whether and how machine learning techniques can influence citizens’ decisions. The access to balanced information is endangered if digital political manipulation can influence voters. The techniques of profiling and targeting on social media platforms can be used for advertising as well as for propaganda: Through tracking of a person's online behaviour, algorithms of social media platforms can create profiles of users. These can be used for the provision of recommendations or pieces of information to specific target groups. As a result, propaganda and disinformation can influence the opinions and (election) decisions of voters much more powerfully than previously. In order to counter disinformation and societal polarization, the paper proposes a responsibility-based approach for social media platforms in diverse political contexts. Based on the implementation requirements of the “Ethics Guidelines for Trustworthy Artificial Intelligence” of the European Commission, the ethical principles will be operationalized, as far as they are directly relevant for the safeguarding of democratic societies. The resulting suggestions show how the social media platform providers can minimize risks for societies through responsible action in the fields of human rights, education and transparency of algorithmic decisions. © 2020 The Author},
	author_keywords = {Artificial intelligence; Behavioural OR; Decision-making; Education; Ethics in OR},
	keywords = {Artificial intelligence; Learning systems; Philosophical aspects; Ethical principles; European Commission; Machine learning techniques; Online behaviours; Political context; Political manipulation; Presidential election; Social media platforms; Social networking (online)},
	publisher = {Elsevier B.V.},
	issn = {03772217},
	coden = {EJORD},
	language = {English},
	abbrev_source_title = {Eur J Oper Res},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Cascajares2021,
	author = {Cascajares, Mila and Alcayde, Alfredo and Salmerón-Manzano, Esther and Manzano-Agugliaro, Francisco},
	title = {The bibliometric literature on scopus and wos: The medicine and environmental sciences categories as case of study},
	year = {2021},
	journal = {International Journal of Environmental Research and Public Health},
	volume = {18},
	number = {11},
	doi = {10.3390/ijerph18115851},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106735947&doi=10.3390%2fijerph18115851&partnerID=40&md5=a3f49279387b6ad59286fc30b2459e37},
	affiliations = {Department of Engineering, University of Almeria, ceiA3, Almeria, 04120, Spain; Faculty of Law, Universidad Internacional de La Rioja (UNIR), Av. de la Paz, 137, Logroño, 26006, Spain},
	abstract = {In a broad sense, science can be understood as the knowledge contained in scientific manuscripts published in scientific journals. Scientific databases index only those journals that reach certain quality standards. Therefore, research and dissemination of scientific knowledge are essential activities for the growth of science itself. The aim of this manuscript is to assess the situation of medicine and environmental sciences among the bibliometric literature and to put it in perspective with the overall bibliometric publications in all scientific fields. The main countries publishing bibliometric manuscripts are China, USA and Spain. The latter country is ranked three out of the top five institutions according to the Scopus and WoS databases. In both databases, the average scientific collaboration of the top 20 institutions offers the same result, 41%. According to Scopus, the main subject categories in which this research falls are social sciences (38%), computer science (26%) and medicine (23%), while the environmental sciences category has 8%. In the analysis of the Medicine category alone, it has been observed that 136 countries have contributions in this field. The main countries are the United States, China and the United Kingdom. In the field of medicine, the main areas studied were: Epidemiology, Pediatrics, Orthopedics, Cardiology, Neurosurgery, Radiology, Ophthalmology, Oncology, Plastic Surgery and Psychiatry. With respect to environmental sciences, less international dissemination has been found, with only 83 countries having worked in this field. The main ones are China, Spain and the United States. Regarding the top 10 institutions, it can be stated that only Spain and China are relevant. Spain focuses on sustainability and China on the environment. The result of an independent keyword analysis of all published bibliometric manuscripts has shown that the main clusters are: Mapping Science (29%), Research Productivity (23%), Medicine (20%), Environmental Sciences (12%), Psychology (7%), Nursing (6%) and Engineering (4%). In short, medicine and environmental sciences are the most relevant areas in the field of bibliometrics after social sciences and computer sciences. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Bibliometry; Environmental science; Medicine; Scopus; Sustainability; Web of Science},
	keywords = {Bibliometrics; Child; China; Environmental Science; Humans; Spain; United Kingdom; United States; China; Spain; United Kingdom; United States; Scopus; literature review; medicine; public health; sustainability; Article; artificial intelligence; bibliometrics; China; engineering; environmental science; human; machine learning; medical ethics; medicine; nursing; publication; Scopus; sociology; Spain; United States; Web of Science; bibliometrics; child; United Kingdom},
	correspondence_address = {E. Salmerón-Manzano; Faculty of Law, Universidad Internacional de La Rioja (UNIR), Logroño, Av. de la Paz, 137, 26006, Spain; email: esther.salmeron@unir.net},
	publisher = {MDPI AG},
	issn = {16617827},
	pmid = {34072479},
	language = {English},
	abbrev_source_title = {Int. J. Environ. Res. Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Tachtler2021,
	author = {Tachtler, Franziska and Aal, Konstantin and Ertl, Tanja and Diethei, Daniel and Niess, Jasmin and Khwaja, Mohammed and Talhouk, Reem and Vilaza, Giovanna Nunes and Lazem, Shaimaa and Singh, Aneesha and Barry, Marguerite and Wulf, Volker and Fitzpatrick, Geraldine},
	title = {Artificially Intelligent Technology for the Margins: A Multidisciplinary Design Agenda},
	year = {2021},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3411763.3441333},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105819111&doi=10.1145%2f3411763.3441333&partnerID=40&md5=a3e2bc70fb0bd66b75a00ec087bc7428},
	affiliations = {Tu Wien Vienna, Austria; University of Siegen, Germany},
	abstract = {There has been increasing interest in socially just use of Artificial Intelligence (AI) and Machine Learning (ML) in the development of technology that may be extended to marginalized people. However, the exploration of such technologies entails the development of an understanding of how they may increase and/or counter marginalization. The use of AI/ML algorithms can lead to several challenges, such as privacy and security concerns, biases, unfairness, and lack of cultural awareness, which especially affect marginalized people. This workshop will provide a forum to share experiences and challenges of developing AI/ML health and social wellbeing technologies with/for marginalized people and will work towards developing design methods to engage in the re-envisioning of AI/ML technologies for and with marginalized people. In doing so we will create cross-research area dialogues and collaborations. These discussions build a basis to (1) explore potential tools to support designing AI/ML systems with marginalized people, and (2) develop a design agenda for future research and AI/ML technology for and with marginalized people. © 2021 Owner/Author.},
	author_keywords = {AI; Data; Ethics; Global South; HCI4D; ICT4D; Marginalized people; ML; Privacy; Security},
	keywords = {Engineering education; Human engineering; Privacy by design; Cultural awareness; Design method; Intelligent technology; Marginalization; Multi-disciplinary designs; Potential tool; Privacy and security; Social well-being; Artificial intelligence},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038095-9},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2021 CHI Conference on Human Factors in Computing Systems: Making Waves, Combining Strengths, CHI EA 2021; Conference date: 8 May 2021 through 13 May 2021; Conference code: 168787; All Open Access, Green Open Access}
}

@ARTICLE{Kothari2021,
	author = {Kothari, Anita and Foisey, Lyndsay and Donelle, Lorie and Bauer, Michael},
	title = {How do Canadian public health agencies respond to the COVID-19 emergency using social media: A protocol for a case study using content and sentiment analysis},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {4},
	doi = {10.1136/bmjopen-2020-041818},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105030571&doi=10.1136%2fbmjopen-2020-041818&partnerID=40&md5=dc688986a828c2387e85f6a5207df97d},
	affiliations = {School of Health Studies, Faculty of Health Sciences, Western University, London, ON, Canada; Health Information Science Graduate Program, Western University, London, ON, Canada; Arthur Labatt Family School of Nursing, Faculty of Health Sciences, Western University, London, ON, Canada; Department of Computer Sciences, Faculty of Science, Western University, London, ON, Canada},
	abstract = {Introduction Keeping Canadians safe requires a robust public health (PH) system. This is especially true when there is a PH emergency, like the COVID-19 pandemic. Social media, like Twitter and Facebook, is an important information channel because most people use the internet for their health information. The PH sector can use social media during emergency events for (1) PH messaging, (2) monitoring misinformation, and (3) responding to questions and concerns raised by the public. In this study, we ask: what is the Canadian PH risk communication response to the COVID-19 pandemic in the context of social media? Methods and analysis We will conduct a case study using content and sentiment analysis to examine how provinces and provincial PH leaders, and the Public Health Agency of Canada and national public heath leaders, engage with the public using social media during the first wave of the pandemic (1 January-3 September 2020). We will focus specifically on Twitter and Facebook. We will compare findings to a gold standard during the emergency with respect to message content. Ethics and dissemination Western University's research ethics boards confirmed that this study does not require research ethics board review as we are using social media data in the public domain. Using our study findings, we will work with PH stakeholders to collaboratively develop Canadian social media emergency response guideline recommendations for PH and other health system organisations. Findings will also be disseminated through peer-reviewed journal articles and conference presentations.  © },
	author_keywords = {COVID-19; infection control; public health; World Wide Web technology},
	keywords = {Canada; COVID-19; Humans; Pandemics; Public Health; SARS-CoV-2; Social Media; anger; Article; Canadian; confusion; content analysis; coronavirus disease 2019; disgust; emergency care; fear; health care system; health service; health workforce; human; interpersonal communication; leadership; machine learning; medical information; public health; sadness; self concept; social distancing; social media; travel; Canada; pandemic; public health; social media},
	correspondence_address = {A. Kothari; School of Health Studies, Faculty of Health Sciences, Western University, London, Canada; email: akothari@uwo.ca},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33888527},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Clarke2021282,
	author = {Clarke, Janice and Skoufalos, Alexandria and Klasko, Stephen K.},
	title = {The Human in the Middle: Artificial Intelligence in Health Care Summary Proceedings Symposium Presentation and Reactor Panel of Experts Thomas Jefferson University December 10, 2019},
	year = {2021},
	journal = {Population Health Management},
	volume = {24},
	number = {2},
	pages = {282 – 285},
	doi = {10.1089/pop.2020.0030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105058248&doi=10.1089%2fpop.2020.0030&partnerID=40&md5=db990bf8d18f34e8e90bdbd5b54fcdc8},
	affiliations = {Jefferson College of Population Health of Thomas Jefferson University, Philadelphia, PA, United States; Thomas Jefferson University and Jefferson Health, Philadelphia, PA, United States},
	keywords = {Artificial Intelligence; Delivery of Health Care; Health Facilities; Humans; Universities; artificial intelligence; Conference Paper; consensus development; health care; health care industry; human; internet of things; machine learning; medical education; medical ethics; medical student; privacy; university; health care delivery; health care facility; university},
	correspondence_address = {J. Clarke; Jefferson College of Population Health of Thomas Jefferson University, Philadelphia, United States; email: janice.clarke@jefferson.edu},
	publisher = {Mary Ann Liebert Inc.},
	issn = {19427891},
	pmid = {32130081},
	language = {English},
	abbrev_source_title = {Popul. Heath. Manage.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Nichol2021,
	author = {Nichol, Ariadne A. and Batten, Jason N. and Halley, Meghan C. and Axelrod, Julia K. and Sankar, Pamela L. and Cho, Mildred K.},
	title = {A typology of existing machine learning-based predictive analytic tools focused on reducing costs and improving quality in health care: Systematic search and content analysis},
	year = {2021},
	journal = {Journal of Medical Internet Research},
	volume = {23},
	number = {6},
	doi = {10.2196/26391},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108803335&doi=10.2196%2f26391&partnerID=40&md5=efd05a3692cba3acb993c6d50f5836a9},
	affiliations = {Stanford School of Medicine, Stanford Center for Biomedical Ethics, Stanford, CA, United States; Department of Medical Ethics and Health Policy, Perelman School of Medicine, Philadelphia, PA, United States},
	abstract = {Background: Considerable effort has been devoted to the development of artificial intelligence, including machine learning-based predictive analytics (MLPA) for use in health care settings. The growth of MLPA could be fueled by payment reforms that hold health care organizations responsible for providing high-quality, cost-effective care. Policy analysts, ethicists, and computer scientists have identified unique ethical and regulatory challenges from the use of MLPA in health care. However, little is known about the types of MLPA health care products available on the market today or their stated goals. Objective: This study aims to better characterize available MLPA health care products, identifying and characterizing claims about products recently or currently in use in US health care settings that are marketed as tools to improve health care efficiency by improving quality of care while reducing costs. Methods: We conducted systematic database searches of relevant business news and academic research to identify MLPA products for health care efficiency meeting our inclusion and exclusion criteria. We used content analysis to generate MLPA product categories and characterize the organizations marketing the products. Results: We identified 106 products and characterized them based on publicly available information in terms of the types of predictions made and the size, type, and clinical training of the leadership of the companies marketing them. We identified 5 categories of predictions made by MLPA products based on publicly available product marketing materials: disease onset and progression, treatment, cost and utilization, admissions and readmissions, and decompensation and adverse events. Conclusions: Our findings provide a foundational reference to inform the analysis of specific ethical and regulatory challenges arising from the use of MLPA to improve health care efficiency. © Ariadne A Nichol, Jason N Batten, Meghan C Halley, Julia K Axelrod, Pamela L Sankar, Mildred K Cho. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 22.06.2021. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on https://www.jmir.org/, as well as this copyright and license information must be included.},
	author_keywords = {Artificial intelligence; Costs; Ethics; Health care quality; Machine learning; Regulation},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Machine Learning; Quality of Health Care; adverse event; Article; artificial intelligence; content analysis; cost control; disease exacerbation; health care cost; health care quality; health care utilization; hospital readmission; human; intensive care unit; machine learning; organizational culture; prediction; social determinants of health; systematic review; total quality management; treatment outcome; artificial intelligence; health care delivery; health care quality; machine learning},
	correspondence_address = {A.A. Nichol; Stanford School of Medicine, Stanford Center for Biomedical Ethics, Stanford, 1215 Welch Road, Modular A, 94305, United States; email: ariadnen@stanford.edu},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {34156338},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Blease2021,
	author = {Blease, Charlotte and Kharko, Anna and Annoni, Marco and Gaab, Jens and Locher, Cosima},
	title = {Machine Learning in Clinical Psychology and Psychotherapy Education: A Mixed Methods Pilot Survey of Postgraduate Students at a Swiss University},
	year = {2021},
	journal = {Frontiers in Public Health},
	volume = {9},
	doi = {10.3389/fpubh.2021.623088},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104666240&doi=10.3389%2ffpubh.2021.623088&partnerID=40&md5=636933433b27637a18fd6233a5c17e80},
	affiliations = {General Medicine and Primary Care, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Faculty of Health, University of Plymouth, Plymouth, United Kingdom; Interdepartmental Center for Research Ethics and Integrity CNR, Rome, Italy; Fondazione Umberto Veronesi, Milan, Italy; Department of Clinical Psychology and Psychotherapy, University of Basel, Basel, Switzerland; Department of Consultation-Liaison Psychiatry and Psychosomatic Medicine, University Hospital Zurich, Zurich, Switzerland},
	abstract = {Background: There is increasing use of psychotherapy apps in mental health care. Objective: This mixed methods pilot study aimed to explore postgraduate clinical psychology students' familiarity and formal exposure to topics related to artificial intelligence and machine learning (AI/ML) during their studies. Methods: In April-June 2020, we conducted a mixed-methods online survey using a convenience sample of 120 clinical psychology students enrolled in a two-year Masters' program at a Swiss University. Results: In total 37 students responded (response rate: 37/120, 31%). Among respondents, 73% (n = 27) intended to enter a mental health profession, and 97% reported that they had heard of the term “machine learning.” Students estimated 0.52% of their program would be spent on AI/ML education. Around half (46%) reported that they intended to learn about AI/ML as it pertained to mental health care. On 5-point Likert scale, students “moderately agreed” (median = 4) that AI/M should be part of clinical psychology/psychotherapy education. Qualitative analysis of students' comments resulted in four major themes on the impact of AI/ML on mental healthcare: (1) Changes in the quality and understanding of psychotherapy care; (2) Impact on patient-therapist interactions; (3) Impact on the psychotherapy profession; (4) Data management and ethical issues. Conclusions: This pilot study found that postgraduate clinical psychology students held a wide range of opinions but had limited formal education on how AI/ML-enabled tools might impact psychotherapy. The survey raises questions about how curricula could be enhanced to educate clinical psychology/psychotherapy trainees about the scope of AI/ML in mental healthcare. © Copyright © 2021 Blease, Kharko, Annoni, Gaab and Locher.},
	author_keywords = {artificial intelligence; attitudes; ethics; machine learning; medical education psychotherapy education; opinions; psychology students; survey},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Pilot Projects; Psychology, Clinical; Psychotherapy; Surveys and Questionnaires; Switzerland; Universities; artificial intelligence; clinical psychology; human; machine learning; pilot study; psychotherapy; questionnaire; Switzerland; university},
	correspondence_address = {C. Blease; General Medicine and Primary Care, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, United States; email: cblease@bidmc.harvard.edu},
	publisher = {Frontiers Media S.A.},
	issn = {22962565},
	pmid = {33898374},
	language = {English},
	abbrev_source_title = {Front. Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Guijo-Rubio2021,
	author = {Guijo-Rubio, David and Briceño, Javier and Gutiérrez, Pedro Antonio and Ayllón, Maria Dolores and Ciria, Rubén and Hervás-Martínez, César},
	title = {Statistical methods versus machine learning techniques for donor-recipient matching in liver transplantation},
	year = {2021},
	journal = {PLoS ONE},
	volume = {16},
	number = {5 May},
	doi = {10.1371/journal.pone.0252068},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106371060&doi=10.1371%2fjournal.pone.0252068&partnerID=40&md5=c40e0db12c3507cabc7c3f4693e0edb1},
	affiliations = {Department of Computer Sciences and Numerical Analysis, University of Córdoba, Córdoba, Spain; Unit of Hepatobiliary Surgery and Liver Transplantation, Hospital Universitario Reina Sofiá, IMIBIC, Córdoba, Spain},
	abstract = {Donor-Recipient (D-R) matching is one of the main challenges to be fulfilled nowadays. Due to the increasing number of recipients and the small amount of donors in liver transplantation, the allocation method is crucial. In this paper, to establish a fair comparison, the United Network for Organ Sharing database was used with 4 different end-points (3 months, and 1, 2 and 5 years), with a total of 39, 189 D-R pairs and 28 donor and recipient variables. Modelling techniques were divided into two groups: 1) classical statistical methods, including Logistic Regression (LR) and Naïve Bayes (NB), and 2) standard machine learning techniques, including Multilayer Perceptron (MLP), Random Forest (RF), Gradient Boosting (GB) or Support Vector Machines (SVM), among others. The methods were compared with standard scores, MELD, SOFT and BAR. For the 5-years end-point, LR (AUC = 0.654) outperformed several machine learning techniques, such as MLP (AUC = 0.599), GB (AUC = 0.600), SVM (AUC = 0.624) or RF (AUC = 0.644), among others. Moreover, LR also outperformed standard scores. The same pattern was reproduced for the others 3 end-points. Complex machine learning methods were not able to improve the performance of liver allocation, probably due to the implicit limitations associated to the collection process of the database.  © 2021 Guijo-Rubio et al.},
	keywords = {Bayes Theorem; Data Interpretation, Statistical; Databases, Factual; Histocompatibility Testing; Humans; Liver Transplantation; Logistic Models; Support Vector Machine; Tissue and Organ Procurement; Tissue Donors; Transplant Recipients; adult; article; controlled study; female; human; liver transplantation; major clinical study; male; multilayer perceptron; random forest; support vector machine; Bayes theorem; donor; ethics; factual database; graft recipient; histocompatibility test; liver transplantation; procedures; psychology; statistical analysis; statistical model; support vector machine; transplantation},
	correspondence_address = {D. Guijo-Rubio; Department of Computer Sciences and Numerical Analysis, University of Córdoba, Córdoba, Spain; email: dguijo@uco.es},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {34019601},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Dunne2021,
	author = {Dunne, Rob and Morris, Tim and Harper, Simon},
	title = {A survey of ambient intelligence},
	year = {2021},
	journal = {ACM Computing Surveys},
	volume = {54},
	number = {4},
	doi = {10.1145/3447242},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109211061&doi=10.1145%2f3447242&partnerID=40&md5=1988805ab7837498e424f409987b2505},
	affiliations = {University of Manchester, Kilburn Building, Manchester, United Kingdom},
	abstract = {Ambient Intelligence (AmI) is the application and embedding of artificial intelligence into everyday environments to seamlessly provide assistive and predictive support in a multitude of scenarios via an invisible user interface. These can be as diverse as autonomous vehicles, smart homes, industrial settings, and healthcare facilities - referred to as Ambient Assistive Living. This survey gives an overview of the field; defines key terms; discusses social, cultural, and ethical issues; and outlines the state of the art in AmI technology, and where opportunities for further research exist. We guide the reader through AmI from its inception more than 20 years ago, focussing on the important topics and research achievements of the past 10 years since the last major survey, before finally detailing the most recents research trends and forecasting where this technology is likely to develop. This survey covers domains, use cases, scenarios, and datasets; cultural concerns and usability issues; security, privacy, and ethics; interaction and recognition; prediction and intelligence; and hardware, infrastructure, and mobile devices. This survey serves as an introduction for researchers and the technical layperson into the topic of AmI and identifies notable opportunities for further research.  © 2021 ACM.},
	author_keywords = {Human-computer interaction; Machine learning; Smart environments},
	keywords = {Artificial intelligence; Automation; Intelligent buildings; Iodine compounds; mHealth; Philosophical aspects; Surveys; User interfaces; Assistive living; Ethical issues; Healthcare facility; Industrial settings; Research achievements; Research trends; Smart homes; State of the art; Ambient intelligence},
	publisher = {Association for Computing Machinery},
	issn = {03600300},
	coden = {ACSUE},
	language = {English},
	abbrev_source_title = {ACM Comput Surv},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@CONFERENCE{Perrier2021843,
	author = {Perrier, Elija},
	title = {Quantum Fair Machine Learning},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {843 – 853},
	doi = {10.1145/3461702.3462611},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112412921&doi=10.1145%2f3461702.3462611&partnerID=40&md5=065f79a457021b97f327ed1721dfdf87},
	affiliations = {University of Technology, Sydney and Australian National University, Sydney, NSW, Australia},
	abstract = {In this paper, we inaugurate the field of quantum fair machine learning. We undertake a comparative analysis of differences and similarities between classical and quantum fair machine learning algorithms, specifying how the unique features of quantum computation alter measures, metrics and remediation strategies when quantum algorithms are subject to fairness constraints. We present the first results in quantum fair machine learning by demonstrating the use of Grover's search algorithm to satisfy statistical parity constraints imposed on quantum algorithms. We provide lower-bounds on iterations needed to achieve such statistical parity within ϵ-tolerance. We extend canonical Lipschitz-conditioned individual fairness criteria to the quantum setting using quantum metrics. We examine the consequences for typical measures of fairness in machine learning context when quantum information processing and quantum data are involved. Finally, we propose open questions and research programmes for this new field of interest to researchers in computer science, ethics and quantum computation. © 2021 ACM.},
	author_keywords = {fair; learning; machine; quantum},
	keywords = {Data handling; Machine learning; Philosophical aspects; Quantum computers; Quantum theory; Comparative analysis; Fairness constraints; Fairness criteria; Grover's search algorithm; Quantum algorithms; Quantum-information processing; Remediation strategies; Research programmes; Learning algorithms},
	correspondence_address = {E. Perrier; University of Technology, Sydney and Australian National University, Sydney, Australia; email: elija.t.perrier@student.uts.edu.au},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685; All Open Access, Green Open Access}
}

@ARTICLE{Donia2021,
	author = {Donia, Joseph and Shaw, James A.},
	title = {Co-design and ethical artificial intelligence for health: An agenda for critical research and practice},
	year = {2021},
	journal = {Big Data and Society},
	volume = {8},
	number = {2},
	doi = {10.1177/20539517211065248},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121725410&doi=10.1177%2f20539517211065248&partnerID=40&md5=0479d6e29814798fc80f88c8869a5d37},
	affiliations = {Institute of Health Policy, Management Evaluation, Dalla Lana School of Public Health, University of Toronto, Toronto, ON, Canada; Joint Centre for Bioethics, Dalla Lana School of Public Health, University of Toronto, Toronto, ON, Canada; Institute for Health System Solutions and Virtual Care, Women's College Hospital, Toronto, ON, Canada},
	abstract = {Applications of artificial intelligence/machine learning (AI/ML) in health care are dynamic and rapidly growing. One strategy for anticipating and addressing ethical challenges related to AI/ML for health care is patient and public involvement in the design of those technologies – often referred to as ‘co-design’. Co-design has a diverse intellectual and practical history, however, and has been conceptualized in many different ways. Moreover, AI/ML introduces challenges to co-design that are often underappreciated. Informed by perspectives from critical data studies and critical digital health studies, we review the research literature on involvement in health care, and involvement in design, and examine the extent to which co-design as commonly conceptualized is capable of addressing the range of normative issues raised by AI/ML for health care. We suggest that AI/ML technologies have amplified and modified existing challenges related to patient and public involvement, and created entirely new challenges. We outline three pitfalls associated with co-design for ethical AI/ML for health care and conclude with suggestions for addressing these practical and conceptual challenges. © The Author(s) 2021.},
	author_keywords = {artificial intelligence; Co-design; data ethics; design ethics; health care; participatory design},
	correspondence_address = {J. Donia; Institute of Health Policy, Management Evaluation, Dalla Lana School of Public Health, University of Toronto, Toronto, Canada; email: joseph.donia@mail.utoronto.ca},
	publisher = {SAGE Publications Ltd},
	issn = {20539517},
	language = {English},
	abbrev_source_title = {Big Data  Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access}
}

@ARTICLE{Nichol2021,
	author = {Nichol, Ariadne A and Bendavid, Eran and Mutenherwa, Farirai and Patel, Chirag and Cho, Mildred K},
	title = {Diverse experts' perspectives on ethical issues of using machine learning to predict HIV/AIDS risk in sub-Saharan Africa: A modified Delphi study},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {7},
	doi = {10.1136/bmjopen-2021-052287},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111657318&doi=10.1136%2fbmjopen-2021-052287&partnerID=40&md5=0353e3822dd60b26eef9160ea33b010a},
	affiliations = {Center for Biomedical Ethics, Stanford University, School of Medicine, Stanford, CA, United States; Department of Primary Care and Population Health, Stanford University, School of Medicine, Stanford, CA, United States; College of Health Sciences, University of KwaZulu-Natal, Durban, South Africa; School of Applied Human Sciences, University of KwaZulu-Natal, Pietermaritzburg, South Africa; Department of Biomedical Informatics, Harvard Medical School, Boston, MA, United States},
	abstract = {Objective To better understand diverse experts' views about the ethical implications of ongoing research funded by the National Institutes of Health that uses machine learning to predict HIV/AIDS risk in sub-Saharan Africa (SSA) based on publicly available Demographic and Health Surveys data. Design Three rounds of semi-structured surveys in an online expert panel using a modified Delphi approach. Participants Experts in informatics, African public health and HIV/AIDS and bioethics were invited to participate. Measures Perceived importance of or agreement about relevance of ethical issues on 5-point unipolar Likert scales. Qualitative data analysis identified emergent themes related to ethical issues and development of an ethical framework and recommendations for open-ended questions. Results Of the 35 invited experts, 22 participated in the online expert panel (63%). Emergent themes were the inclusion of African researchers in all aspects of study design, analysis and dissemination to identify and address local contextual issues, as well as engagement of communities. Experts focused on engagement with health and science professionals to address risks, benefits and communication of findings. Respondents prioritised the mitigation of stigma to research participants but recognised trade-offs between privacy and the need to disseminate findings to realise public health benefits. Strategies for responsible communication of results were suggested, including careful word choice in presentation of results and limited dissemination to need-to-know stakeholders such as public health planners. Conclusion Experts identified ethical issues specific to the African context and to research on sensitive, publicly available data and strategies for addressing these issues. These findings can be used to inform an ethical implementation framework with research stage-specific recommendations on how to use publicly available data for machine learning-based predictive analytics to predict HIV/AIDS risk in SSA.  © Authors 2021},
	author_keywords = {ethics (see medical ethics); health informatics; medical ethics; public health},
	keywords = {Acquired Immunodeficiency Syndrome; Africa South of the Sahara; Delphi Technique; Ethics, Research; Humans; Machine Learning; acquired immune deficiency syndrome; Africa south of the Sahara; Delphi study; human; machine learning; research ethics},
	correspondence_address = {A.A. Nichol; Center for Biomedical Ethics, Stanford University, School of Medicine, Stanford, United States; email: ariadnen@stanford.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34321310},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Milosevic202158,
	author = {Milosevic, Zoran},
	title = {On computable expressions of policies for digital health: Use for privacy consent},
	year = {2021},
	journal = {Studies in Health Technology and Informatics},
	volume = {276},
	pages = {58 – 64},
	doi = {10.3233/SHTI210011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105509518&doi=10.3233%2fSHTI210011&partnerID=40&md5=ab17e9c7298f096f820c1da9f744137c},
	affiliations = {Deontik, Australia},
	abstract = {This paper proposes a formal model for expressing policies in digital health. The aim is to support computable expressions of legislative, regulative and organizational policies. The model is grounded in the semantics of deontic logic [1] and in modelling concepts for expressing accountability, specified in the new RM-ODP Enterprise Language standard [2]. An example of privacy consent based on the FHIR consent resource [3] is used to explain the use of these modelling concepts. The example involves multiple stakeholders and illustrates the complexity associated with the use of machine learning and artificial intelligence systems as part of healthcare delivery governed by informed consent policies.  © 2021 The authors and IOS Press.},
	author_keywords = {artificial intelligence; consent; ethics; FHIR; policy; privacy},
	keywords = {Artificial intelligence; Modeling languages; Semantics; Artificial intelligence systems; Deontic Logic; Formal model; Healthcare delivery; Language standards; Multiple stakeholders; Organizational policies; artificial intelligence; conference paper; health care delivery; human; human experiment; informed consent; language; logic; machine learning; organizational policy; privacy; semantics; Health},
	correspondence_address = {Z. Milosevic; Deontik, Australia; email: zoran@deontik.com},
	editor = {Merolli M. and Bain C. and Schaper L.K.},
	publisher = {IOS Press BV},
	issn = {09269630},
	isbn = {978-164368168-9},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Digital Health Institute Summit 2020; Conference date: 20 November 2020; Conference code: 168550; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kim2021979,
	author = {Kim, Jinseok and Kim, Jenna and Owen-Smith, Jason},
	title = {Ethnicity-based name partitioning for author name disambiguation using supervised machine learning},
	year = {2021},
	journal = {Journal of the Association for Information Science and Technology},
	volume = {72},
	number = {8},
	pages = {979 – 994},
	doi = {10.1002/asi.24459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101234924&doi=10.1002%2fasi.24459&partnerID=40&md5=5b3e288004b26bf4c56dcb4efdba6cdb},
	affiliations = {Institute for Research on Innovation & Science, Survey Research Center, Institute for Social Research, University of Michigan, Ann Arbor, MI, United States; School of Information Sciences, University of Illinois at Urbana – Champaign, Champaign, IL, United States; Department of Sociology, Institute for Social Research, University of Michigan, Ann Arbor, MI, United States},
	abstract = {In several author name disambiguation studies, some ethnic name groups such as East Asian names are reported to be more difficult to disambiguate than others. This implies that disambiguation approaches might be improved if ethnic name groups are distinguished before disambiguation. We explore the potential of ethnic name partitioning by comparing performance of four machine learning algorithms trained and tested on the entire data or specifically on individual name groups. Results show that ethnicity-based name partitioning can substantially improve disambiguation performance because the individual models are better suited for their respective name group. The improvements occur across all ethnic name groups with different magnitudes. Performance gains in predicting matched name pairs outweigh losses in predicting nonmatched pairs. Feature (e.g., coauthor name) similarities of name pairs vary across ethnic name groups. Such differences may enable the development of ethnicity-specific feature weights to improve prediction for specific ethic name categories. These findings are observed for three labeled data with a natural distribution of problem sizes as well as one in which all ethnic name groups are controlled for the same sizes of ambiguous names. This study is expected to motive scholars to group author names based on ethnicity prior to disambiguation. © 2021 The Authors. Journal of the Association for Information Science and Technology published by Wiley Periodicals LLC on behalf of Association for Information Science and Technology.},
	keywords = {Forecasting; Learning systems; Supervised learning; Author name disambiguations; Feature weight; Individual models; Natural distribution; Performance Gain; Problem size; Supervised machine learning; algorithm; article; ethnicity; human; prediction; supervised machine learning; Learning algorithms},
	correspondence_address = {J. Kim; Institute for Research on Innovation & Science, Survey Research Center, Institute for Social Research, University of Michigan, Ann Arbor, United States; email: jinseokk@umich.edu},
	publisher = {John Wiley and Sons Inc},
	issn = {23301635},
	language = {English},
	abbrev_source_title = {J. Assoc. Soc. Inf. Sci. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@ARTICLE{Rahimi2021,
	author = {Rahimi, Samira Abbasgholizadeh and Légaré, France and Sharma, Gauri and Archambault, Patrick and Zomahoun, Herve Tchala Vignon and Chandavong, Sam and Rheault, Nathalie and Wong, Sabrina T. and Langlois, Lyse and Couturier, Yves and Salmeron, Jose L. and Gagnon, Marie-Pierre and Légaré, Jean},
	title = {Application of artificial intelligence in community-based primary health care: Systematic scoping review and critical appraisal},
	year = {2021},
	journal = {Journal of Medical Internet Research},
	volume = {23},
	number = {9},
	doi = {10.2196/29839},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114315142&doi=10.2196%2f29839&partnerID=40&md5=c8ce60f8fec3c4350e70aa5c7c92b18a},
	affiliations = {Department of Family Medicine, Faculty of Medicine and Health Sciences, McGill University, Montreal, QC, Canada; Mila-Quebec AI Institute, Montreal, QC, Canada; Department of Family Medicine and Emergency Medicine, Université Laval, Quebec City, QC, Canada; VITAM - Centre de recherche en santé durable, Université Laval, Quebec City, QC, Canada; Faculty of Engineering, Dayalbagh Educational Institute, Agra, India; Quebec SPOR-Support Unit, Quebec City, QC, Canada; Faculty of Science and Engineering, Université Laval, Quebec City, QC, Canada; School of Nursing, University of British Columbia, Vancouver, BC, Canada; Center for Health Services and Policy Research, University of British Columbia, Vancouver, BC, Canada; Department of Industrial Relations, Université Laval, Quebec City, QC, Canada; OBVIA - Quebec International Observatory on the social impacts of AI and digital technology, Quebec City, QC, Canada; School of Social Work, University of Sherbrooke, Sherbrooke, QC, Canada; Department of Data Science, University Pablo de Olavide, Seville, Spain; Faculty of Nursing, Université Laval, Quebec City, QC, Canada; Arthritis Alliance of Canada, Montreal, QC, Canada},
	abstract = {Background: Research on the integration of artificial intelligence (AI) into community-based primary health care (CBPHC) has highlighted several advantages and disadvantages in practice regarding, for example, facilitating diagnosis and disease management, as well as doubts concerning the unintended harmful effects of this integration. However, there is a lack of evidence about a comprehensive knowledge synthesis that could shed light on AI systems tested or implemented in CBPHC. Objective: We intended to identify and evaluate published studies that have tested or implemented AI in CBPHC settings. Methods: We conducted a systematic scoping review informed by an earlier study and the Joanna Briggs Institute (JBI) scoping review framework and reported the findings according to PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analysis-Scoping Reviews) reporting guidelines. An information specialist performed a comprehensive search from the date of inception until February 2020, in seven bibliographic databases: Cochrane Library, MEDLINE, EMBASE, Web of Science, Cumulative Index to Nursing and Allied Health Literature (CINAHL), ScienceDirect, and IEEE Xplore. The selected studies considered all populations who provide and receive care in CBPHC settings, AI interventions that had been implemented, tested, or both, and assessed outcomes related to patients, health care providers, or CBPHC systems. Risk of bias was assessed using the Prediction Model Risk of Bias Assessment Tool (PROBAST). Two authors independently screened the titles and abstracts of the identified records, read the selected full texts, and extracted data from the included studies using a validated extraction form. Disagreements were resolved by consensus, and if this was not possible, the opinion of a third reviewer was sought. A third reviewer also validated all the extracted data. Results: We retrieved 22,113 documents. After the removal of duplicates, 16,870 documents were screened, and 90 peer-reviewed publications met our inclusion criteria. Machine learning (ML) (41/90, 45%), natural language processing (NLP) (24/90, 27%), and expert systems (17/90, 19%) were the most commonly studied AI interventions. These were primarily implemented for diagnosis, detection, or surveillance purposes. Neural networks (ie, convolutional neural networks and abductive networks) demonstrated the highest accuracy, considering the given database for the given clinical task. The risk of bias in diagnosis or prognosis studies was the lowest in the participant category (4/49, 4%) and the highest in the outcome category (22/49, 45%). Conclusions: We observed variabilities in reporting the participants, types of AI methods, analyses, and outcomes, and highlighted the large gap in the effective development and implementation of AI in CBPHC. Further studies are needed to efficiently guide the development and implementation of AI interventions in CBPHC settings. © 2021 Journal of Medical Internet Research. All rights reserved.},
	author_keywords = {Artificial intelligence; Community-based primary health care; Machine learning; Systematic scoping review},
	keywords = {Artificial Intelligence; Community Health Services; Delivery of Health Care; Health Personnel; Humans; Primary Health Care; adult; age; artificial intelligence; clinical practice; community care; convolutional neural network; economics; ethics; ethnicity; gender; health care personnel; human; legal aspect; medical research; primary health care; Review; systematic review; community care; health care delivery},
	correspondence_address = {S.A. Rahimi; Department of Family Medicine, Faculty of Medicine and Health Sciences, McGill University, Montreal, 5858 Côte-des-Neiges Road, Canada; email: samira.rahimi@mcgill.ca},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {34477556},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Izumi2021,
	author = {Izumi, Keisuke and Minato, Kazumichi and Shiga, Kiko and Sugio, Tatsuki and Hanashiro, Sayaka and Cortright, Kelley and Kudo, Shun and Fujita, Takanori and Sado, Mitsuhiro and Maeno, Takashi and Takebayashi, Toru and Mimura, Masaru and Kishimoto, Taishiro},
	title = {Unobtrusive Sensing Technology for Quantifying Stress and Well-Being Using Pulse, Speech, Body Motion, and Electrodermal Data in a Workplace Setting: Study Concept and Design},
	year = {2021},
	journal = {Frontiers in Psychiatry},
	volume = {12},
	doi = {10.3389/fpsyt.2021.611243},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105918181&doi=10.3389%2ffpsyt.2021.611243&partnerID=40&md5=6b1eee4e40d6c3c891670398f2f1ed77},
	affiliations = {Division of Rheumatology, Department of Internal Medicine, Keio University School of Medicine, Tokyo, Japan; National Hospital Organization Tokyo Medical Center, Tokyo, Japan; Medical AI Center, Keio University, Tokyo, Japan; Department of Neuropsychiatry, Keio University School of Medicine, Tokyo, Japan; Department of Health Policy and Management, Keio University School of Medicine, Tokyo, Japan; World Economic Forum Centre for the Fourth Industrial Revolution Japan, Tokyo, Japan; Center for Stress Research, Keio University, Tokyo, Japan; Human System Design Laboratory, Graduate School of System Design and Management, Keio University, Tokyo, Japan; Department of Preventive Medicine and Public Health, Keio University School of Medicine, Tokyo, Japan; Department of Psychiatry, Donald and Barbara Zucker School of Medicine, New York, NY, United States},
	abstract = {Introduction: Mental disorders are a leading cause of disability worldwide. Depression has a significant impact in the field of occupational health because it is particularly prevalent during working age. On the other hand, there are a growing number of studies on the relationship between “well-being” and employee productivity. To promote healthy and productive workplaces, this study aims to develop a technique to quantify stress and well-being in a way that does not disturb the workplace. Methods and analysis: This is a single-arm prospective observational study. The target population is adult (>20 years old) workers at companies that often engage in desk work; specifically, a person who sits in front of a computer for at least half their work hours. The following data will be collected: (a) participants' background characteristics; (b) participants' biological data during the 4-week observation period using sensing devices such as a camera built into the computer (pulse wave data extracted from the facial video images), a microphone built into their work computer (voice data), and a wristband-type wearable device (electrodermal activity data, body motion data, and body temperature); (c) stress, well-being, and depression rating scale assessment data. The analysis workflow is as follows: (1) primary analysis, comprised of using software to digitalize participants' vital information; (2) secondary analysis, comprised of examining the relationship between the quantified vital data from (1), stress, well-being, and depression; (3) tertiary analysis, comprised of generating machine learning algorithms to estimate stress, well-being, and degree of depression in relation to each set of vital data as well as multimodal vital data. Discussion: This study will evaluate digital phenotype regarding stress and well-being of white-collar workers over a 4-week period using persistently obtainable biomarkers such as heart rate, acoustic characteristics, body motion, and electrodermal activity. Eventually, this study will lead to the development of a machine learning algorithm to determine people's optimal levels of stress and well-being. Ethics and dissemination: Collected data and study results will be disseminated widely through conference presentations, journal publications, and/or mass media. The summarized results of our overall analysis will be supplied to participants. Registration: UMIN000036814 © Copyright © 2021 Izumi, Minato, Shiga, Sugio, Hanashiro, Cortright, Kudo, Fujita, Sado, Maeno, Takebayashi, Mimura and Kishimoto.},
	author_keywords = {adult psychiatry; depression; mental health; occupational & industrial medicine; protocols; stress; wearabe sensors; well-being},
	keywords = {adult; Article; body movement; controlled study; depression; depression rating scale assessment; electrodermal response; human; Likert scale; limit of quantitation; observational study; phenotype; physiological stress; population research; prospective study; psychological rating scale; pulse wave; sample size; self report; speech; wellbeing; working time; workplace},
	correspondence_address = {T. Kishimoto; Medical AI Center, Keio University, Tokyo, Japan; email: taishiro-k@mti.biglobe.ne.jp},
	publisher = {Frontiers Media S.A.},
	issn = {16640640},
	language = {English},
	abbrev_source_title = {Front. Psychiatry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kenny2021486,
	author = {Kenny, Lizbeth M and Nevin, Mark and Fitzpatrick, Kirsten},
	title = {Ethics and standards in the use of artificial intelligence in medicine on behalf of the Royal Australian and New Zealand College of Radiologists},
	year = {2021},
	journal = {Journal of Medical Imaging and Radiation Oncology},
	volume = {65},
	number = {5},
	pages = {486 – 494},
	doi = {10.1111/1754-9485.13289},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111905427&doi=10.1111%2f1754-9485.13289&partnerID=40&md5=a046f3457043de0577b1707ada67820d},
	affiliations = {Royal Brisbane and Women’s Hospital, Herston, QLD, Australia; School of Medicine, University of Queensland, Herston, QLD, Australia; Royal Australian and New Zealand College of Radiologists, Sydney, NSW, Australia},
	abstract = {Introduction: The Royal Australian and New Zealand College of Radiologists (RANZCR) led the medical community in Australia and New Zealand in considering the impact of machine learning and artificial intelligence (AI) in health care. RANZCR identified that medical leadership was largely absent from these discussions, with a notable absence of activity from governments in the Australasian region up to 2019. The clinical radiology and radiation oncology sectors were considered ripe for the adoption of AI, and this raised a range of concerns about how to ensure the ethical application of AI and to guide its safe and appropriate use in our two specialties. Methods: RANZCR’s Artificial Intelligence Committee undertook a landscape review in 2019 anddetermined that AI within clinical radiology and radiation oncology had the potential to grow rapidly and significantly impact the professions. In order to address this, RANZCR drafted ethical principles on the use of AI and standards to guide deployment and engaged in extensive stakeholder consultation to ensure a range of perspectives were received and considered. Results: RANZCR published two key bodies of work: The Ethical Principles of Artificial Intelligence in Medicine, and the Standards of Practice for Artificial Intelligence in Clinical Radiology. Conclusion: RANZCR’s publications in this area have established a solid foundation to prepare for the application of AI, however more work is needed. We will continue to assess the evolution of AI and ML within our professions, strive to guide the upskilling of clinical radiologists and radiation oncologists, advocate for appropriate regulation and produce guidance to ensure that patient care is delivered safely. © 2021 The Authors. Journal of Medical Imaging and Radiation Oncology published by John Wiley & Sons Australia, Ltd on behalf of Royal Australian and New Zealand College of Radiologists},
	author_keywords = {artificial intelligence; clinical radiology; ethics; machine learning; radiation oncology},
	keywords = {Artificial Intelligence; Australia; Humans; New Zealand; Radiologists; Radiology; adult; article; artificial intelligence; ethics; human; machine learning; New Zealand; occupation; patient care; radiation oncologist; radiation oncology; radiologist; radiology; Australia; New Zealand; radiologist},
	correspondence_address = {K. Fitzpatrick; Royal Australian and New Zealand College of Radiologists, Sydney, Australia; email: kirsten.fitzpatrick@ranzcr.edu.au},
	publisher = {John Wiley and Sons Inc},
	issn = {17549477},
	pmid = {34342139},
	language = {English},
	abbrev_source_title = {J. Med. Imaging Radiat. Oncol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Weng2021,
	author = {Weng, Juyang},
	title = {A Developmental Method that Computes Optimal Networks without Post-Selections},
	year = {2021},
	journal = {IEEE International Conference on Development and Learning, ICDL 2021},
	doi = {10.1109/ICDL49984.2021.9515610},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114553592&doi=10.1109%2fICDL49984.2021.9515610&partnerID=40&md5=2c705ded5a0115d91c48f4263e71c222},
	affiliations = {Michigan State University, Department of Computer Science and Engineering, East Lansing, 48824, MI, United States; Michigan State University, Cognitive Science Program, East Lansing, 48824, MI, United States; Michigan State University, Neuroscience Program, East Lansing, 48824, MI, United States; GENISAMA LLC, Okemos, 48864, MI, United States},
	abstract = {This work is the theory of Post-Selection practices that have been rarely studied. Post-Selections mean selections of systems after the systems have been trained. Post-Selections Using Validation Sets (PSUVS) are wasteful and Post-Selections Using Test Sets (PSUTS) are wasteful and unethical. Both result in systems whose generalization powers are weak. The PSUTS fall into two kinds, machine PSUTS and human PSUTS. The connectionist AI school received criticisms for its 'scruffiness' due to a huge number of network parameters and now the machine PSUTS; but the seemingly 'clean' symbolic AI school seems more brittle because of its human PSUTS. This paper analyzes why, in deep learning, error-backprop methods with random initial weights suffer from severe local minima, why PSUTS violates well-established research ethics, and publications that used PSUTS should have transparently reported PSUTS. This paper proposes a Developmental Methodology that trains only a single but optimal network for each application lifetime using a new standard for performance evaluation in machine learning, called developmental errors for all networks trained in a project that the selection of the luckiest network depends on, along with Three Learning Conditions: (1) framework restrictions, (2) training experience and (3) computational resources. This paper also discusses how the brain-inspired Developmental Networks (DNs) avoid PSUTS by reporting developmental errors and its maximum likelihood (ML) optimality under the Three Learning Conditions. DNs are not 'scruffy' because they are ML-estimators of the observed Emergent Turing Machines at each time during their 'lives'. This implies best performance given a limited amount of overall available computational resources for a project.  © 2021 IEEE.},
	keywords = {Backpropagation; Deep learning; Errors; Internet protocols; Maximum likelihood; Turing machines; Computational resources; Initial weights; Local minimums; Network parameters; Optimal networks; Research ethics; Training experiences; Validation sets; Learning systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816242-3},
	language = {English},
	abbrev_source_title = {IEEE Int. Conf. Dev. Learn., ICDL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2021 IEEE International Conference on Development and Learning, ICDL 2021; Conference date: 23 August 2021 through 26 August 2021; Conference code: 171395}
}

@ARTICLE{Cordeiro2021,
	author = {Cordeiro, João V.},
	title = {Digital Technologies and Data Science as Health Enablers: An Outline of Appealing Promises and Compelling Ethical, Legal, and Social Challenges},
	year = {2021},
	journal = {Frontiers in Medicine},
	volume = {8},
	doi = {10.3389/fmed.2021.647897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111052272&doi=10.3389%2ffmed.2021.647897&partnerID=40&md5=98c71c7839b9cf82c6019aefa388184a},
	affiliations = {Public Health Research Centre, NOVA National School of Public Health, Universidade NOVA de Lisboa, Lisboa, Portugal; Comprehensive Health Research Center, Universidade NOVA de Lisboa, Lisboa, Portugal; Centro Interdisciplinar de Ciências Sociais, Lisboa, Portugal},
	abstract = {Digital technologies and data science have laid down the promise to revolutionize healthcare by transforming the way health and disease are analyzed and managed in the future. Digital health applications in healthcare include telemedicine, electronic health records, wearable, implantable, injectable and ingestible digital medical devices, health mobile apps as well as the application of artificial intelligence and machine learning algorithms to medical and public health prognosis and decision-making. As is often the case with technological advancement, progress in digital health raises compelling ethical, legal, and social implications (ELSI). This article aims to succinctly map relevant ELSI of the digital health field. The issues of patient autonomy; assessment, value attribution, and validation of health innovation; equity and trustworthiness in healthcare; professional roles and skills and data protection and security are highlighted against the backdrop of the risks of dehumanization of care, the limitations of machine learning-based decision-making and, ultimately, the future contours of human interaction in medicine and public health. The running theme to this article is the underlying tension between the promises of digital health and its many challenges, which is heightened by the contrasting pace of scientific progress and the timed responses provided by law and ethics. Digital applications can prove to be valuable allies for human skills in medicine and public health. Similarly, ethics and the law can be interpreted and perceived as more than obstacles, but also promoters of fairness, inclusiveness, creativity and innovation in health. © Copyright © 2021 Cordeiro.},
	author_keywords = {artificial intelligence; big data; digital health; ethics; law; patient–doctor relationship; telemedicine},
	keywords = {algorithm bias; artificial intelligence; clinical assessment; computer security; confidentiality; creativity; data privacy; data protection; data science; decision making; dehumanization; digital technology; doctor patient relationship; health care need; health care quality; health data; health equity; human; information security; informed consent; law; legal aspect; machine learning; medical ethics; patient autonomy; patient participation; professional competence; public health; Review; skill; social aspect; telemedicine},
	correspondence_address = {J.V. Cordeiro; Public Health Research Centre, NOVA National School of Public Health, Universidade NOVA de Lisboa, Lisboa, Portugal; email: joao.cordeiro@ensp.unl.pt},
	publisher = {Frontiers Media S.A.},
	issn = {2296858X},
	language = {English},
	abbrev_source_title = {Front. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Collins2021,
	author = {Collins, Gary S and Dhiman, Paula and Andaur Navarro, Constanza L and Ma, Ji and Hooft, Lotty and Reitsma, Johannes B and Logullo, Patricia and Beam, Andrew L and Peng, Lily and Van Calster, Ben and van Smeden, Maarten and Riley, Richard D and Moons, Karel GM},
	title = {Protocol for development of a reporting guideline (TRIPOD-AI) and risk of bias tool (PROBAST-AI) for diagnostic and prognostic prediction model studies based on artificial intelligence},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {7},
	doi = {10.1136/bmjopen-2020-048008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109968495&doi=10.1136%2fbmjopen-2020-048008&partnerID=40&md5=43c8dfa2b478f1fb954de8833f2f3cb7},
	affiliations = {Centre for Statistics in Medicine, Nuffield Department of Orthopaedics, Rheumatology & Musculoskeletal Sciences, University of Oxford, Oxford, United Kingdom; NIHR Oxford Biomedical Research Centre, John Radcliffe Hospital, NIHR Oxford Biomedical Research Centre, Oxford, United Kingdom; Julius Center for Health Sciences and Primary Care, Utrecht, Utrecht, Netherlands; Cochrane Netherlands, Julius Center for Health Sciences and Primary Care, Utrecht, Utrecht, Netherlands; Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, MA, United States; Department of Biomedical Informatics, Harvard Medical School, Boston, MA, United States; Google Health, Google, Palo Alto, CA, United States; Department of Development and Regeneration, KU Leuven, Leuven, Belgium; Department of Biomedical Data Sciences, Leiden University Medical Centre, Leiden, Netherlands; EPI-Centre, KU Leuven, Leuven, Belgium; Centre for Prognosis Research, School of Medicine, Keele University, Keele, United Kingdom},
	abstract = {The Transparent Reporting of a multivariable prediction model of Individual Prognosis Or Diagnosis (TRIPOD) statement and the Prediction model Risk Of Bias ASsessment Tool (PROBAST) were both published to improve the reporting and critical appraisal of prediction model studies for diagnosis and prognosis. This paper describes the processes and methods that will be used to develop an extension to the TRIPOD statement (TRIPOD-artificial intelligence, AI) and the PROBAST (PROBAST-AI) tool for prediction model studies that applied machine learning techniques. TRIPOD-AI and PROBAST-AI will be developed following published guidance from the EQUATOR Network, and will comprise five stages. Stage 1 will comprise two systematic reviews (across all medical fields and specifically in oncology) to examine the quality of reporting in published machine-learning-based prediction model studies. In stage 2, we will consult a diverse group of key stakeholders using a Delphi process to identify items to be considered for inclusion in TRIPOD-AI and PROBAST-AI. Stage 3 will be virtual consensus meetings to consolidate and prioritise key items to be included in TRIPOD-AI and PROBAST-AI. Stage 4 will involve developing the TRIPOD-AI checklist and the PROBAST-AI tool, and writing the accompanying explanation and elaboration papers. In the final stage, stage 5, we will disseminate TRIPOD-AI and PROBAST-AI via journals, conferences, blogs, websites (including TRIPOD, PROBAST and EQUATOR Network) and social media. TRIPOD-AI will provide researchers working on prediction model studies based on machine learning with a reporting guideline that can help them report key details that readers need to evaluate the study quality and interpret its findings, potentially reducing research waste. We anticipate PROBAST-AI will help researchers, clinicians, systematic reviewers and policymakers critically appraise the design, conduct and analysis of machine learning based prediction model studies, with a robust standardised tool for bias evaluation. Ethical approval has been granted by the Central University Research Ethics Committee, University of Oxford on 10-December-2020 (R73034/RE001). Findings from this study will be disseminated through peer-review publications. CRD42019140361 and CRD42019161764. © Author(s) (or their employer(s)) 2021. Re-use permitted under CC BY. Published by BMJ.},
	author_keywords = {epidemiology; general medicine (see internal medicine); statistics & research methods},
	keywords = {Artificial Intelligence; Bias; Checklist; Humans; Prognosis; Research Design; Risk Assessment; article; artificial intelligence; blogging; cancer model; checklist; Delphi study; general practice; human; internal medicine; machine learning; peer review; prediction; research ethics; risk assessment; social media; systematic review; writing; checklist; methodology; prognosis; statistical bias},
	correspondence_address = {G.S. Collins; Centre for Statistics in Medicine, Nuffield Department of Orthopaedics, Rheumatology & Musculoskeletal Sciences, University of Oxford, Oxford, United Kingdom; email: gary.collins@csm.ox.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {34244270},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 148; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Leavy2021695,
	author = {Leavy, Susan and Siapera, Eugenia and O'Sullivan, Barry},
	title = {Ethical Data Curation for AI: An Approach based on Feminist Epistemology and Critical Theories of Race},
	year = {2021},
	journal = {AIES 2021 - Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {695 – 703},
	doi = {10.1145/3461702.3462598},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112470601&doi=10.1145%2f3461702.3462598&partnerID=40&md5=8266ca42b4e5b12d608eee99e2f64caf},
	affiliations = {University College Dublin, Dublin, Ireland; University College Cork, Cork, Ireland},
	abstract = {The potential for bias embedded in data to lead to the perpetuation of social injustice though Artificial Intelligence (AI) necessitates an urgent reform of data curation practices for AI systems, especially those based on machine learning. Without appropriate ethical and regulatory frameworks there is a risk that decades of advances in human rights and civil liberties may be undermined. This paper proposes an approach to data curation for AI, grounded in feminist epistemology and informed by critical theories of race and feminist principles. The objective of this approach is to support critical evaluation of the social dynamics of power embedded in data for AI systems. We propose a set of fundamental guiding principles for ethical data curation that address the social construction of knowledge, call for inclusion of subjugated and new forms of knowledge, support critical evaluation of theoretical concepts within data and recognise the reflexive nature of knowledge. In developing this ethical framework for data curation, we aim to contribute to a virtue ethics for AI and ensure protection of fundamental and human rights. © 2021 Owner/Author.},
	author_keywords = {critical theories of race; data curation; ethical ai; feminist theory},
	keywords = {Artificial intelligence; Embedded systems; Philosophical aspects; Social aspects; Civil liberties; Critical evaluation; Feminist epistemology; Guiding principles; Regulatory frameworks; Social constructions; Social dynamics; Virtue ethics; Data curation},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038473-5},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 4th AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society, AIES 2021; Conference date: 19 May 2021 through 21 May 2021; Conference code: 170685; All Open Access, Bronze Open Access}
}

@CONFERENCE{Johnson202118,
	author = {Johnson, Brittany and Smith, Justin},
	title = {Towards Ethical Data-Driven Software: Filling the Gaps in Ethics Research Practice},
	year = {2021},
	journal = {Proceedings - 2021 IEEE/ACM 2nd International Workshop on Ethics in Software Engineering Research and Practice, SEthics 2021},
	pages = {18 – 25},
	doi = {10.1109/SEthics52569.2021.00011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113221684&doi=10.1109%2fSEthics52569.2021.00011&partnerID=40&md5=984d4847db8d9db2eed6fca9a19ec86b},
	affiliations = {George Mason University, Department of Computer Science, United States; Lafayette College, Department of Computer Science, United States},
	abstract = {More and more, data is being used to drive automated decision making through the integration of machine learning technologies into software. With these advances comes new potential for unexpected, undesirable, and possibly dangerous outcomes for end users. This has led to an increased focus on ethics in technology in both research and practice. Much of the work in ethical practices has been centered on ethics in machine learning and little has been validated for effectiveness in practice. In this paper, we outline the existing work in ethical computing with a focus on efforts that are relevant to data-driven software development. Based on existing work, we identify gaps in our understanding of ethical software development practices and suggestions for future work to help close these gaps.  © 2021 IEEE.},
	author_keywords = {data driven; empirical; ethics; literature review; software; software engineering},
	keywords = {Decision making; Digital storage; Engineering research; Machine learning; Software design; Automated decision making; Data driven; End users; Ethical practices; Machine learning technology; Software development practices; Philosophical aspects},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166544555-9},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/ACM Int. Workshop Ethics Softw. Eng. Res. Pract., SEthics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2nd IEEE/ACM International Workshop on Ethics in Software Engineering Research and Practice, SEthics 2021; Conference date: 4 June 2021; Conference code: 170801}
}

@ARTICLE{Ursin2021,
	author = {Ursin, Frank and Timmermann, Cristian and Orzechowski, Marcin and Steger, Florian},
	title = {Diagnosing Diabetic Retinopathy With Artificial Intelligence: What Information Should Be Included to Ensure Ethical Informed Consent?},
	year = {2021},
	journal = {Frontiers in Medicine},
	volume = {8},
	doi = {10.3389/fmed.2021.695217},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111931123&doi=10.3389%2ffmed.2021.695217&partnerID=40&md5=0d8edc442017fc345e2215dee92f1c10},
	affiliations = {Institute of the History, Philosophy and Ethics of Medicine, Ulm University, Ulm, Germany},
	abstract = {Purpose: The method of diagnosing diabetic retinopathy (DR) through artificial intelligence (AI)-based systems has been commercially available since 2018. This introduces new ethical challenges with regard to obtaining informed consent from patients. The purpose of this work is to develop a checklist of items to be disclosed when diagnosing DR with AI systems in a primary care setting. Methods: Two systematic literature searches were conducted in PubMed and Web of Science databases: a narrow search focusing on DR and a broad search on general issues of AI-based diagnosis. An ethics content analysis was conducted inductively to extract two features of included publications: (1) novel information content for AI-aided diagnosis and (2) the ethical justification for its disclosure. Results: The narrow search yielded n = 537 records of which n = 4 met the inclusion criteria. The information process was scarcely addressed for primary care setting. The broad search yielded n = 60 records of which n = 11 were included. In total, eight novel elements were identified to be included in the information process for ethical reasons, all of which stem from the technical specifics of medical AI. Conclusions: Implications for the general practitioner are two-fold: First, doctors need to be better informed about the ethical implications of novel technologies and must understand them to properly inform patients. Second, patient's overconfidence or fears can be countered by communicating the risks, limitations, and potential benefits of diagnostic AI systems. If patients accept and are aware of the limitations of AI-aided diagnosis, they increase their chances of being diagnosed and treated in time. © Copyright © 2021 Ursin, Timmermann, Orzechowski and Steger.},
	author_keywords = {diabetic retinopathy; ethics; information process; informed consent; machine learning},
	keywords = {Article; artificial intelligence; checklist; content analysis; data protection; decision support system; diabetic retinopathy; human; information processing; informed consent; machine learning; medical ethics; medical information; meta analysis; primary medical care; systematic review},
	correspondence_address = {F. Ursin; Institute of the History, Philosophy and Ethics of Medicine, Ulm University, Ulm, Germany; email: frank.ursin@uni-ulm.de},
	publisher = {Frontiers Media S.A.},
	issn = {2296858X},
	language = {English},
	abbrev_source_title = {Front. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Borg20215,
	author = {Borg, Markus and Bronson, Joshua and Christensson, Linus and Olsson, Fredrik and Lennartsson, Olof and Sonnsjo, Elias and Ebabi, Hamid and Karsberg, Martin},
	title = {Exploring the Assessment List for Trustworthy AI in the Context of Advanced Driver-Assistance Systems},
	year = {2021},
	journal = {Proceedings - 2021 IEEE/ACM 2nd International Workshop on Ethics in Software Engineering Research and Practice, SEthics 2021},
	pages = {5 – 12},
	doi = {10.1109/SEthics52569.2021.00009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113233819&doi=10.1109%2fSEthics52569.2021.00009&partnerID=40&md5=381ee8f9de4f0758d6a3d1c57c6e76ff},
	affiliations = {Rise Research Institutes of Sweden, Humanized Autonomy, Lund, Sweden; Lund University, Dept. of Computer Science, Lund, Sweden; Infotiv Ab, Gothenburg, Sweden},
	abstract = {Artificial Intelligence (AI) is increasingly used in critical applications. Thus, the need for dependable AI systems is rapidly growing. In 2018, the European Commission appointed experts to a High-Level Expert Group on AI (AI-HLEG). AI- HLEG defined Trustworthy AI as 1) lawful, 2) ethical, and 3) robust and specified seven corresponding key requirements. To help development organizations, AI-HLEG recently published the Assessment List for Trustworthy AI (ALTAI). We present an illustrative case study from applying ALTAI to an ongoing development project of an Advanced Driver-Assistance System (ADAS) that relies on Machine Learning (ML). Our experience shows that ALTAI is largely applicable to ADAS development, but specific parts related to human agency and transparency can be disregarded. Moreover, bigger questions related to societal and environmental impact cannot be tackled by an ADAS supplier in isolation. We present how we plan to develop the ADAS to ensure ALTAI-compliance. Finally, we provide three recommendations for the next revision of ALTAI, i.e., life-cycle variants, domainspecific adaptations, and removed redundancy.  © 2021 IEEE.},
	author_keywords = {automotive software; ethics; functional safety; machine learning; trustworthy AI},
	keywords = {Artificial intelligence; Automobile drivers; Engineering research; Environmental impact; Life cycle; Philosophical aspects; Software engineering; AI systems; Critical applications; Development project; Domain specific; European Commission; Human agency; On-machines; Advanced driver assistance systems},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166544555-9},
	language = {English},
	abbrev_source_title = {Proc. - IEEE/ACM Int. Workshop Ethics Softw. Eng. Res. Pract., SEthics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2nd IEEE/ACM International Workshop on Ethics in Software Engineering Research and Practice, SEthics 2021; Conference date: 4 June 2021; Conference code: 170801; All Open Access, Green Open Access}
}

@BOOK{Moniz20211,
	author = {Moniz, Alicia and Gordon, Matt and Bergum, Ida and Chang, Mia and Grant, Ginger},
	title = {Beginning Azure Cognitive Services: Data-driven decision making through artificial intelligence},
	year = {2021},
	journal = {Beginning Azure Cognitive Services: Data-Driven Decision Making Through Artificial Intelligence},
	pages = {1 – 306},
	doi = {10.1007/978-1-4842-7176-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146259653&doi=10.1007%2f978-1-4842-7176-6&partnerID=40&md5=f86a05fdf4e70ddaaa5a24dcdfee108c},
	affiliations = {Houston, TX, United States; Lexington, KY, United States; Oslo, Norway; Berlin, Germany; Scottsdale, AZ, United States},
	abstract = {Get started with Azure Cognitive Services and its APIs that expose machine learning as a service. This book introduces the suite of Azure Cognitive Services and helps you take advantage of the proven machine learning algorithms that have been developed by experts and made available through Cognitive Services, easily integrating those algorithms into your own applications without having to develop the algorithms from scratch. The book also shows you how to use the algorithms provided by Cognitive Services to accelerate data analysis and development within your organization. The authors begin by introducing the tools and describing the steps needed to invoke libraries to analyze structured and unstructured text, speech, and pictures, and you will learn to create interactive chatbots using the Cognitive Services libraries. Each chapter contains the information you need to implement artificial intelligence (AI) via Azure Cognitive Services in your personal and professional projects. The book also covers ethical considerations that are becoming increasingly of concern when using AI to drive decision making. You will be introduced to tools such as FairLearn and InterpretML that can help you detect bias and understand the results your models are generating. What You Will Learn • Invoke the Cognitive Services APIs from a variety of languages and apps • Understand common design architectures for AI solutions in Azure • Decrease discrimination and bias when creating an AI-driven solution • Execute the examples within the book and learn how to extend those examples • Implement best practices for leveraging the Vision, Speech, and Language parts of the suite • Test Cognitive Services APIs via the Azure portal and using the Postman API tool • Execute AI from low-code and no-code platforms like Logic Apps and Microsoft's Power Platform Who This Book Is For Technical professionals who are interested in implementing artificial intelligence (AI) in pre-existing apps, expanding their value and skill sets, or learning more about AI for personal projects; for programmers working in languages such as C# and Python; and for those using low- and no-code platforms such as Microsoft Power Platform. © 2021 by Alicia Moniz, Matt Gordon, Ida Bergum, Mia Chang, Ginger Grant. All rights reserved.},
	author_keywords = {Anomaly detection; Artificial Intelligence (AI); Azure data studio; Chatbots; Cognitive search; Cognitive services; Cognitive speech; Cognitive vision; Data science; Differential privacy; Docker desktop client; Document analysis; Ethics; FairLearn; InterpretML; Machine Learning (ML); Pandas; Postman API; Sentiment analysis; TensorFlow},
	publisher = {Apress Media LLC},
	isbn = {978-148427176-6; 978-148427175-9},
	language = {English},
	abbrev_source_title = {Begin. Azur. Cogn. Serv.: Data-Driven Decis. Mak. Through Artif. Intell.},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{James2021954,
	author = {James, Cornelius A. and Wheelock, Kevin M. and Woolliscroft, James O.},
	title = {Machine Learning: The Next Paradigm Shift in Medical Education},
	year = {2021},
	journal = {Academic Medicine},
	volume = {96},
	number = {7},
	pages = {954 – 957},
	doi = {10.1097/ACM.0000000000003943},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109082946&doi=10.1097%2fACM.0000000000003943&partnerID=40&md5=256335e74e5ccdea1eaecdbea1a2a285},
	affiliations = {Departments of Internal Medicine and Pediatrics, University of Michigan, Medical School, Ann Arbor, MI, United States; Yale School of Medicine, New Haven, CT, United States; Departments of Internal Medicine and Learning Health Sciences, Lyle C. Roll Professor of Medicine, University of Michigan, Medical School, Ann Arbor, MI, United States},
	abstract = {Machine learning (ML) algorithms are powerful prediction tools with immense potential in the clinical setting. There are a number of existing clinical tools that use ML, and many more are in development. Physicians are important stakeholders in the health care system, but most are not equipped to make informed decisions regarding deployment and application of ML technologies in patient care. It is of paramount importance that ML concepts are integrated into medical curricula to position physicians to become informed consumers of the emerging tools employing ML. This paradigm shift is similar to the evidence-based medicine (EBM) movement of the 1990s. At that time, EBM was a novel concept; now, EBM is considered an essential component of medical curricula and critical to the provision of high-quality patient care. ML has the potential to have a similar, if not greater, impact on the practice of medicine. As this technology continues its inexorable march forward, educators must continue to evaluate medical curricula to ensure that physicians are trained to be informed stakeholders in the health care of tomorrow. © 2021 Lippincott Williams and Wilkins. All rights reserved.},
	keywords = {Aged; Algorithms; Clinical Decision-Making; Clinical Trials as Topic; COVID-19 Testing; Curriculum; Delivery of Health Care; Diabetic Retinopathy; Diagnostic Imaging; Education, Medical; Evidence-Based Medicine; Female; History, 20th Century; Humans; Liability, Legal; Machine Learning; Male; Physician-Patient Relations; Physicians; Stakeholder Participation; United States; United States Food and Drug Administration; aged; algorithm; clinical decision making; clinical trial (topic); curriculum; devices; diabetic retinopathy; diagnostic imaging; doctor patient relationship; ethics; evidence based medicine; female; Food and Drug Administration; health care delivery; history; human; legal liability; legislation and jurisprudence; machine learning; male; medical education; organization and management; physician; procedures; stakeholder engagement; United States},
	correspondence_address = {C.A. James; Northville, 39901 Traditions Dr., 48168, United States; email: jamesca@med.umich.edu},
	publisher = {Wolters Kluwer Health},
	issn = {10402446},
	coden = {ACMEE},
	pmid = {33496428},
	language = {English},
	abbrev_source_title = {Acad. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; All Open Access, Bronze Open Access}
}

@CONFERENCE{Gorodishcheva2021136,
	author = {Gorodishcheva, Anna N. and Paskhalskaya, Yuliya V. and Gorodishchev, Alexey V. and Vinogradova, Anna I. and Kovalev, Georgiy P.},
	title = {IoT Ethic in Scientific Communications},
	year = {2021},
	journal = {Proceedings of the 2021 Communication Strategies in Digital Society Seminar, ComSDS 2021},
	pages = {136 – 140},
	doi = {10.1109/ComSDS52473.2021.9422860},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106053528&doi=10.1109%2fComSDS52473.2021.9422860&partnerID=40&md5=eaeac6757a00f0b6bf8f00936c0a9ae4},
	affiliations = {Reshetnev Siberian State University of Science and Technology, Krasnoyarsk, Russian Federation; Krasnogvardeyskiy District Centralized Library System, Saint Petersburg, Russian Federation},
	abstract = {IoT is now essential for the resource allocation of organized things and people. Science is one of the social institutions that now need in the Internet of Things technology to develop the interoperability of heterogeneous devices and scientific research services. The system of interactions with IoT technology for professional scientific communities, which have special ethical rules for responding to political, economic, social and cultural challenges of society, deserves special rules. Poor contextual awareness of the scientific community is closely related to the problem of protecting scientific data in IoT networks from bad compatibility and inability to connect to the specified communication channels. The search and analysis of scientific communications by existing IoT services is limited by the design limits of the methodological use of connecting IoT devices. The ethical norms of the scientific community can be seen in IoT technologies as constraints, indicators, characteristics and reinforcements for machine learning and IoT human-machine communications © 2021 IEEE.},
	author_keywords = {Internet of things; IoT; law of priority; scientific communications; scientific ethics},
	keywords = {Interoperability; Philosophical aspects; Reinforcement learning; Design limits; Heterogeneous devices; Human-machine communication; Internet of things technologies; Scientific communication; Scientific community; Scientific data; Scientific researches; Internet of things},
	editor = {Shaposhnikov S. and Saint Petersburg Electrotechnical University "LETI", Prof. Popov Str. 5, Saint Petersburg and Sharakhina L. and Saint Petersburg Electrotechnical University "LETI", Prof. Popov Str. 5,, Saint Petersburg},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-073814529-7},
	language = {English},
	abbrev_source_title = {Proc. Commun. Strateg. Digit. Soc. Semin., ComSDS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 Communication Strategies in Digital Society Seminar, ComSDS 2021; Conference date: 14 April 2021; Conference code: 168784}
}

@ARTICLE{Goldsmith2021,
	author = {Goldsmith, Jeff and Sun, Yifei and Fried, Linda P. and Wing, Jeannette and Miller, Gary W. and Berhane, Kiros},
	title = {The Emergence and Future of Public Health Data Science},
	year = {2021},
	journal = {Public Health Reviews},
	volume = {42},
	doi = {10.3389/phrs.2021.1604023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113222896&doi=10.3389%2fphrs.2021.1604023&partnerID=40&md5=a96d745daa4b72b44e4069583d35503b},
	affiliations = {Department of Biostatistics, Columbia University Mailman School of Public Health, New York, NY, United States; Columbia University Mailman School of Public Health, New York, NY, United States; Data Science Institute, Columbia University, New York, NY, United States; Department of Environmental Health Sciences, Columbia University Mailman School of Public Health, New York, NY, United States},
	abstract = {Data science is a newly‐formed and, as yet, loosely‐defined discipline that has nonetheless emerged as a critical component of successful scientific research. We seek to provide an understanding of the term “data science,” particularly as it relates to public health; to identify ways that data science methods can strengthen public health research; to propose ways to strengthen education for public health data science; and to discuss issues in data science that may benefit from a public health perspective. © Copyright © 2021 Goldsmith, Sun, Fried, Wing, Miller and Berhane.},
	author_keywords = {big data; computational methods; ethics; interdisciplinary science; machine learning; reproducibility},
	keywords = {big data; data science; education; ethics; human; human experiment; machine learning; note; public health; reproducibility},
	correspondence_address = {J. Goldsmith; Department of Biostatistics, Columbia University Mailman School of Public Health, New York, United States; email: ajg2202@cumc.columbia.edu; Y. Sun; Department of Biostatistics, Columbia University Mailman School of Public Health, New York, United States; email: ys3072@cumc.columbia.edu; K. Berhane; Department of Biostatistics, Columbia University Mailman School of Public Health, New York, United States; email: ktb2132@cumc.columbia.edu; L.P. Fried; Columbia University Mailman School of Public Health, New York, United States; email: lpf8787@cumc.columbia.edu; J. Wing; Data Science Institute, Columbia University, New York, United States; email: wing@columbia.edu; G.W. Miller; Department of Environmental Health Sciences, Columbia University Mailman School of Public Health, New York, United States; email: gm2815@cumc.columbia.edu},
	publisher = {Frontiers Media S.A.},
	issn = {03010422},
	coden = {PBHRA},
	language = {English},
	abbrev_source_title = {Public Health Rev.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}@ARTICLE{Buléon20215,
	author = {Buléon, C. and Minehart, R.D.},
	title = {Lessons learned in medical education research: seeing opportunity amidst the challenges},
	year = {2021},
	journal = {International Journal of Obstetric Anesthesia},
	volume = {45},
	pages = {5 – 7},
	doi = {10.1016/j.ijoa.2020.11.008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099501924&doi=10.1016%2fj.ijoa.2020.11.008&partnerID=40&md5=5dcce0fd5070d589d1c2770ea7f8d90e},
	affiliations = {Department of Anaesthesiology, Intensive Care and Perioperative Medicine, Caen Normandy University Hospital, University of Caen Normandy Medical School, Caen, France; Department of Anesthesia, Critical Care and Pain Medicine, Massachusetts General Hospital, Harvard Medical School, Boston, MA, United States},
	keywords = {Biomedical Research; Education, Medical; Humans; anesthesiology; artificial intelligence; clinical competence; clinical research; comparative study; control group; curriculum development; diagnostic reasoning; Editorial; educational theory; evidence based medicine; exercise; financial management; human; learning theory; machine learning; medical education; Medical Education Research Study Quality Instrument; medical ethics; medical school; mentor; methodology; null result; obstetric anesthesia; professional knowledge; publication; publishing; qualitative analysis; skill; statistically significant result; student satisfaction; teacher; teaching; university; World Health Organization; medical research},
	publisher = {Churchill Livingstone},
	issn = {0959289X},
	coden = {IOANE},
	pmid = {33341311},
	language = {English},
	abbrev_source_title = {Int. J. Obstet. Anesth.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{McCradden2021658,
	author = {McCradden, Melissa D. and Patel, Evani and Chad, Lauren},
	title = {The point-of-care use of a facial phenotyping tool in the genetics clinic: An ethics tête-a-tête},
	year = {2021},
	journal = {American Journal of Medical Genetics, Part A},
	volume = {185},
	number = {2},
	pages = {658 – 660},
	doi = {10.1002/ajmg.a.61985},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096748595&doi=10.1002%2fajmg.a.61985&partnerID=40&md5=5a920d618c33d3ee0f1137952e632b87},
	affiliations = {Department of Bioethics, The Hospital for Sick Children, Toronto, ON, Canada; University of Toronto, Toronto, ON, Canada; Division of Clinical and Metabolic Genetics, The Hospital for Sick Children, Toronto, ON, Canada},
	keywords = {Face; Female; Genetic Diseases, Inborn; Genetic Testing; Humans; Male; Phenotype; Point-of-Care Systems; algorithm; facial recognition; genetic disorder; genetic screening; genetics; health care; health care cost; human; image analysis; Letter; machine learning; medical ethics; molecular diagnosis; phenotype; point of care testing; priority journal; face; female; genetic disorder; genetic screening; male; pathology; phenotype; point of care system},
	correspondence_address = {L. Chad; Department of Bioethics, The Hospital for Sick Children, Toronto, Canada; email: lauren.chad@sickkids.ca; L. Chad; University of Toronto, Toronto, Canada; email: lauren.chad@sickkids.ca; L. Chad; Division of Clinical and Metabolic Genetics, The Hospital for Sick Children, Toronto, Canada; email: lauren.chad@sickkids.ca},
	publisher = {John Wiley and Sons Inc},
	issn = {15524825},
	coden = {AJMGD},
	pmid = {33244863},
	language = {English},
	abbrev_source_title = {Am. J. Med. Genet. Part A},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{McGregor2021,
	author = {McGregor, Carolyn and Dewey, Cate and Luan, Rency},
	title = {Big data and artificial intelligence in healthcare: Ethical and social implications of neonatology},
	year = {2021},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2021-October},
	doi = {10.1109/ISTAS52410.2021.9629162},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123203274&doi=10.1109%2fISTAS52410.2021.9629162&partnerID=40&md5=b33760a51663ddcd32837836d2b087dc},
	affiliations = {Ontario Tech University University of Technology Sydney, Research Chair of Artificial Intelligence for Health and Wellness, Two-time Research Chair of Health Informatics, Australia; University of Guelph, Canada; University of Waterloo, Canada},
	abstract = {High-speed physiological data are proving to be one of the most untapped resources in healthcare today. Many medical devices produce data streams at frequencies of a reading a second or faster making the effective use of that data a Big Data challenge. A growing body of research studies are demonstrating common physiological patterns for a range of medical conditions at earlier stages in the condition progression paving the way for new artificial intelligence and machine learning based approaches that could also be more reliable. There is great potential for real-time assessment of this physiological data to improve patient outcomes and to do so on an individualized personalized level. Systemic use of Big Data and AI in Healthcare present many ethics and social implications. This keynote will demonstrate how Big Data and AI can be used systemically for new approaches in research and clinical care for differential diagnosis and condition management. Ethical and social implications will be considered within the context of the application of these approaches in neonatology.  © 2021 IEEE.},
	author_keywords = {AI bias; artificial intelligence; big data; Neonatology; sepsis},
	keywords = {Artificial intelligence; Big data; Clinical research; Diagnosis; Ethical technology; Physiology; Social aspects; AI bias; Data challenges; Data stream; Ethical implications; High Speed; Medical Devices; Neonatology; Physiological data; Sepsis; Social implication; Health care},
	editor = {Caron B. and Schmitt K.A. and Pearl Z. and Dara R. and Love H.A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166543580-2},
	language = {English},
	abbrev_source_title = {Int Symp Technol Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 IEEE International Symposium on Society and Technology, ISTAS 2021; Conference date: 28 October 2021 through 31 October 2021; Conference code: 175401}
}

@ARTICLE{Thapa2021,
	author = {Thapa, Chandra and Camtepe, Seyit},
	title = {Precision health data: Requirements, challenges and existing techniques for data security and privacy},
	year = {2021},
	journal = {Computers in Biology and Medicine},
	volume = {129},
	doi = {10.1016/j.compbiomed.2020.104130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097345823&doi=10.1016%2fj.compbiomed.2020.104130&partnerID=40&md5=19e6683e1237fba5a761eb494e046e79},
	affiliations = {CSIRO Data61, Sydney, 2122, NSW, Australia},
	abstract = {Precision health leverages information from various sources, including omics, lifestyle, environment, social media, medical records, and medical insurance claims to enable personalized care, prevent and predict illness, and precise treatments. It extensively uses sensing technologies (e.g., electronic health monitoring devices), computations (e.g., machine learning), and communication (e.g., interaction between the health data centers). As health data contain sensitive private information, including the identity of patient and carer and medical conditions of the patient, proper care is required at all times. Leakage of these private information affects the personal life, including bullying, high insurance premium, and loss of job due to the medical history. Thus, the security, privacy of and trust on the information are of utmost importance. Moreover, government legislation and ethics committees demand the security and privacy of healthcare data. Besides, the public, who is the data source, always expects the security, privacy, and trust of their data. Otherwise, they can avoid contributing their data to the precision health system. Consequently, as the public is the targeted beneficiary of the system, the effectiveness of precision health diminishes. Herein, in the light of precision health data security, privacy, ethical and regulatory requirements, finding the best methods and techniques for the utilization of the health data, and thus precision health is essential. In this regard, firstly, this paper explores the regulations, ethical guidelines around the world, and domain-specific needs. Then it presents the requirements and investigates the associated challenges. Secondly, this paper investigates secure and privacy-preserving machine learning methods suitable for the computation of precision health data along with their usage in relevant health projects. Finally, it illustrates the best available techniques for precision health data security and privacy with a conceptual system model that enables compliance, ethics clearance, consent management, medical innovations, and developments in the health domain. © 2020 Elsevier Ltd},
	author_keywords = {Artificial intelligence; Ethical guidelines; Legal requirements; Precision health; Privacy; Security},
	keywords = {Computer Security; Confidentiality; Humans; Precision Medicine; Privacy; Health; Insurance; Laws and legislation; Machine learning; Philosophical aspects; Privacy by design; Best available techniques; Consent managements; Data security and privacy; Government legislations; Machine learning methods; Private information; Regulatory requirements; Security and privacy; adult; artificial intelligence; bullying; computer security; government; health insurance; human; law; lifestyle; machine learning; medical history; medical record; practice guideline; privacy; professional standard; review; social media; trust; computer security; confidentiality; personalized medicine; Information management},
	correspondence_address = {C. Thapa; CSIRO Data61, Sydney, 2122, Australia; email: chandra.thapa@data61.csiro.au},
	publisher = {Elsevier Ltd},
	issn = {00104825},
	coden = {CBMDA},
	pmid = {33271399},
	language = {English},
	abbrev_source_title = {Comput. Biol. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45; All Open Access, Green Open Access}
}

@CONFERENCE{Kasirzadeh2021228,
	author = {Kasirzadeh, Atoosa and Smart, Andrew},
	title = {The use and misuse of counterfactuals in ethical machine learning},
	year = {2021},
	journal = {FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages = {228 – 236},
	doi = {10.1145/3442188.3445886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102653066&doi=10.1145%2f3442188.3445886&partnerID=40&md5=5550bfd46bd897a9fc3b98a3f7a2a099},
	affiliations = {University of Toronto, Australian National University, Australia; Google},
	abstract = {The use of counterfactuals for considerations of algorithmic fairness and explainability is gaining prominence within the machine learning community and industry. This paper argues for more caution with the use of counterfactuals when the facts to be considered are social categories such as race or gender. We review a broad body of papers from philosophy and social sciences on social ontology and the semantics of counterfactuals, and we conclude that the counterfactual approach in machine learning fairness and social explainability can require an incoherent theory of what social categories are. Our findings suggest that most often the social categories may not admit counterfactual manipulation, and hence may not appropriately satisfy the demands for evaluating the truth or falsity of counterfactuals. This is important because the widespread use of counterfactuals in machine learning can lead to misleading results when applied in high-stakes domains. Accordingly, we argue that even though counterfactuals play an essential part in some causal inferences, their use for questions of algorithmic fairness and social explanations can create more problems than they resolve. Our positive result is a set of tenets about using counterfactuals for fairness and explanations in machine learning. © 2021 ACM.},
	author_keywords = {Algorithmic Fairness; Counterfactuals; Ethical AI; Ethics of AI; Explainable AI; Explanation; Fairness; Machine learning; Philosophy; Philosophy of AI; Social category; Social kind; Social ontology},
	keywords = {Ontology; Semantics; Transparency; Causal inferences; Counterfactuals; Machine learning communities; Social categories; Social ontology; Machine learning},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038309-7},
	language = {English},
	abbrev_source_title = {FAccT - Proc. ACM Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; Conference name: 4th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2021; Conference date: 3 March 2021 through 10 March 2021; Conference code: 167464; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Capriglione2021189,
	author = {Capriglione, Francesco},
	title = {LAW AND ECONOMICS. THE CHALLENGE OF ARTIFICIAL INTELLIGENCE},
	year = {2021},
	journal = {Law and Economics Yearly Review},
	volume = {10},
	pages = {189 – 219},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147888492&partnerID=40&md5=7e35276fc1be9214ae4cbc178680bf4b},
	abstract = {In the aftermath of the systemic turbulence caused by the pandemic crisis there is a need to rethink the ways on how law, economics and politics interact in view of the realization of changes of the current legal market order. In this context, the use of technology becomes an essential tool for economic recovery in a post-pandemic, while at the same time it highlights the problem to link the economic effects to ethics. The technological improvement has developed the so-called machine learning which aims to recognise the similarities through algorithms; these are considered the common instruments that resolve the day-to-day problems. However, the deployment of technology raises doubts about the internal procedures to produce outcomes. Therefore, the mechanics of artificial intelligence (AI) does not go beyond neutral data processing that converges towards the objective of an adequate information disclosure; hence the impossibility for AI to activate the relationship between mind, as an organizational form of consciousness, and the brain as a physical structure, relation that characterize the human activity. Hence the consequence to exclude the possibility of thinking to a mechanistic procedure that executes a computer programme, although it would not be able to create the 'right software' to develop a ‘mind’ © 2021 Fondazione Gerardo Capriglione Onlus. All rights reserved.},
	publisher = {Fondazione Gerardo Capriglione Onlus},
	issn = {20509014},
	language = {English},
	abbrev_source_title = {Law Econ. Yrly. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Scola2021378,
	author = {Scola, Leila},
	title = {Artificial Intelligence Against Climate Change},
	year = {2021},
	journal = {Intelligent Computing - Proceedings of the 2021 Computing Conference},
	pages = {378 – 397},
	doi = {10.1007/978-3-030-80126-7_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130743373&doi=10.1007%2f978-3-030-80126-7_29&partnerID=40&md5=3190bfff769ed70b6573d75933b9bd86},
	affiliations = {School of Engineering, Santa Clara University, Santa Clara, United States},
	abstract = {The industrial, transportation, and residential sectors draw the most energy in the United States. With most energy created by burning fossil fuels, a highly inefficient method of energy creation, global greenhouse gas levels are rising, raising the temperature of the earth, causing natural processes to become unbalanced. The health of the earth is declining. The rise of technology and persisting growth of computing devices known as the Internet of Things (IoT) and increasing automation of systems through Artificial Intelligence (AI) and Machine Learning (ML) is a factor of energy expenditure as more humans desire devices and more systems are built. The ethical implications of utilizing new technology should be evaluated before creating more. This paper explores modern computing systems in the sectors that draw the most energy, and, more specifically, the role AI and IoT play in them. Each sector may become more energy efficient, productive, and safer by introducing edge computing through IoT devices and coupling it with AI computing abilities that already automate most processes. Multiple studies show energy consumption and costs are lowered when edge computing is paired with the IoT and AI. There is less human involvement, more regularity in execution and performance, and more widespread use because of the accessibility. This creates safer, cheaper, energy-efficient systems that utilize existing technology. The ethical implications of these systems are much more positive than what already exists. Coupling the power of AI with the IoT will reduce energy expenditure in modern systems and create a more sustainable world. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021},
	author_keywords = {Artificial Intelligence; Edge computing; Energy efficiency; Ethics; Fog computing; Internet of Things; Machine learning; Sustainability},
	keywords = {Climate change; Edge computing; Energy utilization; Ethical technology; Fog computing; Fossil fuels; Green computing; Greenhouse gases; Internet of things; Machine learning; Computing devices; Edge computing; Energy; Energy expenditure; Ethical implications; Greenhouse gas levels; Industrial sector; Natural process; Residential sectors; Transportation sector; Energy efficiency},
	editor = {Arai A.},
	publisher = {Springer Nature},
	isbn = {978-303080125-0},
	language = {English},
	abbrev_source_title = {Intell. Comput. - Proc. Comput. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Computing Conference 2021; Conference date: 15 July 2021 through 16 July 2021; Conference code: 179175}
}

@ARTICLE{Rosen2021,
	author = {Rosen, Tony and Bao, Yuhua and Zhang, Yiye and Clark, Sunday and Wen, Katherine and Elman, Alyssa and Jeng, Philip and Bloemen, Elizabeth and Lindberg, Daniel and Krugman, Richard and Campbell, Jacquelyn and Bachman, Ronet and Fulmer, Terry and Pillemer, Karl and Lachs, Mark},
	title = {Identifying patterns of health care utilisation among physical elder abuse victims using Medicare data and legally adjudicated cases: Protocol for case-control study using data linkage and machine learning},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {2},
	doi = {10.1136/bmjopen-2020-044768},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100645655&doi=10.1136%2fbmjopen-2020-044768&partnerID=40&md5=7952d9046b8d0b4f14f17038da4c213e},
	affiliations = {Department of Emergency Medicine, Weill Cornell Medicine/NewYork-Presbyterian Hospital, New York, NY, United States; Department of Health Policy and Research, Weill Cornell Medical College, New York, NY, United States; Department of Policy Analysis and Management, Cornell University, Ithaca, NY, United States; Department of Internal Medicine, University of Colorado School of Medicine, Aurora, CO, United States; The Kempe Center for the Prevention and Treatment of Child Abuse and Neglect, University of Colorado School of Medicine, Aurora, CO, United States; John Hopkins University School of Nursing, John Hopkins University, Baltimore, MD, United States; Department of Criminology, University of Delaware, Newark, DE, United States; John A Hartford Foundation, New York, NY, United States; Division of Geriatrics and Palliative Care, Weill Cornell Medicine/NewYork-Presbyterian Hospital, New York, NY, United States},
	abstract = {Introduction Physical elder abuse is common and has serious health consequences but is under-recognised and under-reported. As assessment by healthcare providers may represent the only contact outside family for many older adults, clinicians have a unique opportunity to identify suspected abuse and initiate intervention. Preliminary research suggests elder abuse victims may have different patterns of healthcare utilisation than other older adults, with increased rates of emergency department use, hospitalisation and nursing home placement. Little is known, however, about the patterns of this increased utilisation and associated costs. To help fill this gap, we describe here the protocol for a study exploring patterns of healthcare utilisation and associated costs for known physical elder abuse victims compared with non-victims. Methods and analysis We hypothesise that various aspects of healthcare utilisation are differentially affected by physical elder abuse victimisation, increasing ED/hospital utilisation and reducing outpatient/primary care utilisation. We will obtain Medicare claims data for a series of well-characterised, legally adjudicated cases of physical elder abuse to examine victims' healthcare utilisation before and after the date of abuse detection. We will also compare these physical elder abuse victims to a matched comparison group of non-victimised older adults using Medicare claims. We will use machine learning approaches to extend our ability to identify patterns suggestive of potential physical elder abuse exposure. Describing unique patterns and associated costs of healthcare utilisation among elder abuse victims may improve the ability of healthcare providers to identify and, ultimately, intervene and prevent victimisation. Ethics and dissemination This project has been reviewed and approved by the Weill Cornell Medicine Institutional Review Board, protocol #1807019417, with initial approval on 1 August 2018. We aim to disseminate our results in peer-reviewed journals at national and international conferences and among interested patient groups and the public.  © },
	author_keywords = {geriatric medicine; health economics; protocols & guidelines},
	keywords = {Aged; Case-Control Studies; Child; Elder Abuse; Humans; Information Storage and Retrieval; Machine Learning; Medicare; Patient Acceptance of Health Care; United States; aged; article; case control study; controlled study; elder abuse; female; geriatrics; health care personnel; health care utilization; hospital utilization; human; institutional review; machine learning; male; medicare; outpatient; practice guideline; primary medical care; victim; case control study; child; information retrieval; machine learning; medicare; patient attitude; United States},
	correspondence_address = {T. Rosen; Department of Emergency Medicine, Weill Cornell Medicine/NewYork-Presbyterian Hospital, New York, United States; email: aer2006@med.cornell.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33550264},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Rana2021315,
	author = {Rana, Aakanksha and W. Goedmakers, Caroline M. and Smith, Timothy R.},
	title = {Artificial Intelligence and Healthcare Ethics},
	year = {2021},
	journal = {Traumatic Brain Injury: Science, Practice, Evidence and Ethics},
	pages = {315 – 326},
	doi = {10.1007/978-3-030-78075-3_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160176528&doi=10.1007%2f978-3-030-78075-3_31&partnerID=40&md5=4a0ad858aed4e97bf50ba417af01f8b3},
	affiliations = {Department of Neurosurgery, Brigham and Women’s Hospital, Harvard Medical School, Boston, MA, United States; Department of Neurosurgery, Leiden University Medical Center, Leiden, Netherlands},
	abstract = {There is massive potential for healthcare to benefit from the two largest technological innovations of the twenty-first century: big data and artificial intelligence (AI). Backed by machine learning algorithms, AI has opened multitudinous opportunities of knowledge generation from big data. Machine learning, a fundamental driver of current-generation AI, feeds on big data to improve its performance and identify underlying patterns to accomplish predefined goals. With an explosion of healthcare data ranging from basic science, clinical, numerical, language-based, and imaging data to vast amounts of administrative and economic data, artificially intelligent computer programs are well positioned to harvest, manage, analyze, and interpret this data to optimize healthcare delivery. In fact, there are some tasks already, in which machines might outperform clinicians. © Springer Nature Switzerland AG 2021.},
	author_keywords = {Artificial intelligence; Big data; Machine learning; Traumatic brain injury},
	correspondence_address = {T.R. Smith; Department of Neurosurgery, Brigham and Women’s Hospital, Harvard Medical School, Boston, United States; email: trsmith@bwh.harvard.edu},
	publisher = {Springer International Publishing},
	isbn = {978-303078075-3; 978-303078074-6},
	language = {English},
	abbrev_source_title = {Trauma. Brain Injury: Science, Practice, Evid. and Ethics},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ajunwa2021389,
	author = {Ajunwa, Ifeoma and Amrute, Sareeta and Irani, Lilly and Poster, Winifred R. and Stalcup, Meg},
	title = {Tech firms need Black AI scholars and labour rights},
	year = {2021},
	journal = {Nature},
	volume = {590},
	number = {7846},
	pages = {389},
	doi = {10.1038/d41586-021-00407-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101470490&doi=10.1038%2fd41586-021-00407-2&partnerID=40&md5=e78cf11b94beb98e71a83a8aa28d2523},
	author_keywords = {Ethics; Machine learning},
	keywords = {African Americans; Artificial Intelligence; Humans; Machine Learning; artificial intelligence; Black person; cultural diversity; ethics; human; Letter; racism; trade union; workers rights; African American; machine learning},
	publisher = {Nature Research},
	issn = {00280836},
	coden = {NATUA},
	pmid = {33580231},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Besinovic2021,
	author = {Besinovic, Nikola and De Donato, Lorenzo and Flammini, Francesco and Goverde, Rob M. P. and Lin, Zhiyuan and Liu, Ronghui and Marrone, Stefano and Nardone, Roberto and Tang, Tianli and Vittorini, Valeria},
	title = {Artificial Intelligence in Railway Transport: Taxonomy, Regulations and Applications},
	year = {2021},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	doi = {10.1109/TITS.2021.3131637},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121815705&doi=10.1109%2fTITS.2021.3131637&partnerID=40&md5=de16915a3790aa6d8350626f443a7903},
	affiliations = {Department of Transport and Planning, Delft University of Technology, 2600GA Delft, The Netherlands.; Department of Electrical Engineering and Information Technology, University of Naples Federico II, 80125 Naples, Italy.; School of Innovation, Design and Engineering, M&#x00E4;lardalen University, 72220 V&#x00E4;ster&#x00E5;s, Sweden, and also with the Department of Computer Science and Media Technology, Linnaeus University, 35195 Vaxjo, Sweden.; Institute for Transport Studies, University of Leeds, Leeds LS2 9JT, U.K. (e-mail: z.lin@leeds.ac.uk); Institute for Transport Studies, University of Leeds, Leeds LS2 9JT, U.K..; Department of Engineering, University of Naples ``Parthenope,'' 80143 Naples, Italy.; Jiangsu Key Laboratory of Urban ITS, Jiangsu Province Collaborative Innovation Center of Modern Urban Traffic Technologies, School of Transportation, Southeast University, Nanjing 211189, China.},
	abstract = {Artificial Intelligence (AI) is becoming pervasive in most engineering domains, and railway transport is no exception. However, due to the plethora of different new terms and meanings associated with them, there is a risk that railway practitioners, as several other categories, will get lost in those ambiguities and fuzzy boundaries, and hence fail to catch the real opportunities and potential of machine learning, artificial vision, and big data analytics, just to name a few of the most promising approaches connected to AI. The scope of this paper is to introduce the basic concepts and possible applications of AI to railway academics and practitioners. To that aim, this paper presents a structured taxonomy to guide researchers and practitioners to understand AI techniques, research fields, disciplines, and applications, both in general terms and in close connection with railway applications such as autonomous driving, maintenance, and traffic management. The important aspects of ethics and explainability of AI in railways are also introduced. The connection between AI concepts and railway subdomains has been supported by relevant research addressing existing and planned applications in order to provide some pointers to promising directions. IEEE},
	author_keywords = {Artificial intelligence; Artificial intelligence; computer vision; machine learning; Maintenance engineering; predictive maintenance.; Rail transportation; Rails; railway transport; Safety; Software; Taxonomy; traffic management},
	keywords = {Application programs; Artificial intelligence; Computer vision; Learning systems; Maintenance; Object detection; Railroad transportation; Railroads; Rails; Basic concepts; Engineering domains; Fuzzy boundary; New terms; Predictive maintenance; Predictive maintenance.; Rail transportation; Railway transport; Software; Traffic management; Taxonomies},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15249050},
	language = {English},
	abbrev_source_title = {IEEE Trans. Intell. Transp. Syst.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Jedwabny2021,
	author = {Jedwabny, Martin and Bisquert, Pierre and Croitoru, Madalina},
	title = {Generating preferred plans with ethical features},
	year = {2021},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	volume = {34},
	doi = {10.32473/flairs.v34i1.128492},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131128035&doi=10.32473%2fflairs.v34i1.128492&partnerID=40&md5=0e012b21cd3a9b4f252c7dc9e3fd1644},
	affiliations = {LIRMM, Inria, Univ Montpellier, CNRS, Montpellier, France; IATE, Univ Montpellier, INRAE, Institut Agro, Montpellier, France},
	abstract = {Normative ethics has been shown to help automated planners take ethically aware decisions. However, stateof-the-art planning technologies don’t provide a simple and direct way to support ethical features. Here, we propose a new theoretical framework based on a construct, called ethical rule, that allows to model preferences amongst ethically charged features and capture various ethical theories. We show how the framework can model and combine the strengths of these theories. Then, we demonstrate that classical planning domains extended with ethical rules can be compiled into soft goals in PDDL. © 2021by the authors. All rights reserved.},
	keywords = {Machine learning; Classical planning; Ethical theories; Normative ethics; Planning domains; Simple++; Soft goals; State of the art; Theoretical framework; Philosophical aspects},
	editor = {Antonucci A. and Benferhot S. and Premaratne K.},
	publisher = {Florida OJ},
	issn = {23340754},
	language = {English},
	abbrev_source_title = {Proc. Int. Fla. Artif. Intell. Res. Soc. Conf., FLAIRS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 34th International Florida Artificial Intelligence Research Society Conference, FLAIRS-34 2021; Conference date: 16 May 2021 through 19 May 2021; Conference code: 277879; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@BOOK{Garson20211,
	author = {Garson, G. David},
	title = {Data Analytics for the Social Sciences: Applications in R},
	year = {2021},
	journal = {Data Analytics for the Social Sciences: Applications in R},
	pages = {1 – 686},
	doi = {10.4324/9781003109396},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130246336&doi=10.4324%2f9781003109396&partnerID=40&md5=88d8ca29e943a638ae4ef04505d0dfae},
	affiliations = {School of Public and International Affairs, North Carolina State University, United States},
	abstract = {Data Analytics for the Social Sciences is an introductory, graduate-level treatment of data analytics for social science. It features applications in the R language, arguably the fastest growing and leading statistical tool for researchers. The book starts with an ethics chapter on the uses and potential abuses of data analytics. Chapters 2 and 3 show how to implement a broad range of statistical procedures in R. Chapters 4 and 5 deal with regression and classification trees and with random forests. Chapter 6 deals with machine learning models and the "caret" package, which makes available to the researcher hundreds of models. Chapter 7 deals with neural network analysis, and Chapter 8 deals with network analysis and visualization of network data. A final chapter treats text analysis, including web scraping, comparative word frequency tables, word clouds, word maps, sentiment analysis, topic analysis, and more. All empirical chapters have two "Quick Start" exercises designed to allow quick immersion in chapter topics, followed by "In Depth" coverage. Data are available for all examples and runnable R code is provided in a "Command Summary". An appendix provides an extended tutorial on R and RStudio. Almost 30 online supplements provide information for the complete book, "books within the book" on a variety of topics, such as agent-based modeling. Rather than focusing on equations, derivations, and proofs, this book emphasizes hands-on obtaining of output for various social science models and how to interpret the output. It is suitable for all advanced level undergraduate and graduate students learning statistical data analysis. © 2022 G. David Garson.},
	publisher = {Taylor and Francis},
	isbn = {978-100046708-6; 978-036762429-3},
	language = {English},
	abbrev_source_title = {Data Analytics for the Soc. Sciences: Applications in R},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{2021,
	title = {Conference Proceedings: 2021 Ethics and Explainability for Responsible Data Science, EE-RDS 2021},
	year = {2021},
	journal = {Conference Proceedings: 2021 Ethics and Explainability for Responsible Data Science, EE-RDS 2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125926896&partnerID=40&md5=6101256c597817e524f25452ee25d16e},
	abstract = {The proceedings contain 11 papers. The topics discussed include: a review of gender bias mitigation in credit scoring models; explainable machine learning: a manuscript on the customer churn in the telecommunications industry; nano version control and the repo as the next data structure in computer science and artificial intelligence; ensemble deep learning method for COVID-19 detection via chest x-rays; classifying chest x-ray COVID-19 images via transfer learning; classification network of covid-19 based on multi-modality fusion network; detection of COVID-19 from chest x-ray images: a deep learning approach; and PRNet: progressive resolution based network for radiograph based disease classification.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166548358-2},
	language = {English},
	abbrev_source_title = {Conf. Proc.: Ethics Explain. Responsible Data Sci., EE-RDS},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 Ethics and Explainability for Responsible Data Science Conference, EE-RDS 2021; Conference date: 27 October 2021 through 28 October 2021; Conference code: 177335}
}

@ARTICLE{Doorn2021,
	author = {Doorn, Neelke},
	title = {Artificial intelligence in the water domain: Opportunities for responsible use},
	year = {2021},
	journal = {Science of the Total Environment},
	volume = {755},
	doi = {10.1016/j.scitotenv.2020.142561},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092215418&doi=10.1016%2fj.scitotenv.2020.142561&partnerID=40&md5=0fd11ae0e00811a29e4409abe7e39ccb},
	affiliations = {Delft University of Technology, School of Technology, Policy and Management, Department of Values, Technology and Innovation, PO Box 5015, Delft, 2600 GA, Netherlands},
	abstract = {Recent years have seen a rise of techniques based on artificial intelligence (AI). With that have also come initiatives for guidance on how to develop “responsible AI” aligned with human and ethical values. Compared to sectors like energy, healthcare, or transportation, the use of AI-based techniques in the water domain is relatively modest. This paper presents a review of current AI applications in the water domain and develops some tentative insights as to what “responsible AI” could mean there. Building on the reviewed literature, four categories of application are identified: modeling, prediction and forecasting, decision support and operational management, and optimization. We also identify three insights pertaining to the water sector in particular: the use of AI techniques in general, and many-objective optimization in particular, that allow for a pluralism of values and changing values; the use of theory-guided data science, which can avoid some of the pitfalls of strictly data-driven models; and the ability to build on experiences with participatory decision-making in the water sector. These insights suggest that the development and application of responsible AI techniques for the water sector should not be left to data scientists alone, but requires concerted effort by water professionals and data scientists working together, complemented with expertise from the social sciences and humanities. © 2020 The Author},
	author_keywords = {Artificial intelligence; Data science; Ethics; Many-objective optimization; Responsible AI; Water domain},
	keywords = {Artificial Intelligence; Forecasting; Humans; Water; Data Science; Decision making; Decision support systems; Decision theory; bromide; trihalomethane; water; AI applications; Data-driven model; Decision supports; Development and applications; Many-objective optimizations; Operational management; Prediction and forecasting; Water professionals; artificial intelligence; decision support system; ethics; forecasting method; modeling; optimization; planning method; prediction; technology adoption; water industry; Article; artificial intelligence; concentration (parameter); data science; decision making; decision support system; digitalization; environmental parameters; ethics; machine learning; many objective optimization; non maleficence; organization; predictive value; priority journal; privacy; process optimization; responsible use; snow water equivalent; social behavior; social responsibility; society; sociology; transparency; value pluralism; water sector; forecasting; human; Artificial intelligence},
	publisher = {Elsevier B.V.},
	issn = {00489697},
	coden = {STEVA},
	pmid = {33039891},
	language = {English},
	abbrev_source_title = {Sci. Total Environ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Forsyth2021,
	author = {Forsyth, Stacey and Dalton, Bridget and Foster, Ellie Haberl and Walsh, Benjamin and Smilack, Jacqueline and Yeh, Tom},
	title = {Imagine a More Ethical AI: Using Stories to Develop Teens' Awareness and Understanding of Artificial Intelligence and its Societal Impacts},
	year = {2021},
	journal = {2021 Research on Equity and Sustained Participation in Engineering, Computing, and Technology, RESPECT 2021 - Conference Proceedings},
	doi = {10.1109/RESPECT51740.2021.9620549},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123604810&doi=10.1109%2fRESPECT51740.2021.9620549&partnerID=40&md5=58630c5b79e68aee6b98c73a66db7b67},
	affiliations = {University of Colorado Boulder, CU Science Discovery, Boulder, CO, United States},
	abstract = {Artificial intelligence (AI) tools and technologies are increasingly prevalent in society. Many teens interact with AI devices on a daily basis but often have a limited understanding of how AI works, as well as how it impacts society more broadly. It is critical to develop youths' understanding of AI, cultivate ethical awareness, and support diverse youth in pursuing computer science to help ensure future development of more equitable AI technologies. Here, we share our experiences developing and remotely facilitating an interdisciplinary AI ethics program for secondary students designed to increase teens' awareness and understanding of AI and its societal impacts. Students discussed stories with embedded ethical dilemmas, engaged with AI media and simulations, and created digital products to express their stance on an AI ethics issue. Across four iterations in formal and informal settings, we found students to be engaged in AI stories and invested in learning about AI and its societal impacts. Short stories were effective in raising awareness, focusing discussion and supporting students in developing a more nuanced understanding of AI ethics issues, such as fairness, bias and privacy. © 2021 IEEE.},
	author_keywords = {artificial intelligence (AI); ethics; machine learning},
	keywords = {Economic and social effects; Ethical technology; Machine learning; Artificial intelligence; Artificial intelligence technologies; Artificial intelligence tools; Digital products; Ethical awareness; Ethical dilemma; Ethics issues; IT impact; Societal impacts; Tools and technologies; Students},
	editor = {Gardner-McCune C. and Grady S.D. and Jimenez Y. and Ryoo J.J. and Santo R. and Payton J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166544905-2},
	language = {English},
	abbrev_source_title = {Res. Equity Sustain. Particip. Eng., Comput., Technol., RESPECT - Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2021 Research on Equity and Sustained Participation in Engineering, Computing, and Technology, RESPECT 2021; Conference date: 23 May 2021 through 27 May 2021; Conference code: 175130}
}

@CONFERENCE{Peng2021537,
	author = {Peng, Shiya and Liu, Chang and Deng, Yayue and Yu, Dong},
	title = {Morality Between the Lines: Research on Identification of Chinese Moral Sentence; [字里行间的道德：中文文本道德句识别研究]},
	year = {2021},
	journal = {CCL 2021 - Proceedings of the 20th Chinese National Conference on Computational Linguistics},
	pages = {537 – 548},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123436116&partnerID=40&md5=546a4cd124e0e904858f180e0ebbd947},
	affiliations = {Beijing Language, Culture University},
	abstract = {With the development of Artificial Intelligence, AI ethics has captured a great deal of public attention. Automatic moral recognition, as an important task in textual morality study, has attracted a lot of interest of NLP researchers in recent years. This task aims to identify fragments of text that involves morality, which is of great significance to moral-related downstream NLP tasks, such as model bias recognition and elimination. Compared with English, the study on textual moral identification for Chinese is slow, a main reason is that there is no large Chinese moral dataset to support research. Aiming to tackle these issues, we proposed a moral sentence labeling work in Chinese, and conducted a pilot study on the Chinese moral sentence recognition task. In this paper, we first constructed Chinese MOral Sentence dataset (CMOS) which consists of over 100k sentences with moral labels. Then we proposed to carry out the identification task using multiple popular machine learning methods. And we also further explored the identification task with knowledge-aided method. © 2021 China National Conference on Computational Linguistics Published under Creative Commons Attribution 4.0 International License},
	author_keywords = {Artificial intelligence ethics; Text morality},
	keywords = {Artificial intelligence; Character recognition; Computational linguistics; Large dataset; Natural language processing systems; Philosophical aspects; Artificial intelligence ethic; Down-stream; Labelings; Machine learning methods; Model bias; Pilot studies; Sentence recognition; Text morality; Learning systems},
	correspondence_address = {D. Yu; Beijing Language, Culture University; email: yudong_blcu@126.com},
	editor = {Li S. and Sun M. and Liu Y. and Wu H. and Liu K. and Che W. and He S. and Rao G.},
	publisher = {Chinese National Conference on Computational Linguistic (CCL)},
	language = {Chinese},
	abbrev_source_title = {CCL - Proc. Chin. Natl. Conf. Comput. Linguist.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th Chinese National Conference on Computational Linguistics, CCL 2021; Conference date: 13 August 2021 through 15 August 2021; Conference code: 175250}
}

@CONFERENCE{Wilchek20211574,
	author = {Wilchek, Matthew and Wang, Yingjie},
	title = {Synthetic Differential Privacy Data Generation for Revealing Bias Modelling Risks},
	year = {2021},
	journal = {19th IEEE International Symposium on Parallel and Distributed Processing with Applications, 11th IEEE International Conference on Big Data and Cloud Computing, 14th IEEE International Conference on Social Computing and Networking and 11th IEEE International Conference on Sustainable Computing and Communications, ISPA/BDCloud/SocialCom/SustainCom 2021},
	pages = {1574 – 1580},
	doi = {10.1109/ISPA-BDCloud-SocialCom-SustainCom52081.2021.00211},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124139538&doi=10.1109%2fISPA-BDCloud-SocialCom-SustainCom52081.2021.00211&partnerID=40&md5=f345b30898ab88152b4d7d5175c550a0},
	affiliations = {Washington University, M. S. Data Science George, Washington, DC, United States; Georgetown University, M. S. Data Science and Analytics, Washington, DC, United States},
	abstract = {Personally identifiable information (PII) continues to be used in predictive modeling by academic researchers and industry organizations. Most notably, the healthcare industry has been a popular testbed for innovative approaches from academia and institutions to address research using PII in predictive applications and synthetic data generation. The majority of these approaches that generate synthetic PII are based on actual data or obfuscating real data parts. Privacy leakage and ethical disclosure results continue to be among the largest issues that are difficult to avoid in synthetic PII generation techniques. In this analysis, we propose a novel method to generate synthetic, differential privacy data while avoiding the common pitfalls and capable of being leveraged broadly. Evidence is also shown that proves how our novel approach can maintain inference for modeling and potential risks tied to PII features. We conclude with a summarization of our findings and results and a short discussion on how using PII data may impact organizations interested in developing predictive applications. © 2021 IEEE.},
	author_keywords = {Anonymity; Data Ethics; Disclosure; Machine Learning; Privacy; Synthetic Data},
	keywords = {Ethical technology; Machine learning; Risk assessment; Anonymity; Data ethic; Data generation; Differential privacies; Disclosure; Machine-learning; Modeling risk; Personally identifiable information; Privacy; Synthetic data; Data privacy},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166543574-1},
	language = {English},
	abbrev_source_title = {IEEE Int. Symp. Parallel Distrib. Process. Appl., IEEE Int. Conf. Big Data Cloud Comput., IEEE Int. Conf. Soc. Comput. Netw. IEEE Int. Conf. Sustain. Comput. Commun., ISPA/BDCloud/SocialCom/SustainCom},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 19th IEEE International Symposium on Parallel and Distributed Processing with Applications, 11th IEEE International Conference on Big Data and Cloud Computing, 14th IEEE International Conference on Social Computing and Networking and 11th IEEE International Conference on Sustainable Computing and Communications, ISPA/BDCloud/SocialCom/SustainCom 2021; Conference date: 30 September 2021 through 3 October 2021; Conference code: 175747}
}

@CONFERENCE{Russell202146,
	author = {Russell, Jesse},
	title = {Algorithmic Fairness in Applied Machine Learning Contexts},
	year = {2021},
	journal = {ACM International Conference Proceeding Series},
	pages = {46 – 53},
	doi = {10.1145/3456529.3456537},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112404706&doi=10.1145%2f3456529.3456537&partnerID=40&md5=2cbb4ee544eade9de9a4211b96a450f3},
	affiliations = {United States},
	abstract = {Fairness is a common standard in machine learning principles, ethics declarations, and best practices statements. Fairness, though, does not have a singular definition in machine learning. One common theme among fairness concepts is equal treatment by a machine learning model across groups. In some cases, it might be more fair for the machine learning model to produce different predictions or classifications for each group in concordance with differences in their outcome rates. Equal treatment might be an appropriate standard of fairness in some circumstances but not in others. Codes of ethics and standards for machine learning offer many different suggestions about how machine learning ought to be fair. Not only is there a diversity of fairness concepts, but standards also often offer little or no guidance on how these fairness axioms should guide the real-world practice of developing and deploying machine learning models in applied settings. The context in which machine learning is applied may determine which aspects of fairness are expected or upheld. Machine learning to shape, for example, (a) consumer loan approval or rates, (b) job recommendations, (c) text translations, (d) credit decisions, and (e) justice decisions might all impel different conceptions of machine learning fairness. Going beyond an expectation of "equal treatment", machine learning in each of these areas might think about fairness differently.  © 2021 ACM.},
	author_keywords = {applied computing; bias; codes of ethics; fairness; human computer interaction; Machine learning},
	keywords = {Data handling; Information analysis; Philosophical aspects; Turing machines; Applied machine learning; Best practices; Common standards; Ethics and standards; Machine learning models; Real-world practice; Machine learning},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038911-2},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 5th International Conference on Compute and Data Analysis, ICCDA 2021; Conference date: 2 February 2021 through 4 February 2021; Conference code: 170193}
}

@ARTICLE{Martinez-Martin2021e115,
	author = {Martinez-Martin, Nicole and Luo, Zelun and Kaushal, Amit and Adeli, Ehsan and Haque, Albert and Kelly, Sara S and Wieten, Sarah and Cho, Mildred K and Magnus, David and Fei-Fei, Li and Schulman, Kevin and Milstein, Arnold},
	title = {Ethical issues in using ambient intelligence in health-care settings},
	year = {2021},
	journal = {The Lancet Digital Health},
	volume = {3},
	number = {2},
	pages = {e115 – e123},
	doi = {10.1016/S2589-7500(20)30275-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099715522&doi=10.1016%2fS2589-7500%2820%2930275-2&partnerID=40&md5=350d2cf852594df58a8e341f7e6d2899},
	affiliations = {Center for Biomedical Ethics, Stanford University, Stanford, CA, United States; Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, CA, United States; Clinical Excellence Research Center, Department of Medicine, Stanford University, Stanford, CA, United States; Department of Computer Science, Stanford University, Stanford, CA, United States; Department of Bioengineering, Stanford University, Stanford, CA, United States; Stanford Institute for Human-Centered Artificial Intelligence, Stanford University, Stanford, CA, United States},
	abstract = {Ambient intelligence is increasingly finding applications in health-care settings, such as helping to ensure clinician and patient safety by monitoring staff compliance with clinical best practices or relieving staff of burdensome documentation tasks. Ambient intelligence involves using contactless sensors and contact-based wearable devices embedded in health-care settings to collect data (eg, imaging data of physical spaces, audio data, or body temperature), coupled with machine learning algorithms to efficiently and effectively interpret these data. Despite the promise of ambient intelligence to improve quality of care, the continuous collection of large amounts of sensor data in health-care settings presents ethical challenges, particularly in terms of privacy, data management, bias and fairness, and informed consent. Navigating these ethical issues is crucial not only for the success of individual uses, but for acceptance of the field as a whole. © 2021 The Author(s). Published by Elsevier Ltd. This is an Open Access article under the CC BY-NC-ND 4.0 license},
	keywords = {Algorithms; Ambient Intelligence; Bioethical Issues; Data Collection; Data Management; Digital Technology; Documentation; Health Personnel; Humans; Informed Consent; Machine Learning; Patient Care; Patient Safety; Practice Guidelines as Topic; Privacy; Quality of Health Care; Telemedicine; Telemetry; Wearable Electronic Devices; algorithm bias; ambient intelligence; artificial intelligence; clinical decision making; doctor patient relationship; health care; health care quality; human; information processing; informed consent; Internet; legal aspect; machine learning; medical ethics; medical information; privacy; protocol compliance; Review; total quality management; algorithm; bioethics; documentation; electronic device; ethics; health care personnel; patient care; patient safety; practice guideline; procedures; telemedicine; telemetry},
	correspondence_address = {N. Martinez-Martin; Center for Biomedical Ethics, School of Medicine, Stanford University, Stanford, 94305, United States; email: nicolemz@stanford.edu},
	publisher = {Elsevier Ltd},
	issn = {25897500},
	pmid = {33358138},
	language = {English},
	abbrev_source_title = {Lancet Digit. Heal.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Bhandari2021273,
	author = {Bhandari, Sudhir and Shaktawat, Ajit Singh and Tak, Amit and Patel, Bhoopendra and Gupta, Jitentdra and Gupta, Kapil and Kakkar, Shivankan and Shah, Kshitij Darshan and Arora, Ayesha and Dube, Amitabh},
	title = {Independent Role of CT Chest Scan in COVID-19 Prognosis: Evidence From the Machine Learning Classification},
	year = {2021},
	journal = {Scripta Medica (Banja Luka)},
	volume = {52},
	number = {4},
	pages = {273 – 278},
	doi = {10.5937/scriptamed52-34457},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133878539&doi=10.5937%2fscriptamed52-34457&partnerID=40&md5=82ee326f5415ab18f4380dcdcc036574},
	affiliations = {Department of Medicine, SMS Medical College and Hospitals, Rajasthan, Jaipur, India; Department of Physiology, RVRS Medical College and Hospitals, Rajasthan, Bhilwara, India; Department of Physiology, All India Institute of Medical Sciences, Himachal Pradesh, Bilaspur, India; Department of Physiology, SMS Medical College and Hospitals, Rajasthan, Jaipur, India; Department of Pharmacology, SMS Medical College and Hospitals, Rajasthan, Jaipur, India; Arthrocare Hospital, Gujarat, Ahmedabad, India; Chicago School of Professional Psychology, Chicago, IL, United States},
	abstract = {Background: The current coronavirus disease-19 (COVID-19) pandemic call at-tention to the key role informatics play in healthcare. The present study discov-ers an independent role of computerised tomography chest (CT) scans in prognosis of COVID-19 using classification learning algorithms. Methods: In this retrospective study, 57 RT PCR positive COVID-19 patients were enrolled from SMS Medical College, Jaipur (Rajasthan, India) after approv-al from the Institutional Ethics Committee. A set of 21 features including clinical findings and laboratory parameters and chest CT severity score were re-corded. The CT score with mild, moderate and severe categories was chosen as response variable. The dimensionality reduction of feature space was per-formed and classifiers including, decision trees, K-nearest neighbours, support vector machine and ensemble learning were trained with principal compo-nents. The model with highest accuracy and area under the ROC curve (AUC) was selected. Results: The median age of patients was 55 years (range: 20-99 years) with 37 males. The feature space was reduced from 21 to 7 predictors, that included fever, cough, fibrin degradation products, haemoglobin, neutrophil-lymphocyte ratio, ferritin and procalcitonin. The linear support vector machine was chosen as the best classifier with 73.7 % and 0.69 accuracy and AUC for severe CT chest score, respectively. The variance contributed by first three principal compo-nents were 97.5 %, 2.4 % and 0.0 %, respectively. Conclusion: In view of low degree of relationships between predictors and chest CT scan severity score category as interpreted from accuracy and AUC it can be concluded that chest CT scan has an independent role in the prognosis of COVID-19 patients. © 2021 Bhandari et al.},
	author_keywords = {Chest CT scan; Classification; COVID-19; Machine learning; Pan-demic},
	correspondence_address = {A. Tak; Department of Physiology, RVRS Medical College and Hospitals, Bhilwara, Rajasthan, India; email: dramittak@gmail.com},
	publisher = {Faculty of Medicine, University of Banja Luka},
	issn = {24903329},
	language = {English},
	abbrev_source_title = {Scr. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@BOOK{Avgouleas20211,
	author = {Avgouleas, Emilios and Marjosola, Heikki},
	title = {Digital Finance in Europe: Law, Regulation, and Governance},
	year = {2021},
	journal = {Digital Finance in Europe: Law, Regulation, and Governance},
	pages = {1 – 280},
	doi = {10.1515/9783110749472},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135648652&doi=10.1515%2f9783110749472&partnerID=40&md5=0664bd209a8d4839ed750aca301fb20a},
	affiliations = {University of Edinburgh, United Kingdom; School of European Political Economy, Luiss Guido Carli, Italy; Faculty of Law, University of Helsinki, Finland},
	abstract = {Global finance is in the middle of a radical transformation fueled by innovative financial technologies. The coronavirus pandemic has accelerated the digitization of retail financial services in Europe. Institutional interest and digital asset markets are also growing blurring the boundaries between the token economy and traditional finance. Blockchain, AI, quantum computing and decentralised finance (DeFI) are setting the stage for a global battle of business models and philosophies. The post-Brexit EU cannot afford to ignore the promise of digital finance. But the Union is struggling to keep pace with global innovation hubs, particularly when it comes to experimenting with new digital forms of capital raising. Calibrating the EU digital finance strategy is a balancing act that requires a deep understanding of the factors driving the transformation, be they legal, cultural, political or economic, as well as their many implications. The same FinTech inventions that use AI, machine learning and big data to facilitate access to credit may also establish invisible barriers that further social, racial and religious exclusion. The way digital finance actors source, use, and record information presents countless consumer protection concerns. The EU’s strategic response has been years in the making and, finally, in September 2020 the Commission released a Digital Finance Package. This special issue collects contributions from leading scholars who scrutinize the challenges digital finance presents for the EU internal market and financial market regulation from multiple public policy perspectives. Author contributions adopt a critical yet constructive and solutions-oriented approach. They aim to provide policy-relevant research and ideas shedding light on the complexities of the digital finance promise. They also offer solid proposals for reform of EU financial services law. first complete academic analysis of the digitisation of EU finance and its regulation Interdisciplinary (law, economics, and ethics) analysis of the EU Digital Finance Package offers solid proposals for reform of EU financial services law. © 2022 Heikki Marjosola and Emilios Avgouleas, published by Walter de Gruyter GmbH, Berlin/Boston.},
	publisher = {De Gruyter},
	isbn = {978-311074947-2; 978-311074941-0},
	language = {English},
	abbrev_source_title = {Digital Finance in Europe: Law, Regulation, and Gov.},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@BOOK{King2021669,
	author = {King, Melanie R. N. and Timms, Paul D. and Rubin, Tzameret H.},
	title = {Use of Big Data in Insurance},
	year = {2021},
	journal = {The Palgrave Handbook of Technological Finance},
	pages = {669 – 700},
	doi = {10.1007/978-3-030-65117-6_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148253298&doi=10.1007%2f978-3-030-65117-6_24&partnerID=40&md5=8d451e2f8b7a9b26b29edfd6669db369},
	affiliations = {Wolfson School of Mechanical, Electrical and Manufacturing Engineering, Loughborough University, Loughborough, United Kingdom; School of Business and Economics, Loughborough University, Loughborough, United Kingdom},
	abstract = {The global insurance sector is currently undergoing a period of significant change. A new wave of advanced data-processing and analytic techniques, such as machine learning, are being exploited thanks to the supply of huge quantities of data. Abundant datasets are created and made available rapidly, even in real-time, from data captured via mobile devices, Internet of Things and wearable tech. Cloud computing and 5G networks provide the connective backbone of sophisticated data-intensive applications, which combined, have the potential to completely rewrite the basic mechanics of insurance. Although traditionally considered technology laggards, and risk averse, insurance enterprises are now starting to react to this digitisation and the new opportunities it brings. In this chapter, we discuss the function of insurance, how new technologies can augment and change the sector, and highlight some of the key challenges that these new technologies introduce. © The Editor(s) (if applicable) and The Author(s) 2021.},
	author_keywords = {Analytics; Big data; Customer; Ethics; Insurance; InsurTech; IoT; Regulation; Risk; Systems},
	correspondence_address = {M.R.N. King; Wolfson School of Mechanical, Electrical and Manufacturing Engineering, Loughborough University, Loughborough, United Kingdom; email: m.r.n.king@lboro.ac.uk},
	publisher = {Springer International Publishing},
	isbn = {978-303065117-6; 978-303065116-9},
	language = {English},
	abbrev_source_title = {The Palgrave Handb. of Technological Finance},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Liebau2021188,
	author = {Liebau, Daniel and Wong, Tiffany},
	title = {AI and Business Ethics in Financial Markets},
	year = {2021},
	journal = {The AI Book: The Artificial Intelligence Handbook for Investors, Entrepreneurs and FinTech Visionaries},
	pages = {188 – 190},
	doi = {10.1002/9781119551966.ch50},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160113739&doi=10.1002%2f9781119551966.ch50&partnerID=40&md5=1e4e799d7dc7256bf4cd580a613b68e4},
	affiliations = {Lightbulb Capital, United Kingdom; PwC UK, United Kingdom},
	abstract = {Artificial intelligence (Al) is widely discussed in the media, and there are many views on how it will affect humanity's future. This chapter focuses on machine learning algorithms and robotics. It considers principle-based work, issued by the European Union, Hong Kong and Singapore. The chapter discusses fairness and privacy and examines transparency and explainability - the age-old “black box” dilemma. It attempts to address the paradox of accountability in Al and also discusses operationalizing principles to facilitate the ethical use of Al in financial markets. The use of technology to support fraudulent behaviour is vividly described in Scott Patterson's 2013 book Dark Pools. When building AI trading algorithms, we recommend defining boundaries to delineate fair from unfair trading activity. One solution to preserving the privacy of actors in the financial markets could be the use of zero-knowledge proofs. © 2020 FINTECH Circle Ltd.},
	author_keywords = {artificial intelligence; business ethics; explainability; fairness; financial markets; machine learning algorithms; privacy; robotics; transparency},
	publisher = {wiley},
	isbn = {978-111955196-6; 978-111955190-4},
	language = {English},
	abbrev_source_title = {The AI Book: The Artificial Intelligence Handbook for Investors, Entrepreneurs and FinTech Visionaries},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Roué2021,
	author = {Roué, Jean-Michel and Morag, Iris and Haddad, Wassim M and Gholami, Behnood and Anand, Kanwaljeet J S},
	title = {Using sensor-fusion and machine-learning algorithms to assess acute pain in non-verbal infants: A study protocol},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {1},
	doi = {10.1136/bmjopen-2020-039292},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099120082&doi=10.1136%2fbmjopen-2020-039292&partnerID=40&md5=8765e4a4f2cd68c24d1f23dc4ce27d60},
	affiliations = {Neonatal and Pediatric Intensive Care Unit, Brest University Hospital, University of Western Brittany, Brest, France; Shamir Medical Center (Assaf Harofeh), Neonatal Intensive Care Unit, Tel Aviv University Sackler Faculty of Medicine, Tel Aviv, Israel; School of Aerospace Engineering, Georgia Institute of Technology, Atlanta, GA, United States; Autonomous Healthcare, Inc, Hoboken, NJ, United States; Department of Pediatrics, Pain/Stress Neurobiology Laboratory, Maternal and Child Health Research Institute, Stanford University School of Medicine, Stanford, CA, United States},
	abstract = {Introduction Objective pain assessment in non-verbal populations is clinically challenging due to their inability to express their pain via self-report. Repetitive exposures to acute or prolonged pain lead to clinical instability, with long-term behavioural and cognitive sequelae in newborn infants. Strong analgesics are also associated with medical complications, potential neurotoxicity and altered brain development. Pain scores performed by bedside nurses provide subjective, observer-dependent assessments rather than objective data for infant pain management; the required observations are labour intensive, difficult to perform by a nurse who is concurrently performing the procedure and increase the nursing workload. Multimodal pain assessment, using sensor-fusion and machine-learning algorithms, can provide a patient-centred, context-dependent, observer-independent and objective pain measure. Methods and analysis In newborns undergoing painful procedures, we use facial electromyography to record facial muscle activity-related infant pain, ECG to examine heart rate (HR) changes and HR variability, electrodermal activity (skin conductance) to measure catecholamine-induced palmar sweating, changes in oxygen saturations and skin perfusion, and electroencephalography using active electrodes to assess brain activity in real time. This multimodal approach has the potential to improve the accuracy of pain assessment in non-verbal infants and may even allow continuous pain monitoring at the bedside. The feasibility of this approach will be evaluated in an observational prospective study of clinically required painful procedures in 60 preterm and term newborns, and infants aged 6 months or less. Ethics and dissemination The Institutional Review Board of the Stanford University approved the protocol. Study findings will be published in peer-reviewed journals, presented at scientific meetings, taught via webinars, podcasts and video tutorials, and listed on academic/scientific websites. Future studies will validate and refine this approach using the minimum number of sensors required to assess neonatal/infant pain. Trial registration number ClinicalTrials.gov Registry (NCT03330496).  © },
	author_keywords = {neonatology; paediatrics; pain management},
	keywords = {Acute Pain; Humans; Infant; Infant, Newborn; Machine Learning; Pain Management; Pain Measurement; Prospective Studies; adhesive agent; analgesic agent; catecholamine; morphine; algorithm; analgesia; brain function; child behavior; clinical article; clinical classification; data analysis; electrocardiogram; electroencephalography; electromyography; face muscle; facial expression; feasibility study; female; hand palm; heart rate variability; hospitalized infant; human; infant; institutional review; invasive procedure; machine learning; male; muscle function; Neonatal Facial Coding System; Neonatal Pain and Sedation Scale; neonatology; newborn; newborn monitoring; nonverbal communication; observational study; oxygen saturation; pain; pain assessment; pain intensity; prematurity; prospective study; pulse oximetry; rating scale; Review; skin blood flow; skin conductance; software; sweating; videorecording; visual analog scale; workload; machine learning; pain; pain measurement},
	correspondence_address = {J.-M. Roué; Neonatal and Pediatric Intensive Care Unit, Brest University Hospital, University of Western Brittany, Brest, France; email: jean-michel.roue@chu-brest.fr},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33408199},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Ghajargar2021,
	author = {Ghajargar, Maliheh and Bardzell, Jeffrey and Renner, Alison Smith and Krogh, Peter Gall and Höök, Kristina and Cuartielles, David and Boer, Laurens and Wiberg, Mikael},
	title = {From "Explainable AI" to "Graspable AI"},
	year = {2021},
	journal = {TEI 2021 - Proceedings of the 15th International Conference on Tangible, Embedded, and Embodied Interaction},
	doi = {10.1145/3430524.3442704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102059863&doi=10.1145%2f3430524.3442704&partnerID=40&md5=daef7ae1afe8c9c3fba7899e48580cb1},
	affiliations = {Arts and Communication Malmö University, Sweden; College of Information Sciences and Technology, Pennsylvania State University, United States; Machine Learning Visualization Lab Decisive Analytics Corporation, United States; Department of Enginering, Aarhus University, Denmark; Media Technology and Interaction Design, KTH, Royal Institute of Technology, Sweden; IT University Copenhagen, Denmark; Dept of Informatics Umea University, Sweden},
	abstract = {Since the advent of Artificial Intelligence (AI) and Machine Learning (ML), researchers have asked how intelligent computing systems could interact with and relate to their users and their surroundings, leading to debates around issues of biased AI systems, ML black-box, user trust, user's perception of control over the system, and system's transparency, to name a few. All of these issues are related to how humans interact with AI or ML systems, through an interface which uses different interaction modalities. Prior studies address these issues from a variety of perspectives, spanning from understanding and framing the problems through ethics and Science and Technology Studies (STS) perspectives to finding effective technical solutions to the problems. But what is shared among almost all those efforts is an assumption that if systems can explain the how and why of their predictions, people will have a better perception of control and therefore will trust such systems more, and even can correct their shortcomings. This research field has been called Explainable AI (XAI). In this studio, we take stock on prior efforts in this area; however, we focus on using Tangible and Embodied Interaction (TEI) as an interaction modality for understanding ML. We note that the affordances of physical forms and their behaviors potentially can not only contribute to the explainability of ML systems, but also can contribute to an open environment for criticism. This studio seeks to both critique explainable ML terminology and to map the opportunities that TEI can offer to the HCI for designing more sustainable, graspable and just intelligent systems. © 2021 Owner/Author.},
	author_keywords = {Artificial Intelligence; Explainable AI; Interaction Design; Machine Learning; Tangible Embodied Interaction; TEI; XAI},
	keywords = {Behavioral research; Printing machinery; Studios; Affordances; Black boxes; Embodied interaction; Open environment; Research fields; Science and technology studies; Technical solutions; User's perceptions; Intelligent computing},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038213-7},
	language = {English},
	abbrev_source_title = {TEI - Proc. Int. Conf. Tangible, Embed., Embodied Interact.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 15th International Conference on Tangible, Embedded, and Embodied Interaction, TEI 2021; Conference date: 14 February 2021 through 19 February 2021; Conference code: 167036; All Open Access, Green Open Access}
}

@CONFERENCE{2021,
	title = {2021 ITU Kaleidoscope: Connecting Physical and Virtual Worlds, ITU K 2021},
	year = {2021},
	journal = {2021 ITU Kaleidoscope: Connecting Physical and Virtual Worlds, ITU K 2021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124666076&partnerID=40&md5=0230f0eb7104814ffc525ddafdffe801},
	abstract = {The proceedings contain 25 papers. The topics discussed include: deviceless: a serverless approach for the Internet of things; exploring the essence of communication to reach the heart; the adoption gap: ethics, citizenship, institutional factors, and standards for smart cities; strengthen the security of cyberspace with device-independent quantum randomness; optimal pilot sequence design for machine learning based channel estimation in FDD massive MIMO systems; optimizing packet transmission for ledger-based points transfer system in LPWAN: solutions, evaluation and standardization; enhancing the system model for home interior design using augmented reality; and future industrial networks: requirements, challenges, research and standardization needs.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-926133881-7},
	language = {English},
	abbrev_source_title = {ITU Kaleidoscope: Connect. Phys.Virtual Worlds, ITU K},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 International Telecommunication Union Kaleidoscope Academic Conference: Connecting Physical and Virtual Worlds, ITU K 2021; Conference date: 6 December 2021 through 10 December 2021; Conference code: 176195}
}

@CONFERENCE{Baleshta2021,
	author = {Baleshta, Clair and White, Dylan and Reavie, Glen and Cooper, Alysha and Taylor, Graham and Skorburg, Joshua August Gus and Bruwaene, David Van and Gignac, Sarah and Schmidt, Chris and McDonald, Laura and Thaine, Patricia and Ryan, Chloe and Luan, Rency},
	title = {CARE-AI special session on AI ethics},
	year = {2021},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2021-October},
	doi = {10.1109/ISTAS52410.2021.9629130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123163861&doi=10.1109%2fISTAS52410.2021.9629130&partnerID=40&md5=91bda72c64169a7f8f52998ad73f7710},
	affiliations = {Western University, Dept. of Philosophy, Canada; University of Guelph, Dept. of Philosophy, Canada; University of Guelph, Department of Mathematics and Statistics, Canada; University of Guelph, Department of Mathematics and Statistics, Canada; University of Guelph, Canada Research Chair in Machine Learning and Professor, School of Engineering, Canada; University of Guelph, Dept. of Philosophy, Canada; Fairly AI; Future Fertility; Pluto Ventures; Private AI; Acrylic; University of Waterloo, Canada},
	abstract = {This special session organized by the Centre for Advancing Responsible and Ethical Artificial Intelligence (CARE-AI) consists of two 90-minute parts, focusing on two groups at the frontline of AI Ethics: Students and start-up founders. Part 1 is a student-led AI Ethics paper presentation and critique: Two students from the Philosophy program will present original work, 'Analyzing Distrust in Human Interactions with AI,' and 'Enactivism and Modelling Human Behaviour in AI,' (20 min); each presentation will be followed by a prepared critique from a student in the Collaborative Specialization in AI (10 min) and a 15-minute general discussion with the audience. Part 2 is an AI Ethics start-up showcase: 5 Canadian start-up companies (whose products or services either present an AI Ethics dilemma or propose a solution) will present 5-minute pitches, which will each be followed by 5 minutes of expert commentary and 5 minutes of open discussion.  © 2021 IEEE.},
	author_keywords = {AI ethics; black boxing; Canada; human behaviour; machine learning; tech start-up},
	keywords = {Behavioral research; Ethical technology; Machine learning; AI ethic; Black boxing; Canada; Frontline; Human behaviors; Humaninteraction; Specialisation; Start-up companies; Tech start-up; Students},
	editor = {Caron B. and Schmitt K.A. and Pearl Z. and Dara R. and Love H.A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166543580-2},
	language = {English},
	abbrev_source_title = {Int Symp Technol Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 IEEE International Symposium on Society and Technology, ISTAS 2021; Conference date: 28 October 2021 through 31 October 2021; Conference code: 175401; All Open Access, Bronze Open Access}
}

@ARTICLE{Talwar2021511,
	author = {Talwar, Vineet and Chufal, Kundan Singh and Joga, Srujana},
	title = {Artificial Intelligence: A New Tool in Oncologist's Armamentarium},
	year = {2021},
	journal = {Indian Journal of Medical and Paediatric Oncology},
	volume = {42},
	number = {6},
	pages = {511 – 517},
	doi = {10.1055/s-0041-1735577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121742703&doi=10.1055%2fs-0041-1735577&partnerID=40&md5=38fd3443d3ee6a433513d1ba8ea39e72},
	affiliations = {DNB General Medicine, Department of Medical Oncology, Rajiv Gandhi Cancer Institute and Research Centre, Rohini, Sector 5, New Delhi, 110085, India; Department of Radiation Oncology, Rajiv Gandhi Cancer Institute and Research Centre, New Delhi, India},
	abstract = {Artificial intelligence (AI) has become an essential tool in human life because of its pivotal role in communications, transportation, media, and social networking. Inspired by the complex neuronal network and its functions in human beings, AI, using computer-based algorithms and training, had been explored since the 1950s. To tackle the enormous amount of patients' clinical data, imaging, histopathological data, and the increasing pace of research on new treatments and clinical trials, and ever-changing guidelines for treatment with the advent of novel drugs and evidence, AI is the need of the hour. There are numerous publications and active work on AI's role in the field of oncology. In this review, we discuss the fundamental terminology of AI, its applications in oncology on the whole, and its limitations. There is an inter-relationship between AI, machine learning and, deep learning. The virtual branch of AI deals with machine learning. While the physical branch of AI deals with the delivery of different forms of treatment-surgery, targeted drug delivery, and elderly care. The applications of AI in oncology include cancer screening, diagnosis (clinical, imaging, and histopathological), radiation therapy (image acquisition, tumor and organs at risk segmentation, image registration, planning, and delivery), prediction of treatment outcomes and toxicities, prediction of cancer cell sensitivity to therapeutics and clinical decision-making. A specific area of interest is in the development of effective drug combinations tailored to every patient and tumor with the help of AI. Radiomics, the new kid on the block, deals with the planning and administration of radiotherapy. As with any new invention, AI has its fallacies. The limitations include lack of external validation and proof of generalizability, difficulty in data access for rare diseases, ethical and legal issues, no precise logic behind the prediction, and last but not the least, lack of education and expertise among medical professionals. A collaboration between departments of clinical oncology, bioinformatics, and data sciences can help overcome these problems in the near future.  © 2021. Indian Society of Medical and Paediatric Oncology. All rights reserved.},
	author_keywords = {Applications; Artificial intelligence; Clinical decision; Clinical outcomes; Oncology; Radiation oncology; Translational oncology},
	keywords = {artificial intelligence; cancer cell; cancer combination chemotherapy; cancer diagnosis; cancer patient; cancer radiotherapy; cancer screening; clinical decision making; deep learning; digital pathology; drug delivery system; drug sensitivity; elderly care; histopathology; human; image registration; image segmentation; legal aspect; machine learning; medical education; medical ethics; medical expert; nomenclature; oncologist; organs at risk; prediction; radiomics; rare disease; resource shortage; Review; treatment outcome; treatment planning},
	correspondence_address = {S. Joga; DNB General Medicine, Department of Medical Oncology, Rajiv Gandhi Cancer Institute and Research Centre, New Delhi, Rohini, Sector 5, 110085, India; email: srujanajoga@gmail.com},
	publisher = {Thieme Medical Publishers, Inc.},
	issn = {09715851},
	language = {English},
	abbrev_source_title = {Indian J. Med. Paediatr. Oncol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Wilde2021,
	author = {Wilde, Harrison and Chen, Lucia L. and Nguyen, Austin and Kimpel, Zoe and Sidgwick, Joshua and De Unanue, Adolfo and Veronese, Davide and Mateen, Bilal and Ghani, Rayid and Vollmer, Sebastian},
	title = {A recommendation and risk classification system for connecting rough sleepers to essential outreach services},
	year = {2021},
	journal = {Data and Policy},
	volume = {3},
	number = {3},
	doi = {10.1017/dap.2020.23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133023601&doi=10.1017%2fdap.2020.23&partnerID=40&md5=db293b323d5a5b3a0f0012e59745b289},
	affiliations = {Department of Statistics, University of Warwick, Coventry, United Kingdom; School of Informatics, University of Edinburgh, Edinburgh, United Kingdom; Data Science, Tripadvisor, Needham, MA, United States; Master in Data Science, Northwestern University, Chicago, IL, United States; The Alan Turing Institute, London, United Kingdom; Departamento de Matemáticas, Instituto Tecnologico Autonomo de Mexico, Mexico City, Mexico; Master in Public Policy Candidate, Harvard Kennedy School, Cambridge, MA, United States; Machine Learning Department, Heinz College of Information Systems and Public Policy, Carnegie Mellon University, Pittsburgh, PA, United States},
	abstract = {Rough sleeping is a chronic experience faced by some of the most disadvantaged people in modern society. This paper describes work carried out in partnership with Homeless Link (HL), a UK-based charity, in developing a data-driven approach to better connect people sleeping rough on the streets with outreach service providers. HL's platform has grown exponentially in recent years, leading to thousands of alerts per day during extreme weather events; this overwhelms the volunteer-based system they currently rely upon for the processing of alerts. In order to solve this problem, we propose a human-centered machine learning system to augment the volunteers' efforts by prioritizing alerts based on the likelihood of making a successful connection with a rough sleeper. This addresses capacity and resource limitations whilst allowing HL to quickly, effectively, and equitably process all of the alerts that they receive. Initial evaluation using historical data shows that our approach increases the rate at which rough sleepers are found following a referral by at least 15% based on labeled data, implying a greater overall increase when the alerts with unknown outcomes are considered, and suggesting the benefit in a trial taking place over a longer period to assess the models in practice. The discussion and modeling process is done with careful considerations of ethics, transparency, and explainability due to the sensitive nature of the data involved and the vulnerability of the people that are affected.  © The Author(s), 2021. Published by Cambridge University Press in association with Data for Policy.},
	author_keywords = {decision support; homelessness; prioritization; risk classification; social good},
	correspondence_address = {S. Vollmer; Department of Statistics, University of Warwick, Coventry, United Kingdom; email: svollmer@turing.ac.uk},
	publisher = {Cambridge University Press},
	issn = {26323249},
	language = {English},
	abbrev_source_title = {Data. Policy.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Nikitas2021167,
	author = {Nikitas, Alexandros},
	title = {Connected and Autonomous Vehicles: Priorities for Policy and Planning},
	year = {2021},
	journal = {International Encyclopedia of Transportation: Volume 1-7},
	volume = {6},
	pages = {167 – 172},
	doi = {10.1016/B978-0-08-102671-7.10636-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151218415&doi=10.1016%2fB978-0-08-102671-7.10636-0&partnerID=40&md5=440b6e5d9e5d035f767cf34e8e10b1d6},
	affiliations = {Huddersfield Business School, University of Huddersfield, Huddersfield, United Kingdom},
	abstract = {Connected and Autonomous Vehicles (CAVs) is a paradigm-shifting mobility technology that will redefine the urban landscapes of the future by employing the immense capabilities of Artificial Intelligence, Machine Learning and wireless connectivity. Despite great technological breakthroughs orchestrated by the automotive industry and millions of autopiloted road miles traveled in segregated environments and living lab conditions the road to a full-scale implementation is significantly longer and harder that many might anticipate. This is because CAVs is not a simple techno-fix but rather a complex piece of a diverse socio-technical transition to an unprecedented smart mobility paradigm that still needs to prioritize people over machines. Policy and planning need to be seriously reviewed, redesigned and rebranded to incorporate effectively CAVs before these can fulfill their destiny as genuine game-changers in hopefully improving the standard of mobility provision. This paper provides a roadmap of the opportunities and challenges that reflect and affect the policy and planning of CAVs highlighting 10 priority areas namely: technology; legislation; crisis and employment ethics; infrastructure and land use; integration; traffic safety; cyber security and privacy; business models; traffic congestion and travel behavior; and finally acceptability, trust and customer readiness. © 2021 Elsevier Ltd. All rights reserved},
	author_keywords = {Automated Transport; Autonomous Vehicles (AVs); Connected and Autonomous Vehicles (CAVs); Driverless Vehicles; Transport Planning; Transport Policy},
	publisher = {Elsevier},
	isbn = {978-008102672-4; 978-008102671-7},
	language = {English},
	abbrev_source_title = {International Encyclopedia of Transportation: Volume 1-7},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Sahai2021127,
	author = {Sahai, Alok Kumar and Rath, Namita},
	title = {Artificial Intelligence and the 4th Industrial Revolution},
	year = {2021},
	journal = {Artificial Intelligence and Machine Learning in Business Management: Concepts, Challenges, and Case Studies},
	pages = {127 – 144},
	doi = {10.1201/9781003125129-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131476732&doi=10.1201%2f9781003125129-8&partnerID=40&md5=3b0e1d4c2dcb4faea8bd5dea6a8e1368},
	affiliations = {Faculty of Management Studies, Sri Sri University, Cuttack, India},
	abstract = {Artificial Intelligence lies at the core of the 4th Industrial Revolution. The convergence of ever-increasing computing power, machine learning and big data analytics has reshaped the world around us. Today’s computers are knowledge machines that have cognitively evolved brains and use 10-15 layers of neural networks. Today we do not instruct the machines to do something but instead have trained them to learn themselves and solve the problems. Advances in cognitive and neural sciences have led to deep learning and machine learning and are changing the way knowledge economy works. There is a sweeping shift in the immersive automation and mechanization driven by artificial intelligence into goods and services, manufacturing, transport, utilities and changing human dynamics. Technology has moved beyond analytical to predictive to prescriptive applications with the advances in artificial intelligence. Machine learning has enabled long leaps in fields as diverse as economics, finance, marketing, operations, image processing to medical diagnosis. Software personal assistants, robotics, context-aware processing, image processing and facial recognition are conspicuously recognized applications of artificial intelligence. Machine learning as a service features software environment for building machine learning algorithms covering the fields of marketing, risk analysis, stock trading, fraud detection and predictive analysis to name but a few. While AI and ML are changing the game, they also pose threats of governance over data privacy, net ethics and cybersecurity issues and underscore the need for broader cyber laws and policymaking in the future. The transformative impact of artificial intelligence, machine learning and embedded technology will shape the new economy and market space. How will the economies, markets, ecosystems and organizations react and respond in this ever-expanding yet the interconnected world remains to be seen. © 2022 Taylor & Francis Group, LLC.},
	publisher = {CRC Press},
	isbn = {978-100043211-4; 978-036764555-7},
	language = {English},
	abbrev_source_title = {Artificial Intelligence and Machine Learning in Bus. Management: Concepts, Challenges, and Case Studies},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Panesar20211775,
	author = {Panesar, Arjun and Panesar, Harkrishan},
	title = {Artificial Intelligence and Machine Learning in Global Healthcare},
	year = {2021},
	journal = {Handbook of Global Health: With 362 Figures and 152 Tables},
	pages = {1775 – 1813},
	doi = {10.1007/978-3-030-45009-0_75},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150116051&doi=10.1007%2f978-3-030-45009-0_75&partnerID=40&md5=f3dbf42e0e264063b7f516d03613f737},
	affiliations = {Diabetes Digital Media (DDM), University of Warwick, Warwick, United Kingdom},
	abstract = {Although medicine has been receptive to the benefits of machine learning and artificial intelligence (AI), it has only recently started to adopt this rapidly evolving, disruptive technology, particularly when compared to finance, entertainment, and transport sectors. Machine learning enables the detection of hidden connections and patterns, including outcomes prediction. Data is critical for the development of intelligent models, which harness the potential to improve and redefine disease self-management, treatment, and wellness pathways. The consequences of digital health democratization have significant health and ethical impact. This chapter provides an introduction to machine learning and AI and the development of intelligent healthcare systems. It explores applications of AI in healthcare and how the ubiquity of smartphones and Internet of Things (IoT) has accelerated the global shift from volume-based to value-based healthcare. This chapter will highlight key challenges within machine learning, evaluate machine learning projects, and share examples of best practice healthcare AI. Finally, it will review the ethical concerns surrounding machine learning, including how machines affect human behavior, data ownership, bias, unintended consequences, and the advances that have been made to support the global shift toward value-based population health. © The Editors and the World Health Organization 2021.},
	author_keywords = {Artificial intelligence; Big data; Digital health; Ethics; Value-based healthcare},
	correspondence_address = {A. Panesar; Diabetes Digital Media (DDM), University of Warwick, Warwick, United Kingdom; email: arjun@ddm.health},
	publisher = {Springer International Publishing},
	isbn = {978-303045009-0; 978-303045008-3},
	language = {English},
	abbrev_source_title = {Handb. of Global Health: With 362 Figures and 152 Tables},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Arora2021211,
	author = {Arora, Amarpreet Singh and Changotra, Rahil and Rajput, Himadri},
	title = {An Overview to Quantitative Risk Assessment Methodologies},
	year = {2021},
	journal = {Bow Ties in Process Safety and Environmental Management: Current Trends and Future Perspectives},
	pages = {211 – 218},
	doi = {10.1201/9781003140382-12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146107831&doi=10.1201%2f9781003140382-12&partnerID=40&md5=bfbbe46c53217ec89624ab67a3921cc8},
	affiliations = {School of Chemical Engineering, Yeungnam University Gyeongsan, South Korea; School of Energy and Environment, Thapar Institute of Engineering and Technology, Patiala, India; School of Energy and Environment, Thapar Institute of Engineering and Technology, Patiala, India},
	abstract = {Understanding risk, its probability of occurrence and keeping in place the right strategies in the event of incidents is becoming more apparent and crucial. The quantitative risk assessment (QRA) technique is a consolidated and methodical approach to evaluate the risk level, its probability and consequences of hazardous events, which could be based on technical failures or natural disasters leading to the potential possibilities of accidents and articulating the results quantitatively in terms of the risk to the public or the environment. In a broad sense, QRA includes four key processes/stages: hazard identification, hazard evaluation, exposure evaluation, and risk estimation. In the chemical and petro-chemical industires, a primary QRA approach is determination of the potential loss of life (PLL) triggered by undesired events. The effects of PLL can be calculated by specialized software. In the explosives industry, QRA can be useful for on-site risk analysis. This chapter summarizes the importance of QRA. Various methodologies and softwares are adopted to conduct QRA. QRA software is predominantly constructed on the basis of a large amount of historical data and other attributes. Over the years, their scopes have been extended to socio-economic and other financial applications. This chapter outlines the various applications, scopes, and the limitations associated with QRA models. It is indicated that the need to incorporate big data and machine learning will be required to achieve a more robust system. A caution is needed to avoid discriminatory queries in the field of machine ethics. © 2022 selection and editorial matter, Anjani Ravi Kiran Gollakota, Sneha Gautam and Chi-Min Shu.},
	publisher = {CRC Press},
	isbn = {978-100051800-9; 978-036769088-5},
	language = {English},
	abbrev_source_title = {Bow Ties in Process Saf. and Environmental Management: Current Trends and Future Perspectives},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Balcombe2021,
	author = {Balcombe, Luke and De Leo, Diego},
	title = {Digital mental health challenges and the horizon ahead for solutions},
	year = {2021},
	journal = {JMIR Mental Health},
	volume = {8},
	number = {3},
	doi = {10.2196/26811},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103667590&doi=10.2196%2f26811&partnerID=40&md5=33000c9c7bf101f0c3b42aebb04f3e48},
	affiliations = {Australian Institute for Suicide Research and Prevention, Griffith University, Brisbane, Australia},
	abstract = {The demand outstripping supply of mental health resources during the COVID-19 pandemic presents opportunities for digital technology tools to fill this new gap and, in the process, demonstrate capabilities to increase their effectiveness and efficiency. However, technology-enabled services have faced challenges in being sustainably implemented despite showing promising outcomes in efficacy trials since the early 2000s. The ongoing failure of these implementations has been addressed in reconceptualized models and frameworks, along with various efforts to branch out among disparate developers and clinical researchers to provide them with a key for furthering evaluative research. However, the limitations of traditional research methods in dealing with the complexities of mental health care warrant a diversified approach. The crux of the challenges of digital mental health implementation is the efficacy and evaluation of existing studies. Web-based interventions are increasingly used during the pandemic, allowing for affordable access to psychological therapies. However, a lagging infrastructure and skill base has limited the application of digital solutions in mental health care. Methodologies need to be converged owing to the rapid development of digital technologies that have outpaced the evaluation of rigorous digital mental health interventions and strategies to prevent mental illness. The functions and implications of human-computer interaction require a better understanding to overcome engagement barriers, especially with predictive technologies. Explainable artificial intelligence is being incorporated into digital mental health implementation to obtain positive and responsible outcomes. Investment in digital platforms and associated apps for real-time screening, tracking, and treatment offer the promise of cost-effectiveness in vulnerable populations. Although machine learning has been limited by study conduct and reporting methods, the increasing use of unstructured data has strengthened its potential. Early evidence suggests that the advantages outweigh the disadvantages of incrementing such technology. The limitations of an evidence-based approach require better integration of decision support tools to guide policymakers with digital mental health implementation. There is a complex range of issues with effectiveness, equity, access, and ethics (eg, privacy, confidentiality, fairness, transparency, reproducibility, and accountability), which warrant resolution. Evidence-informed policies, development of eminent digital products and services, and skills to use and maintain these solutions are required. Studies need to focus on developing digital platforms with explainable artificial intelligence–based apps to enhance resilience and guide the treatment decisions of mental health practitioners. Investments in digital mental health should ensure their safety and workability. End users should encourage the use of innovative methods to encourage developers to effectively evaluate their products and services and to render them a worthwhile investment. Technology-enabled services in a hybrid model of care are most likely to be effective (eg, specialists using these services among vulnerable, at-risk populations but not severe cases of mental ill health). © Luke Balcombe, Diego De Leo.},
	author_keywords = {Challenges; COVID-19; Digital mental health implementation; Explainable artificial intelligence; Human-computer interaction; Hybrid model of care; Resilience; Technology},
	keywords = {artificial intelligence; clinical outcome; confidentiality; coronavirus disease 2019; cost effectiveness analysis; decision support system; digital technology; ethics; evidence based medicine; health care access; health equity; high risk population; human; human computer interaction; investment; machine learning; mental disease; mental health; mental health care; mobile application; pandemic; policy; privacy; psychotherapy; reproducibility; Review; risk assessment; screening; vulnerable population; web-based intervention},
	correspondence_address = {L. Balcombe; Australian Institute for Suicide Research and Prevention, Griffith University, Brisbane, Messines Ridge Rd, 4122, Australia; email: lukebalcombe@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {23687959},
	language = {English},
	abbrev_source_title = {JMIR Ment. Heal.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gu2021253,
	author = {Gu, Tianlong and Feng, Xuan and Li, Long and Bao, Xuguang and Li, Yunhui},
	title = {Ethical Behavior Discrimination Based on Social News Dataset; [基于社会新闻数据集的伦理行为判别方法]},
	year = {2021},
	journal = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
	volume = {58},
	number = {2},
	pages = {253 – 263},
	doi = {10.7544/issn1000-1239.2021.20200727},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101349861&doi=10.7544%2fissn1000-1239.2021.20200727&partnerID=40&md5=fa50517aa1965af107c91d4456f8edfe},
	affiliations = {Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, 541004, China; College of Information Science and Technology, College of Cyber Security, Jinan University, Guangzhou, 510632, China},
	abstract = {With the broader applications of artificial intelligence (AI), their ethical and moral issues have attracted more and more concerns. How to develop an AI system that complies with human values and ethical norms from the perspective of technology realization, namely, ethical aligned AI design, is one of the important issues that need to be solved urgently. The ethical and moral discrimination based on machine learning is a beneficial exploration in this aspect. Social news data has rich content and knowledge of ethics and morality, which provides the possibility for the training data development of machine learning. Because of this, this paper constructs a social news dataset with ethics and morality of human behavior, which is attached to law and code of conduct dataset for machine learning training and testing. The ethical behavior discrimination model ERNIE-CNN based on enhanced language representation of information entities (ERNIE) and convolutional neural network (CNN), is developed to extract ethical discriminations about behavior by calculating semantic similarity based on the vector representation of words. The experimental results show that the proposed model has better performance than the baseline models. © 2021, Science Press. All right reserved.},
	author_keywords = {CNN; Deep learning; ERNIE; Ethically aligned design; Social news dataset},
	keywords = {Behavioral research; Convolutional neural networks; Machine learning; Semantics; Statistical tests; Baseline models; Code of conduct; Discrimination model; Ethical behavior; Human behaviors; Semantic similarity; Training and testing; Vector representations; Philosophical aspects},
	correspondence_address = {L. Li; Guangxi Key Laboratory of Trusted Software, Guilin University of Electronic Technology, Guilin, 541004, China; email: lilong@guet.edu.cn},
	publisher = {Science Press},
	issn = {10001239},
	coden = {JYYFE},
	language = {Chinese},
	abbrev_source_title = {Jisuanji Yanjiu yu Fazhan},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Charles2021221,
	author = {Charles, Wendy Marie},
	title = {Accelerating Life Sciences Research with Blockchain},
	year = {2021},
	journal = {Studies in Big Data},
	volume = {83},
	pages = {221 – 252},
	doi = {10.1007/978-981-15-9547-9_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119517837&doi=10.1007%2f978-981-15-9547-9_9&partnerID=40&md5=902cfe8a146670c296782e5f23c6039a},
	affiliations = {Life Sciences Division, BurstIQ, Denver, CO, United States},
	abstract = {As life sciences research becomes increasingly focused on patient-centered technologies that allow for remote participation and greater access, distributed ledger technologies (“blockchain”) are being developed to address these needs. Blockchain-based applications range from basic functions, such as securing electronic data with audit trails, to honoring research participants’ informed consent for secondary uses of their data, and to the advanced features of aggregating data on a single platform for sophisticated machine learning, and hundreds of examples in between. There are many questions, however, about the best uses of blockchain and implementation strategies for life sciences research. This chapter introduces uses of blockchain for life sciences research and offers ethical, regulatory, and practical considerations for implementation. Recommendations are pertinent for blockchain developers, researchers, and life sciences organizations considering blockchain solutions for their research. © 2021, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Blockchain; Consent; Ethics; Governance; Life sciences research; Regulatory compliance},
	keywords = {Blockchain; Distributed ledger; Ethical technology; Application range; Audit trails; Basic functions; Block-chain; Consent; Electronic data; Governance; Life sciences research; Remote participation; Secondary use; Regulatory compliance},
	correspondence_address = {W.M. Charles; Life Sciences Division, BurstIQ, Denver, United States; email: wendy.charles@cuanschutz.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21976503},
	language = {English},
	abbrev_source_title = {Stud. Big. Data.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Lee2021191,
	author = {Lee, Irene and Ali, Safinah and Zhang, Helen and Dipaola, Daniella and Breazeal, Cynthia},
	title = {Developing Middle School Students' AI Literacy},
	year = {2021},
	journal = {SIGCSE 2021 - Proceedings of the 52nd ACM Technical Symposium on Computer Science Education},
	pages = {191 – 197},
	doi = {10.1145/3408877.3432513},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103335163&doi=10.1145%2f3408877.3432513&partnerID=40&md5=5d8c82e64c8f3a615eff9dc0a0a27cdc},
	affiliations = {Massachusetts Institute of Technology, Cambridge, MA, United States; Boston College, Chestnut Hill, MA, United States},
	abstract = {In this experience report, we describe an AI summer workshop designed to prepare middle school students to become informed citizens and critical consumers of AI technology and to develop their foundational knowledge and skills to support future endeavors as AI-empowered workers. The workshop featured the 30-hour "Developing AI Literacy"or DAILy curriculum that is grounded in literature on child development, ethics education, and career development. The participants in the workshop were students between the ages of 10 and 14; 87% were from underrepresented groups in STEM and Computing. In this paper we describe the online curriculum, its implementation during synchronous online workshop sessions in summer of 2020, and preliminary findings on student outcomes. We reflect on the successes and lessons we learned in terms of supporting students' engagement and conceptual learning of AI, shifting attitudes toward AI, and fostering conceptions of future selves as AI-enabled workers. We conclude with discussions of the affordances and barriers to bringing AI education to students from underrepresented groups in STEM and Computing. © 2021 Owner/Author.},
	author_keywords = {computational thinking; computing education; machine learning education},
	keywords = {Artificial intelligence; Curricula; Education computing; Employment; STEM (science, technology, engineering and mathematics); Career development; Child development; Conceptual learning; Experience report; Middle school students; Online curriculum; Students' engagements; Under-represented groups; Students},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038062-1},
	language = {English},
	abbrev_source_title = {SIGCSE - Proc. ACM Tech. Symp. Comput. Sci. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 47; Conference name: 52nd ACM Technical Symposium on Computer Science Education, SIGCSE 2021; Conference date: 13 March 2021 through 20 March 2021; Conference code: 167732; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Faqar-Uz-Zaman2021,
	author = {Faqar-Uz-Zaman, S Fatima and Filmann, Natalie and Mahkovic, Dora and Von Wagner, Michael and Detemble, Charlotte and Kippke, Ulf and Marschall, Ursula and Anantharajah, Luxia and Baumartz, Philipp and Sobotta, Paula and Bechstein, Wolf O. and Schnitzbauer, Andreas A.},
	title = {Study protocol for a prospective, double-blinded, observational study investigating the diagnostic accuracy of an app-based diagnostic health care application in an emergency room setting: The eRadaR trial},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {1},
	doi = {10.1136/bmjopen-2020-041396},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099246304&doi=10.1136%2fbmjopen-2020-041396&partnerID=40&md5=a2466b5cf61d14adb5b848a8071596ac},
	affiliations = {Department for General, Visceral and Transplant Surgery, Hospital of the Goethe University Frankfurt Surgery Centre, Frankfurt am Main, Germany; Institute of Biostatistics and Mathematical Modeling, Goethe-University, Frankfurt/Main, Frankfurt, Germany; Ljubljana Central Medical School, Ljubljana, Slovenia; Goethe University Frankfurt, Frankfurt am Main, Hessen, Germany; Hospital of the Goethe University Frankfurt Surgery Centre, Frankfurt am Main, Hessen, Germany; Barmer, Wuppertal, Germany},
	abstract = {Introduction Occurrence of inaccurate or delayed diagnoses is a significant concern in patient care, particularly in emergency medicine, where decision making is often constrained by high throughput and inaccurate admission diagnoses. Artificial intelligence-based diagnostic decision support system have been developed to enhance clinical performance by suggesting differential diagnoses to a given case, based on an integrated medical knowledge base and machine learning techniques. The purpose of the study is to evaluate the diagnostic accuracy of Ada, an app-based diagnostic tool and the impact on patient outcome. Methods and analysis The eRadaR trial is a prospective, double-blinded study with patients presenting to the emergency room (ER) with abdominal pain. At initial contact in the ER, a structured interview will be performed using the Ada-App and both, patients and attending physicians, will be blinded to the proposed diagnosis lists until trial completion. Throughout the study, clinical data relating to diagnostic findings and types of therapy will be obtained and the follow-up until day 90 will comprise occurrence of complications and overall survival of patients. The primary efficacy of the trial is defined by the percentage of correct diagnoses suggested by Ada compared with the final discharge diagnosis. Further, accuracy and timing of diagnosis will be compared with decision making of classical doctor-patient interaction. Secondary objectives are complications, length of hospital stay and overall survival. Ethics and dissemination Ethical approval was received by the independent ethics committee (IEC) of the Goethe-University Frankfurt on 9 April 2020 including the patient information material and informed consent form. All protocol amendments must be reported to and adapted by the IEC. The results from this study will be submitted to peer-reviewed journals and reported at suitable national and international meetings. Trial registration number DRKS00019098.  © },
	author_keywords = {accident & emergency medicine; adult gastroenterology; adult surgery},
	keywords = {Artificial Intelligence; COVID-19; Delivery of Health Care; Emergency Service, Hospital; Humans; Mobile Applications; Observational Studies as Topic; Prospective Studies; Randomized Controlled Trials as Topic; SARS-CoV-2; C reactive protein; abdominal pain; Article; clinical article; diagnostic accuracy; diagnostic test accuracy study; doctor patient relationship; double blind procedure; emergency ward; follow up; good clinical practice; human; ICD-10; length of stay; leukocyte count; medical decision making; mobile application; observational study; overall survival; platelet count; prospective study; structured interview; treatment outcome; artificial intelligence; health care delivery; hospital emergency service; randomized controlled trial (topic)},
	correspondence_address = {S.F. Faqar-Uz-Zaman; Department for General, Visceral and Transplant Surgery, Hospital of the Goethe University Frankfurt Surgery Centre, Frankfurt am Main, Germany; email: sarafatima.faqar-uz-zaman@kgu.de},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33419909},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Long20211,
	author = {Long, Robert},
	title = {Fairness in Machine Learning: Against False Positive Rate Equality as a Measure of Fairness},
	year = {2021},
	journal = {Journal of Moral Philosophy},
	volume = {91},
	number = {1},
	pages = {1 – 30},
	doi = {10.1163/17455243-20213439},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120357710&doi=10.1163%2f17455243-20213439&partnerID=40&md5=6ff17f989af2aaf7f46666fe3f9286a6},
	affiliations = {Department of Philosophy, New York University, New York City, NY, United States},
	abstract = {As machine learning informs increasingly consequential decisions, different metrics have been proposed for measuring algorithmic bias or unfairness. Two popular "fairness measures"are calibration and equality of false positive rate. Each measure seems intuitively important, but notably, it is usually impossible to satisfy both measures. For this reason, a large literature in machine learning speaks of a "fairness tradeoff"between these two measures. This framing assumes that both measures are, in fact, capturing something important. To date, philosophers have seldom examined this crucial assumption, and examined to what extent each measure actually tracks a normatively important property. This makes this inevitable statistical conflict - between calibration and false positive rate equality - an important topic for ethics. In this paper, I give an ethical framework for thinking about these measures and argue that, contrary to initial appearances, false positive rate equality is in fact morally irrelevant and does not measure fairness.  © 2021 Koninklijke Brill NV, Leiden, 2021.},
	author_keywords = {algorithmic bias; fairness; statistical discrimination},
	correspondence_address = {R. Long; Department of Philosophy, New York University, New York City, United States; email: rgblong@gmail.com},
	publisher = {Brill Academic Publishers},
	issn = {17404681},
	language = {English},
	abbrev_source_title = {J. Moral Philos.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@CONFERENCE{Shmueli20213758,
	author = {Shmueli, Boaz and Fell, Jan and Ray, Soumya and Ku, Lun-Wei},
	title = {Beyond Fair Pay: Ethical Implications of NLP Crowdsourcing},
	year = {2021},
	journal = {NAACL-HLT 2021 - 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
	pages = {3758 – 3769},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137696503&partnerID=40&md5=1a67be5210e7ffbec60080a59713a3f0},
	affiliations = {Social Networks and Human-Centered Computing, TIGP, Academia Sinica, Taiwan; Institute of Service Science, National Tsing Hua University, Taiwan; Institute of Information Science, Academia Sinica, Taiwan},
	abstract = {The use of crowdworkers in NLP research is growing rapidly, in tandem with the exponential increase in research production in machine learning and AI. Ethical discussion regarding the use of crowdworkers within the NLP research community is typically confined in scope to issues related to labor conditions such as fair pay. We draw attention to the lack of ethical considerations related to the various tasks performed by workers, including labeling, evaluation, and production. We find that the Final Rule, the common ethical framework used by researchers, did not anticipate the use of online crowdsourcing platforms for data collection, resulting in gaps between the spirit and practice of human-subjects ethics in NLP research. We enumerate common scenarios where crowdworkers performing NLP tasks are at risk of harm. We thus recommend that researchers evaluate these risks by considering the three ethical principles set up by the Belmont Report. We also clarify some common misconceptions regarding the Institutional Review Board (IRB) application. We hope this paper will serve to reopen the discussion within our community regarding the ethical use of crowdworkers. © 2021 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Crowdsourcing; Philosophical aspects; Risk perception; Community IS; Ethical considerations; Ethical implications; Exponential increase; Labelings; Labour conditions; Machine-learning; Research communities; Research productions; Workers'; Natural language processing systems},
	correspondence_address = {B. Shmueli; Social Networks and Human-Centered Computing, TIGP, Academia Sinica, Taiwan; email: shmueli@iis.sinica.edu.tw},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {978-195408546-6},
	language = {English},
	abbrev_source_title = {NAACL-HLT - Conf. N. Am. Chapter Assoc. Comput. Linguist.: Hum. Lang. Technol., Proc. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL-HLT 2021; Conference date: 6 June 2021 through 11 June 2021; Conference code: 182055}
}

@BOOK{Amour2021231,
	author = {Amour, Lamine and Quiniou, Matthieu and Tucci-Piergiovanni, Sara and Bourak, Hichem and Souihi, Sami},
	title = {uTakeCare: Unlock full decentralization of personal data for a respectful decontainment in the context of COVID-19: Toward a digitally empowered anonymous citizenship},
	year = {2021},
	journal = {Data Science for COVID-19 Volume 1: Computational Perspectives},
	pages = {231 – 253},
	doi = {10.1016/B978-0-12-824536-1.00028-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127648202&doi=10.1016%2fB978-0-12-824536-1.00028-9&partnerID=40&md5=21dbd8029bb3d3d952bd8b94efc8190d},
	affiliations = {LISSI Laboratory, University of Paris-Est Créteil (UPEC), Vitry sur Seine, France; UNESCO Chair “ITEN”, Fondation Maison des Sciences de l’Homme, University of Paris, Paris, France; CEA, LIST, PC 174, Gif-sur-Yvette, France; XHUMANISA & Banlieues Santé (NGO), Paris, France; Edupi (NGO), Paris, France},
	abstract = {To control coronavirus disease 2019 (COVID-19), most countries have opted for a containment policy. When a decision of decontainment has to be taken, a question emerges regarding the digital strategy to adopt: Should we track citizens? All of them or only persons who contracted COVID-19? Should we take measures to protect elderly people or people suffering from co-morbidities? Many applications and approaches have been proposed to ensure public safety in the context of COVID-19. In this chapter, we will start by making an inventory of these applications, discuss strategies and technologies adopted, and categorize them. Thereafter we will present an approach consisting in calculating a vulnerability score to propose a solution for protecting people at risk. Then, we will detail the architecture of “uTakeCare, " an open-source application that we have implemented, as well as the method used to calculate the vulnerability score. This method is based on a belief function theory and machine learning techniques. Finally, we will discuss the ethical and legal issues of this application and the methods to be used to address them (e.g., zero-knowledge proof, smart contracts, etc.) as a way to complement general data protection regulation (roadmap to develop personal data) requirements with ethics-by-design and self-sovereign identity solutions. © 2021 Elsevier Inc. All rights reserved.},
	author_keywords = {Blockchain; COVID-19; Ethics-by-design; Machine learning (ML); Security; Zero-knowledge proof (ZKP)},
	publisher = {Elsevier},
	isbn = {978-012824536-1},
	language = {English},
	abbrev_source_title = {Data Science for COVID-19 Volume 1: Computational Perspectives},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Gonzalez Fabre2021289,
	author = {Gonzalez Fabre, Raul and Camacho Ibáñez, Javier and Tejedor Escobar, Pedro},
	title = {Moral control and ownership in AI systems},
	year = {2021},
	journal = {AI and Society},
	volume = {36},
	number = {1},
	pages = {289 – 303},
	doi = {10.1007/s00146-020-01020-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088369854&doi=10.1007%2fs00146-020-01020-z&partnerID=40&md5=4a8bbb520786e63b85284f6509966331},
	affiliations = {Universidad Pontificia Comillas, Madrid, Spain; Instituto de Ingeniería del Conocimiento, Madrid, Spain},
	abstract = {AI systems are bringing an augmentation of human capabilities to shape the world. They may also drag a replacement of human conscience in large chunks of life. AI systems can be designed to leave moral control in human hands, to obstruct or diminish that moral control, or even to prevent it, replacing human morality with pre-packaged or developed ‘solutions’ by the ‘intelligent’ machine itself. Artificial Intelligent systems (AIS) are increasingly being used in multiple applications and receiving more attention from the public and private organisations. The purpose of this article is to offer a mapping of the technological architectures that support AIS, under the specific focus of the moral agency. Through a literature research and reflection process, the following areas are covered: a brief introduction and review of the literature on the topic of moral agency; an analysis using the BDI logic model (Bratman 1987); an elemental review of artificial ‘reasoning’ architectures in AIS; the influence of the data input and the data quality; AI systems’ positioning in decision support and decision making scenarios; and finally, some conclusions are offered about regarding the potential loss of moral control by humans due to AIS. This article contributes to the field of Ethics and Artificial Intelligence by providing a discussion for developers and researchers to understand how and under what circumstances the ‘human subject’ may, totally or partially, lose moral control and ownership over AI technologies. The topic is relevant because AIS often are not single machines but complex networks of machines that feed information and decisions into each other and to human operators. The detailed traceability of input-process-output at each node of the network is essential for it to remain within the field of moral agency. Moral agency is then at the basis of our system of legal responsibility, and social approval is unlikely to be obtained for entrusting important functions to complex systems under which no moral agency can be identified. © 2020, Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Artificial Intelligence; Autonomous systems; Data bias; Decision support; Machine learning; Moral agency},
	keywords = {Automatic identification; Behavioral research; Complex networks; Decision making; Decision support systems; Intelligent systems; Network architecture; Artificial intelligent; Decision supports; Human capability; Literature researches; Multiple applications; Reflection process; Single- machines; Technological architectures; Quality control},
	correspondence_address = {J. Camacho Ibáñez; Universidad Pontificia Comillas, Madrid, Spain; email: jcamacho@comillas.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{McKeown2021,
	author = {McKeown, Alex and Mourby, Miranda and Harrison, Paul and Walker, Sophie and Sheehan, Mark and Singh, Ilina},
	title = {Ethical Issues in Consent for the Reuse of Data in Health Data Platforms},
	year = {2021},
	journal = {Science and Engineering Ethics},
	volume = {27},
	number = {1},
	doi = {10.1007/s11948-021-00282-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100599783&doi=10.1007%2fs11948-021-00282-0&partnerID=40&md5=2c33262abad68ea40662eca4c066d296},
	affiliations = {Department of Psychiatry, Wellcome Centre for Ethics and Humanities, Warneford Hospital, University of Oxford, Oxford, OX3 7JX, United Kingdom; Centre for Health, Law and Emerging Technologies (HeLEX), University of Oxford, Oxford, United Kingdom; Department of Psyhiatry, Oxford Health NHS Foundation Trust, University of Oxford, Oxford, United Kingdom; Department of Psychiatry, University of Oxford, Oxford, United Kingdom; Ethox, Wellcome Centre for Ethics and Humanities, University of Oxford, Oxford, United Kingdom; Department of Psychiatry, Wellcome Centre for Ethics and Humanities, University of Oxford, Oxford, United Kingdom},
	abstract = {Data platforms represent a new paradigm for carrying out health research. In the platform model, datasets are pooled for remote access and analysis, so novel insights for developing better stratified and/or personalised medicine approaches can be derived from their integration. If the integration of diverse datasets enables development of more accurate risk indicators, prognostic factors, or better treatments and interventions, this obviates the need for the sharing and reuse of data; and a platform-based approach is an appropriate model for facilitating this. Platform-based approaches thus require new thinking about consent. Here we defend an approach to meeting this challenge within the data platform model, grounded in: the notion of ‘reasonable expectations’ for the reuse of data; Waldron’s account of ‘integrity’ as a heuristic for managing disagreement about the ethical permissibility of the approach; and the element of the social contract that emphasises the importance of public engagement in embedding new norms of research consistent with changing technological realities. While a social contract approach may sound appealing, however, it is incoherent in the context at hand. We defend a way forward guided by that part of the social contract which requires public approval for the proposal and argue that we have moral reasons to endorse a wider presumption of data reuse. However, we show that the relationship in question is not recognisably contractual and that the social contract approach is therefore misleading in this context. We conclude stating four requirements on which the legitimacy of our proposal rests. © 2021, The Author(s).},
	author_keywords = {Big data; Consent; Ethics; Health data platforms; Machine learning; Social contract},
	keywords = {Contracts; Humans; Informed Consent; Morals; contract; human; informed consent; morality},
	correspondence_address = {A. McKeown; Department of Psychiatry, Wellcome Centre for Ethics and Humanities, Warneford Hospital, University of Oxford, Oxford, OX3 7JX, United Kingdom; email: alexander.mckeown@psych.ox.ac.uk},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13533452},
	pmid = {33538942},
	language = {English},
	abbrev_source_title = {Sci. Eng. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Lee2021165,
	author = {Lee, Michelle Seng Ah and Floridi, Luciano},
	title = {Algorithmic Fairness in Mortgage Lending: from Absolute Conditions to Relational Trade-offs},
	year = {2021},
	journal = {Minds and Machines},
	volume = {31},
	number = {1},
	pages = {165 – 191},
	doi = {10.1007/s11023-020-09529-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086151018&doi=10.1007%2fs11023-020-09529-4&partnerID=40&md5=dea387338a27e4bcd9993017ff6fb269},
	affiliations = {Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom; Oxford Internet Institute, University of Oxford and Alan Turing Institute, Oxford, United Kingdom},
	abstract = {To address the rising concern that algorithmic decision-making may reinforce discriminatory biases, researchers have proposed many notions of fairness and corresponding mathematical formalizations. Each of these notions is often presented as a one-size-fits-all, absolute condition; however, in reality, the practical and ethical trade-offs are unavoidable and more complex. We introduce a new approach that considers fairness—not as a binary, absolute mathematical condition—but rather, as a relational notion in comparison to alternative decisionmaking processes. Using US mortgage lending as an example use case, we discuss the ethical foundations of each definition of fairness and demonstrate that our proposed methodology more closely captures the ethical trade-offs of the decision-maker, as well as forcing a more explicit representation of which values and objectives are prioritised. © 2020, The Author(s).},
	author_keywords = {Algorithmic fairness; Fairness trade-offs; Machine learning; Mortgage discrimination; Technology ethics},
	keywords = {Commerce; Economic and social effects; Philosophical aspects; Decision makers; Decision making process; Explicit representation; New approaches; Trade off; Decision making},
	correspondence_address = {M.S.A. Lee; Department of Computer Science and Technology, University of Cambridge, Cambridge, United Kingdom; email: michelle.sengah.lee@cl.cam.ac.uk},
	publisher = {Springer Science and Business Media B.V.},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Smith2021,
	author = {Smith, Bryant Walker and Green, Cordel and Jaynes, Tyler L. and Dajani, Lubna and Ferraro, Angelo and Muse, Larissa Paredes and Rossetti, Rosaldo and Paiva, Sara and Ali, Jonathan},
	title = {Smart cities through the lens of human rights},
	year = {2021},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2021-October},
	doi = {10.1109/ISTAS52410.2021.9629191},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123163336&doi=10.1109%2fISTAS52410.2021.9629191&partnerID=40&md5=238b56a9be23d7fb731b33e675e0b16c},
	affiliations = {University of South Carolina, School of Law, United States; Broadcasting Commission, Jamaica; Bioethicist, Standards Developer, AI Governance; Digital Innovation OG; Allternet Ltd.; Large System Architecture Smart Grids Massive Communication Failures, Affective Computing, IoT Instrumentation, Civil and Electrical Systems, Standards Contract, and Financial Negotiations; University of Waterloo, Canada},
	abstract = {Smart cities can be described as a smart system comprising numerous integrated smart systems that fuse and share data, including personal and potentially sensitive private information. Such circumstances could intrude on the rights to privacy, and human dignity, with disclosures potentially harmful to the individual, families, friends, associates, and communities. This workshop will examine ways to promote the best outcomes for the residents and visitors of smart cities through the lens of human rights. Affective rights will also be discussed as requisite to formulating the optimal smart city. Moreover, this workshop will foster discussion around the still relatively nascent technology of Affective Computing, which is the application of AI (Artificial Intelligence), ML (Machine Learning), biometric measurement, sentiment analysis, and psychological factor assessment in determining and interacting with the affective states of the individual. This workshop is open to all stakeholders in smart city development and management, including computer scientists, engineers, smart city integrators, application developers, third party vendors, ethicists, city managers and administrators. It should be especially informative for oversight and governance organizations providing auditing and performance evaluations.  © 2021 IEEE.},
	author_keywords = {collective bargaining; ethics; human rights; Smart cities; sustainable development},
	keywords = {Artificial intelligence; Ethical technology; Sentiment analysis; Social aspects; Urban growth; Affective Computing; Biometric measurements; Human rights; Machine-learning; Private information; Right to privacies; Sentiment analysis; Smart System; Sustainable development; Through the lens; Smart city},
	editor = {Caron B. and Schmitt K.A. and Pearl Z. and Dara R. and Love H.A.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166543580-2},
	language = {English},
	abbrev_source_title = {Int Symp Technol Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 IEEE International Symposium on Society and Technology, ISTAS 2021; Conference date: 28 October 2021 through 31 October 2021; Conference code: 175401; All Open Access, Bronze Open Access}
}

@CONFERENCE{Dreyling2021701,
	author = {Dreyling, Richard and Jackson, Eric and Tammet, Tanel and Labanava, Alena and Pappel, Ingrid},
	title = {Social, Legal, and Technical Considerations for Machine Learning and Artificial Intelligence Systems in Government},
	year = {2021},
	journal = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
	volume = {1},
	pages = {701 – 708},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122979555&partnerID=40&md5=50d4baccbd4bae3de8a6b6c8fc74334e},
	affiliations = {Department of Software Science, School of Information Technologies, Tallinn University of Technology, Akadeemia Tee 15a, Tallinn, Estonia},
	abstract = {Expansion of technology has led to governments increasingly reconciling with advanced technologies like machine learning and artificial intelligence. Research has covered the ethical considerations of AI as well as legal and technical aspects of the operation of these systems within the framework of government. This research is an introduction to the topic in the Estonian context which uses a multidisciplinary inquiry based in the theoretical framework of technology adoption and getting citizens to use these services for their benefit. (Suggest that there are first results as well). Copyright © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {AI Bias; AI Ethics; Artificial Intelligence; e-Governance; e-Government; Estonia; Government Services; Machine Learning; ML Bias; ML Ethics},
	keywords = {e-government; Engineering education; Ethical technology; Information use; AI bias; AI ethic; Artificial intelligence systems; E-governance; e-Government; Estonia; Government services; Machine-learning; ML bias; ML ethic; Machine learning},
	editor = {Filipe J. and Smialek M. and Brodsky A. and Hammoudi S.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21844992},
	isbn = {978-989758509-8},
	language = {English},
	abbrev_source_title = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 23rd International Conference on Enterprise Information Systems, ICEIS 2021; Conference date: 26 April 2021 through 28 April 2021; Conference code: 180136}
}

@BOOK{Pilny2021109,
	author = {Pilny, Andrew},
	title = {Computational Methods for Studying Group Communication},
	year = {2021},
	journal = {The Emerald Handbook of Group and Team Communication Research},
	pages = {109 – 133},
	doi = {10.1108/978-1-80043-500-120211009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85131498858&doi=10.1108%2f978-1-80043-500-120211009&partnerID=40&md5=e8ddd9192ca810b5ca9c7e7ce20165a4},
	affiliations = {University of Illinois, United States; University of Kentucky, United States},
	abstract = {This chapter conceptualizes computational methods across three related, yet distinct approaches: (1) Social Simulation, (2) Data Science, and (3) Big Data. Group communication research is then situated and reviewed along these three lines of research. Although some areas have considerable visibility (e.g., network analysis, text mining), some areas are less visible in group communication research (e.g., Social Simulation, Big Data designs). The chapter concludes with suggestions for issues regarding reliability, validity, and ethics. © 2022 by Emerald Publishing Limited.},
	author_keywords = {Big data; Computational social science; Data science; Machine learning; Scientific computing; Simulations; Trace data},
	publisher = {Emerald Group Publishing Ltd.},
	isbn = {978-180043500-1; 978-180043501-8},
	language = {English},
	abbrev_source_title = {The Emerald Handb. of Group and Team Communication Research},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shen2021850,
	author = {Shen, Hong and Deng, Wesley H. and Chattopadhyay, Aditi and Wu, Zhiwei Steven and Wang, Xu and Zhu, Haiyi},
	title = {Value cards: An educational toolkit for teaching social impacts of machine learning through deliberation},
	year = {2021},
	journal = {FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages = {850 – 861},
	doi = {10.1145/3442188.3445971},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102640873&doi=10.1145%2f3442188.3445971&partnerID=40&md5=bc7ef4c51f1de62dccc0df06e4333b3d},
	affiliations = {Carnegie Mellon University, Pittsburgh, PA, United States; University of California, Berkeley, Berkeley, CA, United States; University of Michigan, Ann Arbor, MI, United States},
	abstract = {Recently, there have been increasing calls for computer science curricula to complement existing technical training with topics related to Fairness, Accountability, Transparency and Ethics (FATE). In this paper, we present Value Cards, an educational toolkit to inform students and practitioners the social impacts of different machine learning models via deliberation. This paper presents an early use of our approach in a college-level computer science course. Through an in-class activity, we report empirical data for the initial effectiveness of our approach. Our results suggest that the use of the Value Cards toolkit can improve students' understanding of both the technical definitions and trade-offs of performance metrics and apply them in real-world contexts, help them recognize the significance of considering diverse social values in the development and deployment of algorithmic systems, and enable them to communicate, negotiate and synthesize the perspectives of diverse stakeholders. Our study also demonstrates a number of caveats we need to consider when using the different variants of the Value Cards toolkit. Finally, we discuss the challenges as well as future applications of our approach. © 2021 Owner/Author.},
	author_keywords = {CS Education; Deliberation; Fairness; Machine Learning; Value Cards},
	keywords = {Machine learning; Students; Transparency; Computer Science course; Computer science curricula; Educational toolkits; Empirical data; Future applications; Machine learning models; Performance metrics; Technical training; Economic and social effects},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038309-7},
	language = {English},
	abbrev_source_title = {FAccT - Proc. ACM Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 4th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2021; Conference date: 3 March 2021 through 10 March 2021; Conference code: 167464; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Bracanović202163,
	author = {Bracanović, Tomislav},
	title = {Artificial intelligence, medicine and autonomy; [Umjetna inteligencija, medicina i autonomija]},
	year = {2021},
	journal = {Nova Prisutnost},
	volume = {19},
	number = {1},
	pages = {63 – 76},
	doi = {10.31192/np.19.1.5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85106886012&doi=10.31192%2fnp.19.1.5&partnerID=40&md5=fc09f9c8ac87c87900339427663babf2},
	affiliations = {Institute of Philosophy, Ulica grada Vukovara 54, Zagreb, HR-10000, Croatia},
	abstract = {The paper considers the question whether artificial intelligence-based diagnostic systems (AIBDS) pose a threat to patient autonomy as one of the central principles of biomedical ethics. The first part of the paper explains what AIBDS are and how they work, with an emphasis on machine learning technology and its property of non-transparency. The second part of the paper presents several paradigmatic views on AIBDS as a threat to patient autonomy, with reference to the standard analysis according to which this autonomy includes (at least) three components: intentionality, freedom from constraints and understanding. In the third part of the paper, the arguments pro et contra of the thesis about AIBDS as a threat to autonomy are considered from the perspective of patients, while in the fourth part of the paper they are considered from the perspective of physicians. The paper shows how complex the discussion of these issues can be and what argumentative tools can be made available to opposing parties. © 2021 Christian Academic Circle. All rights reserved.},
	author_keywords = {Artificial intelligence; Autonomy; Biomedical ethics; Diagnostic systems; Machine learning; Non-transparency},
	correspondence_address = {T. Bracanović; Institute of Philosophy, Zagreb, Ulica grada Vukovara 54, HR-10000, Croatia; email: tbracanovic@ifzg.hr.},
	publisher = {Christian Academic Circle},
	issn = {13342312},
	language = {Croatian},
	abbrev_source_title = {Nova Prisut.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Madariaga2021725,
	author = {Madariaga, Ainhoa and Kasherman, Lawrence and Karakasis, Katherine and Degendorfer, Pamela and Heesters, Ann M. and Xu, Wei and Husain, Shahid and Oza, Amit M.},
	title = {Optimizing clinical research procedures in public health emergencies},
	year = {2021},
	journal = {Medicinal Research Reviews},
	volume = {41},
	number = {2},
	pages = {725 – 738},
	doi = {10.1002/med.21749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096641956&doi=10.1002%2fmed.21749&partnerID=40&md5=3735327224eaf39f741b18d6ac1c6976},
	affiliations = {Division of Medical Oncology & Hematology, Princess Margaret Cancer Centre, University of Toronto, Toronto, ON, Canada; Bioethics Program and The Institute for Education Research, University Health Network, University of Toronto, Toronto, ON, Canada; Division of Biostatistics, Princess Margaret Cancer Centre, University of Toronto, Toronto, ON, Canada; Division of Infectious Disease, Department of Medicine, University Health Network, University of Toronto, Toronto, ON, Canada},
	abstract = {Public Health Emergencies of International Concern, such as the coronavirus disease 2019 pandemic, have a devastating impact on an individual and societal level, and there is an urgent need to learn, understand and bridge the therapeutic gap at a time of extreme stress on the patient, health care systems and staff. Well-designed, controlled clinical trials play a crucial role in the discovery of novel diagnostic and management strategies; however, these catastrophic circumstances pose unique challenges in initiating research studies at institutional, national, and international levels, highlighting the importance of a coordinated, collaborative approach. This review discusses key elements necessary to consider for developing clinical trials within a Public Health Emergency setting. © 2020 Wiley Periodicals LLC},
	author_keywords = {artificial intelligence; clinical trial; COVID-19; ethics; master protocols; N-of-1; platform studies; Public Health Emergency; randomized trials; umbrella trial},
	keywords = {Biomedical Research; Clinical Trials as Topic; COVID-19; Emergencies; Humans; Public Health; SARS-CoV-2; anticoagulant agent; antivirus agent; apremilast; ascorbic acid; azithromycin; beta interferon; cenicriviroc; chloroquine; convalescent plasma; dexamethasone; doxycycline; hydroxychloroquine; icatibant; immunomodulating agent; lopinavir plus ritonavir; placebo; razuprotafib; regn-cov2; remdesivir; ruxolitinib; tocilizumab; clinical research; clinical trial (topic); coronavirus disease 2019; digital technology; electronic medical record; good clinical practice; human; machine learning; master study; medical documentation; medical record; natural language processing; observational study; pandemic; policy; public health problem; research ethics; resource management; Review; single-case study; study design; telemonitoring; emergency; epidemiology; ethics; medical research; physiology; public health; virology},
	correspondence_address = {A.M. Oza; Division of Medical Oncology & Hematology, Princess Margaret Cancer Centre, University of Toronto, Toronto, Canada; email: amit.oza@uhn.ca},
	publisher = {John Wiley and Sons Inc},
	issn = {01986325},
	coden = {MRRED},
	pmid = {33174617},
	language = {English},
	abbrev_source_title = {Med. Res. Rev.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Currie2021120,
	author = {Currie, Geoffrey and Hawk, K Elizabeth},
	title = {Ethical and Legal Challenges of Artificial Intelligence in Nuclear Medicine},
	year = {2021},
	journal = {Seminars in Nuclear Medicine},
	volume = {51},
	number = {2},
	pages = {120 – 125},
	doi = {10.1053/j.semnuclmed.2020.08.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090937735&doi=10.1053%2fj.semnuclmed.2020.08.001&partnerID=40&md5=671a9bcf86743b045bf3965f1c972db3},
	affiliations = {School of Dentistry & Health Sciences, Charles Sturt University, Wagga Wagga, Australia; Stanford University, Stanford, CA, United States},
	abstract = {Artificial intelligence (AI) in nuclear medicine has gained significant traction and promises to be a disruptive, but innovative, technology. Recent developments in artificial neural networks, machine learning, and deep learning have ignited debate with respect to ethical and legal challenges associated with the use of AI in healthcare and medicine. While AI in nuclear medicine has the potential to improve workflow and productivity, and enhance clinical and research capabilities, there remains a professional responsibility to the profession and to patients: ethical, social, and legal. Enthusiasm to embrace new technology should not displace responsibilities for the ethical, social, and legal application of technology. This is especially true in relation to data usage, the algorithms applied, and how algorithms are used in practice. Governance of software and algorithms used for detection (segmentation) and/or diagnosis (classification) of disease using medical images requires rigorous evidence-based regulation. A number of frameworks have been developed for ethical application of AI generally in society and in radiology. For nuclear medicine, consideration needs to be given to beneficence, nonmaleficence, fairness and justice, safety, reliability, data security, privacy and confidentiality, mitigation of bias, transparency, explainability, and autonomy. AI is merely a tool, how it is utilised is a human choice. There is potential for AI applications to enhance clinical and research practice in nuclear medicine and concurrently produce deeper, more meaningful interactions between the physicians and the patient. Nonetheless ethical, legal, and social challenges demand careful attention and formulation of standards/guidelines for nuclear medicine. © 2020 Elsevier Inc.},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Nuclear Medicine; Reproducibility of Results; algorithm; artificial intelligence; beneficence; clinical practice; confidentiality; decision making; doctor patient relationship; ethics; evidence based practice; human; information security; justice; legal aspect; nonmaleficence; nuclear medicine; patient safety; personal experience; physician; privacy; reliability; Review; safety; society; health care delivery; reproducibility},
	correspondence_address = {G. Currie; School of Dentistry & Health Sciences, Charles Sturt University, Wagga Wagga, Australia; email: gcurrie@csu.edu.au},
	publisher = {W.B. Saunders},
	issn = {00012998},
	coden = {SMNMA},
	pmid = {33509368},
	language = {English},
	abbrev_source_title = {Semin. Nucl. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@ARTICLE{Tsamados202197,
	author = {Tsamados, Andreas and Aggarwal, Nikita and Cowls, Josh and Morley, Jessica and Roberts, Huw and Taddeo, Mariarosaria and Floridi, Luciano},
	title = {The Ethics of Algorithms: Key Problems and Solutions},
	year = {2021},
	journal = {Philosophical Studies Series},
	volume = {144},
	pages = {97 – 123},
	doi = {10.1007/978-3-030-81907-1_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118784535&doi=10.1007%2f978-3-030-81907-1_8&partnerID=40&md5=74d3158f1e9bca2a0d4f4b4afe21e602},
	affiliations = {Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; Faculty of Law, Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; Alan Turing Institute, London, United Kingdom},
	abstract = {Research on the ethics of algorithms has grown substantially over the past decade. Alongside the exponential development and application of machine learning algorithms, new ethical problems and solutions relating to their ubiquitous use in society have been proposed. This article builds on a review of the ethics of algorithms published in 2016 (Mittelstadt et al. Big Data Soc 3(2). https://doi.org/10.1177/2053951716679679, 2016). The golas are to contribute to the debate on the identification and analysis of the ethical implications of algorithms, to provide an updated analysis of epistemic and normative concerns, and to offer actionable guidance for the governance of the design, development and deployment of algorithms. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Algorithm; Artificial intelligence; Autonomy; Digital ethics; Explainability; Fairness; Machine learning; Privacy; Responsibility; Transparency; Trust},
	correspondence_address = {L. Floridi; Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; email: luciano.floridi@oii.ox.ac.uk},
	publisher = {Springer Nature},
	issn = {09218599},
	language = {English},
	abbrev_source_title = {Philos. Stud. Ser.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Haendel2021427,
	author = {Haendel, Melissa A. and Chute, Christopher G. and Bennett, Tellen D. and Eichmann, David A. and Guinney, Justin and Kibbe, Warren A. and Payne, Philip R.O. and Pfaff, Emily R. and Robinson, Peter N. and Saltz, Joel H. and Spratt, Heidi and Suver, Christine and Wilbanks, John and Wilcox, Adam B. and Williams, Andrew E. and Wu, Chunlei and Blacketer, Clair and Bradford, Robert L. and Cimino, James J. and Clark, Marshall and Colmenares, Evan W. and Francis, Patricia A. and Gabriel, Davera and Graves, Alexis and Hemadri, Raju and Hong, Stephanie S. and Hripscak, George and Jiao, Dazhi and Klann, Jeffrey G. and Kostka, Kristin and Lee, Adam M. and Lehmann, Harold P. and Lingrey, Lora and Miller, Robert T. and Morris, Michele and Murphy, Shawn N. and Natarajan, Karthik and Palchuk, Matvey B. and Sheikh, Usman and Solbrig, Harold and Visweswaran, Shyam and Walden, Anita and Walters, Kellie M. and Weber, Griffin M. and Zhang, Xiaohan Tanner and Zhu, Richard L. and Amor, Benjamin and Girvin, Andrew T. and Manna, Amin and Qureshi, Nabeel and Kurilla, Michael G. and Michael, Sam G. and Portilla, Lili M. and Rutter, Joni L. and Austin, Christopher P. and Gersing, Ken R. and Al-Shukri, Shaymaa and Alaoui, Adil and Baghal, Ahmad and Banning, Pamela D. and Barbour, Edward M. and Becich, Michael J. and Beheshti, Afshin and Bernard, Gordon R. and Bhattacharyya, Sharmodeep and Bissell, Mark M. and Boulware, L. Ebony and Bozzette, Samuel and Brown, Donald E. and Buse, John B. and Bush, Brian J. and Callahan, Tiffany J. and Campion, Thomas R. and Casiraghi, Elena and Chaudhry, Ammar A. and Chen, Guanhua and Chen, Anjun and Clifford, Gari D. and Coffee, Megan P. and Conlin, Tom and Cook, Connor and Crandall, Keith A. and Deacy, Mariam and Dietz, Racquel R. and Dobbins, Nicholas J. and Elkin, Peter L. and Embi, Peter J. and Facelli, Julio C. and Fecho, Karamarie and Feng, Xue and Foraker, Randi E. and Gal, Tamas S. and Ge, Linqiang and Golovko, George and Gouripeddi, Ramkiran and Greene, Casey S. and Gupta, Sangeeta and Gupta, Ashish and Hajagos, Janos G. and Hanauer, David A. and Harper, Jeremy Richard and Harris, Nomi L. and Harris, Paul A. and Hassan, Mehadi R. and He, Yongqun and Hill, Elaine L. and Hoatlin, Maureen E. and Holmes, Kristi L. and Hughes, LaRon and Jawa, Randeep S. and Jiang, Guoqian and Jing, Xia and Joachimiak, Marcin P. and Johnson, Steven G. and Kamaleswaran, Rishikesan and Kannampallil, Thomas George and Kanter, Andrew S. and Kavuluru, Ramakanth and Khanipov, Kamil and Kharrazi, Hadi and Kim, Dongkyu and Knosp, Boyd M. and Krishnan, Arunkumar and Kurc, Tahsin and Lai, Albert M. and Lambert, Christophe G. and Larionov, Michael and Lee, Stephen B. and Lesh, Michael D. and Lichtarge, Olivier and Liu, John and Liu, Sijia and Liu, Hongfang and Loomba, Johanna J. and Mallipattu, Sandeep K. and Mamillapalli, Chaitanya K. and Mason, Christopher E. and Mathew, Jomol P. and McClay, James C. and McMurry, Julie A. and Mehta, Paras P. and Mendelevitch, Ofer and Meystre, Stephane and Moffitt, Richard A. and Moore, Jason H. and Morizono, Hiroki and Mungall, Christopher J. and Munoz-Torres, Monica C. and Neumann, Andrew J. and Ning, Xia and Nyland, Jennifer E. and O’Keefe, Lisa and O’Malley, Anna and O’Neil, Shawn T. and Obeid, Jihad S. and Ogburn, Elizabeth L. and Phuong, Jimmy and Posada, Jose D. and Prasanna, Prateek and Prior, Fred and Prosser, Justin and Purnell, Amanda Lienau and Rahnavard, Ali and Ramadas, Harish and Reese, Justin T. and Robinson, Jennifer L. and Rubin, Daniel L. and Rutherford, Cody D. and Sadhu, Eugene M. and Saha, Amit and Saltz, Mary Morrison and Schaffter, Thomas and Schleyer, Titus K.L. and Setoguchi, Soko and Shah, Nigam H. and Sharafeldin, Noha and Sholle, Evan and Silverstein, Jonathan C. and Solomonides, Anthony and Solway, Julian and Su, Jing and Subbian, Vignesh and Tak, Hyo Jung and Taylor, Bradley W. and Thessen, Anne E. and Thomas, Jason A. and Topaloglu, Umit and Unni, Deepak R. and Vogelstein, Joshua T. and Volz, Andrõa M. and Williams, David A. and Wilson, Kelli M. and Xu, Clark B. and Xu, Hua and Yan, Yao and Zak, Elizabeth and Zhang, Lanjing and Zhang, Chengda and Zheng, Jingyi},
	title = {The National COVID Cohort Collaborative (N3C): Rationale, design, infrastructure, and deployment},
	year = {2021},
	journal = {Journal of the American Medical Informatics Association},
	volume = {28},
	number = {3},
	pages = {427 – 443},
	doi = {10.1093/jamia/ocaa196},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091994547&doi=10.1093%2fjamia%2focaa196&partnerID=40&md5=a4bc4ed7e072ae40e7a2bd0cced2c385},
	affiliations = {Oregon Clinical and Translational Research Institute, Oregon Health and Science University, Portland, OR, United States; Translational and Integrative Sciences Center, Department of Molecular Toxicology, Oregon State University, Corvallis, OR, United States; Schools of Medicine, Public Health, and Nursing, Johns Hopkins University, Baltimore, MD, United States; Section of Informatics and Data Science, Department of Pediatrics, University of Colorado School of Medicine, University of Colorado, Aurora, CO, United States; School of Library and Information Science, The University of Iowa, Iowa City, IA, United States; Sage Bionetworks, Seattle, WA, United States; Duke University, Durham, NC, United States; Institute for Informatics, Washington University in St. Louis, Saint Louis, MO, United States; North Carolina Translational and Clinical Sciences Institute (NC TraCS), University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; Jackson Laboratory, Bar Harbor, ME, United States; Department of Biomedical Informatics, Stony Brook University, Stony Brook, NY, United States; University of Texas Medical Branch, Galveston, TX, United States; University of Washington, Seattle, WA, United States; Tufts Medical Center Clinical and Translational Science Institute, Tufts Medical Center, Boston, MA, United States; Department of Integrative Structural and Computational Biology, The Scripps Research Institute, La Jolla, CA, United States; Janssen Research and Development, LLC, Raritan, NJ, United States; University of Alabama-Birmingham, Birmingham, AL, United States; Department of Pharmaceutical Outcomes and Policy, University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; Johns Hopkins University School of Medicine, Baltimore, MD, United States; University of Iowa Institute for Clinical and Translational Science, The University of Iowa, Iowa City, IA, United States; National Center for Advancing Translational Science, Bethesda, MD, United States; Department of Biomedical Informatics, Columbia University, New York, NY, United States; Harvard Medical School, Boston, MA, United States; IQVIA, Durham, NC, United States; University of North Carolina at Chapel Hill, Chapel Hill, NC, United States; TriNetX, Cambridge, MA, United States; Tufts Clinical and Translational Science Institute, Tufts University, Boston, MA, United States; Department of Biomedical Informatics, University of Pittsburgh, Pittsburgh, PA, United States; Mass General Brigham, Boston, MA, United States; Irving Medical Center, Columbia University, New York, NY, United States; Department of Biomedical Informatics, Harvard Medical School, Boston, MA, United States; Palantir Technologies, Palo Alto, CA, United States; Division of Clinical Innovation, National Center for Advancing Translational Science, Bethesda, MD, United States; National Center for Advancing Translational Sciences, National Institutes of Health, Bethesda, MD, United States; Office of Strategic Alliances, National Center for Advancing Translational Sciences, National Institutes of Health, Bethesda, MD, United States; Office of the Director, National Center for Advancing Translational Science, Bethesda, MD, United States; University of Arkansas for Medical Sciences, Little Rock, AR, United States; Georgetown University, Washington, DC, United States; 3M Health Information Systems, St. Paul, MN, United States; University of Illinois at Chicago, Chicago, IL, United States; Department of Biomedical Informatics, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; KBR, Space Biosciences Division, NASA Ames Research Center, Moffett Field, CA, United States; Vanderbilt University Medical Center, Nashville, TN, United States; Oregon State University, Corvallis, OR, United States; School of Data Science, University of Virginia, Charlottesville, VA, United States; University of North Carolina School of Medicine, Chapel Hill, NC, United States; Virginia Commonwealth University, Richmond, VA, United States; Computational Bioscience, University of Colorado, Anschutz Medical Campus, Boulder, CO, United States; Weill Cornell Medicine, Cornell University, New York, NY, United States; Computer Science Department, Universitá degli Studi di Milano, Milan, Italy; City of Hope National Medical Center, Duarte, CA, United States; University of Wisconsin-Madison, Madison, WI, United States; Web2express.org; Emory University, Georgia Institute of Technology, Atlanta, GA, United States; Grossman School of Medicine, New York University, New York, NY, United States; Computational Biology Institute, Department of Biostatistics and Bioinformatics, Milken Institute School of Public Health, The George Washington University, Washington, DC, United States; Department of Biomedical Informatics, University at Buffalo, Buffalo, NY, United States; Department of Veterans Affairs, New York, NY, United States; Faculty of Engineering, University of Southern Denmark, Odense, Denmark; Regenstrief Institute, Indianapolis, IN, United States; Indiana University School of Medicine, Indianapolis, IN, United States; Center for Clinical and Transnational Science, The University of Utah, Salt Lake City, UT, United States; Copperline Professional Solutions, LLC, Chapel Hill, NC, United States; Department of Biomedical Engineering, University of Virginia, Charlottesville, VA, United States; Washington University in St. Louis School of Medicine, St. Louis, MO, United States; Auburn University, Auburn, AL, United States; The University of Texas Medical Branch, Galveston, TX, United States; University of Utah, Salt Lake City, UT, United States; Department of Systems Pharmacology and Translational Therapeutics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Delaware State University, Dover, DE, United States; Stony Brook University, Stony Brook, NY, United States; University of Michigan, Ann Arbor, MI, United States; Environmental Genomics and Systems Biology Division, Lawrence Berkeley National Laboratory, Berkeley, CA, United States; University of Michigan Medical School, Ann Arbor, MI, United States; University of Rochester Medical Center, Rochester, NY, United States; Hoatlin Biomedical Consulting, Portland, OR, United States; Northwest-ern University Feinberg School of Medicine, Chicago, IL, United States; Center for Translational Data Science, University of Chicago, Chicago, IL, United States; Renaissance School of Medicine, Stony Brook University, Stony Brook, NY, United States; Mayo Clinic, Rochester, MN, United States; Clemson University, Clemson, SC, United States; University of Minnesota, Minneapolis, MN, United States; Emory University School of Medicine, Atlanta, GA, United States; Columbia University, New York, NY, United States; University of Kentucky, Lexington, KY, United States; Johns Hopkins School of Public Health, Baltimore, MD, United States; Children’s National Hospital, Washington, DC, United States; Division of Gastroenterology and Hepatology, Johns Hopkins School of Medicine, Baltimore, MD, United States; Biomedical Informatics, Stony Brook University, Stony Brook, NY, United States; Department of Internal Medicine, Center for Global Health, Division of Translational Informatics, University of New Mexico Health Sciences Center, Albuquerque, NM, United States; Spok, Inc., Springfield, VA, United States; University of Saskatchewan (Regina), Saskatoon, SK, Canada; University of California San Francisco, San Francisco, CA, United States; Synte-gra.io, San Carlos, CA, United States; Baylor College of Medicine, Houston, TX, United States; Optum, Eden Prairie, MN, United States; Department of Health Sciences Research, Mayo Clinic, Rochester, MN, United States; University of Virginia, Charlottesville, VA, United States; Springfield Clinic, Springfield, IL, United States; School of Medicine and Public Health, University of Wisconsin-Madison, Madison, WI, United States; University of Nebraska Medical Center, Omaha, NE, United States; College of Medicine, The University of Arizona, Tucson, AZ, United States; Medical University of South Carolina, Charleston, SC, United States; Institute for Biomedical Informatics, University of Pennsylvania, Philadelphia, PA, United States; The Ohio State University, Columbus, OH, United States; Penn State College of Medicine, Hershey, PA, United States; Northwestern University, Chicago, IL, United States; Department of Public Health Sciences, Medical University of South Carolina, Charleston, SC, United States; Department of Biostatistics, Johns Hopkins Bloomberg School of Public Health, Baltimore, MD, United States; School of Medicine, Division of Biomedical and Health Informatics, University of Washington, Seattle, WA, United States; Stanford University, Stanford, CA, United States; VHA Innovation Ecosystem, Washington, DC, United States; Noblis, Inc., Reston, VA, United States; Wake Forest Baptist Medical, Winston Salem, NC, United States; Biomedical and Health Sciences, Rutgers University, New Brunswick, NJ, United States; School of Medicine, University of Alabama at Birmingham, Birmingham, AL, United States; Research Institute, NorthShore University HealthSystem, Evanston, IL, United States; University of Chicago, Chicago, IL, United States; School of Medicine, Wake Forest University, Winston Salem, NC, United States; College of Engineering, The University of Arizona, Tucson, AZ, United States; Department of Health Services Research and Administration, University of Nebraska Medical Center, Lincoln, NE, United States; Medical College of Wisconsin, Wauwatosa, WI, United States; The University of Texas Health Science Center at Houston, Houston, TX, United States; Molecular Engineering and Sciences Institute, University of Washington, Seattle, Seattle, WA, United States; University of Iowa, Iowa City, IA, United States; Rutgers University, New Brunswick, NJ, United States; Princeton Medical Center, Plainsboro, NJ, United States; Oregon Health & Science University, Portland, OR, United States},
	abstract = {Objective: Coronavirus disease 2019 (COVID-19) poses societal challenges that require expeditious data and knowledge sharing. Though organizational clinical data are abundant, these are largely inaccessible to outside researchers. Statistical, machine learning, and causal analyses are most successful with large-scale data beyond what is available in any given organization. Here, we introduce the National COVID Cohort Collaborative (N3C), an open science community focused on analyzing patient-level data from many centers. Materials and Methods: The Clinical and Translational Science Award Program and scientific community created N3C to overcome technical, regulatory, policy, and governance barriers to sharing and harmonizing individual-level clinical data. We developed solutions to extract, aggregate, and harmonize data across organizations and data models, and created a secure data enclave to enable efficient, transparent, and reproducible collaborative analytics. Results: Organized in inclusive workstreams, we created legal agreements and governance for organizations and researchers; data extraction scripts to identify and ingest positive, negative, and possible COVID-19 cases; a data quality assurance and harmonization pipeline to create a single harmonized dataset; population of the secure data enclave with data, machine learning, and statistical analytics tools; dissemination mechanisms; and a synthetic data pilot to democratize data access. Conclusions: The N3C has demonstrated that a multisite collaborative learning health network can overcome barriers to rapidly build a scalable infrastructure incorporating multiorganizational clinical data for COVID-19 analytics. We expect this effort to save lives by enabling rapid collaboration among clinicians, researchers, and data scientists to identify treatments and specialized care and thereby reduce the immediate and long-Term impacts of COVID-19.  © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of the American Medical Informatics Association.},
	author_keywords = {clinical data model harmonization; collaborative analytics; COVID-19; EHR data; open science; SARS-CoV-2},
	keywords = {Computer Security; COVID-19; Data Analysis; Data Science; Ethics Committees, Research; Government Regulation; Humans; Information Dissemination; Intersectoral Collaboration; National Institutes of Health (U.S.); United States; Article; clinical study; cohort analysis; coronavirus disease 2019; data aggregation; data extraction; data privacy; data quality; ethics; human; information processing; information security; institutional review; machine learning; organization; patient coding; phenotype; publication; statistical analysis; computer security; data analysis; government regulation; information dissemination; intersectoral collaboration; national health organization; organization and management; professional standard; United States},
	correspondence_address = {M.A. Haendel; Linus Pauling Science Center, Corvallis, 97331, United States; email: melissa@tislab.org; C.G. Chute; Johns Hopkins University, Baltimore, 2024 E Monument St, 21287, United States; email: chute@jhu.edu},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	pmid = {32805036},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 168; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Malik2021,
	author = {Malik, Avni and Patel, Paranjay and Ehsan, Lubaina and Guleria, Shan and Hartka, Thomas and Adewole, Sodiq and Syed, Sana},
	title = {Ten simple rules for engaging with artificial intelligence in biomedicine},
	year = {2021},
	journal = {PLoS Computational Biology},
	volume = {17},
	number = {2},
	doi = {10.1371/JOURNAL.PCBI.1008531},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101438143&doi=10.1371%2fJOURNAL.PCBI.1008531&partnerID=40&md5=b6e40b6c32b34b29f3dcfcda96c96ef4},
	affiliations = {College of Arts and Sciences, University of Virginia, Charlottesville, VA, United States; School of Medicine, University of Virginia, Charlottesville, VA, United States; Departmentof Pediatrics, Division of Gastroenterology, Hepatology, and Nutrition, School of Medicine, University ofVirginia, Charlottesville, VA, United States; Department of Emergency Medicine, School ofMedicine, University of Virginia, Charlottesville, VA, United States; Department of Systemsand Information Engineering, School of Data Science, University of Virginia, Charlottesville, VA, United States},
	keywords = {Artificial Intelligence; Biomedical Technology; Computational Biology; Deep Learning; Humans; Machine Learning; Vocabulary; Simple++; algorithm; artificial intelligence; automation; biomedicine; clinical medicine; decision making; deep learning; diabetic retinopathy; electronic medical record; genomics; health care; health care facility; health care system; human; image analysis; machine learning; medical error; patient care; primary medical care; proteomics; Review; task performance; biology; ethics; medical technology; vocabulary; Artificial intelligence},
	correspondence_address = {S. Syed; Department of Systemsand Information Engineering, School of Data Science, University of Virginia, Charlottesville, United States; email: sana.syed@virginia.edu},
	publisher = {Public Library of Science},
	issn = {1553734X},
	pmid = {33571194},
	language = {English},
	abbrev_source_title = {PLoS Comput. Biol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Bozkurt20211,
	author = {Bozkurt, Aras and Karadeniz, Abdulkadir and Baneres, David and Guerrero-Roldán, Ana Elena and Rodríguez, M. Elena},
	title = {Artificial intelligence and reflections from educational landscape: A review of AI studies in half a century},
	year = {2021},
	journal = {Sustainability (Switzerland)},
	volume = {13},
	number = {2},
	pages = {1 – 16},
	doi = {10.3390/su13020800},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099871578&doi=10.3390%2fsu13020800&partnerID=40&md5=f90c303e21f48fa1e7a563ae45b8cb09},
	affiliations = {Open Education Faculty, Anadolu University, Eskişehir, 26470, Turkey; College of Human Sciences, University of South Africa (UNISA), Pretoria, 0003, South Africa; ELearn Center, Universitat Oberta de Catalunya, Barcelona, 08018, Spain; Faculty of Computer Science, Multimedia and Telecommunications, Universitat Oberta de Catalunya, Barcelona, 08018, Spain},
	abstract = {Artificial intelligence (AI) has penetrated every layer of our lives, and education is not immune to the effects of AI. In this regard, this study examines AI studies in education in half a century (1970-2020) through a systematic review approach and benefits from social network analysis and text-mining approaches. Accordingly, the research identifies three research clusters (1) artificial intelligence, (2) pedagogical, and (3) technological issues, and suggests five broad research themes which are (1) adaptive learning and personalization of education through AI-based practices, (2) deep learning and machine Learning algorithms for online learning processes, (3) Educational human-AI interaction, (4) educational use of AI-generated data, and (5) AI in higher education. The study also highlights that ethics in AI studies is an ignored research area. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {AI; AI in education; AIEd; Artificial intelligence; Deep learning; Education; Machine learning},
	keywords = {algorithm; artificial intelligence; education; ethics; learning; literature review; network analysis; social network},
	correspondence_address = {A. Karadeniz; Open Education Faculty, Anadolu University, Eskişehir, 26470, Turkey; email: akaradeniz@uoc.edu},
	publisher = {MDPI AG},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Schneider20211,
	author = {Schneider, Bertrand and Dowell, Nia and Thompson, Kate},
	title = {Collaboration analytics — current state and potential futures},
	year = {2021},
	journal = {Journal of Learning Analytics},
	volume = {8},
	number = {1},
	pages = {1 – 12},
	doi = {10.18608/JLA.2021.7447},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120728331&doi=10.18608%2fJLA.2021.7447&partnerID=40&md5=e7d44615666a2a6dbae01182475175ec},
	affiliations = {Harvard University, Graduate School of Education, 13 Appian Way, Longfellow Hall 333, Cambridge, 02138, MA, United States; University of California, Irvine, EDUC 3361A, Irvine, 92697, CA, United States; The University of Melbourne, Melbourne, VIC, Australia},
	abstract = {This special issue brings together a rich collection of papers in collaboration analytics. With topics including theory building, data collection, modelling, designing frameworks, and building machine learning models, this issue represents some of the most active areas of research in the field. In this editorial, we summarize the papers; discuss the nature of collaboration analytics based on this body of work; describe the associated opportunities, challenges, and risks; and depict potential futures for the field. We conclude by discussing the implications of this special issue for collaboration analytics. © 2021, UTS ePRESS. All rights reserved.},
	author_keywords = {Adaptive systems; Collaborative learning; Data modelling; Learning analytics; Privacy and ethics; Theory},
	correspondence_address = {B. Schneider; Harvard University, Graduate School of Education, Cambridge, 13 Appian Way, Longfellow Hall 333, 02138, United States; email: bertrand_schneider@gse.harvard.edu},
	publisher = {UTS ePRESS},
	issn = {19297750},
	language = {English},
	abbrev_source_title = {J. Learn. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Gold Open Access}
}

@CONFERENCE{Beretta2021794,
	author = {Beretta, Elena and Vetrò, Antonio and Lepri, Bruno and Martin, Juan Carlos De},
	title = {Detecting discriminatory risk through data annotation based on Bayesian inferences},
	year = {2021},
	journal = {FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages = {794 – 804},
	doi = {10.1145/3442188.3445940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102650796&doi=10.1145%2f3442188.3445940&partnerID=40&md5=226cf4968bd63d54eccc5a01835c2015},
	affiliations = {Nexa Center for Internet and Society, Department of Control and Computer Engineering, Politecnico di Torino, Turin, Italy; Fondazione Bruno Kessler, Trento, Italy},
	abstract = {Thanks to the increasing growth of computational power and data availability, the research in machine learning has advanced with tremendous rapidity. Nowadays, the majority of automatic decision making systems are based on data. However, it is well known that machine learning systems can present problematic results if they are built on partial or incomplete data. In fact, in recent years several studies have found a convergence of issues related to the ethics and transparency of these systems in the process of data collection and how they are recorded. Although the process of rigorous data collection and analysis is fundamental in the model design, this step is still largely overlooked by the machine learning community. For this reason, we propose a method of data annotation based on Bayesian statistical inference that aims to warn about the risk of discriminatory results of a given data set. In particular, our method aims to deepen knowledge and promote awareness about the sampling practices employed to create the training set, highlighting that the probability of success or failure conditioned to a minority membership is given by the structure of the data available. We empirically test our system on three datasets commonly accessed by the machine learning community and we investigate the risk of racial discrimination. © 2021 ACM.},
	author_keywords = {Data ethics; Data labeling; Human annotation; Machine learning; Race discrimination; Sampling bias},
	keywords = {Bayesian networks; Decision making; Discriminators; Machine learning; Transparency; Automatic decision; Bayesian inference; Bayesian statistical inference; Computational power; Data availability; Machine learning communities; Probability of success; Racial discriminations; Data acquisition},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038309-7},
	language = {English},
	abbrev_source_title = {FAccT - Proc. ACM Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 4th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2021; Conference date: 3 March 2021 through 10 March 2021; Conference code: 167464; All Open Access, Green Open Access}
}

@CONFERENCE{Ximenes2021,
	author = {Ximenes, Bianca Helena and Ramalho, Geber L.},
	title = {Concrete ethical guidelines and best practices in machine learning development},
	year = {2021},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2021-January},
	doi = {10.1109/ISTAS52410.2021.9728979},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85127511762&doi=10.1109%2fISTAS52410.2021.9728979&partnerID=40&md5=834e39117f0c50100a6b3b04a48f9331},
	affiliations = {Universidade Federal de Pernambuco, Centro de Informática, Recife, Brazil},
	abstract = {The rapid adoption of Machine Learning (ML) in human's daily lives and activities is raising ethical dilemmas and issues. A form of minimizing possible harm to society is to provide guidance to ML developers, who can build systems that are ethical by design. Unfortunately, developers do not have proper ethical formation in regular undergraduate courses, and the existing documents, despite being abundant, are vague and focused on governments and corporations rather than on individual developers. This paper proposes ethical recommendations, 18 concrete guidelines and 24 best practices, for developers. These recommendations were formulated in a focus group and validated quantitatively in a survey with over 130 ML developers working in both industry and Academia. This paper also investigates the state of adoption of such recommendations and compares what developers think they should do to achieve more ethical results versus what they actually do. © 2021 IEEE.},
	author_keywords = {best practices; developers; Ethical Machine Learning; ethics; focus group; guidelines; survey},
	keywords = {Concretes; Ethical technology; Machine learning; Best practices; Daily activity; Daily lives; Developer; Ethical dilemma; Ethical issues; Ethical machine learning; Focus groups; Guideline; Machine-learning; Surveys},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	language = {English},
	abbrev_source_title = {Int Symp Technol Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2021 IEEE International Symposium on Society and Technology, ISTAS 2021; Conference date: 28 October 2021 through 31 October 2021; Conference code: 175401}
}

@BOOK{Giger20211691,
	author = {Giger, Maryellen L.},
	title = {AI/Machine Learning in Medical Imaging},
	year = {2021},
	journal = {Molecular Imaging: Principles and Practice},
	pages = {1691 – 1702},
	doi = {10.1016/B978-0-12-816386-3.00052-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85129038554&doi=10.1016%2fB978-0-12-816386-3.00052-1&partnerID=40&md5=8b6a0d175d2e201cfec65f4e1edc28a0},
	affiliations = {Department of Radiology, The University of Chicago, Chicago, IL, United States},
	abstract = {Artificial intelligence (AI), or machine intelligence, can be broadly viewed as the use of computers, instead of humans, to learn from data input to a computer, and then, based on that learning, to problem-solve specific tasks. In medical imaging, the image data serve as the inputs to the AI system. While AI has been investigated over decades for the interpretation of medical images, it has only been in the recent decade that it has been greatly embraced by academia, industry, and the public. AI applications are being demonstrated in multiple areas of medical imaging including the clinical tasks of disease detection, diagnosis, prognosis, and therapeutic patient management, with algorithms of segmentation, computer-extraction of characteristics of abnormal and normal structures, radiomics, and deep learning. The potential practice-changing advances in AI have also yielded discussions on ethics and its effect on healthcare costs and workforce. A major concern in using AI is that some systems present as “black boxes” that, while yielding a correct prediction of a medical condition, lack the corresponding explanation on why the AI-reported decision was made. Overall, many are now viewing AI as ultimately a new “tool” in healthcare that will eventually enable the clinician to be more effective and efficient, as opposed to being replaced. © 2021 Elsevier Inc. All rights reserved.},
	author_keywords = {Artificial intelligence; Classification; Decision support; Machine learning; Medical imaging; Radiomics},
	publisher = {Elsevier},
	isbn = {978-012816386-3; 978-012816387-0},
	language = {English},
	abbrev_source_title = {Molecular Imaging: Principles and Practice},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Scheetz2021155,
	author = {Scheetz, Jane and He, Mingguang and van Wijngaarden, Peter},
	title = {Ophthalmology and the emergence of artificial intelligence},
	year = {2021},
	journal = {Medical Journal of Australia},
	volume = {214},
	number = {4},
	pages = {155 – 157.e1},
	doi = {10.5694/mja2.50932},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100962016&doi=10.5694%2fmja2.50932&partnerID=40&md5=a21462d89cb224e23251fcecc590974e},
	affiliations = {Centre for Eye Research Australia, Royal Victorian Eye and Ear Hospital, University of Melbourne, Melbourne, VIC, Australia; State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen University, Guangzhou, China; University of Melbourne, Melbourne, VIC, Australia},
	author_keywords = {Artificial intelligence; Clinical decision-making; Ophthalmology; Quality of health care},
	keywords = {Artificial Intelligence; Diagnostic Techniques, Ophthalmological; Eye Diseases; Humans; Ophthalmology; age related macular degeneration; algorithm; anonymised data; Article; artificial intelligence; artificial neural network; clinical decision making; deep learning; diabetic retinopathy; disease classification; disease exacerbation; emergency health service; eye photography; glaucoma; global disease burden; health care cost; health care policy; health care quality; machine learning; malpractice; medical ethics; medicolegal aspect; ophthalmology; patient care; personalized medicine; privacy; retina vein occlusion; retrolental fibroplasia; artificial intelligence; eye disease; human; ophthalmology; visual system examination},
	correspondence_address = {J. Scheetz; Centre for Eye Research Australia, Royal Victorian Eye and Ear Hospital, University of Melbourne, Melbourne, Australia; email: peterv@unimelb.edu.au},
	publisher = {John Wiley and Sons Inc},
	issn = {0025729X},
	coden = {MJAUA},
	pmid = {33583047},
	language = {English},
	abbrev_source_title = {Med. J. Aust.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@BOOK{Robbins2021371,
	author = {Robbins, Scott},
	title = {Machine Learning, Mass Surveillance, and National Security: Data, Efficacy, and Meaningful Human Control},
	year = {2021},
	journal = {The Palgrave Handbook of National Security},
	pages = {371 – 388},
	doi = {10.1007/978-3-030-53494-3_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149354944&doi=10.1007%2f978-3-030-53494-3_16&partnerID=40&md5=0ef39753e014cc108974c9b3b8e3ce98},
	affiliations = {Bonn University, Bonn, Germany},
	abstract = {This chapter highlights the many issues confronting the use of machine learning (ML) in the context of national security and mass surveillance, with a focus on the ethical challenges posed by ML. This attention to ethics serves two purposes. First, given this fast-moving field, an ethical focus allows for broader recognition of the issues arising from ML—even though particular aspects of the technology will continue to change, many of these ethical issues will remain constant. Second, these issues are chosen because they are important—not only are these likely to be ongoing issues for national security, they warrant concern and attention. The first set of issues stems from the data used to train ML algorithms and the second set of issues concerns the efficacy of ML, without which it would be unethical to use. Finally, due to the opacity of the features causing a particular ML decision, there are social issues surrounding human accountability and responsibility when something goes wrong. That is, how do we ensure that humans are in meaningful control over ML algorithms that could result in ethically salient consequences? The chapter concludes that while navigating all of these issues will be difficult, knowing that they exist is the first step toward ensuring that ML is implemented for mass surveillance in a way consistent with liberal democratic values. © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2022.},
	correspondence_address = {S. Robbins; Bonn University, Bonn, Germany; email: sarobbins@protonmail.com},
	publisher = {Springer International Publishing},
	isbn = {978-303053494-3; 978-303053493-6},
	language = {English},
	abbrev_source_title = {The Palgrave Handb. of National Security},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Corrado2021395,
	author = {Corrado, Edward M.},
	title = {Artificial Intelligence: The Possibilities for Metadata Creation},
	year = {2021},
	journal = {Technical Services Quarterly},
	volume = {38},
	number = {4},
	pages = {395 – 405},
	doi = {10.1080/07317131.2021.1973797},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121501695&doi=10.1080%2f07317131.2021.1973797&partnerID=40&md5=d3c883ee946ac297a5e5669ebc1f43f6},
	affiliations = {University Librarian, Naval Postgraduate School, Monterey, CA, United States},
	abstract = {Artificial intelligence is being touted as an enormous leap forward in technology that will change the future and drive innovation across all disciplines. How is artificial intelligence currently being used in libraries and what is its potential for creating quality descriptive metadata in the future? We will review some current and future developments and discus some of the ethical considerations of artificial intelligence when it comes to descriptive metadata creation that librarians will want to pay attention to going forward. © 2021 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	author_keywords = {Artificial intelligence; cataloging ethics; descriptive metadata; machine learning},
	keywords = {Ethical technology; Libraries; Metadata; 'current; Cataloging ethic; Descriptive metadata; Ethical considerations; Machine learning},
	correspondence_address = {E.M. Corrado; University Librarian, Naval Postgraduate School, Monterey, United States; email: ecorrado@ecorrado.us},
	publisher = {Routledge},
	issn = {07317131},
	language = {English},
	abbrev_source_title = {Tech. Ser. Q.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Hamatani2021,
	author = {Hamatani, Sayo and Hirano, Yoshiyuki and Sugawara, Ayako and Isobe, Masanori and Kodama, Naoki and Yoshihara, Kazufumi and Moriguchi, Yoshiya and Ando, Tetsuya and Endo, Yuka and Takahashi, Jumpei and Nohara, Nobuhiro and Takamura, Tsunehiko and Hori, Hiroaki and Noda, Tomomi and Tose, Keima and Watanabe, Keita and Adachi, Hiroaki and Gondo, Motoharu and Takakura, Shu and Fukudo, Shin and Shimizu, Eiji and Yoshiuchi, Kazuhiro and Sato, Yasuhiro and Sekiguchi, Atsushi},
	title = {Eating Disorder Neuroimaging Initiative (EDNI): A multicentre prospective cohort study protocol for elucidating the neural effects of cognitive-behavioural therapy for eating disorders},
	year = {2021},
	journal = {BMJ Open},
	volume = {11},
	number = {1},
	doi = {10.1136/bmjopen-2020-042685},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099988341&doi=10.1136%2fbmjopen-2020-042685&partnerID=40&md5=c74926f02fd94141c706c6e57037aff8},
	affiliations = {Research Center for Child Mental Development, Chiba University, Chiba, Japan; Japan Society for the Promotion of Science, Tokyo, Japan; United Graduate School of Child Development, Osaka University, Hamamatsu University School of Medicine, Chiba, Japan; Department of Behavioral Medicine, National Institute of Mental Health, National Center of Neurology and Psychiatry, Tokyo, Japan; Department of Psychiatry, Graduate School of Medicine, Kyoto University, Kyoto, Japan; Division of Psychosomatic Medicine, Department of Neurology, University of Occupational and Environmental Health, Kitakyushu, Japan; Department of Psychosomatic Medicine, Graduate School of Medical Sciences, Kyushu University, Fukuoka, Japan; Department of Psychosomatic Medicine, Tohoku University Hospital, Sendai, Japan; Department of Stress Sciences and Psychosomatic Medicine, Graduate School of Medicine, University of Tokyo, Tokyo, Japan; Department of Radiology, University of Occupational and Environmental Health School of Medicine, Kitakyushu, Japan; Department of Psychosomatic Medicine, Kitakyushu Municipal Medical Center, Fukuoka, Japan; Department of Behavioral Medicine, Tohoku University Graduate School of Medicine, Sendai, Japan; Department of Cognitive Behavioral Physiology, Graduate School of Medicine, Chiba University, Chiba, Japan},
	abstract = {Introduction Anorexia nervosa is a refractory psychiatric disorder with a mortality rate of 5.9% and standardised mortality ratio of 5.35, which is much higher than other psychiatric disorders. The standardised mortality ratio of bulimia nervosa is 1.49; however, it is characterised by suicidality resulting in a shorter time to death. While there is no current validated drug treatment for eating disorders in Japan, cognitive-behavioural therapy (CBT) is a well-established and commonly used treatment. CBT is also recommended in the Japanese Guidelines for the Treatment of Eating Disorders (2012) and has been covered by insurance since 2018. However, the neural mechanisms responsible for the effect of CBT have not been elucidated, and the use of biomarkers such as neuroimaging data would be beneficial. Methods and analysis The Eating Disorder Neuroimaging Initiative is a multisite prospective cohort study. We will longitudinally collect data from 72 patients with eating disorders (anorexia nervosa and bulimia nervosa) and 70 controls. Data will be collected at baseline, after 21-41 sessions of CBT and 12 months later. We will assess longitudinal changes in neural circuit function, clinical data, gene expression and psychological measures by therapeutic intervention and analyse the relationship among them using machine learning methods. Ethics and dissemination The study was approved by The Ethical Committee of the National Center of Neurology and Psychiatry (A2019-072). We will obtain written informed consent from all patients who participate in the study after they had been fully informed about the study protocol. All imaging, demographic and clinical data are shared between the participating sites and will be made publicly available in 2024. Trial registration number UMIN000039841  © },
	author_keywords = {eating disorders; neurobiology; neurophysiology; psychiatry},
	keywords = {Adult; Anorexia Nervosa; Brain; Bulimia Nervosa; Cognitive Behavioral Therapy; Feeding and Eating Disorders; Female; Humans; Japan; Magnetic Resonance Imaging; Multicenter Studies as Topic; Neuroimaging; Prospective Studies; biological marker; adult; anorexia nervosa; Article; bulimia; clinical outcome; clinical trial protocol; cognitive behavioral therapy; cohort analysis; diffusion tensor imaging; disease severity; functional magnetic resonance imaging; gene expression; human; machine learning; major clinical study; multicenter study; neurobiology; observational study; prospective study; psychologic assessment; anorexia nervosa; brain; bulimia; cognitive behavioral therapy; diagnostic imaging; eating disorder; female; Japan; multicenter study (topic); neuroimaging; nuclear magnetic resonance imaging; procedures; psychology},
	correspondence_address = {A. Sekiguchi; Department of Behavioral Medicine, National Institute of Mental Health, National Center of Neurology and Psychiatry, Tokyo, Japan; email: asekiguchi@ncnp.go.jp},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33495256},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Shakir2021808,
	author = {Shakir, Majed and Biletskiy, Yevgen},
	title = {Smart Microgrid Architecture for Home Energy Management System},
	year = {2021},
	journal = {2021 IEEE Energy Conversion Congress and Exposition, ECCE 2021 - Proceedings},
	pages = {808 – 813},
	doi = {10.1109/ECCE47101.2021.9595165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123375124&doi=10.1109%2fECCE47101.2021.9595165&partnerID=40&md5=eaec6fe6be9a23ae7d7b812f2bd0b7b5},
	affiliations = {University of New Brunswick, Dept. Electrical and Computer Engineering, Fredericton, Canada},
	abstract = {The present paper is devoted to adaptation of the achievements in the general research field of smart grid to the small power utilization systems, or microgrids. In particular, the focus of the present research is the architectural solution for a smart microgrid for automated home energy management systems. The proposed system architecture includes three main subsystems: load identification, forecasting and optimization. An automated home energy management system design requires general understanding of regulations and the ethics in collecting the building appliances data. The system design requires power data from the appliances be handled carefully when the data is stored. This is implemented to track the algorithm accuracy and data integrity. The software developed based on the present smart microgrid architecture delivers the lowest energy consumption price without sacrificing users comfort. One of the important features of the present architecture is adjustability because any of the three subsystems can be easily replaced by another subsystem with a more effective method in background.  © 2021 IEEE.},
	author_keywords = {AI; HEMS; Machine learning; Microgrid; Smar Grid},
	keywords = {Electric power transmission networks; Energy management; Energy management systems; Information management; Machine learning; Smart power grids; Systems analysis; Architectural solutions; HEMS; Home energy management systems; Microgrid; Microgrid architecture; Research fields; Smar grid; Smart grid; Smart Micro Grids; Utilization systems; Energy utilization},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172815135-9},
	language = {English},
	abbrev_source_title = {IEEE Energy Convers. Congr. Expo., ECCE - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 13th IEEE Energy Conversion Congress and Exposition, ECCE 2021; Conference date: 10 October 2021 through 14 October 2021; Conference code: 174227}
}

@ARTICLE{Moen2021902,
	author = {Moen, Taylor R. and Chen, Baiyu and Holmes, David R. and Duan, Xinhui and Yu, Zhicong and Yu, Lifeng and Leng, Shuai and Fletcher, Joel G. and McCollough, Cynthia H.},
	title = {Low-dose CT image and projection dataset},
	year = {2021},
	journal = {Medical Physics},
	volume = {48},
	number = {2},
	pages = {902 – 911},
	doi = {10.1002/mp.14594},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097613525&doi=10.1002%2fmp.14594&partnerID=40&md5=8d3ecba94d4eeede88958f5869438297},
	affiliations = {Department of Radiology, Mayo Clinic, Rochester, MN, United States; Biomedical Imaging Resource, Mayo Clinic, Rochester, MN, United States; NYU Langone Medical Center, 660 First Avenue, 4th Floor, New York, 10016, NY, United States; UT Southwestern Medical Center, 5323 Harry Hines Boulevard, Dallas, 75390, TX, United States; Accuray Incorporated, 28900 Fountain Pkwy STE A, Solon, 44139, OH, United States},
	abstract = {Purpose: To describe a large, publicly available dataset comprising computed tomography (CT) projection data from patient exams, both at routine clinical doses and simulated lower doses. Acquisition and Validation Methods: The library was developed under local ethics committee approval. Projection and image data from 299 clinically performed patient CT exams were archived for three types of clinical exams: noncontrast head CT scans acquired for acute cognitive or motor deficit, low-dose noncontrast chest scans acquired to screen high-risk patients for pulmonary nodules, and contrast-enhanced CT scans of the abdomen acquired to look for metastatic liver lesions. Scans were performed on CT systems from two different CT manufacturers using routine clinical protocols. Projection data were validated by reconstructing the data using several different reconstruction algorithms and through use of the data in the 2016 Low Dose CT Grand Challenge. Reduced dose projection data were simulated for each scan using a validated noise-insertion method. Radiologists marked location and diagnosis for detected pathologies. Reference truth was obtained from the patient medical record, either from histology or subsequent imaging. Data Format and Usage Notes: Projection datasets were converted into the previously developed DICOM-CT-PD format, which is an extended DICOM format created to store CT projections and acquisition geometry in a nonproprietary format. Image data are stored in the standard DICOM image format and clinical data in a spreadsheet. Materials are provided to help investigators use the DICOM-CT-PD files, including a dictionary file, data reader, and user manual. The library is publicly available from The Cancer Imaging Archive (https://doi.org/10.7937/9npb-2637). Potential Applications: This CT data library will facilitate the development and validation of new CT reconstruction and/or denoising algorithms, including those associated with machine learning or artificial intelligence. The provided clinical information allows evaluation of task-based diagnostic performance. © 2020 American Association of Physicists in Medicine},
	author_keywords = {CT projection data; iterative reconstruction; low-dose CT; machine learning; patient data},
	keywords = {Algorithms; Artificial Intelligence; Humans; Image Processing, Computer-Assisted; Radiation Dosage; Thorax; Tomography Scanners, X-Ray Computed; Tomography, X-Ray Computed; Computerized tomography; Diagnosis; Hospital data processing; Image enhancement; Image reconstruction; Large dataset; Machine learning; Medical imaging; Computed tomography projection data; Computed tomography scan; Dose computed tomographies; Image data; Iterative reconstruction; Low dose; Low-dose computed tomography; Machine-learning; Patient data; Projection data; Article; artificial intelligence; clinical protocol; computer assisted tomography; digital imaging and communications in medicine; high risk patient; human; image reconstruction; liver metastasis; lung nodule; machine learning; major clinical study; noise; radiation dose; reconstruction algorithm; algorithm; artificial intelligence; computed tomography scanner; image processing; radiation dose; thorax; x-ray computed tomography; Iterative methods},
	correspondence_address = {C.H. McCollough; Department of Radiology, Mayo Clinic, Rochester, United States; email: mccollough.cynthia@mayo.edu},
	publisher = {John Wiley and Sons Ltd},
	issn = {00942405},
	coden = {MPHYA},
	pmid = {33202055},
	language = {English},
	abbrev_source_title = {Med. Phys.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Parker202113,
	author = {Parker, William and Jaremko, Jacob L. and Cicero, Mark and Azar, Marleine and El-Emam, Khaled and Gray, Bruce G. and Hurrell, Casey and Lavoie-Cardinal, Flavie and Desjardins, Benoit and Lum, Andrea and Sheremeta, Lori and Lee, Emil and Reinhold, Caroline and Tang, An and Bromwich, Rebecca},
	title = {Canadian Association of Radiologists White Paper on De-Identification of Medical Imaging: Part 1, General Principles},
	year = {2021},
	journal = {Canadian Association of Radiologists Journal},
	volume = {72},
	number = {1},
	pages = {13 – 24},
	doi = {10.1177/0846537120967349},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094894028&doi=10.1177%2f0846537120967349&partnerID=40&md5=e51fb8b65fe40290bcde9149424f089f},
	affiliations = {Department of Radiology, University of British Columbia, Vancouver, BC, Canada; SapienML Corp, Vancouver, BC, Canada; Department of Radiology & Diagnostic Imaging, University of Alberta, Edmonton, Canada; Bit Inc, Toronto, ON, Canada; True North Imaging, Thornhill, ON, Canada; Department of Medicine, Université de Montréal, Montréal, QC, Canada; School of Epidemiology and Public Health, University of Ottawa, ON, Canada; Department of Medical Imaging, University of Toronto, Toronto, Canada; Canadian Association of Radiologists, Ottawa, Canada; Department of Psychiatry and Neuroscience, Université Laval, QC, Canada; Department of Radiology, University of Pennsylvania, PA, United States; Department of Medical Imaging, Western University, London, ON, Canada; Northern Alberta Institute of Technology, AB, Canada; Fraser Health Authority, Vancouver, BC, Canada; McGill University Health Center, McGill University, Montreal, Canada; Augmented Intelligence Precision Health Laboratory of the Research Institute, McGill University Health Center, McGill University, Montreal, Canada; Department of Radiology, Radio-oncology, and Nuclear Medicine, Universite de Montreal, Montreal, QC, Canada; Department of Law and Legal Studies, Carleton University, Ottawa, Canada},
	abstract = {The application of big data, radiomics, machine learning, and artificial intelligence (AI) algorithms in radiology requires access to large data sets containing personal health information. Because machine learning projects often require collaboration between different sites or data transfer to a third party, precautions are required to safeguard patient privacy. Safety measures are required to prevent inadvertent access to and transfer of identifiable information. The Canadian Association of Radiologists (CAR) is the national voice of radiology committed to promoting the highest standards in patient-centered imaging, lifelong learning, and research. The CAR has created an AI Ethical and Legal standing committee with the mandate to guide the medical imaging community in terms of best practices in data management, access to health care data, de-identification, and accountability practices. Part 1 of this article will inform CAR members on principles of de-identification, pseudonymization, encryption, direct and indirect identifiers, k-anonymization, risks of reidentification, implementations, data set release models, and validation of AI algorithms, with a view to developing appropriate standards to safeguard patient information effectively. © The Author(s) 2020.},
	author_keywords = {anonymization; artificial intelligence; data sharing; de-identification; medical imaging},
	keywords = {Algorithms; Artificial Intelligence; Canada; Data Anonymization; Diagnostic Imaging; Humans; Machine Learning; Radiologists; Societies, Medical; adult; algorithm; anonymization; artificial intelligence; big data; diagnostic imaging; health care access; human; identifiable information; lifelong learning; machine learning; privacy; radiologist; radiology; radiomics; review; validation process; voice; algorithm; anonymization; artificial intelligence; Canada; diagnostic imaging; ethics; medical society; practice guideline; radiologist},
	correspondence_address = {W. Parker; Department of Radiology, University of British Columbia, Vancouver, Canada; email: william@alumni.ubc.ca; W. Parker; SapienML Corp, Vancouver, Canada; email: william@alumni.ubc.ca},
	publisher = {SAGE Publications Inc.},
	issn = {08465371},
	coden = {JCARA},
	pmid = {33138621},
	language = {English},
	abbrev_source_title = {Can. Assoc. Radiol. J.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Bronze Open Access}
}

@CONFERENCE{Thakur20211930,
	author = {Thakur, Gautam and Caspersen, Janna and Herrmannova, Drahomira and Eaton, Bryan and Burdette, Jordan},
	title = {A Mixed-Method Design Approach for Empirically Based Selection of Unbiased Data Annotators},
	year = {2021},
	journal = {Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
	pages = {1930 – 1938},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123956422&partnerID=40&md5=2c88bcd8c314fe7155d7b22dfc909196},
	affiliations = {Oak Ridge National Laboratory, 1 Bethel Valley Road, Oak Ridge, 37830, TN, United States},
	abstract = {Implicit bias embedded in the annotated data is by far the greatest impediment in the effectual use of supervised machine learning models in tasks involving race, ethics, and geopolitical polarization. For societal good and demonstrable positive impact on wider society, it is paramount to carefully select data annotators and rigorously validate the annotation process. Current approaches to selecting annotators are not sufficiently grounded in scientific principles and are limited at the policy-guidance level, thereby rendering them unusable for machine learning practitioners. This work proposes a new approach based on the mixed-methods design that is functional, adaptable, and simpler to implement in selecting unbiased annotators for any machine learning problem. By demonstrating it on a real-world geopolitical problem, we also identified and ranked key inane profile characteristics towards an empirically-based selection of unbiased data annotators. © 2021 Association for Computational Linguistics},
	keywords = {Computational linguistics; Design; Electric grounding; 'current; Design approaches; Machine learning models; Machine learning problem; Mixed method; New approaches; Policy guidance; Scientific principles; Simple++; Supervised machine learning; Supervised learning},
	editor = {Zong C. and Xia F. and Li W. and Navigli R.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {978-195408554-1},
	language = {English},
	abbrev_source_title = {Find. Assoc. Comput. Linguist.: ACL-IJCNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 174271}
}

@CONFERENCE{Friedman20212210,
	author = {Friedman, Marissa and Ford, Cameron and Elings Pi, Mary and Singh, Vijay and Tan, Tracey},
	title = {Using AI/Machine Learning to Extract Data from Japanese American Confinement Records},
	year = {2021},
	journal = {Proceedings - 2021 IEEE International Conference on Big Data, Big Data 2021},
	pages = {2210 – 2219},
	doi = {10.1109/BigData52589.2021.9672076},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125314304&doi=10.1109%2fBigData52589.2021.9672076&partnerID=40&md5=413f4985ac6ca394db317d0f2ce9b6f5},
	affiliations = {University of California, Berkeley, The Bancroft Library, Berkeley, United States; Doxie.AI},
	abstract = {As part of a Japanese American Confinement Sites (JACS) grant-funded project, supported by the National Park Service, the Bancroft Library at UC Berkeley is digitizing nearly 210,000 pages of War Relocation Authority (WRA) Form 26 individual records of Japanese Americans incarcerated during WWII. The library has partnered with Doxie.AI to develop a customized machine learning pipeline for extracting structured data from these records A number of challenges have arisen due to variability in content, structure, and placement of text on the page, and the presence of a wide variety of characteristics in the archival records that produce visual noise. This has prompted an iterative and dynamic approach to process records by camp. By blending library staff's content and domain knowledge with the technical expertise of Doxie.AI, the project team is meeting or exceeding baseline targets for accuracy rates across the majority of fields. Additionally, ethical issues pertaining to the digital release of this data and the digitized records in their entirety will be explored with a Community Advisory Group, as the library seeks to establish a responsible digital curation plan for these resources. In alignment with Collections as Data principles that encourage the responsible computational use of special collections, this project represents a crucial opportunity to explore new methods for enhancing access to our growing digital special collections. © 2021 IEEE.},
	author_keywords = {archival ethics; artificial intelligence; collections as data; community engagement; digital collections; Japanese American WWII incarceration; machine learning},
	keywords = {Blending; Digital libraries; E-learning; Iterative methods; Machine learning; Philosophical aspects; Archival ethic; Collection as data; Community engagement; Content structure; Digital collections; Japanese american WWII incarceration; Machine-learning; National Park Service; Structured data; Visual noise; Data mining},
	editor = {Chen Y. and Ludwig H. and Tu Y. and Fayyad U. and Zhu X. and Hu X.T. and Byna S. and Liu X. and Zhang J. and Pan S. and Papalexakis V. and Wang J. and Cuzzocrea A. and Ordonez C.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166543902-2},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, Big Data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2021 IEEE International Conference on Big Data, Big Data 2021; Conference date: 15 December 2021 through 18 December 2021; Conference code: 176404}
}

@ARTICLE{Fish2021425,
	author = {Fish, Adam},
	title = {Crash Theory: Entrapments of Conservation Drones and Endangered Megafauna},
	year = {2021},
	journal = {Science Technology and Human Values},
	volume = {46},
	number = {2},
	pages = {425 – 451},
	doi = {10.1177/0162243920920356},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084525490&doi=10.1177%2f0162243920920356&partnerID=40&md5=db8f1be3c7b8a2c02161a0872649a288},
	affiliations = {School of Arts and Media, University of New South Wales, Sydney, NSW, Australia},
	abstract = {Drones deployed to monitor endangered species often crash. These crashes teach us that using drones for conservation is a contingent practice ensnaring humans, technologies, and animals. This article advances a crash theory in which pilots, conservation drones, and endangered megafauna are relata, or related actants, that intra-act, cocreating each other and a mutually constituted phenomena. These phenomena are entangled, with either reciprocal dependencies or erosive entrapments. The crashing of conservation drones and endangered species requires an ethics of care, repair, or reworlding. Diffractions, disruptions that expose difference, result from crashes and reveal the precarious manner by which technologies, laws, and discourses bring nature and culture together. To support crash theory, this article presents three ethnographic cases. A drone crash in the United Kingdom near white rhinoceroses while building machine learning training data exhibits the involvement of the electromagnetic spectrum; the threat of crashes in the Pacific Northwest near Puget Sound orcas discloses the impacts of drone laws; and drone crashes in Sri Lanka among Asian elephants presents the problems of technoliberal ideals around programming natural worlds. Throughout the article, a methodology is developed, parallelism, which attends to the material similarities in lateral phenomena. © The Author(s) 2020.},
	author_keywords = {crash; drone; endangered species; entanglement; entrapment; natureculture; programmability; repair; technoliberalism; UAV},
	correspondence_address = {A. Fish; School of Arts and Media, University of New South Wales, Sydney, Australia; email: a.fish@unsw.edu.au},
	publisher = {SAGE Publications Inc.},
	issn = {01622439},
	language = {English},
	abbrev_source_title = {Sci. Technol. Hum. Values},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Rismani2021,
	author = {Rismani, Shalaleh and Moon, Ajung},
	title = {How do AI systems fail socially?: an engineering risk analysis approach},
	year = {2021},
	journal = {Proceedings - 2021 IEEE International Symposium on Ethics in Engineering, Science and Technology: Engineering and Corporate Social Responsibility, ETHICS 2021},
	doi = {10.1109/ETHICS53270.2021.9632769},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124025841&doi=10.1109%2fETHICS53270.2021.9632769&partnerID=40&md5=b650dab1448717a883d9c1ce9a30db56},
	affiliations = {McGill University, Electrical and Computer Engineering, Montreal, Canada},
	abstract = {Failure Mode and Effect Analysis (FMEA) has been used as an engineering risk assessment tool since 1949. FMEAs are effective in preemptively identifying and addressing how a device or process might fail in operation and are often used in the design of high-risk technology applications such as military, automotive industry and medical devices. In this work, we explore whether FMEAs can serve as a risk assessment tool for machine learning practitioners, especially in deploying systems for high-risk applications (e.g. algorithms for recidivism assessment). In particular, we discuss how FMEAs can be used to identify social and ethical failures of Artificial Intelligent Systemss (AISs), recognizing that FMEAs have the potential to uncover a broader range of failures. We first propose a process for developing a Social FMEAs (So-FMEAs) by building on the existing FMEAs framework and a recently published definition of Social Failure Modes by Millar. We then demonstrate a simple proof-of-concept, So-FMEAs for the COMPAS algorithm, a risk assessment tool used by judges to make recidivism-related decisions for convicted individuals. Through this preliminary investigation, we illustrate how a traditional engineering risk management tool could be adapted for analyzing social and ethical failures of AIS. Engineers and designers of AISs can use this new approach to improve their system's design and perform due diligence with respect to potential ethical and social failures.  © 2021 IEEE.},
	author_keywords = {AI accountability; AI design; AI ethics; Failure Mode and Effect Analysis; Social Failure Mode},
	keywords = {Automotive industry; Failure (mechanical); Intelligent systems; Machine learning; Military applications; Philosophical aspects; Risk analysis; Risk assessment; Risk management; Safety engineering; AI accountability; AI design; AI ethic; AI systems; Artificial intelligent; Engineering risk analysis; Ethical failure; Failure mode and effects analysis; Risk assessment tool; Social failure mode; Failure modes},
	editor = {Cheong M. and Herkert J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166540801-1},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Symp. Ethics Eng., Sci. Technol.: Eng. Corp. Soc. Responsib., ETHICS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2021 IEEE International Symposium on Ethics in Engineering, Science and Technology, ETHICS 2021; Conference date: 28 October 2021 through 31 October 2021; Conference code: 175480}
}

@ARTICLE{Birhane2021,
	author = {Birhane, Abeba},
	title = {Algorithmic injustice: a relational ethics approach},
	year = {2021},
	journal = {Patterns},
	volume = {2},
	number = {2},
	doi = {10.1016/j.patter.2021.100205},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100761051&doi=10.1016%2fj.patter.2021.100205&partnerID=40&md5=b1802f1db618e4eecb2603e2664b92ce},
	affiliations = {School of Computer Science, University College Dublin, Ireland & Lero—The Irish Software Research Centre, Dublin, Ireland},
	abstract = {It has become trivial to point out that algorithmic systems increasingly pervade the social sphere. Improved efficiency—the hallmark of these systems—drives their mass integration into day-to-day life. However, as a robust body of research in the area of algorithmic injustice shows, algorithmic systems, especially when used to sort and predict social outcomes, are not only inadequate but also perpetuate harm. In particular, a persistent and recurrent trend within the literature indicates that society's most vulnerable are disproportionally impacted. When algorithmic injustice and harm are brought to the fore, most of the solutions on offer (1) revolve around technical solutions and (2) do not center disproportionally impacted communities. This paper proposes a fundamental shift—from rational to relational—in thinking about personhood, data, justice, and everything in between, and places ethics as something that goes above and beyond technical solutions. Outlining the idea of ethics built on the foundations of relationality, this paper calls for a rethinking of justice and ethics as a set of broad, contingent, and fluid concepts and down-to-earth practices that are best viewed as a habit and not a mere methodology for data science. As such, this paper mainly offers critical examinations and reflection and not “solutions.” Machine learning (ML) increasingly permeates every sphere of life. Complex, contextual, continually moving social and political challenges are automated and packaged as mathematical and engineering problems. Simultaneously, research on algorithmic injustice shows how ML automates and perpetuates historical, often unjust and discriminatory, patterns. The negative consequences of algorithmic systems, especially on marginalized communities, have spurred work on algorithmic fairness. Still, most of this work is narrow in scope, focusing on fine-tuning specific models, making datasets more inclusive/representative, and “debiasing” datasets. Although such work can constitute part of the remedy, a fundamentally equitable path must examine the wider picture, such as unquestioned or intuitive assumptions in datasets, current and historical injustices, and power asymmetries. As such, this work does not offer a list of implementable solutions towards a “fair” system, but rather is a call for scholars and practitioners to critically examine the field. It is taken for granted that ML and data science are fields that solve problems using data and algorithms. Thus, challenges are often formulated as problem/solution. One of the consequences of such discourse is that challenges that refuse such a problem/solution formulation, or those with no clear “solutions”, or approaches that primarily offer critical analysis are systematically discarded and perceived as out of the scope of these fields. This work hopes for a system-wide acceptance of critical work as an essential component of AI ethics, fairness, and justice. It has become trivial to point out that algorithmic systems increasingly pervade the social sphere. Improved efficiency—the hallmark of these systems—drives their mass integration into day-to-day life. However, as a robust body of research in the area of algorithmic injustice shows, algorithmic systems, especially when used to sort and predict social outcomes, are not only inadequate but also perpetuate harm. In particular, a persistent and recurrent trend within the literature indicates that society's most vulnerable are disproportionally impacted. When algorithmic injustice and harm are brought to the fore, most of the solutions on offer (1) revolve around technical solutions and (2) do not center disproportionally impacted communities. This paper proposes a fundamental shift—from rational to relational—in thinking about personhood, data sciences, justice, and everything in between, and places ethics as something that goes above and beyond technical solutions. Outlining the idea of ethics built on the foundations of relationality, this paper calls for a rethinking of justice and ethics as a set of broad, contingent, and fluid concepts and down-to-earth practices that are best viewed as a habit and not a mere methodology for data science. As such, this paper mainly offers critical examinations and reflection and not “solutions.” © 2021 The Author},
	author_keywords = {Afro-feminism; artificial intelligence; complex systems; data science; DSML 1: Concept: Basic principles of a new data science output observed and reported; embodiment; enaction; ethics; justice; machine learning; relational epistemology},
	keywords = {Data Science; Digital storage; Efficiency; Critical analysis; De-biasing; Engineering problems; Fine tuning; Mass integration; Social outcomes; Technical solutions; Philosophical aspects},
	correspondence_address = {A. Birhane; School of Computer Science, University College Dublin, Ireland & Lero—The Irish Software Research Centre, Dublin, Ireland; email: abeba.birhane@ucdconnect.ie},
	publisher = {Cell Press},
	issn = {26663899},
	language = {English},
	abbrev_source_title = {Patterns},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 107; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Parker202125,
	author = {Parker, William and Jaremko, Jacob L. and Cicero, Mark and Azar, Marleine and El-Emam, Khaled and Gray, Bruce G. and Hurrell, Casey and Lavoie-Cardinal, Flavie and Desjardins, Benoit and Lum, Andrea and Sheremeta, Lori and Lee, Emil and Reinhold, Caroline and Tang, An and Bromwich, Rebecca},
	title = {Canadian Association of Radiologists White Paper on De-identification of Medical Imaging: Part 2, Practical Considerations},
	year = {2021},
	journal = {Canadian Association of Radiologists Journal},
	volume = {72},
	number = {1},
	pages = {25 – 34},
	doi = {10.1177/0846537120967345},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094927785&doi=10.1177%2f0846537120967345&partnerID=40&md5=fdbfbebf96a7df6d79fc233d9ddae34f},
	affiliations = {Department of Radiology, University of British Columbia, Vancouver, BC, Canada; SapienML Corp, Vancouver, BC, Canada; Department of Radiology & Diagnostic Imaging, University of Alberta, Edmonton, Canada; Bit Inc, Toronto, ON, Canada; True North Imaging, Thornhill, ON, Canada; Department of Medicine, Université de Montréal, Montréal, QC, Canada; School of Epidemiology and Public Health, University of Ottawa, ON, Canada; Department of Medical Imaging, University of Toronto, Toronto, Canada; Canadian Association of Radiologists, Ottawa, Canada; Department of Psychiatry and Neuroscience, Université Laval, QC, Canada; Department of Radiology, University of Pennsylvania, PA, United States; Department of Medical Imaging, Western University, London, ON, Canada; Northern Alberta Institute of Technology, Edmonton, AB, Canada; Fraser Health Authority, Vancouver, BC, Canada; McGill University Health Center, McGill University, Montréal, Canada; Augmented Intelligence Precision Health Laboratory of the Research Institute of McGill University Health Centre, Montréal, QC, Canada; Department of Radiology, Radio-oncology, and Nuclear Medicine, Universite de Montreal, Montréal, QC, Canada; Department of Law and Legal Studies, Carleton University, Ottawa, Canada},
	abstract = {The application of big data, radiomics, machine learning, and artificial intelligence (AI) algorithms in radiology requires access to large data sets containing personal health information. Because machine learning projects often require collaboration between different sites or data transfer to a third party, precautions are required to safeguard patient privacy. Safety measures are required to prevent inadvertent access to and transfer of identifiable information. The Canadian Association of Radiologists (CAR) is the national voice of radiology committed to promoting the highest standards in patient-centered imaging, lifelong learning, and research. The CAR has created an AI Ethical and Legal standing committee with the mandate to guide the medical imaging community in terms of best practices in data management, access to health care data, de-identification, and accountability practices. Part 2 of this article will inform CAR members on the practical aspects of medical imaging de-identification, strengths and limitations of de-identification approaches, list of de-identification software and tools available, and perspectives on future directions. © The Author(s) 2020.},
	author_keywords = {anonymization; artificial intelligence; data sharing; de-identification; medical imaging},
	keywords = {Algorithms; Artificial Intelligence; Canada; Data Anonymization; Diagnostic Imaging; Humans; Machine Learning; Radiologists; Societies, Medical; adult; anonymization; artificial intelligence; big data; diagnostic imaging; health care access; human; identifiable information; lifelong learning; machine learning; privacy; radiologist; radiology; radiomics; review; software; voice; algorithm; anonymization; artificial intelligence; Canada; diagnostic imaging; ethics; medical society; practice guideline; radiologist},
	correspondence_address = {W. Parker; Department of Radiology, University of British Columbia, Vancouver, Canada; email: william@alumni.ubc.ca; W. Parker; SapienML Corp, Vancouver, Canada; email: william@alumni.ubc.ca},
	publisher = {SAGE Publications Inc.},
	issn = {08465371},
	coden = {JCARA},
	pmid = {33140663},
	language = {English},
	abbrev_source_title = {Can. Assoc. Radiol. J.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Bronze Open Access}
}

@ARTICLE{Mishra2021,
	author = {Mishra, Deepti and Parish, Karen and Lugo, Ricardo Gregorio and Wang, Hao},
	title = {A framework for using humanoid robots in the school learning environment},
	year = {2021},
	journal = {Electronics (Switzerland)},
	volume = {10},
	number = {6},
	doi = {10.3390/electronics10060756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102835152&doi=10.3390%2felectronics10060756&partnerID=40&md5=714333483397cc93c68807dfb6a7a5c7},
	affiliations = {Department of Computer Science (IDI), NTNU—Norwegian University of Science and Technology, Gjøvik, 2815, Norway; Faculty of Education, Inland Norway University of Applied Sciences, Lillehammer, 2624, Norway; Department of Information Security and Communication Technology (IIK), NTNU—Norwegian University of Science and Technology, Gjøvik, 2815, Norway},
	abstract = {With predictions of robotics and efficient machine learning being the building blocks of the Fourth Industrial Revolution, countries need to adopt a long-term strategy to deal with potential challenges of automation and education must be at the center of this long-term strategy. Education must provide students with a grounding in certain skills, such as computational thinking and an understanding of robotics, which are likely to be required in many future roles. Targeting an acknowledged gap in existing humanoid robot research in the school learning environment, we present a multidisciplinary framework that integrates the following four perspectives: technological, pedagogical, efficacy of humanoid robots and a consideration of the ethical implications of using humanoid robots. Further, this paper presents a proposed application, evaluation and a case study of how the framework can be used. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Education; Effi-cacy; Ethics; Human–robot interaction; Pedagogy; School learning environment},
	correspondence_address = {D. Mishra; Department of Computer Science (IDI), NTNU—Norwegian University of Science and Technology, Gjøvik, 2815, Norway; email: deepti.mishra@ntnu.no},
	publisher = {MDPI AG},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@CONFERENCE{Gill2021576,
	author = {Gill, Rupali and Singh, Jaiteg},
	title = {Machine Learning Approaches for Neuroscientific Behavioral Analysis: A Neuromarketing perspective},
	year = {2021},
	journal = {2021 4th International Conference on Recent Developments in Control, Automation and Power Engineering, RDCAPE 2021},
	pages = {576 – 580},
	doi = {10.1109/RDCAPE52977.2021.9633604},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123835207&doi=10.1109%2fRDCAPE52977.2021.9633604&partnerID=40&md5=b8ae66981fbe4c64d73e52ab35957530},
	affiliations = {Chitkara University, Institute Of Engineering And Technology, Chitkara University, Punjab, India},
	abstract = {Neuromarketing has evolved from the fusion of neuroscience and marketing techniques. It intends to measure the interest, attitude, and behavior of consumers towards either any product, service, design, or advertisement. The probable study of various neuroscience techniques with machine learning classification and prediction algorithms is have been studied. Early literature pertaining to neuromarketing is primarily focused on individual techniques, application areas, ethics, datasets, algorithms. This manuscript intends to extend a previous literature by studying essential machine learning techniques, prominent datasets, algorithms, and available equipment for designing neuroscientific experiments. The manuscript concluded with the probable pros and cons of using different machine learning techniques associated with contemporary use of neuroscientific methods. Towards machine learning techniques has many applications in the field of Brain computer interface (BCI), neuromarketing, neurophysiology and clinical neuroscience. In neuromarketing, these techniques help in improving product sales, return on investment, product design etc. © 2021 IEEE.},
	author_keywords = {Artificial neural networks (ANN); Classification techniques; Electroencephalography (EEG); K nearest neighbor(k-NN); Linear discriminant analyzer (LDA); Machine learning; Neuromarketing; Neuroscience; Support vector machine (SVM)},
	keywords = {Brain computer interface; Consumer behavior; Electroencephalography; Electrophysiology; Learning algorithms; Nearest neighbor search; Product design; Support vector machines; Artificial neural network; Classification technique; Electroencephalography; K near neighbor; Linear discriminant analyzer; Linear discriminants; Nearest-neighbour; Neuromarketing; Support vector machine; Support vectors machine; Neural networks},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166541429-6},
	language = {English},
	abbrev_source_title = {Int. Conf. Recent Dev. Control, Autom. Power Eng., RDCAPE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 4th International Conference on Recent Developments in Control, Automation and Power Engineering, RDCAPE 2021; Conference date: 7 October 2021 through 9 October 2021; Conference code: 175483}
}

@BOOK{Österle2021263,
	author = {Österle, Hubert},
	title = {Ethics or Quality of Life?},
	year = {2021},
	journal = {Perspectives on Digital Humanism},
	pages = {263 – 269},
	doi = {10.1007/978-3-030-86144-5_35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152823895&doi=10.1007%2f978-3-030-86144-5_35&partnerID=40&md5=051b7164fd9b0660fec934d3d8e6be09},
	affiliations = {University of St. Gallen, St. Gallen, Switzerland},
	abstract = {Governmental and non-governmental organizations around the world are trying to shape socio-technical development, especially the use of information technology, for the benefit of people. They are developing ethical guidelines for the creation and evaluation of digital services. The discipline of Life Engineering must combine the knowledge of several disciplines, such as psychology, machine learning, economics, and ethics, so that technology serves people, i.e., contributes to well-being. Therefore, a solid understanding of quality of life should be the starting point, explaining the patterns of human behavior and their impact on well-being. Digital services of all kinds provide increasingly detailed digital twins and give us the opportunity to operationalize ethical principles. © The Editor(s) (if applicable) and The Author(s) 2022, corrected publication 2022.},
	correspondence_address = {H. Österle; University of St. Gallen, St. Gallen, Switzerland; email: hubert.oesterle@unisg.ch},
	publisher = {Springer International Publishing},
	isbn = {978-303086144-5; 978-303086143-8},
	language = {English},
	abbrev_source_title = {Perspectives on Digital Humanism},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Cheong2021106,
	author = {Cheong, Marc and Leins, Kobi and Coghlan, Simon},
	title = {Computer science communities: Who is speaking, and who is listening to the women? Using an ethics of care to promote diverse voices},
	year = {2021},
	journal = {FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages = {106 – 115},
	doi = {10.1145/3442188.3445874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102617830&doi=10.1145%2f3442188.3445874&partnerID=40&md5=d5bd5760c228372a2c4bd77f16f4b253},
	affiliations = {Centre for AI and Digital Ethics, Faculty of Engineering and IT, University of Melbourne, Parkville, VIC, Australia},
	abstract = {Those working on policy, digital ethics and governance often refer to issues in 'computer science', that includes, but is not limited to, common subfields such as Artificial Intelligence (AI), Computer Science (CS) Computer Security (InfoSec), Computer Vision (CV), Human Computer Interaction (HCI), Information Systems, (IS), Machine Learning (ML), Natural Language Processing (NLP) and Systems Architecture. Within this framework, this paper is a preliminary exploration of two hypotheses, namely 1) Each community has differing inclusion of minoritised groups (using women as our test case, by identifying female-sounding names); and 2) Even where women exist in a community, they are not published representatively. Using data from 20,000 research records, totalling 503,318 names, preliminary data supported our hypothesis. We argue that ACM has an ethical duty of care to its community to increase these ratios, and to hold individual computing communities to account in order to do so, by providing incentives and a regular reporting system, in order to uphold its own Code. © 2021 ACM.},
	author_keywords = {Computer science; Diversity; Gender; Gender representation; Publishing; Research; Sex equality},
	keywords = {Artificial intelligence; Engineering education; Human computer interaction; Philosophical aspects; Security of data; Transparency; Digital ethics; Human computer interaction (HCI); Individual computing; NAtural language processing; Reporting systems; Science community; Subfields; Systems architecture; Natural language processing systems},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038309-7},
	language = {English},
	abbrev_source_title = {FAccT - Proc. ACM Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 4th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2021; Conference date: 3 March 2021 through 10 March 2021; Conference code: 167464; All Open Access, Green Open Access}
}

@ARTICLE{Morley2021153,
	author = {Morley, Jessica and Floridi, Luciano and Kinsey, Libby and Elhalal, Anat},
	title = {From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices},
	year = {2021},
	journal = {Philosophical Studies Series},
	volume = {144},
	pages = {153 – 183},
	doi = {10.1007/978-3-030-81907-1_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118801492&doi=10.1007%2f978-3-030-81907-1_10&partnerID=40&md5=4498f0d028436debb184b179de65df55},
	affiliations = {Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; Digital Catapult, London, United Kingdom},
	abstract = {The debate about the ethical implications of Artificial Intelligence dates from the 1960s (Samuel in Science, 132(3429):741–742, 1960. https://doi.org/10.1126/scien ce.132.3429.741 ; Wiener in Cybernetics: or control and communication in the animal and the machine, MIT Press, New York, 1961). However, in recent years symbolic AI has been complemented and sometimes replaced by (Deep) Neural Networks and Machine Learning (ML) techniques. This has vastly increased its potential utility and impact on society, with the consequence that the ethical debate has gone mainstream. Such a debate has primarily focused on principles—the ‘what’ of AI ethics (beneficence, non-maleficence, autonomy, justice and explicability)—rather than on practices, the ‘how.’ Awareness of the potential issues is increasing at a fast rate, but the AI community’s ability to take action to mitigate the associated risks is still at its infancy. Our intention in presenting this research is to contribute to closing the gap between principles and practices by constructing a typology that may help practically-minded developers apply ethics at each stage of the Machine Learning development pipeline, and to signal to researchers where further work is needed. The focus is exclusively on Machine Learning, but it is hoped that the results of this research may be easily applicable to other branches of AI. The article outlines the research method for creating this typology, the initial findings, and provides a summary of future research needs. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Applied ethics; Artificial intelligence; Data governance; Digital ethics; Ethics of AI; Governance; Machine learning},
	correspondence_address = {L. Floridi; Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; email: luciano.floridi@oii.ox.ac.uk},
	publisher = {Springer Nature},
	issn = {09218599},
	language = {English},
	abbrev_source_title = {Philos. Stud. Ser.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Green Open Access}
}

@ARTICLE{Ursin2021,
	author = {Ursin, Frank and Timmermann, Cristian and Steger, Florian},
	title = {Ethical implications of alzheimer’s disease prediction in asymptomatic individuals through artificial intelligence},
	year = {2021},
	journal = {Diagnostics},
	volume = {11},
	number = {3},
	doi = {10.3390/diagnostics11030440},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116952349&doi=10.3390%2fdiagnostics11030440&partnerID=40&md5=38d5d93dcfd11e9f5cf2f2decc5faf7e},
	affiliations = {Institute of the History, Philosophy and Ethics of Medicine, Ulm University, Parkstrasse 11, Ulm, D-89073, Germany},
	abstract = {Biomarker-based predictive tests for subjectively asymptomatic Alzheimer’s disease (AD) are utilized in research today. Novel applications of artificial intelligence (AI) promise to predict the onset of AD several years in advance without determining biomarker thresholds. Until now, little attention has been paid to the new ethical challenges that AI brings to the early diagnosis in asymptomatic individuals, beyond contributing to research purposes, when we still lack adequate treatment. The aim of this paper is to explore the ethical arguments put forward for AI aided AD prediction in subjectively asymptomatic individuals and their ethical implications. The ethical assessment is based on a systematic literature search. Thematic analysis was conducted inductively of 18 included publications. The ethical framework includes the principles of autonomy, beneficence, non-maleficence, and justice. Reasons for offering predictive tests to asymptomatic individuals are the right to know, a positive balance of the risk-benefit assessment, and the opportunity for future planning. Reasons against are the lack of disease modifying treatment, the accuracy and explicability of AI aided prediction, the right not to know, and threats to social rights. We conclude that there are serious ethical concerns in offering early diagnosis to asymptomatic individuals and the issues raised by the application of AI add to the already known issues. Nevertheless, pre-symptomatic testing should only be offered on request to avoid inflicted harm. We recommend developing training for physicians in communicating AI aided prediction. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Autonomy; Explicability; Informed consent; Justice; Machine learning; Population screening; Pre-symptomatic; Preclinical},
	keywords = {biological marker; adult; Alzheimer disease; Article; artificial intelligence; beneficence; cognitive defect; cost effectiveness analysis; deep learning; dementia; early diagnosis; employment discrimination; empowerment; female; health care policy; health insurance; human; male; medical decision making; medical ethics; neurologic disease; nonmaleficence; patient autonomy; physician; practice guideline; publication; systematic review; systematic review (topic); terminal care; thematic analysis},
	correspondence_address = {F. Ursin; Institute of the History, Philosophy and Ethics of Medicine, Ulm University, Ulm, Parkstrasse 11, D-89073, Germany; email: frank.ursin@uni-ulm.de},
	publisher = {MDPI},
	issn = {20754418},
	language = {English},
	abbrev_source_title = {Diagn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sheetal2021997,
	author = {Sheetal, Abhishek and Savani, Krishna},
	title = {A Machine Learning Model of Cultural Change: Role of Prosociality, Political Attitudes, and Protestant Work Ethic},
	year = {2021},
	journal = {American Psychologist},
	volume = {76},
	number = {6},
	pages = {997 – 1012},
	doi = {10.1037/amp0000868},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122844742&doi=10.1037%2famp0000868&partnerID=40&md5=f17f44cdea1702dee5305b8d76485801},
	affiliations = {Division of Strategy, International Business, and Entrepreneurship, Nanyang Business School, Nanyang Technological University, Singapore; Division of Leadership, Management, and Organisation, Nanyang Business School, Nanyang Technological University, Singapore},
	abstract = {What attitudes, values, and beliefs serve as key markers of cultural change? To answer this question, we examined 221,485 respondents from the World Values Survey, a multiwavecross-country survey of people’s attitudes, values, and beliefs. We trained a machine learningmodel to classify respondents into seven waves (i.e., periods). Once trained, the machinelearning model identified a separate group of 24,611 respondents’ wave with a balanced accuracyof 77%. We then queried the model to identify the attitudes, values, and beliefs thatcontributed the most to its classification decisions, and therefore, served as markers of culturalchange. These included religiosity, social attitudes, political attitudes, independence,life satisfaction, Protestant work ethic, and prosociality. Although past research in culturalchange has discussed decreasing religiosity and increasing liberalism and independence, ithas not yet identified Protestant work ethic, political orientation, and prosociality as valuesrelevant to cultural change. Thus, the current research points to new directions for futureresearch on cultural change that might not be evident from either a deductive or an inductiveapproach. This research illustrates that the abductive approach of machine learning, whichfocuses on the most likely explanations for an outcome, can help generate novel insights © 2021. American Psychological Association},
	author_keywords = {Cultural change; Gradient boosting; Machine learning; World values survey},
	keywords = {Attitude; Humans; Machine Learning; Politics; Protestantism; attitude; human; machine learning; politics; Protestantism},
	correspondence_address = {K. Savani; Division of Leadership, Management, and Organisation, Nanyang Business School, Nanyang Technological University, Singapore; email: ksavani@ntu.edu.sg},
	publisher = {American Psychological Association},
	issn = {0003066X},
	coden = {AMPSA},
	pmid = {34914435},
	language = {English},
	abbrev_source_title = {Am. Psychol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@ARTICLE{Tranter-Entwistle2021420,
	author = {Tranter-Entwistle, Isaac and Wang, Holly and Daly, Kenny and Maxwell, Scott and Connor, Saxon},
	title = {The Challenges of Implementing Artificial Intelligence into Surgical Practice},
	year = {2021},
	journal = {World Journal of Surgery},
	volume = {45},
	number = {2},
	pages = {420 – 428},
	doi = {10.1007/s00268-020-05820-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092540701&doi=10.1007%2fs00268-020-05820-8&partnerID=40&md5=109938f7da575ebf9470b0236a7c6f00},
	affiliations = {Department of General Surgery, Christchurch Hospital, Christchurch, New Zealand; Decision Support, Christchurch Hospital, Christchurch, New Zealand},
	abstract = {Background: Artificial intelligence is touted as the future of medicine. Classical algorithms for the detection of common bile duct stones (CBD) have had poor clinical uptake due to low accuracy. This study explores the challenges of developing and implementing a machine-learning model for the prediction of CBD stones in patients presenting with acute biliary disease (ABD). Methods: All patients presenting acutely to Christchurch Hospital over a two-year period with ABD were retrospectively identified. Clinical data points including lab test results, demographics and ethnicity were recorded. Several statistical techniques were utilised to develop a machine-learning model. Issues with data collection, quality, interpretation and barriers to implementation were identified and highlighted. Results: Issues with patient identification, coding accuracy, and implementation were encountered. In total, 1315 patients met inclusion criteria. Incorrect international classification of disease 10 (ICD-10) coding was noted in 36% (137/382) of patients recorded as having CBD stones. Patients with CBD stones were significantly older and had higher aspartate aminotransferase (AST), alanine aminotransferase (ALT), bilirubin and gamma-glutamyl transferase (GGT) levels (p < 0.001). The no information rate was 81% (1070/1315 patients). The optimum model developed was the gradient boosted model with a PPV of 67%, NPV of 87%, sensitivity of 37% and a specificity of 96% for common bile duct stones. Conclusion: This paper highlights the utility of machine learning in predicting CBD stones. Accuracy is limited by current data and issues do exist around both the ethics and practicality of implementation. Regardless, machine learning represents a promising new paradigm for surgical practice. © 2020, Société Internationale de Chirurgie.},
	keywords = {Acute Disease; Adult; Aged; Aged, 80 and over; Artificial Intelligence; Biliary Tract Diseases; Bilirubin; Cholangiopancreatography, Endoscopic Retrograde; Choledocholithiasis; Computer Simulation; Female; Humans; Liver Function Tests; Machine Learning; Male; Middle Aged; Predictive Value of Tests; Retrospective Studies; bilirubin; acute disease; adult; aged; artificial intelligence; biliary tract disease; blood; common bile duct stone; computer simulation; endoscopic retrograde cholangiopancreatography; female; human; liver function test; machine learning; male; middle aged; predictive value; procedures; retrospective study; very elderly},
	correspondence_address = {I. Tranter-Entwistle; Department of General Surgery, Christchurch Hospital, Christchurch, New Zealand; email: tranter.isaac@gmail.com},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03642313},
	coden = {WJSUD},
	pmid = {33051700},
	language = {English},
	abbrev_source_title = {World J. Surg.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Prioleau20211013,
	author = {Prioleau, Diandra and Richardson, Brianna and Drobina, Emma and Williams, Rua and Martin, Joshua and Gilbert, Juan E.},
	title = {How Students in Computing-Related Majors Distinguish Social Implications of Technology},
	year = {2021},
	journal = {SIGCSE 2021 - Proceedings of the 52nd ACM Technical Symposium on Computer Science Education},
	pages = {1013 – 1019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103340801&partnerID=40&md5=22ec75fdca66fe30fcc62c5fca780ffe},
	affiliations = {University of Florida, Gainesville, FL, United States; Purdue University, West Lafayette, IN, United States},
	abstract = {The demand for machine learning and data science has grown exponentially in recent years. Yet, as the influence of these fields reach farther into daily life, the disparate impacts of these algorithms and models on more marginalized populations have also begun to surface rapidly. To address this emerging crisis, it is necessary to equip the next generation of computer scientists with the ethical tools needed to tackle these issues. Thus, an exploratory study was conducted to investigate how students who are currently enrolled in computing-related programs evaluate and understand the ethical and social impact of technology. 43 students in computing majors were presented with 5 scenarios of different technologies that utilizes machine learning to address potentially sensitive areas (e.g. policing, medical diagnosing). The long-format responses to these scenarios were qualitatively analyzed. Additionally, quantitative analysis was conducted after qualitatively coding the long-format responses into four sentiments. Ultimately, we found that participants were able to decipher the social implications of technology. However, many issues of systemic discrimination were missing from participants' analysis. Alarmingly, our findings also indicated that 50% or more of participants were not exposed to most of the technologies highlighted in the scenarios, which highlights a potential gap in computing curriculum of connecting ethics as well as racial, cultural, and socioeconomic understanding to computer science. Based on these results, we suggest that computing-related curriculum be reevaluated with ethical training in mind. © 2021 ACM.},
	author_keywords = {computing education; ethics; social implication; technology},
	keywords = {Curricula; Data Science; Diagnosis; Education computing; Engineering education; Machine learning; Philosophical aspects; Social aspects; Students; Computer scientists; Computing curricula; Computing majors; Ethical training; Exploratory studies; Sensitive area; Social impact-of-technology; Social implications of technologies; Economic and social effects},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038062-1},
	language = {English},
	abbrev_source_title = {SIGCSE - Proc. ACM Tech. Symp. Comput. Sci. Educ.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 52nd ACM Technical Symposium on Computer Science Education, SIGCSE 2021; Conference date: 13 March 2021 through 20 March 2021; Conference code: 167732}
}

@ARTICLE{Morley2021313,
	author = {Morley, Jessica and Machado, Caio C. V. and Burr, Christopher and Cowls, Josh and Joshi, Indra and Taddeo, Mariarosaria and Floridi, Luciano},
	title = {The Ethics of AI in Health Care: A Mapping Review},
	year = {2021},
	journal = {Philosophical Studies Series},
	volume = {144},
	pages = {313 – 346},
	doi = {10.1007/978-3-030-81907-1_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118775517&doi=10.1007%2f978-3-030-81907-1_18&partnerID=40&md5=514f08116bff2ec518230b2058b75ad2},
	affiliations = {Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; Alan Turing Institute, London, United Kingdom; NHSX, London, United Kingdom},
	abstract = {This article presents a mapping review of the literature concerning the ethics of artificial intelligence (AI) in health care. The goal of this review is to summarise current debates and identify open questions for future research. Five literature databases were searched (Scopus, Google Scholar, Philpapers, Web of Science, Pub Med), in April 2019, to support the following research question: “how can the primary ethical risks presented by AI-health be categorised, and what issues must policymakers, regulators and developers consider in order to be ‘ethically mindful?’”. A series of screening stages were carried out—for example, removing articles that focused on digital health in general (e.g. data sharing, data access, data privacy, surveillance/nudging, consent, ownership of health data, evidence of efficacy)—yielding a total of 156 papers that were included in the review. We find that ethical issues can be (a) epistemic, related to misguided, inconclusive or inscrutable evidence; (b) normative, related to unfair outcomes and transformative effectives; or (c) related to traceability. We further find that these ethical issues arise at six levels of abstraction: individual, interpersonal, group, institutional, and societal or sectoral. Finally, we outline a number of considerations for policymakers and regulators, mapping these to existing literature, and categorising each as epistemic, normative or traceability-related and at the relevant level of abstraction. This article contributes to the debate on AI in health care by offering a comprehensive analysis of the relevant literature, focusing on the ethical implications for individuals, interpersonal relationships, groups, institutions, societies and the health sector as a whole. Our goal is to inform policymakers, regulators and developers of what they must consider if they are to enable health and care systems to capitalise on the dual advantage of ethical AI; maximising the opportunities to cut costs, improve care, and improve the efficiency of health and care systems, whilst proactively avoiding the potential harms. We argue that if action is not swiftly taken in this regard, a new ‘AI winter’ could occur due to chilling effects related to a loss of public trust in the benefits of AI for health care. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Ethics; Health policies; Healthcare; Machine learning},
	correspondence_address = {L. Floridi; Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; email: luciano.floridi@oii.ox.ac.uk},
	publisher = {Springer Nature},
	issn = {09218599},
	language = {English},
	abbrev_source_title = {Philos. Stud. Ser.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Topaloglu2021593,
	author = {Topaloglu, Mustafa Y. and Morrell, Elisabeth M. and Topaloglu, Umit},
	title = {Federated Learning in Healthcare is the Future, But the Problems Are Contemporary},
	year = {2021},
	journal = {International Conference on Web Information Systems and Technologies, WEBIST - Proceedings},
	volume = {2021-October},
	pages = {593 – 598},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146197197&partnerID=40&md5=989120c1157db3b46a8e903da19af8a1},
	affiliations = {Department of Computer Science, Wake Forest University, Winston Salem, 27109, NC, United States; Departments of Cancer Biology and Biostatistics, Wake Forest School of Medicine, Winston Salem, 27157, NC, United States},
	abstract = {Federated Learning (FL) has originated out of a need to mitigate certain inherent limitations of ML, particularly the capability to train on larger datasets for improved performance, which is typically an unwieldy coordination for an inter-institutional collaboration due to existing patient protection laws and regulations. FL may also play a crucial role in bypassing ML's innate algorithmic discrimination issues via the access of underrepresented groups' data spanning across geographically distributed institutions and the diverse populations. FL inherits many of the difficulties of ML and as such we have discussed two pressing FL challenges, namely: privacy of the model exchange as well as equity and contribution considerations. © 2021 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved.},
	author_keywords = {Federated Learning; Machine Learning; Machine Learning Ethics; Machine Learning Legal Issues; Privacy},
	keywords = {Laws and legislation; Population statistics; Federated learning; Inherent limitations; Large datasets; Legal issues; Machine learning ethic; Machine learning legal issue; Machine-learning; Privacy; Machine learning},
	editor = {Mayo F.D. and Marchiori M. and Filipe J.},
	publisher = {Science and Technology Publications, Lda},
	issn = {21843252},
	isbn = {978-989758536-4},
	language = {English},
	abbrev_source_title = {International Conference on Web Information Systems and Technologies, WEBIST - Proceedings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 17th International Conference on Web Information Systems and Technologies, WEBIST 2021; Conference date: 26 October 2021 through 28 October 2021; Conference code: 181964}
}

@ARTICLE{Javed2021,
	author = {Javed, Saleha and Adewumi, Tosin P. and Liwicki, Foteini Simistira and Liwicki, Marcus},
	title = {Understanding the role of objectivity in machine learning and research evaluation},
	year = {2021},
	journal = {Philosophies},
	volume = {6},
	number = {1},
	doi = {10.3390/philosophies6010022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112443947&doi=10.3390%2fphilosophies6010022&partnerID=40&md5=c9cfa2c98f5b9b200b691a352b6af73e},
	affiliations = {Machine Learning Group, Department of Computer Science, Electrical and Space Engineering, EISLAB, Luleå University of Technology, Luleå, 97187, Sweden},
	abstract = {This article makes the case for more objectivity in Machine Learning (ML) research. Any research work that claims to hold benefits has to be scrutinized based on many parameters, such as the methodology employed, ethical considerations and its theoretical or technical contribution. We approach this discussion from a Naturalist philosophical outlook. Although every analysis may be subjective, it is important for the research community to keep vetting the research for continuous growth and to produce even better work. We suggest standardizing some of the steps in ML research in an objective way and being aware of various biases threatening objectivity. The ideal of objectivity keeps research rational since objectivity requires beliefs to be based on facts. We discuss some of the current challenges, the role of objectivity in the two elements (product and process) that are up for consideration in ML and make recommendations to support the research community. © 2021 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Ethics; Machine learning; Naturalism; Objectivity; Philosophy of science},
	correspondence_address = {S. Javed; Machine Learning Group, Department of Computer Science, Electrical and Space Engineering, EISLAB, Luleå University of Technology, Luleå, 97187, Sweden; email: saleha.javed@ltu.se},
	publisher = {MDPI AG},
	issn = {24099287},
	language = {English},
	abbrev_source_title = {Philos.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@ARTICLE{Arnold2021121,
	author = {Arnold, Mark Henderson},
	title = {Teasing out Artificial Intelligence in Medicine: An Ethical Critique of Artificial Intelligence and Machine Learning in Medicine},
	year = {2021},
	journal = {Journal of Bioethical Inquiry},
	volume = {18},
	number = {1},
	pages = {121 – 139},
	doi = {10.1007/s11673-020-10080-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099112321&doi=10.1007%2fs11673-020-10080-1&partnerID=40&md5=0733db0bc8fa2bbedbced418a7d25af2},
	affiliations = {School of Rural Health (Dubbo/Orange), Sydney Medical School, Faculty of Medicine and Health, University of Sydney, Sydney, Australia; Sydney Health Ethics, School of Public Health, University of Sydney, Sydney, Australia},
	abstract = {The rapid adoption and implementation of artificial intelligence in medicine creates an ontologically distinct situation from prior care models. There are both potential advantages and disadvantages with such technology in advancing the interests of patients, with resultant ontological and epistemic concerns for physicians and patients relating to the instatiation of AI as a dependent, semi- or fully-autonomous agent in the encounter. The concept of libertarian paternalism potentially exercised by AI (and those who control it) has created challenges to conventional assessments of patient and physician autonomy. The unclear legal relationship between AI and its users cannot be settled presently, an progress in AI and its implementation in patient care will necessitate an iterative discourse to preserve humanitarian concerns in future models of care. This paper proposes that physicians should neither uncritically accept nor unreasonably resist developments in AI but must actively engage and contribute to the discourse, since AI will affect their roles and the nature of their work. One’s moral imaginative capacity must be engaged in the questions of beneficence, autonomy, and justice of AI and whether its integration in healthcare has the potential to augment or interfere with the ends of medical practice. © 2021, Journal of Bioethical Inquiry Pty Ltd.},
	author_keywords = {Artificial intelligence; Epistemology; Ethics; Machine learning; Medical practice; Ontology},
	keywords = {Artificial Intelligence; Beneficence; Delivery of Health Care; Humans; Machine Learning; Medicine; artificial intelligence; beneficence; health care delivery; human; machine learning; medicine},
	correspondence_address = {M.H. Arnold; Sydney Health Ethics, School of Public Health, University of Sydney, Sydney, Australia; email: mark.arnold@sydney.edu.au},
	publisher = {Springer},
	issn = {11767529},
	pmid = {33415596},
	language = {English},
	abbrev_source_title = {J. Bioethical Inq.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Bronze Open Access, Green Open Access}
}

@BOOK{Telford2021191,
	author = {Telford, Kevin},
	title = {AI Trust, Ethics, Transparency and Enablement},
	year = {2021},
	journal = {The AI Book: The Artificial Intelligence Handbook for Investors, Entrepreneurs and FinTech Visionaries},
	pages = {191 – 194},
	doi = {10.1002/9781119551966.ch51},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160162915&doi=10.1002%2f9781119551966.ch51&partnerID=40&md5=e2cc2297b7a4251366b02b3ed847256b},
	affiliations = {Thoughtworks, United Kingdom},
	abstract = {This chapter, titled beyond artificial intelligence (Al) Reg-Tech takes the reader to a vision where trusted financial services (FS) organizations embrace a standard of trust, ethics, transparency and enablement (TETE) framework. At the intersection of creativity and enabling technology lies an abundance of new products, services and infinite new data sources. This is labeled as intelligent empowerment (IE) human and tech augmentation. AI/machine learning (ML) are components within IE. The TETE proposal is an AI/ML trust framework to encompass the growth of IE, for measuring organizational trustworthiness. As AI tech and Internet of Things deployment carry on at pace, events such as social profiling of citizens’ data for FS decisions highlights a few FS challenges. TETE will be implemented as a global standard for FS. It will start with FS self-governing, using the TETE principles through organization collaboration, such as FCA and ICO. © 2020 FINTECH Circle Ltd.},
	author_keywords = {artificial intelligence; financial services; intelligence empowerment; machine learning; TETE framework},
	publisher = {wiley},
	isbn = {978-111955196-6; 978-111955190-4},
	language = {English},
	abbrev_source_title = {The AI Book: The Artificial Intelligence Handbook for Investors, Entrepreneurs and FinTech Visionaries},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kuhn2021364,
	author = {Kuhn, Michael},
	title = {Big Data, AI, and the Pleasures of Engineering; [Big Data, AI und die Freude am Ingenieurwesen]},
	year = {2021},
	journal = {Chemie-Ingenieur-Technik},
	volume = {93},
	number = {3},
	pages = {364 – 372},
	doi = {10.1002/cite.202000221},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100483993&doi=10.1002%2fcite.202000221&partnerID=40&md5=7ed6757cc4218b4ff5b36258eabe20db},
	affiliations = {Technische Universität München, Lehrstuhl für Systemverfahrenstechnik, Gregor-Mendel-Straße 4, Freising, 85354, Germany},
	abstract = {In this provocative contribution, the consequences of Big Data and AI for the engineering sciences are critically explored. Big Data and AI are characterized by intransparency and their potential to surprise. With these characteristics, however, the pleasures of designing technology vanish and the appeal of the discipline declines. Against this, it is argued for a transparent and human technology development which is joyful and also facilitates taking responsibility. The presented argument is at its core a philosophical one, motivated by the conviction that philosophy can contribute importantly to technology. © 2021, Wiley-VCH Verlag. All rights reserved.},
	author_keywords = {Digitalization; Ethics; Industry 4.0; Machine learning; Philosophy},
	keywords = {Philosophical aspects; Engineering science; Technology development; Big data},
	correspondence_address = {M. Kuhn; Technische Universität München, Lehrstuhl für Systemverfahrenstechnik, Freising, Gregor-Mendel-Straße 4, 85354, Germany; email: michael.kuhn@tum.de},
	publisher = {Wiley-VCH Verlag},
	issn = {0009286X},
	coden = {CITEA},
	language = {German},
	abbrev_source_title = {Chem Ing Tech},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Salman2021,
	author = {Salman, Md. Sadeki and Shila, Nazmun Naher and Hasan, Khalid and Ahmed, Piash and Keya, Mumenunnessa and Khushbu, Sharun Akter and Noori, Sheak Rashed Haider},
	title = {Data Mining Technique for Prediction System of Heart Disease Using Associative Classifications},
	year = {2021},
	journal = {2021 12th International Conference on Computing Communication and Networking Technologies, ICCCNT 2021},
	doi = {10.1109/ICCCNT51525.2021.9579825},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126193249&doi=10.1109%2fICCCNT51525.2021.9579825&partnerID=40&md5=ea86461719f3eaa69b0b087b18757363},
	affiliations = {Dept. of CSE, Daffodil International University, Dhaka, Bangladesh},
	abstract = {In this study, several aspects of the human body have been focused upon. This paper attempts to cast light on pre-and post-pathological conditions, man-machine interactions, human mindset, and ethics of AI. The paper emphasizes the cultural impacts of overeating, profuse drinking, and smoking habits. It uplifts the basic necessity of growing awareness schemes. Patients are seeking treatment in health care centers with the following serious pathological conditions and complications (We exclude the COVID-19 pandemic because it has been adequately publicized by media and press): Heart Attack, Stroke Cancer, Fatty liver & liver cirrhosis. Because of being the leading causes of sudden death prediction of heart attack is very important. Our main focus is to determine the best machine learning method. With optimal parameters, we evaluate the Dataset. Model Accuracy for the heart Attack Machine Learning Model was the highest for the Logistic Regression mode land it was 93.41%. On the contrary, the accuracy for Linear Regression Model was 60.10% which was the least. © 2021 IEEE.},
	author_keywords = {BernoulliNB; Decision Tree; GaussianNB; Heart Attack Prediction; KNN; Linear Regression; Logistic Regression; Machine Learning algorithm; SVC},
	keywords = {Cardiology; Data mining; Diseases; Forecasting; Heart; Learning algorithms; Logistic regression; Machine learning; Patient treatment; Attack prediction; Bernoullinb; Gaussiannb; Heart attack; Heart attack prediction; KNN; Logistics regressions; Machine learning algorithms; Pathological conditions; SVC; Decision trees},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172818595-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Comput. Commun. Netw. Technol., ICCCNT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th International Conference on Computing Communication and Networking Technologies, ICCCNT 2021; Conference date: 6 July 2021 through 8 July 2021; Conference code: 177114}
}

@CONFERENCE{Owusu20215700,
	author = {Owusu, Maxwell and Kuffer, Monika and Belgiu, Mariana and Grippa, Tais and Lennert, Moritz and Georganos, Stefanos and Vanhuysse, Sabine},
	title = {GEO-ETHICS IN SLUM MAPPING},
	year = {2021},
	journal = {International Geoscience and Remote Sensing Symposium (IGARSS)},
	volume = {2021-July},
	pages = {5700 – 5703},
	doi = {10.1109/IGARSS47720.2021.9553570},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85126049108&doi=10.1109%2fIGARSS47720.2021.9553570&partnerID=40&md5=44d2fb513912e0bbef320943c34fc57e},
	affiliations = {Faculty of Geo-Information Science and Earth Observation (ITC), University of Twente, Enschede, 5414 AE, Netherlands; Department of Geosciences, Environment and Society, Université libre De Bruxelles (ULB), Bruxelles, 1050, Belgium},
	abstract = {Earth Observation (EO) to produce policy-driven information on slums has been receiving increasing attention amongst experts. However, the geo-ethical concerns associated with making slum information publicly available are commonly neglected among the EO community. This study analysed the geo-ethics in terms of technology, product, and application-level using topic-focused interviews in the Greater Accra Region, Ghana. We identified that potential users have little knowledge of machine learning-based slum mapping methods, which implies the need for technology and product documentation to improve the acceptability and usability of EO data. We observed an application mismatch among institutions. While NGOs and research institutions required data for pro-poor initiatives, most government institutions needed data for slum eradication. Such mismatches require a rethinking of how slum data should be made public. We present a guide to disseminate information to users in support of developing a global slum data repository. © 2021 IEEE.},
	author_keywords = {Geo-ethics; Machine learning; Slums; Urban remote sensing},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166540369-6},
	coden = {IGRSE},
	language = {English},
	abbrev_source_title = {Dig Int Geosci Remote Sens Symp (IGARSS)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2021 IEEE International Geoscience and Remote Sensing Symposium, IGARSS 2021; Conference date: 12 July 2021 through 16 July 2021; Conference code: 176845}
}

@CONFERENCE{Stark2021782,
	author = {Stark, Luke and Hoey, Jesse},
	title = {The ethics of emotion in artificial intelligence systems},
	year = {2021},
	journal = {FAccT 2021 - Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency},
	pages = {782 – 793},
	doi = {10.1145/3442188.3445939},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102619063&doi=10.1145%2f3442188.3445939&partnerID=40&md5=6c3f0aa0b1abf6c26695951443437a70},
	affiliations = {Faculty of Information and Media Studies, University of Western Ontario, London, ON, Canada; David R. Cheriton School of Computer Science, University of Waterloo, Waterloo, ON, Canada},
	abstract = {In this paper, we develop a taxonomy of conceptual models and proxy data used for digital analysis of human emotional expression and outline how the combinations and permutations of these models and data impact their incorporation into artificial intelligence (AI) systems. We argue we should not take computer scientists at their word that the paradigms for human emotions they have developed internally and adapted from other disciplines can produce ground truth about human emotions; instead, we ask how different conceptualizations of what emotions are, and how they can be sensed, measured and transformed into data, shape the ethical and social implications of these AI systems. © 2021 Owner/Author.},
	author_keywords = {Action Control Theory; Affect; Affective computing; AI; AI ethics; Artificial intelligence; Basic Emotion Theory; Emotion; Emotion AI; Ethics; Fairness; Machine learning; ML; Norms; Privacy},
	keywords = {Philosophical aspects; Transparency; Artificial intelligence systems; Computer scientists; Conceptual model; Digital analysis; Emotional expressions; Ground truth; Human emotion; Social implication; Artificial intelligence},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038309-7},
	language = {English},
	abbrev_source_title = {FAccT - Proc. ACM Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; Conference name: 4th ACM Conference on Fairness, Accountability, and Transparency, FAccT 2021; Conference date: 3 March 2021 through 10 March 2021; Conference code: 167464; All Open Access, Bronze Open Access}
}

@CONFERENCE{Hobbs2021,
	author = {Hobbs, Robert},
	title = {Integrating ethically align design into agile and CRISP-DM},
	year = {2021},
	journal = {Conference Proceedings - IEEE SOUTHEASTCON},
	volume = {2021-March},
	doi = {10.1109/SoutheastCon45413.2021.9401899},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104982769&doi=10.1109%2fSoutheastCon45413.2021.9401899&partnerID=40&md5=861772d3c1faba18efa7bbe1faddbab0},
	affiliations = {Jacksonville, FL, USA, United States},
	abstract = {The growth of Autonomous/Intelligent systems has come with notable failures to address ethical concerns. The IEEE and European Union are progressing guides defining ethical systems' behaviors; however, organizations must consider integrating ethical processes into their development methodology. The paper outlines two current ethical guides and two development frameworks to give context for a proposed integration of steps to address ethical concerns into the Agile framework. By making ethical questions part of the standard processes, the organization can convert a one-time check for ethical issues into a long-term move to an ethical organization. © 2021 IEEE.},
	author_keywords = {Agile; CRISP-DM; Development Process; Ethics; Machine Learning; Quality},
	keywords = {Agile manufacturing systems; CRISP-DM; Development frameworks; Development methodology; Ethical concerns; Ethical issues; Ethical question; European union; One-time; Philosophical aspects},
	correspondence_address = {R. Hobbs; Jacksonville, FL, United States; email: Robert.Hobbs@Computer.Org},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {07347502},
	isbn = {978-073811131-5},
	coden = {CPISD},
	language = {English},
	abbrev_source_title = {Conf Proc IEEE SOUTHEASTCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2021 SoutheastCon, SoutheastCon 2021; Conference date: 10 March 2021 through 13 March 2021; Conference code: 168566}
}

@BOOK{Balagué202199,
	author = {Balagué, Christine},
	title = {The challenge of responsible AI},
	year = {2021},
	journal = {Artificial Intelligence for Sustainable Value Creation},
	pages = {99 – 121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85130206734&partnerID=40&md5=2e6e454bb62f4ae2063668dcfae56a7d},
	affiliations = {Institut Mines-Télécom Business School (IMT-BS), France},
	abstract = {The dichotomic vision of artificial intelligence, which emerged during the last years, underlines both the benefits of machine learning in innovation and the negative consequences of AI on organizations and more globally on society. After an historical contextualization of digital transformation, this chapter first provides an understanding of the potential negative impacts of AI, second presents the concept of ethics and its application to AI systems, third describes different initiatives to tackle the issue of negative consequences of AI. It also illustrates the theoretical aspects of ethics in AI by analyzing current technologies presented at CES 2020 in Las Vegas. Finally, the chapter provides guidelines for managers to address the issue of ethics in AI, including metrics for corporate social responsibility. © Margherita Pagani and Renaud Champion 2021.},
	publisher = {Edward Elgar Publishing Ltd.},
	isbn = {978-183910439-8; 978-183910438-1},
	language = {English},
	abbrev_source_title = {Artificial Intelligence for Sustainable Value Creation},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Blake20211728,
	author = {Blake, Robert W. and Mathew, Robins and George, Abraham and Papakostas, Nikolaos},
	title = {Impact of Artificial Intelligence on Engineering: Past, Present and Future},
	year = {2021},
	journal = {Procedia CIRP},
	volume = {104},
	pages = {1728 – 1733},
	doi = {10.1016/j.procir.2021.11.291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121639548&doi=10.1016%2fj.procir.2021.11.291&partnerID=40&md5=945d704144b07041ee119277a12df4e4},
	affiliations = {Laboratory for Advanced Manufacturing Simulation and Robotics, School of Mechanical and Materials Engineering, University College Dublin, Ireland},
	abstract = {Recent advancements in cloud computing and software technology have resulted in the development of powerful Artificial Intelligence (AI) tools for engineering applications. However, the impact of AI in future engineering jobs remains ambiguous. This paper discusses recent AI developments, AI applications, the influence of AI on the Engineering profession, and the productivity of engineers. In addition, ethics, and professional impacts to be considered with the introduction of AI are addressed. The results of a survey conducted among people from Engineering colleges across Ireland are also presented. © 2021 The Author(s).},
	author_keywords = {Artificial Intelligence; Deep Learning; Ethics; Industry 4.0; Machine Learning},
	keywords = {Application programs; Engineering education; Ethical technology; Industry 4.0; Artificial intelligence tools; Cloud computing technologies; Deep learning; Engineering applications; Engineering colleges; Engineering jobs; Engineering profession; Machine-learning; Professional impacts; Software technology; Deep learning},
	correspondence_address = {N. Papakostas; Laboratory for Advanced Manufacturing Simulation and Robotics, School of Mechanical and Materials Engineering, University College Dublin, Ireland; email: nikolaos.papakostas@ucd.ie},
	editor = {Mourtzis D.},
	publisher = {Elsevier B.V.},
	issn = {22128271},
	language = {English},
	abbrev_source_title = {Procedia CIRP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 54th CIRP Conference on Manufacturing Ssystems, CMS 2021; Conference date: 22 September 2021 through 24 September 2021; Conference code: 175290; All Open Access, Gold Open Access}
}

@ARTICLE{Akter2021,
	author = {Akter, Shahriar and Dwivedi, Yogesh K. and Biswas, Kumar and Michael, Katina and Bandara, Ruwan J. and Sajib, Shahriar},
	title = {Addressing Algorithmic Bias in AI-Driven Customer Management},
	year = {2021},
	journal = {Journal of Global Information Management},
	volume = {29},
	number = {6},
	doi = {10.4018/JGIM.20211101.oa3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151789998&doi=10.4018%2fJGIM.20211101.oa3&partnerID=40&md5=5595082648720c0f7c1866fc658cfbf4},
	affiliations = {University of Wollongong, Australia; Swansea University, UK & Symbiosis Institute of Business Management, Symbiosis International (Deemed), India; Arizona State University, United States; University of Technology, Sydney, Australia},
	abstract = {Research on AI has gained momentum in recent years. Many scholars and practitioners have been increasingly highlighting the dark sides of AI, particularly related to algorithm bias.. This study elucidates situations in which AI-enabled analytics systems make biased decisions against customers based on gender, race, religion, age, nationality, or socioeconomic status. Based on a systematic literature review, this research proposes two approaches (i.e., a priori and post-hoc) to overcome such biases in customer management. As part of a priori approach, the findings suggest scientific, application, stakeholder, and assurance consistencies. With regard to the post-hoc approach, the findings recommend six steps: bias identification, review of extant findings, selection of the right variables, responsible and ethical model development, data analysis, and action on insights. Overall, this study contributes to the ethical and responsible use of AI applications. © 2021 IGI Global. All rights reserved.},
	author_keywords = {AI Ethics; Algorithm Bias; Artificial Intelligence; Machine Learning; Responsible AI},
	keywords = {Learning algorithms; Philosophical aspects; Sales; AI ethic; Algorithm bias; Algorithmics; Analytics systems; Customer managements; Machine-learning; Responsible AI; Scientific applications; Socio-economic status; Systematic literature review; Machine learning},
	publisher = {IGI Global},
	issn = {10627375},
	language = {English},
	abbrev_source_title = {J. Global Inf. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Cernadas2021,
	author = {Cernadas, Eva and Fernández-Delgado, Manuel},
	title = {Embedded ethics to teach machine learning courses: An experience},
	year = {2021},
	journal = {Proceedings - 11th International Conference on Virtual Campus, JICV 2021},
	doi = {10.1109/JICV53222.2021.9600426},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123167615&doi=10.1109%2fJICV53222.2021.9600426&partnerID=40&md5=2dfcecf1fb273fd0e3ac570cf88ed9bb},
	affiliations = {University of Santiago de Compostela, Centro Singular de Investigación en Tecnoloxías Intelixentes da USC (CiTIUS), Santiago de Compostela, Spain},
	abstract = {Artificial intelligence offers many possibilities, some can improve the well-being of people, but others can be harmful to citizens, especially women. Examples are hiring decision support systems, criminal justice, facial and voice recognition, or machine translators. In order to make students aware of the development of these intelligent systems in the future, it is necessary to incorporate specific ethics content with a gender perspective as a transversal competence in university degrees and masters related to artificial intelligence and machine learning. In this paper we present the experiences in two subjects of machine learning, one undergraduate and one master, which are taught for the first time in the academic year 2020-2021 at the University of Santiago de Compostela. The activity allowed students to reflect on ethical and gender issues in the exercise of their professional future for the development of machine learning systems.  © 2021 IEEE.},
	author_keywords = {artificial intelligence; gender; inequality; machine learning},
	keywords = {Decision support systems; Ethical technology; Machine learning; Criminal justice; Ethical issues; Gender issues; Inequality; Machine learning systems; Machine translator; University degree; Well being; Intelligent systems},
	editor = {Garcia-Holgado A. and Garcia-Penalvo F.J. and Carina S. C.S. and Infante-Moro A. and Infante-Moro J.C.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166543703-5},
	language = {English},
	abbrev_source_title = {Proc. - Int. Conf. Virtual Campus, JICV},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 11th International Conference on Virtual Campus, JICV 2021; Conference date: 30 September 2021 through 1 October 2021; Conference code: 174030}
}

@ARTICLE{Green2021397,
	author = {Green, Nancy L.},
	title = {Argumentation schemes: From genetics to international relations to environmental science policy to AI ethics},
	year = {2021},
	journal = {Argument and Computation},
	volume = {12},
	number = {3},
	pages = {397 – 416},
	doi = {10.3233/AAC-210551},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119404084&doi=10.3233%2fAAC-210551&partnerID=40&md5=dd92f56ded03843c9d2bec447d361459},
	affiliations = {University of North Carolina Greensboro, Greensboro, 27402, NC, United States},
	abstract = {Argumentation schemes have played a key role in our research projects on computational models of natural argument over the last decade. The catalogue of schemes in Walton, Reed and Macagno's 2008 book, Argumentation Schemes, served as our starting point for analysis of the naturally occurring arguments in written text, i.e., text in different genres having different types of author, audience, and subject domain (genetics, international relations, environmental science policy, AI ethics), for different argument goals, and for different possible future applications. We would often first attempt to analyze the arguments in our corpora in terms of those schemes, then adapt schemes as needed for the goals of the project, and in some cases implement them for use in computational models. Among computational researchers, the main interest in argumentation schemes has been for use in argument mining by applying machine learning methods to existing argument corpora. In contrast, a primary goal of our research has been to learn more about written arguments themselves in various contemporary fields. Our approach has been to manually analyze semantics, discourse structure, argumentation, and rhetoric in texts. Another goal has been to create sharable digital corpora containing the results of our studies. Our approach has been to define argument schemes for use by human corpus annotators or for use in logic programs for argument mining. The third goal is to design useful computer applications based upon our studies, such as argument diagramming systems that provide argument schemes as building blocks. This paper describes each of the various projects: the methods, the argument schemes that were identified, and how they were used. Then a synthesis of the results is given with a discussion of open issues.  © 2021-The authors. Published by IOS Press.},
	author_keywords = {argument corpus; argument generation; argument mining; argument modeling systems; Argumentation schemes; computational models of natural argument},
	keywords = {Computational methods; Learning systems; Logic programming; Philosophical aspects; Semantics; Argument corpus; Argument generation; Argument mining; Argument modeling system; Argument models; Argumentation schemes; Computational model of natural argument; Computational modelling; International relations; Modelling systems; Computation theory},
	correspondence_address = {N.L. Green; University of North Carolina Greensboro, Greensboro, 27402, United States; email: nlgreen@uncg.edu},
	publisher = {IOS Press BV},
	issn = {19462166},
	language = {English},
	abbrev_source_title = {Argum. Comput.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Pinka2021121,
	author = {Pinka, Robert},
	title = {Synthetic Deliberation: Can Emulated Imagination Enhance Machine Ethics?},
	year = {2021},
	journal = {Minds and Machines},
	volume = {31},
	number = {1},
	pages = {121 – 136},
	doi = {10.1007/s11023-020-09531-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087942371&doi=10.1007%2fs11023-020-09531-w&partnerID=40&md5=2ccd2bf08daeb9afaad910d87d439e5e},
	affiliations = {Department of Philosophy, University of North Carolina at Charlotte, Charlotte, NC, United States},
	abstract = {Artificial intelligence is becoming increasingly entwined with our daily lives: AIs work as assistants through our phones, control our vehicles, and navigate our vacuums. As these objects become more complex and work within our societies in ways that affect our well-being, there is a growing demand for machine ethics—we want a guarantee that the various automata in our lives will behave in a way that minimizes the amount of harm they create. Though many technologies exist as moral artifacts (and perhaps moral agents), the development of a truly ethical AI system is highly contentious; theorists have proposed and critiqued countless possibilities for programming these agents to become ethical. Many of these arguments, however, presuppose the possibility that an artificially intelligent system can actually be ethical. In this essay, I will explore a potential path to AI ethics by considering the role of imagination in the deliberative process via the work of John Dewey and his interpreters, showcasing one form of reinforcement learning that mimics imaginative deliberation. With these components in place, I contend that such an artificial agent is capable of something very near ethical behavior—close enough that we may consider it so. © 2020, Springer Nature B.V.},
	author_keywords = {Artificial intelligence; Machine ethics; Machine learning; Philosophy of technology; Pragmatism; STS},
	keywords = {Intelligent systems; Reinforcement learning; AI systems; Artificial agents; Daily lives; Deliberative process; Ethical behavior; Growing demand; Moral agents; Well being; Philosophical aspects},
	correspondence_address = {R. Pinka; Department of Philosophy, University of North Carolina at Charlotte, Charlotte, United States; email: rpinka@uncc.edu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Campolo202183,
	author = {Campolo, Alexander},
	title = {“Thinking, Judging, Noticing, Feeling”: John W. Tukey against the Mechanization of Inferential Knowledge},
	year = {2021},
	journal = {Know},
	volume = {5},
	number = {1},
	pages = {83 – 111},
	doi = {10.1086/713021},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116046060&doi=10.1086%2f713021&partnerID=40&md5=6c899cf49e72c7cf960b1f4d4cee8067},
	affiliations = {University of Chicago, United States},
	abstract = {During the past half-century, a set of statistical techniques and ideas about inference have experienced a remarkable scientific success. Significance at the 5 percent level has come to mark a clear and distinct criterion for scientific knowledge in a wide range of fields. Recently, however, this convention has been embroiled in controversy, as the relentless pursuit of significance has produced a range of well-known scientific abuses. Instead of staking out a position in these debates, this article analyzes the history of epistemological values underlying them. It focuses on an earlier critic of the misuse of statistical tests: John W. Tukey. Speaking to behavioral scientists in the middle of the twentieth century, Tukey insisted that reducing inference to a set of universal rules or mechanical procedures to eliminate uncertainty was a pursuit doomed to failure. Scientists needed to accept the irreducibility of individual judgments and decisions in data analysis, even when they risked charges of subjectivism or arbitrariness. For Tukey, the enforcement of scientific consensus and even the value of objectivity must yield to empirical judgments and an ethic of individual conscience. These values were informed by his comparative understanding of the history of science, which reserved a special place for empiricism in younger sciences. Reconstructing Tukey’s work offers an alternative perspective on the quantitative, formal objectivity of the postwar sciences as well as the present, where big data and machine learning have raised thorny new problems for statistical inference and scientific expertise © 2021, University of Chicago Press. All rights reserved.},
	publisher = {University of Chicago Press},
	issn = {2473599X},
	language = {English},
	abbrev_source_title = {Know.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shung2021295,
	author = {Shung, Dennis L and Sung, Joseph J Y},
	title = {Challenges of developing artificial intelligence-assisted tools for clinical medicine},
	year = {2021},
	journal = {Journal of Gastroenterology and Hepatology (Australia)},
	volume = {36},
	number = {2},
	pages = {295 – 298},
	doi = {10.1111/jgh.15378},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101751266&doi=10.1111%2fjgh.15378&partnerID=40&md5=fadce131ba95ad004737eebcc90d3125},
	affiliations = {Yale School of Medicine, New Haven, CT, United States; Nanyang Technological University, Singapore, Singapore},
	abstract = {Machine learning, a subset of artificial intelligence (AI), is a set of computational tools that can be used to enhance provision of clinical care in all areas of medicine. Gastroenterology and hepatology utilize multiple sources of information, including visual findings on endoscopy, radiologic imaging, manometric testing, genomes, proteomes, and metabolomes. However, clinical care is complex and requires a thoughtful approach to best deploy AI tools to improve quality of care and bring value to patients and providers. On the operational level, AI-assisted clinical management should consider logistic challenges in care delivery, data management, and algorithmic stewardship. There is still much work to be done on a broader societal level in developing ethical, regulatory, and reimbursement frameworks. A multidisciplinary approach and awareness of AI tools will create a vibrant ecosystem for using AI-assisted tools to guide and enhance clinical practice. From optically enhanced endoscopy to clinical decision support for risk stratification, AI tools will potentially transform our practice by leveraging massive amounts of data to personalize care to the right patient, in the right amount, at the right time. © 2021 Journal of Gastroenterology and Hepatology Foundation and John Wiley & Sons Australia, Ltd},
	author_keywords = {artificial intelligence; digestive system diseases; machine learning},
	keywords = {Data Management; Decision Making, Computer-Assisted; Delivery of Health Care; Diagnostic Imaging; Endoscopy; Endoscopy, Gastrointestinal; Gastroenterology; Genome; Humans; Machine Learning; Metabolome; Precision Medicine; Proteome; Quality Improvement; Quality of Health Care; Risk Assessment; proteome; Article; artificial intelligence; clinical medicine; cost effectiveness analysis; decision support system; endoscopy; gastrointestinal disease; health care delivery; human; information processing; machine learning; medical ethics; medical liability; patient care; priority journal; quality control; reimbursement; diagnostic imaging; gastroenterology; gastrointestinal endoscopy; genome; health care quality; machine learning; metabolome; personalized medicine; procedures; risk assessment; total quality management},
	correspondence_address = {D.L. Shung; Yale School of Medicine, New Haven, United States; email: dennis.shung@yale.edu},
	publisher = {Blackwell Publishing},
	issn = {08159319},
	coden = {JGHEE},
	pmid = {33624889},
	language = {English},
	abbrev_source_title = {J. Gastroenterol. Hepatol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}@ARTICLE{Prabakaran2021,
	author = {Prabakaran, Ponraj and Rao, Sambasiva P and Wendt, Maria},
	title = {Animal immunization merges with innovative technologies: A new paradigm shift in antibody discovery},
	year = {2021},
	journal = {mAbs},
	volume = {13},
	number = {1},
	doi = {10.1080/19420862.2021.1924347},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105424969&doi=10.1080%2f19420862.2021.1924347&partnerID=40&md5=874a9a1da2b8d0a62044ddadfe291a79},
	affiliations = {Biologics Research US, Global Large Molecules Research, Sanofi, Framingham, MA, United States},
	abstract = {Animal-derived antibody sources, particularly, transgenic mice that are engineered with human immunoglobulin loci, along with advanced antibody generation technology platforms have facilitated the discoveries of human antibody therapeutics. For example, isolation of antigen-specific B cells, microfluidics, and next-generation sequencing have emerged as powerful tools for identifying and developing monoclonal antibodies (mAbs). These technologies enable not only antibody drug discovery but also lead to the understanding of B cell biology, immune mechanisms and immunogenetics of antibodies. In this perspective article, we discuss the scientific merits of animal immunization combined with advanced methods for antibody generation as compared to animal-free alternatives through in-vitro-generated antibody libraries. The knowledge gained from animal-derived antibodies concerning the recombinational diversity, somatic hypermutation patterns, and physiochemical properties is found more valuable and prerequisite for developing in vitro libraries, as well as artificial intelligence/machine learning methods to discover safe and effective mAbs. © 2021 The Author(s). Published with license by Taylor & Francis Group, LLC.},
	author_keywords = {Animal immunization; animal-derived antibody; antibody discovery; antibody technologies; monoclonal antibody (mAb)},
	keywords = {Animals; Antibodies, Monoclonal, Humanized; Drug Discovery; Humans; Mice; adalimumab; caplacizumab; monoclonal antibody; velocimmune; monoclonal antibody; antibody library; Article; artificial intelligence; B lymphocyte; cell isolation; computer model; drug development; high throughput sequencing; human; hybridoma; immune response; immunization; machine learning; medical technology; microfluidics; nonhuman; physical chemistry; somatic hypermutation; animal; drug development; ethics; immunology; mouse; procedures},
	correspondence_address = {P. Prabakaran; Large Molecule Research Sanofi, Framingham, 01701, United States; email: Prabakaran.ponraj@sanofi.com},
	publisher = {Bellwether Publishing, Ltd.},
	issn = {19420862},
	pmid = {33947305},
	language = {English},
	abbrev_source_title = {mAbs},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Dolganova202134,
	author = {Dolganova, Olga I.},
	title = {Improving customer experience with artificial intelligence by adhering to ethical principles},
	year = {2021},
	journal = {Business Informatics},
	volume = {15},
	number = {2},
	pages = {34 – 46},
	doi = {10.17323/2587-814X.2021.2.34.46},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109134435&doi=10.17323%2f2587-814X.2021.2.34.46&partnerID=40&md5=860d54e6e6ee3475bd601ee791f320a7},
	affiliations = {Financial University under the Government of the Russian Federation, Address: 38 Scherbakovskaya Street, Moscow, 105187, Russian Federation},
	abstract = {The intensive development and application of artificial intelligence technologies in organizing interaction with clients is accompanied by such difficulties as: The client's unwillingness to communicate with the robot, distrust, fear, negative experience of the clients. Such problems can be solved by adhering to ethical principles of using artificial intelligence. In scientific and practical research on this topic, there are many general recommendations that are difficult to apply in practice, or, on the contrary, that describe the methods for solving a highly specialized technical or management problem. The purpose of this article is to determine the ethical principles and methods, the observance and implementation of which would increase confidence in artificial intelligence systems among client of a particular organization. As a result of the analysis and synthesis of the scientific and practical investigations, as well as the empirical experience of Russian and foreign companies, the main areas of application of artificial intelligence technologies affecting the customer experience were identified. The ethical principles recommended to be followed by business have been formulated and systematized. The main methods have been also identified to enable implementation of these principles in practice, and so to reduce the negative effects of customer interaction with artificial intelligence and increase their confidence in the company. © 2021 Business Informatics.},
	author_keywords = {Artificial intelligence (AI); Customer experience; Ethical AI; Ethical principles; Ethics; Machine learning; Robot; Trust},
	correspondence_address = {O.I. Dolganova; Financial University under the Government of the Russian Federation, Moscow, Address: 38 Scherbakovskaya Street, 105187, Russian Federation; email: oidolganova@fa.ru},
	publisher = {National Research University, Higher School of Econoimics},
	issn = {2587814X},
	language = {English},
	abbrev_source_title = {Bus. inform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{2021,
	title = {20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12896 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115191822&partnerID=40&md5=dd33c6f1dc80f55f3f9baa7b5865bb76},
	abstract = {The proceedings contain 65 papers. The special focus in this conference is on e-Business, e-Services and e-Society. The topics include: Data-Driven Collaborative Human-AI Decision Making; Always Trust the Advice of AI in Difficulties? Perceptions Around AI in Decision Making; big Data Analytics Affordances for Social Innovation: A Theoretical Framework; COVID-19 Discrepancies Rising from Population Density Political Polarization Exacerbates Policy Gap; Ethics and AI Issues: Old Container with New Wine?; governing Artificial Intelligence and Algorithmic Decision Making: Human Rights and Beyond; Analysing AI via Husserl and Kuhn How a Phenomenological Approach to Artificial Intelligence Imposes a Paradigm Shift; the Ethical Implications of Lawtech; Deploying AI Governance Practices: A Revelatory Case Study; AI in the Workplace: Exploring Chatbot Use and Users’ Emotions; Towards Ecosystems for Responsible AI: Expectations on Sociotechnical Systems, Agendas, and Networks in EU Documents; Ethics in AI: A Software Developmental and Philosophical Perspective; stop Ordering Machine Learning Algorithms by Their Explainability! An Empirical Investigation of the Tradeoff Between Performance and Explainability; Gender Bias in AI: Implications for Managerial Practices; a Systematic Review of Fairness in Artificial Intelligence Algorithms; is Downloading This App Consistent with My Values?: Conceptualizing a Value-Centered Privacy Assistant; operationalization of a Glass Box Through Visualization: Applied to a Data Driven Profiling Approach; artificial Intelligence and the Evolution of Managerial Skills: An Exploratory Study; the Diffusion of Innovation Experience: Leveraging the Human Factor to Improve Technological Adoption Within an Organisation; exploring the Link Between Digitalization and Sustainable Development: Research Agendas; industry 4.0 and Organisations: Key Organisational Capabilities.},
	editor = {Dennehy D. and Griva A. and Pouloudi N. and Dwivedi Y.K. and Dwivedi Y.K. and Pappas I. and Pappas I. and Mantymaki M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303085446-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 264489}
}

@ARTICLE{Kellmeyer2021241,
	author = {Kellmeyer, Philipp},
	title = {Artificial intelligence in basic and clinical neuroscience: Opportunities and ethical challenges},
	year = {2021},
	journal = {Neuroforum},
	volume = {25},
	number = {4},
	pages = {241 – 250},
	doi = {10.1515/nf-2019-0018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072280804&doi=10.1515%2fnf-2019-0018&partnerID=40&md5=654fde9a046dbcece15acaed0b33938e},
	affiliations = {Neuromedical Artificial Intelligence Lab, Department of Neurosurgery, Medical Center - University of Freiburg, Engelbergerstr. 21, Freiburg im Breisgau, D-79106, Germany; Freiburg Institute for Advanced Studies (FRIAS), University of Freiburg, Germany; Cluster of Excellence BrainLinks-BrainTools, University of Freiburg, Germany; Institute for Biomedical Ethics and History of Medicine, University of Zurich, Switzerland},
	abstract = {The analysis of large amounts of personal data with artificial neural networks for deep learning is the driving technology behind new artificial intelligence (AI) systems for all areas in science and technology. These AI methods have evolved from applications in computer vision, the automated analysis of images, and now include frameworks and methods for analyzing multimodal data-sets that combine data from many different source, including biomedical devices, smartphones and common user behavior in cyberspace. For neuroscience, these widening streams of personal data and machine learning methods provide many opportunities for basic data-driven research as well as for developing new tools for diagnostic, predictive and therapeutic applications for disorders of the nervous system. The increasing automation and autonomy of AI systems, however, also creates substantial ethical challenges for basic research and medical applications. Here, scientific and medical opportunities as well ethical challenges are summarized and discussed. © 2019 Kellmeyer, published by De Gruyter.},
	author_keywords = {Artificial intelligence; Big data; Deep learning; Machine learning; Neuroethics},
	keywords = {artificial intelligence; big data; deep learning; human; human computer interaction; identity; machine learning; medical ethics; neuroscience; personal autonomy; privacy; Review; statistical bias; trust},
	correspondence_address = {P. Kellmeyer; Neuromedical Artificial Intelligence Lab, Department of Neurosurgery, Medical Center - University of Freiburg, Freiburg im Breisgau, Engelbergerstr. 21, D-79106, Germany; email: philipp.kellmeyer@uniklinik-freiburg.de},
	publisher = {De Gruyter Open Ltd},
	issn = {09470875},
	language = {English},
	abbrev_source_title = {Neuroforum},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Zhang2021111,
	author = {Zhang, Qingquan and Liu, Jialin and Zhang, Zeqi and Wen, Junyi and Mao, Bifei and Yao, Xin},
	title = {Fairer Machine Learning Through Multi-objective Evolutionary Learning},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12894 LNCS},
	pages = {111 – 123},
	doi = {10.1007/978-3-030-86380-7_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115673628&doi=10.1007%2f978-3-030-86380-7_10&partnerID=40&md5=da293a478b6328473b9eaf64f6f8a7d0},
	affiliations = {Research Institute of Trustworthy Autonomous System, Southern University of Science and Technology (SUSTech), Shenzhen, China; Guangdong Provincial Key Laboratory of Brain-inspired Intelligent Computation, Department of Computer Science and Engineering, Southern University of Science and Technology (SUSTech), Shenzhen, China; Trustworthiness Theory Research Center, Huawei Technologies Co., Ltd., Shenzhen, China},
	abstract = {Dilemma between model accuracy and fairness in machine learning models has been shown theoretically and empirically. So far, dozens of fairness measures have been proposed, among which incompatibility and complementarity exist. However, no fairness measure has been universally accepted as the single fairest measure. No one has considered multiple fairness measures simultaneously. In this paper, we propose a multi-objective evolutionary learning framework for mitigating unfairness caused by considering a single measure only, in which a multi-objective evolutionary algorithm is used during training to balance accuracy and multiple fairness measures simultaneously. In our case study, besides the model accuracy, two fairness measures that are conflicting to each other are selected. Empirical results show that our proposed multi-objective evolutionary learning framework is able to find Pareto-front models efficiently and provide fairer machine learning models that consider multiple fairness measures. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {AI ethics; Discrimination in machine learning; Fairness in machine learning; Fairness measures; Multi-objective learning},
	keywords = {Evolutionary algorithms; AI ethic; Discrimination in machine learning; Evolutionary Learning; Fairness in machine learning; Fairness measures; Learning frameworks; Machine learning models; Modeling accuracy; Multi-objective evolutionary; Multi-objective learning; Machine learning},
	correspondence_address = {X. Yao; Research Institute of Trustworthy Autonomous System, Southern University of Science and Technology (SUSTech), Shenzhen, China; email: xiny@sustech.edu.cn},
	editor = {Farkaš I. and Masulli P. and Otte S. and Wermter S.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303086379-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 30th International Conference on Artificial Neural Networks, ICANN 2021; Conference date: 14 September 2021 through 17 September 2021; Conference code: 265279}
}

@ARTICLE{Romero-Rivas2021,
	author = {Romero-Rivas, Carlos and Rodriguez-Cuadrado, Sara},
	title = {The Psychological Impact of the COVID-19 Pandemic Affected Decision-Making Processes},
	year = {2021},
	journal = {Spanish Journal of Psychology},
	doi = {10.1017/SJP.2021.14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102873883&doi=10.1017%2fSJP.2021.14&partnerID=40&md5=fedca4dcf0d108ea35dd1953a1545825},
	affiliations = {Universidad Autónoma de Madrid, Madrid, 28049, Spain},
	abstract = {A sample of 641 participants were presented with four decision-making tasks during the first stages of the COVID-19 lockdown in Spain: The dictator game, framing problems, utilitarian/deontological and altruistic/egoistic moral dilemmas. Participants also completed questionnaires on mental health status and experiences related to the COVID-19 pandemic. We used boosted regression trees (an advanced form of regression analysis based on machine learning) to model relationships between responses to the questionnaires and decision-making tasks. Results showed that the psychological impact of the COVID-19 pandemic predicted participants' responses to the framing problems and utilitarian/deontological and altruistic/egoistic moral dilemmas (but not to the dictator game). More concretely, the more psychological impact participants suffered, the more they were willing to choose the safest response in the framing problems, and the more deontological/altruistic were their responses to moral dilemmas. These results suggest that the psychological impact of the COVID-19 pandemic might prompt automatic processes. © Universidad Complutense de Madrid and Colegio Oficial de Psicólogos de Madrid 2021.},
	author_keywords = {COVID-19; decision-making; dictator game; framing problems; moral dilemmas},
	keywords = {Adolescent; Adult; Aged; Altruism; Anxiety; COVID-19; Decision Making; Depression; Ethical Theory; Ethics; Female; Humans; Machine Learning; Male; Mental Health; Middle Aged; Morals; Regression Analysis; SARS-CoV-2; Spain; Stress, Psychological; Young Adult; adolescent; adult; aged; altruism; anxiety; decision making; depression; ethical theory; ethics; female; human; machine learning; male; mental health; mental stress; middle aged; morality; psychology; regression analysis; Spain; young adult},
	correspondence_address = {C. Romero-Rivas; Universidad Autónoma de Madrid, Madrid, 28049, Spain; email: carlos.romeror@uam.es},
	publisher = {Cambridge University Press},
	issn = {11387416},
	pmid = {33745483},
	language = {English},
	abbrev_source_title = {Span. J. Psychol.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@ARTICLE{Jackson2021,
	author = {Jackson, Brian R. and Ye, Ye and Crawford, James M. and Becich, Michael J. and Roy, Somak and Botkin, Jeffrey R. and de Baca, Monica E. and Pantanowitz, Liron},
	title = {The Ethics of Artificial Intelligence in Pathology and Laboratory Medicine: Principles and Practice},
	year = {2021},
	journal = {Academic Pathology},
	volume = {8},
	doi = {10.1177/2374289521990784},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101149634&doi=10.1177%2f2374289521990784&partnerID=40&md5=63b2e8f23f9b4c04936d98f1819aa397},
	affiliations = {Department of Pathology, University of Utah School of Medicine, Salt Lake City, UT, United States; ARUP Laboratories, Salt Lake City, UT, United States; Department of Biomedical Informatics, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Department of Pathology and Laboratory Medicine, Donald and Barbara Zucker School of Medicine at Hofstra/Northwell, Hempstead, NY, United States; Division of Pathology, Cincinnati Children’s Hospital Medical Center, Cincinnati, OH, United States; Department of Pediatrics, University of Utah School of Medicine, Salt Lake City, UT, United States; Pacific Pathology Partners, Seattle, WA, United States; Department of Pathology, University of Michigan, Ann Arbor, MI, United States},
	abstract = {Growing numbers of artificial intelligence applications are being developed and applied to pathology and laboratory medicine. These technologies introduce risks and benefits that must be assessed and managed through the lens of ethics. This article describes how long-standing principles of medical and scientific ethics can be applied to artificial intelligence using examples from pathology and laboratory medicine. © The Author(s) 2021.},
	author_keywords = {algorithms; artificial intelligence; big data; ethics; machine learning; privacy},
	correspondence_address = {B.R. Jackson; Department of Pathology, University of Utah School of Medicine, Salt Lake City, United States; email: brian.jackson@aruplab.com; B.R. Jackson; ARUP Laboratories, Salt Lake City, United States; email: brian.jackson@aruplab.com},
	publisher = {SAGE Publications Ltd},
	issn = {23742895},
	language = {English},
	abbrev_source_title = {Acad.  Pathol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Parums2021,
	author = {Parums, Dinah V.},
	title = {Editorial: Artificial intelligence (ai) in clinical medicine and the 2020 consort-ai study guidelines},
	year = {2021},
	journal = {Medical Science Monitor},
	volume = {27},
	doi = {10.12659/MSM.933675},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109715554&doi=10.12659%2fMSM.933675&partnerID=40&md5=bc2c708654f679568e56ec84631f8d8c},
	affiliations = {International Scientific Information Inc., Melville, NY, United States},
	abstract = {Artificial intelligence (AI) in clinical medicine includes physical robotics and devices and virtual AI and machine learning. Concerns have been raised regarding ethical issues for the use of AI in surgery, including guidance for surgical decisions, patient confidentiality, and the need for support from controlled clinical trials to use these methods so that clinical guidelines can be developed. The most common applications for virtual AI include disease diagnosis, health monitoring and digital patient consultations, clinical training, patient data management, drug development, and personalized medicine. In September 2020, the CONSORT-A1 extension was developed with 14 additional items that should be reported for AI studies that include clear descriptions of the AI intervention, skills required, study setting, inputs and outputs of the AI intervention, analysis of errors, and the human and AI interactions. This Editorial aims to present current applications and challenges of AI in clinical medicine and the importance of the new 2020 CONSORT-AI study guidelines. © 2021 International Scientific Information, Inc.. All rights reserved.},
	author_keywords = {Artificial Intelligence; Editorial; Guidelines as Topicl; Machine Learning; Robotics},
	keywords = {Artificial Intelligence; Clinical Medicine; Ethics, Clinical; Humans; Practice Guidelines as Topic; Research Design; Surgical Procedures, Operative; artificial intelligence; clinical medicine; ethics; human; medical ethics; methodology; practice guideline; procedures; surgery},
	correspondence_address = {D.V. Parums; International Scientific Information Inc., Melville, United States; email: dinah.v.parums@isi-science.com},
	publisher = {International Scientific Information, Inc.},
	issn = {12341010},
	coden = {MSMOF},
	pmid = {34176921},
	language = {English},
	abbrev_source_title = {Med. Sci. Monit.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Scola2021378,
	author = {Scola, Leila},
	title = {Artificial Intelligence Against Climate Change},
	year = {2021},
	journal = {Lecture Notes in Networks and Systems},
	volume = {284},
	pages = {378 – 397},
	doi = {10.1007/978-3-030-80126-7_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112720705&doi=10.1007%2f978-3-030-80126-7_29&partnerID=40&md5=c8eff8376bd621273bf84e40aaf82fe9},
	affiliations = {School of Engineering, Santa Clara University, Santa Clara, United States},
	abstract = {The industrial, transportation, and residential sectors draw the most energy in the United States. With most energy created by burning fossil fuels, a highly inefficient method of energy creation, global greenhouse gas levels are rising, raising the temperature of the earth, causing natural processes to become unbalanced. The health of the earth is declining. The rise of technology and persisting growth of computing devices known as the Internet of Things (IoT) and increasing automation of systems through Artificial Intelligence (AI) and Machine Learning (ML) is a factor of energy expenditure as more humans desire devices and more systems are built. The ethical implications of utilizing new technology should be evaluated before creating more. This paper explores modern computing systems in the sectors that draw the most energy, and, more specifically, the role AI and IoT play in them. Each sector may become more energy efficient, productive, and safer by introducing edge computing through IoT devices and coupling it with AI computing abilities that already automate most processes. Multiple studies show energy consumption and costs are lowered when edge computing is paired with the IoT and AI. There is less human involvement, more regularity in execution and performance, and more widespread use because of the accessibility. This creates safer, cheaper, energy-efficient systems that utilize existing technology. The ethical implications of these systems are much more positive than what already exists. Coupling the power of AI with the IoT will reduce energy expenditure in modern systems and create a more sustainable world. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial Intelligence; Edge computing; Energy efficiency; Ethics; Fog computing; Internet of Things; Machine learning; Sustainability},
	correspondence_address = {L. Scola; School of Engineering, Santa Clara University, Santa Clara, United States; email: leila.a.scola@gmail.com},
	editor = {Arai K.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303080125-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Computing Conference, 2021; Conference date: 15 July 2021 through 16 July 2021; Conference code: 262429}
}

@ARTICLE{Stahl2021374,
	author = {Stahl, B.C. and Andreou, A. and Brey, P. and Hatzakis, T. and Kirichenko, A. and Macnish, K. and Laulhé Shaelou, S. and Patel, A. and Ryan, M. and Wright, D.},
	title = {Artificial intelligence for human flourishing – Beyond principles for machine learning},
	year = {2021},
	journal = {Journal of Business Research},
	volume = {124},
	pages = {374 – 388},
	doi = {10.1016/j.jbusres.2020.11.030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098925550&doi=10.1016%2fj.jbusres.2020.11.030&partnerID=40&md5=644281bf13242697104ad2dcb4fb88c0},
	affiliations = {De Montfort University, United Kingdom; University of Twente, Netherlands; Trilateral Research, United Kingdom; F-Secure, Finland; Aequitas, Cyprus; University of Central Lancashire, Cyprus; Wageningen University & Research, Netherlands},
	abstract = {The technical and economic benefits of artificial intelligence (AI) are counterbalanced by legal, social and ethical issues. It is challenging to conceptually capture and empirically measure both benefits and downsides. We therefore provide an account of the findings and implications of a multi-dimensional study of AI, comprising 10 case studies, five scenarios, an ethical impact analysis of AI, a human rights analysis of AI and a technical analysis of known and potential threats and vulnerabilities. Based on our findings, we separate AI ethics discourse into three streams: (1) specific issues related to the application of machine learning, (2) social and political questions arising in a digitally enabled society and (3) metaphysical questions about the nature of reality and humanity. Human rights principles and legislation have a key role to play in addressing the ethics of AI. This work helps to steer AI to contribute to human flourishing. © 2020 The Author(s)},
	author_keywords = {Artificial intelligence; Big data; Ethics; Governance; Human rights},
	correspondence_address = {B.C. Stahl; De Montfort University, The Gateway, Leicester, LE2 9BH, United Kingdom; email: bstahl@dmu.ac.uk},
	publisher = {Elsevier Inc.},
	issn = {01482963},
	coden = {JBRED},
	language = {English},
	abbrev_source_title = {J. Bus. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 47; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Mühlhoff2020867,
	author = {Mühlhoff, Rainer},
	title = {Automatisierte Ungleichheit Ethik der Künstlichen Intelligenz in der biopolitischen Wende des Digitalen Kapitalismus},
	year = {2020},
	journal = {Deutsche Zeitschrift fur Philosophie},
	volume = {68},
	number = {6},
	pages = {867 – 890},
	doi = {10.1515/dzph-2020-0059},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098142880&doi=10.1515%2fdzph-2020-0059&partnerID=40&md5=de86ed3267ce6db7cf3595a9dac50251},
	affiliations = {Technische Universität Berlin, Cluster Science of Intelligence, Marchstraße 23, Berlin, 10587, Germany},
	abstract = {This paper sets out the notion of a current "biopolitical turn of digital capitalism"resulting from the increasing deployment of AI and data analytics technologies in the public sector. With applications of AI-based automated decisions currently shifting from the domain of business to customer (B2C) relations to government to citizen (G2C) relations, a new form of governance arises that operates through "algorithmic social selection". Moreover, the paper describes how the ethics of AI is at an impasse concerning these larger societal and socioeconomic trends and calls for an ethics of AI that includes, and acts in close alliance with, social and political philosophy. As an example, the problem of Predictive Analytics is debated to make the point that data-driven AI (Machine Learning) is currently one of the main ethical challenges in the ethics of AI.  © 2020 Walter de Gruyter GmbH, Berlin/Boston 2020.},
	author_keywords = {automated decision-making; biopolitics; critical theory; digital capitalism; ethics of AI; Machine Learning; Predictive Analytics; social philosophy; social selection},
	correspondence_address = {R. Mühlhoff; Technische Universität Berlin, Cluster Science of Intelligence, Berlin, Marchstraße 23, 10587, Germany; email: muehlhoff@tu-berlin.de},
	publisher = {De Gruyter Open Ltd},
	issn = {00121045},
	language = {English},
	abbrev_source_title = {Dtsch. Z. Philos.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@BOOK{Galliott2021137,
	author = {Galliott, Jai and Baggiarini, Bianca and Rupka, Sean},
	title = {Empirical data on attitudes toward autonomous systems},
	year = {2021},
	journal = {Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare},
	pages = {137 – 148},
	doi = {10.1093/oso/9780197546048.003.0010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112344868&doi=10.1093%2foso%2f9780197546048.003.0010&partnerID=40&md5=5dd093375997fd1f599187ab0d760cd2},
	affiliations = {Defence & Security Technology Group, UNSW, The Australian Defence Force Academy, Australia; Modern War Institute, United States Military Academy, West Point, United States; The Centre for Technology and Global Affairs, University of Oxford, United Kingdom; UNSW, Canberra, Australia},
	abstract = {Combat automation, enabled by rapid technological advancements in artificial intelligence and machine learning, is a guiding principle in the conduct of war today. Yet, empirical data on the impact of algorithmic combat on military personnel remains limited. This chapter draws on data from a historically unprecedented survey of Australian Defence Force Academy cadets. Given that this generation of trainees will be the first to deploy autonomous systems (AS) in a systematic way, their views are especially important. This chapter focuses its analysis on five themes: the dynamics of human-machine teams; the perceived risks, benefits, and capabilities of AS; the changing nature of (and respect for) military labor and incentives; preferences to oversee a robot, versus carrying out a mission themselves; and the changing meaning of soldiering. We utilize the survey data to explore the interconnected consequences of neoliberal governing for cadets’ attitudes toward AS, and citizen-soldiering more broadly. Overall, this chapter argues that Australian cadets are open to working with and alongside AS, but under the right conditions. Armed forces, in an attempt to capitalize on these technologically savvy cadets, have shifted from institutional to occupational employers. However, in our concluding remarks, we caution against unchecked technological fetishism, highlighting the need to critically question the risks of AS on moral deskilling, and the application of market-based notions of freedom to the military domain. © Oxford University Press 2021.},
	author_keywords = {Attitudes toward autonomy; Military ethics; Military labor preferences; Moral deskilling; Perceptions of AWS},
	publisher = {Oxford University Press},
	isbn = {978-019754604-8},
	language = {English},
	abbrev_source_title = {Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kondori2021161,
	author = {Kondori, Esmaeil and Neves-Silva, Rui},
	title = {A New Challenge for Machine Ethics Regarding Decision-Making in Manufacturing Systems},
	year = {2021},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {626},
	pages = {161 – 172},
	doi = {10.1007/978-3-030-78288-7_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112005854&doi=10.1007%2f978-3-030-78288-7_16&partnerID=40&md5=080c9e56727e005f7de6ec95670278b7},
	affiliations = {School of Science and Technology, NOVA University of Lisbon, Caparica, 2829-516, Portugal},
	abstract = {In order to deal with increasingly complex manufacturing systems, we need to make sophisticated decisions. A new challenge emerges when dealing with presenting a new decision – making model merged by an off-line (production data including; staffs, machinery, materials) and on-line (sensors, actuators) data to render a shared responsibility of decision´s consequences between machine and human through giving weight to the taken decisions. Undoubtedly, to make an accurate fair prediction, this presented model should follow the ethical rules. However, the mostly past research works about relationship between machine and ethics mainly have focused on human and his responsibility in applying of technology and only humans have engaged in ethical issues. In light of the digital era especially applying AI and Machine learning, necessarily a new approach should be applied to the interplay between the machine, ethics, and human by adding an ethical dimension to those machines which involve with decision making. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {Artificial intelligence; Machine ethics; Sliding decision - making; Smart manufacturing systems},
	keywords = {Behavioral research; Decision making; Machinery; Manufacture; Complex manufacturing systems; Digital era; Ethical issues; New approaches; Production data; Shared responsibility; Philosophical aspects},
	correspondence_address = {E. Kondori; School of Science and Technology, NOVA University of Lisbon, Caparica, 2829-516, Portugal; email: kondori@campus.fct.unl.pt},
	editor = {Camarinha-Matos L.M. and Ferreira P. and Brito G.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303078287-0},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 12th IFIP WG 5.5/SOCOLNET Advanced Doctoral Conference on Computing, Electrical and Industrial Systems, DoCEIS 2021; Conference date: 7 July 2021 through 9 July 2021; Conference code: 261859}
}

@ARTICLE{Kennedy2021198,
	author = {Kennedy, Rónán},
	title = {The Ethical Implications of Lawtech},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12896 LNCS},
	pages = {198 – 207},
	doi = {10.1007/978-3-030-85447-8_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115130773&doi=10.1007%2f978-3-030-85447-8_18&partnerID=40&md5=863e4829f3314f32a97d23cf40da01a2},
	affiliations = {School of Law, National University of Ireland Galway, Galway, Ireland},
	abstract = {The development of information and communications technology has changed the work of many professionals and may now be radically changing the functioning of the legal system. ‘Lawtech’, or technology which supports, replaces, or improves the provision of legal services and the operation of the justice system, has become more and more important. Lawtech raises significant ethical issues. It often relies on so-called ‘artificial intelligence’ (AI), but this does not ‘think’ as humans do. Software, such as machine learning tools, can help judges to make decisions. Some jurisdictions are replacing judges with AI. Lawyers also use AI to predict the outcomes of litigation. These tools can be more transparent and fairer. However, they may also be more opaque. Also, researchers raise questions about whether the data and processes used in these applications simply reflects and strengthens existing biases and prejudices. Lawtech provides an opportunity to improve the operation of the legal services market and the justice system for the benefit for the citizen and the consumer. However, this is not certain, and it could worsen existing problems or create new ones. This will require careful consideration and more research in the future. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {Artificial intelligence; Bias; Courts; Ethics; Judicial support; Law; Lawtech; Lawyers; Legaltech},
	keywords = {Electronic commerce; Laws and legislation; Philosophical aspects; Ethical implications; Ethical issues; Existing problems; Information and communications technology; Legal services; Legal system; Artificial intelligence},
	correspondence_address = {R. Kennedy; School of Law, National University of Ireland Galway, Galway, Ireland; email: ronan.m.kennedy@nuigalway.ie},
	editor = {Dennehy D. and Griva A. and Pouloudi N. and Dwivedi Y.K. and Dwivedi Y.K. and Pappas I. and Pappas I. and Mantymaki M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303085446-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 264489}
}

@ARTICLE{Božanić2021249,
	author = {Božanić, Mladen and Sinha, Saurabh},
	title = {6G: The Intelligent Network},
	year = {2021},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {751},
	pages = {249 – 279},
	doi = {10.1007/978-3-030-69273-5_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102059136&doi=10.1007%2f978-3-030-69273-5_8&partnerID=40&md5=ba5dd1f7b1fc90949f1f4e463ba5d12f},
	affiliations = {Faculty of Engineering and Built Environment, University of Johannesburg, Johannesburg, South Africa; Office of the Deputy Vice-Chancellor, University of Johannesburg, Johannesburg, South Africa},
	abstract = {Perhaps one of the most disruptive technologies that will be mature by the time 6G is ready for deployment will be AI. Pervasive AI for communications and special cases of machine learning and edge intelligence are the three components that will turn 6G networks into intelligent networks. Each of these concepts will be discussed in this chapter in some detail. This chapter will also reconsider the topic of the ethics of AI. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	keywords = {Intelligent networks; Disruptive technology; Edge intelligence; G-networks; Three component; Artificial intelligence},
	correspondence_address = {M. Božanić; Faculty of Engineering and Built Environment, University of Johannesburg, Johannesburg, South Africa; email: mbozanic@ieee.org},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18761100},
	language = {English},
	abbrev_source_title = {Lect. Notes Electr. Eng.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Williams2021143,
	author = {Williams, Damien Patrick},
	title = {Constructing Situated and Social Knowledge: Ethical, Sociological, and Phenomenological Factors in Technological Design},
	year = {2021},
	journal = {Philosophy of Engineering and Technology},
	volume = {37},
	pages = {143 – 159},
	doi = {10.1007/978-3-030-70099-7_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105995327&doi=10.1007%2f978-3-030-70099-7_7&partnerID=40&md5=4ab48d2afbeded45023797496067eb4c},
	affiliations = {Virginia Polytechnic Institute and State University, Blacksburg, VA, United States},
	abstract = {Designers, programmers, and others in the fields of technology and engineering are—recently, and with increasing speed and urgency—coming to understand that there are many ways that human biases and assumptions can create problems within the fields of engineering, programming, algorithmic systems, machine learning, artificial intelligence, and design. In order to understand these assumptions and how they get instantiated in our technological systems, we have to understand various social, psychological, and philosophical frameworks. We must understand how concepts such as intersectionality, embodiment, the extended mind hypothesis, epistemic valuation, and phenomenological experience come together to form the bases for our moral behavior and social interactions. In this paper, I use tools from intersectional feminist theory, feminist epistemology, disability studies, and phenomenology to highlight several questions which represent otherwise discounted categories of knowledge. The audience will come to recognize that each of these questions represents a set of lived experiences and, in some cases, life or death concerns for people in the world, and must be understood and taken into account when designing and deploying technological systems. As long as humans translate their experience and understanding of the world both into technologies and languages that other technologies can understand, humans need to take pains to privilege the perspectives of those traditionally under-served and marginalized groups who understand not only the existence of these questions and their implications, but also the epistemologies and life strategies that they represent. This increased understanding will broaden and deepen our understanding of what our technological systems are and can do, for all of us. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Algorithmic bias; Artificial intelligencee; Philosophy of technology; Science, technology, and society; Technological ethics},
	correspondence_address = {D.P. Williams; Virginia Polytechnic Institute and State University, Blacksburg, United States; email: damien.williams7@gmail.com},
	publisher = {Springer Nature},
	issn = {18797202},
	language = {English},
	abbrev_source_title = {Philos. Eng. Technol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2021591,
	author = {Zhang, Baobao and Anderljung, Markus and Kahn, Lauren and Dreksler, Noemi and Horowitz, Michael C. and Dafoe, Allan},
	title = {Ethics and governance of artificial intelligence: Evidence from a survey of machine learning researchers},
	year = {2021},
	journal = {Journal of Artificial Intelligence Research},
	volume = {71},
	pages = {591 – 666},
	doi = {10.1613/JAIR.1.12895},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113710203&doi=10.1613%2fJAIR.1.12895&partnerID=40&md5=a5db4fb802d168663fee1e8945d5684b},
	affiliations = {Department of Government, Cornell University, Ithaca, 14853, NY, United States; Centre for the Governance of AI, Oxford, OX2 0DJ, United Kingdom; Perry World House, University of Pennsylvania, Philadelphia, 19104, PA, United States},
	abstract = {Machine learning (ML) and artificial intelligence (AI) researchers play an important role in the ethics and governance of AI, including through their work, advocacy, and choice of employment. Nevertheless, this influential group’s attitudes are not well understood, undermining our ability to discern consensuses or disagreements between AI/ML researchers. To examine these researchers’ views, we conducted a survey of those who published in two top AI/ML conferences (N = 524). We compare these results with those from a 2016 survey of AI/ML researchers (Grace et al., 2018) and a 2018 survey of the US public (Zhang & Dafoe, 2020). We find that AI/ML researchers place high levels of trust in international organizations and scientific organizations to shape the development and use of AI in the public interest; moderate trust in most Western tech companies; and low trust in national militaries, Chinese tech companies, and Facebook. While the respondents were overwhelmingly opposed to AI/ML researchers working on lethal autonomous weapons, they are less opposed to researchers working on other military applications of AI, particularly logistics algorithms. A strong majority of respondents think that AI safety research should be prioritized and that ML institutions should conduct pre-publication review to assess potential harms. Being closer to the technology itself, AI/ML researchers are well placed to highlight new risks and develop technical solutions, so this novel attempt to measure their attitudes has broad relevance. The findings should help to improve how researchers, private sector executives, and policymakers think about regulations, governance frameworks, guiding principles, and national and international governance strategies for AI. ©2021 AI Access Foundation.},
	keywords = {Machine learning; Military applications; Philosophical aspects; Risk assessment; Guiding principles; International organizations; Policy makers; Potential harm; Private sectors; Public interest; Safety research; Technical solutions; Surveys},
	publisher = {AI Access Foundation},
	issn = {10769757},
	coden = {JAIRF},
	language = {English},
	abbrev_source_title = {J Artif Intell Res},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{de Cerqueira20215240,
	author = {de Cerqueira, José Antonio Siqueira and dos Althoff, Lucas S. and de Almeida, Paulo Santos and Canedo, Edna Dias},
	title = {Ethical perspectives in AI: A two-folded exploratory study from literature and active development projects},
	year = {2021},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2020-January},
	pages = {5240 – 5249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108344615&partnerID=40&md5=446a8b9742792e05533a34bf716c589d},
	affiliations = {University of Brasília(UnB), DF, Brasília, Brazil},
	abstract = {Background: Interest in Artificial Intelligence (AI) based systems has been gaining traction at a fast pace, both for software development teams and for society as a whole. This increased interest has lead to the employment of AI techniques such as Machine Learning and Deep Learning for diverse purposes, like medicine and surveillance systems, and such uses have raised the awareness about the ethical implications of the usage of AI systems. Aims: With this work we aim to obtain an overview of the current state of the literature and software projects on tools, methods and techniques used in practical AI ethics. Method: We have conducted an exploratory study in both a scientific database and a software projects repository in order to understand their current state on techniques, methods and tools used for implementing AI ethics. Results: A total of 182 abstracts were retrieved and five classes were devised from the analysis in Scopus, 1) AI in Agile and Business for Requirement Engineering (RE) (22.8%), 2) RE in Theoretical Context (14.8%), 3) Quality Requirements (22.6%), 4) Proceedings and Conferences (22%), 5) AI in Requirements Engineering (17.8%). Furthermore, out of 589 projects from GitHub, we found 21 tools for implementing AI ethics. Highlighted publicly available tools found to assist the implementation of AI ethics are InterpretML, Deon and TransparentAI. Conclusions: The combined energy of both explored sources fosters an enhanced debate and stimulates progress towards AI ethics in practice. © 2021 IEEE Computer Society. All rights reserved.},
	keywords = {Deep learning; Software design; Development project; Ethical implications; Ethical perspectives; Quality requirements; Requirement engineering; Scientific database; Software development teams; Surveillance systems; Philosophical aspects},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813314-0},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 54th Annual Hawaii International Conference on System Sciences, HICSS 2021; Conference date: 4 January 2021 through 8 January 2021; Conference code: 169537}
}

@ARTICLE{Lin2021700,
	author = {Lin, Hongzhen and Liu, Wei},
	title = {Risks and Prevention in the Application of AI},
	year = {2021},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1283},
	pages = {700 – 704},
	doi = {10.1007/978-3-030-62746-1_104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097057057&doi=10.1007%2f978-3-030-62746-1_104&partnerID=40&md5=aecc335d871623db08adf01478527629},
	affiliations = {School of Hengda Management, Wuhan University of Science and Technology, Wuhan, China; Subject Construction Office, Zhongnan University of Economics and Law, Wuhan, China},
	abstract = {Aim of this study is to explore the risks in the design and application of artificial intelligence and put forward corresponding preventive measures. Using the method of literature research deeply, correctly understand and analyze the problem of the risks in the design and application of artificial intelligence. AI business applications bring convenience to human, but also bring a lot of risk problems to social development. There are risks such as security issues, consumer privacy issues, moral hazard and so on. The causes of risks in AI design and application are incomplete laws and regulations and imperfect the ways of supervision and relief and limitations of artificial intelligence technology and lack of new ethics and morality matching artificial intelligence. The conclusion is that effective risk prevention measures must be taken to prevent risks in time. Safety designs should be strengthened to reduce risk from the source. The supervision and management system of artificial intelligence must be improved to curtail moral hazard. © 2021, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Design and application; Risk; Security},
	keywords = {Big data; Internet of things; Laws and legislation; Machine learning; Privacy by design; Risk assessment; Risk management; Artificial intelligence technologies; Business applications; Design and application; Laws and regulations; Literature researches; Management systems; Preventive measures; Social development; Advanced Analytics},
	correspondence_address = {W. Liu; Subject Construction Office, Zhongnan University of Economics and Law, Wuhan, China; email: liuewei@foxmail.com},
	editor = {MacIntyre J. and Zhao J. and Ma X.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21945357},
	isbn = {978-303062745-4},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: International Conference on Machine Learning and Big Data Analytics for IoT Security and Privacy, SPIoT 2020; Conference date: 6 November 2020 through 8 November 2020; Conference code: 251339}
}

@ARTICLE{Kaibel202178,
	author = {Kaibel, Chris and Biemann, Torsten},
	title = {Rethinking the Gold Standard With Multi-armed Bandits: Machine Learning Allocation Algorithms for Experiments},
	year = {2021},
	journal = {Organizational Research Methods},
	volume = {24},
	number = {1},
	pages = {78 – 103},
	doi = {10.1177/1094428119854153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067831854&doi=10.1177%2f1094428119854153&partnerID=40&md5=a5177e7fe0d82dbf4ca2c48e786022cf},
	affiliations = {Department of Management, University of Mannheim, Germany},
	abstract = {In experiments, researchers commonly allocate subjects randomly and equally to the different treatment conditions before the experiment starts. While this approach is intuitive, it means that new information gathered during the experiment is not utilized until after the experiment has ended. Based on methodological approaches from other scientific disciplines such as computer science and medicine, we suggest machine learning algorithms for subject allocation in experiments. Specifically, we discuss a Bayesian multi-armed bandit algorithm for randomized controlled trials and use Monte Carlo simulations to compare its efficiency with randomized controlled trials that have a fixed and balanced subject allocation. Our findings indicate that a randomized allocation based on Bayesian multi-armed bandits is more efficient and ethical in most settings. We develop recommendations for researchers and discuss the limitations of our approach. © The Author(s) 2019.},
	author_keywords = {ethics in research; experiments; exploration versus exploitation; machine learning; multi-armed bandit; randomized controlled trial},
	correspondence_address = {C. Kaibel; Department of Management, University of Mannheim, Germany; email: chris.kaibel@bwl.uni-mannheim.de},
	publisher = {SAGE Publications Inc.},
	issn = {10944281},
	language = {English},
	abbrev_source_title = {Org. Res. Methods},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Denton2021,
	author = {Denton, Emily and Hanna, Alex and Amironesei, Razvan and Smart, Andrew and Nicole, Hilary},
	title = {On the genealogy of machine learning datasets: A critical history of ImageNet},
	year = {2021},
	journal = {Big Data and Society},
	volume = {8},
	number = {2},
	doi = {10.1177/20539517211035955},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115712002&doi=10.1177%2f20539517211035955&partnerID=40&md5=71142b9dd6925f433de51b117192d436},
	affiliations = {Google Research, NY, United States; Center for Applied Data Ethics, University of San Francisco, CA, United States},
	abstract = {In response to growing concerns of bias, discrimination, and unfairness perpetuated by algorithmic systems, the datasets used to train and evaluate machine learning models have come under increased scrutiny. Many of these examinations have focused on the contents of machine learning datasets, finding glaring underrepresentation of minoritized groups. In contrast, relatively little work has been done to examine the norms, values, and assumptions embedded in these datasets. In this work, we conceptualize machine learning datasets as a type of informational infrastructure, and motivate a genealogy as method in examining the histories and modes of constitution at play in their creation. We present a critical history of ImageNet as an exemplar, utilizing critical discourse analysis of major texts around ImageNet’s creation and impact. We find that assumptions around ImageNet and other large computer vision datasets more generally rely on three themes: the aggregation and accumulation of more data, the computational construction of meaning, and making certain types of data labor invisible. By tracing the discourses that surround this influential benchmark, we contribute to the ongoing development of the standards and norms around data development in machine learning and artificial intelligence research. © The Author(s) 2021.},
	author_keywords = {AI ethics; algorithmic fairness; artificial intelligence; big data; genealogy; Machine learning},
	correspondence_address = {E. Denton; Google Research, United States; email: dentone@google.com},
	publisher = {SAGE Publications Ltd},
	issn = {20539517},
	language = {English},
	abbrev_source_title = {Big Data  Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 47; All Open Access, Gold Open Access}
}

@ARTICLE{Zaborovskij2021231,
	author = {Zaborovskij, Vladimir and Polyanskiy, Vladimir},
	title = {Modal logic of digital transformation: Relentless pace to “exo-intellectual” platform},
	year = {2021},
	journal = {Lecture Notes in Networks and Systems},
	volume = {157},
	pages = {231 – 240},
	doi = {10.1007/978-3-030-64430-7_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098276753&doi=10.1007%2f978-3-030-64430-7_20&partnerID=40&md5=9048fdd6d1b1a24c31b1692e84269498},
	affiliations = {Peter the Great St. Petersburg Polytechnic University, Saint-Petersburg, Russian Federation; Institute for Problems in Mechanical Engineering, Russian Academy of Sciences, Saint-Petersburg, Russian Federation},
	abstract = {It is a generally accepted opinion that digital transformation of the economic and production infrastructure of today’s society are natural result of technologies evolution of in which information processing factors start to play the lead role with building “smart” machines capable in autonomic manner performing tasks that typically require human intelligence. Machine mind, consciousness and artificial intelligence (AI) now are priority interdisciplinary branches of natural and computer science with multiple approaches and advancements in virtually every sector of the production and entertainment industry. The popularity of the idea of artificial intelligence is due to some factors: computer technology has become prevalent; digitalization transforming touched of nearly every corner of the humane world, science and technology. But here is a threat that the chaotic relentless pace of human intellectual development may push technological evolution to the unstable attractor known as “flickering mind” [1]. The article is devoted to the analysis of the role that logic and ethics can play in the process of technology development, especially in the aspect of fundamental research and adaptation of the education system to new challenges associated with the symbiosis of human intelligence and computer modeling capabilities to predicts the possible ways of evolution. This symbiosis forms a new technological reality, the essence of which can be expressed by the word exo-intelligence, which means computer technologies that can simulate cognitive functions – new class of mathematical objects which phenomenological features will be discussed below. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021.},
	author_keywords = {Artificial intelligence; Cognitive functions; Exo-intelligence; Machine learning; Technology development},
	correspondence_address = {V. Zaborovskij; Peter the Great St. Petersburg Polytechnic University, Saint-Petersburg, Russian Federation; email: zaborovskij_vs@spbstu.ru},
	editor = {Schaumburg H. and Korablev V. and Laszlo U.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23673370},
	isbn = {978-303064429-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 5th International Conference on Technological Transformation: A New Role for Human, Machines and Management, TT 2020; Conference date: 16 September 2020 through 18 September 2020; Conference code: 253119}
}

@ARTICLE{Lillywhite2021129,
	author = {Lillywhite, Aspen and Wolbring, Gregor},
	title = {Coverage of ethics within the artificial intelligence and machine learning academic literature: The case of disabled people},
	year = {2021},
	journal = {Assistive Technology},
	volume = {33},
	number = {3},
	pages = {129 – 135},
	doi = {10.1080/10400435.2019.1593259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064570984&doi=10.1080%2f10400435.2019.1593259&partnerID=40&md5=4349dd4b82e91458a1ccac547e62d563},
	affiliations = {Community Rehabilitation and Disability Studies, Department of Community Health Sciences, Cumming School of Medicine, University of Calgary, Calgary, AB, Canada},
	abstract = {Disabled people are often the anticipated users of scientific and technological products and processes advanced and enabled by artificial intelligence (AI) and machine learning (ML). Disabled people are also impacted by societal impacts of AI/ML. Many ethical issues are identified within AI/ML as fields and within individual applications of AI/ML. At the same time, problems have been identified in how ethics discourses engage with disabled people. The aim of our scoping review was to better understand to what extent and how the AI/ML focused academic literature engaged with the ethics of AI/ML in relation to disabled people. Of the n = 1659 abstracts engaging with AI/ML and ethics downloaded from Scopus (which includes all Medline articles) and the 70 databases of EBSCO ALL, we found 54 relevant abstracts using the term “patient” and 11 relevant abstracts mentioning terms linked to “impair*”, “disab*” and “deaf”. Our study suggests a gap in the literature that should be filled given the many AI/ML related ethical issues identified in the literature and their impact on disabled people. © 2019 RESNA.},
	author_keywords = {artificial intelligence; disabled people; ethics; machine learning; people with disabilities},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Abstracting; Artificial intelligence; Economic and social effects; Ethical aspects; Learning systems; Machine learning; Academic literature; Applications of AI; Disabled people; Ethical issues; Medline; People with disabilities; Scoping review; Societal impacts; artificial intelligence; human; machine learning; Philosophical aspects},
	correspondence_address = {G. Wolbring; 3330 Hospital Drive NW, T2N 4N1, Canada; email: gwolbrin@ucalgary.ca},
	publisher = {Taylor and Francis Ltd.},
	issn = {10400435},
	coden = {ASTEF},
	pmid = {30995161},
	language = {English},
	abbrev_source_title = {Assistive Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@ARTICLE{Annane2020,
	author = {Annane, Djillali and Pirracchio, Romain and Billot, Laurent and Waschka, Andre and Chevret, Sylvie and Cohen, Jeremy and Finfer, Simon and Gordon, Anthony and Hammond, Naomi and Myburgh, John and Venkatesh, Balasubramanian and Delaney, Anthony},
	title = {Effects of low-dose hydrocortisone and hydrocortisone plus fludrocortisone in adults with septic shock: A protocol for a systematic review and meta-analysis of individual participant data},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {12},
	doi = {10.1136/bmjopen-2020-040931},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097125547&doi=10.1136%2fbmjopen-2020-040931&partnerID=40&md5=8f3a587cb86d6d574c25355d899b3230},
	affiliations = {School of Medicine, Versailles Saint-Quentin-en-Yvelines University, Versailles, île-de-France, France; Universite Paris-Saclay, Saint-Aubin, île-de-France, France; Zuckerberg San Francisco General Hospital and Trauma Center, San Francisco, CA, United States; Statistics Division, George Institute for Global Health, Newtown, NSW, Australia; University of California Berkeley, Berkeley, CA, United States; University of Paris, Paris, île-de-France, France; University of Queensland, Brisbane, QLD, Australia; George Institute for Global Health, Newtown, NSW, Australia; Section of Anaesthetics, Pain Medicine and Intensive Care, Imperial College London, London, United Kingdom; George Institute for Global Health, Camperdown, NSW, Australia; St George Clinical School, University of New South Wales, Sydney, NSW, Australia; Royal Brisbane and Women's Hospital, Herston, QLD, Australia},
	abstract = {Introduction The benefits and risks of low-dose hydrocortisone in patients with septic shock have been investigated in numerous randomised controlled trials and trial-level meta-analyses. Yet, the routine use of this treatment remains controversial. To overcome the limitations of previous meta-analyses inherent to the use of aggregate data, we will perform an individual patient data meta-analysis (IPDMA) on the effect of hydrocortisone with or without fludrocortisone compared with placebo or usual care on 90-day mortality and other outcomes in patients with septic shock. Methods and analysis To assess the benefits and risks of hydrocortisone, with or without fludrocortisone for adults with septic shock, we will search major electronic databases from inception to September 2020 (Cochrane Central Register of Controlled Trials, MEDLINE, EMBASE and Latin American Caribbean Health Sciences Literature), complimented by a search for unpublished trials. The primary analysis will compare hydrocortisone with or without fludrocortisone to placebo or no treatment in adult patients with septic shock. Secondary analyses will compare hydrocortisone to placebo (or usual care), hydrocortisone plus fludrocortisone to placebo (or usual care), and hydrocortisone versus hydrocortisone plus fludrocortisone. The primary outcome will be all cause mortality at 90 days. We will conduct both one-stage IPDMA using mixed-effect models and machine learning with targeted maximum likelihood analyses. We will assess the risk of bias related to unshared data and related to the quality of individual trial. Ethics and dissemination This IPDMA will use existing data from completed randomised clinical trials and will comply with the ethical and regulatory requirements regarding data sharing for each of the component trials. The findings of this study will be submitted for publication in a peer-review journal with straightforward policy for open access.  © Author(s) (or their employer(s)) 2020.},
	keywords = {Adult; Caribbean Region; Fludrocortisone; Humans; Hydrocortisone; Meta-Analysis as Topic; Shock, Septic; fludrocortisone; hydrocortisone; placebo; fludrocortisone; hydrocortisone; adult; all cause mortality; Article; clinical outcome; clinical trial; continuous infusion; controlled study; female; human; length of stay; low drug dose; machine learning; male; maximum likelihood method; meta analysis; peer review; secondary analysis; septic shock; systematic review; treatment duration; Caribbean; meta analysis (topic)},
	correspondence_address = {D. Annane; School of Medicine, Versailles Saint-Quentin-en-Yvelines University, Versailles, île-de-France, France; email: djillali.annane@aphp.fr},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33268422},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Santy20214704,
	author = {Santy, Sebastin and Rani, Anku and Choudhury, Monojit},
	title = {Use of Formal Ethical Reviews in NLP Literature: Historical Trends and Current Practices},
	year = {2021},
	journal = {Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021},
	pages = {4704 – 4710},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115876379&partnerID=40&md5=0afe9bec161e8bc244b12fdadfd8499e},
	affiliations = {Microsoft Research, Bangalore, India; Plaksha University, Mohali, India},
	abstract = {Ethical aspects of research in language technologies have received much attention recently. It is a standard practice to get a study involving human subjects reviewed and approved by a professional ethics committee/board of the institution. How commonly do we see mention of ethical approvals in NLP research? What types of research or aspects of studies are usually subject to such reviews? With the rising concerns and discourse around the ethics of NLP, do we also observe a rise in formal ethical reviews of NLP studies? And, if so, would this imply that there is a heightened awareness of ethical issues that was previously lacking? We aim to address these questions by conducting a detailed quantitative and qualitative analysis of the ACL Anthology, as well as comparing the trends in our field to those of other related disciplines, such as cognitive science, machine learning, data mining, and systems. © 2021 Association for Computational Linguistics},
	keywords = {Cognitive systems; Computational linguistics; Data mining; Ethical technology; Cognitive science; Current practices; Ethical issues; Ethics committee; Historical trends; Human subjects; Language technology; Professional ethics; Quantitative and qualitative analysis; Standard practices; Natural language processing systems},
	editor = {Zong C. and Xia F. and Li W. and Navigli R.},
	publisher = {Association for Computational Linguistics (ACL)},
	isbn = {978-195408554-1},
	language = {English},
	abbrev_source_title = {Find. Assoc. Comput. Linguist.: ACL-IJCNLP},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021; Conference date: 1 August 2021 through 6 August 2021; Conference code: 174271}
}

@ARTICLE{Bay2021358,
	author = {Bay, Morten},
	title = {Four challenges to Confucian virtue ethics in technology},
	year = {2021},
	journal = {Journal of Information, Communication and Ethics in Society},
	volume = {19},
	number = {3},
	pages = {358 – 373},
	doi = {10.1108/JICES-01-2021-0004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111941749&doi=10.1108%2fJICES-01-2021-0004&partnerID=40&md5=28a0896981e1e6ab0592b1581ecf9cc7},
	affiliations = {Annenberg School of Communication, University of Southern California, Los Angeles, CA, United States},
	abstract = {Purpose: As interest in technology ethics is increasing, so is the interest in bringing schools of ethics from non-Western philosophical traditions to the field, particularly when it comes to information and communication technology. In light of this development and recent publications that result from it, this paper aims to present responds critically to recent work on Confucian virtue ethics (CVE) and technology. Design/methodology/approach: Four critiques are presented as theoretical challenges to CVE in technology, claiming that current literature insufficiently addresses: overall applicability, collective ethics issues, epistemic overconfidence within technology corporations and amplification of epistemic overconfidence by the implementation of CVE. These challenges make use of general CVE literature and work on technology critique, political philosophy, epistemology and business ethics. Findings: Implementing CVE in technology may yield some benefits, but these may be outweighed by other outcomes, include strengthening hierarchies, widening inequities, increasing, rather than limiting, predictive activity, personal data collection, misinformation, privacy violations and challenges to the democratic process. Originality/value: Though not directly advocating against CVE, the paper reveals hitherto unidentified and serious issues that should be addressed before CVE are used to inform ethics guidelines or regulatory policies. It also serves as a foundation for further inquiry into how Eastern philosophy more broadly can inform technology ethics in the West. © 2021, Emerald Publishing Limited.},
	author_keywords = {Artificial intelligence; China; Confucius; Ethics; Google; Karl Popper; Machine learning; Misinformation; Prediction; Utilitarianism; Virtue},
	correspondence_address = {M. Bay; Annenberg School of Communication, University of Southern California, Los Angeles, United States; email: mortenbay@live.com},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {1477996X},
	language = {English},
	abbrev_source_title = {J. Inf. Commun. Ethics Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Van Brummelen202115655,
	author = {Van Brummelen, Jessica and Heng, Tommy and Tabunshchyk, Viktoriya},
	title = {Teaching Tech to Talk: K-12 Conversational Artificial Intelligence Literacy Curriculum and Development Tools},
	year = {2021},
	journal = {35th AAAI Conference on Artificial Intelligence, AAAI 2021},
	volume = {17B},
	pages = {15655 – 15663},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118691914&partnerID=40&md5=3c5c312db58e2eb8e826ec1287065dd1},
	affiliations = {Massachusetts Institute of Technology, Cambridge, MA, United States},
	abstract = {With children talking to smart-speakers, smart-phones and even smart-microwaves daily, it is increasingly important to educate students on how these agents work-from underlying mechanisms to societal implications. Researchers are developing tools and curriculum to teach K-12 students broadly about artificial intelligence (AI); however, few studies have evaluated these tools with respect to AI-specific learning outcomes, and even fewer have addressed student learning about AI-based conversational agents. We evaluated our Conversational Agent Interface for MIT App Inventor and workshop curriculum with respect to 8 AI competencies from the literature. Furthermore, we analyze teacher (n=9) and student (n=47) feedback from workshops with the interface and recommend that future work (1) leverages design considerations to optimize engagement, (2) collaborates with teachers, and (3) addresses a range of student abilities through pacing and opportunities for extension. We found evidence for student understanding of all 8 competencies, with the most difficult concepts being AI ethics and machine learning. We recommend emphasizing these topics in future curricula. Copyright © 2021, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved},
	keywords = {Artificial intelligence; Smartphones; Students; Conversational agents; Design considerations; Development tools; Learning outcome; Leverage design; Smart phones; Societal implications; Specific learning; Student learning; Teachers'; Curricula},
	publisher = {Association for the Advancement of Artificial Intelligence},
	isbn = {978-171383597-4},
	language = {English},
	abbrev_source_title = {AAAI Conf. Artif. Intell., AAAI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; Conference name: 35th AAAI Conference on Artificial Intelligence, AAAI 2021; Conference date: 2 February 2021 through 9 February 2021; Conference code: 176953}
}

@ARTICLE{Dang2021403,
	author = {Dang, Quang-Vinh},
	title = {Right to Be Forgotten in the Age of Machine Learning},
	year = {2021},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1352},
	pages = {403 – 411},
	doi = {10.1007/978-3-030-71782-7_35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103518970&doi=10.1007%2f978-3-030-71782-7_35&partnerID=40&md5=7a86a13261aa4c794a0e84feedaee43e},
	affiliations = {Industrial University of Ho Chi Minh City, Ho Chi Minh City, Viet Nam},
	abstract = {The right to be forgotten (RtbF) is considered as one of the fundamental human rights in many legal systems. However, given the popularity of the computer systems in our daily life, and particularly the rapid development of the machine learning techniques, the RtbF need to be considered again. In this study we review the definitions of RtbF in several major legal documents and the application of the right in practice. We then discuss the differential privacy as a framework to support the RtbF. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Ethics of AI; Law of machine learning; Privacy preserving machine learning},
	keywords = {Daily lives; Differential privacies; Human rights; Legal documents; Legal system; Machine learning techniques; Right to be forgotten; Machine learning},
	correspondence_address = {Q.-V. Dang; Industrial University of Ho Chi Minh City, Ho Chi Minh City, Viet Nam; email: dangquangvinh@iuh.edu.vn},
	editor = {Antipova T.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21945357},
	isbn = {978-303071781-0},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: International Conference on Advances in Digital Science, ICADS 2021; Conference date: 19 February 2021 through 21 February 2021; Conference code: 256499}
}

@ARTICLE{Mahmoudian202117,
	author = {Mahmoudian, Haniyeh},
	title = {Ethics and data governance in marketing analytics and artificial intelligence},
	year = {2021},
	journal = {Applied Marketing Analytics},
	volume = {7},
	number = {1},
	pages = {17 – 22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113207928&partnerID=40&md5=a0b0126b2041e4cdcc30c745cc9116a1},
	affiliations = {DataRobot, 225 Franklin Street, 13th Floor, Boston, 02110, MA, United States},
	abstract = {Recently, marketers have seized the opportunity to leverage the power of Big Data analytics, machine learning and artificial intelligence in their work. However, greater use of data is accompanied by increasing concerns and ethical challenges regarding aspects of data collection, data security and privacy. Implementing a data governance framework and standardising the data life cycle can help analytics-based marketing departments work more effectively, and to proactively address the concerns inherent in their operations. This paper discusses some of the current challenges and how data governance provides principles that organisations can use in their quest for a more robust approach to analytics-based marketing. © Henry Stewart Publications 2054-7544 (2021).},
	author_keywords = {Analytics; Artificial intelligence; Big Data; Data ethics; Data governance; Machine learning},
	correspondence_address = {H. Mahmoudian; DataRobot, Boston, 225 Franklin Street, 13th Floor, 02110, United States; email: haniyeh.mahmoudian@datarobot.com},
	publisher = {Henry Stewart Publications},
	issn = {20547544},
	language = {English},
	abbrev_source_title = {Appl. Mark. Anal.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ludermir202185,
	author = {Ludermir, Teresa Bernarda},
	title = {Inteligência Artificial e Aprendizado de Máquina: estado atual e tendências},
	year = {2021},
	journal = {Estudos Avancados},
	volume = {35},
	number = {101},
	pages = {85 – 94},
	doi = {10.1590/s0103-4014.2021.35101.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104763475&doi=10.1590%2fs0103-4014.2021.35101.007&partnerID=40&md5=de31d31f06d74f2a585be575c668632a},
	affiliations = {Universidade Federal de Pernambuco, Centro de Informática, Recife, Pernambuco, Brazil},
	abstract = {The field of Artificial Intelligence has advanced extraordinarily in recent years, and nowadays it is used to solve numerous technological and economic problems. Because much of the current success of Artificial Intelligence derives from Machine Learning techniques, particularly Neural Networks, this article will discuss these areas of research as well as the current state, challenges and research opportunities of AI. We will also mention concerns about social impacts and ethical issues. © 2021. All Rights Reserved.},
	author_keywords = {Artificial Intelligence; Ethics in Artificial Intelligence; Machine Learning},
	correspondence_address = {T.B. Ludermir; Universidade Federal de Pernambuco, Centro de Informática, Recife, Brazil; email: tbl@cin.ufpe.br},
	publisher = {Instituto de Estudos Avancados da Universidade de Sao Paulo},
	issn = {01034014},
	language = {English},
	abbrev_source_title = {Estud. Av.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Sabel2021259,
	author = {Sabel, Clive E. and Amegbor, Prince M. and Zhang, Zhaoxi and Chen, Tzu-Hsin Karen and Poulsen, Maria B. and Hertel, Ole and Sigsgaard, Torben and Horsdal, Henriette T. and Pedersen, Carsten B. and Khan, Jibran},
	title = {Urban Health and Wellbeing},
	year = {2021},
	journal = {Urban Book Series},
	pages = {259 – 280},
	doi = {10.1007/978-981-15-8983-6_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103961391&doi=10.1007%2f978-981-15-8983-6_17&partnerID=40&md5=90a902caea79c1e450b0a7d3679f11e7},
	affiliations = {BERTHA Big Data Centre for Environment and Health, Aarhus University, Roskilde, Denmark; Department of Environmental Science, Aarhus University, Roskilde, Denmark; Department of Public Health - Institute of Environmental and Occupational Medicine, Aarhus University, Roskilde, Denmark; Department of Economics and Business Economics, CIRRAU - Centre for Integrated Register-based Research, Aarhus University, Roskilde, Denmark},
	abstract = {This chapter explores how the Internet of Things and the utilization of cutting-edge information technology are shaping global research and discourse on the health and wellbeing of urban populations. The chapter begins with a review of smart cities and health and then delves into the types of data available to researchers. The chapter then discusses innovative methods and techniques, such as machine learning, personalized sensing, and tracking, that researchers use to examine the health and wellbeing of urban populations. The applications of these data, methods, and techniques are then illustrated taking examples from BERTHA (Big Data Centre for Environment and Health) based at Aarhus University, Denmark. The chapter concludes with a discussion on issues of ethics, privacy, and confidentiality surrounding the use of sensitive and personalized data and tracking or sensing individuals across time and urban space. © 2021, The Author(s).},
	correspondence_address = {C.E. Sabel; BERTHA Big Data Centre for Environment and Health, Aarhus University, Roskilde, Denmark; email: cs@envs.au.dk},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {2365757X},
	language = {English},
	abbrev_source_title = {Urban Book Ser.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Sit20202635,
	author = {Sit, Muhammed and Demiray, Bekir Z. and Xiang, Zhongrun and Ewing, Gregory J. and Sermet, Yusuf and Demir, Ibrahim},
	title = {A comprehensive review of deep learning applications in hydrology and water resources},
	year = {2020},
	journal = {Water Science and Technology},
	volume = {82},
	number = {12},
	pages = {2635 – 2670},
	doi = {10.2166/wst.2020.369},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093922286&doi=10.2166%2fwst.2020.369&partnerID=40&md5=adfb90d03dab73cd722c77c96f00743f},
	affiliations = {Interdisciplinary Graduate Program in Informatics, University of Iowa, Iowa City, United States; IIHR - Hydroscience and Engineering, University of Iowa, 100 C. Maxwell Stanley Hydraulics Laboratory, Iowa City, 52242-1585, IA, United States; Department of Computer Science, University of Iowa, Iowa City, United States; Department of Civil and Environmental Engineering, University of Iowa, Iowa City, United States; Department of Electrical and Computer Engineering, University of Iowa, Iowa City, United States},
	abstract = {The global volume of digital data is expected to reach 175 zettabytes by 2025. The volume, variety and velocity of water-related data are increasing due to large-scale sensor networks and increased attention to topics such as disaster response, water resources management, and climate change. Combined with the growing availability of computational resources and popularity of deep learning, these data are transformed into actionable and practical knowledge, revolutionizing the water industry. In this article, a systematic review of literature is conducted to identify existing research that incorporates deep learning methods in the water sector, with regard to monitoring, management, governance and communication of water resources. The study provides a comprehensive review of state-of-the-art deep learning approaches used in the water industry for generation, prediction, enhancement, and classification tasks, and serves as a guide for how to utilize available deep learning methods for future water resources challenges. Key issues and challenges in the application of these techniques in the water domain are discussed, including the ethics of these technologies for decision-making in water resources management and governance. Finally, we provide recommendations and future directions for the application of deep learning models in hydrology and water resources. © IWA Publishing 2020},
	author_keywords = {Artificial intelligence; Deep learning; Hydroscience; Machine learning; Review; Water},
	keywords = {Climate Change; Deep Learning; Hydrology; Water Resources; Climate change; Decision making; Deep learning; Hydrology; Information management; Learning systems; Sensor networks; Water supply; water; Classification tasks; Computational resources; Disaster response; Hydrology and water resource; Large scale sensor network; Learning approach; Systematic Review; Water resources management; algorithm; communication; decision making; governance approach; hydrology; literature review; water management; water resource; aquatic environment; architecture; Article; artificial intelligence; artificial neural network; autoencoder; biotechnology; classification algorithm; convolution algorithm; convolutional neural network; decision making; deep belief network; deep learning; deep neural network; deep q network; Elman network; extreme learning machine; feed forward neural network; gated recurrent unit network; generative adversarial network; hydrology; long short term memory network; machine learning; nonlinear autoregressive model; nonlinear regression analysis; prediction; Q learning; recurrent neural network; regression analysis; reinforcement learning (machine learning); reproducibility; restricted Boltzmann machine; systematic review (topic); unsupervised machine learning; water availability; water management; water monitoring; water quality; water supply; climate change; hydrology; Water resources},
	correspondence_address = {M. Sit; Interdisciplinary Graduate Program in Informatics, University of Iowa, Iowa City, United States; email: muhammed-sit@uiowa.edu},
	publisher = {IWA Publishing},
	issn = {02731223},
	coden = {WSTED},
	pmid = {33341760},
	language = {English},
	abbrev_source_title = {Water Sci. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 135; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Ashofteh2021771,
	author = {Ashofteh, Afshin and Bravo, Jorge M.},
	title = {Data science training for official statistics: A new scientific paradigm of information and knowledge development in national statistical systems},
	year = {2021},
	journal = {Statistical Journal of the IAOS},
	volume = {37},
	number = {3},
	pages = {771 – 789},
	doi = {10.3233/SJI-210841},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115003191&doi=10.3233%2fSJI-210841&partnerID=40&md5=5a3e7fc587c22a98562d4698231dc8ea},
	affiliations = {NOVA Information Management School (NOVA IMS), NOVA University Lisbon, Lisbon, Portugal; Statistics Portugal (Instituto Nacional de Estatística (INE)), Portugal; Paris, France; MagIC (Information Management Research Center), NOVA Information Management School (NOVA IMS), NOVA University Lisbon, Lisbon, Portugal; CEFAGE - Center for Advanced Studies in Management and Economics, University of Èvora, Èvora, Portugal},
	abstract = {The ability to incorporate new and Big Data sources and to benefit from emerging technologies such as Web Technologies, Remote Data Collection methods, User Experience Platforms, and Trusted Smart Statistics will become increasingly important in producing and disseminating official statistics. The skills and competencies required to automate, analyse, and optimize such complex systems are often not part of the traditional skill set of most National Statistical Offices. The adoption of these technologies requires new knowledge, methodologies and the upgrading of the quality assurance framework, technology, security, privacy, and legal matters. However, there are methodological challenges and discussions among scholars about the diverse methodical confinement and the wide array of skills and competencies considered relevant for those working with big data at NSOs. This paper develops a Data Science Model for Official Statistics (DSMOS), graphically summarizing the role of data science in statistical business processes. The model combines data science, existing scientific paradigms, and trusted smart statistics, and develops around a restricted number of constructs. We considered a combination of statistical engineering, data engineering, data analysis, software engineering and soft skills such as statistical thinking, statistical literacy and specific knowledge of official statistics and dissemination of official statistics products as key requirements of data science in official statistics. We then analyse and discuss the educational requirements of the proposed model, clarifying their contribution, interactions, and current and future importance in official statistics. The DSMOS was validated through a quantitative method, using a survey addressed to experts working at the European statistical systems. The empirical results show that the core competencies considered relevant for the DSMOS include acquisition and processing capabilities related to Statistics, high-frequency data, spatial data, Big Data, and microdata/nano-data, in addition to problem-solving skills, Spatio-temporal modelling, machine learning, programming with R and SAS software, Data visualisation using novel technologies, Data and statistical literacy, Ethics in Official Statistics, New data methodologies, New data quality tools, standards and frameworks for official statistics. Some disadvantages and vulnerabilities are also addressed in the paper. © 2021 - The authors. Published by IOS Press.},
	author_keywords = {Big Data; Data science; information management; machine learning; official statistics; statistical engineering; statistical literacy},
	correspondence_address = {A. Ashofteh; NOVA Information Management School (NOVA IMS), Nova University Lisbon, Lisbon, Portugal; email: aashofteh@novaims.unl.pt; A. Ashofteh; Statistics Portugal (Instituto Nacional de Estatística (INE)), Portugal; email: aashofteh@novaims.unl.pt},
	publisher = {IOS Press BV},
	issn = {18747655},
	language = {English},
	abbrev_source_title = {Stat. J. IAOS},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Bronze Open Access, Green Open Access}
}

@BOOK{Taulli20201,
	author = {Taulli, Tom},
	title = {Implementing AI Systems: Transform Your Business in 6 Steps},
	year = {2020},
	journal = {Implementing AI Systems: Transform Your Business in 6 Steps},
	pages = {1 – 196},
	doi = {10.1007/978-1-4842-6385-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85151489791&doi=10.1007%2f978-1-4842-6385-3&partnerID=40&md5=243b90515a88dc2c8cb6d7126dfb34c3},
	affiliations = {Monrovia, CA, United States},
	abstract = {AI is one of the fastest growing corners of the tech world. But there remains one big problem: many AI projects fail. The fact is that AI is unique among IT projects. The technology requires a different mindset, in terms of understanding probabilities, data structures and complex algorithms. There is also a need to deal with complex issues like ethics and privacy. This is where Implementing AI Systems comes in. You'll learn the step-by-step process for successful implementations of AI, backed up with numerous case studies from top companies. This book puts everything you need to know into one place - that is, it's the handbook you need for AI. You'll focus primarily on understanding the core concepts for AI like NLP, Machine Learning, Deep Learning and so on. This book will help you find the right areas to apply AI. What You'll Learn • Put together an effective data strategy • Create models and how to successfully test them • Evaluate AI tools • Assemble the right team • Scale AI across an organization Who This Book Is For Primarily for managers, IT professionals and executives of mid-size and large companies wanting to implement AI in their organization. © 2021 by Tom Taulli. All rights reserved.},
	author_keywords = {AI implementation; Analytics; Artificial Intelligence; Data Modelling; Digital transformation; Scaling AI; Training AI models},
	publisher = {Apress Media LLC},
	isbn = {978-148426385-3; 978-148426384-6},
	language = {English},
	abbrev_source_title = {Implement. AI Syst.: Transform. Your Bus. in 6 Steps},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{King2021251,
	author = {King, Thomas C. and Aggarwal, Nikita and Taddeo, Mariarosaria and Floridi, Luciano},
	title = {Artificial Intelligence Crime: An Interdisciplinary Analysis of Foreseeable Threats and Solutions},
	year = {2021},
	journal = {Philosophical Studies Series},
	volume = {144},
	pages = {251 – 282},
	doi = {10.1007/978-3-030-81907-1_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118771742&doi=10.1007%2f978-3-030-81907-1_13&partnerID=40&md5=972e87dc6a2d0de9ac9660d70c3475cd},
	affiliations = {Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; Amherst, Cheltenham, United Kingdom; Faculty of Law, Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; Alan Turing Institute, London, United Kingdom},
	abstract = {Artificial Intelligence (AI) research and regulation seek to balance the benefits of innovation against any potential harms and disruption. However, one unintended consequence of the recent surge in AI research is the potential re-orientation of AI technologies to facilitate criminal acts, term in this article AI-Crime (AIC). AIC is theoretically feasible thanks to published experiments in automating fraud targeted at social media users, as well as demonstrations of AI-driven manipulation of simulated markets. However, because AIC is still a relatively young and inherently interdisciplinary area—spanning socio-legal studies to formal science—there is little certainty of what an AIC future might look like. This article offers the first systematic, interdisciplinary literature analysis of the foreseeable threats of AIC, providing ethicists, policy-makers, and law enforcement organisations with a synthesis of the current problems, and a possible solution space. © 2021, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {AI and law; AI-crime; Artificial intelligence; Dual-use; Ethics; Machine learning},
	correspondence_address = {L. Floridi; Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; email: luciano.floridi@oii.ox.ac.uk},
	publisher = {Springer Nature},
	issn = {09218599},
	language = {English},
	abbrev_source_title = {Philos. Stud. Ser.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Ahmed2020953,
	author = {Ahmed, S. and Shipman, A. and Millington, G. and A. Langan, E. and R. Ingram, J.},
	title = {Consent for publication: why it matters now more than ever},
	year = {2020},
	journal = {Clinical and Experimental Dermatology},
	volume = {45},
	number = {8},
	pages = {953 – 954},
	doi = {10.1111/ced.14341},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090067482&doi=10.1111%2fced.14341&partnerID=40&md5=db8f388c0a3db6ec7a92f73ead89b811},
	affiliations = {British Association of Dermatologists, London, United Kingdom; Dermatology, Portsmouth Hospitals NHS Trust, Portsmouth, United Kingdom; Dermatology, Norfolk and Norwich University Hospital, Norwich, United Kingdom; Department of Dermatology and Venerology, University Hospital of Schleswig Holstein, Lübeck, Germany; Dermatological Sciences, University of Manchester, Manchester, United Kingdom; Department of Dermatology & Wound Healing, Division of Infection and Immunity, Cardiff University, Cardiff, United Kingdom},
	keywords = {Data Collection; Dermatology; Ethics, Research; Humans; Informed Consent; Journalism, Medical; Machine Learning; Practice Patterns, Physicians'; Publications; confidentiality; Editorial; human; informed consent; medical literature; medical research; open access publishing; priority journal; privacy; publication; social media; clinical practice; dermatology; information processing; informed consent; legislation and jurisprudence; machine learning; procedures; publication; publishing; research ethics},
	correspondence_address = {S. Ahmed; British Association of Dermatologists, London, United Kingdom; email: shehnaz@bad.org.uk},
	publisher = {Blackwell Publishing Ltd},
	issn = {03076938},
	coden = {CEDED},
	pmid = {32875603},
	language = {English},
	abbrev_source_title = {Clin. Exp. Dermatol.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Champagnie202194,
	author = {Champagnie, Samantha and Gogan, Janis L.},
	title = {Responsible Machine Learning Pilot Test Projects: A Medical Coding Case Study},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12896 LNCS},
	pages = {94 – 106},
	doi = {10.1007/978-3-030-85447-8_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115141193&doi=10.1007%2f978-3-030-85447-8_9&partnerID=40&md5=9d362baa90e8d00aae9705f177389d84},
	affiliations = {Muma College of Business, University of South Florida, Tampa, FL, United States; Bentley University, Waltham, MA, United States},
	abstract = {Prior studies reported on many machine learning (ML) projects that under-performed. What steps can leaders take during ML pilot projects to identify and mitigate project risks and systems risks, before implementing new ML systems at scale? We report on an exploratory case study of a U.S.-based healthcare provider organization’s ML pilot project, undertaken when a software vendor proposed an automated solution that would combine natural language processing (NLP) and ML, to improve medical claims coding quality. We reveal tactics the client took during the pilot project, to spot and limit risks that could ultimately harm the firm, its healthcare providers, and its patients. We conclude with suggestions for further research on responsible ML. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {AI; Ethics; Governance; Machine learning; NLP},
	keywords = {Electronic commerce; Health care; Natural language processing systems; Automated solutions; Coding quality; Exploratory case studies; Health care providers; Medical claims; NAtural language processing; Pilot projects; Software vendors; Machine learning},
	correspondence_address = {J.L. Gogan; Bentley University, Waltham, United States; email: jgogan@bentley.edu},
	editor = {Dennehy D. and Griva A. and Pouloudi N. and Dwivedi Y.K. and Dwivedi Y.K. and Pappas I. and Pappas I. and Mantymaki M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303085446-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 264489}
}

@ARTICLE{Spiegel2021,
	author = {Spiegel, Jerry M. and Wilkinson, James and Ehrlich, Rodney and Lockhart, Karen and Yassi, Annalee and Barker, Stephen and Riera, Francisco and Kistnasamy, Barry},
	title = {Using artificial intelligence for high-volume identification of silicosis and tuberculosis a bio-ethics approach},
	year = {2021},
	journal = {Annals of Global Health},
	volume = {87},
	number = {1},
	doi = {10.5334/aogh.3206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109800678&doi=10.5334%2faogh.3206&partnerID=40&md5=bd7379a4977249af54e353f26f9ea796},
	affiliations = {School of Population and Public Health, The University of British Columbia, Vancouver, BC, Canada; School of Public Health and Family Medicine, University of Cape Town, Cape Town, South Africa; IMC Worldwide Inc, London, United Kingdom; Brink, London, United Kingdom; National Department of Health, Johannesburg, South Africa},
	abstract = {Although Artificial Intelligence (AI) is being increasingly applied, considerable distrust about introducing “disruptive” technologies persists. Intrinsic and contextual factors influencing where and how such innovations are introduced therefore require careful scrutiny to ensure that health equity is promoted. To illustrate one such critical approach, we describe and appraise an AI application - the development of computer assisted diagnosis (CAD) to support more efficient adjudication of compensation claims from former gold miners with occupational lung disease in Southern Africa. In doing so, we apply a bio-ethical lens that considers the principles of beneficence, non-maleficence, autonomy and justice and add explicability as a core principle. We draw on the AI literature, our research on CAD validation and process efficiency, as well as apprehensions of users and stakeholders. Issues of concern included AI accuracy, biased training of AI systems, data privacy, impact on human skill development, transparency and accountability in AI use, as well as intellectual property ownership. We discuss ways in which each of these potential obstacles to successful use of CAD could be mitigated. We conclude that efforts to overcoming technical challenges in applying AI must be accompanied from the onset by attention to ensuring its ethical use. © 2021 The Author(s).},
	keywords = {Artificial Intelligence; Bioethical Issues; Delivery of Health Care; Humans; Silicosis; Social Justice; Tuberculosis; gold; Africa; Article; artificial intelligence; avoidance behavior; beneficence; benefit-finding; bioethics; clinical effectiveness; clinical outcome; clinical research; compensation; computer assisted diagnosis; data privacy; diagnostic accuracy; disease classification; false negative result; false positive result; health equity; human; justice; machine learning; medical education; miner; nonmaleficence; occupational lung disease; patent; patient autonomy; patient harm; public sector; sensitivity and specificity; silicosis; skill; social responsibility; solidarity; stakeholder engagement; systematic review (topic); tuberculosis; validation process; ethics; health care delivery; silicosis; social justice; tuberculosis},
	correspondence_address = {J.M. Spiegel; School of Population and Public Health, The University of British Columbia, Vancouver, Canada; email: jerry.spiegel@ubc.ca},
	publisher = {Ubiquity Press},
	issn = {22149996},
	pmid = {34249620},
	language = {English},
	abbrev_source_title = {Ann. of Global Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sumiyama2021218,
	author = {Sumiyama, Kazuki and Futakuchi, Toshiki and Kamba, Shunsuke and Matsui, Hiroaki and Tamai, Naoto},
	title = {Artificial intelligence in endoscopy: Present and future perspectives},
	year = {2021},
	journal = {Digestive Endoscopy},
	volume = {33},
	number = {2},
	pages = {218 – 230},
	doi = {10.1111/den.13837},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096712794&doi=10.1111%2fden.13837&partnerID=40&md5=22c52df974c2b2aaf1cf07e9440d128d},
	affiliations = {Department of Endoscopy, The Jikei University School of Medicine, Tokyo, Japan},
	abstract = {Artificial intelligence (AI) has been attracting considerable attention as an important scientific topic in the field of medicine. Deep-leaning (DL) technologies have been applied more dominantly than other traditional machine-learning methods. They have demonstrated excellent capability to retract visual features of objectives, even unnoticeable ones for humans, and analyze huge amounts of information within short periods. The amount of research applying DL-based models to real-time computer-aided diagnosis (CAD) systems has been increasing steadily in the GI endoscopy field. An array of published data has already demonstrated the advantages of DL-based CAD models in the detection and characterization of various neoplastic lesions, regardless of the level of the GI tract. Although the diagnostic performances and study designs vary widely, owing to a lack of academic standards to assess the capability of AI for GI endoscopic diagnosis fairly, the superiority of CAD models has been demonstrated for almost all applications studied so far. Most of the challenges associated with AI in the endoscopy field are general problems for AI models used in the real world outside of medical fields. Solutions have been explored seriously and some solutions have been tested in the endoscopy field. Given that AI has become the basic technology to make machines react to the environment, AI would be a major technological paradigm shift, for not only diagnosis but also treatment. In the near future, autonomous endoscopic diagnosis might no longer be just a dream, as we are witnessing with the advent of autonomously driven electric vehicles. © 2020 Japan Gastroenterological Endoscopy Society},
	author_keywords = {artificial intelligence; CADe; CADx; convolutional neural network; deep learning},
	keywords = {Artificial Intelligence; Diagnosis, Computer-Assisted; Endoscopy; Humans; Machine Learning; artificial intelligence; colorectal disease; colorectal polyp; computer assisted diagnosis; convolutional neural network; deep learning; digestive system injury; esophageal squamous cell carcinoma; gastrointestinal endoscopy; gastrointestinal tumor; human; information processing; medical ethics; Review; upper gastrointestinal tract; computer assisted diagnosis; endoscopy; machine learning},
	correspondence_address = {K. Sumiyama; Department of Endoscopy, The Jikei University School of Medicine, Tokyo, Japan; email: kaz_sum@jikei.ac.jp},
	publisher = {Blackwell Publishing},
	issn = {09155635},
	coden = {DIENE},
	pmid = {32935376},
	language = {English},
	abbrev_source_title = {Dig. Endosc.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Bronze Open Access}
}

@ARTICLE{Park2021259,
	author = {Park, Baekkwan and Rao, Dhana L. and Gudivada, Venkat N.},
	title = {Dangers of bias in data-intensive information systems},
	year = {2021},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1162},
	pages = {259 – 271},
	doi = {10.1007/978-981-15-4851-2_28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087004771&doi=10.1007%2f978-981-15-4851-2_28&partnerID=40&md5=317c63e9f9eff7068a3a87ca51b7c48c},
	affiliations = {Center for Survey Research, East Carolina University, Greenville, 27855, NC, United States; Department of Biology, East Carolina University, Greenville, 27855, NC, United States; Department of Computer Science, East Carolina University, Greenville, 27855, NC, United States},
	abstract = {Data-intensive information systems (DIS) are pervasive and virtually affect people in all walks of life. Artificial intelligence and machine learning technologies are the backbone of DIS systems. Various types of biases embedded into DIS systems have serious significance and implications for individuals as well as the society at large. In this paper, we discuss various types of bias—both human and machine—and suggest ways to eliminate or minimize it. We also make a case for digital ethics education and outline ways to incorporate such education into computing curricula. © Springer Nature Singapore Pte Ltd 2021.},
	author_keywords = {Algorithmic bias; Digital ethics; Human bias; Information systems},
	keywords = {Artificial intelligence; Embedded systems; Information systems; Information use; Computing curricula; Data intensive; Digital ethics; Machine learning technology; Engineering education},
	correspondence_address = {V.N. Gudivada; Department of Computer Science, East Carolina University, Greenville, 27855, United States; email: gudivadav15@ecu.edu},
	editor = {Deshpande P. and Abraham A. and Iyer B. and Ma K.},
	publisher = {Springer},
	issn = {21945357},
	isbn = {978-981154850-5},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 5th International Conference on Computing in Engineering and Technology, ICCET 2020; Conference date: 9 January 2020 through 11 January 2020; Conference code: 241049}
}

@ARTICLE{Ferrell2021178,
	author = {Ferrell, O.C. and Ferrell, Linda},
	title = {Applying the Hunt Vitell ethics model to artificial intelligence ethics},
	year = {2021},
	journal = {Journal of Global Scholars of Marketing Science: Bridging Asia and the World},
	volume = {31},
	number = {2},
	pages = {178 – 188},
	doi = {10.1080/21639159.2020.1785918},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111572098&doi=10.1080%2f21639159.2020.1785918&partnerID=40&md5=6c4669a0c6da024414e965357990754e},
	affiliations = {Department of Marketing, Auburn University, Auburn, AL, United States},
	abstract = {The Hunt-Vitell (H-V) model of marketing ethics has been validated over the last 30 years. The model explains how people make ethical decisions. Artificial intelligence (AI), involving machine learning, is replacing humans and making decisions based on algorithms or rules developed by programmers. The challenge is how to program the ethical component of AI decisions normally provided by humans. H-V is a descriptive model that can be applied to making AI ethical decisions. A blueprint and revised H-V model is developed as a guide to implementing AI ethics. © 2021 Korean Scholars of Marketing Science.},
	author_keywords = {Artificial intelligence ethics; business ethics; ethical evaluations; Hunt Vitell ethics model; machine learning},
	correspondence_address = {L. Ferrell; Department of Marketing, Auburn University, Auburn, 36830, United States; email: LKF0009@auburn.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {21639159},
	language = {English},
	abbrev_source_title = {J. Glob. Scholar Mark. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Bonnefon20201019,
	author = {Bonnefon, Jean-François and Rahwan, Iyad},
	title = {Machine Thinking, Fast and Slow},
	year = {2020},
	journal = {Trends in Cognitive Sciences},
	volume = {24},
	number = {12},
	pages = {1019 – 1027},
	doi = {10.1016/j.tics.2020.09.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096168942&doi=10.1016%2fj.tics.2020.09.007&partnerID=40&md5=c83c0f908e652ce58f450d73009e97b8},
	affiliations = {Toulouse School of Economics (TSM-R), CNRS, Université Toulouse Capitole, Toulouse, France; Center for Humans and Machines, Max-Planck Institute for Human Development, Berlin, Germany},
	abstract = {Machines do not ‘think fast and slow’ in the sense that humans do in dual-process models of cognition. However, the people who create the machines may attempt to emulate or simulate these fast and slow modes of thinking, which will in turn affect the way end users relate to these machines. In this opinion article we consider the complex interplay in the way various stakeholders (engineers, user experience designers, regulators, ethicists, and end users) can be inspired, challenged, or misled by the analogy between the fast and slow thinking of humans and the Fast and Slow Thinking of machines. © 2020 Elsevier Ltd},
	author_keywords = {algorithm aversion; artificial intelligence; dual-process; machine behavior; machine ethics; trust},
	keywords = {Humans; Machine Learning; Technology; Thinking; Biology; Cognitive systems; Dual process; End users; Slow mode; algorithm; artificial intelligence; aversion; cognition; ethicist; ethics; human; human experiment; process model; review; trust; machine learning; technology; thinking; User experience},
	correspondence_address = {J.-F. Bonnefon; Toulouse School of Economics (TSM-R), CNRS, Université Toulouse Capitole, Toulouse, France; email: jean-francois.bonnefon@tse-fr.eu},
	publisher = {Elsevier Ltd},
	issn = {13646613},
	coden = {TCSCF},
	pmid = {33129719},
	language = {English},
	abbrev_source_title = {Trends Cogn. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Arora2020,
	author = {Arora, Tanima and Martin, Melissa and Grimshaw, Alyssa and Mansour, Sherry and Wilson, Francis P},
	title = {Prediction of outcomes after acute kidney injury in hospitalised patients: Protocol for a systematic review},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {12},
	doi = {10.1136/bmjopen-2020-042035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098221683&doi=10.1136%2fbmjopen-2020-042035&partnerID=40&md5=f420fa58341944baf0baa2098a25b503},
	affiliations = {Clinical and Translational Research Accelerator, Yale School of Medicine, New Haven, CO, United States; Harvey Cushing Library, Yale University School of Medicine, New Haven, CO, United States; Yale University},
	abstract = {Introduction Acute kidney injury (AKI) is common and is associated with negative long-term outcomes. Given the heterogeneity of the syndrome, the ability to predict outcomes of AKI may be beneficial towards effectively using resources and personalising AKI care. This systematic review will identify, describe and assess current models in the literature for the prediction of outcomes in hospitalised patients with AKI. Methods and analysis Relevant literature from a comprehensive search across six databases will be imported into Covidence. Abstract screening and full-text review will be conducted independently by two team members, and any conflicts will be resolved by a third member. Studies to be included are cohort studies and randomised controlled trials with at least 100 subjects, adult hospitalised patients, with AKI. Only those studies evaluating multivariable predictive models reporting a statistical measure of accuracy (area under the receiver operating curve or C-statistic) and predicting resolution of AKI, progression of AKI, subsequent dialysis and mortality will be included. Data extraction will be performed independently by two team members, with a third reviewer available to resolve conflicts. Results will be reported using Preferred Reporting Items for Systematic Reviews and Meta-Analysis guidelines. Risk of bias will be assessed using Prediction model Risk Of Bias ASsessment Tool. Ethics and dissemination We are committed to open dissemination of our results through the registration of our systematic review on PROSPERO and future publication. We hope that our review provides a platform for future work in realm of using artificial intelligence to predict outcomes of common diseases. PROSPERO registration number CRD42019137274.  © },
	author_keywords = {acute renal failure; adult nephrology; dialysis},
	keywords = {Acute Kidney Injury; Adult; Artificial Intelligence; Humans; Meta-Analysis as Topic; Renal Dialysis; Systematic Reviews as Topic; creatinine; acute kidney failure; adult; cohort analysis; creatinine blood level; hospital patient; human; machine learning; mortality; observational study; outcome assessment; prediction; randomized controlled trial (topic); renal replacement therapy; retrospective study; Review; systematic review; urine volume; acute kidney failure; artificial intelligence; hemodialysis; meta analysis (topic)},
	correspondence_address = {T. Arora; Clinical and Translational Research Accelerator, Yale School of Medicine, New Haven, United States; email: tanima.arora@yale.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33371041},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Brenna2021107,
	author = {Brenna, Connor T.A.},
	title = {Medical machines: The expanding role of ethics in technology-driven healthcare},
	year = {2021},
	journal = {Canadian Journal of Bioethics},
	volume = {4},
	number = {1},
	pages = {107 – 111},
	doi = {10.7202/1077638AR},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108358953&doi=10.7202%2f1077638AR&partnerID=40&md5=4a754146f73d23714b9ee5d403f9d9de},
	affiliations = {Department of Medicine, University of Toronto, Toronto, Canada},
	abstract = {Emerging technologies such as artificial intelligence are actively revolutionizing the healthcare industry. While there is widespread concern that these advances will displace human practitioners within the healthcare sector, there are several tasks - including original and nuanced ethical decision making - that they cannot replace. Further, the implementation of artificial intelligence in clinical practice can be anticipated to drive the production of novel ethical tensions surrounding its use, even while eliminating some of the technical tasks which currently compete with ethical deliberation for clinicians' limited time. A new argument therefore arises to suggest that although these disruptive technologies will change the face of medicine, they may also foster a revival of several fundamental components inherent to the role of healthcare professionals, chiefly, the principal activities of moral philosophy. Accordingly, "machine medicine" presents a vital opportunity to reinvigorate the field of bioethics, rather than withdraw from it. © 2021 University of Montreal. All rights reserved.},
	author_keywords = {Artificial intelligence; Bioethics; Emerging technologies; Ethical principles; Healthcare; Machine learning; Traditional roles},
	correspondence_address = {C.T.A. Brenna; Department of Medicine, University of Toronto, Toronto, Canada; email: connor.brenna@mail.utoronto.ca},
	publisher = {University of Montreal},
	issn = {25614665},
	language = {English},
	abbrev_source_title = {Can. J. Bioethics},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2021,
	title = {Expression of concern: A new machine learning model based on induction of rules for autism detection (Health Informatics Journal, (2019), 26, 1, (264–286), 10.1177/1460458218824711)},
	year = {2021},
	journal = {Health Informatics Journal},
	volume = {27},
	number = {1},
	doi = {10.1177/1460458220948624},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115060320&doi=10.1177%2f1460458220948624&partnerID=40&md5=e53d65a58d703da088d472cd62fa821f},
	abstract = {The Health Informatics Journal Editorial Office became aware that the peer review process for these articles did not meet the journal’s usual rigorous peer review standards. Following guidance from the Committee on Publication Ethics (COPE), the irregularities were investigated but it was determined that the research in these articles has moved on too far to be re-reviewed fairly. The institution of the corresponding author of this article has been informed of the irregularities and the editorial decision to publish an expression of concern for these articles. The Editor and SAGE strive to uphold the very highest standards of publication ethics and are committed to supporting the high standards of integrity of Health Informatics Journal. Authors, reviewers, editors and interested readers should consult the ethics section of the SAGE website and the Committee on Publication Ethics (COPE) website for guidelines on publication ethics. © The Author(s) 2020.},
	keywords = {expression of concern},
	publisher = {SAGE Publications Ltd},
	issn = {14604582},
	coden = {HIJEA},
	language = {English},
	abbrev_source_title = {Health Informatics J.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Kothawade2021,
	author = {Kothawade, Suraj and Khandelwal, Vinaya and Basu, Kinjal and Wang, Huaduo and Gupta, Gopal},
	title = {AUTO-DISCERN: Autonomous driving using common sense reasoning},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2970},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117013747&partnerID=40&md5=14743430f2bad9d1c51e9407a79256e8},
	affiliations = {Computer Science Department, University of Texas at Dallas, Richardson, United States},
	abstract = {Driving an automobile involves the tasks of observing surroundings, then making a driving decision based on these observations (steer, brake, coast, etc.). In autonomous driving, all these tasks have to be automated. Autonomous driving technology thus far has relied primarily on machine learning techniques. We argue that appropriate technology should be used for the appropriate task. That is, while machine learning technology is good for observing and automatically understanding the surroundings of an automobile, driving decisions are better automated via commonsense reasoning rather than machine learning. In this paper, we discuss (i) how commonsense reasoning can be automated using answer set programming (ASP) and the goal-directed s(CASP) ASP system, and (ii) develop the AUTO-DISCERN 1 system using this technology for automating decision-making in driving. The goal of our research, described in this paper, is to develop an autonomous driving system that works by simulating the mind of a human driver. Since driving decisions are based on human-style reasoning, they are explainable, their ethics can be ensured, and they will always be correct, provided the system modeling and system inputs are correct. © 2021 CEUR-WS. All rights reserved.},
	keywords = {Automation; Computer circuits; Decision making; Engineering education; Knowledge representation; Logic programming; Machine learning; Answer set programming; Appropriate technologies; Automobile driving; Autonomous driving; Commonsense reasoning; Decision-based; Goal-directed; Machine learning techniques; Machine learning technology; Programming system; Autonomous vehicles},
	editor = {Arias J. and D�Asaro F.A. and Dyoub A. and Gupta G. and Hecher M. and Hecher M. and LeBlanc E. and Penaloza R. and Salazar E. and Saptawijaya A. and Weitkamper F. and Zangari J.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2021 International Conference on Logic Programming Workshops, ICLP Workshops 2021; Conference date: 20 September 2021 through 21 September 2021; Conference code: 172261}
}

@BOOK{Scholz202157,
	author = {Scholz, Jason and Galliott, Jai},
	title = {The humanitarian imperative for minimally-just AI in weapons},
	year = {2021},
	journal = {Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare},
	pages = {57 – 72},
	doi = {10.1093/oso/9780197546048.003.0005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112287250&doi=10.1093%2foso%2f9780197546048.003.0005&partnerID=40&md5=56d6d92df49dece26e3ed8c8f974c974},
	affiliations = {RMIT University, Australia; University of New South Wales, Australia; Defence & Security Technology Group, UNSW, The Australian Defence Force Academy, Australia; Modern War Institute, United States Military Academy, West Point, United States; The Centre for Technology and Global Affairs, University of Oxford, United Kingdom},
	abstract = {For the use of force to be lawful and morally just, future autonomous systems must not commit humanitarian errors or acts of fratricide. To achieve this, we distinguish a novel preventative form of minimally-just autonomy using artificial intelligence (MinAI) to avert attacks on protected symbols, protected sites, and signals of surrender. MinAI compares favorably with respect to maximally-just forms proposed to date. We examine how fears of speculative artificial general intelligence has distracted resources from making current weapons more compliant with international humanitarian law, particularly Additional Protocol 1 of the Geneva Convention and its Article 36. Critics of our approach may argue that machine learning can be fooled, that combatants can commit perfidy to protect themselves, and so on. We confront this issue, including recent research on the subversion of AI, and conclude that the moral imperative for MinAI in weapons remains undiminished. © Oxford University Press 2021.},
	author_keywords = {Artificial intelligence; Autonomous weapon systems; Legal robots; Machine ethics; Machine learning; Machine reasoning},
	publisher = {Oxford University Press},
	isbn = {978-019754604-8},
	language = {English},
	abbrev_source_title = {Lethal Autonomous Weapons: Re-Examining the Law and Ethics of Robotic Warfare},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Salazar20211694,
	author = {Salazar, Ricardo and Neutatz, Felix and Abedjan, Ziawasch},
	title = {Automated feature engineering for algorithmic fairness},
	year = {2021},
	journal = {Proceedings of the VLDB Endowment},
	volume = {14},
	number = {9},
	pages = {1694 – 1702},
	doi = {10.14778/3461535.3463474},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115160562&doi=10.14778%2f3461535.3463474&partnerID=40&md5=ac20993154e1d5a1f8cdff910dc4014e},
	affiliations = {TU Berlin, Germany; Leibniz Universität Hannover, L3S Research Center, Germany},
	abstract = {One of the fundamental problems of machine ethics is to avoid the perpetuation and amplification of discrimination through machine learning applications. In particular, it is desired to exclude the influence of attributes with sensitive information, such as gender or race, and other causally related attributes on the machine learning task. The state-of-the-art bias reduction algorithm Capuchin breaks the causality chain of such attributes by adding and removing tuples. However, this horizontal approach can be considered invasive because it changes the data distribution. A vertical approach would be to prune sensitive features entirely. While this would ensure fairness without tampering with the data, it could also hurt the machine learning accuracy. Therefore, we propose a novel multi-objective feature selection strategy that leverages feature construction to generate more features that lead to both high accuracy and fairness. On three well-known datasets, our system achieves higher accuracy than other fairness-aware approaches while maintaining similar or higher fairness. © by the owner/author(s).},
	keywords = {Algorithmics; Automated features; Bias reduction; Feature engineerings; High-accuracy; Horizontal approach; Machine learning applications; Reduction algorithms; Sensitive informations; State of the art; Machine learning},
	publisher = {VLDB Endowment},
	issn = {21508097},
	language = {English},
	abbrev_source_title = {Proc. VLDB Endow.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 47th International Conference on Very Large Data Bases, VLDB 2021; Conference date: 16 August 2021 through 20 August 2021; Conference code: 263909}
}

@ARTICLE{2021,
	title = {3rd International Conference on Intelligent Technologies and Applications, INTAP 2020},
	year = {2021},
	journal = {Communications in Computer and Information Science},
	volume = {1382},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103519437&partnerID=40&md5=0bbbaafda58e57b12ebece2db2d38096},
	abstract = {The proceedings contain 34 papers. The special focus in this conference is on Intelligent Technologies and Applications. The topics include: Interpretable Option Discovery Using Deep Q-Learning and Variational Autoencoders; evaluating Predictive Deep Learning Models; Pre-trained CNN Based Deep Features with Hand-Crafted Features and Patient Data for Skin Lesion Classification; data-Driven Machine Learning Approach for Human Action Recognition Using Skeleton and Optical Flow; multilingual Voice Impersonation Dataset and Evaluation; a Survey on Unknown Presentation Attack Detection for Fingerprint; hierarchical Interpolation of Imagenet Features for Cross-Dataset Presentation Attack Detection; cross-lingual Speaker Verification: Evaluation on X-Vector Method; fusion of Texture and Optical Flow Using Convolutional Neural Networks for Gender Classification in Videos; exploring Circular Hough Transforms for Detecting Hand Feature Points in Noisy Images from Ghost-Circle Patterns; A PM 2.5 Forecasting Model Based on Air Pollution and Meteorological Conditions in Neighboring Areas; the Aquatic Surface Robot (AnSweR), a Lightweight, Low Cost, Multipurpose Unmanned Research Vessel; empirical Analysis of Data Mining Techniques in Network Intrusion Detection Systems; deep Neural Network Based Malicious Network Activity Detection Under Adversarial Machine Learning Attacks; towards Low Cost and Smart Load Testing as a Service Using Containers; securityGuard: An Automated Secure Coding Framework; the Multi-objective Feature Selection in Android Malware Detection System; border Management Systems: How Can They Help Against Pandemics; translating Ethical Theory into Ethical Action: An Ethic of Responsibility Approach to Value-Oriented Design; An Example of Privacy and Data Protection Best Practices for Biometrics Data Processing in Border Control: Lesson Learned from SMILE; protecting IoT Devices with Software-Defined Networks.},
	editor = {Yildirim Yayilgan S. and Bajwa I.S. and Sanfilippo F.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18650929},
	isbn = {978-303071710-0},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Intelligent Technologies and Applications, INTAP 2020; Conference date: 28 September 2020 through 30 September 2020; Conference code: 256479}
}

@ARTICLE{Laacke20214,
	author = {Laacke, Sebastian and Mueller, Regina and Schomerus, Georg and Salloch, Sabine},
	title = {Artificial Intelligence, Social Media and Depression. A New Concept of Health-Related Digital Autonomy},
	year = {2021},
	journal = {American Journal of Bioethics},
	volume = {21},
	number = {7},
	pages = {4 – 20},
	doi = {10.1080/15265161.2020.1863515},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098971645&doi=10.1080%2f15265161.2020.1863515&partnerID=40&md5=939febc4c6856f1db3dc7cc7d01fb491},
	affiliations = {University Medicine Greifswald, Germany; University of Tübingen, Germany; University of Leipzig Medical Center, Germany; Hannover Medical School, United States},
	abstract = {The development of artificial intelligence (AI) in medicine raises fundamental ethical issues. As one example, AI systems in the field of mental health successfully detect signs of mental disorders, such as depression, by using data from social media. These AI depression detectors (AIDDs) identify users who are at risk of depression prior to any contact with the healthcare system. The article focuses on the ethical implications of AIDDs regarding affected users’ health-related autonomy. Firstly, it presents the (ethical) discussion of AI in medicine and, specifically, in mental health. Secondly, two models of AIDDs using social media data and different usage scenarios are introduced. Thirdly, the concept of patient autonomy, according to Beauchamp and Childress, is critically discussed. Since this concept does not encompass the specific challenges linked with the digital context of AIDDs in social media sufficiently, the current analysis suggests, finally, an extended concept of health-related digital autonomy. © 2020 Taylor & Francis Group, LLC.},
	author_keywords = {Diagnosis; digital; ethics; machine learning; mental health},
	keywords = {Artificial Intelligence; Delivery of Health Care; Depression; Humans; Mental Health; Social Media; adult; article; artificial intelligence; ethics; human; machine learning; mental health; patient autonomy; social media; depression; health care delivery; mental health},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33393864},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27}
}

@ARTICLE{Amann2020,
	author = {Amann, Julia and Blasimme, Alessandro and Vayena, Effy and Frey, Dietmar and Madai, Vince I.},
	title = {Explainability for artificial intelligence in healthcare: a multidisciplinary perspective},
	year = {2020},
	journal = {BMC Medical Informatics and Decision Making},
	volume = {20},
	number = {1},
	doi = {10.1186/s12911-020-01332-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096905043&doi=10.1186%2fs12911-020-01332-6&partnerID=40&md5=e8d9fbdea0ec51948feafa1748bf977c},
	affiliations = {Health Ethics and Policy Lab, Department of Health Sciences and Technology, ETH Zurich, Hottingerstrasse 10, Zurich, 8092, Switzerland; Charité Lab for Artificial Intelligence in Medicine—CLAIM, Charité - Universitätsmedizin Berlin, Berlin, Germany; School of Computing and Digital Technology, Faculty of Computing, Engineering and the Built Environment, Birmingham City University, Birmingham, United Kingdom},
	abstract = {Background: Explainability is one of the most heavily debated topics when it comes to the application of artificial intelligence (AI) in healthcare. Even though AI-driven systems have been shown to outperform humans in certain analytical tasks, the lack of explainability continues to spark criticism. Yet, explainability is not a purely technological issue, instead it invokes a host of medical, legal, ethical, and societal questions that require thorough exploration. This paper provides a comprehensive assessment of the role of explainability in medical AI and makes an ethical evaluation of what explainability means for the adoption of AI-driven tools into clinical practice. Methods: Taking AI-based clinical decision support systems as a case in point, we adopted a multidisciplinary approach to analyze the relevance of explainability for medical AI from the technological, legal, medical, and patient perspectives. Drawing on the findings of this conceptual analysis, we then conducted an ethical assessment using the “Principles of Biomedical Ethics” by Beauchamp and Childress (autonomy, beneficence, nonmaleficence, and justice) as an analytical framework to determine the need for explainability in medical AI. Results: Each of the domains highlights a different set of core considerations and values that are relevant for understanding the role of explainability in clinical practice. From the technological point of view, explainability has to be considered both in terms how it can be achieved and what is beneficial from a development perspective. When looking at the legal perspective we identified informed consent, certification and approval as medical devices, and liability as core touchpoints for explainability. Both the medical and patient perspectives emphasize the importance of considering the interplay between human actors and medical AI. We conclude that omitting explainability in clinical decision support systems poses a threat to core ethical values in medicine and may have detrimental consequences for individual and public health. Conclusions: To ensure that medical AI lives up to its promises, there is a need to sensitize developers, healthcare professionals, and legislators to the challenges and limitations of opaque algorithms in medical AI and to foster multidisciplinary collaboration moving forward. © 2020, The Author(s).},
	author_keywords = {Artificial intelligence; Clinical decision support; Explainability; Interpretability; Machine learning},
	keywords = {Artificial Intelligence; Decision Support Systems, Clinical; Delivery of Health Care; Health Facilities; Humans; Informed Consent; artificial intelligence; clinical decision support system; health care delivery; health care facility; human; informed consent},
	correspondence_address = {J. Amann; Health Ethics and Policy Lab, Department of Health Sciences and Technology, ETH Zurich, Zurich, Hottingerstrasse 10, 8092, Switzerland; email: julia.amann@hest.ethz.ch},
	publisher = {BioMed Central Ltd},
	issn = {14726947},
	pmid = {33256715},
	language = {English},
	abbrev_source_title = {BMC Med. Informatics Decis. Mak.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 265; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Fischer2021110,
	author = {Fischer, Isabel and Beswick, Claire and Newell, Sue},
	title = {Rho AI – Leveraging artificial intelligence to address climate change: Financing, implementation and ethics},
	year = {2021},
	journal = {Journal of Information Technology Teaching Cases},
	volume = {11},
	number = {2},
	pages = {110 – 116},
	doi = {10.1177/2043886920961782},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101683424&doi=10.1177%2f2043886920961782&partnerID=40&md5=a8688d06d174f053f9c2e1422a2ee3b1},
	affiliations = {University of Warwick, United Kingdom; University of the Witwatersrand, South Africa},
	abstract = {The case focusses on Rho AI, a data science firm, and its attempt to leverage artificial intelligence to encourage environmental, social and governance investments to limit the impact of climate change. Rho AI’s proposed open-source artificial intelligence tool integrates automated web scraping technology and machine learning with natural language processing. The aim of the tool is to enable investors to evaluate the climate impact of companies and to use this evaluation as a basis for making investments in companies. The case study allows for students to gain an insight into some of the strategic choices that need to be considered when developing an artificial intelligence–based tool. Students will be able to explore the role of ethics in decision-making related to artificial intelligence, while familiarising themselves with key technical terminology and possible business models. The case encourages students to see beyond the technical granularities and to consider the multi-faceted, wider corporate and societal issues and priorities. This case contributes to students recognising that business is not conducted in a vacuum and enhances students’ understanding of the role of business in society during new developments triggered by digital technology. © Association for Information Technology Trust 2021.},
	author_keywords = {Artificial intelligence; business models; climate change; digital leadership; environmental; ethics; social and governance investing},
	correspondence_address = {I. Fischer; University of Warwick, United Kingdom; email: Isabel.Fischer@wbs.ac.uk},
	publisher = {SAGE Publications Inc.},
	issn = {20438869},
	language = {English},
	abbrev_source_title = {J. Infor. Technol. Teach. Classes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Moulin20211,
	author = {Moulin, Thiago C. and Covill, Laura E. and Itskov, Pavel M. and Williams, Michael J. and Schiöth, Helgi B.},
	title = {Rodent and fly models in behavioral neuroscience: An evaluation of methodological advances, comparative research, and future perspectives},
	year = {2021},
	journal = {Neuroscience and Biobehavioral Reviews},
	volume = {120},
	pages = {1 – 12},
	doi = {10.1016/j.neubiorev.2020.11.014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097239984&doi=10.1016%2fj.neubiorev.2020.11.014&partnerID=40&md5=e5ebb3b3e3e59fce536392705b6b408c},
	affiliations = {Functional Pharmacology Unit, Department of Neuroscience, Uppsala University, Uppsala, Sweden; Center for Hematology and Regenerative Medicine, Karolinska Institutet, Stockholm, Sweden; Department of Pharmacology, Institute of Pharmacy, Sechenov First Moscow State Medical University, Moscow, Russian Federation; Champalimaud Centre for the Unknown, Lisbon, Portugal; Institute for Translational Medicine and Biotechnology, Sechenov First Moscow State Medical University, Moscow, Russian Federation},
	abstract = {The assessment of behavioral outcomes is a central component of neuroscientific research, which has required continuous technological innovations to produce more detailed and reliable findings. In this article, we provide an in-depth review on the progress and future implications for three model organisms (mouse, rat, and Drosophila) essential to our current understanding of behavior. By compiling a comprehensive catalog of popular assays, we are able to compare the diversity of tasks and usage of these animal models in behavioral research. This compilation also allows for the evaluation of existing state-of-the-art methods and experimental applications, including optogenetics, machine learning, and high-throughput behavioral assays. We go on to discuss novel apparatuses and inter-species analyses for centrophobism, feeding behavior, aggression and mating paradigms, with the goal of providing a unique view on comparative behavioral research. The challenges and recent advances are evaluated in terms of their translational value, ethical procedures, and trustworthiness for behavioral research. © 2020 The Authors},
	author_keywords = {3Rs; Aggression; Animal ethics; Animal models; Anxiety; Artificial intelligence; Behavioral tests; Centrophobism; Closed-loop feedback optogenetics; Feeding; Mating; Reproducibility; Translational research},
	keywords = {aggression; animal experiment; animal model; anxiety; artificial intelligence; behavioral research; clinical assessment; controlled study; Drosophila; ethics; feeding behavior; machine learning; male; mating; mouse; neuroscience; nonhuman; optogenetics; rat; reproducibility; review; rodent; translational research},
	correspondence_address = {T.C. Moulin; Department of Neuroscience, Uppsala University, BMC, Uppsala, Box 593, 751 24, Sweden; email: thiago.moulin@neuro.uu.se},
	publisher = {Elsevier Ltd},
	issn = {01497634},
	coden = {NBRED},
	pmid = {33242563},
	language = {English},
	abbrev_source_title = {Neurosci. Biobehav. Rev.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Sollini2020,
	author = {Sollini, Martina and Bartoli, Francesco and Marciano, Andrea and Zanca, Roberta and Slart, Riemer H. J. A. and Erba, Paola A.},
	title = {Artificial intelligence and hybrid imaging: the best match for personalized medicine in oncology},
	year = {2020},
	journal = {European Journal of Hybrid Imaging},
	volume = {4},
	number = {1},
	doi = {10.1186/s41824-020-00094-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100671063&doi=10.1186%2fs41824-020-00094-8&partnerID=40&md5=870b5195b62174bd3e9aee242c80877f},
	affiliations = {Department of Biomedical Sciences, Humanitas University, Pieve Emanuele (Milan), Italy; Humanitas Clinical and Research Center, Rozzano (Milan), Italy; Regional Center of Nuclear Medicine, Department of Translational Research and New Technologies in Medicine and Surgery, University of Pisa, Pisa, Italy; University Medical Center Groningen, Medical Imaging Center, University of Groningen, Groningen, Netherlands; Faculty of Science and Technology, Biomedical Photonic Imaging, University of Twente, Enschede, Netherlands},
	abstract = {Artificial intelligence (AI) refers to a field of computer science aimed to perform tasks typically requiring human intelligence. Currently, AI is recognized in the broader technology radar within the five key technologies which emerge for their wide-ranging applications and impact in communities, companies, business, and value chain framework alike. However, AI in medical imaging is at an early phase of development, and there are still hurdles to take related to reliability, user confidence, and adoption. The present narrative review aimed to provide an overview on AI-based approaches (distributed learning, statistical learning, computer-aided diagnosis and detection systems, fully automated image analysis tool, natural language processing) in oncological hybrid medical imaging with respect to clinical tasks (detection, contouring and segmentation, prediction of histology and tumor stage, prediction of mutational status and molecular therapies targets, prediction of treatment response, and outcome). Particularly, AI-based approaches have been briefly described according to their purpose and, finally lung cancer—being one of the most extensively malignancy studied by hybrid medical imaging—has been used as illustrative scenario. Finally, we discussed clinical challenges and open issues including ethics, validation strategies, effective data-sharing methods, regulatory hurdles, educational resources, and strategy to facilitate the interaction among different stakeholders. Some of the major changes in medical imaging will come from the application of AI to workflow and protocols, eventually resulting in improved patient management and quality of life. Overall, several time-consuming tasks could be automatized. Machine learning algorithms and neural networks will permit sophisticated analysis resulting not only in major improvements in disease characterization through imaging, but also in the integration of multiple-omics data (i.e., derived from pathology, genomic, proteomics, and demographics) for multi-dimensional disease featuring. Nevertheless, to accelerate the transition of the theory to practice a sustainable development plan considering the multi-dimensional interactions between professionals, technology, industry, markets, policy, culture, and civil society directed by a mindset which will allow talents to thrive is necessary. © 2020, The Author(s).},
	author_keywords = {Artificial intelligence; Computer-aided diagnosis systems; Deep learning; Distributed learning; Hybrid imaging; Imaging biomarkers; Machine learning; Natural language processing; PET/CT; Radiomics},
	correspondence_address = {P.A. Erba; Regional Center of Nuclear Medicine, Department of Translational Research and New Technologies in Medicine and Surgery, University of Pisa, Pisa, Italy; email: paola.erba@unipi.it},
	publisher = {Springer Science and Business Media B.V.},
	issn = {25103636},
	language = {English},
	abbrev_source_title = {Eur. J. Hybrid Imag.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Oliver20211,
	author = {Oliver, Jeffrey C. and McNeil, Torbet},
	title = {Undergraduate data science degrees emphasize computer science and statistics but fall short in ethics training and domain-specific context},
	year = {2021},
	journal = {PeerJ Computer Science},
	volume = {7},
	pages = {1 – 15},
	doi = {10.7717/peerj-cs.441},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104803598&doi=10.7717%2fpeerj-cs.441&partnerID=40&md5=e90b96195aaec84d78048f572a5ba349},
	affiliations = {Office of Digital Innovation & Stewardship, University Libraries, University of Arizona, Tucson, AZ, United States; Department of Educational Policy Studies and Practice, University of Arizona, Tucson, AZ, United States},
	abstract = {The interdisciplinary field of data science, which applies techniques from computer science and statistics to address questions across domains, has enjoyed recent considerable growth and interest. This emergence also extends to undergraduate education, whereby a growing number of institutions now offer degree programs in data science. However, there is considerable variation in what the field actually entails and, by extension, differences in how undergraduate programs prepare students for data-intensive careers. We used two seminal frameworks for data science education to evaluate undergraduate data science programs at a subset of 4-year institutions in the United States; developing and applying a rubric, we assessed how well each program met the guidelines of each of the frameworks. Most programs scored high in statistics and computer science and low in domain-specific education,ethics, and areas of communication. Moreover, the academic unit administering the degree program significantly influenced the course-load distribution of computer science and statistics/mathematics courses. We conclude that current data science undergraduate programs provide solid grounding in computational and statistical approaches, yet may not deliver sufficient context in terms of domain knowledge and ethical considerations necessary for appropriate data science applications. Additional refinement of the expectations for undergraduate data science education is warranted. © Copyright 2021 Oliver and McNeil Distributed under Creative Commons CC-BY 4.0},
	author_keywords = {Computer science; Curricula; Data science; Education; Ethics; Machine learning; Statistics},
	keywords = {Application programs; Curricula; Education computing; Electric grounding; Philosophical aspects; Statistics; Students; Ethical considerations; Interdisciplinary fields; Load distributions; Science applications; Science education; Statistical approach; Undergraduate education; Undergraduate program; Data Science},
	correspondence_address = {J.C. Oliver; Office of Digital Innovation & Stewardship, University Libraries, University of Arizona, Tucson, United States; email: jcoliver@email.arizona.edu},
	publisher = {PeerJ Inc.},
	issn = {23765992},
	language = {English},
	abbrev_source_title = {PeerJ Comput. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Chassagnon2020,
	author = {Chassagnon, Guillaume and Zacharaki, Evangelia I. and Bommart, Sébastien and Burgel, Pierre-Régis and Chiron, Raphael and Dangeard, Séverine and Paragios, Nikos and Martin, Clémence and Revel, Marie-Pierre},
	title = {Quantification of cystic fibrosis lung disease with radiomics-based ct scores},
	year = {2020},
	journal = {Radiology: Cardiothoracic Imaging},
	volume = {2},
	number = {6},
	doi = {10.1148/ryct.2020200022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112101481&doi=10.1148%2fryct.2020200022&partnerID=40&md5=3d55d592a056ffc3b77857f5241195e8},
	affiliations = {Department of Radiology, Groupe Hospitalier Cochin-Hotel Dieu, AP-HP, Université Paris Descartes, 27 Rue du Faubourg Saint-Jacques, Paris, 75014, France; Respiratory Medicine and National Cystic Reference Center, Groupe Hospitalier Cochin-Hotel Dieu, AP-HP, Université Paris Descartes, 27 Rue du Faubourg Saint-Jacques, Paris, 75014, France; Center for Visual Computing, Ecole CentraleSupelec, Grande Voie des Vignes, Chatenay Malabry, France; U1016 Inserm, Institut Cochin, Paris, France; Radiology Department, Hôpital Arnaud de Villeneuve, CHU de Montpellier, Université de Montpellier, Montpellier, France; Pulmonary Department, Hôpital Arnaud de Villeneuve, CHU de Montpellier, Université de Montpellier, Montpellier, France; ERN-Lung CF Network, France; TheraPanacea, Paris-Biotech-Santé, Paris, France},
	abstract = {Purpose: To develop radiomics-based CT scores for assessing lung disease severity and exacerbation risk in adult patients with cystic fibrosis (CF). Materials and Methods: This two-center retrospective observational study was approved by an institutional ethics committee, and the need for patient consent was waived. A total of 215 outpatients with CF referred for unenhanced follow-up chest CT were evaluated in two different centers between January 2013 and December 2016. After lung segmentation, chest CT scans from center 1 (training cohort, 162 patients [median age, 29 years; interquartile range {IQR}, 24–36 years; 84 men]) were used to build CT scores from 38 extracted CT features, using five different machine learning techniques trained to predict a clinical prognostic score, the Nkam score. The correlations between the developed CT scores, two different clinical prognostic scores (Liou and CF-ABLE), forced expiratory volume in 1 second (FEV1 ), and risk of respiratory exacerbations were evaluated in the test cohort (center 2, 53 patients [median age, 27 years; IQR, 22–35 years; 34 men]) using the Spearman rank coefficient. Results: In the test cohort, all radiomics-based CT scores showed moderate to strong correlation with the Nkam score (R = 0.57 to 0.63, P < .001) and Liou scores (R =-0.55 to-0.65, P < .001), whereas the correlation with CF-ABLE score was weaker (R = 0.28 to 0.38, P = .005 to .048). The developed CT scores showed strong correlation with predicted FEV1 (R =-0.62 to-0.66, P < .001) and weak to moderate correlation with the number of pulmonary exacerbations to occur in the 12 months after the CT examination (R = 0.38 to 0.55, P < .001 to P = .006). Conclusion: Radiomics can be used to build automated CT scores that correlate to clinical severity and exacerbation risk in adult patients with CF. © RSNA, 2020.},
	correspondence_address = {M.-P. Revel; Department of Radiology, Groupe Hospitalier Cochin-Hotel Dieu, AP-HP, Université Paris Descartes, Paris, 27 Rue du Faubourg Saint-Jacques, 75014, France; email: marie-pierre.revel@aphp.fr},
	publisher = {Radiological Society of North America Inc.},
	issn = {26386135},
	language = {English},
	abbrev_source_title = {Radiol. Cardiothorac. Imaging.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Reinhardt202143,
	author = {Reinhardt, Karoline},
	title = {Diversity-sensitive social platforms and responsibility Some ethical considerations},
	year = {2021},
	journal = {Informacios Tarsadalom},
	volume = {21},
	number = {2},
	pages = {43 – 62},
	doi = {10.22503/inftars.XXI.2021.2.4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117783558&doi=10.22503%2finftars.XXI.2021.2.4&partnerID=40&md5=a6e2165be66fcb24c0fc9b0cc32f9c70},
	affiliations = {Eberhard Karls Universität, Tübingen, Germany},
	abstract = {There is an ongoing debate on how algorithms and machine learning can and should deal with human diversity while avoiding the pitfalls of statistical stereotyping, the re-enforcement of clichés and the perpetuation of unjust discrimination. Computer scientists try to tackle these issues by developing algorithms and social-interaction protocols for mediating diversity-aware interactions between people, for instance on diversity-sensitive social platforms. At the same time, diversity-related data often comprise sensitive personal data, and their collection, storage and management increases the vulnerability of users to various misuse scenarios. Already this observation leads to the question, how do we need to conceptualize responsibility to do justice to the increased vulnerability? In this paper, I thus focus on the questions a diversity-sensitive social platform raises with regard to responsibility, and propose a tentative ethical framework of responsibility for these platforms. © 2021 Infonia. All rights reserved.},
	author_keywords = {Algorithms; Applied ethics; Diversity; Responsibility; Social platforms},
	publisher = {Infonia},
	issn = {15878694},
	language = {English},
	abbrev_source_title = {Informacios Tars.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Pillai2020,
	author = {Pillai, Prarthana and Ayare, Prathamesh and Balasingam, Balakumar and Milne, Kevin and Biondi, Francesco},
	title = {Response time and eye tracking datasets for activities demanding varying cognitive load},
	year = {2020},
	journal = {Data in Brief},
	volume = {33},
	doi = {10.1016/j.dib.2020.106389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092913822&doi=10.1016%2fj.dib.2020.106389&partnerID=40&md5=95021e055521632fa6a56b739511beb6},
	affiliations = {Department of Electrical and Computer Engineering, University of Windsor, 401 Sunset Avenue, Windsor, N9G 3P4, ON, Canada; Faculty of Human Kinetics, University of Windsor, 401 Sunset Avenue, Windsor, N9G 3P4, ON, Canada},
	abstract = {The dataset contains the following three measures that are widely used to determine cognitive load in humans: Detection Response Task - response time, pupil diameter, and eye gaze. These measures were recorded from 28 participants while they underwent tasks that are designed to permeate three different cognitive difficulty levels. The dataset will be useful to those researchers who seek to employ low cost, non-invasive sensors to detect cognitive load in humans and to develop algorithms for human-system automation. One such application is found in Advanced Driver Assistance Systems where eye-trackers are employed to monitor the alertness of the drivers. The dataset would also be helpful to researchers who are interested in employing machine learning algorithms to develop predictive models of humans for applications in human-machine system automation. The data is collected by the authors at the Department of Electrical & Computer Engineering in collaboration with the Faculty of Human Kinetics at the University of Windsor under the guidance of their Research Ethics Board. © 2020 The Authors},
	author_keywords = {Cognitive load detection; Detection; Detection response task (DRT); Eye-tracking; Human-computer interface; Machine learning; Psychological signals; Pupil dilation; Signal processing},
	correspondence_address = {P. Pillai; Department of Electrical and Computer Engineering, University of Windsor, Windsor, 401 Sunset Avenue, N9G 3P4, Canada; email: pillaip@uwindsor.ca},
	publisher = {Elsevier Inc.},
	issn = {23523409},
	language = {English},
	abbrev_source_title = {Data Brief},
	type = {Data paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Larijani202189,
	author = {Larijani, Bagher and Goodarzi, Parisa and Payab, Moloud and Tayanloo-Beik, Akram and Sarvari, Masoumeh and Gholami, Mahdi and Gilany, Kambiz and Nasli-Esfahani, Ensieh and Yarahmadi, Mehrnoosh and Ghaderi, Firoozeh and Arjmand, Babak},
	title = {The Design and Application of an Appropriate Parkinson’s Disease Animal Model in Regenerative Medicine},
	year = {2021},
	journal = {Advances in Experimental Medicine and Biology},
	volume = {1341},
	pages = {89 – 105},
	doi = {10.1007/5584_2019_422},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85114285669&doi=10.1007%2f5584_2019_422&partnerID=40&md5=3ef180fbaba18087bb0e2123bcbc326a},
	affiliations = {Endocrinology and Metabolism Research Center, Endocrinology and Metabolism Clinical Sciences Institute, Tehran University of Medical sciences, Tehran, Iran; Brain and Spinal Cord Injury Research Center, Neuroscience Institute, Tehran University of Medical Sciences, Tehran, Iran; Obesity and Eating Habits Research Center, Endocrinology and Metabolism Molecular-Cellular Sciences Institute, Tehran University of Medical Sciences, Tehran, Iran; Cell Therapy and Regenerative Medicine Research Center, Endocrinology and Metabolism Molecular-Cellular Sciences Institute, Tehran University of Medical Sciences, Tehran, Iran; Metabolomics and Genomics Research Center, Endocrinology and Metabolism Molecular-Cellular Sciences Institute, Tehran University of Medical Sciences, Tehran, Iran; Department of Toxicology & Pharmacology, Faculty of Pharmacy, Toxicology and Poisoning Research Center, Tehran University of Medical Sciences, Tehran, Iran; Department of Biomedical Sciences, University of Antwerp, Antwerp, Belgium; Integrative Oncology Department, Breast Cancer Research Center, Motamed Cancer Institute, ACECR, Tehran, Iran; Diabetes Research Center, Endocrinology and Metabolism Clinical Sciences Institute, Tehran University of Medical Sciences, Tehran, Iran},
	abstract = {Objectives: Aging as an inevitable and complex physiological process occurs through a progressive decrease in the potential of tissue regeneration. Given the increasing global outbreak of aging and age-related disorders, it is important to control this phenomenon. Parkinson’s disease (one of the age-related neurodegenerative and progressive disorders) resulted from predominant dopaminergic neurons deficiency. Usual Parkinson’s disease treatments just can lead to symptomatically relieving. Recently, cell therapy and regenerative medicine a great promise in the treatment of several types of disorders including Parkinson’s disease. Herein, before starting clinical trials, preclinical studies should be performed to answer some fundamental questions about the safety and efficacy of various treatments. Additionally, developing a well-designed and approved study is required to provide an appropriate animal model with strongly reliable validation methods. Hereupon, this review will discuss about the design and application of an appropriate Parkinson’s disease animal model in regenerative medicine. Evidence acquisition: In order to conduct the present review, numbers of Parkinson’s disease preclinical studies, as well as literatures related to the animal modeling, were considered. Results: Appropriate animal models which approved by related authorize committees should have a high similarity to humans from anatomical, physiological, behavioral, and genetic characteristics view of point. Conclusion: It is concluded that animal studies before starting clinical trials have an important role in answering the crucial questions about the various treatments safety and efficacy. Therein, it is recommended that all of animal modeling stages be assessed by animal ethics and welfare guidelines and also evaluated by different validation tests. However, it is better to find some alternatives to replacement, refinement, and, reduction of animals. Nowadays, some novel technologies such as using imaging methods have been introduced. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Animal welfare; Parkinson’s disease; Regenerative medicine; Research design; Validation},
	keywords = {Aging; Animals; Disease Models, Animal; Dopaminergic Neurons; Humans; Parkinson Disease; Regenerative Medicine; 1,2,3,6 tetrahydro 1 methyl 4 phenylpyridine; amantadine; apomorphine; catechol methyltransferase inhibitor; cholinergic receptor blocking agent; levodopa; oxidopamine; paraquat; piribedil; pramipexole; rotenone; a syn gene; A30P gene; anatomy; Anura; behavior; brain depth stimulation; Caenorhabditis elegans; Callitrichinae; cat; clinical evaluation; DJ 1 gene; dog; Drosophila; gene knockout; gene overexpression; genetics; goldfish; Gottingen minipig; guinea pig; Haplorhini; in vivo study; LRRK2 gene; machine learning; neuroimaging; nonhuman; nuclear magnetic resonance imaging; Oryzias; parkin gene; Parkinson disease; physiology; PINK1 gene; positron emission tomography; practice guideline; regenerative medicine; sheep; voxel based morphometry; yeast; zebra fish; aging; animal; disease model; dopaminergic nerve cell; human; Parkinson disease; regenerative medicine},
	correspondence_address = {B. Arjmand; Metabolomics and Genomics Research Center, Endocrinology and Metabolism Molecular-Cellular Sciences Institute, Tehran University of Medical Sciences, Tehran, Iran; email: barjmand@sina.tums.ac.ir},
	publisher = {Springer},
	issn = {00652598},
	coden = {AEMBA},
	pmid = {31485993},
	language = {English},
	abbrev_source_title = {Adv. Exp. Med. Biol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Mancl2021222,
	author = {Mancl, Dennis and Fraser, Steven D.},
	title = {The Future of Software Engineering: Where Will Machine Learning, Agile, and Virtualization Take Us Next?},
	year = {2021},
	journal = {Lecture Notes in Business Information Processing},
	volume = {426},
	pages = {222 – 230},
	doi = {10.1007/978-3-030-88583-0_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118175089&doi=10.1007%2f978-3-030-88583-0_23&partnerID=40&md5=418049b44a421f03bda9f08f49fe6a0c},
	affiliations = {MSWX Software Experts, Bridgewater, 08807, NJ, United States; Innoxec, Santa Clara, CA, United States},
	abstract = {Software has become the lifeblood of the 21st century, enabling a broad range of commercial, medical, educational, agricultural, and government applications. These applications are designed and deployed through a variety of software best practices. With the onset of the COVID-19 pandemic, developers have embraced virtualization (remote working) and a variety of strategies to manage the complexity of global development on multiple platforms. However, evolving hazards such as network security, algorithm bias, and the combination of careless developers and deliberate attacks continue to be a challenge. An XP2021 panel organized and chaired by Steven Fraser debated the future of software engineering and related topics such education, ethics, and tools. The panel featured Anita Carleton (CMU’s SEI), Priya Marsonia (Cognizant), Bertrand Meyer (SIT, Eiffel Software), Landon Noll (Independent Consultant), and Kati Vilkki (Reaktor). © 2021, The Author(s).},
	author_keywords = {Agile; AI; Applications; Collaboration; Education; Machine learning; Professionalism; Remote working; Societal needs; Software engineering},
	keywords = {Agricultural robots; Application programs; Network security; Virtual reality; Virtualization; Agile; Collaboration; Global development; Machine-learning; Multiple platforms; Professionalism; Remote working; Societal need; Software best practices; Virtualizations; Machine learning},
	correspondence_address = {D. Mancl; MSWX Software Experts, Bridgewater, 08807, United States; email: dmancl@acm.org},
	editor = {Gregory P. and Kruchten P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18651348},
	isbn = {978-303088582-3},
	language = {English},
	abbrev_source_title = {Lect. Notes Bus. Inf. Process.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 22nd International Conference on Agile Software Development, 2021; Conference date: 14 June 2021 through 18 June 2021; Conference code: 267229; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Doherty2021213,
	author = {Doherty, Lorrainne},
	title = {Can Aristotelian virtue theory survive Fourth Order Technology? An ethics perspective},
	year = {2021},
	journal = {South African Journal of Philosophy},
	volume = {40},
	number = {2},
	pages = {213 – 227},
	doi = {10.1080/02580136.2021.1941652},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109158615&doi=10.1080%2f02580136.2021.1941652&partnerID=40&md5=ec2911ca5fd561315aa5a1d4bfee5b3f},
	affiliations = {School of Mechanical, Industrial and Aeronautical Engineering, University of the Witwatersrand, Johannesburg, South Africa},
	abstract = {The Fourth Industrial Revolution (4IR) and accompanying Fourth Order technologies (FOTs) sit at the confluence of epistemé and techné knowledge identified in classical Greek philosophy. The former is interpreted as scientific knowledge and discoveries, and the latter is its practical application in the form of “new” technologies and manufacturing processes. This helps explain both 4IR and FOT where 4IR is characterised by the science of digitisation and computerisation, and FOT by machines combining artificial intelligence (AI) and advanced machine learning (AML), both key components in FOT functionality. Through the use of codification and algorithms, scientists and engineers are trying to imitate human thought and behaviour in ways devoid of human virtue and relationality, vital ingredients in the “lived” experience. Classical Aristotelian virtue theory is agent-based, but recognises the importance of the “lived experience”, both individual (self) and in terms of their relationality in the wider community (other). Phronesis, or practical wisdom, is a critical tool in Aristotelian virtue theory as it is theorised to assist the individual in their “lived” human experiences in the acquisition of both intellectual virtues (rational) and moral virtues (emotional), leading to a state of eudaimonia, or ultimate well-being for the individual (self) and eventually wider society (other). Aristotelian virtue theory understands that human life is not always calculable, measurable, or rational, but it has a corresponding and arguably deeper and more profound meaning and influence through the relative and moral brought about through the “lived” human experience and its iteration. © 2021 South African Journal of Philosophy.},
	correspondence_address = {L. Doherty; School of Mechanical, Industrial and Aeronautical Engineering, University of the Witwatersrand, Johannesburg, South Africa; email: lorrainne.doherty@wits.ac.za},
	publisher = {Taylor and Francis Ltd.},
	issn = {02580136},
	language = {English},
	abbrev_source_title = {S. Afr. J. Philos.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{P2021205,
	author = {P, Deepak and Chakraborty, Tanmoy and Long, Cheng and G, Santhosh Kumar},
	title = {Ethical Considerations in Data-Driven Fake News Detection},
	year = {2021},
	journal = {Information Retrieval Series},
	volume = {42},
	pages = {205 – 232},
	doi = {10.1007/978-3-030-62696-9_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105990118&doi=10.1007%2f978-3-030-62696-9_10&partnerID=40&md5=d45f278be0c8e68457af1eeff38438da},
	affiliations = {Queen’s University Belfast, Belfast, United Kingdom; Indraprastha Institute of Information Technology, Delhi, India; School of Computer Science and Engineering, Nanyang Technological University, Singapore, Singapore; Department of Computer Science, Cochin University of Science and Technology, Cochin, Kerala, India},
	abstract = {Data-driven and AI-based detection of fake news has seen much recent interest. The focus of research on data-driven fake news detection has been on developing novel and effective machine learning pipelines. The field has flourished with the rapid advances in deep learning methodologies and the availability of several labelled datasets to benchmark methods. While treating fake news detection as yet another data analytics problem, there has been little work on analyzing the ethical and normative considerations within such a task. This work, in a first-of-its-kind effort, analyzes ethical and normative considerations in using data-driven automation for fake news detection. We first consider the ethical dimensions of importance within the task context, followed by a detailed discussion on adhering to fairness and democratic values while combating fake news through data-driven AI-based automation. Throughout this chapter, we place emphasis on acknowledging the nuances of the digital media domain and also attempt to outline technologically grounded recommendations on how fake news detection algorithms could evolve while preserving and deepening democratic values within society. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Data science; Ethics; Fairness; Fake news detection},
	correspondence_address = {D. P; Queen’s University Belfast, Belfast, United Kingdom; email: deepaksp@acm.org},
	publisher = {Springer Nature},
	issn = {18717500},
	language = {English},
	abbrev_source_title = {Inf. Retr. Ser.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Bacci2021,
	author = {Bacci, Nicholas and Davimes, Joshua and Steyn, Maryna and Briers, Nanette},
	title = {Development of the Wits Face Database: An African database of high-resolution facial photographs and multimodal closed-circuit television (CCTV) recordings},
	year = {2021},
	journal = {F1000Research},
	volume = {10},
	doi = {10.12688/f1000research.50887.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103353506&doi=10.12688%2ff1000research.50887.1&partnerID=40&md5=984c57ae5e632c3b05783bac5359e8bf},
	affiliations = {Human Variation and Identification Research Unit (HVIRU), School of Anatomical Sciences, University of the Witwatersrand, Johannesburg, Gauteng, 2193, South Africa},
	abstract = {Forensic facial comparison is a commonly used, yet under-evaluated method employed in medicolegal contexts across the world. Testing the accuracy and reliability of facial comparisons requires large scale controlled and matching facial image databases. Databases that contain images of individuals on closed-circuit television (CCTV), with matching formal and informal photographs are needed for this type of research. Although many databases are available, the majority if not all are developed in order to improve facial recognition and face detection algorithms through machine learning, with very limited if any measure of standardisation. This paper aims to review the available databases and describe the development of a high resolution, standardised facial photograph and CCTV recording database of male Africans. The database is composed of a total of 6220 standardised and uncontrolled suboptimal facial photographs of 622 matching individuals in five different views, as well as corresponding CCTV footage of 334 individuals recorded under different realistic conditions. A detailed description of the composition and acquisition process of the database as well as its subdivisions and possible uses are provided. The challenges and limitations of developing this database are also highlighted, particularly with regard to obtaining CCTV video recordings and ethics for a database of faces. The application process to access the database is also briefly described. © 2021 Bacci N et al.},
	author_keywords = {CCTV; Face database; Facial comparison; Facial identification; Facial photographs; Facial recognition; Morphological analysis},
	keywords = {Databases, Factual; Facial Recognition; Humans; Male; Reproducibility of Results; Television; Video Recording; African; Article; data base; facial recognition; forensic science; human; image quality; male; morphology; photography; factual database; reproducibility; television; videorecording},
	correspondence_address = {N. Bacci; Human Variation and Identification Research Unit (HVIRU), School of Anatomical Sciences, University of the Witwatersrand, Johannesburg, Gauteng, 2193, South Africa; email: nicholasbacci@gmail.com},
	publisher = {F1000 Research Ltd},
	issn = {20461402},
	pmid = {33815766},
	language = {English},
	abbrev_source_title = {F1000 Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Wright20202160,
	author = {Wright, Steven A.},
	title = {AI in the Law: Towards Assessing Ethical Risks},
	year = {2020},
	journal = {Proceedings - 2020 IEEE International Conference on Big Data, Big Data 2020},
	pages = {2160 – 2169},
	doi = {10.1109/BigData50022.2020.9377950},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85103842801&doi=10.1109%2fBigData50022.2020.9377950&partnerID=40&md5=ad6a379d6a6bb7b60ee110193497911d},
	affiliations = {Georgia State University, College of Law, Atlanta, United States},
	abstract = {The exponential growth in data over the past decade has impacted the legal industry; both requiring automated solutions for the cost effective and efficient management of the volume and variety of big (legal) data; and, enabling artificial intelligence techniques based on machine learning for the analysis of that data. While many legal practitioners focus on specific services niches, the impact of AI in the law is much broader than individual niches. While AI systems and concerns for their ethical operation are not new, the scale of impact and adoption of AI systems in legal practice makes consideration of the ethics of these systems timely. While there has been recent progress in development of ethical guidelines for AI systems, much of this is targeted at the developers of these systems in general, or the actions of these AI systems as autonomous entities, rather than in the legal practice context. Much of the ethical guidance - whether for AI systems or legal professional is captured in high level principles within more narrowly defined domains, more specific guidance may be appropriate to identify and assess ethical risks. As adoption and operation of AI software in routine legal practice becomes more commonplace, more detailed guidance on assessing the scope and scale of ethical risks is needed. © 2020 IEEE.},
	author_keywords = {AI; Assessment; Ethics; Law},
	keywords = {Big data; Cost effectiveness; Philosophical aspects; Risk assessment; Artificial intelligence techniques; Automated solutions; Autonomous entities; Cost effective; Efficient managements; Exponential growth; On-machines; Recent progress; Artificial intelligence},
	correspondence_address = {S.A. Wright; Georgia State University, College of Law, Atlanta, United States; email: swright22@gsu.edu},
	editor = {Wu X. and Jermaine C. and Xiong L. and Hu X.T. and Kotevska O. and Lu S. and Xu W. and Aluru S. and Zhai C. and Al-Masri E. and Chen Z. and Saltz J.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816251-5},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Big Data, Big Data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 8th IEEE International Conference on Big Data, Big Data 2020; Conference date: 10 December 2020 through 13 December 2020; Conference code: 168025}
}

@ARTICLE{Fleming2021181,
	author = {Fleming, Megan N.},
	title = {Considerations for the ethical implementation of psychological assessment through social media via machine learning},
	year = {2021},
	journal = {Ethics and Behavior},
	volume = {31},
	number = {3},
	pages = {181 – 192},
	doi = {10.1080/10508422.2020.1817026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090449224&doi=10.1080%2f10508422.2020.1817026&partnerID=40&md5=87079099d8746356c2f2e57bba40227e},
	affiliations = {Department of Psychological Sciences, University of Missouri, United States},
	abstract = {The ubiquity of social media usage has led to exciting new technologies such as machine learning. Machine learning is poised to change many fields of health, including psychology. The wealth of information provided by each social media user in combination with machine-learning technologies may pave the way for automated psychological assessment and diagnosis. Assessment of individuals’ social media profiles using machine-learning technologies for diagnosis and screening confers many benefits (i.e., time and cost efficiency, reduced recall bias, information about an individual’s emotions and functioning spanning months or years, etc.); however, the implementation of these technologies will pose unique challenges to the professional ethics of psychology. Namely, psychologists must understand the impact of these assessment technologies on privacy and confidentiality, informed consent, recordkeeping, bases for assessments, and diversity and justice. This paper offers a brief review of the current applications of machine-learning technologies in psychology and public health, provides an overview of potential implementations in clinical settings, and introduces ethical considerations for professional psychologists. This paper presents considerations which may aid in the extension of the current Ethical Principles of Psychologists and Code of Conduct to address these important technological advancements in the field of clinical psychology. © 2020 Taylor & Francis Group, LLC.},
	author_keywords = {Automated assessment; ethical principles of psychologists; machine learning in psychology; psychology; social media},
	keywords = {adult; article; clinical psychology; confidentiality; female; human; human experiment; informed consent; justice; machine learning; male; privacy; psychologic assessment; public health; recall bias; social media},
	correspondence_address = {M.N. Fleming; Department of Psychological Sciences, University of Missouri, Columbia, 65203, United States; email: mnf8t6@mail.missouri.edu},
	publisher = {Routledge},
	issn = {10508422},
	language = {English},
	abbrev_source_title = {Ethics Behav.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Nanetti2021,
	author = {Nanetti, Andrea},
	title = {Defining Heritage Science: A Consilience Pathway to Treasuring the Complexity of Inheritable Human Experiences through Historical Method, AI, and ML},
	year = {2021},
	journal = {Complexity},
	volume = {2021},
	doi = {10.1155/2021/4703820},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101919974&doi=10.1155%2f2021%2f4703820&partnerID=40&md5=fceda71679aaa01c381e4c6403c44245},
	affiliations = {Nanyang Technological University, Singapore, Singapore},
	abstract = {Societies have always used their heritage to remain resilient and to express their cultural identities. Today, all the still-available experiences accrued by human societies over time and across space are, in principle, essential in coping with the twenty-first century grand challenges of humanity (refer to the 17 UN Sustainable Development Goals). Artificial intelligence and machine learning algorithms can assist the next generation of historians, heritage stakeholders, and decision-makers in (1) decoding unstructured knowledge and wisdom embedded in selected cultural artefacts and social rituals, (2) encoding data in machine-readable systems, (3) aggregating information according to the user's needs in real time, and (4) simulating the consequences of either erasing, neglecting, putting in latency, or preserving and sharing specific human experiences. What our global society needs is a multilingual and transcultural approach to decode-encode the treasure of human experience and transmit it to the next generation of world citizens. This approach can be the pathway to work on a new science of heritage, its ethics, and empathy.  © 2021 Andrea Nanetti.},
	keywords = {Decision making; Decoding; Embedded systems; Encoding (symbols); Learning algorithms; Real time systems; Time sharing systems; Cultural identity; Decision makers; Encoding data; Global society; Grand Challenge; Historical methods; Human society; User's needs; Machine learning},
	correspondence_address = {A. Nanetti; Nanyang Technological University, Singapore, Singapore; email: nanetti.andrea@gmail.com},
	publisher = {Hindawi Limited},
	issn = {10762787},
	language = {English},
	abbrev_source_title = {Complexity},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{O'Reilly-Shah2020843,
	author = {O'Reilly-Shah, Vikas N. and Gentry, Katherine R. and Walters, Andrew M. and Zivot, Joel and Anderson, Corrie T. and Tighe, Patrick J.},
	title = {Bias and ethical considerations in machine learning and the automation of perioperative risk assessment},
	year = {2020},
	journal = {British Journal of Anaesthesia},
	volume = {125},
	number = {6},
	pages = {843 – 846},
	doi = {10.1016/j.bja.2020.07.040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089668538&doi=10.1016%2fj.bja.2020.07.040&partnerID=40&md5=45bacad5c6e4b50ae33499c79f36e474},
	affiliations = {Department of Anesthesiology and Pain Medicine, University of Washington School of Medicine, Seattle, WA, United States; Department of Anesthesiology and Pain Medicine, Seattle Children's Hospital, Seattle, WA, United States; Department of Anesthesiology, Emory University, Atlanta, GA, United States; Department of Anesthesiology, University of Florida, Gainesville, FL, United States},
	author_keywords = {artificial intelligence; gender bias; healthcare inequality; machine learning; perioperative medicine; racial bias; risk prediction},
	keywords = {Anesthesiology; Automation; Bias; Humans; Machine Learning; Perioperative Care; Risk Assessment; automation; Editorial; machine learning; medical ethics; perioperative period; priority journal; risk assessment; statistical bias; anesthesiology; automation; ethics; human; machine learning; perioperative period; procedures; risk assessment; statistical bias},
	correspondence_address = {V.N. O'Reilly-Shah; Department of Anesthesiology and Pain Medicine, University of Washington School of Medicine, Seattle, United States; email: voreill@uw.edu},
	publisher = {Elsevier Ltd},
	issn = {00070912},
	coden = {BJANA},
	pmid = {32838979},
	language = {English},
	abbrev_source_title = {Br. J. Anaesth.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Green Open Access}
}

@ARTICLE{Boers202026,
	author = {Boers, Sarah N. and Jongsma, Karin R. and Lucivero, Federica and Aardoom, Jiska and Büchner, Frederike L. and de Vries, Martine and Honkoop, Persijn and Houwink, Elisa J. F. and Kasteleyn, Marise J. and Meijer, Eline and Pinnock, Hilary and Teichert, Martina and van der Boog, Paul and van Luenen, Sanne and van der Kleij, Rianne M. J. J. and Chavannes, Niels H.},
	title = {SERIES: eHealth in primary care. Part 2: Exploring the ethical implications of its application in primary care practice},
	year = {2020},
	journal = {European Journal of General Practice},
	volume = {26},
	number = {1},
	pages = {26 – 32},
	doi = {10.1080/13814788.2019.1678958},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074912060&doi=10.1080%2f13814788.2019.1678958&partnerID=40&md5=941b74733b49f86ead45ab7dc7eab6ca},
	affiliations = {Julius Centre for Health Sciences and Primary Care, Department of Medical Humanities, University Medical Centre Utrecht, Utrecht, Netherlands; Ethox and Wellcome Centre for Ethics and Humanities, Nuffield Department of Population Health, University of Oxford, Oxford, United Kingdom; Department of Public Health and Primary Care, Leiden University Medical Centre, Leiden, Netherlands; National eHealth Living Lab (NELL), Leiden, Netherlands; Department of Medical Ethics and Health Law, Leiden University Medical Centre, Leiden, Netherlands; Biomedical Data Sciences, Leiden University Medical Centre, Leiden, Netherlands; Usher Institute of Population Health Sciences and Informatics, University of Edinburgh, Edinburgh, United Kingdom; Department of Clinical Pharmacy & Toxicology, Leiden University Medical Centre, Leiden, Netherlands; Department of Nephrology, Leiden University Medical Centre, Leiden, Netherlands},
	abstract = {Background: eHealth promises to increase self-management and personalised medicine and improve cost-effectiveness in primary care. Paired with these promises are ethical implications, as eHealth will affect patients’ and primary care professionals’ (PCPs) experiences, values, norms, and relationships. Objectives: We argue what ethical implications related to the impact of eHealth on four vital aspects of primary care could (and should) be anticipated. Discussion: (1) EHealth influences dealing with predictive and diagnostic uncertainty. Machine-learning based clinical decision support systems offer (seemingly) objective, quantified, and personalised outcomes. However, they also introduce new loci of uncertainty and subjectivity. The decision-making process becomes opaque, and algorithms can be invalid, biased, or even discriminatory. This has implications for professional responsibilities and judgments, justice, autonomy, and trust. (2) EHealth affects the roles and responsibilities of patients because it can stimulate self-management and autonomy. However, autonomy can also be compromised, e.g. in cases of persuasive technologies and eHealth can increase existing health disparities. (3) The delegation of tasks to a network of technologies and stakeholders requires attention for responsibility gaps and new responsibilities. (4) The triangulate relationship: patient–eHealth–PCP requires a reconsideration of the role of human interaction and ‘humanness’ in primary care as well as of shaping Shared Decision Making. Conclusion: Our analysis is an essential first step towards setting up a dedicated ethics research agenda that should be examined in parallel to the development and implementation of eHealth. The ultimate goal is to inspire the development of practice-specific ethical recommendations. © 2019, © 2019 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {digital health; doctor–patient relationship; eHealth; ethics; primary care},
	keywords = {Decision Making, Shared; Decision Support Systems, Clinical; Humans; Machine Learning; Personal Autonomy; Persuasive Communication; Physician's Role; Physician-Patient Relations; Precision Medicine; Primary Health Care; Role; Self-Management; Telemedicine; adult; article; attention; clinical decision support system; cost effectiveness analysis; ethics; health disparity; human; justice; machine learning; outcome assessment; personalized medicine; primary medical care; responsibility; self care; shared decision making; telehealth; trust; uncertainty; doctor patient relationship; personal autonomy; persuasive communication; physician attitude; primary health care; role playing; telemedicine},
	correspondence_address = {S.N. Boers; Julius Centre for Health Sciences and Primary Care, Department of Medical Humanities, UMC Utrecht, Utrecht, Internal mail no Str. 6. 131, P.O. Box 85500, 3508, Netherlands; email: s.n.boers@umcutrecht.nl},
	publisher = {Taylor and Francis Ltd},
	issn = {13814788},
	coden = {EJGPF},
	pmid = {31663394},
	language = {English},
	abbrev_source_title = {Eur. J. Gen. Pract.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Castelvecchi202112,
	author = {Castelvecchi, Davide},
	title = {Prestigious AI meeting takes steps to improve ethics of research},
	year = {2021},
	journal = {Nature},
	volume = {589},
	number = {7840},
	pages = {12 – 13},
	doi = {10.1038/d41586-020-03611-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099427537&doi=10.1038%2fd41586-020-03611-8&partnerID=40&md5=7ec7b968abb0006267c29017b63f21bf},
	author_keywords = {Ethics; Machine learning; Technology},
	keywords = {Artificial Intelligence; Congresses as Topic; Ethics Committees; Ethics, Research; Female; Humans; Machine Learning; Male; Peer Review, Research; Racism; Sexism; Social Change; artificial intelligence; ethics; female; human; machine learning; male; organization; peer review; prevention and control; professional standard; racism; research ethics; sexism; social change},
	publisher = {NLM (Medline)},
	issn = {14764687},
	pmid = {33361804},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@ARTICLE{Shouval2021239,
	author = {Shouval, Roni and Fein, Joshua A. and Savani, Bipin and Mohty, Mohamad and Nagler, Arnon},
	title = {Machine learning and artificial intelligence in haematology},
	year = {2021},
	journal = {British Journal of Haematology},
	volume = {192},
	number = {2},
	pages = {239 – 250},
	doi = {10.1111/bjh.16915},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087159991&doi=10.1111%2fbjh.16915&partnerID=40&md5=c4b43a26a18199d12b94339eeb2c425b},
	affiliations = {Adult Bone Marrow Transplant Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, NY, United States; Hematology and Bone Marrow Transplantation Division, Chaim Sheba Medical Center, Tel-Hashomer, Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel; University of Connecticut Medical Center, Farmington, CT, United States; Division of Hematology-Oncology, Department of Medicine, Vanderbilt University Medical Center, Nashville, TN, United States; European Society for Blood and Marrow Transplantation Paris Study Office/CEREST-TC, Paris, France; Service d'Hématologie Clinique et de Thérapie Cellulaire, Hôpital Saint Antoine, AP-HP, Paris, France},
	abstract = {Digitalization of the medical record and integration of genomic methods into clinical practice have resulted in an unprecedented wealth of data. Machine learning is a subdomain of artificial intelligence that attempts to computationally extract meaningful insights from complex data structures. Applications of machine learning in haematological scenarios are steadily increasing. However, basic concepts are often unfamiliar to clinicians and investigators. The purpose of this review is to provide readers with tools to interpret and critically appraise machine learning literature. We begin with the elucidation of standard terminology and then review examples in haematology. Guidelines for designing and evaluating machine-learning studies are provided. Finally, we discuss limitations of the machine-learning approach. © 2020 British Society for Haematology and John Wiley & Sons Ltd},
	author_keywords = {artificial intelligence; haematology; leukaemia; machine learning; prediction models},
	keywords = {Computational Biology; Hematology; Humans; Machine Learning; Medical Records; acute graft versus host disease; acute leukemia; acute myeloid leukemia; allogeneic hematopoietic stem cell transplantation; artificial intelligence; artificial neural network; Burkitt lymphoma; chronic lymphatic leukemia; convolutional neural network; data mining; data processing; decision tree; deep learning; diagnostic accuracy; diffuse large B cell lymphoma; discriminant analysis; facial recognition; hematologic malignancy; hematology; human; k nearest neighbor; logistic regression analysis; machine learning; medical ethics; minimal residual disease; mortality; multilayer perceptron; myelodysplastic syndrome; myeloid metaplasia; practice guideline; prediction; priority journal; prognosis; random forest; reinforcement learning (machine learning); reproducibility; Review; sickle cell anemia; supervised machine learning; support vector machine; treatment outcome; tumor differentiation; unsupervised machine learning; biology; hematology; medical record; procedures},
	correspondence_address = {R. Shouval; Adult Bone Marrow Transplant Service, Department of Medicine, Memorial Sloan Kettering Cancer Center, New York, United States; email: shouval@gmail.com; R. Shouval; Hematology and Bone Marrow Transplantation Division, Chaim Sheba Medical Center, Tel-Hashomer, Sackler School of Medicine, Tel Aviv University, Tel Aviv, Israel; email: shouval@gmail.com},
	publisher = {Blackwell Publishing Ltd},
	issn = {00071048},
	coden = {BJHEA},
	pmid = {32602593},
	language = {English},
	abbrev_source_title = {Br. J. Haematol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Brown2021,
	author = {Brown, Shea and Davidovic, Jovana and Hasan, Ali},
	title = {The algorithm audit: Scoring the algorithms that score us},
	year = {2021},
	journal = {Big Data and Society},
	volume = {8},
	number = {1},
	doi = {10.1177/2053951720983865},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100535118&doi=10.1177%2f2053951720983865&partnerID=40&md5=b1c1bffd6120f40882de599356575f70},
	affiliations = {Department of Physics Astronomy, University of Iowa, Iowa City, IA, United States; BABL AI Research, Iowa City, IA, United States; Department of Philosophy, University of Iowa, Iowa City, IA, United States},
	abstract = {In recent years, the ethical impact of AI has been increasingly scrutinized, with public scandals emerging over biased outcomes, lack of transparency, and the misuse of data. This has led to a growing mistrust of AI and increased calls for mandated ethical audits of algorithms. Current proposals for ethical assessment of algorithms are either too high level to be put into practice without further guidance, or they focus on very specific and technical notions of fairness or transparency that do not consider multiple stakeholders or the broader social context. In this article, we present an auditing framework to guide the ethical assessment of an algorithm. The audit instrument itself is comprised of three elements: a list of possible interests of stakeholders affected by the algorithm, an assessment of metrics that describe key ethically salient features of the algorithm, and a relevancy matrix that connects the assessed metrics to stakeholder interests. The proposed audit instrument yields an ethical evaluation of an algorithm that could be used by regulators and others interested in doing due diligence, while paying careful attention to the complex societal context within which the algorithm is deployed. © The Author(s) 2021.},
	author_keywords = {Algorithm audits; algorithm ethics; ethics; ethics of AI; machine learning; machine learning and ethics},
	correspondence_address = {J. Davidovic; BABL AI Research, Iowa City, United States; email: jovana-davidovic@uiowa.edu; J. Davidovic; Department of Philosophy, University of Iowa, Iowa City, United States; email: jovana-davidovic@uiowa.edu},
	publisher = {SAGE Publications Ltd},
	issn = {20539517},
	language = {English},
	abbrev_source_title = {Big Data  Soc.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 59; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kolanska2021,
	author = {Kolanska, Kamila and Chabbert-Buffet, Nathalie and Daraï, Emile and Antoine, Jean-Marie},
	title = {Artificial intelligence in medicine: A matter of joy or concern?},
	year = {2021},
	journal = {Journal of Gynecology Obstetrics and Human Reproduction},
	volume = {50},
	number = {1},
	doi = {10.1016/j.jogoh.2020.101962},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095766568&doi=10.1016%2fj.jogoh.2020.101962&partnerID=40&md5=728651e3530923da9c8321729ba06d99},
	affiliations = {Service de Gynécologie Obstétrique et Médecine de la Reproduction, AP-HP Sorbonne Université site Tenon, 4 rue de la Chine, Paris, 75020, France},
	abstract = {Artificial Intelligence (AI), a concept which dates back to the 1950s, is increasingly being developed by many medical specialties, especially those based on imaging or surgery. While the cognitive component of AI is far superior to that of human intelligence, it lacks consciousness, feelings, intuition and adaptation to unexpected situations. Furthermore, fundamental questions arise with regard to data security, the impact on healthcare professions, and the distribution of roles between physicians and AI especially concerning consent to medical care and liability in the event of a therapeutic accident. © 2020 Elsevier Masson SAS},
	author_keywords = {Algorithm; Artificial intelligence; Deep learning; Machine learning},
	keywords = {Artificial Intelligence; Humans; Medicine; artificial intelligence; computer security; consciousness; deep learning; human; human experiment; intuition; medical care; occupation; physician; review; therapeutic error; artificial intelligence; ethics; medicine},
	correspondence_address = {J.-M. Antoine; Assistance Publique - Hôpitaux de Paris, Hôpital Tenon, Service de Gynécologie Obstétrique et médecine de la Reproduction, Paris, 4 rue de la Chine, 75020, France; email: jean-marie.antoine@aphp.fr},
	publisher = {Elsevier Masson s.r.l.},
	issn = {24687847},
	pmid = {33148398},
	language = {English},
	abbrev_source_title = {J. Gynecol. Obstet. Hum. Reprod.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Bronze Open Access}
}

@ARTICLE{Milano2020957,
	author = {Milano, Silvia and Taddeo, Mariarosaria and Floridi, Luciano},
	title = {Recommender systems and their ethical challenges},
	year = {2020},
	journal = {AI and Society},
	volume = {35},
	number = {4},
	pages = {957 – 967},
	doi = {10.1007/s00146-020-00950-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080068526&doi=10.1007%2fs00146-020-00950-y&partnerID=40&md5=645ddb778b1e6fea54c27a692c804b09},
	affiliations = {Oxford Internet Institute, University of Oxford, 1 St Giles, Oxford, OX1 3JS, United Kingdom; The Alan Turing Institute, 96 Euston Road, London, NW1 2DB, United Kingdom},
	abstract = {This article presents the first, systematic analysis of the ethical challenges posed by recommender systems through a literature review. The article identifies six areas of concern, and maps them onto a proposed taxonomy of different kinds of ethical impact. The analysis uncovers a gap in the literature: currently user-centred approaches do not consider the interests of a variety of other stakeholders—as opposed to just the receivers of a recommendation—in assessing the ethical impacts of a recommender system. © 2020, The Author(s).},
	author_keywords = {Algorithms; Artificial intelligence; Digital ethics; Ethical trade-offs; Ethics of recommendation; Machine learning; Recommender systems},
	keywords = {Algorithms; Artificial intelligence; Economic and social effects; Learning systems; Machine learning; Recommender systems; Areas of concerns; Digital ethics; Literature reviews; Systematic analysis; Trade off; User-centred; Philosophical aspects},
	correspondence_address = {S. Milano; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles, OX1 3JS, United Kingdom; email: silvia.milano@oii.ox.ac.uk},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 109; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Dengel2021203,
	author = {Dengel, Andreas and Devillers, Laurence and Schaal, Laura Maria},
	title = {Augmented Human and Human-Machine Co-evolution: Efficiency and Ethics},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12600 LNCS},
	pages = {203 – 227},
	doi = {10.1007/978-3-030-69128-8_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100979759&doi=10.1007%2f978-3-030-69128-8_13&partnerID=40&md5=8cbf91187f3712a6597fae786d5c6ec9},
	affiliations = {DFKI, Kaiserslautern, Germany; University of Kaiserslautern, Kaiserslautern, Germany; Sorbonne-University, Limsi-DATAIA Institute (Saclay), Paris, France},
	abstract = {Capability and expected potential of AI-based computer solutions increased significantly in the recent years, mainly due to progress in machine learning technologies and available data. Growing effectiveness in reasoning, knowledge representation, automatic training via machine learning, and especially in computer vision and speech technology result in AI systems becoming an ever-better communication and work partner of their human counterparts. Deeply embedded in the every-day context of work and leisure, AI systems can act as competent dialog partners and powerful work assistants. Furthermore, they increasingly help humans to better acquire new insights, process and apply situation-specific instructions, receive improved training and learn new knowledge more effectively. Ultimately, intelligent systems exhibit the potential to become inseparable partners of humans or – in case e.g. of prosthesis solutions and innovative sensor technology – even become part of the human body. Such close mental and physical interconnection between human and AI system raises new concerns and ethical questions which need to be considered not only by computer scientists, but ask for interdisciplinary work and social discourse. This paper outlines the different levels of human-computer integration, gives examples of the innovative potential in work assistance and learning support, and sketches ethical and moral issues conjoined with such progress. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Co-adaption; Co-creation; Co-learning},
	keywords = {Embedded systems; Intelligent systems; Machine learning; Philosophical aspects; Speech communication; Automatic training; Computer integration; Computer scientists; Computer solution; Interdisciplinary work; Machine learning technology; Sensor technologies; Specific instruction; Knowledge representation},
	correspondence_address = {A. Dengel; DFKI, Kaiserslautern, Germany; email: andreas.dengel@dfki.de},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Nadeem2021259,
	author = {Nadeem, Ayesha and Marjanovic, Olivera and Abedin, Babak},
	title = {Gender Bias in AI: Implications for Managerial Practices},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12896 LNCS},
	pages = {259 – 270},
	doi = {10.1007/978-3-030-85447-8_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115159571&doi=10.1007%2f978-3-030-85447-8_23&partnerID=40&md5=f3da739363fd7ffbe78c59bd7c243485},
	affiliations = {University of Technology Sydney, Sydney, NSW, Australia; Macquarie University, Sydney, NSW, Australia},
	abstract = {Artificial intelligence (AI) applications are widely employed nowadays in almost every industry impacting individuals and society. As many important decisions are now being automated by various AI applications, fairness is fast becoming a vital concern in AI. Moreover, the organizational applications of AI-enabled decision systems have exacerbated this problem by amplifying the pre-existing societal bias and creating new types of biases. Interestingly, the related literature and industry press suggest that AI systems are often biased towards gender. Specifically, AI hiring tools are often biased towards women. Therefore, it is an increasing concern to reconsider the organizational managerial practices for AI-enabled decision systems to bring fairness in decision making. Additionally, organizations should develop fair, ethical internal structures and corporate strategies and governance to manage the gender imbalance in AI recruitment process. Thus, by systematically reviewing and synthesizing the literature, this paper presents a comprehensive overview of the managerial practices taken in relation to gender bias in AI. Our findings indicate that managerial practices include: better fairness governance practices, continuous training on fairness and ethics for all stakeholders, collaborative organizational learning on fairness & demographic characteristics, interdisciplinary approach & understanding of AI ethical principles, Workplace diversity in managerial roles, designing strategies for incorporating algorithmic transparency and accountability & ensuring human in the loop. In this paper, we aim to contribute to the emerging IS literature on AI by presenting a consolidated picture and understanding of this phenomenon. Based on our findings, we indicate direction for future research in IS for the better development and use of AI systems. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {Analytics; Artificial Intelligence; Fairness; Gender; Machine learning},
	keywords = {Behavioral research; Decision making; Electronic commerce; Industrial management; Managers; Personnel training; Philosophical aspects; Applications of AI; Corporate strategies; Demographic characteristics; Ethical principles; Internal structure; Managerial practices; Organizational learning; Recruitment process; Artificial intelligence},
	correspondence_address = {A. Nadeem; University of Technology Sydney, Sydney, Australia; email: Ayesha.Nadeem@student.uts.edu.au},
	editor = {Dennehy D. and Griva A. and Pouloudi N. and Dwivedi Y.K. and Dwivedi Y.K. and Pappas I. and Pappas I. and Mantymaki M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303085446-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 264489}
}

@ARTICLE{Hill2021,
	author = {Hill, Adele and Joyner, Christopher H. and Keith-Jopp, Chloe and Yet, Barbaros and Sakar, Ceren Tuncer and Marsh, William and Morrissey, Dylan},
	title = {A bayesian network decision support tool for low back pain using a RAND appropriateness procedure: proposal and internal pilot study},
	year = {2021},
	journal = {JMIR Research Protocols},
	volume = {10},
	number = {1},
	doi = {10.2196/21804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100308934&doi=10.2196%2f21804&partnerID=40&md5=148a61bbf63679dedf00716ec040cbf6},
	affiliations = {Sport and Exercise Medicine, Queen Mary University of London, London, United Kingdom; Electronics, Engineering and Computer Science, Queen Mary University of London, London, United Kingdom; Barts Health NHS Trust, London, United Kingdom; Graduate School of Informatics, Middle East Technical University, Ankara, Turkey; Department of Industrial Engineering, Hacettepe University, Ankara, Turkey},
	abstract = {Background: Low back pain (LBP) is an increasingly burdensome condition for patients and health professionals alike, with consistent demonstration of increasing persistent pain and disability. Previous decision support tools for LBP management have focused on a subset of factors owing to time constraints and ease of use for the clinician. With the explosion of interest in machine learning tools and the commitment from Western governments to introduce this technology, there are opportunities to develop intelligent decision support tools. We will do this for LBP using a Bayesian network, which will entail constructing a clinical reasoning model elicited from experts. Objective: This paper proposes a method for conducting a modified RAND appropriateness procedure to elicit the knowledge required to construct a Bayesian network from a group of domain experts in LBP, and reports the lessons learned from the internal pilot of the procedure. Methods: We propose to recruit expert clinicians with a special interest in LBP from across a range of medical specialties, such as orthopedics, rheumatology, and sports medicine. The procedure will consist of four stages. Stage 1 is an online elicitation of variables to be considered by the model, followed by a face-to-face workshop. Stage 2 is an online elicitation of the structure of the model, followed by a face-to-face workshop. Stage 3 consists of an online phase to elicit probabilities to populate the Bayesian network. Stage 4 is a rudimentary validation of the Bayesian network. Results: Ethical approval has been obtained from the Research Ethics Committee at Queen Mary University of London. An internal pilot of the procedure has been run with clinical colleagues from the research team. This showed that an alternating process of three remote activities and two in-person meetings was required to complete the elicitation without overburdening participants. Lessons learned have included the need for a bespoke online elicitation tool to run between face-to-face meetings and for careful operational definition of descriptive terms, even if widely clinically used. Further, tools are required to remotely deliver training about self-identification of various forms of cognitive bias and explain the underlying principles of a Bayesian network. The use of the internal pilot was recognized as being a methodological necessity. Conclusions: We have proposed a method to construct Bayesian networks that are representative of expert clinical reasoning for a musculoskeletal condition in this case. We have tested the method with an internal pilot to refine the process prior to deployment, which indicates the process can be successful. The internal pilot has also revealed the software support requirements for the elicitation process to model clinical reasoning for a range of conditions. ©Adele Hill, Christopher H Joyner, Chloe Keith-Jopp, Barbaros Yet, Ceren Tuncer Sakar, William Marsh, Dylan Morrissey.},
	author_keywords = {Back pain; Bayesian methods; Consensus; Decision making},
	correspondence_address = {A. Hill; Sport and Exercise Medicine, Queen Mary University of London, London, Mile End Road, E1 4NS, United Kingdom; email: a.hill@smd18.qmul.ac.uk},
	publisher = {JMIR Publications Inc.},
	issn = {19290748},
	language = {English},
	abbrev_source_title = {JMIR Res. Prot.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Dessì202157,
	author = {Dessì, Danilo and Käser, Tanja and Marras, Mirko and Popescu, Elvira and Sack, Harald},
	title = {Designing intelligent systems for online education: Open challenges and future directions},
	year = {2021},
	journal = {CEUR Workshop Proceedings},
	volume = {2876},
	pages = {57 – 64},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108023544&partnerID=40&md5=6b55831194c48db2ecd513c7b6529069},
	affiliations = {Epfl, Switzerland; Fiz Karlsruhe - Leibniz Institute for Information Infrastructure, Germany; Karlsruhe Institute of Technology, Institute Aifb, Germany; University of Craiova, Romania},
	abstract = {The design and delivering of platforms for online education is fostering increasingly intense research. Scaling up education online brings new emerging needs related with hardly manageable classes, overwhelming content alternatives, and academic dishonesty while interacting remotely, as examples. However, with the impressive progress of the data mining and machine learning fields, combined with the large amounts of learning-related data and high-performance computing, it has been possible to gain a deeper understanding of the nature of learning and teaching online. Methods at the analytical and algorithmic levels are constantly being developed and hybrid approaches are receiving an increasing attention. Recent methods are analyzing not only the online traces left by students a posteriori, but also the extent to which this data can be turned into actionable insights and models, to support the above needs in a computationally efficient, adaptive and timely way. In this paper, we present relevant open challenges lying at the intersection between the machine learning and educational communities, that need to be addressed to further develop the field of intelligent systems for online education. Several areas of research in this field are identified, such as data availability and sharing, time-wise and multi-modal data modelling, generalizability, fairness, explainability, interpretability, privacy, and ethics behind models delivered for supporting education. Practical challenges and recommendations for possible research directions are provided for each of them, paving the way for future advances in this field. © 2021 CEUR-WS. All rights reserved.},
	author_keywords = {Data Mining; E-Learning; Education; Learning Analytics; Machine Learning; MOOC; Online Courses},
	keywords = {Data mining; Education computing; Intelligent systems; Machine learning; Modal analysis; Online systems; Privacy by design; Academic dishonesty; Algorithmic levels; Computationally efficient; Data availability; Educational community; High performance computing; Learning and teachings; On-line education; E-learning},
	editor = {Dessi D. and Dessi D. and Kaser T. and Marras M. and Sack H. and Sack H.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Workshop on Enabling Data-Driven Decisions from Learning on the Web, L2D 2021; Conference date: 12 March 2021; Conference code: 169453}
}

@ARTICLE{Dinnar202165,
	author = {Dinnar, Samuel “Mooly” and Dede, Chris and Johnson, Emmanuel and Straub, Carrie and Korjus, Kristjan},
	title = {Artificial Intelligence and Technology in Teaching Negotiation},
	year = {2021},
	journal = {Negotiation Journal},
	volume = {37},
	number = {1},
	pages = {65 – 82},
	doi = {10.1111/nejo.12351},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099275316&doi=10.1111%2fnejo.12351&partnerID=40&md5=06724b2391ed248153f3cce801b54c91},
	affiliations = {Samuel, Harvard Law School, Massachusetts Institute of Technology (MIT), United States; Harvard’s Graduate School of Education, United States; University of Southern California, United States; Mursion, Inc., South Africa; University of Tartu, Estonia},
	abstract = {Artificial intelligence (AI), machine learning (ML), affective computing, and big-data techniques are improving the ways that humans negotiate and learn to negotiate. These technologies, long deployed in industry and academic research, are now being adopted for educational use. We describe several systems that help human negotiators evaluate and learn from role-play simulations as well as applications that help human instructors teach negotiators at the individual, team, and organizational levels. AI can enable the personalization of negotiation instruction, taking into consideration factors such as culture and bias. These tools will enable improvements not only in the teaching of negotiation, but also in teaching humans how to program and collaborate with technology-based negotiation systems, including avatars and computer-controlled negotiation agents. These advances will provide theoretical and practical insights, require serious consideration of ethical issues, and revolutionize the way we practice and teach negotiation. © 2021 President and Fellows of Harvard College},
	author_keywords = {affective computing; AI; artificial intelligence; avatars; computer-controlled negotiation agents; ethics; machine learning; negotiation; teaching},
	correspondence_address = {S.M. Dinnar; Samuel, Harvard Law School, Massachusetts Institute of Technology (MIT), United States; email: sdinnar@meedance.com},
	publisher = {Blackwell Publishing Ltd},
	issn = {07484526},
	language = {English},
	abbrev_source_title = {Negot. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Groepenhoff2020,
	author = {Groepenhoff, Floor and Eikendal, Anouk L M and Bots, Sophie Heleen and Van Ommen, Anne-Mar and Overmars, L.M. and Kapteijn, Daniek and Pasterkamp, Gerard and Reiber, Johan H C and Hautemann, David and Menken, Roxana and Wittekoek, Marianne E and Hofstra, Leonard and Onland-Moret, N Charlotte and Haitjema, Saskia and Hoefer, Imo and Leiner, Tim and Den Ruijter, Hester M},
	title = {Cardiovascular imaging of women and men visiting the outpatient clinic with chest pain or discomfort: Design and rationale of the ARGUS Study},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {12},
	doi = {10.1136/bmjopen-2020-040712},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097912765&doi=10.1136%2fbmjopen-2020-040712&partnerID=40&md5=db5e87feb43e37c4905672a1ef0513d5},
	affiliations = {Central Diagnostic Laboratory, University Medical Center Utrecht, Utrecht, Netherlands; Laboratory of Experimental Cardiology, University Medical Center Utrecht, Utrecht, Netherlands; Medical Imaging Systems BV, MEDIS, Leiden, Netherlands; Cardiology, Cardiology Centers Netherlands, Utrecht, Netherlands; Cardiology, HeartLife Clinics, Utrecht, Netherlands; Department of Epidemiology, Julius Center for Health Sciences and Primary Care, Utrecht, Netherlands; Radiology, University Medical Centre Utrecht, Utrecht University, Utrecht, Netherlands},
	abstract = {Introduction Chest pain or discomfort affects 20%-40% of the general population over the course of their life and may be a symptom of myocardial ischaemia. For the diagnosis of obstructive macrovascular coronary artery disease (CAD), algorithms have been developed; however, these do not exclude microvascular angina. This may lead to false reassurance of symptomatic patients, mainly women, with functionally significant, yet non-obstructive coronary vascular disease. Therefore, this study aims to estimate the prevalence of both macrovascular and microvascular coronary vascular disease in women and men presenting with chest pain or discomfort, and to subsequently develop a decision-support tool to aid cardiologists in referral to cardiovascular imaging for both macrovascular and microvascular CAD evaluation. Methods and analysis Women and men with chest pain or discomfort, aged 45 years and older, without a history of cardiovascular disease, who are referred to an outpatient cardiology clinic by their general practitioner are eligible for inclusion. Coronary CT angiography is used for anatomical imaging. Additionally, myocardial perfusion imaging by adenosine stress cardiac MRI is performed to detect functionally significant coronary vascular disease. Electronic health record data, collected during regular cardiac work-up, including medical history, cardiovascular risk factors, physical examination, echocardiography, (exercise) ECG and blood samples for standard cardiovascular biomarkers and research purposes, are obtained. Participants will be classified as positive or negative for coronary vascular disease based on all available data by expert panel consensus (a cardiovascular radiologist and two cardiologists). After completion of the clinical study, all collected data will be used to develop a decision support tool using predictive modelling and machine-learning techniques. Ethics and dissemination The study protocol was approved by the Institutional Review Board of the University Medical Center Utrecht. Results will be disseminated through national and international conferences and in peer-reviewed journals in cardiovascular disease. Trial registration number Trialregister.nl Registry NL8702.  © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {cardiology; cardiovascular imaging; coronary heart disease},
	keywords = {Ambulatory Care Facilities; Chest Pain; Coronary Angiography; Coronary Artery Disease; Female; Humans; Male; Middle Aged; gadobutrol; adult; Article; cardiovascular magnetic resonance; cardiovascular risk; clinical trial; cohort analysis; computed tomographic angiography; controlled study; coronary artery disease; decision support system; echocardiography; electrocardiogram; electronic health record; exercise electrocardiography; female; health care; human; machine learning; major clinical study; male; medical history; middle aged; model; outpatient department; physical examination; prospective study; thorax pain; coronary angiography; coronary artery disease; diagnostic imaging; outpatient department; thorax pain},
	correspondence_address = {H.M. Den Ruijter; Laboratory of Experimental Cardiology, University Medical Center Utrecht, Utrecht, Netherlands; email: h.m.denRuijter-2@umcutrecht.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33323438},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{McCradden20202024,
	author = {McCradden, Melissa D. and Joshi, Shalmali and Anderson, James A. and Mazwi, Mjaye and Goldenberg, Anna and Shaul, Randi Zlotnik},
	title = {Patient safety and quality improvement: Ethical principles for a regulatory approach to bias in healthcare machine learning},
	year = {2020},
	journal = {Journal of the American Medical Informatics Association},
	volume = {27},
	number = {12},
	pages = {2024 – 2027},
	doi = {10.1093/jamia/ocaa085},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095511303&doi=10.1093%2fjamia%2focaa085&partnerID=40&md5=4275d6aae3c9c22b2fdab2038ec28d06},
	affiliations = {Bioethics Department, The Hospital for Sick Children, Toronto, ON, Canada; Vector Institute, Toronto, ON, Canada; Institute for Health Policy, Management and Evaluation, University of Toronto, Toronto, ON, Canada; Joint Centre for Bioethics, University of Toronto, Toronto, ON, Canada; Department of Critical Care Medicine, Hospital for Sick Children, Toronto, ON, Canada; Genetics and Genome Biology, Hospital for Sick Children, Peter Gilgan Centre for Research and Learning, Toronto, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; CIFAR, Toronto, ON, Canada; Department of Paediatrics, University of Toronto, Toronto, ON, Canada; Child Health Evaluative Sciences, The Hospital for Sick Children, Peter Gilgan Centre for Research, Toronto, ON, Canada},
	abstract = {Accumulating evidence demonstrates the impact of bias that reflects social inequality on the performance of machine learning (ML) models in health care. Given their intended placement within healthcare decision making more broadly, ML tools require attention to adequately quantify the impact of bias and reduce its potential to exacerbate inequalities. We suggest that taking a patient safety and quality improvement approach to bias can support the quantification of bias-related effects on ML. Drawing from the ethical principles underpinning these approaches, we argue that patient safety and quality improvement lenses support the quantification of relevant performance metrics, in order to minimize harm while promoting accountability, justice, and transparency. We identify specific methods for operationalizing these principles with the goal of attending to bias to support better decision making in light of controllable and uncontrollable factors. © The Author(s) 2020.},
	author_keywords = {Healthcare delivery; Machine learning; Patient safety; Quality improvement; Systematic bias},
	keywords = {Artificial Intelligence; Data Collection; Government Regulation; Healthcare Disparities; Humans; Patient Safety; Prejudice; Quality Improvement; Social Determinants of Health; adult; decision making; drawing; drug safety; health care delivery; human; justice; machine learning; patient safety; review; statistical bias; total quality management; artificial intelligence; ethics; government regulation; health care disparity; information processing; prejudice; social determinants of health},
	correspondence_address = {M.D. McCradden; Bioethics Department, Toronto, 525 University Ave, M5G 2L3, Canada; email: melissa.mccradden@sickkids.ca},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	pmid = {32585698},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; All Open Access, Green Open Access}
}

@ARTICLE{Albertetti202195,
	author = {Albertetti, Fabrizio and Simalastar, Alena and Rizzotti-Kaddouri, Aïcha},
	title = {Stress Detection with Deep Learning Approaches Using Physiological Signals},
	year = {2021},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {360},
	pages = {95 – 111},
	doi = {10.1007/978-3-030-69963-5_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102729863&doi=10.1007%2f978-3-030-69963-5_7&partnerID=40&md5=230ce7eada37abc0bf8dee0f670c2239},
	affiliations = {School of Engineering, Haute Ecole Arc Ingénierie, Neuchatel, Switzerland; School of Engineering, Haute Ecole Spécialisée Valais-Wallis, Sion, Switzerland},
	abstract = {The problem of stress detection and classification has attracted a lot of attention in the past decade. It has been tackled with mainly two different approaches, where signals were either collected in ambulatory settings, which can be limited to the period of presence in the hospital, or in continuous mode in the field. A sensor-based continuous measurement of stress in daily life has a potential to increase awareness of patterns of stress occurrence. In this work, we first present a data-flow infrastructure suitable for two types of studies that conforms with the data protection requirements of the ethics committee monitoring the research on humans. The detection and binary classification of stress events is compared with three different machine learning models based on the features (meta-data) extracted from physiological signals acquired in laboratory conditions and ground-truth stress level information provided by the subjects themselves via questionnaires associated with these features. The main signals considered in current classification are electro-dermal activity (EDA) and blood volume pulse (BVP) signals. Different models are compared and the best configuration yields an F1 score of 0.71 (random baseline: 0.48). The importance on prediction of phasic and tonic EDA components is also investigated. Our results also pave the way for further work on this topic with both machine learning approaches and signal processing directions. © 2021, ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering.},
	author_keywords = {Affective computing; Physiological monitoring; Self-management systems; Stress prediction; Sympathetic and parasympathetic activation; Telemonitoring},
	keywords = {Biomedical signal processing; Classification (of information); Health care; Internet of things; Learning systems; Physiological models; Physiology; Privacy by design; Stresses; Surveys; Binary classification; Blood volume pulse; Continuous measurements; Laboratory conditions; Machine learning approaches; Machine learning models; Physiological signals; Protection requirements; Deep learning},
	correspondence_address = {A. Rizzotti-Kaddouri; School of Engineering, Haute Ecole Arc Ingénierie, Neuchatel, Switzerland; email: aicha.rizzotti@he-arc.ch},
	editor = {Goleva R. and Garcia N.R. and Pires I.M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18678211},
	isbn = {978-303069962-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Inst. Comput. Sci. Soc. Informatics Telecommun. Eng.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 7th International Conference on Internet of Things (IoT) Technologies for HealthCare, HealthyIoT 2020; Conference date: 3 December 2020 through 3 December 2020; Conference code: 255709}
}

@ARTICLE{SEAVER2021509,
	author = {SEAVER, NICK},
	title = {CARE AND SCALE: Decorrelative Ethics in Algorithmic Recommendation},
	year = {2021},
	journal = {Cultural Anthropology},
	volume = {36},
	number = {3},
	pages = {509 – 537},
	doi = {10.14506/ca36.3.11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115785448&doi=10.14506%2fca36.3.11&partnerID=40&md5=3459d74382d1bba3ab36540e04693393},
	affiliations = {Tufts University, United States},
	abstract = {The people who make algorithmic recommender systems want apparently incompatible things: they pride themselves on the scale at which their software works, but they also want to treat their materials and users with care. Care and scale are commonly understood as contradictory goals: to be careful is to work at small scale, while working at large scale requires abandoning the small concerns of care. Drawing together anthropological work on care and scale, this article analyzes how people who make music recommender systems try to reconcile these values, reimagining what care and scale mean and how they relate to each other in the process. It describes decorrelation, an ethical technique that metaphorically borrows from the mathematics of machine learning, which practitioners use to reimagine how values might relate with each other. This “decorrelative ethics” facilitates new arrangements of care and scale, which challenge conventional anthropological theorizing. © 2021. All rights reserved.},
	author_keywords = {algorithms; care; ethics; music; scale},
	publisher = {American Anthropological Association},
	issn = {08867356},
	language = {English},
	abbrev_source_title = {Cult. Anthropol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access}
}

@ARTICLE{De Silva2021,
	author = {De Silva, Kushan and Enticott, Joanne and Barton, Christopher and Forbes, Andrew and Saha, Sajal and Nikam, Rujuta},
	title = {Use and performance of machine learning models for type 2 diabetes prediction in clinical and community care settings: Protocol for a systematic review and meta-analysis of predictive modeling studies},
	year = {2021},
	journal = {Digital Health},
	volume = {7},
	doi = {10.1177/20552076211047390},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116068506&doi=10.1177%2f20552076211047390&partnerID=40&md5=0dbeb5164d59447192df6a34b5a8500e},
	affiliations = {Monash Centre for Health Research and Implementation, School of Public Health and Preventive Medicine, Faculty of Medicine, Nursing, and Health Sciences, Monash University, Australia; Department of General Practice, School of Public Health and Preventive Medicine, Faculty of Medicine, Nursing, and Health Sciences, Monash University, Australia; Biostatistics Unit, Division of Research Methodology, School of Public Health and Preventive Medicine, Faculty of Medicine, Nursing, and Health Sciences, Monash University, Australia},
	abstract = {Objective: Machine learning involves the use of algorithms without explicit instructions. Of late, machine learning models have been widely applied for the prediction of type 2 diabetes. However, no evidence synthesis of the performance of these prediction models of type 2 diabetes is available. We aim to identify machine learning prediction models for type 2 diabetes in clinical and community care settings and determine their predictive performance. Methods: The systematic review of English language machine learning predictive modeling studies in 12 databases will be conducted. Studies predicting type 2 diabetes in predefined clinical or community settings are eligible. Standard CHARMS and TRIPOD guidelines will guide data extraction. Methodological quality will be assessed using a predefined risk of bias assessment tool. The extent of validation will be categorized by Reilly–Evans levels. Primary outcomes include model performance metrics of discrimination ability, calibration, and classification accuracy. Secondary outcomes include candidate predictors, algorithms used, level of validation, and intended use of models. The random-effects meta-analysis of c-indices will be performed to evaluate discrimination abilities. The c-indices will be pooled per prediction model, per model type, and per algorithm. Publication bias will be assessed through funnel plots and regression tests. Sensitivity analysis will be conducted to estimate the effects of study quality and missing data on primary outcome. The sources of heterogeneity will be assessed through meta-regression. Subgroup analyses will be performed for primary outcomes. Ethics and dissemination: No ethics approval is required, as no primary or personal data are collected. Findings will be disseminated through scientific sessions and peer-reviewed journals. PROSPERO registration number: CRD42019130886. © The Author(s) 2021.},
	author_keywords = {machine learning; meta-analysis; prediction models; protocol; Type 2 diabetes},
	correspondence_address = {K. De Silva; Monash Centre for Health Research and Implementation, School of Public Health and Preventive Medicine, Faculty of Medicine, Nursing, and Health Sciences, Monash University, Australia; email: kushan.ranakombu@monash.edu},
	publisher = {SAGE Publications Inc.},
	issn = {20552076},
	language = {English},
	abbrev_source_title = {Digit. Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Henze2020,
	author = {Henze, Larissa and Walter, Uwe and Escobar, Hugo Murua and Junghanss, Christian and Jaster, Robert and Köhling, Rüdiger and Lange, Falko and Salehzadeh-Yazdi, Ali and Wolkenhauer, Olaf and Hamed, Mohamed and Barrantes, Israel and Palmer, Daniel and Möller, Steffen and Kowald, Axel and Heussen, Nicole and Fuellen, Georg},
	title = {Towards biomarkers for outcomes after pancreatic ductal adenocarcinoma and ischaemic stroke, with focus on (co)-morbidity and ageing/cellular senescence (SASKit): Protocol for a prospective cohort study},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {12},
	doi = {10.1136/bmjopen-2020-039560},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098170362&doi=10.1136%2fbmjopen-2020-039560&partnerID=40&md5=9ebdaf2003b2632f7836055415191c04},
	affiliations = {Department of Medicine, Clinic III, Hematology, Oncology, Palliative Medicine, Rostock University Medical Center and Research Focus Oncology, Rostock, Germany; Department of Neurology, Rostock University Medical Center, Centre for Transdisciplinary Neurosciences Rostock, Rostock, Germany; Department of Gastroenterology, Rostock University Medical Center and Research Focus Oncology, Rostock, Germany; Oscar Langendorff Institute of Physiology, Rostock University Medical Center, Centre for Transdisciplinary Neurosciences Rostock and Ageing of Individuals and Society, Interdisciplinary Faculty, Rostock University, Rostock, Germany; Oscar Langendorff Institute of Physiology, Rostock University Medical Center, Rostock, Germany; Department of Systems Biology and Bioinformatics, University of Rostock, Rostock, Germany; Department of Systems Biology and Bioinformatics, University of Rostock, Centre for Transdisciplinary Neurosciences Rostock, Rostock University Medical Center, Rostock, Germany; Institute for Biostatistics and Informatics in Medicine and Ageing Research, Rostock University Medical Center Research Focus Oncology, Rostock, Germany; Institute for Biostatistics and Informatics in Medicine and Ageing Research, Rostock University Medical Center, Rostock, Germany; Department of Medical Statistics, Rwth Aachen, Aachen, Germany; Institute for Biostatistics and Informatics in Medicine and Ageing Research, Rostock University Medical Center, Centre for Transdisciplinary Neurosciences Rostock and Research Focus Oncology, Rostock and Ageing of Individuals and Society, Interdisciplinary Faculty, Rostock University, Rostock, Germany},
	abstract = {Introduction Ageing-related processes such as cellular senescence are believed to underlie the accumulation of diseases in time, causing (co)morbidity, including cancer, thromboembolism and stroke. Interfering with these processes may delay, stop or reverse morbidity. The aim of this study is to investigate the link between (co)morbidity and ageing by exploring biomarkers and molecular mechanisms of disease-triggered deterioration in patients with pancreatic ductal adenocarcinoma (PDAC) and (thromboembolic) ischaemic stroke (IS). Methods and analysis We will recruit 50 patients with PDAC, 50 patients with (thromboembolic) IS and 50 controls at Rostock University Medical Center, Germany. We will gather routine blood data, clinical performance measurements and patient-reported outcomes at up to seven points in time, alongside in-depth transcriptomics and proteomics at two of the early time points. Aiming for clinically relevant biomarkers, the primary outcome is a composite of probable sarcopenia, clinical performance (described by ECOG Performance Status for patients with PDAC and the Modified Rankin Scale for patients with stroke) and quality of life. Further outcomes cover other aspects of morbidity such as cognitive decline and of comorbidity such as vascular or cancerous events. The data analysis is comprehensive in that it includes biostatistics and machine learning, both following standard role models and additional explorative approaches. Prognostic and predictive biomarkers for interventions addressing senescence may become available if the biomarkers that we find are specifically related to ageing/cellular senescence. Similarly, diagnostic biomarkers will be explored. Our findings will require validation in independent studies, and our dataset shall be useful to validate the findings of other studies. In some of the explorative analyses, we shall include insights from systems biology modelling as well as insights from preclinical animal models. We anticipate that our detailed study protocol and data analysis plan may also guide other biomarker exploration trials. Ethics and dissemination The study was approved by the local ethics committee (Ethikkommission an der Medizinischen Fakultät der Universität Rostock, A2019-0174), registered at the German Clinical Trials Register (DRKS00021184), and results will be published following standard guidelines.  © },
	author_keywords = {health informatics; immunology; molecular aspects; stroke; thromboembolism},
	keywords = {Adenocarcinoma; Aging; Brain Ischemia; Cellular Senescence; Cohort Studies; Comorbidity; COVID-19; Female; Germany; Humans; Ischemic Stroke; Male; Pancreatic Neoplasms; Prospective Studies; Quality of Life; SARS-CoV-2; Stroke; biological marker; adult; animal experiment; animal model; Article; biostatistics; blood sampling; brain ischemia; cancer prognosis; cell aging; clinical article; cognitive defect; cohort analysis; comorbidity; controlled study; demography; European Quality of Life 5 Dimensions 5 Level questionnaire; female; Germany; grip strength; human; male; muscle function; muscle isometric contraction; muscle strength; nonhuman; pancreas adenocarcinoma; patient-reported outcome; prevalence; prospective study; proteomics; quality of life; Rankin scale; sarcopenia; systems biology; thromboembolism; transcriptomics; transfer of learning; university hospital; unsupervised machine learning; adenocarcinoma; aging; brain ischemia; cell aging; cerebrovascular accident; comorbidity; pancreas tumor},
	correspondence_address = {G. Fuellen; Institute for Biostatistics and Informatics in Medicine and Ageing Research, Rostock University Medical Center, Centre for Transdisciplinary Neurosciences Rostock and Research Focus Oncology, Rostock and Ageing of Individuals and Society, Interdisciplinary Faculty, Rostock University, Rostock, Germany; email: fuellen@uni-rostock.de},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33334830},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Wadhwani2020133,
	author = {Wadhwani, Abhishek and Jain, Priyank},
	title = {Machine Learning Model Cards Transparency Review: Using model card toolkit},
	year = {2020},
	journal = {2020 IEEE Pune Section International Conference, PuneCon 2020},
	pages = {133 – 137},
	doi = {10.1109/PuneCon50868.2020.9362382},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85102658577&doi=10.1109%2fPuneCon50868.2020.9362382&partnerID=40&md5=0cf49040d0b4382634ce94948b1853cd},
	affiliations = {Oriental College of Technology, Dept. of Information Technology, Bhopal Madhya Pradesh, India; Manit Bhopal, Dept. of Cse, Madhya Pradesh, India},
	abstract = {In our day to day life, we rely on information that is provided by product makers to make rightful choices such as the nutritional content of food, warnings in medications, strength parameters of a constructed road, etc but when it comes to AI there's has not been any such provided information. The machine learning models are very often distributed without a proper clear understanding of how it functions, i.e. under what conditions would it perform the best and most consistently, whether or not it has blind spots, and, if so, then where are they.Model cards are a very recent and hot topic of research. In Machine Learning (ML), transparency with model cards is relevant as it affects a wide range of domains, from health care to finance and jobs, etc. This research paper presents the importance of model cards and transparency issues. © 2020 IEEE.},
	author_keywords = {datasheets; disaggregated evaluation; ethics; fairness in AI; Machine Learning model evaluation; Model documentation},
	keywords = {Transparency; Blind spots; Hot topics; It functions; Machine learning models; Research papers; Strength parameters; Machine learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172819600-8},
	language = {English},
	abbrev_source_title = {IEEE Pune Sect. Int. Conf., PuneCon},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; Conference name: 3rd IEEE Pune Section International Conference, PuneCon 2020; Conference date: 16 December 2020 through 18 December 2020; Conference code: 167617}
}

@ARTICLE{Hackstein2021,
	author = {Hackstein, Urs and Krüger, Tobias and Mair, Alexander and Degünther, Charlotte and Krickl, Stefan and Schlensak, Christian and Bernhard, Stefan},
	title = {Early diagnosis of aortic aneurysms based on the classification of transfer function parameters estimated from two photoplethysmographic signals},
	year = {2021},
	journal = {Informatics in Medicine Unlocked},
	volume = {25},
	doi = {10.1016/j.imu.2021.100652},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109014603&doi=10.1016%2fj.imu.2021.100652&partnerID=40&md5=bfd37a624ed369be2ddaf472f76dd01f},
	affiliations = {Technische Hochschule Mittelhessen, Fachbereich Life Science Engineering, Gießen, Germany; Universitätsklinikum Tübingen, Klinik für Thorax-, Herz- und Gefäßchirurgie, Tübingen, Germany; Freie Universität Berlin, Institute of Mathematics, Berlin, Germany},
	abstract = {Background: Cardiovascular diseases are the leading cause of death worldwide. Particularly aortic aneurysms are problematic and underdiagnosed: Existing diagnostic techniques either lack sensitivity or require specialized expertise, are invasive and costly which hampers effective screening. The objective of this proof-of-concept study is to develop an easy-to-use, non-invasive diagnostic method to generate suspicious facts about the presence of aortic aneurysms at the family physician level. This study is based on previous in-silico results and reports on the first clinical study ever to validate attempts to diagnose aortic aneurysms using machine learning techniques. Method: Two feature selection approaches for a classification “control group vs. aneurysms in the thoracic or abdominal aorta“ using Naive Bayes and K-Nearest-Neighbor-algorithms were applied to in-vivo data from a clinical study including 55 patients. The first attempt based on parameter estimation of AutoRegressive-MovingAverage (ARMAX)-models, the second on frequency response of the transfer function, both computed using two peripheral photoplethysmographic signals. Results: In both cases only around 60% overall accuracy was achieved, but as classifiers trained and tested with randomly permuted labels show less accuracy, an intrinsic effect of aneurysms could be verified. Compared to previous in-silico results, the lower accuracy can be explained by low signal-to-noise ratio of the sensors used in connection with the low peripheral perfusion of the highly morbid patients, variability and number of patients in the clinical study. Conclusion: Both approaches have shown basic classification quality in a proof-of-concept clinical setting, however to overcome remaining uncertainties, training of the classifier with a larger number of patients is necessary. Nevertheless, we assume, that the method will improve the interpretation of cardiovascular signals in the early diagnosis of aortic aneurysms in near future. (clinical study approved by Ethics Committee, University Hospital Tübingen (Germany) (No. 136/2018801)). © 2021 The Authors},
	author_keywords = {Aortic aneurysm; ARMAX-models; Classification; Clinical study; Frequency response; Parameter estimation},
	keywords = {iodinated contrast medium; nonionic contrast medium; abdominal aortic aneurysm; adult; aged; aortic aneurysm; Article; Bayesian learning; computed tomographic angiography; computer model; controlled clinical trial; decision tree; diagnostic accuracy; diagnostic test accuracy study; disease classification; early diagnosis; feature selection; female; Fourier transform; heart rate; human; image processing; k nearest neighbor; machine learning; major clinical study; male; middle aged; photoelectric plethysmography; signal noise ratio; support vector machine; thoracic aorta aneurysm},
	correspondence_address = {U. Hackstein; Technische Hochschule Mittelhessen, Fachbereich LSE, Gießen, Wiesenstraße 14, 35390, Germany; email: urs.hackstein@lse.thm.de},
	publisher = {Elsevier Ltd},
	issn = {23529148},
	language = {English},
	abbrev_source_title = {Inform. Med. Unlocked},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{Tarafdar2021,
	author = {Tarafdar, Monideepa and Teodorescu, Mike H.M. and Tanriverdi, Hüseyin and Robert, Lionel P. and Morse, Lily},
	title = {Seeking ethical use of AI algorithms: Challenges and mitigations},
	year = {2021},
	journal = {International Conference on Information Systems, ICIS 2020 - Making Digital Inclusive: Blending the Local and the Global},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101327479&partnerID=40&md5=70ffa940d881c59928a6176f5d9c5fd4},
	affiliations = {Lancaster University, United Kingdom; Boston College, Carroll School of Management; University of Texas at Austin, McCombs School of Business; University of Michigan, School of Information; West Virginia University, John Chambers College of Business and Economics},
	abstract = {This panel will discuss the problems of bias and fairness in organizational use of AI algorithms. The panel will first put forth key issues regarding biases that arise when AI algorithms are applied to organizational processes. We will then propose a socio-technical approach to bias mitigation. We will further share proposals for companies and policymakers on improving AI algorithmic fairness and bias mitigation within organizations. The panel will bring together scholars examining social and technical aspects of bias and its mitigation, from the perspective of information systems, ethics, machine learning, robotics, and human capital. The panel will end with an open discussion of where the field of information systems can step in to guide fairness and ethical use in AI algorithms in the coming years. © ICIS 2020. All rights reserved.},
	author_keywords = {Bias; Ethics; Fairness; Machine learning; Protected attribute; Socio-technical},
	keywords = {Blending; Information systems; Information use; Philosophical aspects; AI algorithms; Human capitals; Key Issues; Organizational process; Policy makers; Socio-technical approach; Technical aspects; Social robots},
	publisher = {Association for Information Systems},
	isbn = {978-173363255-3},
	language = {English},
	abbrev_source_title = {Int. Conf. Inf. Syst., ICIS - Mak. Digit. Incl.: Blending Local Glob.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2020 International Conference on Information Systems - Making Digital Inclusive: Blending the Local and the Global, ICIS 2020; Conference date: 13 December 2020 through 16 December 2020; Conference code: 167844}
}

@ARTICLE{Nagaraj2020336,
	author = {Nagaraj, Sujay and Harish, Vinyas and McCoy, Liam G. and Morgado, Felipe and Stedman, Ian and Lu, Stephen and Drysdale, Erik and Brudno, Michael and Singh, Devin},
	title = {From Clinic to Computer and Back Again: Practical Considerations When Designing and Implementing Machine Learning Solutions for Pediatrics},
	year = {2020},
	journal = {Current Treatment Options in Pediatrics},
	volume = {6},
	number = {4},
	pages = {336 – 349},
	doi = {10.1007/s40746-020-00205-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091123462&doi=10.1007%2fs40746-020-00205-4&partnerID=40&md5=fea807c3b75e11d196f59d2b68fb79db},
	affiliations = {Faculty of Medicine, University of Toronto, Toronto, ON, Canada; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Institute of Health Policy, Management and Evaluation, University of Toronto, Toronto, ON, Canada; Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada; School of Public Policy and Administration, York University, Toronto, ON, Canada; Paediatric Emergency Medicine, The Hospital for Sick Children, Toronto, ON, Canada; University Health Network, Toronto, ON, Canada; Vector Institute for Artificial Intelligence, Toronto, ON, Canada},
	abstract = {Purpose of review: Machine learning (ML), a branch of artificial intelligence, is influencing all fields in medicine, with an abundance of work describing its application to adult practice. ML in pediatrics is distinctly unique with clinical, technical, and ethical nuances limiting the direct translation of ML tools developed for adults to pediatric populations. To our knowledge, no work has yet focused on outlining the unique considerations that need to be taken into account when designing and implementing ML in pediatrics. Recent findings: The nature of varying developmental stages and the prominence of family-centered care lead to vastly different data-generating processes in pediatrics. Data heterogeneity and a lack of high-quality pediatric databases further complicate ML research. In order to address some of these nuances, we provide a common pipeline for clinicians and computer scientists to use as a foundation for structuring ML projects, and a framework for the translation of a developed model into clinical practice in pediatrics. Throughout these pathways, we also highlight ethical and legal considerations that must be taken into account when working with pediatric populations and data. Summary: Here, we describe a comprehensive outline of special considerations required of ML in pediatrics from project ideation to implementation. We hope this review can serve as a high-level guideline for ML scientists and clinicians alike to identify applications in the pediatric setting, generate effective ML solutions, and subsequently deliver them to patients, families, and providers. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Design; Ethics; Machine learning; Pediatric medicine; Translation},
	keywords = {artificial intelligence; child; computer scientist; developmental stage; ethics; human; machine learning; pediatrics; pipeline; practice guideline; review},
	correspondence_address = {S. Nagaraj; Department of Computer Science, University of Toronto, Toronto, Canada; email: s.nagaraj@mail.utoronto.ca},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21986088},
	language = {English},
	abbrev_source_title = {Curr. Treat. Options Pediatr.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@ARTICLE{Wong20211,
	author = {Wong, Anthony},
	title = {Ethics and Regulation of Artificial Intelligence},
	year = {2021},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {614},
	pages = {1 – 18},
	doi = {10.1007/978-3-030-80847-1_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112133856&doi=10.1007%2f978-3-030-80847-1_1&partnerID=40&md5=f9de980b8df61e854efcb347459b6b56},
	affiliations = {AGW Legal & Advisory, Sydney, Australia; IFIP, Laxenburg, Austria; Australian Computer Society (ACS), Sydney, Australia},
	abstract = {Over the last few years, the world has deliberated and developed numerous ethical principles and frameworks. It is the general opinion that the time has arrived to move from principles and to operationalize on the ethical practice of AI. It is now recognized that principles and standards can play a universal harmonizing role for the development of AI-related legal norms across the globe. However, how do we translate and embrace these articulated values, principles and actions to guide Nation States around the world to formulate their regulatory systems, policies or other legal instruments regarding AI? Our regulatory systems have attempted to keep abreast of new technologies by recalibrating and adapting our regulatory frameworks to provide for new opportunities and risks, to confer rights and duties, safety and liability frameworks, and to ensure legal certainty for businesses. These past adaptations have been reactive and sometimes piecemeal, often with artificial delineation on rights and responsibilities and with unintended flow-on consequences. Previously, technologies have been deployed more like tools, but as autonomy and self-learning capabilities increase, robots and intelligent AI systems will feel less and less like machines and tools. There is now a significant difference, because machine learning AI systems have the ability ‘to learn’, adapt their performances and ‘make decisions’ from data and ‘life experiences’. This paper presented at the International Joint Conference on Artificial Intelligence - Pacific Rim International Conference on Artificial Intelligence in 2021 provides brief insights on some selected topical developments in ethical principles and frameworks, our regulatory systems and the current debates on some of the risks and challenges from the use and actions of AI, autonomous and intelligent systems [1]. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {AI; Automation; Data protection; Employment; Ethics; Explainability; Job transition; Law; Legal personhood; Liability; Privacy; Regulation; Robots; Transparency},
	keywords = {End effectors; Intelligent systems; Knowledge management; Philosophical aspects; Ethical practices; Ethical principles; Legal instruments; Life experiences; Regulatory frameworks; Regulatory systems; Rights and responsibilities; Self-learning capability; Learning systems},
	correspondence_address = {A. Wong; AGW Legal & Advisory, Sydney, Australia; email: anthonywong@agwconsult.com},
	editor = {Mercier-Laurent E. and Owoc M.L. and Özgür Kayalica M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303080846-4},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 8th IFIP WG 12.6 International Workshop on Artificial Intelligence for Knowledge Management, AI4KM 2021 held in conjunction with International Joint Conference on Artificial Intelligence, IJCAI 2020; Conference date: 7 January 2021 through 8 January 2021; Conference code: 262349}
}

@ARTICLE{Sanghvi2021S215,
	author = {Sanghvi, Darshana},
	title = {"publish or Perish"; Time to question an age old adage?},
	year = {2021},
	journal = {Indian Journal of Radiology and Imaging},
	volume = {31},
	number = {5},
	pages = {S215 – S216},
	doi = {10.4103/ijri.IJRI_487_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100339746&doi=10.4103%2fijri.IJRI_487_20&partnerID=40&md5=3defb983737c90f30290cf43d9e54bc7},
	affiliations = {Department of Radiology, Kokilaben Dhirubhai Ambani Hospital, Mumbai, Maharashtra, India},
	keywords = {angiotensin receptor antagonist; antihypertensive agent; chloroquine; dipeptidyl carboxypeptidase inhibitor; hydroxychloroquine; macrolide; measles mumps rubella vaccine; hydroxychloroquine; aging; antihypertensive therapy; artificial intelligence; big data; cardiovascular disease; clinical trial (topic); coronavirus disease 2019; deep learning; disease association; disease registry; dying; electronic medical record; expression of concern; heart ventricle arrhythmia; hospital patient; human; immunization; Letter; machine learning; measles; medical ethics; medical literature; mortality risk; pandemic; peer review; physician; publication; scientist; statistician; United Kingdom; World Health Organization; autism; coronavirus disease 2019; medical literature; mortality},
	correspondence_address = {D. Sanghvi; Department of Radiology, Kokilaben Dhirubhai Ambani Hospital, Mumbai, Maharashtra, India; email: sanghvidarshana@gmail.com},
	publisher = {Wolters Kluwer Medknow Publications},
	issn = {09713026},
	coden = {IJRIE},
	language = {English},
	abbrev_source_title = {Indian J. Radiol. Imaging},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Gerdes2021243,
	author = {Gerdes, Anne},
	title = {Dialogical Guidelines Aided by Knowledge Acquisition: Enhancing the Design of Explainable Interfaces and Algorithmic Accuracy},
	year = {2021},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1288},
	pages = {243 – 257},
	doi = {10.1007/978-3-030-63128-4_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096464793&doi=10.1007%2f978-3-030-63128-4_19&partnerID=40&md5=c127dabbcb478a51b8b0806ade733e3b},
	affiliations = {Department of Design and Communication, University of Southern Denmark, Universitetsparken 1, Kolding, 6000, Denmark},
	abstract = {Understanding expert domain knowledge may inform the design of explainable interfaces that convey comprehensible information by “mirroring” the explanation practice of domain experts. Likewise, scrutinizing expert domain knowledge is pivotal to guarantee data quality and enhance algorithmic accuracy, by zooming in on the types of data and information that constitute relevant and reliable representations in a given domain. Against this backdrop, the paper revitalizes the field of knowledge acquisition and presents easily applicable user-centered and value-oriented dialogical guidelines to unravel domain knowledge with the aim of enhancing the design of explainable interfaces and algorithmic accuracy. While it might seem counter-intuitive to revisit the field of knowledge acquisition in the era of machine learning and deep learning, there are plenty of cases in which AI systems, trained on biased data, have led to epistemological deficiencies with morally harmful consequences. In order to improve the data preparation and modelling stage in the development of ML models, this paper suggests that AI developers could benefit from the pragmatic application of manageable dialogical guidelines aided by knowledge acquisition to cultivate shared understanding between AI developers and domain expert end users. © 2021, Springer Nature Switzerland AG.},
	author_keywords = {Algorithmic accuracy; Dialogical guidelines; Epistemic opacity; Ethics; Explainable AI; Knowledge acquisition},
	keywords = {Deep learning; Data and information; Data preparation; Data quality; Domain experts; Domain knowledge; Shared understanding; User-centered; Zooming-in; Knowledge acquisition},
	correspondence_address = {A. Gerdes; Department of Design and Communication, University of Southern Denmark, Kolding, Universitetsparken 1, 6000, Denmark; email: gerdes@sdu.dk},
	editor = {Arai K. and Kapoor S. and Bhatia R.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21945357},
	isbn = {978-303063127-7},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: Future Technologies Conference, FTC 2020; Conference date: 5 November 2020 through 6 November 2020; Conference code: 251149; All Open Access, Green Open Access}
}

@ARTICLE{van ‘t Wout20211036,
	author = {van ‘t Wout, Elwin and Pieringer, Christian and Torres Irribarra, David and Asahi, Kenzo and Larroulet, Pilar},
	title = {Machine learning for policing: a case study on arrests in Chile},
	year = {2021},
	journal = {Policing and Society},
	volume = {31},
	number = {9},
	pages = {1036 – 1050},
	doi = {10.1080/10439463.2020.1779270},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087112163&doi=10.1080%2f10439463.2020.1779270&partnerID=40&md5=b1f4ead2c920aa437d56f3acee911e3d},
	affiliations = {Institute for Mathematical and Computational Engineering, School of Engineering and Faculty of Mathematics, Pontificia Universidad Católica de Chile, Santiago, Chile; Escuela de Psicología, Pontificia Universidad Católica de Chile, Santiago, Chile; Escuela de Gobierno, Pontificia Universidad Católica de Chile, Santiago, Chile; Centre for Sustainable Urban Development (CEDEUS), Santiago, Chile; Instituto de Sociología, Pontificia Universidad Católica de Chile, Santiago, Chile; Millennium Nucleus for the Study of the Life Course and Vulnerability (MLIV), Santiago, Chile},
	abstract = {Police agencies expend considerable effort to anticipate future incidences of criminal behaviour. Since a large proportion of crimes are committed by a small group of individuals, preventive measures are often targeted on prolific offenders. There is a long-standing expectation that new technologies can improve the accurate identification of crime patterns. Here, we explore big data technology and design a machine learning algorithm for forecasting repeated arrests. The forecasts are based on administrative data provided by the national Chilean police agencies, including a history of arrests in Santiago de Chile and personal metadata such as gender and age. Excellent algorithmic performance was achieved with various supervised machine learning techniques. Still, there are many challenges regarding the design of the mathematical model, and its eventual incorporation into predictive policing will depend upon better insights into the effectiveness and ethics of preemptive strategies. © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Data analytics; predictive policing; repeated arrests},
	correspondence_address = {E. van ‘t Wout; Institute for Mathematical and Computational Engineering, School of Engineering and Faculty of Mathematics, Pontificia Universidad Católica de Chile, Santiago, Chile; email: e.wout@uc.cl},
	publisher = {Routledge},
	issn = {10439463},
	language = {English},
	abbrev_source_title = {Policing Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Gunkel2020307,
	author = {Gunkel, David J.},
	title = {Mind the gap: responsible robotics and the problem of responsibility},
	year = {2020},
	journal = {Ethics and Information Technology},
	volume = {22},
	number = {4},
	pages = {307 – 320},
	doi = {10.1007/s10676-017-9428-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025076629&doi=10.1007%2fs10676-017-9428-2&partnerID=40&md5=1175b99c276096f3cade0ba501b9dc4c},
	affiliations = {Northern Illinois University, Dekalb, 60115, IL, United States},
	abstract = {The task of this essay is to respond to the question concerning robots and responsibility—to answer for the way that we understand, debate, and decide who or what is able to answer for decisions and actions undertaken by increasingly interactive, autonomous, and sociable mechanisms. The analysis proceeds through three steps or movements. (1) It begins by critically examining the instrumental theory of technology, which determines the way one typically deals with and responds to the question of responsibility when it involves technology. (2) It then considers three instances where recent innovations in robotics challenge this standard operating procedure by opening gaps in the usual way of assigning responsibility. The innovations considered in this section include: autonomous technology, machine learning, and social robots. (3) The essay concludes by evaluating the three different responses—instrumentalism 2.0, machine ethics, and hybrid responsibility—that have been made in face of these difficulties in an effort to map out the opportunities and challenges of and for responsible robotics. © 2017, Springer Science+Business Media B.V.},
	author_keywords = {Ethics; Machine ethics; Philosophy; Responsibility; Robot; Robotics; Technology},
	keywords = {Engineering education; Ethical aspects; Philosophical aspects; Robots; Autonomous technology; Instrumental theories; Philosophy; Responsibility; Standard operating procedures; Robotics},
	correspondence_address = {D.J. Gunkel; Northern Illinois University, Dekalb, 60115, United States; email: dgunkel@niu.edu},
	publisher = {Springer Science and Business Media B.V.},
	issn = {13881957},
	language = {English},
	abbrev_source_title = {Ethics Inf. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 57}
}

@ARTICLE{Xhafa20211,
	author = {Xhafa, Fatos and Krause, Paul},
	title = {IoT-Based Computational Modeling for Next Generation Agro-Ecosystems: Research Issues, Emerging Trends and Challenges},
	year = {2021},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {67},
	pages = {1 – 21},
	doi = {10.1007/978-3-030-71172-6_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107368723&doi=10.1007%2f978-3-030-71172-6_1&partnerID=40&md5=65d618167834beb628cb252abd2b03c1},
	affiliations = {Universitat Politècnica de Catalunya, Barcelona, Spain; University of Surrey, Guildford, United Kingdom},
	abstract = {In this introductory chapter we highlight some fundamental concepts, architectures and definitions related to IoT-based Computational Modeling for Next Generation Agro-ecosystems. We distinguish and discus the paradigms of Cloud-to-thing Continuum as a large digital ecosystem comprising IoT, Edge, Fog, and Cloud Computing, data cycles from data gathering, processing and analysis to knowledge generation and decision making. Machine learning and stream processing, optimization, simulation frameworks, symbiotic modeling and the digital twin as well as emerging research trends, ethics and health & safety issues are also introduced and discussed. Challenges arising from processing and analyzing large and heterogeneous data sets are pointed out with some examples of killer applications from Agriculture 4.0. These concepts, models, technologies, frameworks and benchmarks are covered in the chapters of the book and exemplified with real life use cases and applications. In all, Cloud-to-thing continuum and IoT as part of it are envisaged as game changers for Computational Modeling of Next Generation Agro-ecosystems. © 2021, Springer Nature Switzerland AG.},
	keywords = {Agricultural robots; Benchmarking; Computation theory; Data handling; Decision making; Digital twin; Ecosystems; Computational model; Digital ecosystem; Fundamental concepts; Heterogeneous data; Killer-application; Knowledge generations; Simulation framework; Stream processing; Internet of things},
	correspondence_address = {F. Xhafa; Universitat Politècnica de Catalunya, Barcelona, Spain; email: fatos@cs.upc.edu},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23674512},
	language = {English},
	abbrev_source_title = {Lecture. Notes. Data Eng. Commun. Tech.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Boyapati2020756,
	author = {Boyapati, Sumati and Swarna, Srinivasa Rao and Sharma, Shweta and Agrawal, Rashmi},
	title = {A review of bigdata and machine learning techniques in healthcare},
	year = {2020},
	journal = {Proceedings of the 3rd International Conference on Intelligent Sustainable Systems, ICISS 2020},
	pages = {756 – 761},
	doi = {10.1109/ICISS49785.2020.9315876},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100727872&doi=10.1109%2fICISS49785.2020.9315876&partnerID=40&md5=7622638e22d916f6769b0ad975d773a7},
	affiliations = {INC, IRIS Software, Edison, NJ, United States; Tata, Consultancy Services, Edision, NJ, United States; MDSU Ajmer, Ajmer, India; Manav Rachna International Institute of Research and Studies, Faculty of Computer Application},
	abstract = {The study of big data by machine learning offers significant favorable circumstances for the assimilation and assessment of large amounts of complex medical services information. To adequately use machine learning devices in medical services, some constraints must be measured and key points must be measured, for example, its clinical use and ethics in the use of medical services. Favorable circumstances of machine learning incorporate adaptability and versatility contrasted and conventional biostatistical strategies, which makes it deployable for some errands, for example, hazard separation, finding and grouping, and endurance expectations. The health care services measure includes a lot of gigantic information that can be of various kinds and put in better places. The digitization of data, if appropriately dissected, prompts an expansion like cycles and administrations in the Healthcare area. In this specific situation, Machine Learning (ML) is the key empowering innovation to diminish the expenses of medical services extricating knowledge from information. The objective of ML is to improve a framework with no ceaseless human mediation. Medical Decision Support Systems (MDSS) are an additional incentive from one viewpoint by accelerating determination and care measures, then again decreasing the hour of clinical staff or concentrated learning. © 2020 IEEE.},
	author_keywords = {Biomedical Research; Classification of Big data; Healthcare; Techniques},
	keywords = {Biohazards; Decision support systems; Health care; Better places; Clinical staff; Clinical use; Healthcare services; Large amounts; Machine learning techniques; Medical decision support system; Medical services; Machine learning},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172817089-3},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Intell. Sustain. Syst., ICISS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 3rd International Conference on Intelligent Sustainable Systems, ICISS 2020; Conference date: 3 December 2020 through 5 December 2020; Conference code: 166600}
}

@ARTICLE{Tschaepe202195,
	author = {Tschaepe, Mark},
	title = {Pragmatic ethics for generative adversarial networks: Coupling, cyborgs, and machine learning},
	year = {2021},
	journal = {Contemporary Pragmatism},
	volume = {18},
	number = {1},
	pages = {95 – 111},
	doi = {10.1163/18758185-bja10005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107447175&doi=10.1163%2f18758185-bja10005&partnerID=40&md5=ff70ad7747f04ee4b6b96d6140d6d3cf},
	affiliations = {Division of Social Work, Behavioral and Political Science, Prairie View A&M University, Prairie View, TX, United States},
	abstract = {This article addresses the need for adaptive ethical analysis within machine learning that accounts for emerging problems concerning social bias and generative adversarial networks (gan s). I use John Dewey’s criticisms of the reflex arc concept in psychology as a basis for understanding how these problems stem from human-gan interaction. By combining Dewey’s criticisms with Donna Haraway’s idea of cyborgs, Luciano Floridi’s concept of distributed morality, and Shaowen Bardzell’s recommendations for a feminist approach to human-computer interaction, I suggest a dynamic perspective from which to begin analyzing and solving issues of injustice evident in this particular domain of machine learning. © koninklijke brill nv, leiden, 2021.},
	author_keywords = {Bias; Coupling; Ethics of technology; Generative adversarial networks; Machine learning},
	correspondence_address = {M. Tschaepe; Division of Social Work, Behavioral and Political Science, Prairie View A&M University, Prairie View, United States; email: mdtschaepe@pvamu.edu},
	publisher = {Brill Academic Publishers},
	issn = {15723429},
	language = {English},
	abbrev_source_title = {Contemp. Pragmatism},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{McFarlane2020,
	author = {McFarlane, Jacob and Illes, Judy},
	title = {Neuroethics at the interface of machine learning and schizophrenia},
	year = {2020},
	journal = {npj Schizophrenia},
	volume = {6},
	number = {1},
	doi = {10.1038/s41537-020-0108-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088259376&doi=10.1038%2fs41537-020-0108-6&partnerID=40&md5=1b260d023c0df0ca663be7f5011ad03f},
	affiliations = {Cognitive Systems, Faculty of Arts, University of British Columbia, Vancouver, BC, Canada; Neuroethics Canada, Division of Neurology, Department of Medicine, University of British Columbia, Vancouver, BC, Canada},
	abstract = {Ethical discourse around machine learning analysis of free speech for the detection of schizophrenia has largely focused on consent and personal privacy. We focus here on additional ethics concerns and principles that must be addressed to move the pendulum of risk over to benefit and propose solutions to achieve that shift. © 2020, The Author(s).},
	keywords = {bioethics; confidentiality; human; interpersonal communication; machine learning; Note; priority journal; privacy; schizophrenia},
	correspondence_address = {J. Illes; Neuroethics Canada, Division of Neurology, Department of Medicine, University of British Columbia, Vancouver, Canada; email: jilles@mail.ubc.ca},
	publisher = {Nature Research},
	issn = {2334265X},
	language = {English},
	abbrev_source_title = {NPJ Schizophr.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Xivuri2021271,
	author = {Xivuri, Khensani and Twinomurinzi, Hossana},
	title = {A Systematic Review of Fairness in Artificial Intelligence Algorithms},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12896 LNCS},
	pages = {271 – 284},
	doi = {10.1007/978-3-030-85447-8_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115174333&doi=10.1007%2f978-3-030-85447-8_24&partnerID=40&md5=f2893ca3129fe73bede0bf71ca17cd55},
	affiliations = {University of Johannesburg, Auckland Park, Johannesburg, South Africa},
	abstract = {Despite being the fastest-growing field because of its ability to enhance competitive advantage, there are concerns about the inherent fairness in Artificial Intelligence (AI) algorithms. In this study, a systematic review was performed on AI and the fairness of AI algorithms. 47 articles were reviewed for their focus, method of research, sectors, practices, and location. The key findings, summarized in a table, suggest that there is a lack of formalised AI terminology and definitions which subsequently results in contrasting views of AI algorithmic fairness. Most of the research is conceptual and focused on the technical aspects of narrow AI, compared to general AI or super AI. The public services sector is the target of most research, particularly criminal justice and immigration, followed by the health sector. AI algorithmic fairness is currently more focused on the technical and social/human aspects compared to the economic aspects. There was very little research from Asia, Middle East, Oceania, and Africa. The study makes suggestions for further research. © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {AI; Algorithms; Bias; Ethics; Fairness; Machine learning},
	keywords = {Competition; Electronic commerce; Service industry; AI algorithms; Artificial intelligence algorithms; Competitive advantage; Criminal justice; Economic aspects; Public services; Systematic Review; Technical aspects; Artificial intelligence},
	correspondence_address = {K. Xivuri; University of Johannesburg, Auckland Park, Johannesburg, South Africa; email: 200911813@uj.ac.za},
	editor = {Dennehy D. and Griva A. and Pouloudi N. and Dwivedi Y.K. and Dwivedi Y.K. and Pappas I. and Pappas I. and Mantymaki M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303085446-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 264489}
}

@ARTICLE{Kochupillai2020285,
	author = {Kochupillai, Mrinalini and Lütge, Christoph and Poszler, Franziska},
	title = {Programming Away Human Rights and Responsibilities? “The Moral Machine Experiment” and the Need for a More “Humane” AV Future},
	year = {2020},
	journal = {NanoEthics},
	volume = {14},
	number = {3},
	pages = {285 – 299},
	doi = {10.1007/s11569-020-00374-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096621400&doi=10.1007%2fs11569-020-00374-4&partnerID=40&md5=89475407412fefa28e5d64d9168be2f2},
	affiliations = {Department of Aerospace and Geodesy, Technical University of Munich, Munich, Germany; Munich Intellectual Property Law Center, Munich, Germany; Institute for Ethics in Artificial Intelligence, Technical University of Munich, Munich, Germany; Chair of Business Ethics, Technical University of Munich, Munich, Germany},
	abstract = {Dilemma situations involving the choice of which human life to save in the case of unavoidable accidents are expected to arise only rarely in the context of autonomous vehicles (AVs). Nonetheless, the scientific community has devoted significant attention to finding appropriate and (socially) acceptable automated decisions in the event that AVs or drivers of AVs were indeed to face such situations. Awad and colleagues, in their now famous paper “The Moral Machine Experiment”, used a “multilingual online ‘serious game’ for collecting large-scale data on how citizens would want AVs to solve moral dilemmas in the context of unavoidable accidents.” Awad and colleagues undoubtedly collected an impressive and philosophically useful data set of armchair intuitions. However, we argue that applying their findings to the development of “global, socially acceptable principles for machine learning” would violate basic tenets of human rights law and fundamental principles of human dignity. To make its arguments, our paper cites principles of tort law, relevant case law, provisions from the Universal Declaration of Human Rights, and rules from the German Ethics Code for Autonomous and Connected Driving. © 2020, The Author(s).},
	author_keywords = {Artificial intelligence; Autonomous vehicles; Ethics; Human dignity; Human rights; Human values; Law; Moral machines; Responsibility; Tort law},
	correspondence_address = {M. Kochupillai; Department of Aerospace and Geodesy, Technical University of Munich, Munich, Germany; email: m.kochupillai@tum.de},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18714757},
	language = {English},
	abbrev_source_title = {NanoEthics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Chowdhury2021233,
	author = {Chowdhury, Tanay and Oredo, John},
	title = {Ethics in AI: A Software Developmental and Philosophical Perspective},
	year = {2021},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12896 LNCS},
	pages = {233 – 241},
	doi = {10.1007/978-3-030-85447-8_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85115183719&doi=10.1007%2f978-3-030-85447-8_21&partnerID=40&md5=a7fe48960d6777a295b1612853de8ea9},
	affiliations = {Aviva Group Ireland, Galway, Ireland; University of Nairobi, Nairobi, Kenya},
	abstract = {The launch of various AI systems has been one of the main highlights of the industry. Alongside the enormous and revolutionary benefits, AI can cause numerous problems (usually resulting from poor design) and people have recently started to get serious about researching ways to make AI safer. Many of the AI safety concerns sound like science fiction, problems that might occur with very strong AI systems that are still years away, making these issues difficult to investigate. We don’t know what such potential AI systems would be like, but similar issues exist with AI systems that are currently in progress or even running in the real world. The author addresses the possible implications in this article, outlining some important approaches in terms of software development methodologies and philosophy that we can start working on right now to support us with current AI systems and, hopefully, future systems © 2021, IFIP International Federation for Information Processing.},
	author_keywords = {Algorithmic bias; Artificial Intelligence; Ethics; Machine learning; Philosophy},
	keywords = {Behavioral research; Electronic commerce; Philosophical aspects; AI systems; Real-world; Running-in; Safety concerns; Science fictions; Software development methodologies; Software design},
	correspondence_address = {T. Chowdhury; Aviva Group Ireland, Galway, Ireland; email: tanay_chowdhury@outlook.com},
	editor = {Dennehy D. and Griva A. and Pouloudi N. and Dwivedi Y.K. and Dwivedi Y.K. and Pappas I. and Pappas I. and Mantymaki M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303085446-1},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th IFIP WG 6.11 Conference on e-Business, e-Services and e-Society, I3E 2021; Conference date: 1 September 2021 through 3 September 2021; Conference code: 264489}
}@ARTICLE{Bowen2020727,
	author = {Bowen, Mary Elizabeth},
	title = {Monitoring functional status using a wearable real-time locating technology},
	year = {2020},
	journal = {Nursing Outlook},
	volume = {68},
	number = {6},
	pages = {727 – 733},
	doi = {10.1016/j.outlook.2020.04.012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086509773&doi=10.1016%2fj.outlook.2020.04.012&partnerID=40&md5=807159835e02430adc4f9b7523dad687},
	affiliations = {School of Nursing, University of Delaware, Newark, DE, United States; Cpl Michael J. Crescenz VA Medical Center, 3900 Woodland AvenuePhiladelphia, Philadelphia, 19104, PA, United States},
	abstract = {Sensor technologies enable real-time, continuous, and objective monitoring of activity and functioning in later life. In long-term care, timely assessment of functional status is needed to prevent falls and other acute events. However, the electronic forms and paper and pencil tools currently used are time-consuming and conducted too infrequently (e.g., every 6 months) to provide the sensitivity and specificity required. Staff are also unable to detect subtle changes in functioning through observation alone. The purpose of this paper is to discuss the use of a wearable real-time locating system that utilizes ultra wideband radio technology to continuously and objectively measure activity and aspects of functional status. This paper discusses the associated conceptualization and development of the scoring algorithms, raw data transformation, use of traditional paper and pencil tools and electronic health record data to validate sensor data, and other tips for those interested in this type of wearable sensor technology. © 2020},
	author_keywords = {Cognition; Data analysis; Data science; Mobility limitation; Supervised machine learning; Walking speed},
	keywords = {Forecasting; Humans; Inventions; Monitoring, Physiologic; Wearable Electronic Devices; devices; electronic device; ethics; forecasting; human; invention; physiologic monitoring; procedures},
	correspondence_address = {M.E. Bowen; School of Nursing, University of Delaware, Newark, Tower at STAR, 100 Discovery Blvd, 19713, United States; email: mebowen@udel.edu},
	publisher = {Mosby Inc.},
	issn = {00296554},
	coden = {NUOUA},
	pmid = {32546324},
	language = {English},
	abbrev_source_title = {Nurs. Outlook},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Arnold2020178,
	author = {Arnold, Carrie},
	title = {The controversial company using DNA to sketch the faces of criminals},
	year = {2020},
	journal = {Nature},
	volume = {585},
	number = {7824},
	pages = {178 – 181},
	doi = {10.1038/d41586-020-02545-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090818317&doi=10.1038%2fd41586-020-02545-5&partnerID=40&md5=4a2cbd0e71b6a46bee467dae2c8e6261},
	author_keywords = {Ethics; Genetics; Society},
	keywords = {Adolescent; Biometric Identification; China; Criminals; DNA; Ethnic Groups; Face; Forensic Genetics; Genetic Privacy; Humans; Law Enforcement; Machine Learning; Male; Minority Groups; Pedigree; Phenotype; Polymorphism, Single Nucleotide; Prejudice; Reproducibility of Results; Safety; United States; DNA; adolescent; anatomy and histology; biometry; China; ethics; ethnic group; face; forensic genetics; genetic privacy; genetics; human; law enforcement; machine learning; male; minority group; offender; pedigree; phenotype; prejudice; procedures; reproducibility; safety; single nucleotide polymorphism; United States},
	publisher = {NLM (Medline)},
	issn = {14764687},
	pmid = {32908260},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Morley20202141,
	author = {Morley, Jessica and Floridi, Luciano and Kinsey, Libby and Elhalal, Anat},
	title = {From What to How: An Initial Review of Publicly Available AI Ethics Tools, Methods and Research to Translate Principles into Practices},
	year = {2020},
	journal = {Science and Engineering Ethics},
	volume = {26},
	number = {4},
	pages = {2141 – 2168},
	doi = {10.1007/s11948-019-00165-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076852860&doi=10.1007%2fs11948-019-00165-5&partnerID=40&md5=98425a80a9904aa733ee35cca41c20c9},
	affiliations = {Oxford Internet Institute, University of Oxford, 1 St Giles’, Oxford, OX1 3JS, United Kingdom; Alan Turing Institute, British Library, 96 Euston Rd, London, NW1 2DB, United Kingdom; Digital Catapult, 101 Euston Road, Kings Cross, London, NW1 2RA, United Kingdom},
	abstract = {The debate about the ethical implications of Artificial Intelligence dates from the 1960s (Samuel in Science, 132(3429):741–742, 1960. https://doi.org/10.1126/science.132.3429.741; Wiener in Cybernetics: or control and communication in the animal and the machine, MIT Press, New York, 1961). However, in recent years symbolic AI has been complemented and sometimes replaced by (Deep) Neural Networks and Machine Learning (ML) techniques. This has vastly increased its potential utility and impact on society, with the consequence that the ethical debate has gone mainstream. Such a debate has primarily focused on principles—the ‘what’ of AI ethics (beneficence, non-maleficence, autonomy, justice and explicability)—rather than on practices, the ‘how.’ Awareness of the potential issues is increasing at a fast rate, but the AI community’s ability to take action to mitigate the associated risks is still at its infancy. Our intention in presenting this research is to contribute to closing the gap between principles and practices by constructing a typology that may help practically-minded developers apply ethics at each stage of the Machine Learning development pipeline, and to signal to researchers where further work is needed. The focus is exclusively on Machine Learning, but it is hoped that the results of this research may be easily applicable to other branches of AI. The article outlines the research method for creating this typology, the initial findings, and provides a summary of future research needs. © 2019, The Author(s).},
	author_keywords = {Applied ethics; Artificial intelligence; Data governance; Digital ethics; Ethics of AI; Governance; Machine learning},
	keywords = {Animals; Artificial Intelligence; Beneficence; Humans; Machine Learning; Research Personnel; Social Justice; animal; artificial intelligence; beneficence; human; machine learning; personnel; social justice},
	correspondence_address = {J. Morley; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles’, OX1 3JS, United Kingdom; email: Jessica.morley@kellogg.ox.ac.uk},
	publisher = {Springer},
	issn = {13533452},
	pmid = {31828533},
	language = {English},
	abbrev_source_title = {Sci. Eng. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 176; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Tanisawa2020969,
	author = {Tanisawa, Kumpei and Wang, Guan and Seto, Jane and Verdouka, Ioanna and Twycross-Lewis, Richard and Karanikolou, Antonia and Tanaka, Masashi and Borjesson, Mats and Di Luigi, Luigi and Dohi, Michiko and Wolfarth, Bernd and Swart, Jeroen and Bilzon, James Lee John and Badtieva, Victoriya and Papadopoulou, Theodora and Casasco, Maurizio and Geistlinger, Michael and Bachl, Norbert and Pigozzi, Fabio and Pitsiladis, Yannis},
	title = {Sport and exercise genomics: The FIMS 2019 consensus statement update},
	year = {2020},
	journal = {British Journal of Sports Medicine},
	volume = {54},
	number = {16},
	pages = {969 – 975},
	doi = {10.1136/bjsports-2019-101532},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082519659&doi=10.1136%2fbjsports-2019-101532&partnerID=40&md5=0ef6c73e6ce1eacd52f8716bdaa740f5},
	affiliations = {Faculty of Sport Sciences, Waseda University, Tokorozawa, Japan; Collaborating Centre of Sports Medicine, University of Brighton, Eastbourne, United Kingdom; Murdoch Children's Research Institute, Parkville, VIC, Australia; Department of Paediatrics, University of Melbourne, Parkville, VIC, Australia; School of Engineering and Materials Science, Queen Mary University of London, London, United Kingdom; Department for Health and Longevity Research, National Institutes of Biomedical Innovation, Health and Nutrition, Tokyo, Japan; Department of Neuroscience and Physiology, Center for Health and Performance, Goteborg University, Göteborg, Sweden; Sahlgrenska University Hospital/Ostra, Göteborg, Sweden; Unit of Endocrinology, Department of Movement, Human and Health Sciences, University of Rome Foro Italico, Rome, Italy; Sport Medical Center, Japan Institute of Sports Sciences, Tokyo, Japan; Department of Sport Medicine, Humboldt University and Charité, University School of Medicine, Berlin, Germany; Uct Research Unit for Exercise Science and Sports Medicine, Cape Town, South Africa; Department for Health, University of Bath, Bath, United Kingdom; I.M. Sechenov First Moscow State Medical University Sechenov University, Ministry of Health of Russia, Moscow, Russian Federation; Moscow Research and Practical Center for Medical Rehabilitation, Restorative and Sports Medicine Moscow Healthcare Department, Moscow, Russian Federation; Defence Medical Rehabilitation Centre, Stanford Hall, Loughborough, United Kingdom; British Association of Sport and Exercise Medicine, Doncaster, United Kingdom; Italian Federation of Sports Medicine (FMSI), Rome, Italy; Unit of International Law, Department of Constitutional, International and European Law, University of Salzburg, Salzburg, Austria; Institute of Sports Science, University of Vienna, Vienna, Austria; Austrian Institute of Sports Medicine, Vienna, Austria; Sport Medicine Unit, Department of Movement Human and Health Sciences, University of Rome Foro Italico, Rome, Italy},
	abstract = {Rapid advances in technologies in the field of genomics such as high throughput DNA sequencing, big data processing by machine learning algorithms and gene-editing techniques are expected to make precision medicine and gene-therapy a greater reality. However, this development will raise many important new issues, including ethical, moral, social and privacy issues. The field of exercise genomics has also advanced by incorporating these innovative technologies. There is therefore an urgent need for guiding references for sport and exercise genomics to allow the necessary advancements in this field of sport and exercise medicine, while protecting athletes from any invasion of privacy and misuse of their genomic information. Here, we update a previous consensus and develop a guiding reference for sport and exercise genomics based on a SWOT (Strengths, Weaknesses, Opportunities and Threats) analysis. This SWOT analysis and the developed guiding reference highlight the need for scientists/clinicians to be well-versed in ethics and data protection policy to advance sport and exercise genomics without compromising the privacy of athletes and the efforts of international sports federations. Conducting research based on the present guiding reference will mitigate to a great extent the risks brought about by inappropriate use of genomic information and allow further development of sport and exercise genomics in accordance with best ethical standards and international data protection principles and policies. This guiding reference should regularly be updated on the basis of new information emerging from the area of sport and exercise medicine as well as from the developments and challenges in genomics of health and disease in general in order to best protect the athletes, patients and all other relevant stakeholders.  © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {genes; genetic testing; genetics},
	keywords = {Exercise; Genetic Privacy; Genomics; Health Policy; Humans; Sports; consensus development; ethics; exercise; genetic privacy; genomics; health care policy; human; physiology; sport},
	correspondence_address = {Y. Pitsiladis; Collaborating Centre of Sports Medicine, University of Brighton, Eastbourne, United Kingdom; email: Y.Pitsiladis@Brighton.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {03063674},
	coden = {BJSMD},
	pmid = {32201388},
	language = {English},
	abbrev_source_title = {Br. J. Sports Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Clark2020,
	author = {Clark, Sierra N and Alli, Abosede S and Brauer, Michael and Ezzati, Majid and Baumgartner, Jill and Toledano, Mireille B and Hughes, Allison F and Nimo, James and Bedford Moses, Josephine and Terkpertey, Solomon and Vallarino, Jose and Agyei-Mensah, Samuel and Agyemang, Ernest and Nathvani, Ricky and Muller, Emily and Bennett, James and Wang, Jiayuan and Beddows, Andrew and Kelly, Frank and Barratt, Benjamin and Beevers, Sean and Arku, Raphael E},
	title = {High-resolution spatiotemporal measurement of air and environmental noise pollution in Sub-Saharan African cities: Pathways to Equitable Health Cities Study protocol for Accra, Ghana},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {8},
	doi = {10.1136/bmjopen-2019-035798},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089769213&doi=10.1136%2fbmjopen-2019-035798&partnerID=40&md5=2b333f47043b2db6885a3b190ba8191d},
	affiliations = {Department of Epidemiology and Biostatistics, Imperial College London, London, United Kingdom; MRC Center for Environment and Health, Imperial College London London, London, United Kingdom; Department of Environmental Health Sciences, University of Massachusetts Amherst, Amherst, MA, United States; School of Population and Public Health, University of British Columbia, Vancouver, BC, Canada; Abdul Latif Jameel Institute for Disease and Emergency Analytics, Imperial College London, London, United Kingdom; Regional Institute for Population Studies, University of Ghana, Legon, Accra, Ghana; Institute for Health and Social Policy, McGill University, Montreal, QC, Canada; Department of Epidemiology Biostatistics, and Occupational Health, McGill University, Montreal, QC, Canada; Department of Physics, University of Ghana, Legon, Accra, Ghana; Department of Environmental Health, Harvard T.H. Chan School of Public Health, Boston, MA, United States; Department of Geography and Resource Development, University of Ghana, Legon, Accra, Ghana; NIHR HPRU in Environmental Exposures and Health, Imperial College London, London, United Kingdom},
	abstract = {Introduction Air and noise pollution are emerging environmental health hazards in African cities, with potentially complex spatial and temporal patterns. Limited local data are a barrier to the formulation and evaluation of policies to reduce air and noise pollution. Methods and analysis We designed a year-long measurement campaign to characterise air and noise pollution and their sources at high-resolution within the Greater Accra Metropolitan Area (GAMA), Ghana. Our design uses a combination of fixed (year-long, n=10) and rotating (week-long, n =∼130) sites, selected to represent a range of land uses and source influences (eg, background, road traffic, commercial, industrial and residential areas, and various neighbourhood socioeconomic classes). We will collect data on fine particulate matter (PM 2.5), nitrogen oxides (NO x), weather variables, sound (noise level and audio) along with street-level time-lapse images. We deploy low-cost, low-power, lightweight monitoring devices that are robust, socially unobtrusive, and able to function in Sub-Saharan African (SSA) climate. We will use state-of-the-art methods, including spatial statistics, deep/machine learning, and processed-based emissions modelling, to capture highly resolved temporal and spatial variations in pollution levels across the GAMA and to identify their potential sources. This protocol can serve as a prototype for other SSA cities. Ethics and dissemination This environmental study was deemed exempt from full ethics review at Imperial College London and the University of Massachusetts Amherst; it was approved by the University of Ghana Ethics Committee (ECH 149/18-19). This protocol is designed to be implementable in SSA cities to map environmental pollution to inform urban planning decisions to reduce health harming exposures to air and noise pollution. It will be disseminated through local stakeholder engagement (public and private sectors), peer-reviewed publications, contribution to policy documents, media, and conference presentations.  © },
	author_keywords = {epidemiology; public health; statistics & research methods},
	keywords = {Air Pollutants; Air Pollution; Cities; Environmental Monitoring; Ghana; Humans; London; Noise; Particulate Matter; nitrogen oxide; air pollution; Article; city planning; environmental health; environmental monitoring; Ghana; health hazard; human; industrial area; machine learning; neighborhood; noise pollution; particulate matter 2.5; public health; public policy; residential area; social class; traffic; weather; air pollutant; city; England; Ghana; noise; particulate matter},
	correspondence_address = {R.E. Arku; Department of Environmental Health Sciences, University of Massachusetts Amherst, Amherst, United States; email: rarku@umass.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {32819940},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Arga2020512,
	author = {Arga, Kazlm Yalçln},
	title = {COVID-19 and the Futures of Machine Learning},
	year = {2020},
	journal = {OMICS A Journal of Integrative Biology},
	volume = {24},
	number = {9},
	pages = {512 – 514},
	doi = {10.1089/omi.2020.0093},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088826906&doi=10.1089%2fomi.2020.0093&partnerID=40&md5=3c815b931894d11784e26279aa09b5ad},
	affiliations = {Department of Bioengineering, Faculty of Engineering, Marmara University, Istanbul, Turkey; Health Institutes of Turkey, Istanbul, Turkey},
	keywords = {Access to Information; Betacoronavirus; Big Data; Biomedical Research; Coronavirus Infections; Humans; Information Dissemination; International Cooperation; Machine Learning; Pandemics; Pneumonia, Viral; Public Health; artificial intelligence; big data; clinical decision making; clinical outcome; coronavirus disease 2019; data analysis; electronic health record; human; machine learning; medical technology; metadata; Note; pandemic; personalized medicine; priority journal; access to information; Betacoronavirus; Coronavirus infection; ethics; information dissemination; international cooperation; machine learning; medical research; pandemic; pathogenicity; pathology; procedures; public health; virus pneumonia},
	correspondence_address = {K.Y. Arga; Department of Bioengineering, Faculty of Engineering, Marmara University, Kadikoy, Istanbul, Building D, Office: 405, 34722, Turkey; email: kazim.arga@marmara.edu.tr},
	publisher = {Mary Ann Liebert Inc.},
	issn = {15362310},
	coden = {OMICA},
	pmid = {32511048},
	language = {English},
	abbrev_source_title = {OMICS J. Integr. Biol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Arenas-Castañeda2020,
	author = {Arenas-Castañeda, Pavel E and Aroca Bisquert, Fuensanta and Martinez-Nicolas, Ismael and Castillo Espíndola, Luis A and Barahona, Igor and Maya-Hernández, Cynthya and Lavana Hernández, Martha Miriam and Manrique Mirón, Paulo César and Alvarado Barrera, Daniela Guadalupe and Treviño Aguilar, Erik and Barrios Núñez, Axayácatl and De Jesus Carlos, Giovanna and Vildosola Garcés, Anabel and Flores Mercado, Josselyne and Barrigon, Maria Luisa and Artes, Antonio and De Leon, Santiago and Molina-Pizarro, Cristian Antonio and Rosado Franco, Arsenio and Perez-Rodriguez, Mercedes and Courtet, Philippe and Martínez-Alés, Gonzalo and Baca-Garcia, Enrique},
	title = {Universal mental health screening with a focus on suicidal behaviour using smartphones in a Mexican rural community: Protocol for the SMART-SCREEN population-based survey},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {7},
	doi = {10.1136/bmjopen-2019-035041},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088352169&doi=10.1136%2fbmjopen-2019-035041&partnerID=40&md5=946ac2eb443cd25a8d6477cee1f79569},
	affiliations = {Secretaría de Salud de la Ciudad de México, Jurisdicción Sanitaria Milpa Alta, Milpa Alta, Mexico; Instituto de Matematicas. Unidad de Cuernavaca. Universidad Nacional Autonoma de Mexico, Cuernavaca, Mexico; CNRS-UMI 4584 - LaSoL Laboratorio Internacional Solomon Lefschetz, Ciudad de Mexico, Mexico; Faculty of Life Sciences, Catholic University of Murcia (UCAM), Murcia, Spain; Hospital General de Milpa Alta, Milpa Alta, Mexico; Cátedra-Conacyt, Instituto de Matemáticas, Unidad de Cuernavaca, Universidad Nacional Autónoma de México, Cuernavaca, Mexico; Center for Evaluation and Surveys Research, National Institute of Public Health (INSP), Cuernavaca, Mexico; Servicios de Salud Del Instituto de Educación Media Superior CDMX, Ciudad de Mexico, Mexico; Unidad de Medicina Familiar ISSSTE, Ciudad de Mexico, Mexico; Psychiatry, Autonomous University of Madrid, Madrid, Spain; Psychiatry, University Hospital Jimenez Diaz Foundation, Madrid, Spain; Department of Signal Theory and Communications, Universidad Carlos III de Madrid, Madrid, Leganés, Spain; CIBERSAM (Centro de Investigacion en Salud Mental), Carlos III Institute of Health, Madrid, Spain; Department of Signal Theory and Communications, Universidad Carlos III de Madrid, Madrid, Spain; Yucatan State Mental Health Institute, Merida, Mexico; Psychiatry, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Department of Emergency Psychiatry and Acute Care, University of Montpellier, Hôpital Lapeyronie, CHU Montpellier, Montpellier, France; Department of Epidemiology, Columbia University Mailman School of Public Health, New York, NY, United States; Universidad Catolica Del Maule, Talca, Chile; CIBERSAM, Madrid, Spain; Department of Psychiatry, Centre Hospitalier Universitaire de Nîmes, Nîmes, France},
	abstract = {Introduction Mental disorders represent the second cause of years lived with disability worldwide. Suicide mortality has been targeted as a key public health concern by the WHO. Smartphone technology provides a huge potential to develop massive and fast surveys. Given the vast cultural diversity of Mexico and its abrupt orography, smartphone-based resources are invaluable in order to adequately manage resources, services and preventive measures in the population. The objective of this study is to conduct a universal suicide risk screening in a rural area of Mexico, measuring also other mental health outcomes such as depression, anxiety and alcohol and substance use disorders. Methods and analysis A population-based cross-sectional study with a temporary sampling space of 9 months will be performed between September 2019 and June 2020. We expect to recruit a large percentage of the target population (at least 70%) in a short-term survey of Milpa Alta Delegation, which accounts for 137 927 inhabitants in a territorial extension of 288 km 2. They will be recruited via an institutional call and a massive public campaign to fill in an online questionnaire through mobile-assisted or computer-assisted web app. This questionnaire will include data on general health, validated questionnaires including Well-being Index 5, Patient Health Questionnaire-9, Generalized Anxiety Disorder Scale 2, Alcohol Use Disorders Identification Test, selected questions of the Drug Abuse Screening Test and Columbia-Suicide Severity Rating Scales and Diagnostic and statistical manual of mental disorders (DSM-5) questions about self-harm. We will take into account information regarding time to mobile app response and geo-spatial location, and aggregated data on social, demographical and environmental variables. Traditional regression modelling, multilevel mixed methods and data-driven machine learning approaches will be used to test hypotheses regarding suicide risk factors at the individual and the population level. Ethics and dissemination Ethical approval (002/2019) was granted by the Ethics Review Board of the Hospital Psiquiátrico Yucatán, Yucatán (Mexico). This protocol has been registered in ClinicalTrials.gov. The starting date of the study is 3 September 2019. Results will serve for the planning and healthcare of groups with greater mental health needs and will be disseminated via publications in peer-reviewed journal and presented at relevant mental health conferences. Trial registration number NCT04067063. © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {health surveys; mass screening; mental health; smartphone; suicidal ideation},
	keywords = {Cross-Sectional Studies; Humans; Internet; Mental Disorders; Mental Health; Mexico; Rural Population; Smartphone; Suicidal Ideation; Suicide; Surveys and Questionnaires; adolescent; adult; aged; Alcohol Use Disorders Identification Test; alcoholism; anxiety disorder; Article; cell phone use; clinical evaluation; clinical trial (topic); cross-sectional study; depression; drug dependence; DSM-5; ecological momentary assessment; generalized anxiety disorder; health care planning; human; mental health; Mexico; mobile application; Patient Health Questionnaire 9; questionnaire; rural area; screening; suicidal behavior; suicidal ideation; Internet; mental disease; mental health; questionnaire; rural population; smartphone; suicidal ideation; suicide},
	correspondence_address = {E. Baca-Garcia; Psychiatry, Autonomous University of Madrid, Madrid, Spain; email: ebacgar2@yahoo.es},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {32690505},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Suver2020,
	author = {Suver, Christine and Thorogood, Adrian and Doerr, Megan and Wilbanks, John and Knoppers, Bartha},
	title = {Bringing code to data: Do not forget governance},
	year = {2020},
	journal = {Journal of Medical Internet Research},
	volume = {22},
	number = {7},
	doi = {10.2196/18087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088847062&doi=10.2196%2f18087&partnerID=40&md5=ec2e607c6387bcfac421086ce67e4d0c},
	affiliations = {Sage Bionetworks, Seattle, WA, United States; Centre of Genomics and Policy, McGill University, Montreal, QC, Canada},
	abstract = {Developing or independently evaluating algorithms in biomedical research is difficult because of restrictions on access to clinical data. Access is restricted because of privacy concerns, the proprietary treatment of data by institutions (fueled in part by the cost of data hosting, curation, and distribution), concerns over misuse, and the complexities of applicable regulatory frameworks. The use of cloud technology and services can address many of the barriers to data sharing. For example, researchers can access data in high performance, secure, and auditable cloud computing environments without the need for copying or downloading. An alternative path to accessing data sets requiring additional protection is the model-to-data approach. In model-to-data, researchers submit algorithms to run on secure data sets that remain hidden. Model-to-data is designed to enhance security and local control while enabling communities of researchers to generate new knowledge from sequestered data. Model-to-data has not yet been widely implemented, but pilots have demonstrated its utility when technical or legal constraints preclude other methods of sharing. We argue that model-to-data can make a valuable addition to our data sharing arsenal, with 2 caveats. First, model-to-data should only be adopted where necessary to supplement rather than replace existing data-sharing approaches given that it requires significant resource commitments from data stewards and limits scientific freedom, reproducibility, and scalability. Second, although model-to-data reduces concerns over data privacy and loss of local control when sharing clinical data, it is not an ethical panacea. Data stewards will remain hesitant to adopt model-to-data approaches without guidance on how to do so responsibly. To address this gap, we explored how commitments to open science, reproducibility, security, respect for data subjects, and research ethics oversight must be re-evaluated in a model-to-data context. © Christine Suver, Adrian Thorogood, Megan Doerr, John Wilbanks, Bartha Knoppers. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 28.07.2020. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included},
	author_keywords = {Data management; Data science; Ethics; Machine learning; Privacy; Research},
	keywords = {Biomedical Research; Cloud Computing; Humans; Information Dissemination; Reproducibility of Results; adult; cloud computing; data science; human; machine learning; privacy; reproducibility; research ethics; respect; review; information dissemination; medical research; procedures},
	correspondence_address = {C. Suver; Sage Bionetworks, Seattle, 2901 Third Avenue, 98121, United States; email: cfsuver@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {32540846},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Park2020627,
	author = {Park, Yurim and Casey, Daniel and Joshi, Indra and Zhu, Jiming and Cheng, Feng},
	title = {Emergence of New Disease: How Can Artificial Intelligence Help?},
	year = {2020},
	journal = {Trends in Molecular Medicine},
	volume = {26},
	number = {7},
	pages = {627 – 629},
	doi = {10.1016/j.molmed.2020.04.007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084605042&doi=10.1016%2fj.molmed.2020.04.007&partnerID=40&md5=8acfbc8d39163231371fbaa119542db0},
	affiliations = {Radcliffe Department of Medicine, Medical Sciences Division, University of Oxford, Oxford, United Kingdom; Innovation Faculty, Celltrion Healthcare, Slough, United Kingdom; Digital Health and Artificial Intelligence Laboratory, National Health Service, London, United Kingdom; Vanke School of Public Health and School of Medicine, Tsinghua University, Beijing, China; Institute for Hospital Management, Tsinghua Shenzhen International Graduate School, Shenzhen, China},
	abstract = {Emergence of new disease remains a critical parameter in human health and society. Advances in artificial intelligence (AI) allow for rapid processing and analysis of massive and complex data. In this forum article, the recent applications across disease prediction and drug development in relation to the COVID-19 pandemic are reviewed. © 2020 Elsevier Ltd},
	author_keywords = {artificial Intelligence; COVID-19; machine learning},
	keywords = {Artificial Intelligence; Betacoronavirus; Communicable Diseases, Emerging; Coronavirus Infections; Humans; Machine Learning; Pandemics; Pneumonia, Viral; antivirus agent; viral protein; virus RNA; accuracy; algorithm; analysis; artificial intelligence; artificial neural network; biotechnology; clinical outcome; coronavirus disease 2019; data analysis; disease risk assessment; drug approval; drug development; drug repositioning; human; machine learning; mathematical model; medical ethics; nonhuman; nucleic acid base substitution; pandemic; pharmacovigilance; prediction; protein structure; RNA sequence; Short Survey; society; structural analysis; virus mutation; virus transmission; virus virulence; Betacoronavirus; communicable disease; Coronavirus infection; pandemic; physiology; virology; virus pneumonia},
	correspondence_address = {Y. Park; Radcliffe Department of Medicine, Medical Sciences Division, University of Oxford, Oxford, United Kingdom; email: yurim.park@st-hugh.ox.ac.uk},
	publisher = {Elsevier Ltd},
	issn = {14714914},
	coden = {TMMRC},
	pmid = {32418724},
	language = {English},
	abbrev_source_title = {Trends Mol. Med.},
	type = {Short survey},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Buchlak20201372,
	author = {Buchlak, Quinlan D. and Esmaili, Nazanin and Leveque, Jean-Christophe and Bennett, Christine and Piccardi, Massimo and Farrokhi, Farrokh},
	title = {Ethical thinking machines in surgery and the requirement for clinical leadership},
	year = {2020},
	journal = {American Journal of Surgery},
	volume = {220},
	number = {5},
	pages = {1372 – 1374},
	doi = {10.1016/j.amjsurg.2020.06.073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088802790&doi=10.1016%2fj.amjsurg.2020.06.073&partnerID=40&md5=1606ec72491da81e5afc7abc1de259ea},
	affiliations = {School of Medicine, The University of Notre Dame Australia, Sydney, NSW, Australia; Department of Medicine, University of Toronto, Toronto, ON, Canada; Faculty of Engineering and IT, University of Technology Sydney, Ultimo, NSW, Australia; Neuroscience Institute, Virginia Mason Medical Center, Seattle, WA, United States},
	keywords = {Clinical Decision-Making; Decision Support Systems, Clinical; Humans; Leadership; Machine Learning; Patient Safety; Specialties, Surgical; Thinking; algorithm; artificial intelligence; cognition; deep neural network; Editorial; empathy; ethics; human; leadership; machine learning; medical specialist; post hoc analysis; priority journal; surgery; surgical risk; wellbeing; clinical decision making; clinical decision support system; patient safety; procedures; surgery; thinking},
	correspondence_address = {Q.D. Buchlak; The University of Notre Dame Australia, Sydney, 160 Oxford St, 2015, Australia; email: quinlan.buchlak1@my.nd.edu.au},
	publisher = {Elsevier Inc.},
	issn = {00029610},
	coden = {AJSUA},
	pmid = {32723487},
	language = {English},
	abbrev_source_title = {Am. J. Surg.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@ARTICLE{Walsh20201144,
	author = {Walsh, Simon L F and Humphries, Stephen M and Wells, Athol U and Brown, Kevin K},
	title = {Imaging research in fibrotic lung disease; applying deep learning to unsolved problems},
	year = {2020},
	journal = {The Lancet Respiratory Medicine},
	volume = {8},
	number = {11},
	pages = {1144 – 1153},
	doi = {10.1016/S2213-2600(20)30003-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090234671&doi=10.1016%2fS2213-2600%2820%2930003-5&partnerID=40&md5=3a59bca20daaf67e63bc42b3e52de58a},
	affiliations = {National Heart and Lung Institute, Imperial College, London, United Kingdom; Quantitative Imaging Laboratory, Department of Radiology, National Jewish Health, Denver, CO, United States; Division of Pulmonary and Critical Care Medicine, National Jewish Health, Denver, CO, United States; Interstitial Lung Disease Unit, Royal Brompton Hospital, London, United Kingdom},
	abstract = {Over the past decade, there has been a groundswell of research interest in computer-based methods for objectively quantifying fibrotic lung disease on high resolution CT of the chest. In the past 5 years, the arrival of deep learning-based image analysis has created exciting new opportunities for enhancing the understanding of, and the ability to interpret, fibrotic lung disease on CT. Specific unsolved problems for which computer-based imaging analysis might provide solutions include the development of reliable methods for assisting with diagnosis, detecting early disease, and predicting disease behaviour using baseline imaging data. However, to harness this technology, technical and societal challenges must be overcome. Large CT datasets will be needed to power the training of deep learning algorithms. Open science research and collaboration between academia and industry must be encouraged. Prospective clinical utility studies will be needed to test computer algorithm performance in real-world clinical settings and demonstrate patient benefit over current best practice. Finally, ethical standards, which ensure patient confidentiality and mitigate against biases in training datasets, that can be encoded in machine-learning systems will be needed as well as bespoke data governance and accountability frameworks to encourage buy-in from health-care professionals, patients, and the public. © 2020 Elsevier Ltd},
	keywords = {Cohort Studies; Databases, Factual; Deep Learning; Female; Forecasting; Humans; Image Interpretation, Computer-Assisted; Machine Learning; Male; Pulmonary Fibrosis; Radiography, Thoracic; Retrospective Studies; Tomography, X-Ray Computed; algorithm; artificial intelligence; computer assisted tomography; deep learning; diagnostic imaging; disease exacerbation; early diagnosis; ethics; fibrosing alveolitis; human; imaging; lung biopsy; lung fibrosis; medical research; patient care; prediction; priority journal; Review; standardization; cohort analysis; computer assisted diagnosis; diagnostic imaging; factual database; female; forecasting; lung fibrosis; machine learning; male; pathology; procedures; retrospective study; thorax radiography; x-ray computed tomography},
	correspondence_address = {S.L.F. Walsh; National Heart and Lung Institute, Imperial College, London, SW3 6LY, United Kingdom; email: s.walsh@imperial.co.uk},
	publisher = {Lancet Publishing Group},
	issn = {22132600},
	pmid = {32109428},
	language = {English},
	abbrev_source_title = {Lancet Respir. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34}
}

@ARTICLE{Ramírez-Cifuentes2020,
	author = {Ramírez-Cifuentes, Diana and Freire, Ana and Baeza-Yates, Ricardo and Puntí, Joaquim and Medina-Bravo, Pilar and Velazquez, Diego Alejandro and Gonfaus, Josep Maria and Gonzàlez, Jordi},
	title = {Detection of suicidal ideation on social media: Multimodal, relational, and behavioral analysis},
	year = {2020},
	journal = {Journal of Medical Internet Research},
	volume = {22},
	number = {7},
	doi = {10.2196/17758},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088158400&doi=10.2196%2f17758&partnerID=40&md5=3127d51515918eb686ecf1650ad1ff48},
	affiliations = {Department of Information and Communication Technologies, Universitat Pompeu Fabra, Carrer de Tànger, 122-140, Barcelona, 08018, Spain; Hospital de Día de Adolescentes, Servicio de Salud Mental, Consorci Corporació Sanitària Parc Taulí, Sabadell, Spain; Departamento de Psicología Clínica y de la Salud, Universitat Autònoma de Barcelona, Barcelona, Spain; Department of Communication, Universitat Pompeu Fabra, Barcelona, Spain; Computer Vision Center, Universitat Autònoma de Barcelona, Bellaterra (Barcelona), Spain; Visual Tagging Services, Bellaterra (Barcelona), Spain},
	abstract = {Background: Suicide risk assessment usually involves an interaction between doctors and patients. However, a significant number of people with mental disorders receive no treatment for their condition due to the limited access to mental health care facilities; the reduced availability of clinicians; the lack of awareness; and stigma, neglect, and discrimination surrounding mental disorders. In contrast, internet access and social media usage have increased significantly, providing experts and patients with a means of communication that may contribute to the development of methods to detect mental health issues among social media users. Objective: This paper aimed to describe an approach for the suicide risk assessment of Spanish-speaking users on social media. We aimed to explore behavioral, relational, and multimodal data extracted from multiple social platforms and develop machine learning models to detect users at risk. Methods: We characterized users based on their writings, posting patterns, relations with other users, and images posted. We also evaluated statistical and deep learning approaches to handle multimodal data for the detection of users with signs of suicidal ideation (suicidal ideation risk group). Our methods were evaluated over a dataset of 252 users annotated by clinicians. To evaluate the performance of our models, we distinguished 2 control groups: users who make use of suicide-related vocabulary (focused control group) and generic random users (generic control group). Results: We identified significant statistical differences between the textual and behavioral attributes of each of the control groups compared with the suicidal ideation risk group. At a 95% CI, when comparing the suicidal ideation risk group and the focused control group, the number of friends (P=.04) and median tweet length (P=.04) were significantly different. The median number of friends for a focused control user (median 578.5) was higher than that for a user at risk (median 372.0). Similarly, the median tweet length was higher for focused control users, with 16 words against 13 words of suicidal ideation risk users. Our findings also show that the combination of textual, visual, relational, and behavioral data outperforms the accuracy of using each modality separately. We defined text-based baseline models based on bag of words and word embeddings, which were outperformed by our models, obtaining an increase in accuracy of up to 8% when distinguishing users at risk from both types of control users. Conclusions: The types of attributes analyzed are significant for detecting users at risk, and their combination outperforms the results provided by generic, exclusively text-based baseline models. After evaluating the contribution of image-based predictive models, we believe that our results can be improved by enhancing the models based on textual and relational features. These methods can be extended and applied to different use cases related to other mental disorders. © Diana Ramírez-Cifuentes, Ana Freire, Ricardo Baeza-Yates, Joaquim Puntí, Pilar Medina-Bravo, Diego Alejandro Velazquez, Josep Maria Gonfaus, Jordi Gonzàlez.},
	author_keywords = {Machine learning; Mental health; Risk assessment; Social media; Suicidal ideation},
	keywords = {Female; Health Behavior; Humans; Male; Risk Assessment; Social Media; Suicidal Ideation; Article; behavior assessment; controlled study; data accuracy; deep learning; friend; human; risk assessment; social media; Spanish (language); statistical analysis; suicidal ideation; vocabulary; writing; ethics; female; health behavior; male; risk assessment; social media},
	correspondence_address = {D. Ramírez-Cifuentes; Department of Information and Communication Technologies, Universitat Pompeu Fabra, Barcelona, Carrer de Tànger, 122-140, 08018, Spain; email: diana.ramirez@upf.edu},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {32673256},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Frismanda2020603,
	author = {Frismanda and Gumelar, Agustinus Bimo and Adi, Derry Pramono and Setiawan, Eman and Widodo, Agung and Sulistyono, My Teguh},
	title = {Machine learning performance comparison for toxic speech classification : Online payday loan scams in Indonesia},
	year = {2020},
	journal = {Proceedings - 2020 International Seminar on Application for Technology of Information and Communication: IT Challenges for Sustainability, Scalability, and Security in the Age of Digital Disruption, iSemantic 2020},
	pages = {603 – 608},
	doi = {10.1109/iSemantic50169.2020.9234259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096825813&doi=10.1109%2fiSemantic50169.2020.9234259&partnerID=40&md5=bc1be9d1c9d1497ad407f5ed648dffe1},
	affiliations = {Fakultas Ilmu Komputer, Universitas Narotama, Surabaya, Indonesia; Faculty of Computer Science, Narotama University, Surabaya, Indonesia; Fakultas Ilmu Komputer, Universitas Dian Nuswantoro, Surabaya, Indonesia},
	abstract = {The recent advancement of Machine Learning (ML) has brought us to many implementations. Online payday loan scam is a phenomenon which interestingly containing toxic speech in conversation. Toxic speech means implying threat toxic speech, offensive language, and hate speech. toxic speech would ultimately trigger such responses, namely loss of work ethic, alienation from the social, even suicidal thought. Despite the unnerving impact of toxic speech, there is still little known research regarding toxic speech, one of them is how to classify toxic speech. This research aims to make a comparison of various ML techniques with the means of classifying toxic speech found in the online payday loan scam phenomenon. For this experiment, we employed Support Vector Machine (SVM), Multi-Layer Perceptron (MLP), Random Forest (RF), and k-Nearest Neighbour (k-NN). All data were taken, filtered, and normalized manually from YouTube. Many reported the incident of online payday loan scam via YouTube in the form of two-way call communication. In total, there are 79 fraud report records converted into.wav files, followed by the feature extraction process using openSMILE, and are classified using machine learning. We get the MLP result which has an acquisition value of 97.9%, below that received SVM 97.2%.  © 2020 IEEE.},
	author_keywords = {multi layer perceptron; online payday loan scam; support vector machine; toxic speech},
	keywords = {Decision trees; E-learning; Learning systems; Multilayer neural networks; Nearest neighbor search; Speech; Wages; Indonesia; K nearest neighbours (k-NN); Multi layer perceptron; Offensive languages; Speech classification; Two ways; Work ethics; YouTube; Support vector machines},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172819068-6},
	language = {English},
	abbrev_source_title = {Proc. - Int. Semin. Appl. Technol. Inf. Commun.: IT Challenges Sustain., Scalability, Secur. Age Digit. Disrupt., iSemantic},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 International Seminar on Application for Technology of Information and Communication, iSemantic 2020; Conference date: 19 September 2020 through 20 September 2020; Conference code: 164507}
}

@ARTICLE{Mortier2020,
	author = {Mortier, Philippe and Vilagut, Gemma and Puértolas Gracia, Beatriz and De Inés Trujillo, Ana and Alayo Bueno, Itxaso and Ballester Coma, Laura and Blasco Cubedo, María Jesús and Cardoner, Narcís and Colls, Cristina and Elices, Matilde and Garcia-Altes, Anna and Gené Badia, Manel and Gómez Sánchez, Javier and Martín Sánchez, Mario and Morros, Rosa and Prat Pubill, Bibiana and Qin, Ping and Mehlum, Lars and Kessler, Ronald C and Palao, Diego and Pérez Sola, Víctor and Alonso, Jordi},
	title = {Catalonia Suicide Risk Code Epidemiology (CSRC-Epi) study: Protocol for a population-representative nested case-control study of suicide attempts in Catalonia, Spain},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {7},
	doi = {10.1136/bmjopen-2020-037365},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088024365&doi=10.1136%2fbmjopen-2020-037365&partnerID=40&md5=6c6f54ea17475f74f2cdc43696542ad0},
	affiliations = {Health Services Research Group, Imim Hospital Del Mar Medical Research Institute, Barcelona, Spain; Ciber Epidemiología y Salud Pública (CIBERESP), Madrid, Spain; Department of Social Psychology, Autonomous University of Barcelona (UAB), Cerdanyola Del Vallès, Barcelona, Spain; Department of Psychology, University of Girona (UdG), Girona, Spain; Department of Health and Experimental Sciences, Pompeu Fabra University (UPF), Barcelona, Spain; Depression and Anxiety Program, Department of Mental Health, Parc Taulí Sabadell, Hospital Universitari, Sabadell, Spain; Department of Psychiatry and Legal Medicine, Universitat Autònoma de Barcelona (UAB), Cerdanyola Del Vallès, Barcelona, Spain; Centro de Investigación en Red de Salud Mental, Cibersam, Madrid, Spain; Institut d'Investigació i Innovació Parc Taulí (I3PT), Sabadell, Barcelona, Spain; Agència de Qualitat i Avaluació Sanitàries de Catalunya, Health Evaluation and Quality Agency of Catalonia (AQuAS), Catalan Health Department, Barcelona, Spain; Neurosciences Research Programme, Imim Hospital Del Mar Medical Research Institute, Barcelona, Spain; Institut d'Investigació Biomèdica (IIB Sant Pau), Barcelona, Spain; Legal Medicine Unit, Faculty of Medicine, University of Barcelona, Barcelona, Spain; Preventive Medicine and Public Health Training Unit PSMar-UPF-ASPB, Parc de Salut Mar, Agència de Salut Pública de Barcelona, Pompeu Fabra University, Barcelona, Spain; Fundacio Inst. Universitari per A la Recerca A l'Atencio Primaria de Salut Jordi Gol i Gurina (IDIAPJGol), Barcelona, Spain; Departament de Farmacologia, De Terapèutica i de Toxicologia, Universitat Autònoma de Barcelona, Barcelona, Spain; Institut Català de la Salut (ICS), Metropolitana Nord, Barcelona, Spain; Master Plan on Mental Health and Addictions, Ministry of Health Catalan Government, Barcelona, Spain; National Centre for Suicide Research and Prevention, Institute of Clinical Medicine, University of Oslo, Oslo, Norway; Department of Health Care Policy, Harvard Medical School, Boston, MA, United States; Institut de Neuropsiquiatria i Addiccions, Hospital Del Mar, Barcelona, Spain},
	abstract = {Introduction Suicide attempts represent an important public health burden. Centralised electronic health record (EHR) systems have high potential to provide suicide attempt surveillance, to inform public health action aimed at reducing risk for suicide attempt in the population, and to provide data-driven clinical decision support for suicide risk assessment across healthcare settings. To exploit this potential, we designed the Catalonia Suicide Risk Code Epidemiology (CSRC-Epi) study. Using centralised EHR data from the entire public healthcare system of Catalonia, Spain, the CSRC-Epi study aims to estimate reliable suicide attempt incidence rates, identify suicide attempt risk factors and develop validated suicide attempt risk prediction tools. Methods and analysis The CSRC-Epi study is registry-based study, specifically, a two-stage exposure-enriched nested case-control study of suicide attempts during the period 2014-2019 in Catalonia, Spain. The primary study outcome consists of first and repeat attempts during the observation period. Cases will come from a case register linked to a suicide attempt surveillance programme, which offers in-depth psychiatric evaluations to all Catalan residents who present to clinical care with any suspected risk for suicide. Predictor variables will come from centralised EHR systems representing all relevant healthcare settings. The study's sampling frame will be constructed using population-representative administrative lists of Catalan residents. Inverse probability weights will restore representativeness of the original population. Analysis will include the calculation of age-standardised and sex-standardised suicide attempt incidence rates. Logistic regression will identify suicide attempt risk factors on the individual level (ie, relative risk) and the population level (ie, population attributable risk proportions). Machine learning techniques will be used to develop suicide attempt risk prediction tools. Ethics and dissemination This protocol is approved by the Parc de Salut Mar Clinical Research Ethics Committee (2017/7431/I). Dissemination will include peer-reviewed scientific publications, scientific reports for hospital and government authorities, and updated clinical guidelines. Trial registration number NCT04235127.  © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {epidemiology; mental health; psychiatry; public health; statistics & research methods; suicide & self-harm},
	keywords = {Case-Control Studies; Humans; Risk; Risk Factors; Spain; Suicidal Ideation; Suicide, Attempted; Article; case control study; human; incidence; machine learning; mortality; predictor variable; risk assessment; risk factor; Spain; suicide attempt; epidemiology; risk; Spain; suicidal ideation},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {32660952},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Handfield2020803,
	author = {Handfield, Robert and Sun, Hang and Rothenberg, Lori},
	title = {Assessing supply chain risk for apparel production in low cost countries using newsfeed analysis},
	year = {2020},
	journal = {Supply Chain Management},
	volume = {25},
	number = {6},
	pages = {803 – 821},
	doi = {10.1108/SCM-11-2019-0423},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086019648&doi=10.1108%2fSCM-11-2019-0423&partnerID=40&md5=ea8da7f96e7056ed89a4690efcaad0e1},
	affiliations = {Department of Business Management, North Carolina State University, Raleigh, NC, United States; Poole College of Management, North Carolina State University, Raleigh, NC, United States; Wilson College of Textiles, North Carolina State University, Raleigh, NC, United States},
	abstract = {Purpose: With the growth of unstructured data, opportunities to generate insights into supply chain risks in low cost countries (LCCs) are emerging. Sourcing risk has primarily focused on short-term mitigation. This paper aims to offer an approach that uses newsfeed data to assess regional supply base risk in LCC’s for the apparel sector, which managers can use to plan for future risk on a long-term planning horizon. Design/methodology/approach: This paper demonstrates that the bulk of supplier risk assessments focus on short-term responses to disruptions in developed countries, revealing a gap in assessments of long-term risks for supply base expansion in LCCs. This paper develops an approach for predicting and planning for long-term supply base risk in LCC’s to address this shortfall. A machine-based learning algorithm is developed that uses the analysis of competing hypotheses heuristic to convert data from multiple news feeds into numerical risk scores and visual maps of supply chain risk. This paper demonstrates the approach by converting large amounts of unstructured data into two measures, risk impact and risk probability, leading to visualization of country-level supply base risks for a global apparel company. Findings: This paper produced probability and impact scores for 23 distinct supply base risks across 10 countries in the apparel sector. The results suggest that the most significant long-term risks of supply disruption for apparel in LCC’s are human resource regulatory risks, workplace issues, inflation costs, safety violations and social welfare violations. The results suggest that apparel brands seeking suppliers in the regions of Cambodia, India, Bangladesh, Brazil and Vietnam should be aware of the significant risks in these regions that may require mitigative action. Originality/value: This approach establishes a novel approach for objectively projecting future global sourcing risk, and yields visually mapped outcomes that can be applied in forecasting and planning for future risks when considering sourcing locations in LCC’s. © 2020, Emerald Publishing Limited.},
	author_keywords = {Buyer-seller relationships; Industrial purchasing; Machine learning; Supplier relationships; Supply base risk analysis; Supply chain disruptions; Supply chain ethics; Supply chain risk; Supply risk; Sustainability},
	correspondence_address = {R. Handfield; Department of Business Management, North Carolina State University, Raleigh, United States; email: rbhandfi@ncsu.edu},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {13598546},
	language = {English},
	abbrev_source_title = {Supply Chain Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@ARTICLE{Filho2020579,
	author = {Filho, Erito Marques de Souza and Fernandes, Fernando de Amorim and Pereira, Nikolas Cunha de Assis and Mesquita, Claudio Tinoco and Gismondi, Ronaldo Altenburg},
	title = {Ethics, artificial intelligence and cardiology; [Ética, inteligência artificial e cardiologia]},
	year = {2020},
	journal = {Arquivos Brasileiros de Cardiologia},
	volume = {115},
	number = {3},
	pages = {579 – 583},
	doi = {10.36660/abc.20200143},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091994761&doi=10.36660%2fabc.20200143&partnerID=40&md5=bfb39315655630b8e23f397e615559ad},
	affiliations = {Pós-graduação em Ciências Cardiovasculares da Universidade Federal Fluminense, Niterói, RJ, Brazil; Universidade Federal Rural do Rio de Janeiro-Departamento de Tecnologias e Linguagens, Nova Iguaçu, RJ, Brazil; Setor de Medicina Nuclear do Serviço de Radiologia do Hospital Universitário Antônio Pedro, (EBESERH-HUAP-UFF), Niterói, RJ, Brazil; Hospital Niterói D´or, Niterói, RJ, Brazil},
	author_keywords = {Artificial intelligence; Decision making,compter-assisted; Information management; Software},
	keywords = {Algorithms; Artificial Intelligence; Cardiology; acute heart infarction; artificial intelligence; cardiology; cardiovascular risk; clinical practice; computed tomographic angiography; decision making; electrocardiography monitoring; health care personnel; human; machine learning; mathematical model; Note; phenotype; algorithm},
	correspondence_address = {E.M.S. Filho; Pós-graduação em Ciências Cardiovasculares da Universidade Federal Fluminense, Niterói, Brazil; email: mederitomarques@gmail.com; E.M.S. Filho; Universidade Federal Rural do Rio de Janeiro-Departamento de Tecnologias e Linguagens, Nova Iguaçu, Brazil; email: mederitomarques@gmail.com; ; },
	publisher = {Arquivos Brasileiros de Cardiologia},
	issn = {0066782X},
	coden = {ABCAA},
	pmid = {33027384},
	language = {English},
	abbrev_source_title = {Arq. Bras. Cardiol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Fiske202032,
	author = {Fiske, Amelia and Tigard, Daniel and Müller, Ruth and Haddadin, Sami and Buyx, Alena and McLennan, Stuart},
	title = {Embedded Ethics Could Help Implement the Pipeline Model Framework for Machine Learning Healthcare Applications},
	year = {2020},
	journal = {American Journal of Bioethics},
	volume = {20},
	number = {11},
	pages = {32 – 35},
	doi = {10.1080/15265161.2020.1820101},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094630751&doi=10.1080%2f15265161.2020.1820101&partnerID=40&md5=0891a65fc15c89428ee52d67b52cced5},
	affiliations = {Technical University of Munich, Germany; University of Basel, Switzerland},
	keywords = {Delivery of Health Care; Humans; Machine Learning; Morals; health care delivery; human; machine learning; morality},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33103978},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Akinosho2020,
	author = {Akinosho, Taofeek D. and Oyedele, Lukumon O. and Bilal, Muhammad and Ajayi, Anuoluwapo O. and Delgado, Manuel Davila and Akinade, Olugbenga O. and Ahmed, Ashraf A.},
	title = {Deep learning in the construction industry: A review of present status and future innovations},
	year = {2020},
	journal = {Journal of Building Engineering},
	volume = {32},
	doi = {10.1016/j.jobe.2020.101827},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092169429&doi=10.1016%2fj.jobe.2020.101827&partnerID=40&md5=7a267a7a37c7290f959f6d2bec0649cb},
	affiliations = {Big Data Enterprise and Artificial Intelligence Laboratory (Big-DEAL), Bristol Business School, University of West of the England, Bristol, United Kingdom; Department of Civil and Environmental Engineering, Brunel University London, Kingston Lane, Uxbridge, United Kingdom},
	abstract = {The construction industry is known to be overwhelmed with resource planning, risk management and logistic challenges which often result in design defects, project delivery delays, cost overruns and contractual disputes. These challenges have instigated research in the application of advanced machine learning algorithms such as deep learning to help with diagnostic and prescriptive analysis of causes and preventive measures. However, the publicity created by tech firms like Google, Facebook and Amazon about Artificial Intelligence and applications to unstructured data is not the end of the field. There abound many applications of deep learning, particularly within the construction sector in areas such as site planning and management, health and safety and construction cost prediction, which are yet to be explored. The overall aim of this article was to review existing studies that have applied deep learning to prevalent construction challenges like structural health monitoring, construction site safety, building occupancy modelling and energy demand prediction. To the best of our knowledge, there is currently no extensive survey of the applications of deep learning techniques within the construction industry. This review would inspire future research into how best to apply image processing, computer vision, natural language processing techniques of deep learning to numerous challenges in the industry. Limitations of deep learning such as the black box challenge, ethics and GDPR, cybersecurity and cost, that can be expected by construction researchers and practitioners when adopting some of these techniques were also discussed. © 2020 The Author(s)},
	author_keywords = {Autoencoders; Construction industry; Convolutional neural networks; Deep learning; Generative adversarial networks},
	keywords = {Construction industry; Image processing; Learning algorithms; Learning systems; Natural language processing systems; Project management; Risk management; Safety engineering; Security of data; Structural health monitoring; Construction costs; Construction sectors; Construction site safety; Contractual disputes; Energy demand prediction; Learning techniques; NAtural language processing; Preventive measures; Deep learning},
	correspondence_address = {L.O. Oyedele; Big Data Enterprise and Artificial Intelligence Laboratory (Big-DEAL), Bristol Business School, University of West of England, Bristol, Frenchay Campus, Coldharbour Lane, BS16 1QY, United Kingdom; email: Ayolook2001@yahoo.co.uk},
	publisher = {Elsevier Ltd},
	issn = {23527102},
	language = {English},
	abbrev_source_title = {J. Build. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 121; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Morley2020,
	author = {Morley, Jessica and Machado, Caio C.V. and Burr, Christopher and Cowls, Josh and Joshi, Indra and Taddeo, Mariarosaria and Floridi, Luciano},
	title = {The ethics of AI in health care: A mapping review},
	year = {2020},
	journal = {Social Science and Medicine},
	volume = {260},
	doi = {10.1016/j.socscimed.2020.113172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088128904&doi=10.1016%2fj.socscimed.2020.113172&partnerID=40&md5=f645dfbabca91490a89853d9a6eae9aa},
	affiliations = {Oxford Internet Institute, University of Oxford, 1 St Giles, Oxford, OX1 3JS, United Kingdom; Alan Turing Institute, British Library, 96 Euston Rd, London, NW1 2DB, United Kingdom; Department of Computer Science, University of Oxford, 15 Parks Rd, Oxford, OX1 3QD, United Kingdom; NHSX, Skipton House, 80 London Road, SE1 6LH, United Kingdom},
	abstract = {This article presents a mapping review of the literature concerning the ethics of artificial intelligence (AI) in health care. The goal of this review is to summarise current debates and identify open questions for future research. Five literature databases were searched to support the following research question: how can the primary ethical risks presented by AI-health be categorised, and what issues must policymakers, regulators and developers consider in order to be ‘ethically mindful? A series of screening stages were carried out—for example, removing articles that focused on digital health in general (e.g. data sharing, data access, data privacy, surveillance/nudging, consent, ownership of health data, evidence of efficacy)—yielding a total of 156 papers that were included in the review. We find that ethical issues can be (a) epistemic, related to misguided, inconclusive or inscrutable evidence; (b) normative, related to unfair outcomes and transformative effectives; or (c) related to traceability. We further find that these ethical issues arise at six levels of abstraction: individual, interpersonal, group, institutional, and societal or sectoral. Finally, we outline a number of considerations for policymakers and regulators, mapping these to existing literature, and categorising each as epistemic, normative or traceability-related and at the relevant level of abstraction. Our goal is to inform policymakers, regulators and developers of what they must consider if they are to enable health and care systems to capitalise on the dual advantage of ethical AI; maximising the opportunities to cut costs, improve care, and improve the efficiency of health and care systems, whilst proactively avoiding the potential harms. We argue that if action is not swiftly taken in this regard, a new ‘AI winter’ could occur due to chilling effects related to a loss of public trust in the benefits of AI for health care. © 2020 Elsevier Ltd},
	author_keywords = {Artificial intelligence; Ethics; Health policies; Healthcare; Machine learning},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Morals; Ownership; Privacy; artificial intelligence; database; ethics; health care; artificial intelligence; cold stress; ethics; health care policy; human; machine learning; privacy; review; systematic review; trust; winter; health care delivery; morality; organization and management},
	correspondence_address = {J. Morley; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles, OX1 3JS, United Kingdom; email: jessica.morley@oii.ox.ac.uk},
	publisher = {Elsevier Ltd},
	issn = {02779536},
	coden = {SSMDE},
	pmid = {32702587},
	language = {English},
	abbrev_source_title = {Soc. Sci. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 127}
}

@BOOK{Riel2020246,
	author = {Riel, Jeremy},
	title = {Essential features and critical issues with educational chatbots: Toward personalized learning via digital agents},
	year = {2020},
	journal = {Handbook of Research on Modern Educational Technologies, Applications, and Management (2 Vol.)},
	pages = {246 – 262},
	doi = {10.4018/978-1-7998-3476-2.ch015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85121294435&doi=10.4018%2f978-1-7998-3476-2.ch015&partnerID=40&md5=d61e8c1d25626ec3a7af8481828a8091},
	affiliations = {Faculty Assistance Center for Technology, University of Illinois, Chicago, United States},
	abstract = {Conversational agents, also known as chatbots, are automated systems for engaging in two-way dialogue with human users. These systems have existed in one form or another for at least 60 years but have recently demonstrated significant potential with advances in machine learning and artificial intelligence technologies. The use of conversational agents or chatbots for education can potentially reduce costs and supplement teacher instruction in transformative ways for formal learning. This chapter examines the design and status of chatbots and conversational agents for educational purposes. Common design functions and goals of educational chatbots are described, along with current practical applications of chatbots for educational purposes. Finally, this chapter considers issues about pedagogical commitments, ethics, and equity to suggest future work in the field. © 2021, IGI Global.},
	publisher = {IGI Global},
	isbn = {978-179983477-9; 978-179983476-2},
	language = {English},
	abbrev_source_title = {Handb. of Res. on Mod. Educ. Technol., Appl., and Manag. (2 Vol.)},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Bærøe202048,
	author = {Bærøe, Kristine and Jansen, Maarten and Kerasidou, Angeliki},
	title = {Machine Learning in Healthcare: Exceptional Technologies Require Exceptional Ethics},
	year = {2020},
	journal = {American Journal of Bioethics},
	volume = {20},
	number = {11},
	pages = {48 – 51},
	doi = {10.1080/15265161.2020.1820103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094649232&doi=10.1080%2f15265161.2020.1820103&partnerID=40&md5=acc01dff3bec0a3c65a1ef236fb805b5},
	affiliations = {University of Bergen, Norway; Radboud University Nijmegen, Netherlands; University of Oxford, United Kingdom},
	keywords = {Delivery of Health Care; Humans; Machine Learning; Morals; health care delivery; human; machine learning; morality},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33103974},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Cowgill2020679,
	author = {Cowgill, Bo and Dell'acqua, Fabrizio and Deng, Samuel and Hsu, Daniel and Verma, Nakul and Chaintreau, Augustin},
	title = {Biased Programmers? or Biased Data? A Field Experiment in Operationalizing AI Ethics},
	year = {2020},
	journal = {EC 2020 - Proceedings of the 21st ACM Conference on Economics and Computation},
	pages = {679 – 681},
	doi = {10.1145/3391403.3399545},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089283815&doi=10.1145%2f3391403.3399545&partnerID=40&md5=3d498e25540c24f42946ea9fc17594fc},
	affiliations = {Columbia University, New York, United States},
	abstract = {Why do biased algorithmic predictions arise, and what interventions can prevent them? We examine this topic with a field experiment about using machine learning to predict human capital. We randomly assign approximately 400 AI engineers to develop software under different experimental conditions to predict standardized test scores of OECD residents. We then assess the resulting predictive algorithms using the realized test performances, and through randomized audit-like manipulations of algorithmic inputs. We also used the diversity of our subject population to measure whether demographically non-traditional engineers were more likely to notice and reduce algorithmic bias, and whether algorithmic prediction errors are correlated within programmer demographic groups. This document describes our experimental design and motivation; the full results of our experiment are available at https://ssrn.com/abstract=3615404. © 2020 Owner/Author.},
	author_keywords = {algorithmic fairness; field experiment},
	keywords = {Forecasting; Population statistics; Software testing; Algorithmic prediction; Demographic groups; Experimental conditions; Field experiment; Non-traditional; Predictive algorithms; Standardized tests; Test performance; Design of experiments},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037975-5},
	language = {English},
	abbrev_source_title = {EC - Proc. ACM Conf. Econ. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; Conference name: 21st ACM Conference on Economics and Computation, EC 2020; Conference date: 13 July 2020 through 17 July 2020; Conference code: 161741; All Open Access, Green Open Access}
}

@ARTICLE{Goodman202026,
	author = {Goodman, Kenneth W.},
	title = {Ethics in Health Informatics},
	year = {2020},
	journal = {Yearbook of medical informatics},
	volume = {29},
	number = {1},
	pages = {26 – 31},
	doi = {10.1055/s-0040-1701966},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089800959&doi=10.1055%2fs-0040-1701966&partnerID=40&md5=c2db29c77feda273ef9056994b62e9ef},
	affiliations = {Institute for Bioethics and Health Policy, University of Miami Miller School of Medicine, Miami, United States},
	abstract = {Contemporary bioethics was fledged and is sustained by challenges posed by new technologies. These technologies have affected many lives. Yet health informatics affects more lives than any of them. The challenges include the development and the appropriate uses and users of machine learning software, the balancing of privacy rights against the needs of public health and clinical practice in a time of Big Data analytics, whether and how to use this technology, and the role of ethics and standards in health policy. Historical antecedents in statistics and evidence-based practice foreshadow some of the difficulties now faced, but the scope and scale of these challenges requires that ethics, too, be brought to scale in parallel, especially given the size of contemporary data sets and the processing power of new computers. Fortunately, applied ethics affords a variety of tools to help identify and rank applicable values, support best practices, and contribute to standards. The bioethics community can in partnership with the informatics community arrive at policies that promote the health sciences while reaffirming the many and varied rights that patients expect will be honored. Georg Thieme Verlag KG Stuttgart.},
	keywords = {Artificial Intelligence; Big Data; Bioethical Issues; Confidentiality; Humans; Information Dissemination; Learning Health System; Medical Informatics; Privacy; Public Policy; artificial intelligence; bioethics; confidentiality; ethics; human; information dissemination; medical informatics; privacy; public policy},
	publisher = {NLM (Medline)},
	issn = {23640502},
	pmid = {32303095},
	language = {English},
	abbrev_source_title = {Yearb Med Inform},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Schwendicke2020769,
	author = {Schwendicke, F. and Samek, W. and Krois, J.},
	title = {Artificial Intelligence in Dentistry: Chances and Challenges},
	year = {2020},
	journal = {Journal of Dental Research},
	volume = {99},
	number = {7},
	pages = {769 – 774},
	doi = {10.1177/0022034520915714},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084049434&doi=10.1177%2f0022034520915714&partnerID=40&md5=7023164b90ca61d27bd76d52880ecf97},
	affiliations = {Department of Operative and Preventive Dentistry, Charité – Universitätsmedizin Berlin, Berlin, Germany; Department of Video Coding and Analytics, Fraunhofer Heinrich Hertz Institute, Berlin, Germany},
	abstract = {The term “artificial intelligence” (AI) refers to the idea of machines being capable of performing human tasks. A subdomain of AI is machine learning (ML), which “learns” intrinsic statistical patterns in data to eventually cast predictions on unseen data. Deep learning is a ML technique using multi-layer mathematical operations for learning and inferring on complex data like imagery. This succinct narrative review describes the application, limitations and possible future of AI-based dental diagnostics, treatment planning, and conduct, for example, image analysis, prediction making, record keeping, as well as dental research and discovery. AI-based applications will streamline care, relieving the dental workforce from laborious routine tasks, increasing health at lower costs for a broader population, and eventually facilitate personalized, predictive, preventive, and participatory dentistry. However, AI solutions have not by large entered routine dental practice, mainly due to 1) limited data availability, accessibility, structure, and comprehensiveness, 2) lacking methodological rigor and standards in their development, 3) and practical questions around the value and usefulness of these solutions, but also ethics and responsibility. Any AI application in dentistry should demonstrate tangible value by, for example, improving access to and quality of care, increasing efficiency and safety of services, empowering and enabling patients, supporting medical research, or increasing sustainability. Individual privacy, rights, and autonomy need to be put front and center; a shift from centralized to distributed/federated learning may address this while improving scalability and robustness. Lastly, trustworthiness into, and generalizability of, dental AI solutions need to be guaranteed; the implementation of continuous human oversight and standards grounded in evidence-based dentistry should be expected. Methods to visualize, interpret, and explain the logic behind AI solutions will contribute (“explainable AI”). Dental education will need to accompany the introduction of clinical AI solutions by fostering digital literacy in the future dental workforce. © The Author(s) 2020.},
	author_keywords = {decision-making; deep learning; dental; diagnostic systems; informatics; machine learning},
	keywords = {Artificial Intelligence; Dentistry; Forecasting; Humans; Image Processing, Computer-Assisted; artificial intelligence; dentistry; forecasting; human; image processing},
	correspondence_address = {F. Schwendicke; Department of Operative and Preventive Dentistry, Charité – Universitätsmedizin Berlin, Germany; email: falk.schwendicke@charite.de},
	publisher = {SAGE Publications Inc.},
	issn = {00220345},
	coden = {JDREA},
	pmid = {32315260},
	language = {English},
	abbrev_source_title = {J. Dent. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 185; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kalluri2020169,
	author = {Kalluri, Pratyusha},
	title = {Don't ask if artificial intelligence is good or fair, ask how it shifts power},
	year = {2020},
	journal = {Nature},
	volume = {583},
	number = {7815},
	pages = {169},
	doi = {10.1038/d41586-020-02003-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087724296&doi=10.1038%2fd41586-020-02003-2&partnerID=40&md5=b1e0ee238edcee30e0516bb0382d2569},
	author_keywords = {Ethics; Research data; Research management; Society},
	keywords = {Congresses as Topic; Empowerment; Humans; Machine Learning; Power, Psychological; Social Dominance; Vulnerable Populations; empowerment; human; machine learning; organization; social dominance; vulnerable population},
	publisher = {NLM (Medline)},
	issn = {14764687},
	pmid = {32636520},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 86}
}

@ARTICLE{McCradden202040,
	author = {McCradden, Melissa D. and Anderson, James A. and Zlotnik Shaul, Randi},
	title = {Accountability in the Machine Learning Pipeline: The Critical Role of Research Ethics Oversight},
	year = {2020},
	journal = {American Journal of Bioethics},
	volume = {20},
	number = {11},
	pages = {40 – 42},
	doi = {10.1080/15265161.2020.1820111},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094643803&doi=10.1080%2f15265161.2020.1820111&partnerID=40&md5=cc4a4ade7685be987e0c581cf7455779},
	affiliations = {The Hospital for Sick Children, Canada},
	keywords = {Ethics Committees, Research; Ethics, Research; Humans; Machine Learning; Social Responsibility; human; machine learning; professional standard; research ethics; social responsibility},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33103980},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{McLennan202020,
	author = {McLennan, Stuart and Lee, Meredith M. and Fiske, Amelia and Celi, Leo Anthony},
	title = {AI Ethics Is Not a Panacea},
	year = {2020},
	journal = {American Journal of Bioethics},
	volume = {20},
	number = {11},
	pages = {20 – 22},
	doi = {10.1080/15265161.2020.1819470},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094659085&doi=10.1080%2f15265161.2020.1819470&partnerID=40&md5=04ffd692ef612de51f4477f7cff1cbc7},
	affiliations = {Technical University of Munich, Germany; University of Basel, Switzerland; UC Berkeley Division of Computing, Data Science, and Society, United States; Beth Israel Deaconess Medical Center, United States; Harvard–Massachusetts Institute of Technology, United States; Harvard T.H. Chan School of Public Health, United States},
	keywords = {Humans; Machine Learning; Morals; human; machine learning; morality},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33103983},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@CONFERENCE{Figueiredo2020151,
	author = {Figueiredo, Flavio and Giori, Felipe and Soares, Guilherme and Arantes, Mariana and Almeida, Jussara M. and Benevenuto, Fabricio},
	title = {Understanding targeted video-ads in children's content},
	year = {2020},
	journal = {Proceedings of the 31st ACM Conference on Hypertext and Social Media, HT 2020},
	pages = {151 – 160},
	doi = {10.1145/3372923.3404787},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089475880&doi=10.1145%2f3372923.3404787&partnerID=40&md5=4ec036c606c7373fb564dfaa7cb2ba8a},
	affiliations = {Universidade Federal de Minas Gerais, Belo Horizonte, Brazil},
	abstract = {As the volume of online video entertainment via streaming increases, ever so more are users targeted by online advertisement algorithms. Nevertheless, this rise in targeting and revenue does not come without any concerns. That is, even though the online advertising business model has is very successful, nowadays, rising societal concerns regarding the ethics and extent to which such algorithms agree with the laws of different countries are also present. Motivated by the dichotomy above, we here explore how targeted video-ads meet the regulatory policies regarding children advertising in Brazil and Canada. To perform our study, we create synthetic user personas that watch YouTube videos daily. Our personas are tailored to stream children's content while controlling for several variables (e.g., gender, country, and type of content streamed). With the data gathered, our analyses reveal statistical evidence of algorithmic targeting in videos geared towards children. Also, some of the advertised products (e.g., alcoholic beverages and fast-food) go directly against the regulations of the studied countries. With advertisements being matched to users by machine learning algorithms, it is impossible to state whether regulations are not followed on purpose (e.g., advertisers gaming the system). Nevertheless, our findings and discussion do raise a flag that regulations may not be sufficient, and content providers may still need to audit systems to meet the regulations. © 2020 ACM.},
	author_keywords = {Advertising; Children; Ethics and law; Video streaming},
	keywords = {Alcoholic beverages; Hypertext systems; Learning algorithms; Machine learning; Marketing; Social networking (online); Business modeling; Content providers; Online advertisements; Online advertising; Regulatory policies; Several variables; Societal concerns; Statistical evidence; Laws and legislation},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145037098-1},
	language = {English},
	abbrev_source_title = {Proc. ACM Conf. Hypertext Soc. Media, HT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 31st ACM Conference on Hypertext and Social Media, HT 2020; Conference date: 13 July 2020 through 15 July 2020; Conference code: 161736}
}

@ARTICLE{DiCenzo20205798,
	author = {DiCenzo, Daniel and Quiaoit, Karina and Fatima, Kashuf and Bhardwaj, Divya and Sannachi, Lakshmanan and Gangeh, Mehrdad and Sadeghi-Naini, Ali and Dasgupta, Archya and Kolios, Michael C. and Trudeau, Maureen and Gandhi, Sonal and Eisen, Andrea and Wright, Frances and Look Hong, Nicole and Sahgal, Arjun and Stanisz, Greg and Brezden, Christine and Dinniwell, Robert and Tran, William T. and Yang, Wei and Curpen, Belinda and Czarnota, Gregory J.},
	title = {Quantitative ultrasound radiomics in predicting response to neoadjuvant chemotherapy in patients with locally advanced breast cancer: Results from multi-institutional study},
	year = {2020},
	journal = {Cancer Medicine},
	volume = {9},
	number = {16},
	pages = {5798 – 5806},
	doi = {10.1002/cam4.3255},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087203638&doi=10.1002%2fcam4.3255&partnerID=40&md5=b9acb1e71d037f5ba6b65d247c964287},
	affiliations = {Department of Radiation Oncology, Sunnybrook Health Sciences Centre, Toronto, ON, Canada; Department of Radiation Oncology, University of Toronto, Toronto, ON, Canada; Physical Sciences, Sunnybrook Research Institute, Toronto, ON, Canada; Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada; Department of Electrical Engineering and Computer Sciences, Lassonde School of Engineering, York University, Toronto, ON, Canada; Department of Physics, Ryerson University, Toronto, ON, Canada; Medical Oncology, Department of Medicine, Sunnybrook Health Sciences Centre, Toronto, ON, Canada; Department of Medicine, University of Toronto, Toronto, ON, Canada; Surgical Oncology, Department of Surgery, Sunnybrook Health Sciences Centre, Toronto, ON, Canada; Department of Surgery, University of Toronto, Toronto, ON, Canada; Medical Oncology, Saint Michael's Hospital, University of Toronto, Toronto, ON, Canada; Department of Radiation Oncology, Princess Margaret Hospital, University Health Network, Toronto, ON, Canada; Radiation Oncology, London Health Sciences Centre, London, ON, Canada; Department of Oncology, Schulich School of Medicine and Dentistry, Western University, London, ON, Canada; Evaluative Clinical Sciences, Sunnybrook Research Institute, Toronto, ON, Canada; Department of Diagnostic Radiology, University of Texas, Houston, TX, United States; Department of Medical Imaging, Sunnybrook Health Sciences Centre, Toronto, ON, Canada; Department of Medical Imaging, University of Toronto, Toronto, ON, Canada},
	abstract = {Background: This study was conducted in order to develop a model for predicting response to neoadjuvant chemotherapy (NAC) in patients with locally advanced breast cancer (LABC) using pretreatment quantitative ultrasound (QUS) radiomics. Methods: This was a multicenter study involving four sites across North America, and appropriate approval was obtained from the individual ethics committees. Eighty-two patients with LABC were included for final analysis. Primary tumors were scanned using a clinical ultrasound system before NAC was started. The tumors were contoured, and radiofrequency data were acquired and processed from whole tumor regions of interest. QUS spectral parameters were derived from the normalized power spectrum, and texture analysis was performed based on six QUS features using a gray level co-occurrence matrix. Patients were divided into responder or nonresponder classes based on their clinical-pathological response. Classification analysis was performed using machine learning algorithms, which were trained to optimize classification accuracy. Cross-validation was performed using a leave-one-out cross-validation method. Results: Based on the clinical outcomes of NAC treatment, there were 48 responders and 34 nonresponders. A K-nearest neighbors (K-NN) approach resulted in the best classifier performance, with a sensitivity of 91%, a specificity of 83%, and an accuracy of 87%. Conclusion: QUS-based radiomics can predict response to NAC based on pretreatment features with acceptable accuracy. © 2020 The Authors. Cancer Medicine published by John Wiley & Sons Ltd.},
	author_keywords = {imaging biomarker; locally advanced breast cancer; machine learning; neoadjuvant chemotherapy; quantitative ultrasound; radiomics; response prediction; texture analysis},
	keywords = {Adult; Aged; Algorithms; Antineoplastic Combined Chemotherapy Protocols; Breast Neoplasms; Canada; Chemotherapy, Adjuvant; Female; Humans; Machine Learning; Male; Middle Aged; Neoadjuvant Therapy; Prospective Studies; Sensitivity and Specificity; Treatment Outcome; Ultrasonography; United States; cyclophosphamide; docetaxel; doxorubicin; epirubicin; fluorouracil; paclitaxel; trastuzumab; antineoplastic agent; adult; advanced cancer; aged; Article; B scan; breast cancer; cancer classification; cancer hormone therapy; cancer radiotherapy; echography; estrogen receptor positive breast cancer; female; human; human epidermal growth factor receptor 2 positive breast cancer; k nearest neighbor; machine learning; major clinical study; male; multicenter study; neoadjuvant chemotherapy; North America; observational study; prediction; priority journal; prospective study; quantitative analysis; radiomics; response evaluation criteria in solid tumors; sensitivity and specificity; treatment outcome; treatment response; triple negative breast cancer; validation study; adjuvant chemotherapy; algorithm; breast tumor; Canada; clinical trial; diagnostic imaging; echography; middle aged; neoadjuvant therapy; pathology; procedures; United States},
	correspondence_address = {G.J. Czarnota; Department of Radiation Oncology, Sunnybrook Health Sciences Centre, Toronto, Canada; email: gregory.czarnota@sunnybrook.ca; G.J. Czarnota; Department of Radiation Oncology, University of Toronto, Toronto, Canada; email: gregory.czarnota@sunnybrook.ca; G.J. Czarnota; Physical Sciences, Sunnybrook Research Institute, Toronto, Canada; email: gregory.czarnota@sunnybrook.ca; G.J. Czarnota; Department of Medical Biophysics, University of Toronto, Toronto, Canada; email: gregory.czarnota@sunnybrook.ca; G.J. Czarnota; Department of Electrical Engineering and Computer Sciences, Lassonde School of Engineering, York University, Toronto, Canada; email: gregory.czarnota@sunnybrook.ca; G.J. Czarnota; Department of Physics, Ryerson University, Toronto, Canada; email: gregory.czarnota@sunnybrook.ca},
	publisher = {Blackwell Publishing Ltd},
	issn = {20457634},
	pmid = {32602222},
	language = {English},
	abbrev_source_title = {Cancer Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Budd20201183,
	author = {Budd, Jobie and Miller, Benjamin S. and Manning, Erin M. and Lampos, Vasileios and Zhuang, Mengdie and Edelstein, Michael and Rees, Geraint and Emery, Vincent C. and Stevens, Molly M. and Keegan, Neil and Short, Michael J. and Pillay, Deenan and Manley, Ed and Cox, Ingemar J. and Heymann, David and Johnson, Anne M. and McKendry, Rachel A.},
	title = {Digital technologies in the public-health response to COVID-19},
	year = {2020},
	journal = {Nature Medicine},
	volume = {26},
	number = {8},
	pages = {1183 – 1192},
	doi = {10.1038/s41591-020-1011-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089188396&doi=10.1038%2fs41591-020-1011-4&partnerID=40&md5=e6b8d0a9028e4eb82be55aff8f4dad66},
	affiliations = {London Centre for Nanotechnology, University College London, London, United Kingdom; Division of Medicine, University College London, London, United Kingdom; Department of Computer Science, University College London, London, United Kingdom; The Centre for Advanced Spatial Analysis, University College London, London, United Kingdom; Centre on Global Security, Chatham House, London, United Kingdom; Faculty of Life Sciences, University College London, London, United Kingdom; Department of Microbial Sciences, University of Surrey, Guildford, United Kingdom; Department of Materials and Department of Bioengineering, Imperial College London, London, United Kingdom; Translational and Clinical Research Institute, Newcastle University, Newcastle, United Kingdom; Department for International Trade, University College London, London, United Kingdom; Division of Infection and Immunity, University College London, London, United Kingdom; School of Geography, University of Leeds, Leeds, United Kingdom; Department of Computer Science, University of Copenhagen, Copenhagen, Denmark; London School of Hygiene and Tropical Medicine, London, United Kingdom; Institute of Global Health, University College London, London, United Kingdom},
	abstract = {Digital technologies are being harnessed to support the public-health response to COVID-19 worldwide, including population surveillance, case identification, contact tracing and evaluation of interventions on the basis of mobility data and communication with the public. These rapid responses leverage billions of mobile phones, large online datasets, connected devices, relatively low-cost computing resources and advances in machine learning and natural language processing. This Review aims to capture the breadth of digital innovations for the public-health response to COVID-19 worldwide and their limitations, and barriers to their implementation, including legal, ethical and privacy barriers, as well as organizational and workforce barriers. The future of public health is likely to become increasingly digital, and we review the need for the alignment of international strategies for the regulation, evaluation and use of digital technologies to strengthen pandemic management, and future preparedness for COVID-19 and other infectious diseases. © 2020, Springer Nature America, Inc.},
	keywords = {Betacoronavirus; Coronavirus Infections; Humans; Machine Learning; Natural Language Processing; Pandemics; Pneumonia, Viral; Population Surveillance; Privacy; Public Health; contact examination; coronavirus disease 2019; data quality; data visualization; decision support system; disease surveillance; human; interpersonal communication; medical ethics; medical technology; pandemic; priority journal; privacy; public health service; Review; workforce; Betacoronavirus; Coronavirus infection; health survey; machine learning; natural language processing; pandemic; pathogenicity; public health; virology; virus pneumonia},
	correspondence_address = {R.A. McKendry; London Centre for Nanotechnology, University College London, London, United Kingdom; email: r.a.mckendry@ucl.ac.uk},
	publisher = {Nature Research},
	issn = {10788956},
	coden = {NAMEF},
	pmid = {32770165},
	language = {English},
	abbrev_source_title = {Nat. Med.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 493; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Kiemde2020373,
	author = {Kiemde, Sountongnoma Martial Anicet and Kora, Ahmed Dooguy},
	title = {Fairness of Machine Learning Algorithms for the Black Community},
	year = {2020},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2020-November},
	pages = {373 – 377},
	doi = {10.1109/ISTAS50296.2020.9462194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113253281&doi=10.1109%2fISTAS50296.2020.9462194&partnerID=40&md5=8d254b774ad234431ddd3d286414c471},
	affiliations = {Laboratory E-Inov Ecole Supérieure Multinationale des Telecommunications, Dakar, Senegal},
	abstract = {This paper seeks to study the limits of the definitions of algorithmic fairness in relation to a protected variable, namely skin color. Discrimination towards the black community have existed for a long time. ML algorithms have only amplified or revealed existing discrimination. AI is a mirror that reflects the reality of our societies. The lack of a universal definition of algorithmic fairness makes it difficult to detect cases of discrimination in machine learning algorithms. We believe that independent or sensitive variables such as skin color are benchmarks that could be used to decide whether or not a decision is fair. We also recommend avoiding the use of proxy data. © 2020 IEEE.},
	author_keywords = {Algorithms; Black community; Ethics; Fairness},
	keywords = {Machine learning; Ml algorithms; Proxy data; Sensitive variables; Skin color; Learning algorithms},
	correspondence_address = {S.M.A. Kiemde; Laboratory E-Inov Ecole Supérieure Multinationale des Telecommunications, Dakar, Senegal; email: kiemde.anicet97@gmail.com},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166541507-1},
	language = {English},
	abbrev_source_title = {Int Symp Technol Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 IEEE International Symposium on Technology and Society, ISTAS 2020; Conference date: 12 November 2020 through 15 November 2020; Conference code: 171023}
}

@ARTICLE{Castelvecchi2020347,
	author = {Castelvecchi, Davide},
	title = {Is facial recognition too biased to be let loose?},
	year = {2020},
	journal = {Nature},
	volume = {587},
	number = {7834},
	pages = {347 – 349},
	doi = {10.1038/d41586-020-03186-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096407776&doi=10.1038%2fd41586-020-03186-4&partnerID=40&md5=9fd9bede4840e5dce1e37038c578124d},
	author_keywords = {Computer science; Ethics; Machine learning},
	keywords = {Facial Recognition; Machine Learning; Pattern Recognition, Automated; Technology; automated pattern recognition; facial recognition; machine learning; technology},
	publisher = {NLM (Medline)},
	issn = {14764687},
	pmid = {33208976},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@ARTICLE{Sisk2020,
	author = {Sisk, Bryan A. and Antes, Alison L. and Burrous, Sara and Dubois, James M.},
	title = {Parental attitudes toward artificial intelligence-driven precision medicine technologies in pediatric healthcare},
	year = {2020},
	journal = {Children},
	volume = {7},
	number = {9},
	doi = {10.3390/children7090145},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85116306277&doi=10.3390%2fchildren7090145&partnerID=40&md5=571ce27e22e8ec672a3af39e1afb4796},
	affiliations = {Department of Pediatrics, Division of Hematology/Oncology, Washington University School of Medicine, St. Louis, 63110, MO, United States; Department of Medicine, Washington University School of Medicine, St. Louis, 63110, MO, United States; Brown School, Washington University, St. Louis, 63130, MO, United States},
	abstract = {Precision medicine relies upon artificial intelligence (AI)-driven technologies that raise ethical and practical concerns. In this study, we developed and validated a measure of parental openness and concerns with AI-driven technologies in their child’s healthcare. In this cross-sectional survey, we enrolled parents of children <18 years in 2 rounds for exploratory (n = 418) and confirmatory (n = 386) factor analysis. We developed a 12-item measure of parental openness to AI-driven technologies, and a 33-item measure identifying concerns that parents found important when considering these technologies. We also evaluated associations between openness and attitudes, beliefs, personality traits, and demographics. Parents (N = 804) reported mean openness to AI-driven technologies of M = 3.4/5, SD = 0.9. We identified seven concerns that parents considered important when evaluating these technologies: quality/accuracy, privacy, shared decision making, convenience, cost, human element of care, and social justice. In multivariable linear regression, parental openness was positively associated with quality (beta = 0.23), convenience (beta = 0.16), and cost (beta = 0.11), as well as faith in technology (beta = 0.23) and trust in health information systems (beta = 0.12). Parental openness was negatively associated with the perceived importance of shared decision making (beta = −0.16) and being female (beta = −0.12). Developers might support parental openness by addressing these concerns during the development and implementation of novel AI-driven technologies. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Artificial intelligence; Biomedical technology; Child health; Ethics; Machine learning; Pediatrics; Personalized medicine; Precision medicine},
	correspondence_address = {B.A. Sisk; Department of Pediatrics, Division of Hematology/Oncology, Washington University School of Medicine, St. Louis, 63110, United States; email: siskb@wustl.edu},
	publisher = {MDPI},
	issn = {22279067},
	language = {English},
	abbrev_source_title = {Child.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tarkoma2020,
	author = {Tarkoma, Sasu and Alghnam, Suliman and Howell, Michael D.},
	title = {Fighting pandemics with digital epidemiology},
	year = {2020},
	journal = {EClinicalMedicine},
	volume = {26},
	doi = {10.1016/j.eclinm.2020.100512},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089817285&doi=10.1016%2fj.eclinm.2020.100512&partnerID=40&md5=43070357046ae01e74602038ec8e0069},
	affiliations = {University of Helsinki, Pietari Kalmin katu 5, 00014, Finland; King Abdullah International Medical Research Center (KAIMRC), King Saud Bin Abdulaziz University for Health Sciences (KSAU-HS), Al-Sheikh Jaber Al-Sabah St., Riyadh, 11426, Saudi Arabia; Google Health, Palo Alto, CA, United States},
	keywords = {access to information; computer security; contact examination; coronavirus disease 2019; data analysis; digital epidemiology; digital literacy; disease surveillance; environmental monitoring; epidemiologist; epidemiology; flu like syndrome; global health security; health care concepts; health care policy; health equity; health literacy; human; information processing; machine learning; medical ethics; medical research; Note; pandemic; practice guideline; public health; World Health Organization},
	correspondence_address = {S. Tarkoma; University of Helsinki, Pietari Kalmin katu 5, 00014, Finland; email: sasu.tarkoma@helsinki.fi},
	publisher = {Lancet Publishing Group},
	issn = {25895370},
	language = {English},
	abbrev_source_title = {EClinicalMedicine},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kweon2020,
	author = {Kweon, Solbi and Lee, Jeong Hoon and Lee, Younghee and Park, Yu Rang},
	title = {Personal health information inference using machine learning on RNA expression data from patients with cancer: Algorithm validation study},
	year = {2020},
	journal = {Journal of Medical Internet Research},
	volume = {22},
	number = {8},
	doi = {10.2196/18387},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089335576&doi=10.2196%2f18387&partnerID=40&md5=92615b5320ef1ebd71cc1b0bb32d8f8f},
	affiliations = {Department of Biomedical System Informatics, Yonsei University College of Medicine, 50-1 Yonsei-ro Seodaemun-gu, Seoul, 03722, South Korea; Department of Medical Engineering, Asan Medical Institute of Convergence Science and Technology, Asan Medical Center, University of Ulsan College of Medicine, Seoul, South Korea; Department of Biomedical Informatics, University of Utah School of Medicine, Salt Lake City, UT, United States},
	abstract = {Background: As the need for sharing genomic data grows, privacy issues and concerns, such as the ethics surrounding data sharing and disclosure of personal information, are raised. Objective: The main purpose of this study was to verify whether genomic data is sufficient to predict a patient's personal information. Methods: RNA expression data and matched patient personal information were collected from 9538 patients in The Cancer Genome Atlas program. Five personal information variables (age, gender, race, cancer type, and cancer stage) were recorded for each patient. Four different machine learning algorithms (support vector machine, decision tree, random forest, and artificial neural network) were used to determine whether a patient's personal information could be accurately predicted from RNA expression data. Performance measurement of the prediction models was based on the accuracy and area under the receiver operating characteristic curve. We selected five cancer types (breast carcinoma, kidney renal clear cell carcinoma, head and neck squamous cell carcinoma, low-grade glioma, and lung adenocarcinoma) with large samples sizes to verify whether predictive accuracy would differ between them. We also validated the efficacy of our four machine learning models in analyzing normal samples from 593 cancer patients. Results: In most samples, personal information with high genetic relevance, such as gender and cancer type, could be predicted from RNA expression data alone. The prediction accuracies for gender and cancer type, which were the best models, were 0.93-0.99 and 0.78-0.94, respectively. Other aspects of personal information, such as age, race, and cancer stage, were difficult to predict from RNA expression data, with accuracies ranging from 0.0026-0.29, 0.76-0.96, and 0.45-0.79, respectively. Among the tested machine learning methods, the highest predictive accuracy was obtained using the support vector machine algorithm (mean accuracy 0.77), while the lowest accuracy was obtained using the random forest method (mean accuracy 0.65). Gender and race were predicted more accurately than other variables in the samples. On average, the accuracy of cancer stage prediction ranged between 0.71-0.67, while the age prediction accuracy ranged between 0.18-0.23 for the five cancer types. Conclusions: We attempted to predict patient information using RNA expression data. We found that some identifiers could be predicted, but most others could not. This study showed that personal information available from RNA expression data is limited and this information cannot be used to identify specific patients. © 2020 Journal of Medical Internet Research. All rights reserved.},
	author_keywords = {Cancer; Machine learning; Personal information; Prediction; Privacy issue; RNA sequencing},
	keywords = {Adolescent; Adult; Aged; Aged, 80 and over; Algorithms; Child; Female; Health Records, Personal; High-Throughput Nucleotide Sequencing; Humans; Machine Learning; Male; Middle Aged; Neoplasms; Neural Networks, Computer; RNA; Support Vector Machine; Young Adult; RNA; RNA; adolescent; adult; age; aged; Article; artificial neural network; breast carcinoma; cancer patient; cancer staging; child; decision tree; diagnostic accuracy; female; gender; gene expression; glioma; head and neck squamous cell carcinoma; human; lung adenocarcinoma; machine learning; major clinical study; male; medical information; oncogenomics; prediction; race; random forest; renal clear cell carcinoma cell line; RNA sequence; support vector machine; tumor gene; validation study; algorithm; high throughput sequencing; medical record; metabolism; middle aged; neoplasm; procedures; psychology; support vector machine; very elderly; young adult},
	correspondence_address = {Y.R. Park; Department of Biomedical System Informatics, Yonsei University College of Medicine, Seoul, 50-1 Yonsei-ro Seodaemun-gu, 03722, South Korea; email: yurangpark@yuhs.ac},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {32773372},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Swirsky202030,
	author = {Swirsky, Eric S. and Gu, Carol and Boyd, Andrew D.},
	title = {An Ethical Framework to Nowhere},
	year = {2020},
	journal = {American Journal of Bioethics},
	volume = {20},
	number = {11},
	pages = {30 – 32},
	doi = {10.1080/15265161.2020.1820109},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094645786&doi=10.1080%2f15265161.2020.1820109&partnerID=40&md5=ddd800a8dcc921d019e36ec2b7bf4975},
	affiliations = {University of Illinois at Chicago, United States},
	keywords = {Ethical Analysis; Humans; Machine Learning; Morals; ethics; human; machine learning; morality},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33103982},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Mantovani2020,
	author = {Mantovani, Eugenio and Böröcz, István and de Hert, Paul},
	title = {Conducting research with school children and data in line with “ethical principles” lawyers at work in the ethics management of the H2020 mathisis project},
	year = {2020},
	journal = {Computer Law and Security Review},
	volume = {38},
	doi = {10.1016/j.clsr.2020.105451},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089598849&doi=10.1016%2fj.clsr.2020.105451&partnerID=40&md5=b2c3996b1641d70d16aa111b0e080ac5},
	affiliations = {Research Group on Law, Science, Technology & Society (LSTS) at Vrije Universiteit Brussel (VUB), Brussels, Belgium},
	abstract = {Recent advancements in human-computer interaction, machine learning and in artificial intelligence hold the potential to influence both the curriculum and the pedagogy of school children. While the impacts of new technologies remain uncertain, ongoing research and innovation projects are already developing and testing such technologies in schools. This article builds on the experience of the authors as advisors for a Horizon 2020 (H2020) project conducting research with schoolchildren in twenty schools across the United Kingdom, Italy and Spain (the project MaTHiSiS). This contribution presents and discusses how the authors lived up to the obligation of conducting research in line with “ethical principles”. © 2020 Eugenio Mantovani, István Böröcz, Paul de Hert},
	author_keywords = {Ethical principles; National schooling systems; Personal data protection law; Research; School children; School children with special needs},
	keywords = {Artificial intelligence; Human computer interaction; Ethical principles; Ethics management; Horizon 2020; Innovation projects; United kingdom; Philosophical aspects},
	correspondence_address = {I. Böröcz; Research Group on Law, Science, Technology & Society (LSTS) at Vrije Universiteit Brussel (VUB), Brussels, Belgium; email: istvan.mate.borocz@vub.be},
	publisher = {Elsevier Ltd},
	issn = {02673649},
	coden = {CLSRE},
	language = {English},
	abbrev_source_title = {Comput Law Secur. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Wu2020106,
	author = {Wu, Wenying and Michalatos, Panagiotis and Protopapaps, Pavlos and Yang, Zheng},
	title = {Gender Classification and Bias Mitigation in Facial Images},
	year = {2020},
	journal = {WebSci 2020 - Proceedings of the 12th ACM Conference on Web Science},
	pages = {106 – 114},
	doi = {10.1145/3394231.3397900},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088402820&doi=10.1145%2f3394231.3397900&partnerID=40&md5=b7f3782911fb127b597b9c2c0411822c},
	affiliations = {Visa Inc., United States; Autodesk, United States; Harvard John A. Paulson School of Engineering and Applied Sciences, United States; Simplebet, United States},
	abstract = {Gender classification algorithms have important applications in many domains today such as demographic research, law enforcement, as well as human-computer interaction. Recent research showed that algorithms trained on biased benchmark databases could result in algorithmic bias. However, to date, little research has been carried out on gender classification algorithms' bias towards gender minorities subgroups, such as the LGBTQ and the non-binary population, who have distinct characteristics in gender expression. In this paper, we began by conducting surveys on existing benchmark databases for facial recognition and gender classification tasks. We discovered that the current benchmark databases lack representation of gender minority subgroups. We worked on extending the current binary gender classifier to include a non-binary gender class. We did that by assembling two new facial image databases: 1) a racially balanced inclusive database with a subset of LGBTQ population 2) an inclusive-gender database that consists of people with non-binary gender. We worked to increase classification accuracy and mitigate algorithmic biases on our baseline model trained on the augmented benchmark database. Our ensemble model has achieved an overall accuracy score of 90.39%, which is a 38.72% increase from the baseline binary gender classifier trained on Adience. While this is an initial attempt towards mitigating bias in gender classification, more work is needed in modeling gender as a continuum by assembling more inclusive databases. © 2020 ACM.},
	author_keywords = {convolutional neural networks; gender classification; machine learning ethics},
	keywords = {Database systems; Face recognition; Human computer interaction; Image classification; Baseline models; Benchmark database; Classification accuracy; Ensemble modeling; Facial recognition; Gender classification; Overall accuracies; Recent researches; Classification (of information)},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145037989-2},
	language = {English},
	abbrev_source_title = {WebSci - Proc. ACM Conf. Web Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; Conference name: 12th ACM Conference on Web Science, WebSci 2020; Conference date: 6 July 2020 through 10 July 2020; Conference code: 161377; All Open Access, Green Open Access}
}

@ARTICLE{Zimmermann20202321,
	author = {Zimmermann, Georg and Trinka, Eugen},
	title = {Accounting for individual variability in baseline seizure frequencies when planning randomized clinical trials remains challenging},
	year = {2020},
	journal = {Epilepsia},
	volume = {61},
	number = {10},
	pages = {2321 – 2322},
	doi = {10.1111/epi.16676},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091688036&doi=10.1111%2fepi.16676&partnerID=40&md5=65f6a91c0cf4befe845f0981ae295a5c},
	affiliations = {Team Biostatistics and Big Medical Data, IDA Lab Salzburg, Paracelsus Medical University, Salzburg, Austria; Department of Neurology, Christian Doppler University Hospital, Paracelsus Medical University, Salzburg, Austria; Department of Mathematics, Paris-Lodron-University of Salzburg, Salzburg, Austria; Center for Cognitive Neuroscience, Salzburg, Austria; Department of Public Health, Health Services Research and Health Technology Assessment, University for Health Sciences, Medical Informatics, and Technology, Hall in Tirol, Austria},
	keywords = {Epilepsy; Humans; Randomized Controlled Trials as Topic; Seizures; clinical practice; human; Letter; machine learning; medical ethics; priority journal; randomized controlled trial (topic); seizure; statistical model; epilepsy; randomized controlled trial (topic)},
	correspondence_address = {G. Zimmermann; Team Biostatistics and Big Medical Data, IDA Lab Salzburg, Paracelsus Medical University, Salzburg, Austria; email: georg.zimmermann@pmu.ac.at; G. Zimmermann; Department of Neurology, Christian Doppler University Hospital, Paracelsus Medical University, Salzburg, Austria; email: georg.zimmermann@pmu.ac.at; G. Zimmermann; Department of Mathematics, Paris-Lodron-University of Salzburg, Salzburg, Austria; email: georg.zimmermann@pmu.ac.at},
	publisher = {Blackwell Publishing Inc.},
	issn = {00139580},
	coden = {EPILA},
	pmid = {32996125},
	language = {English},
	abbrev_source_title = {Epilepsia},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Eaton20201,
	author = {Eaton, Malachy},
	title = {Computers, people, and thought: From data mining to evolutionary robotics},
	year = {2020},
	journal = {Computers, People, and Thought: From Data Mining to Evolutionary Robotics},
	pages = {1 – 233},
	doi = {10.1007/978-3-030-55300-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150093712&doi=10.1007%2f978-3-030-55300-5&partnerID=40&md5=61b16de4e8925d8d4f30b261e84f8ccf},
	affiliations = {Dept of Computer Science and Information Systems, University of Limerick, Limerick, Ireland},
	abstract = {In this book the author discusses synergies between computers and thought, related to the field of Artificial Intelligence; between people and thought, leading to questions of consciousness and our existence as humans; and between computers and people, leading to the recent remarkable advances in the field of humanoid robots. He then looks toward the implications of intelligent 'conscious' humanoid robots with superior intellects, able to operate in our human environments. After presenting the basic engineering components and supporting logic of computer systems, and giving an overview of the contributions of pioneering scientists in the domains of computing, logic, and robotics, in the core of the book the author examines the meaning of thought and intelligence in the context of specific tasks and successful AI approaches. In the final part of the book he introduces related societal and ethical implications. The book will be a useful accompanying text in courses on artificial intelligence, robotics, intelligent systems, games, and evolutionary computing. It will also be valuable for general readers and historians of technology. © Springer Nature Switzerland AG 2020. All rights reserved.},
	author_keywords = {Artificial Intelligence (AI); Bioinspired Computing; Computational Intelligence (CI); Data Mining; Ethics; Evolutionary Computing (EC); Evolutionary Robotics (ER); Game AI; Human-Inspired AI; Humanoid Robots; Intelligent Systems; Machine Learning (ML); Philosophy of Technology},
	publisher = {Springer International Publishing},
	isbn = {978-303055300-5; 978-303055299-2},
	language = {English},
	abbrev_source_title = {Comput., People, and Thought: From Data Mining to Evol. Robot.},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Moss2020,
	author = {Moss, Emanuel and Metcalf, Jacob},
	title = {High Tech, High Risk: Tech Ethics Lessons for the COVID-19 Pandemic Response},
	year = {2020},
	journal = {Patterns},
	volume = {1},
	number = {7},
	doi = {10.1016/j.patter.2020.100102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100534323&doi=10.1016%2fj.patter.2020.100102&partnerID=40&md5=8a69c3906d07bbd543b3eca5fc93dc7f},
	affiliations = {Data & Society Research Institute, New York, 10010, NY, United States; CUNY Graduate Center, New York, 10016, NY, United States},
	abstract = {The COVID-19 pandemic has, in a matter of a few short months, drastically reshaped society around the world. Because of the growing perception of machine learning as a technology capable of addressing large problems at scale, machine learning applications have been seen as desirable interventions in mitigating the risks of the pandemic disease. However, machine learning, like many tools of technocratic governance, is deeply implicated in the social production and distribution of risk and the role of machine learning in the production of risk must be considered as engineers and other technologists develop tools for the current crisis. This paper describes the coupling of machine learning and the social production of risk, generally, and in pandemic responses specifically. It goes on to describe the role of risk management in the effort to institutionalize ethics in the technology industry and how such efforts can benefit from a deeper understanding of the social production of risk through machine learning. This paper describes the coupling of machine learning and the social production of risk in general, with specific illustrations drawn from machine learning applications in response to the COVID-19 pandemic. As the COVID-19 pandemic has drastically reshaped society around the world, many have looked to machine learning as a technology capable of addressing large problems at scale, and machine learning applications have been seen as desirable interventions in mitigating the risks of the pandemic disease. However, machine learning, like many tools of technocratic governance, is deeply implicated in the social production and distribution of risk. Therefore, the role of machine learning in the production of risk must be considered as engineers and other technologists develop tools for the current crisis. The paper concludes by describing the role of risk management in the effort to institutionalize ethics in the technology industry, and how such efforts can benefit from understanding the social production of risk through machine learning. This paper describes the coupling of machine learning and the social production of risk, with specific illustrations drawn from machine learning applications in response to the COVID-19 pandemic. It goes on to describe the role of risk management in the effort to institutionalize ethics in the technology industry, and how such efforts can benefit from a deeper understanding of the social production of risk through machine learning. © 2020 The Authors},
	author_keywords = {DSML 1: Concept: Basic principles of a new data science output observed and reported},
	keywords = {Engineers; Machine learning; Philosophical aspects; Risk perception; High tech; Large problems; Machine learning applications; Social productions; Technology industry; Risk management},
	correspondence_address = {E. Moss; Data & Society Research Institute, New York, 10010, United States; email: emoss@gradcenter.cuny.edu; J. Metcalf; Data & Society Research Institute, New York, 10010, United States; email: jake.metcalf@datasociety.net},
	publisher = {Cell Press},
	issn = {26663899},
	language = {English},
	abbrev_source_title = {Patterns},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ho2020,
	author = {Ho, Anita},
	title = {Are we ready for artificial intelligence health monitoring in elder care?},
	year = {2020},
	journal = {BMC Geriatrics},
	volume = {20},
	number = {1},
	doi = {10.1186/s12877-020-01764-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091474084&doi=10.1186%2fs12877-020-01764-9&partnerID=40&md5=397540bb911a16762e5ddcff7432ae8a},
	affiliations = {Centre for Applied Ethics, University of British Columbia, 227-6356 Agricultural Road, Vancouver, V6T 1Z2, BC, Canada; Bioethics Program, University of California San Francisco, Vancouver, Canada; Centre for Health Evaluation and Outcome Sciences, Vancouver, Canada},
	abstract = {Background: The world is experiencing a dramatic increase in the aging population, challenging the sustainability of traditional care models that have relied on in-person monitoring. This debate article discusses whether artificial intelligence health monitoring may be suitable enhancement or replacement for elder care. Main text: Internationally, as life expectancy continues to rise, many countries are facing a severe shortage of direct care workers. The health workforce is aging, and replacement remains a challenge. Artificial intelligence health monitoring technologies may play a novel and significant role in filling the human resource gaps in caring for older adults by complementing current care provision, reducing the burden on family caregivers, and improving the quality of care. Nonetheless, opportunities brought on by these emerging technologies raise ethical questions that must be addressed to ensure that these automated systems can truly enhance care and health outcomes for older adults. This debate article explores some ethical dimensions of using automated health monitoring technologies. It argues that, in order for these health monitoring technologies to fulfill the wishes of older adults to age in place and also to empower them and improve their quality of life, we need deep knowledge of how stakeholders may balance their considerations of relational care, safety, and privacy. Conclusion: It is only when we design artificial intelligence health monitoring technologies with intersecting clinical and ethical factors in mind that the resulting systems will enhance productive relational care, facilitate independent living, promote older adults' health outcomes, and minimize waste.  © 2020 The Author(s).},
	author_keywords = {Aging in place; Artificial intelligence; Ethics; Health monitoring; Independent living; Machine learning},
	keywords = {Aged; Aging; Artificial Intelligence; Caregivers; Humans; Independent Living; Quality of Life; aged; article; artificial intelligence; care behavior; caregiver; ethics; health workforce; human; independent living; life expectancy; machine learning; privacy; quality of life; worker; aging; independent living; quality of life},
	correspondence_address = {A. Ho; Centre for Applied Ethics, University of British Columbia, Vancouver, 227-6356 Agricultural Road, V6T 1Z2, Canada; email: Anitaho.ethics@gmail.com},
	publisher = {BioMed Central Ltd},
	issn = {14712318},
	pmid = {32957946},
	language = {English},
	abbrev_source_title = {BMC Geriatr.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Aguilera2020,
	author = {Aguilera, Adrian and Figueroa, Caroline A. and Hernandez-Ramos, Rosa and Sarkar, Urmimala and Cemballi, Anupama and Gomez-Pathak, Laura and Miramontes, Jose and Yom-Tov, Elad and Chakraborty, Bibhas and Yan, Xiaoxi and Xu, Jing and Modiri, Arghavan and Aggarwal, Jai and Jay Williams, Joseph and Lyles, Courtney R.},
	title = {MHealth app using machine learning to increase physical activity in diabetes and depression: Clinical trial protocol for the DIAMANTE Study},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {8},
	doi = {10.1136/bmjopen-2019-034723},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089769786&doi=10.1136%2fbmjopen-2019-034723&partnerID=40&md5=e9593fcf22a21c05979b941efd1e8dd5},
	affiliations = {School of Social Welfare, University of California Berkeley, Berkeley, CA, United States; Ucsf Center for Vulnerable Populations, Division of General Internal Medicine San Francisco, Zuckerberg San Francisco General Hospital, San Francisco, CA, United States; Microsoft Research, Herzeliya, Israel; Centre for Quantitative Medicine, Duke-National University, Singapore Medical School, Singapore, Singapore; Department of Statistics and Applied Probability, National University of Singapore, Singapore, Singapore; Department of Biostatistics and Bioinformatics, Duke University, Durham, NC, United States; Computer Science University of Toronto, Toronto, ON, Canada},
	abstract = {Introduction Depression and diabetes are highly disabling diseases with a high prevalence and high rate of comorbidity, particularly in low-income ethnic minority patients. Though comorbidity increases the risk of adverse outcomes and mortality, most clinical interventions target these diseases separately. Increasing physical activity might be effective to simultaneously lower depressive symptoms and improve glycaemic control. Self-management apps are a cost-effective, scalable and easy access treatment to increase physical activity. However, cutting-edge technological applications often do not reach vulnerable populations and are not tailored to an individual's behaviour and characteristics. Tailoring of interventions using machine learning methods likely increases the effectiveness of the intervention. Methods and analysis In a three-arm randomised controlled trial, we will examine the effect of a text-messaging smartphone application to encourage physical activity in low-income ethnic minority patients with comorbid diabetes and depression. The adaptive intervention group receives messages chosen from different messaging banks by a reinforcement learning algorithm. The uniform random intervention group receives the same messages, but chosen from the messaging banks with equal probabilities. The control group receives a weekly mood message. We aim to recruit 276 adults from primary care clinics aged 18-75 years who have been diagnosed with current diabetes and show elevated depressive symptoms (Patient Health Questionnaire depression scale-8 (PHQ-8) >5). We will compare passively collected daily step counts, self-report PHQ-8 and most recent haemoglobin A1c from medical records at baseline and at intervention completion at 6-month follow-up. Ethics and dissemination The Institutional Review Board at the University of California San Francisco approved this study (IRB: 17-22608). We plan to submit manuscripts describing our user-designed methods and testing of the adaptive learning algorithm and will submit the results of the trial for publication in peer-reviewed journals and presentations at (inter)-national scientific meetings. Trial registration number NCT03490253; pre-results. © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {Depression & mood disorders; Diabetes & endocrinology; Health informatics; Telemedicine},
	keywords = {Adolescent; Adult; Aged; Depression; Diabetes Mellitus; Ethnic Groups; Exercise; Humans; Machine Learning; Middle Aged; Minority Groups; Mobile Applications; Randomized Controlled Trials as Topic; San Francisco; Telemedicine; Young Adult; hemoglobin A1c; adult; aged; Article; clinical trial protocol; comorbidity; controlled study; depression; diabetes mellitus; ethnic group; female; follow up; human; machine learning; major clinical study; male; Patient Health Questionnaire 8; physical activity; primary medical care; randomized controlled trial; reinforcement learning (machine learning); self care; self report; step count; text messaging; adolescent; California; depression; diabetes mellitus; exercise; machine learning; middle aged; minority group; mobile application; randomized controlled trial (topic); telemedicine; young adult},
	correspondence_address = {C.A. Figueroa; School of Social Welfare, University of California Berkeley, Berkeley, United States; email: c.a.fgueroa@berkeley.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {32819981},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Char20207,
	author = {Char, Danton S. and Abràmoff, Michael D. and Feudtner, Chris},
	title = {Identifying Ethical Considerations for Machine Learning Healthcare Applications},
	year = {2020},
	journal = {American Journal of Bioethics},
	volume = {20},
	number = {11},
	pages = {7 – 17},
	doi = {10.1080/15265161.2020.1819469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094636710&doi=10.1080%2f15265161.2020.1819469&partnerID=40&md5=ea27d68a1c4b7e7f93895b127cf8a76c},
	affiliations = {Stanford University School of Medicine, United States; University of Iowa, United States; Digital Diagnostics, United States; The University of Pennsylvania, United States; The Children’s Hospital of Philadelphia, United States},
	abstract = {Along with potential benefits to healthcare delivery, machine learning healthcare applications (ML-HCAs) raise a number of ethical concerns. Ethical evaluations of ML-HCAs will need to structure the overall problem of evaluating these technologies, especially for a diverse group of stakeholders. This paper outlines a systematic approach to identifying ML-HCA ethical concerns, starting with a conceptual model of the pipeline of the conception, development, implementation of ML-HCAs, and the parallel pipeline of evaluation and oversight tasks at each stage. Over this model, we layer key questions that raise value-based issues, along with ethical considerations identified in large part by a literature review, but also identifying some ethical considerations that have yet to receive attention. This pipeline model framework will be useful for systematic ethical appraisals of ML-HCA from development through implementation, and for interdisciplinary collaboration of diverse stakeholders that will be required to understand and subsequently manage the ethical implications of ML-HCAs. © 2020 Taylor & Francis Group, LLC.},
	author_keywords = {Artificial intelligence; effectiveness; ethics; machine learning; safety; test characteristics},
	keywords = {Delivery of Health Care; Humans; Machine Learning; Morals; article; artificial intelligence; attention; conception; conceptual model; ethics; health care delivery; machine learning; pipeline; human; morality},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33103967},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 104; All Open Access, Green Open Access}
}

@ARTICLE{Clarke2020446,
	author = {Clarke, Natasha and Foltz, Peter and Garrard, Peter},
	title = {How to do things with (thousands of) words: Computational approaches to discourse analysis in Alzheimer's disease},
	year = {2020},
	journal = {Cortex},
	volume = {129},
	pages = {446 – 463},
	doi = {10.1016/j.cortex.2020.05.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087216490&doi=10.1016%2fj.cortex.2020.05.001&partnerID=40&md5=1af5ced058e197e5389636da86cc9099},
	affiliations = {Neurosciences Research Centre, Molecular & Clinical Sciences Research Institute, St George's, University of London, Cranmer Terrace, London, United Kingdom; Institute of Cognitive Science, University of Colorado, Boulder, United States},
	abstract = {Natural Language Processing (NLP) is an ever-growing field of computational science that aims to model natural human language. Combined with advances in machine learning, which learns patterns in data, it offers practical capabilities including automated language analysis. These approaches have garnered interest from clinical researchers seeking to understand the breakdown of language due to pathological changes in the brain, offering fast, replicable and objective methods. The study of Alzheimer's disease (AD), and preclinical Mild Cognitive Impairment (MCI), suggests that changes in discourse (connected speech or writing) may be key to early detection of disease. There is currently no disease-modifying treatment for AD, the leading cause of dementia in people over the age of 65, but detection of those at risk of developing the disease could help with the identification and testing of medications which can take effect before the underlying pathology has irreversibly spread. We outline important components of natural language, as well as NLP tools and approaches with which they can be extracted, analysed and used for disease identification and risk prediction. We review literature using these tools to model discourse across the spectrum of AD, including the contribution of machine learning approaches and Automatic Speech Recognition (ASR). We conclude that NLP and machine learning techniques are starting to greatly enhance research in the field, with measurable and quantifiable language components showing promise for early detection of disease, but there remain research and practical challenges for clinical implementation of these approaches. Challenges discussed include the availability of large and diverse datasets, ethics of data collection and sharing, diagnostic specificity and clinical acceptability. © 2020 Elsevier Ltd},
	author_keywords = {Alzheimer's disease; Discourse; Machine learning; Mild Cognitive Impairment; Natural Language Processing},
	keywords = {Alzheimer disease; autoanalysis; automatic speech recognition; computer simulation; discourse analysis; entropy; human; neural word embedding; Review; semantics; vocabulary},
	correspondence_address = {N. Clarke; Neurosciences Research Centre, Molecular & Clinical Sciences Research Institute, St George's, University of London, Cranmer Terrace, London, SW17 0RE, United Kingdom; email: p1607544@sgul.ac.uk},
	publisher = {Masson SpA},
	issn = {00109452},
	coden = {CRTXA},
	pmid = {32622173},
	language = {English},
	abbrev_source_title = {Cortex},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Green Open Access}
}

@ARTICLE{Morgan2020,
	author = {Morgan, Catherine and Craddock, Ian and Tonkin, Emma L. and Kinnunen, Kirsi M. and Mcnaney, Roisin and Whitehouse, Sam and Mirmehdi, Majid and Heidarivincheh, Farnoosh and Mcconville, Ryan and Carey, Julia and Horne, Alison and Rolinski, Michal and Rochester, Lynn and Maetzler, Walter and Matthews, Helen and Watson, Oliver and Eardley, Rachel and Whone, Alan L.},
	title = {Protocol for PD SENSORS: Parkinson's Disease Symptom Evaluation in a Naturalistic Setting producing Outcome measuRes using SPHERE technology. An observational feasibility study of multi-modal multi-sensor technology to measure symptoms and activities of daily living in Parkinson's disease},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {11},
	doi = {10.1136/bmjopen-2020-041303},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097034214&doi=10.1136%2fbmjopen-2020-041303&partnerID=40&md5=68649942202ffa4ff238b48b33dc24a0},
	affiliations = {Translational Health Sciences, University of Bristol Medical School, Bristol, United Kingdom; Movement Disorders Group, North Bristol NHS Trust, Avon, United Kingdom; School of Computer Science, Electrical and Electronic Engineering and Engineering Mathematics, Faculty of Engineering, University of Bristol, Bristol, United Kingdom; Research and Development, IXICO, London, United Kingdom; Population Health Sciences, University of Bristol Medical School, Bristol, United Kingdom; Institute of Neuroscience, Newcastle University, Newcastle, United Kingdom; NHS Foundation Trust, Newcastle Upon Tyne Hospitals, Newcastle Upon Tyne, United Kingdom; Department of Neurology, University Medical Center Schleswig-Holstein Campus Kiel, Kiel, Germany; Research Department, Cure Parkinson's Trust, London, United Kingdom; Bristol Health Partners, Bristol, United Kingdom},
	abstract = {Introduction The impact of disease-modifying agents on disease progression in Parkinson's disease is largely assessed in clinical trials using clinical rating scales. These scales have drawbacks in terms of their ability to capture the fluctuating nature of symptoms while living in a naturalistic environment. The SPHERE (Sensor Platform for HEalthcare in a Residential Environment) project has designed a multi-sensor platform with multimodal devices designed to allow continuous, relatively inexpensive, unobtrusive sensing of motor, non-motor and activities of daily living metrics in a home or a home-like environment. The aim of this study is to evaluate how the SPHERE technology can measure aspects of Parkinson's disease. Methods and analysis This is a small-scale feasibility and acceptability study during which 12 pairs of participants (comprising a person with Parkinson's and a healthy control participant) will stay and live freely for 5 days in a home-like environment embedded with SPHERE technology including environmental, appliance monitoring, wrist-worn accelerometry and camera sensors. These data will be collected alongside clinical rating scales, participant diary entries and expert clinician annotations of colour video images. Machine learning will be used to look for a signal to discriminate between Parkinson's disease and control, and between Parkinson's disease symptoms 'on' and 'off' medications. Additional outcome measures including bradykinesia, activity level, sleep parameters and some activities of daily living will be explored. Acceptability of the technology will be evaluated qualitatively using semi-structured interviews. Ethics and dissemination Ethical approval has been given to commence this study; the results will be disseminated as widely as appropriate.  © 2020 Author(s).},
	author_keywords = {information technology; parkinson's disease; qualitative research; statistics & research methods},
	keywords = {Activities of Daily Living; Feasibility Studies; Humans; Outcome Assessment, Health Care; Parkinson Disease; Symptom Assessment; Technology; adult; Article; bradykinesia; clinical article; clinical protocol; daily life activity; feasibility study; human; machine learning; naturalistic inquiry; observational study; outcome assessment; Parkinson disease; program acceptability; rating scale; semi structured interview; sleep parameters; symptom assessment; daily life activity; Parkinson disease; symptom assessment; technology},
	correspondence_address = {C. Morgan; Translational Health Sciences, University of Bristol Medical School, Bristol, United Kingdom; email: catherine.morgan@bristol.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33257491},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mörch2020,
	author = {Mörch, Carl-Maria and Gupta, Abhishek and Mishara, Brian L.},
	title = {Canada protocol: An ethical checklist for the use of artificial Intelligence in suicide prevention and mental health},
	year = {2020},
	journal = {Artificial Intelligence in Medicine},
	volume = {108},
	doi = {10.1016/j.artmed.2020.101934},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088640847&doi=10.1016%2fj.artmed.2020.101934&partnerID=40&md5=e3bc432caaaa229a84467780ba06a242},
	affiliations = {Algora Lab, University of Montréal, Canada; International Observatory on the Societal Impacts of AI and Digital Technology (OBVIA), Canada; Mila - Québec Artificial Intelligence Institute, Canada; Psychology Department, Université Du Québec à Montréal, Canada; Centre for Research and Intervention on Suicide, Ethical Issues and End of Life Practices (CRISE), Montréal, Canada; Montreal AI Ethics Institute, Canada; Microsoft, Canada},
	author_keywords = {Artificial intelligence; Big Data; Ethics; Machine learning; Mental Health; Prevention; Suicide},
	keywords = {Artificial Intelligence; Big Data; Checklist; Humans; Mental Health; Suicide; Article; artificial intelligence; Canada; checklist; clinical protocol; conceptual framework; consultation; Delphi study; evidence based practice; human; medical ethics; mental health; mental health care; practice guideline; priority journal; publication; questionnaire; suicide; validation process; checklist; mental health},
	correspondence_address = {C.-M. Mörch; Algora Lab, Mila-Québec Artificial Intelligence Institute, Montréal, 6666 Rue Saint-Urbain, H2S 3H1, Canada; email: carl.morch@umontreal.ca},
	publisher = {Elsevier B.V.},
	issn = {09333657},
	coden = {AIMEE},
	pmid = {32972663},
	language = {English},
	abbrev_source_title = {Artif. Intell. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@ARTICLE{Thieme2020,
	author = {Thieme, Anja and Belgrave, Danielle and Doherty, Gavin},
	title = {Machine Learning in Mental Health: A systematic review of the HCI literature to support the development of effective and implementable ML Systems},
	year = {2020},
	journal = {ACM Transactions on Computer-Human Interaction},
	volume = {27},
	number = {5},
	doi = {10.1145/3398069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090445793&doi=10.1145%2f3398069&partnerID=40&md5=ab0bc8c892659a57e1539d9a6e0eb5a3},
	affiliations = {Healthcare Intelligence, Microsoft Research, 21 Station Road, Cambridge, Cambridgeshire, CB1 2FB, United Kingdom; School of Computer Science and Statistics, Trinity College Dublin, College Green, Dublin 2, Ireland},
	abstract = {High prevalence of mental illness and the need for effective mental health care, combined with recent advances in AI, has led to an increase in explorations of how the field of machine learning (ML) can assist in the detection, diagnosis and treatment of mental health problems. ML techniques can potentially offer new routes for learning patterns of human behavior; identifying mental health symptoms and risk factors; developing predictions about disease progression; and personalizing and optimizing therapies. Despite the potential opportunities for using ML within mental health, this is an emerging research area, and the development of effective ML-enabled applications that are implementable in practice is bound up with an array of complex, interwoven challenges. Aiming to guide future research and identify new directions for advancing development in this important domain, this article presents an introduction to, and a systematic review of, current ML work regarding psycho-socially based mental health conditions from the computing and HCI literature. A quantitative synthesis and qualitative narrative review of 54 papers that were included in the analysis surfaced common trends, gaps, and challenges in this space. Discussing our findings, we (i) reflect on the current state-of-the-art of ML work for mental health, (ii) provide concrete suggestions for a stronger integration of human-centered and multi-disciplinary approaches in research and development, and (iii) invite more consideration of the potentially far-reaching personal, social, and ethical implications that ML models and interventions can have, if they are to find widespread, successful adoption in real-world mental health contexts.  © 2020 Owner/Author.},
	author_keywords = {AI applications; ethics; health care; interaction design; interpretability; machine learning; Mental health; mental illness; real-world interventions; society + AI; systematic review},
	keywords = {Behavioral research; Diagnosis; Disease control; Diseases; Machine learning; Disease progression; Ethical implications; Human behaviors; Learning patterns; Multi-disciplinary approach; Research and development; State of the art; Systematic Review; Health risks},
	correspondence_address = {A. Thieme; Healthcare Intelligence, Microsoft Research, Cambridge, Cambridgeshire, 21 Station Road, CB1 2FB, United Kingdom; email: anthie@microsoft.com},
	publisher = {Association for Computing Machinery},
	issn = {10730516},
	language = {English},
	abbrev_source_title = {ACM Trans. Comput.-Hum. Interact.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 113; All Open Access, Bronze Open Access}
}

@BOOK{Galiautdinov202019,
	author = {Galiautdinov, Rinat},
	title = {The Soul of artificial intelligence and races' separation of AI and homo},
	year = {2020},
	journal = {Responsible AI and Ethical Issues for Businesses and Governments},
	pages = {19 – 34},
	doi = {10.4018/978-1-7998-4285-9.ch002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85137439806&doi=10.4018%2f978-1-7998-4285-9.ch002&partnerID=40&md5=18258540c489a895eb3848da28ee2c62},
	abstract = {Artificial intelligence breaks into our lives. However, some questions are already being raised, and increasingly, these issues affect aspects of morality and ethics. Is it possible to scoff at thinking AI? When will it be invented? What prevents us from writing laws of robotics right now, putting morality into them? What surprises does machine learning bring us now? Can machine learning be fooled, and how difficult is it? But even greater questions arise in the context of the separation of races of AI and humans. Is AI racism our future? This chapter explores these questions. © 2021, IGI Global.},
	publisher = {IGI Global},
	isbn = {978-179984286-6; 978-179984285-9},
	language = {English},
	abbrev_source_title = {Responsible AI and Ethical Issues for Businesses and Gov.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Martins20202288,
	author = {Martins, Russell Seth and Cheema, Daniyaal AHmad and Sohail, M. Rizwan},
	title = {The Pandemic of Publications: Are We Sacrificing Quality for Quantity?},
	year = {2020},
	journal = {Mayo Clinic Proceedings},
	volume = {95},
	number = {10},
	pages = {2288 – 2290},
	doi = {10.1016/j.mayocp.2020.07.026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091625807&doi=10.1016%2fj.mayocp.2020.07.026&partnerID=40&md5=c80a2131038fa2d7c5874f8faa6e3945},
	affiliations = {Aga Khan University Hospital, Karachi, Pakistan; Mayo Clinic, Rochester, MN, United States},
	keywords = {COVID-19; Data Accuracy; Humans; Periodicals as Topic; Publishing; hydroxychloroquine; artificial intelligence; clinical research; coronavirus disease 2019; decision making; evidence based practice; health care management; health care personnel; health care system; health promotion; health service; human; Letter; machine learning; medical ethics; medical information; pandemic; practice guideline; publication; quality control; social media; World Health Organization; measurement accuracy; publication; publishing},
	publisher = {Elsevier Ltd},
	issn = {00256196},
	coden = {MACPA},
	pmid = {33012361},
	language = {English},
	abbrev_source_title = {Mayo Clin. Proc.},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Du-Harpur2020423,
	author = {Du-Harpur, X. and Watt, F.M. and Luscombe, N.M. and Lynch, M.D.},
	title = {What is AI? Applications of artificial intelligence to dermatology},
	year = {2020},
	journal = {British Journal of Dermatology},
	volume = {183},
	number = {3},
	pages = {423 – 430},
	doi = {10.1111/bjd.18880},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081404412&doi=10.1111%2fbjd.18880&partnerID=40&md5=b29250dd967ac010ab949b4e7a7dfe93},
	affiliations = {Centre for Stem Cells and Regenerative Medicine, Faculty of Life Sciences and Medicine, King's College London, 28th Floor, Tower Wing, Guy's Hospital, London, SE1 9RT, United Kingdom; The Francis Crick Institute, 1 Midland Road, London, United Kingdom; St John's Institute of Dermatology, Guy's Hospital, London, United Kingdom; Okinawa Institute of Science and Technology Graduate University, Okinawa, 904-0495, Japan},
	abstract = {In the past, the skills required to make an accurate dermatological diagnosis have required exposure to thousands of patients over many years. However, in recent years, artificial intelligence (AI) has made enormous advances, particularly in the area of image classification. This has led computer scientists to apply these techniques to develop algorithms that are able to recognize skin lesions, particularly melanoma. Since 2017, there have been numerous studies assessing the accuracy of algorithms, with some reporting that the accuracy matches or surpasses that of a dermatologist. While the principles underlying these methods are relatively straightforward, it can be challenging for the practising dermatologist to make sense of a plethora of unfamiliar terms in this domain. Here we explain the concepts of AI, machine learning, neural networks and deep learning, and explore the principles of how these tasks are accomplished. We critically evaluate the studies that have assessed the efficacy of these methods and discuss limitations and potential ethical issues. The burden of skin cancer is growing within the Western world, with major implications for both population skin health and the provision of dermatology services. AI has the potential to assist in the diagnosis of skin lesions and may have particular value at the interface between primary and secondary care. The emerging technology represents an exciting opportunity for dermatologists, who are the individuals best informed to explore the utility of this powerful novel diagnostic tool, and facilitate its safe and ethical implementation within healthcare systems. © 2020 The Authors. British Journal of Dermatology published by John Wiley & Sons Ltd on behalf of British Association of Dermatologists},
	keywords = {Algorithms; Artificial Intelligence; Dermatology; Humans; Machine Learning; Neural Networks, Computer; artificial intelligence; artificial neural network; automated pattern recognition; automation; cancer patient; clinical assessment; clinical evaluation; computer aided design; convolutional neural network; cutaneous melanoma; deep learning; deep neural network; dermatologist; dermatology; diagnostic accuracy; diagnostic test accuracy study; disease burden; health care system; health service; human; machine learning; medical ethics; medical technology; mobile application; priority journal; receiver operating characteristic; Review; secondary health care; sensitivity and specificity; skill; skin cancer; skin defect; study design; supervised machine learning; Western world; algorithm; machine learning},
	correspondence_address = {X. Du-Harpur; Centre for Stem Cells and Regenerative Medicine, Faculty of Life Sciences and Medicine, King's College London, London, 28th Floor, Tower Wing, Guy's Hospital, SE1 9RT, United Kingdom; email: xinyi.du@kcl.ac.uk; X. Du-Harpur; The Francis Crick Institute, London, 1 Midland Road, United Kingdom; email: xinyi.du@kcl.ac.uk; X. Du-Harpur; St John's Institute of Dermatology, Guy's Hospital, London, United Kingdom; email: xinyi.du@kcl.ac.uk},
	publisher = {Blackwell Publishing Ltd},
	issn = {00070963},
	coden = {BJDEA},
	pmid = {31960407},
	language = {English},
	abbrev_source_title = {Br. J. Dermatol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 72; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Yu2020,
	author = {Yu, Cheng-Sheng and Lin, Yu-Jiun and Lin, Chang-Hsien and Lin, Shiyng-Yu and Wu, Jenny L. and Chang, Shy-Shin},
	title = {Erratum: Development of an online health care assessment for preventive medicine: A machine learning approach (Journal of Medical Internet Research (2020) 22:6 (e18585) DOI: 10.2196/18585)},
	year = {2020},
	journal = {Journal of Medical Internet Research},
	volume = {22},
	number = {7},
	doi = {10.2196/21753},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088811733&doi=10.2196%2f21753&partnerID=40&md5=b67826141f76746e25abb406abdc6f6a},
	affiliations = {Department of Family Medicine, Taipei Medical University Hospital, Taipei, Taiwan; Department of Family Medicine, School of Medicine, College of Medicine, Taipei Medical University, Taipei, Taiwan},
	abstract = {In “Development of an Online Health Care Assessment for Preventive Medicine: A Machine Learning Approach” (J Med Internet Res 2020;22(6):e18585) the authors noticed an error in the Institutional Review Board (IRB) approval number. Under the Ethics heading in the Methods section, the IRB approval number was listed as “N201906023” (TMUH TMU-JIRB number N201906023) The correct number is “N202003088”: (TMUH TMU-JIRB number N202003088) The correction will appear in the online version of the paper on the JMIR Publications website on July 27, 2020, together with the publication of this correction notice. Because this was made after submission to PubMed, PubMed Central, and other full-text repositories, the corrected article has also been resubmitted to those repositories. © Cheng-Sheng Yu, Yu-Jiun Lin, Chang-Hsien Lin, Shiyng-Yu Lin, Jenny L Wu, Shy-Shin Chang. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 27.07.2020. This is an open-access article distributed under the terms of the Creative Commons Attribution License (https://creativecommons.org/licenses/by/4.0/), which permits unrestricted use, distribution, and reproduction in any medium, provided the original work, first published in the Journal of Medical Internet Research, is properly cited. The complete bibliographic information, a link to the original publication on http://www.jmir.org/, as well as this copyright and license information must be included.},
	keywords = {erratum},
	correspondence_address = {S.-S. Chang; Department of Family Medicine, School of Medicine, College of Medicine, Taipei Medical University, Taipei, 250 Wuxing St, 11031, Taiwan; email: sschang0529@gmail.com},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {32716902},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hussain2020,
	author = {Hussain, Zain and Shah, Syed Ahmar and Mukherjee, Mome and Sheikh, Aziz},
	title = {Predicting the risk of asthma attacks in children, adolescents and adults: Protocol for a machine learning algorithm derived from a primary care-based retrospective cohort},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {7},
	doi = {10.1136/bmjopen-2019-036099},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088678784&doi=10.1136%2fbmjopen-2019-036099&partnerID=40&md5=3b233d4cf83147d3d7ac1623070a430c},
	affiliations = {Usher Institute, Edinburgh Medical School, University of Edinburgh, Edinburgh, United Kingdom; Asthma UK Centre for Applied Research (AUKCAR), University of Edinburgh, Edinburgh, United Kingdom; Division of Community Health Sciences, University of Edinburgh, Edinburgh, United Kingdom},
	abstract = {Introduction Most asthma attacks and subsequent deaths are potentially preventable. We aim to develop a prognostic tool for identifying patients at high risk of asthma attacks in primary care by leveraging advances in machine learning. Methods and analysis Current prognostic tools use logistic regression to develop a risk scoring model for asthma attacks. We propose to build on this by systematically applying various well-known machine learning techniques to a large longitudinal deidentified primary care database, the Optimum Patient Care Research Database, and comparatively evaluate their performance with the existing logistic regression model and against each other. Machine learning algorithms vary in their predictive abilities based on the dataset and the approach to analysis employed. We will undertake feature selection, classification (both one-class and two-class classifiers) and performance evaluation. Patients who have had actively treated clinician-diagnosed asthma, aged 8-80 years and with 3 years of continuous data, from 2016 to 2018, will be selected. Risk factors will be obtained from the first year, while the next 2 years will form the outcome period, in which the primary endpoint will be the occurrence of an asthma attack. Ethics and dissemination We have obtained approval from OPCRD's Anonymous Data Ethics Protocols and Transparency (ADEPT) Committee. We will seek ethics approval from The University of Edinburgh's Research Ethics Group (UREG). We aim to present our findings at scientific conferences and in peer-reviewed journals. © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY. Published by BMJ.},
	author_keywords = {asthma; epidemiology; health informatics; public health},
	keywords = {Adolescent; Adult; Aged; Aged, 80 and over; Algorithms; Asthma; Child; Humans; Machine Learning; Middle Aged; Primary Health Care; Retrospective Studies; Risk Factors; Young Adult; beta adrenergic receptor blocking agent; beta adrenergic receptor stimulating agent; corticosteroid; leukotriene receptor blocking agent; theophylline; adolescent; adult; aged; Article; asthma; child; classification algorithm; cohort analysis; data base; feature selection; human; machine learning; outcome assessment; primary medical care; retrospective study; risk factor; algorithm; asthma; middle aged; primary health care; risk factor; very elderly; young adult},
	correspondence_address = {S.A. Shah; Usher Institute, Edinburgh Medical School, University of Edinburgh, Edinburgh, United Kingdom; email: ahmar.shah@ed.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {32709646},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Grasso202083,
	author = {Grasso, Isabella and Russell, David and Matthews, Abigail and Matthews, Jeanna and Record, Nicholas R.},
	title = {Applying Algorithmic Accountability Frameworks with Domain-specific Codes of Ethics: A Case Study in Ecosystem Forecasting for Shellfish Toxicity in the Gulf of Maine},
	year = {2020},
	journal = {FODS 2020 - Proceedings of the 2020 ACM-IMS Foundations of Data Science Conference},
	pages = {83 – 91},
	doi = {10.1145/3412815.3416897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096975824&doi=10.1145%2f3412815.3416897&partnerID=40&md5=de9f2781a88c16adcb10909630251759},
	affiliations = {Clarkson University, Potsdam, United States; University of Wisconsin-Madison, Madison, United States; Bigelow Laboratory for Ocean Sciences, East Boothbay, United States},
	abstract = {Ecological forecasts are used to inform decisions that can havesignificant impacts on the lives of individuals and on the healthof ecosystems. These forecasts, or models, embody the ethics oftheir creators as well as many seemingly arbitrary implementationchoices made along the way. They can contain implementationerrors as well as reflect patterns of bias learned when ingestingdatasets derived from past biased decision making. Principles andframeworks for algorithmic accountability allow a wide range ofstakeholders to place the results of models and software systemsinto context. We demonstrate how the combination of algorithmicaccountability frameworks and domain-specific codes of ethics helpanswer calls to uphold fairness and human values, specifically indomains that utilize machine learning algorithms. This helps avoidmany of the unintended consequences that can result from deploy-ing "black box"systems to solve complex problems. In this paper,we discuss our experience applying algorithmic accountability prin-ciples and frameworks to ecosystem forecasting, focusing on a casestudy forecasting shellfish toxicity in the Gulf of Maine. We adaptexisting frameworks such as Datasheets for Datasets and ModelCards for Model Reporting from their original focus on personallyidentifiable private data to include public datasets, such as thoseoften used in ecosystem forecasting applications, to audit the casestudy. We show how high level algorithmic accountability frame-works and domain level codes of ethics compliment each other,incentivizing more transparency, accountability, and fairness inautomated decision-making systems. © 2020 ACM.},
	author_keywords = {algorithmic accountability; ecology; ethics; forecasting},
	keywords = {Data Science; Decision making; Ecosystems; Forecasting; Learning algorithms; Philosophical aspects; Shellfish; Toxicity; Accountability framework; Biased decision makings; Complex problems; Decision-making systems; Domain levels; Domain-specific codes; Gulf of maine; Unintended consequences; Machine learning},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145038103-1},
	language = {English},
	abbrev_source_title = {FODS - Proc. ACM-IMS Found. Data Sci. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2020 ACM-IMS Foundations of Data Science Conference, FODS 2020; Conference date: 19 October 2020 through 20 October 2020; Conference code: 164272}
}

@ARTICLE{Breidbach2020163,
	author = {Breidbach, Christoph F. and Maglio, Paul},
	title = {Accountable algorithms? The ethical implications of data-driven business models},
	year = {2020},
	journal = {Journal of Service Management},
	volume = {31},
	number = {2},
	pages = {163 – 185},
	doi = {10.1108/JOSM-03-2019-0073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085148384&doi=10.1108%2fJOSM-03-2019-0073&partnerID=40&md5=ff5c29ee661d2612a01ca52af3a3c8e0},
	affiliations = {University of Queensland, Brisbane, Australia; University of California, Merced, CA, United States},
	abstract = {Purpose: The purpose of this study is to identify, analyze and explain the ethical implications that can result from the datafication of service. Design/methodology/approach: This study uses a midrange theorizing approach to integrate currently disconnected perspectives on technology-enabled service, data-driven business models, data ethics and business ethics to introduce a novel analytical framework centered on data-driven business models as the general metatheoretical unit of analysis. The authors then contextualize the framework using data-intensive insurance services. Findings: The resulting midrange theory offers new insights into how using machine learning, AI and big data sets can lead to unethical implications. Centered around 13 ethical challenges, this work outlines how data-driven business models redefine the value network, alter the roles of individual actors as cocreators of value, lead to the emergence of new data-driven value propositions, as well as novel revenue and cost models. Practical implications: Future research based on the framework can help guide practitioners to implement and use advanced analytics more effectively and ethically. Originality/value: At a time when future technological developments related to AI, machine learning or other forms of advanced data analytics are unpredictable, this study instigates a critical and timely discourse within the service research community about the ethical implications that can arise from the datafication of service by introducing much-needed theory and terminology. © 2020, Emerald Publishing Limited.},
	author_keywords = {AI; Big data; Business model; Ethics},
	correspondence_address = {C.F. Breidbach; University of Queensland, Brisbane, Australia; email: c.breidbach@business.uq.edu.au},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {17575818},
	language = {English},
	abbrev_source_title = {J. Serv. Manage.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25}
}

@ARTICLE{Lewis202022,
	author = {Lewis, Anna C. F.},
	title = {Where Bioethics Meets Machine Ethics},
	year = {2020},
	journal = {American Journal of Bioethics},
	volume = {20},
	number = {11},
	pages = {22 – 24},
	doi = {10.1080/15265161.2020.1819471},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094645655&doi=10.1080%2f15265161.2020.1819471&partnerID=40&md5=66b9d941b61a9019f12b65eeb8a66815},
	affiliations = {Harvard University, United States},
	keywords = {Bioethics; Ethical Theory; Humans; Machine Learning; Morals; bioethics; ethical theory; human; machine learning; morality},
	correspondence_address = {A.C.F. Lewis; Harvard University, Cambridge, 02138, United States; email: annalewis@fas.harvard.edu},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33103981},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{2020,
	title = {SIGITE 2020 - Proceedings of the 21st Annual Conference on Information Technology Education},
	year = {2020},
	journal = {SIGITE 2020 - Proceedings of the 21st Annual Conference on Information Technology Education},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094918290&partnerID=40&md5=6d310cce098b61ae313b5b77107c4974},
	abstract = {The proceedings contain 101 papers. The topics discussed include: ethics assessed: an interdisciplinary effort to develop standards for automated learning assessment in IT courses; teaching adversarial machine learning: educating the next generation of technical and security professionals; interpretable deep learning for university dropout prediction; understanding students’ identification and use of patterns while writing SQL queries; analytics prevalent undergraduate IT program; benefits and pitfalls of Jupyter notebooks in the classroom; understanding barriers and motivations of non-traditional students learning programming in an online CS1 course; blockchain-based learning credential revision and revocation method; an initial survey of deaf and hard-of-hearing student use of a composite screen solution utilizing web conferencing software; and the adoption, issues, and challenges of wearable healthcare technology for the elderly.},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145037045-5},
	language = {English},
	abbrev_source_title = {SIGITE - Proc. Annu. Conf. Inf. Technol. Educ.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 21st Annual Conference of the Special Interest Group in Information Technology Education, SIGITE 2020; Conference date: 7 October 2020 through 9 October 2020; Conference code: 163733}
}

@ARTICLE{Ellmann20201,
	author = {Ellmann, Stephan and Schlicht, Michael and Dietzel, Matthias and Janka, Rolf and Hammon, Matthias and Saake, Marc and Ganslandt, Thomas and Hartmann, Arndt and Kunath, Frank and Wullich, Bernd and Uder, Michael and Bäuerle, Tobias},
	title = {Computer-aided diagnosis in multiparametric mri of the prostate: An open-access online tool for lesion classification with high accuracy},
	year = {2020},
	journal = {Cancers},
	volume = {12},
	number = {9},
	pages = {1 – 15},
	doi = {10.3390/cancers12092366},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090491568&doi=10.3390%2fcancers12092366&partnerID=40&md5=5f37504b24879171caf191deaa44a0d4},
	affiliations = {Department of Radiology, University Hospital Erlangen, Erlangen, 91054, Germany; Department of Medical Informatics, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, 91058, Germany; Heinrich-Lanz-Center for Digital Health, Department of Biomedical Informatics, University Medicine Mannheim, Heidelberg University, Mannheim, 68177, Germany; Institute of Pathology, University Hospital Erlangen, Erlangen, 91054, Germany; Department of Urology and Paediatric Urology, University Hospital Erlangen, Erlangen, 91054, Germany},
	abstract = {Computer-aided diagnosis (CADx) approaches could help to objectify reporting on prostate mpMRI, but their use in many cases is hampered due to common-built algorithms that are not publicly available. The aim of this study was to develop an open-access CADx algorithm with high accuracy for classification of suspicious lesions in mpMRI of the prostate. This retrospective study was approved by the local ethics commission, with waiver of informed consent. A total of 124 patients with 195 reported lesions were included. All patients received mpMRI of the prostate between 2014 and 2017, and transrectal ultrasound (TRUS)-guided and targeted biopsy within a time period of 30 days. Histopathology of the biopsy cores served as a standard of reference. Acquired imaging parameters included the size of the lesion, signal intensity (T2w images), diffusion restriction, prostate volume, and several dynamic parameters along with the clinical parameters patient age and serum PSA level. Inter-reader agreement of the imaging parameters was assessed by calculating intraclass correlation coefficients. The dataset was stratified into a train set and test set (156 and 39 lesions in 100 and 24 patients, respectively). Using the above parameters, a CADx based on an Extreme Gradient Boosting algorithm was developed on the train set, and tested on the test set. Performance optimization was focused on maximizing the area under the Receiver Operating Characteristic curve (ROCAUC). The algorithm was made publicly available on the internet. The CADx reached an ROCAUC of 0.908 during training, and 0.913 during testing (p = 0.93). Additionally, established rule-in and rule-out criteria allowed classifying 35.8% of the malignant and 49.4% of the benign lesions with error rates of <2%. All imaging parameters featured excellent inter-reader agreement. This study presents an open-access CADx for classification of suspicious lesions in mpMRI of the prostate with high accuracy. Applying the provided rule-in and rule-out criteria might facilitate to further stratify the management of patients at risk. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Artificial intelligence; Computer-aided diagnosis; Machine learning; Prostate cancer; Prostate mpMRI},
	keywords = {prostate specific antigen; adult; aged; antigen blood level; area under the curve; Article; artificial intelligence; clinical assessment; clinical feature; cohort analysis; controlled study; correlational study; descriptive research; diagnostic accuracy; diagnostic test accuracy study; diffusion tensor imaging; health care access; histopathology; human; human tissue; informed consent; machine learning; major clinical study; male; multiparametric magnetic resonance imaging; prostate biopsy; prostate cancer; prostate volume; receiver operating characteristic; retrospective study; risk assessment; scoring system; transrectal ultrasonography; tumor volume},
	correspondence_address = {S. Ellmann; Department of Radiology, University Hospital Erlangen, Erlangen, 91054, Germany; email: stephan.ellmann@uk-erlangen.de},
	publisher = {MDPI AG},
	issn = {20726694},
	language = {English},
	abbrev_source_title = {Cancers},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Boyd202087,
	author = {Boyd, Karen},
	title = {Ethical sensitivity in machine learning development},
	year = {2020},
	journal = {Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW},
	pages = {87 – 92},
	doi = {10.1145/3406865.3418359},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095119149&doi=10.1145%2f3406865.3418359&partnerID=40&md5=d78e671b5b5ac8b190bfc2810d1c93eb},
	affiliations = {University of Maryland, College Park, MD, United States},
	abstract = {Despite a great deal of attention to developing ethical mitigations for Machine Learning (ML) training data and models, we don't yet know how these interventions will be adopted by those who curate data and use them to train ML models. Will they help ML engineers find and address ethical concerns in their work? My proposed dissertation seeks to understand ML engineers? ethical sensitivity? their propensity to notice, analyze, and act on socially impactful aspects of their work-while curating training data and describe the effects of context documents and ethical guides as practice-based ethics interventions in this early stage of ML development. It asks how ML engineers recognize,particularize, and judge ethical questions while exploring new training data; introduces Ethical Sensitivity to the study of social computing; and will describe how Datasheets intervene in perception and particularization; and will develop a document that can help engineers move from particularization to judgment. It will accomplish these goals using a think aloud experiment with engineers working with unfamiliar training data (with or without a Datasheet), a Value Sensitive Design study that aims to fit an ethical mitigation guide to engineers? work practices, and a systematic review of ethical sensitivity. © 2020 Owner/Author.},
	author_keywords = {Datasets; Ethical sensitivity; Ethics; Machine learning; Technology development; Work practices},
	keywords = {Data curation; Engineers; Groupware; Interactive computer systems; Machine learning; Personnel training; Philosophical aspects; Social networking (online); Technology transfer; Data sheets; Ethical concerns; Ethical question; Systematic Review; Think aloud; Training data; Value sensitive design; Work practices; Professional aspects},
	correspondence_address = {K. Boyd; University of Maryland, College Park, United States; email: klboyd@umd.edu},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038059-1},
	language = {English},
	abbrev_source_title = {Proc. ACM Conf. Comput. Support. Coop. Work CSCW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 3rd ACM Conference on Computer-Supported Cooperative Work and Social Computing, CSCW 2020; Conference date: 17 October 2020 through 21 October 2020; Conference code: 164204}
}

@ARTICLE{Raisaro20201721,
	author = {Raisaro, J.L. and Marino, Francesco and Troncoso-Pastoriza, Juan and Beau-Lejdstrom, Raphaelle and Bellazzi, Riccardo and Murphy, Robert and Bernstam, Elmer V. and Wang, Henry and Bucalo, Mauro and Chen, Yong and Gottlieb, Assaf and Harmanci, Arif and Kim, Miran and Kim, Yejin and Klann, Jeffrey and Klersy, Catherine and Malin, Bradley A. and Meán, Marie and Prasser, Fabian and Scudeller, Luigia and Torkamani, Ali and Vaucher, Julien and Puppala, Mamta and Wong, Stephen T. C. and Frenkel-Morgenstern, Milana and Xu, Hua and Musa, Baba Maiyaki and Habib, Abdulrazaq G. and Cohen, Trevor and Wilcox, Adam and Salihu, Hamisu M. and Sofia, Heidi and Jiang, Xiaoqian and Hubaux, J.P.},
	title = {SCOR: A secure international informatics infrastructure to investigate COVID-19},
	year = {2020},
	journal = {Journal of the American Medical Informatics Association},
	volume = {27},
	number = {11},
	pages = {1721 – 1726},
	doi = {10.1093/jamia/ocaa172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089117172&doi=10.1093%2fjamia%2focaa172&partnerID=40&md5=93a883a344f4e19a42541136ddc1125d},
	affiliations = {Data Science Group and Precision Medicine Unit, Lausanne University Hospital, Lausanne, Switzerland; Laboratory for Data Security, EPFL, Lausanne, Switzerland; Institute of Global Health, University of Geneva, Geneva, Switzerland; Department of Electrical Computer and Biomedical Engineering, University of Pavia, Pavia, Italy; IRCCS ICS Maugeri, Pavia, Italy; School of Biomedical Informatics, UTHealth, Houston, TX, United States; Division of General Internal Medicine, Department of Internal Medicine, McGovern School of Medicine, UTHealth, Houston, TX, United States; Department of Emergency Medicine, McGovern School of Medicine, UTHealth, Houston, TX, United States; BIOMERIS Srl, Pavia, Italy; Department of Biostatistics Epidemiology and Informatics, Perelman School of Medicine, University of Pennsylvania, Philadelphia, PA, United States; Laboratory of Computer Science, Massachusetts General Hospital, Boston, MA, United States; Biometry and Clinical Epidemiology Service, Fondazione IRCCS Policlinico San Matteo, Pavia, Italy; Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Internal Medicine, Lausanne University Hospital, Lausanne, Switzerland; Medical Informatics Group, Berlin Institute of Health, Berlin, Germany; Charité-Universitätsmedizin Berlin, Berlin, Germany; Scientific Direction, Clinical Epidemiology and Biostatistics, Fondazione IRCCS Ca' Grande Ospedale Maggiore Policlinico, Milan, Italy; Department of Integrative Structural and Computational Biology, Scripps Research, San Diego, CA, United States; Department of Systems Medicine and Bioengineering, Houston Methodist Cancer Center, Weill Cornell Medical College, Houston, TX, United States; Cancer Genomics and BioComputing of Complex Diseases Laboratory, Azrieli Faculty of Medicine, Bar-Ilan University, Safed, Israel; Department of Medicine, Africa Center of Excellence in Population Health and Policy, Bayero University, Kano, Nigeria; Biomedical Informatics and Medical Education, University of Washington, Seattle, WA, United States; Department of Family and Community Medicine, Baylor College of Medicine, Houston, TX, United States; National Institutes of Health (NIH), National Human Genome Research Institute, Bethesda, MD, United States},
	abstract = {Global pandemics call for large and diverse healthcare data to study various risk factors, treatment options, and disease progression patterns. Despite the enormous efforts of many large data consortium initiatives, scientific community still lacks a secure and privacy-preserving infrastructure to support auditable data sharing and facilitate automated and legally compliant federated analysis on an international scale. Existing health informatics systems do not incorporate the latest progress in modern security and federated machine learning algorithms, which are poised to offer solutions. An international group of passionate researchers came together with a joint mission to solve the problem with our finest models and tools. The SCOR Consortium has developed a ready-to-deploy secure infrastructure using world-class privacy and security technologies to reconcile the privacy/utility conflicts. We hope our effort will make a change and accelerate research in future pandemics with broad and diverse samples on an international scale.  © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of the American Medical Informatics Association.},
	author_keywords = {COVID-19; federated learning; healthcare privacy; international consortium; secure data analysis},
	keywords = {Biomedical Research; Computer Security; Coronavirus Infections; Humans; Information Dissemination; Internationality; Machine Learning; Pandemics; Pneumonia, Viral; Privacy; Article; clinical research; coronavirus disease 2019; hospital readmission; hospitalization; human; information processing; information science; information security; pandemic; prediction; privacy; risk factor; computer security; Coronavirus infection; ethics; information dissemination; international cooperation; machine learning; medical research; pandemic; privacy; virus pneumonia},
	correspondence_address = {X. Jiang; School of Biomedical Informatics, UTHealth, Houston, 7000 Fannin St #600, United States; email: xiaoqian.jiang@uth.tmc.edu},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	pmid = {32918447},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{McGreevey2020552,
	author = {McGreevey, John D. and Hanson, C. William and Koppel, Ross},
	title = {Clinical, legal, and ethical aspects of artificial intelligence-assisted conversational agents in health care},
	year = {2020},
	journal = {JAMA - Journal of the American Medical Association},
	volume = {324},
	number = {6},
	pages = {552 – 553},
	doi = {10.1001/jama.2020.2724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089192624&doi=10.1001%2fjama.2020.2724&partnerID=40&md5=71515d98de238084b10795712928ef3b},
	affiliations = {University of Pennsylvania Health System, Perelman School of Medicine, Section of Hospital Medicine, Division of General Internal Medicine, Institute for Biomedical Informatics, University of Pennsylvania, Philadelphia, United States; Perelman School of Medicine, University of Pennsylvania, University of Pennsylvania Health System, Philadelphia, United States; School of Engineering and Applied Science, University of Pennsylvania, Philadelphia, United States; Department of Medical Informatics, Jacobs School of Medicine, University at Buffalo, State University of New York, Buffalo, United States},
	keywords = {Artificial Intelligence; Bioethical Issues; Communication; Computer Security; Delivery of Health Care; Federal Government; Government Regulation; Humans; Natural Language Processing; Speech Recognition Software; artificial intelligence; clinician; computer security; decision making; Food and Drug Administration; government; health care; health care organization; health care system; health equity; legal aspect; licence; licensing; machine learning; medical ethics; natural language processing; Note; patient safety; priority journal; privacy; scoring system; simulation; software; technology; automatic speech recognition; bioethics; ethics; government regulation; health care delivery; human; interpersonal communication; legislation and jurisprudence; procedures},
	correspondence_address = {J.D. Mcgreevey; University of Pennsylvania Health System, Philadelphia, 3400 Spruce St, 19104, United States; email: john.mcgreevey@pennmedicine.upenn.edu},
	publisher = {American Medical Association},
	issn = {00987484},
	coden = {JAMAA},
	pmid = {32706386},
	language = {English},
	abbrev_source_title = {JAMA},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 39}
}

@CONFERENCE{Sweetser2020,
	author = {Sweetser, Penny and Aitchison, Matthew},
	title = {Do Game Bots Dream of Electric Rewards?: The universality of intrinsic motivation},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3402942.3402965},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092307187&doi=10.1145%2f3402942.3402965&partnerID=40&md5=bcba7a09febada8e50a14c282b76433d},
	affiliations = {Australian National University, Australia},
	abstract = {The purpose of this paper is to draw together theories, ideas, and observations related to rewards, motivation, and play to develop and question our understanding and practice of designing reward-based systems and technology. Our exploration includes reinforcement, rewards, motivational theory, flow, play, games, gamification, and machine learning. We examine the design and psychology of reward-based systems in society and technology, using gamification and machine learning as case studies. We propose that the problems that exist with reward-based systems in our society are also present and pertinent when designing technology. We suggest that motivation, exploration, and play are not just fundamental to human learning and behaviour, but that they could transcend nature into machine learning. Finally, we question the value and potential harm of the reward-based systems that permeate every aspect of our lives and assert the importance of ethics in the design of all systems and technology. © 2020 ACM.},
	author_keywords = {flow; games; gamification; intrinsic motivation; learning; machine learning; play; reinforcement learning; reward-based systems; rewards; self-determination theory},
	keywords = {Behavioral research; Botnet; Computer games; Gamification; Machine learning; Case-studies; Game bots; Human learning; Intrinsic motivation; Potential harm; Society and technologies; Motivation},
	editor = {Yannakakis G.N. and Liapis A. and Penny K. and Volz V. and Khosmood F. and Lopes P.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038807-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on the Foundations of Digital Games, FDG 2020; Conference date: 15 September 2020 through 18 September 2020; Conference code: 163063; All Open Access, Green Open Access}
}

@CONFERENCE{Belavadi202099,
	author = {Belavadi, Vibha and Zhou, Yan and Bakdash, Jonathan Z. and Kantarcioglu, Murat and Krawczyk, Daniel C. and Nguyen, Linda and Rakic, Jelena and Thuriasingham, Bhavani},
	title = {MultiModal Deception Detection: Accuracy, Applicability and Generalizability*},
	year = {2020},
	journal = {Proceedings - 2020 2nd IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications, TPS-ISA 2020},
	pages = {99 – 106},
	doi = {10.1109/TPS-ISA50397.2020.00023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100426913&doi=10.1109%2fTPS-ISA50397.2020.00023&partnerID=40&md5=28705a33e970c9a6b13ac26421dba51f},
	affiliations = {University of Texas at Dallas, Department of Computer Science, Richardson, 75080, TX, United States; Army Research Laboratory South, University of Texas at Dallas, U.S. Army Combat Capabilities Development Command, Richardson, 75080, TX, United States; University of Texas at Dallas, School of Behavioral and Brain Sciences, Richardson, 75080, TX, United States},
	abstract = {The increasing use of Artificial Intelligence (AI) systems in face recognition and video processing in recent times creates higher stakes for their application in daily life. Increasingly, critical decisions are being made using these AI systems in application domains such as employment, finance, and crime prevention. These applications are done through the use of more abstract concepts such as emotions, trait evaluations (e.g., trustworthiness), and behavior (e.g., deception). These abstract concepts are learned by the AI system using the verbal and non-verbal cues from the human subject stimuli (e,g., facial expressions, movements, audio, text) for inference. Because the use of AI systems often happens in high stakes scenarios, it is of utmost importance that the AI system participating in the decision-making process is highly reliable and credible. In this paper, we specifically consider the feasibility of using such an AI system for deception detection. We examine if deception can be caught using multimodal aspects such as facial expressions and movements, audio cues, video cues, etc. We experiment using three different datasets with varying degrees of deception to explore the problem of deception detection. We also study state-of-the-art deception detection systems and investigate whether we can extend their algorithm into new datasets. We conclude that there is a lack of reasonable evidence that AI-based deception detection is generalizable over different scenarios of lying (lying deliberately, lying under duress, and lying through half-truths) and that in the future additional factors will need to be considered to make such a claim. © 2020 IEEE.},
	author_keywords = {deception detection; ethics; facial expressions; machine learning; multi-modal data analysis},
	keywords = {Behavioral research; Decision making; Intelligent systems; Network security; Privacy by design; Video signal processing; Abstract concept; Crime Prevention; Deception detection; Decision making process; Facial Expressions; Human subjects; State of the art; Video processing; Face recognition},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172818543-9},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Trust, Priv. Secur. Intell. Syst. Appl., TPS-ISA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2nd IEEE International Conference on Trust, Privacy and Security in Intelligent Systems and Applications, TPS-ISA 2020; Conference date: 1 December 2020 through 3 December 2020; Conference code: 166664}
}

@ARTICLE{Levin2020655,
	author = {Levin, M. and Bongard, J. and Lunshof, J.E.},
	title = {Applications and ethics of computer-designed organisms},
	year = {2020},
	journal = {Nature Reviews Molecular Cell Biology},
	volume = {21},
	number = {11},
	pages = {655 – 656},
	doi = {10.1038/s41580-020-00284-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089257997&doi=10.1038%2fs41580-020-00284-z&partnerID=40&md5=5e67e2dc9adf793477bb939ada6d4be2},
	affiliations = {Allen Discovery Center at Tufts University, Medford, MA, United States; Wyss Institute for Biologically Inspired Engineering, Harvard University, Boston, MA, United States; Department of Computer Science, University of Vermont, Burlington, VT, United States; Department of Global Health and Social Medicine, Harvard Center for Bioethics, Harvard Medical School, Boston, MA, United States; Department of Genetics, University Medical Center Groningen, University of Groningen, Groningen, Netherlands},
	keywords = {Animals; Biomedical Engineering; Computer-Assisted Instruction; Computers; Developmental Biology; Humans; Machine Learning; biobot; bioengineering; biomedicine; ethics; machine learning; Note; organisms; priority journal; robotics; xenobot; animal; biomedical engineering; computer; developmental biology; ethics; human; teaching},
	correspondence_address = {M. Levin; Allen Discovery Center at Tufts University, Medford, United States; email: michael.levin@tufts.edu},
	publisher = {Nature Research},
	issn = {14710072},
	coden = {NRMCB},
	pmid = {32782340},
	language = {English},
	abbrev_source_title = {Nat. Rev. Mol. Cell Biol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}

@ARTICLE{Haque2020193,
	author = {Haque, Albert and Milstein, Arnold and Fei-Fei, Li},
	title = {Illuminating the dark spaces of healthcare with ambient intelligence},
	year = {2020},
	journal = {Nature},
	volume = {585},
	number = {7824},
	pages = {193 – 202},
	doi = {10.1038/s41586-020-2669-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090380499&doi=10.1038%2fs41586-020-2669-y&partnerID=40&md5=9deefaba9e27b1c91ce68731bbd78017},
	affiliations = {Department of Computer Science, Stanford University, Stanford, CA, United States; Clinical Excellence Research Center, Stanford University School of Medicine, Stanford, CA, United States; Stanford Institute for Human-Centered Artificial Intelligence, Stanford University, Stanford, CA, United States},
	abstract = {Advances in machine learning and contactless sensors have given rise to ambient intelligence—physical spaces that are sensitive and responsive to the presence of humans. Here we review how this technology could improve our understanding of the metaphorically dark, unobserved spaces of healthcare. In hospital spaces, early applications could soon enable more efficient clinical workflows and improved patient safety in intensive care units and operating rooms. In daily living spaces, ambient intelligence could prolong the independence of older individuals and improve the management of individuals with a chronic disease by understanding everyday behaviour. Similar to other technologies, transformation into clinical applications at scale must overcome challenges such as rigorous clinical validation, appropriate data privacy and model transparency. Thoughtful use of this technology would enable us to understand the complex interplay between the physical environment and health-critical human behaviours. © 2020, Springer Nature Limited.},
	keywords = {Algorithms; Ambient Intelligence; Chronic Disease; Delivery of Health Care; Environmental Monitoring; Hospital Units; Humans; Mental Health; Patient Safety; Privacy; artificial intelligence; machine learning; model validation; numerical model; physical analysis; algorithm; ambient intelligence; behavior; behavior assessment; chronic disease; computer aided design; convolutional neural network; critically ill patient; daily life activity; elderly care; endoscopic surgery; falling; health care delivery; hospital; hospital cost; hospital infection; infection control; intensive care unit; machine learning; medical documentation; mental health; patient mobility; patient monitoring; patient safety; priority journal; privacy; research ethics; Review; workflow; chronic disease; environmental monitoring; health care delivery; hospital subdivisions and components; human; procedures},
	correspondence_address = {L. Fei-Fei; Department of Computer Science, Stanford University, Stanford, United States; email: feifeili@stanford.edu},
	publisher = {Nature Research},
	issn = {00280836},
	coden = {NATUA},
	pmid = {32908264},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 101; All Open Access, Bronze Open Access}
}

@ARTICLE{Dixon-Román2020116,
	author = {Dixon-Román, Ezekiel and Parisi, Luciana},
	title = {Data capitalism and the counter futures of ethics in artificial intelligence},
	year = {2020},
	journal = {Communication and the Public},
	volume = {5},
	number = {3-4},
	pages = {116 – 121},
	doi = {10.1177/2057047320972029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095958612&doi=10.1177%2f2057047320972029&partnerID=40&md5=f1526bda247b610023c2111197eec2e2},
	affiliations = {University of Pennsylvania, United States; Duke University, United States},
	abstract = {Ethics in data science and artificial intelligence have gained broader prominence in both scholarly and public discourse. Much of the scholarly engagements have often been based on perspectives of transparency, politics of representation, moral ethical norms, and refusal. In this article, while the authors agree that there is a problem with the universal model of technology, they argue that what these perspectives do not address is the postcolonial epistemology of the machine. Drawing from Mark Fisher’s science fiction capital, it is posited that data capitalism doesn’t rely on data as a given, but on what data can become; it operates in the future as much as the calculation of probabilities coincides with the predictive extraction of surplus value. The authors argue that in order to address ethical and sociopolitical concerns in artificial intelligence, technosocial systems must be understood in data capitalism. After discussing what they characterize as the three paradigms of prediction, the authors point toward the transformative potential of temporal structures and indeterminacies in automated self-regulating systems. They argue therefore that assumptions of technological determinism that are found in debates about the reproduction of biases in systems of predictive intelligence has nothing to do with the technical machine, but is rather the result of a continuous re-territorialization of the technosocial possibilities of re-inventing epistemological paradigms outside the framework of colonial capital. © The Author(s) 2020.},
	author_keywords = {Artificial intelligence; critical theory; ethics; machine learning; postcolonial studies},
	correspondence_address = {E. Dixon-Román; University of Pennsylvania, United States; email: ezekield@sp2.upenn.edu},
	publisher = {SAGE Publications Inc.},
	issn = {20570481},
	language = {English},
	abbrev_source_title = {Communication and the Public},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Skeba2020,
	author = {Skeba, Patrick and Baumer, Eric P. S.},
	title = {Informational Friction as a Lens for Studying Algorithmic Aspects of Privacy},
	year = {2020},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	volume = {4},
	number = {CSCW2},
	doi = {10.1145/3415172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094214547&doi=10.1145%2f3415172&partnerID=40&md5=a97e4960c981d0633c598de1379ff382},
	affiliations = {Lehigh University, Bethlehem, PA, United States},
	abstract = {This paper addresses challenges in conceptualizing privacy posed by algorithmic systems that can infer sensitive information from seemingly innocuous data. This type of privacy is of imminent concern due to the rapid adoption of machine learning and artificial intelligence systems in virtually every industry. In this paper, we suggest informational friction, a concept from Floridi's ethics of information, as a valuable conceptual lens for studying algorithmic aspects of privacy. Informational friction describes the amount of work required for one agent to access or alter the information of another. By focusing on amount of work, rather than the type of information or manner in which it is collected, informational friction can help to explain why automated analyses should raise privacy concerns independently of, and in addition to, those associated with data collection. As a demonstration, this paper analyze law enforcement use of facial recognition, andFacebook's targeted advertising model using informational friction and demonstrate risks inherent to these systems which are not completely identified in another popular framework, Nissenbaum's Contextual Integrity.The paper concludes with a discussion of broader implications, both for privacy research and for privacy regulation.  © 2020 ACM.},
	author_keywords = {algorithmic privacy; facial recognition; informational friction; privacy; targeted advertising},
	keywords = {Artificial intelligence; Face recognition; Friction; Laws and legislation; Algorithmic aspects; Artificial intelligence systems; Automated analysis; Facial recognition; Privacy concerns; Privacy regulation; Sensitive informations; Targeted advertising; Privacy by design},
	publisher = {Association for Computing Machinery},
	issn = {25730142},
	language = {English},
	abbrev_source_title = {Proc. ACM Hum. Comput. Interact.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@CONFERENCE{Elgezery2020894,
	author = {Elgezery, Hanan Wagih and Awny, Mohamed Mamdouh},
	title = {Artificial intelligence for retail industry in Egypt: Challenges and opportunities},
	year = {2020},
	journal = {Towards the Digital World and Industry X.0 - Proceedings of the 29th International Conference of the International Association for Management of Technology, IAMOT 2020},
	pages = {894 – 906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092644251&partnerID=40&md5=e2a43bca86018e38880f52222dc19520},
	affiliations = {Nile University / Good News 4Me, Data management, Egypt; Nile University, Nile University, Management of Technology, Egypt},
	abstract = {In the era of digital transformation, a mass disruption in the global industries have been detected. Big data, the Internet of Things (IoT) and Artificial Intelligence (AI) are just examples of technologies that are holding such digital disruptive power. On the other hand, retailing is a high-intensity competition and disruptive industry driving the global economy and the second largest globally in employment after the agriculture. AI has large potential to contribute to global economic activity and the biggest sector gains would be in retail. AI is the engine that is poised to drive the future of retail to all-new destinations. The purpose of this research paper is to identify the real opportunities and threats for AI in the Egyptian retail business. Drawing on a detailed analysis to assess the AI opportunity for Egypt in terms of technology, people, culture and ethics and impact using Microsoft five dimensions model conducted in 2018 in UK. Automation of labor was found to play the greatest role to improve the productivity rate in Egypt and the early digitization is the key AI enabler in the country. The research paper highlighted the importance of leveraging data science and build a data asset to both upgrade the customers' experiences and drive digital transformation in retail industry. In brief, this research paper attempts to answer the question “What are the real opportunities and threats for AI in the retail business?” Drawing on a detailed analysis of the business impacts of AI in the Egyptian market and the way to take advantage of them. Further studied are needed to establish the framework that consists of a baseline set of retail business processes integrated with the sales predictive machine learning models. So, the AI model will be embedded in the business process and maintained over time to achieve the full benefit of it. © 2020 Towards the Digital World and Industry X.0 - Proceedings of the 29th International Conference of the International Association for Management of Technology, IAMOT 2020. All rights reserved.},
	author_keywords = {AI; Data analytics; Deep Learning; Machine Learning; Predictive Analytics; Retail},
	keywords = {Agricultural robots; Competition; Digital storage; Industrial management; Internet of things; Metadata; Predictive analytics; Sales; Business impact; Business Process; Digital transformation; Global economic activity; Global economies; Internet of thing (IOT); Machine learning models; Productivity rate; Artificial intelligence},
	editor = {Pretorius L. and Pretorius M.W.},
	publisher = {University of Pretoria},
	isbn = {978-177592195-0},
	language = {English},
	abbrev_source_title = {Towards Digit. World Ind. X.0 - Proc. Int. Conf. Int. Assoc. Manag. Technol., IAMOT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 29th International Conference of the International Association for Management of Technology: Towards the Digital World and Industry X.0, IAMOT 2020; Conference date: 13 September 2020 through 17 September 2020; Conference code: 163281}
}

@CONFERENCE{Richardson2020489,
	author = {Richardson, Brianna and Prioleau, Diandra and Alikhademi, Kiana and Gilbert, Juan E.},
	title = {Public Accountability: Understanding Sentiments towards Artificial Intelligence across Dispositional Identities},
	year = {2020},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2020-November},
	pages = {489 – 496},
	doi = {10.1109/ISTAS50296.2020.9462184},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113198806&doi=10.1109%2fISTAS50296.2020.9462184&partnerID=40&md5=af6c2be0da1cacd7030fb32e8a0055c4},
	affiliations = {University of Florida Gainesville, Computer Information Science Engineering, Usa, United States},
	abstract = {Artificial Intelligence (Al) and Machine Learning (ML) have been influential across many industries. Companies, nearly every day, are finding new means and methods of benefiting from these technologies. Despite this prevalence, individuals still report a significant level of distrust towards Al and its applications. To rehabilitate the relationship between Al and its consumers, developers must expose these new technologies to consumers and include them in the process of critiquing and assisting in the improvement of such technologies. The goal of this work is to introduce a new initiative towards an Ethical Al society. Participants are given the opportunity to learn about modem applications of Al and the space to reflect on these technologies. It is found that across the exampled technologies, differences of opinions are significantly correlated to specific dispositional identities, such as gender and computing experience. Furthermore, trends of trust across the general public are compared to that of students enrolled in a computer science course. These results depict vastly differing opinions across technologies which validate the need for public exposure and critique. This work highlights the need for researchers and developers to investigate opinions across dispositional identities, including race, gender, socioeconomic status, etc. The study has shown to be beneficial, with over 70% of individuals reporting having learned about a new application of Al. © 2020 IEEE.},
	author_keywords = {Al; algorithmic bias; ethics; fairness; ML; trust inAI},
	keywords = {Engineering education; Computer Science course; Gender and computing; General publics; ITS applications; New applications; Public accountability; Public exposure; Socio-economic status; Artificial intelligence},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-166541507-1},
	language = {English},
	abbrev_source_title = {Int Symp Technol Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 IEEE International Symposium on Technology and Society, ISTAS 2020; Conference date: 12 November 2020 through 15 November 2020; Conference code: 171023}
}

@ARTICLE{Germann2020499,
	author = {Germann, Christoph and Marbach, Giuseppe and Civardi, Francesco and Fucentese, Sandro F. and Fritz, Jan and Sutter, Reto and Pfirrmann, Christian W.A. and Fritz, Benjamin},
	title = {Deep Convolutional Neural Network-Based Diagnosis of Anterior Cruciate Ligament Tears: Performance Comparison of Homogenous Versus Heterogeneous Knee MRI Cohorts with Different Pulse Sequence Protocols and 1.5-T and 3-T Magnetic Field Strengths},
	year = {2020},
	journal = {Investigative Radiology},
	volume = {55},
	number = {8},
	pages = {499 – 506},
	doi = {10.1097/RLI.0000000000000664},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088207831&doi=10.1097%2fRLI.0000000000000664&partnerID=40&md5=9525daa29e7118aa21cbbb781d7c23e0},
	affiliations = {Department of Radiology, Balgrist University Hospital, Forchstrasse 340, Zurich, CH-8008, Switzerland; Faculty of Medicine, University of Zurich, Switzerland; Balzano Informatik AG, Switzerland; Department of Orthopedic Surgery, Balgrist University Hospital, Zurich, Switzerland; Russell H. Morgan Department of Radiology and Radiological Science, Johns Hopkins University School of Medicine, Baltimore, MD, United States},
	abstract = {Objectives The aim of this study was to clinically validate a Deep Convolutional Neural Network (DCNN) for the detection of surgically proven anterior cruciate ligament (ACL) tears in a large patient cohort and to analyze the effect of magnetic resonance examinations from different institutions, varying protocols, and field strengths. Materials and Methods After ethics committee approval, this retrospective analysis of prospectively collected data was performed on 512 consecutive subjects, who underwent knee magnetic resonance imaging (MRI) in a total of 59 different institutions followed by arthroscopic knee surgery at our institution. The DCNN and 3 fellowship-trained full-time academic musculoskeletal radiologists evaluated the MRI examinations for full-thickness ACL tears independently. Surgical reports served as the reference standard. Statistics included diagnostic performance metrics, including sensitivity, specificity, area under the receiver operating curve ("AUC ROC"), and kappa statistics. P values less than 0.05 were considered to represent statistical significance. Results Anterior cruciate ligament tears were present in 45.7% (234/512) and absent in 54.3% (278/512) of the subjects. The DCNN had a sensitivity of 96.1%, which was not significantly different from the readers (97.5%-97.9%; all P ≥ 0.118), but significantly lower specificity of 93.1% (readers, 99.6%-100%; all P < 0.001) and "AUC ROC"of 0.935 (readers, 0.989-0.991; all P < 0.001) for the entire cohort. Subgroup analysis showed a significantly lower sensitivity, specificity, and "AUC ROC"of the DCNN for outside MRI (92.5%, 87.1%, and 0.898, respectively) than in-house MRI (99.0%, 94.4%, and 0.967, respectively) examinations (P = 0.026, P = 0.043, and P < 0.05, respectively). There were no significant differences in DCNN performance for 1.5-T and 3-T MRI examinations (all P ≥ 0.753, respectively). Conclusions Deep Convolutional Neural Network performance of ACL tear diagnosis can approach performance levels similar to fellowship-trained full-time academic musculoskeletal radiologists at 1.5 T and 3 T; however, the performance may decrease with increasing MRI examination heterogeneity.  © Wolters Kluwer Health, Inc. All rights reserved.},
	author_keywords = {anterior cruciate ligament injuries; artificial intelligence; knee injuries; magnetic resonance imaging; neural networks (computer)},
	keywords = {Adult; Anterior Cruciate Ligament Injuries; Arthroscopy; Cohort Studies; Deep Learning; Female; Humans; Image Processing, Computer-Assisted; Magnetic Fields; Magnetic Resonance Imaging; Male; Retrospective Studies; Sensitivity and Specificity; adult; anterior cruciate ligament rupture; area under the curve; Article; cohort analysis; controlled study; convolutional neural network; diagnostic accuracy; diagnostic test accuracy study; female; human; image analysis; knee surgery; machine learning; major clinical study; male; nuclear magnetic resonance imaging; prevalence; priority journal; prospective study; receiver operating characteristic; retrospective study; sensitivity and specificity; training; anterior cruciate ligament injury; arthroscopy; comparative study; diagnostic imaging; image processing; magnetic field; procedures},
	publisher = {Lippincott Williams and Wilkins},
	issn = {00209996},
	coden = {INVRA},
	pmid = {32168039},
	language = {English},
	abbrev_source_title = {Invest. Radiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Brouwer2020144,
	author = {Brouwer, Charlotte L. and Dinkla, Anna M. and Vandewinckele, Liesbeth and Crijns, Wouter and Claessens, Michaël and Verellen, Dirk and van Elmpt, Wouter},
	title = {Machine learning applications in radiation oncology: Current use and needs to support clinical implementation},
	year = {2020},
	journal = {Physics and Imaging in Radiation Oncology},
	volume = {16},
	pages = {144 – 148},
	doi = {10.1016/j.phro.2020.11.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097178517&doi=10.1016%2fj.phro.2020.11.002&partnerID=40&md5=9f157c054ec84e098fc56ede670a5a3f},
	affiliations = {University of Groningen, University Medical Center Groningen, Department of Radiation Oncology, Groningen, Netherlands; Department of Radiation Oncology, Amsterdam University Medical Center, VU University, Netherlands; Department Oncology, Laboratory of Experimental Radiotherapy, KU Leuven, Leuven, Belgium; Radiation Oncology, UZ Leuven, Leuven, Belgium; Iridium Network, Wilrijk (Antwerp), Belgium; Faculty of Medicine and Health Sciences, University of Antwerp, Antwerp, Belgium; Department of Radiation Oncology (MAASTRO), GROW School for Oncology, Maastricht University Medical Centre+, Maastricht, Netherlands},
	abstract = {Background and purpose: The use of artificial intelligence (AI)/ machine learning (ML) applications in radiation oncology is emerging, however no clear guidelines on commissioning of ML-based applications exist. The purpose of this study was therefore to investigate the current use and needs to support implementation of ML-based applications in routine clinical practice. Materials and methods: A survey was conducted among medical physicists in radiation oncology, consisting of four parts: clinical applications (1), model training, acceptance and commissioning (2), quality assurance (QA) in clinical practice and General Data Protection Regulation (GDPR) (3), and need for education and guidelines (4). Survey answers of medical physicists of the same radiation oncology centre were treated as a separate unique responder in case reporting on different AI applications. Results: In total, 213 medical physicists from 202 radiation oncology centres were included in the analysis. Sixty-nine percent (1 4 7) was using (37%) or preparing (32%) to use ML in clinic, mostly for contouring and treatment planning. In 86%, human observers were still involved in daily clinical use for quality check of the output of the ML algorithm. Knowledge on ethics, legislation and data sharing was limited and scattered among responders. Besides the need for (implementation) guidelines, training of medical physicists and larger databases containing multicentre data was found to be the top priority to accommodate the further introduction of ML in clinical practice. Conclusion: The results of this survey indicated the need for education and guidelines on the implementation and quality assurance of ML-based applications to benefit clinical introduction. © 2020 The Author(s)},
	author_keywords = {Artificial intelligence; Clinical implementation; Commissioning; Machine learning; Quality assurance; Radiotherapy; Survey},
	keywords = {adult; algorithm; article; artificial intelligence; case report; clinical article; education; ethics; female; human; human experiment; law; machine learning; male; medical physicist; multicenter study; practice guideline; quality control; radiation oncology; radiotherapy; treatment planning},
	correspondence_address = {C.L. Brouwer; Department of Radiation Oncology, University Medical Center Groningen, RB Groningen, PO Box 30001, 9700, Netherlands; email: c.l.brouwer@umcg.nl},
	publisher = {Elsevier Ireland Ltd},
	issn = {24056316},
	language = {English},
	abbrev_source_title = {Phy. Imaging Radiat. Oncol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 30; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Slota2020,
	author = {Slota, Stephen C. and Fleischmann, Kenneth R. and Greenberg, Sherri and Verma, Nitin and Cummings, Brenna and Li, Lan and Shenefiel, Chris},
	title = {Good systems, bad data?: Interpretations of AI hype and failures},
	year = {2020},
	journal = {Proceedings of the Association for Information Science and Technology},
	volume = {57},
	number = {1},
	doi = {10.1002/pra2.275},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111267771&doi=10.1002%2fpra2.275&partnerID=40&md5=6f8be294e7928e22eda1bda855628cbd},
	affiliations = {School of Information, The University of Texas at Austin, Austin, TX, United States; LBJ School of Public Affairs, The University of Texas at Austin, Austin, TX, United States; Cisco Systems, San Jose, CA, United States},
	abstract = {Artificial intelligence (AI), including machine learning (ML), is widely viewed as having substantial transformative potential across society, and novel implementations of these technologies promise new modes of living, working, and community engagement. Data and the algorithms that operate upon it thus operate under an expansive ethical valence, bearing consequence to both the development of these potentially transformative technologies and our understanding of how best to manage and support its impact. This paper reports upon an interview-driven study of stakeholders engaged with technology development, policy, and law relating to AI. Among our participating stakeholders, unexpected outcomes and flawed implementations of AI, especially those leading to negative social consequences, are often attributed to ill-structured, incomplete, or biased data, and the algorithms and interpretations that might produce negative social consequence are seen as neutrally representing the data, or otherwise blameless in that consequence. We propose a more complex infrastructural view of the tools, data, and operation of AI systems as necessary to the production of social good, and explore how representations of the successes and failures of these systems, even among experts, tend to valorize algorithmic analysis and locate fault at the quality of the data rather than the implementation of systems. 83rd Annual Meeting of the Association for Information Science & Technology October 25-29, 2020. Author(s) retain copyright, but ASIS&T receives an exclusive publication license.},
	author_keywords = {critical infrastructure studies; ethics of artificial intelligence; media hype; value-sensitive design},
	keywords = {Economic and social effects; Ethical technology; Bad data; Community engagement; Critical infrastructure study; Ethic of artificial intelligence; Machine-learning; Medium hype; Social consequences; Technology development; Technology policy; Value sensitive design; Artificial intelligence},
	correspondence_address = {S.C. Slota; School of Information, The University of Texas at Austin, Austin, United States; email: steveslota@gmail.com},
	publisher = {John Wiley and Sons Inc},
	issn = {23739231},
	language = {English},
	abbrev_source_title = {Proceedings of the Association for Information Science and Technology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Deepak20203511,
	author = {Deepak, P. and Jose, Joemon M. and Sanil, V.},
	title = {Fairness in Unsupervised Learning},
	year = {2020},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {3511 – 3512},
	doi = {10.1145/3340531.3412175},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095865067&doi=10.1145%2f3340531.3412175&partnerID=40&md5=5614832c5589fe97a43bd204181384c9},
	affiliations = {Queen's University Belfast, Belfast, United Kingdom; University of Glasgow, Glasgow, United Kingdom; Indian Institute of Technology Delhi, New Delhi, India},
	abstract = {Data in digital form is expanding at an exponential rate, far outpacing any chance of getting any significant fraction labelled manually. This has resulted in heightened research emphasis on unsupervised learning, learning in the absence of labels. In fact, unsupervised learning has been often dubbed as the next frontier of AI. Unsupervised learning is the most plausible model to analyze the bulk of passively collected data that spans across various domains; e.g., social media footprints, safety/surveilance cameras, IoT devices, sensors, smartphone apps, medical wearables, traffic sensing devices and public wi-fi access. While fairness in supervised learning, such as classification tasks, has inspired a large amount of research in the past few years, work on fair unsupervised learning has been relatively slow in picking up. This tutorial targets to provide an overview of: (i) fairness issues in unsupervised learning drawing abundantly from political philosophy, (ii) current research in fair unsupervised learning, and (iii) new directions to extend the state-of-the-art in fair unsupervised learning. While we intend to broadly cover all tasks in unsupervised learning, our focus will be on clustering, retrieval and representation learning. In a unique departure from conventional data science tutorials, we will place significant emphasis on presenting and debating pertinent literature from ethics and philosophy. Overall, this half-day tutorial brings a strong emphasis on ensuring strong interdisciplinarity. © 2020 Owner/Author.},
	author_keywords = {fairness; machine learning; unsupervised learning},
	keywords = {Data Science; Knowledge management; mHealth; Classification tasks; Digital forms; Exponential rates; Interdisciplinarity; Plausible model; Sensing devices; Smartphone apps; State of the art; Unsupervised learning},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036859-9},
	language = {English},
	abbrev_source_title = {Int Conf Inf Knowledge Manage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 29th ACM International Conference on Information and Knowledge Management, CIKM 2020; Conference date: 19 October 2020 through 23 October 2020; Conference code: 164320}
}

@ARTICLE{Bombard2020505,
	author = {Bombard, Yvonne and Hayeems, Robin Z.},
	title = {How digital tools can advance quality and equity in genomic medicine},
	year = {2020},
	journal = {Nature Reviews Genetics},
	volume = {21},
	number = {9},
	pages = {505 – 506},
	doi = {10.1038/s41576-020-0260-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087026986&doi=10.1038%2fs41576-020-0260-x&partnerID=40&md5=da760a62b9dc24d1afc58ff965b7d863},
	affiliations = {Genomics Health Services Research Program, Li Ka Shing Knowledge Institute, St. Michael’s Hospital, Unity Health, Toronto, ON, Canada; Institute of Health Policy Management and Evaluation, University of Toronto, Toronto, ON, Canada; Program in Child Health Evaluative Sciences, The Hospital for Sick Children, Toronto, ON, Canada},
	keywords = {Betacoronavirus; Coronavirus Infections; Genetic Counseling; Genetics, Medical; Health Services Accessibility; Healthcare Disparities; Humans; Pandemics; Pneumonia, Viral; Quality Assurance, Health Care; Social Distance; Software; Telemedicine; algorithm; capacity building; clinical outcome; coronavirus disease 2019; decision support system; family history; health care access; health equity; health literacy; human; internet access; machine learning; medical geneticist; medical genetics; medical record; medication compliance; multidisciplinary team; Note; participatory management; patient counseling; patient referral; preventive health service; priority journal; tertiary health care; videoconferencing; watershed; Betacoronavirus; Coronavirus infection; devices; ethics; genetic counseling; health care delivery; health care disparity; health care quality; organization and management; pandemic; pathogenicity; procedures; social distance; software; telemedicine; virology; virus pneumonia},
	correspondence_address = {Y. Bombard; Genomics Health Services Research Program, Li Ka Shing Knowledge Institute, St. Michael’s Hospital, Unity Health, Toronto, Canada; email: yvonne.bombard@utoronto.ca},
	publisher = {Nature Research},
	issn = {14710056},
	coden = {NRGAA},
	pmid = {32601319},
	language = {English},
	abbrev_source_title = {Nat. Rev. Gen.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Hardt202018,
	author = {Hardt, Michaela and Chin, Marshall H.},
	title = {It is Time for Bioethicists to Enter the Arena of Machine Learning Ethics},
	year = {2020},
	journal = {American Journal of Bioethics},
	volume = {20},
	number = {11},
	pages = {18 – 20},
	doi = {10.1080/15265161.2020.1820115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094680155&doi=10.1080%2f15265161.2020.1820115&partnerID=40&md5=117d6c364e19c1581edd2c1ee3993806},
	affiliations = {University of Chicago, United States},
	keywords = {Ethicists; Ethics Consultation; Humans; Machine Learning; Morals; ethicist; ethics; human; machine learning; morality},
	correspondence_address = {M. Hardt; Berkeley, 94707, United States; email: hardtmichaela@gmail.com},
	publisher = {Routledge},
	issn = {15265161},
	pmid = {33103973},
	language = {English},
	abbrev_source_title = {Am. J. Bioethics},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Smaïl-Tabbone2020188,
	author = {Smaïl-Tabbone, Malika and Rance, Bastien},
	title = {Contributions from the 2019 Literature on Bioinformatics and Translational Informatics},
	year = {2020},
	journal = {Yearbook of medical informatics},
	volume = {29},
	number = {1},
	pages = {188 – 192},
	doi = {10.1055/s-0040-1702002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089813156&doi=10.1055%2fs-0040-1702002&partnerID=40&md5=882ca90a343e5c46490df339b1635a4e},
	affiliations = {CNRS, Inria Nancy Grand-Est, Loria UMR 7503 ,Université de Lorraine, Nancy, France; HEGP, AP-HP & Université de Paris, UMRS 1138 Centre de Recherche des Cordeliers, INSERM, Paris, France},
	abstract = {OBJECTIVES: Summarize recent research and select the best papers published in 2019 in the field of Bioinformatics and Translational Informatics (BTI) for the corresponding section of the International Medical Informatics Association Yearbook. METHODS: A literature review was performed for retrieving from PubMed papers indexed with keywords and free terms related to BTI. Independent review allowed the section editors to select a list of 15 candidate best papers which were subsequently peer-reviewed. A final consensus meeting gathering the whole Yearbook editorial committee was organized to finally decide on the selection of the best papers. RESULTS: Among the 931 retrieved papers covering the various subareas of BTI, the review process selected four best papers. The first paper presents a logical modeling of cancer pathways. Using their tools, the authors are able to identify two known behaviours of tumors. The second paper describes a deep-learning approach to predicting resistance to antibiotics in Mycobacterium tuberculosis. The authors of the third paper introduce a Genomic Global Positioning System (GPS) enabling comparison of genomic data with other individuals or genomics databases while preserving privacy. The fourth paper presents a multi-omics and temporal sequence-based approach to provide a better understanding of the sequence of events leading to Alzheimer's Disease. CONCLUSIONS: Thanks to the normalization of open data and open science practices, research in BTI continues to develop and mature. Noteworthy achievements are sophisticated applications of leading edge machine-learning methods dedicated to personalized medicine. Georg Thieme Verlag KG Stuttgart.},
	keywords = {Computational Biology; Genomics; Humans; Machine Learning; Medical Informatics; Translational Medical Research; biology; ethics; genomics; human; machine learning; medical informatics; translational research},
	publisher = {NLM (Medline)},
	issn = {23640502},
	pmid = {32823315},
	language = {English},
	abbrev_source_title = {Yearb Med Inform},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Luo2020,
	author = {Luo, Hao and Lau, Kui Kai and Wong, Gloria H.Y. and Chan, Wai-Chi and Mak, Henry K. F. and Zhang, Qingpeng and Knapp, Martin and Wong, Ian C. K.},
	title = {Predicting dementia diagnosis from cognitive footprints in electronic health records: A case-control study protocol},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {11},
	doi = {10.1136/bmjopen-2020-043487},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096761146&doi=10.1136%2fbmjopen-2020-043487&partnerID=40&md5=35f2a9e7d61f4054b55fcc8e7c1a7864},
	affiliations = {Department of Social Work and Social Administration, University of Hong Kong, Hong Kong, Hong Kong; Department of Computer Science, University of Hong Kong, Hong Kong, Hong Kong; Department of Medicine, University of Hong Kong, Hong Kong, Hong Kong; Department of Psychiatry, University of Hong Kong, Hong Kong, Hong Kong; Department of Diagnostic Radiology, University of Hong Kong, Hong Kong, Hong Kong; School of Data Science, City University of Hong Kong, Hong Kong, Hong Kong; Care Policy and Evaluation Centre (CPEC), London School of Economics and Political Science, London, United Kingdom; Centre for Safe Medication Practice and Research, Department of Pharmacology and Pharmacy, University of Hong Kong, Hong Kong, Hong Kong; Research Department of Practice and Policy, University College London School of Pharmacy, London, UK, United Kingdom},
	abstract = {Introduction Dementia is a group of disabling disorders that can be devastating for persons living with it and for their families. Data-informed decision-making strategies to identify individuals at high risk of dementia are essential to facilitate large-scale prevention and early intervention. This population-based case-control study aims to develop and validate a clinical algorithm for predicting dementia diagnosis, based on the cognitive footprint in personal and medical history. Methods and analysis We will use territory-wide electronic health records from the Clinical Data Analysis and Reporting System (CDARS) in Hong Kong between 1 January 2001 and 31 December 2018. All individuals who were at least 65 years old by the end of 2018 will be identified from CDARS. A random sample of control individuals who did not receive any diagnosis of dementia will be matched with those who did receive such a diagnosis by age, gender and index date with 1:1 ratio. Exposure to potential protective/risk factors will be included in both conventional logistic regression and machine-learning models. Established risk factors of interest will include diabetes mellitus, midlife hypertension, midlife obesity, depression, head injuries and low education. Exploratory risk factors will include vascular disease, infectious disease and medication. The prediction accuracy of several state-of-the-art machine-learning algorithms will be compared. Ethics and dissemination This study was approved by Institutional Review Board of The University of Hong Kong/Hospital Authority Hong Kong West Cluster (UW 18-225). Patients' records are anonymised to protect privacy. Study results will be disseminated through peer-reviewed publications. Codes of the resulted dementia risk prediction algorithm will be made publicly available at the website of the Tools to Inform Policy: Chinese Communities' Action in Response to Dementia project (http://www.tip-card.hku.hk/).  © 2020 Author(s). Published by BMJ.},
	author_keywords = {dementia; epidemiology; public health},
	keywords = {Adult; Aged; Aged, 80 and over; Case-Control Studies; Cognition; Dementia; Electronic Health Records; Female; Hong Kong; Humans; Male; Middle Aged; age; aged; algorithm; Article; benchmarking; case control study; cognition; controlled study; dementia; descriptive research; electronic health record; female; Hong Kong; human; machine learning; male; population based case control study; prediction; risk factor; adult; cognition; dementia; electronic health record; middle aged; very elderly},
	correspondence_address = {H. Luo; Department of Social Work and Social Administration, University of Hong Kong, Hong Kong, Hong Kong; email: haoluo@hku.hk; H. Luo; Department of Computer Science, University of Hong Kong, Hong Kong, Hong Kong; email: haoluo@hku.hk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33444218},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Stevens2020,
	author = {Stevens, Marthe and Wehrens, Rik and de Bont, Antoinette},
	title = {Epistemic virtues and data-driven dreams: On sameness and difference in the epistemic cultures of data science and psychiatry},
	year = {2020},
	journal = {Social Science and Medicine},
	volume = {258},
	doi = {10.1016/j.socscimed.2020.113116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086823685&doi=10.1016%2fj.socscimed.2020.113116&partnerID=40&md5=a549d07e87b3d2b8850c22c39971ab44},
	affiliations = {Department of Health Care Governance, Erasmus School of Health Policy & Management, P.O. Box 1738, Rotterdam, 3000, DR, Netherlands},
	abstract = {Data science and psychiatry have diverse epistemic cultures that come together in data-driven initiatives (e.g., big data, machine learning). The literature on these initiatives seems to either downplay or overemphasize epistemic differences between the fields. In this paper, we study the convergence and divergence of the epistemic cultures of data science and psychiatry. This approach is more likely to capture where and how the cultures differ and gives insights into how practitioners from both fields find ways to work together despite their differences. We introduce the notions of “epistemic virtues” to focus on epistemic differences ethnographically, and “trading zones” to concentrate on how differences are negotiated. This leads us to the following research question: how are epistemic differences negotiated by data science and psychiatry practitioners in a hospital-based data-driven initiative? Our results are based on an ethnographic study in which we observed a Dutch psychiatric hospital department developing prediction models of patient outcomes based on machine learning techniques (September 2017 – February 2018). Many epistemic virtues needed to be negotiated, such as completeness or selectivity in data inclusion. These differences were traded locally and temporarily, stimulated by shared epistemic virtues (such as a systematic approach), boundary objects and socialization processes. Trading became difficult when virtues were too diverse, differences were enlarged by storytelling and parties did not have the time or capacity to learn about the other. In the discussion, we argue that our combined theoretical framework offers a fresh way to study how cooperation between diverse practitioners goes and where it can be improved. We make a call for bringing epistemic differences into the open as this makes a grounded discussion possible about the added value of data-driven initiatives and the role they can play in healthcare. © 2020 The Author(s)},
	author_keywords = {Epistemic cultures; Epistemic virtues; Ethnography; Healthcare; Machine learning; Netherlands; Trading zone},
	keywords = {Anthropology, Cultural; Data Science; Delivery of Health Care; Humans; Psychiatry; Virtues; culture; ethics; health care; medicine; article; conceptual framework; data science; ethnography; human; machine learning; mental hospital; morality; Netherlands; physician; prediction; psychiatry; socialization; storytelling; cultural anthropology; health care delivery},
	correspondence_address = {M. Stevens; Department of Health Care Governance, Erasmus School of Health Policy & Management, Rotterdam, P.O. Box 1738, 3000, Netherlands; email: stevens@eshpm.eur.nl},
	publisher = {Elsevier Ltd},
	issn = {02779536},
	coden = {SSMDE},
	pmid = {32599412},
	language = {English},
	abbrev_source_title = {Soc. Sci. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ahmed2020409,
	author = {Ahmed, S. and Shipman, A. and Millington, G. and Langan, E.A. and Ingram, J.R.},
	title = {Consent for publication: why it matters now more than ever},
	year = {2020},
	journal = {British Journal of Dermatology},
	volume = {183},
	number = {3},
	pages = {409 – 410},
	doi = {10.1111/bjd.19320},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090167149&doi=10.1111%2fbjd.19320&partnerID=40&md5=86732c94f11d0e7ce0342d77dafc00c4},
	affiliations = {British Association of Dermatologists, London, United Kingdom; Dermatology, Portsmouth Hospitals NHS Trust, Portsmouth, United Kingdom; Dermatology, Norfolk and Norwich University Hospital, Norwich, United Kingdom; Department of Dermatology and Venereology, University Hospital of Schleswig Holstein, Lübeck, Germany; Dermatological Sciences, University of Manchester, Manchester, United Kingdom; Department of Dermatology & Wound Healing, Division of Infection and Immunity, Cardiff University, Cardiff, United Kingdom},
	keywords = {Humans; Informed Consent; clinical article; clinical practice; dermatology; Editorial; informed consent; machine learning; medical specialist; priority journal; publication; publishing; research ethics; social media; human},
	correspondence_address = {S. Ahmed; British Association of Dermatologists, London, United Kingdom; email: shehnaz@bad.org.uk},
	publisher = {Blackwell Publishing Ltd},
	issn = {00070963},
	coden = {BJDEA},
	pmid = {32880902},
	language = {English},
	abbrev_source_title = {Br. J. Dermatol.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Loftus202092,
	author = {Loftus, Tyler J. and Filiberto, Amanda C. and Balch, Jeremy and Ayzengart, Alexander L. and Tighe, Patrick J. and Rashidi, Parisa and Bihorac, Azra and Upchurch, Gilbert R.},
	title = {Intelligent, Autonomous Machines in Surgery},
	year = {2020},
	journal = {Journal of Surgical Research},
	volume = {253},
	pages = {92 – 99},
	doi = {10.1016/j.jss.2020.03.046},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083644375&doi=10.1016%2fj.jss.2020.03.046&partnerID=40&md5=dde863a6608254fb12841136f32bb1fb},
	affiliations = {Department of Surge ry, University of Florida Health, Gainesville, FL, United States; Departments of Biomedical Engineering, Computer and Information Science and Engineering, and Electrical and Computer Engineering, University of Florida, Gainesville, FL, United States; Departments of Anesthesiology, Orthopedics, and Information Systems/Operations Management, University of Florida Health, Gainesville, FL, United States; Department of Medicine, University of Florida Health, Gainesville, FL, United States},
	abstract = {Surgeons perform two primary tasks: operating and engaging patients and caregivers in shared decision-making. Human dexterity and decision-making are biologically limited. Intelligent, autonomous machines have the potential to augment or replace surgeons. Rather than regarding this possibility with denial, ire, or indifference, surgeons should understand and steer these technologies. Closer examination of surgical innovations and lessons learned from the automotive industry can inform this process. Innovations in minimally invasive surgery and surgical decision-making follow classic S-shaped curves with three phases: (1) introduction of a new technology, (2) achievement of a performance advantage relative to existing standards, and (3) arrival at a performance plateau, followed by replacement with an innovation featuring greater machine autonomy and less human influence. There is currently no level I evidence demonstrating improved patient outcomes using intelligent, autonomous machines for performing operations or surgical decision-making tasks. History suggests that if such evidence emerges and if the machines are cost effective, then they will augment or replace humans, initially for simple, common, rote tasks under close human supervision and later for complex tasks with minimal human supervision. This process poses ethical challenges in assigning liability for errors, matching decisions to patient values, and displacing human workers, but may allow surgeons to spend less time gathering and analyzing data and more time interacting with patients and tending to urgent, critical—and potentially more valuable—aspects of patient care. Surgeons should steer these technologies toward optimal patient care and net social benefit using the uniquely human traits of creativity, altruism, and moral deliberation. © 2020 Elsevier Inc.},
	author_keywords = {Artificial intelligence; Automation; Innovation; Machine learning; Surgery},
	keywords = {Artificial Intelligence; Decision Support Systems, Clinical; Diffusion of Innovation; History, 20th Century; History, 21st Century; Humans; Inventions; Liability, Legal; Patient Participation; Robotic Surgical Procedures; Surgeons; achievement; adult; altruism; article; artificial intelligence; automation; bullock; caregiver; creativity; human; machine learning; male; minimally invasive surgery; morality; nonhuman; patient care; shared decision making; surgeon; worker; artificial intelligence; clinical decision support system; devices; ethics; history; invention; legal liability; mass communication; patient participation; psychology; robot assisted surgery},
	correspondence_address = {G.R. Upchurch; Department of Surgery, Edward R. Woodward Professor & Chair University of Florida, Gainesville, PO Box 100286 1600 SW Archer Road, Room 6174, 32610-0286, United States; email: gib.upchurch@surgery.ufl.edu},
	publisher = {Academic Press Inc.},
	issn = {00224804},
	coden = {JSGRA},
	pmid = {32339787},
	language = {English},
	abbrev_source_title = {J. Surg. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Liu2020324,
	author = {Liu, T.Y. Alvin  and Bressler, Neil M.},
	title = {Controversies in artificial intelligence},
	year = {2020},
	journal = {Current Opinion in Ophthalmology},
	volume = {31},
	number = {5},
	pages = {324 – 328},
	doi = {10.1097/ICU.0000000000000694},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089301729&doi=10.1097%2fICU.0000000000000694&partnerID=40&md5=8a3dde5c9976560363ce215b9fd3e2a4},
	affiliations = {Retina Division, Wilmer Eye Institute, Johns Hopkins University, School of Medicine, 600N. Wolfe St, Baltimore, 21287-9227, MD, United States},
	abstract = {Purpose of review To review four recent controversial topics arising from deep learning applications in ophthalmology. Recent findings The controversies of four recent topics surrounding deep learning applications in ophthalmology are discussed, including the following: Lack of explainability, limited generalizability, potential biases and protection of patient confidentiality in large-scale data transfer. Summary These controversial issues spanning the domains of clinical medicine, public health, computer science, ethics and legal issues, are complex and likely will benefit from an interdisciplinary approach if artificial intelligence in ophthalmology is to succeed over the next decade.  © 2020 Wolters Kluwer Health, Inc.},
	author_keywords = {Biases; deep learning; explainability; generalizability; patient confidentiality},
	keywords = {Artificial Intelligence; Big Data; Eye Diseases; Humans; Image Interpretation, Computer-Assisted; Ophthalmology; artificial intelligence; back propagation; clinical medicine; clinical practice; confidentiality; deep learning; deep neural network; feature learning (machine learning); human; learning algorithm; medical ethics; ophthalmology; prediction; Review; computer assisted diagnosis; eye disease; procedures},
	correspondence_address = {N.M. Bressler; Retina Division, Wilmer Eye Institute, Johns Hopkins University, School of Medicine, Baltimore, 600N. Wolfe St, 21287-9227, United States; email: nmboffice@jhmi.edu},
	publisher = {Lippincott Williams and Wilkins},
	issn = {10408738},
	coden = {COOTE},
	pmid = {32769696},
	language = {English},
	abbrev_source_title = {Curr. Opin. Ophthalmol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Bilstrup20201211,
	author = {Bilstrup, Karl-Emil Kjær and Kaspersen, Magnus H. and Petersen, Marianne Graves},
	title = {Staging reflections on ethical dilemmas in machine learning: A card-based design workshop for high school students},
	year = {2020},
	journal = {DIS 2020 - Proceedings of the 2020 ACM Designing Interactive Systems Conference},
	pages = {1211 – 1222},
	doi = {10.1145/3357236.3395558},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090503228&doi=10.1145%2f3357236.3395558&partnerID=40&md5=978b2514e83b658271d66a287ab5dea9},
	affiliations = {Department of Computer Science, Aarhus University, Aarhus, Denmark},
	abstract = {The increased use of machine learning (ML) in society raises questions of how ethical dilemmas inherent in computational artefacts can be made understandable and explorable for students. To investigate this, we developed a card-based design workshop that allows students to reflect on ethical dilemmas by designing their own ML applications. The workshop was developed in an iterative process engaging four high school classrooms with students aged 16-20. We found that scaffolding students in designing meaningful ML systems served to qualify their ethical reflections. Further students' design processes allowed them to engage with the ethical dilemmas and to tie these to the properties of the technology and to their design decisions. We suggest seeing technology-close discussions about ethics as a goal in design processes, and prototyping as a means to ground these discussions in students' own design decisions, and we contribute a workshop format and design artefacts that allow for this. © 2020 ACM.},
	author_keywords = {Computational empowerment; Computational thinking; Design processes; Ethics; Machine learning},
	keywords = {Design; Machine learning; Philosophical aspects; Scaffolds; Design decisions; Design process; Design workshops; Ethical dilemma; High school classrooms; High school students; Iterative process; Ml systems; Students},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036974-9},
	language = {English},
	abbrev_source_title = {DIS Companion - Companion Publ. ACM Des. Interact. Syst. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 18; Conference name: 2020 ACM Conference on Designing Interactive Systems, DIS 2020; Conference date: 6 July 2020 through 10 July 2020; Conference code: 161555; All Open Access, Bronze Open Access}
}

@ARTICLE{Hsu2020139,
	author = {Hsu, William and Baumgartner, Christian and Deserno, Thomas M.},
	title = {Notable Papers and Trends from 2019 in Sensors, Signals, and Imaging Informatics},
	year = {2020},
	journal = {Yearbook of medical informatics},
	volume = {29},
	number = {1},
	pages = {139 – 144},
	doi = {10.1055/s-0040-1702004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089808648&doi=10.1055%2fs-0040-1702004&partnerID=40&md5=66dfd4542ed684d0492ccb210658f265},
	affiliations = {Medical & Imaging Informatics, Department of Radiological Sciences, David Geffen School of Medicine at UCLA, United States; Institute of Health Care Engineering with European Testing Center of Medical Devices, Graz University of Technology, Austria; Peter L. Reichertz Institute for Medical Informatics of TU Braunschweig and Hannover Medical School, Braunschweig, Germany},
	abstract = {OBJECTIVE: To highlight noteworthy papers that are representative of 2019 developments in the fields of sensors, signals, and imaging informatics. METHOD: A broad literature search was conducted in January 2020 using PubMed. Separate predefined queries were created for sensors/signals and imaging informatics using a combination of Medical Subject Heading (MeSH) terms and keywords. Section editors reviewed the titles and abstracts of both sets of results. Papers were assessed on a three-point Likert scale by two co-editors, rated from 3 (do not include) to 1 (should be included). Papers with an average score of 2 or less were then read by all three section editors, and the group nominated top papers based on consensus. These candidate best papers were then rated by at least six external reviewers. RESULTS: The query related to signals and sensors returned a set of 255 papers from 140 unique journals. The imaging informatics query returned a set of 3,262 papers from 870 unique journals. Based on titles and abstracts, the section co-editors jointly filtered the list down to 50 papers from which 15 candidate best papers were nominated after discussion. A composite rating after review determined four papers which were then approved by consensus of the International Medical Informatics Association (IMIA) Yearbook editorial board. These best papers represent different international groups and journals. CONCLUSIONS: The four best papers represent state-of-the-art approaches for processing, combining, and analyzing heterogeneous sensor and imaging data. These papers demonstrate the use of advanced machine learning techniques to improve comparisons between images acquired at different time points, fuse information from multiple sensors, and translate images from one modality to another. Georg Thieme Verlag KG Stuttgart.},
	keywords = {Deep Learning; Diagnostic Imaging; Humans; Medical Informatics; Neural Networks, Computer; Signal Processing, Computer-Assisted; diagnostic imaging; ethics; human; medical informatics; signal processing},
	publisher = {NLM (Medline)},
	issn = {23640502},
	pmid = {32823307},
	language = {English},
	abbrev_source_title = {Yearb Med Inform},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Hausken2020,
	author = {Hausken, Kjell},
	title = {Cyber resilience in firms, organizations and societies},
	year = {2020},
	journal = {Internet of Things (Netherlands)},
	volume = {11},
	doi = {10.1016/j.iot.2020.100204},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093818854&doi=10.1016%2fj.iot.2020.100204&partnerID=40&md5=e62d8d81d4c50672bc5b26167bd163e3},
	affiliations = {Faculty of Science and Technology, University of Stavanger, Stavanger, 4036, Norway},
	abstract = {Cyber resilience involves most societal actors, i.e. organizations, individuals, threat actors, governments, insurers, etc., at most levels of organization. Actors are embedded within each other and choose strategies based on beliefs and preferences which impact and is impacted by cyber resilience. The article reviews the literature, attempting to capture the core ingredients of cyber resilience. Non-threat actors seeking to obtain cyber resilience are distinguished from threat actors. Actors have resources, competence, technology, and tools. They make choices that impact the cyber resilience for all actors, including themselves. Cyber resilience relates to cyber insurance through entry requirements or preconditions for cyber contracts, need for various services such as incident response, data gathering, and cover limitations. Cyber resilience is linked to the internet of things which in the future can be expected to simplify life through artificial intelligence and machine learning, while being vulnerable through a large attack surface, insufficient technology, challenging handling of data, possible high trust in computers and software, and ethics. © 2020 The Author(s)},
	author_keywords = {Cyber resilience; Insurance; Internet of things; Levels of organization; Non-threat actors; Recovery; Threat actors},
	publisher = {Elsevier B.V.},
	issn = {25426605},
	language = {English},
	abbrev_source_title = {Internet. Thing.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Kim2020210,
	author = {Kim, Wonchul and Lee, Keeheon},
	title = {Building Ethical AI from News Articles},
	year = {2020},
	journal = {2020 IEEE / ITU International Conference on Artificial Intelligence for Good, AI4G 2020},
	pages = {210 – 217},
	doi = {10.1109/AI4G50087.2020.9311054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100328914&doi=10.1109%2fAI4G50087.2020.9311054&partnerID=40&md5=661a3c0408217c9166d4bd45701d916b},
	affiliations = {Graduate School of Communication, Yonsei University, South Korea; Underwood International College, Yonsei University, South Korea},
	abstract = {Improving performance of artificial intelligence (AI) has been the most important focus of AI studies. As a result, AI is expected to replace what considered to be done by human intelligence. Additionally, human societies are willing to accept AI agents as members to collaborate with. For AI agents to be successfully integrated into human societies, the agents must understand important values in the societies. Ethics is a system of values that sustain the societies and it is considered as the most important. Therefore, there should be a way for AI agents to understand ethical values of human societies. In this paper, we show how to extract ethical values and moral values of the age from news articles using natural language processing. Our result shows that from newspaper articles ethical and moral values could be extracted and modeled for AI agents to refer. In conclusion AI can calculated ethicality of text by itself. In the future, we can develop more ethical autonomous AI agents.  © 2020 IEEE.},
	author_keywords = {Artificial intelligence; ethics; machine learning; word embedding},
	keywords = {Autonomous agents; Natural language processing systems; Philosophical aspects; Ethical values; Human intelligence; Human society; Important value; Improving performance; NAtural language processing; News articles; Artificial intelligence},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172817031-2},
	language = {English},
	abbrev_source_title = {IEEE / ITU Int. Conf. Artif. Intell. Good, AI4G},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2020 IEEE / ITU International Conference on Artificial Intelligence for Good, AI4G 2020; Conference date: 21 September 2020 through 25 September 2020; Conference code: 166493}
}

@ARTICLE{Cantarini2020261,
	author = {Cantarini, Paola},
	title = {Artificial intelligence and pandemic control: Digital biopolitics and the end of the era of humanism; [Inteligência artificial e controle de pandemias: Biopolítica digital e o fim da era do humanismo]},
	year = {2020},
	journal = {Revista Juridica},
	volume = {4},
	number = {61},
	pages = {261 – 277},
	doi = {10.21902/revistajur.2316-753X.v4i61.4609},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096646757&doi=10.21902%2frevistajur.2316-753X.v4i61.4609&partnerID=40&md5=c4240f4f670430e1d0fd59aad111b33e},
	abstract = {Objective: the article aims, in short, to bring an interdisciplinary approach to the study of such themes, involving artificial intelligence, pandemic control, personal data, digital biopolitics, bringing critical questions about controversial and sensitive aspects, especially regarding control of pandemics with the use of artificial intelligence, its impact in terms of data protection, and bring the necessary reasoning to postulate the need for regulation via weighting, that is, applying responsibly and according to the objective and rationality related to the principle of proportionality, avoiding arbitrary and subjective decisions, since it is dealing with fundamental rights, and norms of fundamental rights in collision in the practical case. On the other hand, the aim is to analyze the issue of ethics involved in the use of artificial intelligence, and which ethics would be possible, since there is no case of accountability for artificial intelligence itself, due to the lack of legal personality and legal capacity, stating that only human beings would be able to adopt moral and ethical judgments. Methodology: The methodology used is based on reading a large bibliographic production, as indicated throughout the text. Results: The research intended to bring contributions to the legal debate about the ethical and legal repercussions on the use of artificial intelligence, especially in the health sector, and its inseparable relationship with the theme of data protection, and with respect for fundamental rights and humans. Data protection and the use of artificial intelligence in the highlighted sector, and the implication of ethical issues, are phenomena that are closely related, not least because the area of data protection starts to suffer greater impact precisely with the use of artificial intelligence, with big data, internet of things, deep learning and machine learning. In addition to the need for objective parameters, in the light of principiological laws, and the application of the weighting procedure when faced with so-called “hard cases”, cases involving collision of fundamental rights rules, as in the field of the use of artificial intelligence in combating the Covid pandemic, it is essential to have ethical guidelines, digital ethics in order to identify new perspectives, potential and limits for the use of data and artificial intelligence, focusing on the central value of the human person, disconnecting them it is based on a patrimonial vision about personal data and the use of artificial intelligence, being essential the promotion of human values and the human supervision of such technology, remaining the human control of it. Contributions: The research aims to address some of the critical and sensitive issues involving such fields of study, such as the problem of the lack of effectiveness of ethical principles, legal principles, the insufficiency of principiological laws, and to verify how the issue of the use of artificial intelligence in combating the Covid pandemic has been discussed in national and international doctrine, as well as in jurisprudence, bringing critical reflections about the possibility of facing the generalization of a state of exception, bringing contributions in order to verify which are the best alternatives, in order to avoid the affront to fundamental and human rights in view of such an exceptional situation, and what parameters should be adopted, in order to protect above all the inviolable nucleus of every fundamental right, where human dignity is found, an axial principle of every State Democratic of Law. © 2020, Centro Universitário Curitiba - UNICURITIBA. All rights reserved.},
	author_keywords = {Artificial intelligence; Control of pandemics; Digital biopolitics},
	publisher = {Centro Universitário Curitiba - UNICURITIBA},
	issn = {2316753X},
	language = {Portuguese},
	abbrev_source_title = {Rev. Jurid.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Awad2020,
	author = {Awad, Edmond and Anderson, Michael and Anderson, Susan Leigh and Liao, Beishui},
	title = {An approach for combining ethical principles with public opinion to guide public policy},
	year = {2020},
	journal = {Artificial Intelligence},
	volume = {287},
	doi = {10.1016/j.artint.2020.103349},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087749668&doi=10.1016%2fj.artint.2020.103349&partnerID=40&md5=a61d76afda34da38ae9032ad3aabeaa1},
	affiliations = {University of Exeter, Exeter, United Kingdom; University of Hartford, Hartford, CT, United States; University of Connecticut, Storrs, CT, United States; Zhejiang University, Hangzhou, China},
	abstract = {We propose a framework for incorporating public opinion into policy making in situations where values are in conflict. This framework advocates creating vignettes representing value choices, eliciting the public's opinion on these choices, and using machine learning to extract principles that can serve as succinct statements of the policies implied by these choices and rules to guide the behavior of autonomous systems. © 2020 Elsevier B.V.},
	author_keywords = {Machine ethics; Moral machine},
	keywords = {Public policy; Autonomous systems; Ethical principles; Policy making; Public opinions; Social aspects},
	correspondence_address = {E. Awad; University of Exeter, Exeter, United Kingdom; email: e.awad@exeter.ac.uk},
	publisher = {Elsevier B.V.},
	issn = {00043702},
	coden = {AINTB},
	language = {English},
	abbrev_source_title = {Artif Intell},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Van Noorden2020354,
	author = {Van Noorden, Richard},
	title = {The ethical questions that haunt facial-recognition research},
	year = {2020},
	journal = {Nature},
	volume = {587},
	number = {7834},
	pages = {354 – 358},
	doi = {10.1038/d41586-020-03187-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096407339&doi=10.1038%2fd41586-020-03187-3&partnerID=40&md5=658a55b0a8765bc2a6027d5652521140},
	author_keywords = {Computer science; Ethics; Machine learning; Politics},
	keywords = {Age Factors; Algorithms; Automated Facial Recognition; Censorship, Research; China; Datasets as Topic; Ethics, Research; Ethnic Groups; Female; Human Rights; Humans; Informed Consent; Islam; Korea; Male; Military Science; Photography; Politics; Privacy; Sex Factors; Tibet; age; algorithm; censorship; China; ethics; ethnic group; ethnology; female; human; human rights; information processing; informed consent; Islam; Korea; male; military phenomena; photography; politics; privacy; research ethics; sex factor; Tibet},
	publisher = {NLM (Medline)},
	issn = {14764687},
	pmid = {33208967},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 42}
}

@ARTICLE{Alexander20207,
	author = {Alexander, John C. and Romito, Bryan T. and Çobanoǧlu, Murat Can},
	title = {The present and future role of artificial intelligence and machine learning in anesthesiology},
	year = {2020},
	journal = {International Anesthesiology Clinics},
	volume = {58},
	number = {4},
	pages = {7 – 16},
	doi = {10.1097/AIA.0000000000000294},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092332102&doi=10.1097%2fAIA.0000000000000294&partnerID=40&md5=b108f1e5ef00cf37d8142396fa200a18},
	affiliations = {Department of Anesthesiology and Pain Management, University of Texas Southwestern, Dallas, TX, United States; Lyda Hill Department of Bioinformatics, University of Texas Southwestern, Dallas, TX, United States},
	keywords = {Anesthesiology; Artificial Intelligence; Humans; Machine Learning; anesthesiology; Article; artificial intelligence; automation; computer model; convolutional neural network; futurology; health care industry; health care utilization; human; intensive care unit; intraoperative period; machine learning; medical ethics; priority journal; sepsis; software; statistical reasoning; treatment outcome; machine learning},
	correspondence_address = {J.C. Alexander; Dallas, 5323 Harry Hines Blvd, 75390-9068, United States; email: john.alexander@utsouthwestern.edu},
	publisher = {Lippincott Williams and Wilkins},
	issn = {00205907},
	coden = {IACLA},
	pmid = {32841964},
	language = {English},
	abbrev_source_title = {Int. Anesthesiol. Clin.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Cockerill2020345,
	author = {Cockerill, Richard G.},
	title = {Ethics implications of the use of artificial intelligence in violence risk assessment},
	year = {2020},
	journal = {Journal of the American Academy of Psychiatry and the Law},
	volume = {48},
	number = {3},
	pages = {345 – 349},
	doi = {10.29158/JAAPL.003940-20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090681690&doi=10.29158%2fJAAPL.003940-20&partnerID=40&md5=cb2d107e863492f57c41a7b3973a1982},
	affiliations = {UCLA-Semel Institute for Neuroscience and Behavior, Los Angeles, CA, United States},
	abstract = {Artificial intelligence is rapidly transforming the landscape of medicine. Specifically, algorithms powered by deep learning are already gaining increasingly wide adoption in fields such as radiology, pathology, and preventive medicine. Forensic psychiatry is a complex and intricate specialty that seeks to balance the disparate approaches of psychiatric science, which strives to explain human behavior deterministically, and the law, which emphasizes free choice and moral responsibility. This balancing, a central task of the forensic psychiatrist, is necessarily fraught with ambiguity. Such a complex task may intuitively seem impenetrable to artificial intelligence. This article first aims to challenge this assumption and then seeks to address the unique concerns posed by the adoption of artificial intelligence in violence risk assessment and prediction. The relevant ethics concerns are analyzed within the framework of traditional bioethics principles. Finally, recommendations for practitioners, ethicists, and others are offered as a starting point for further discussion. © 2020, American Academy of Psychiatry and the Law. All rights reserved.},
	keywords = {Artificial Intelligence; Beneficence; Forensic Psychiatry; Humans; Machine Learning; Personal Autonomy; Risk Assessment; Social Justice; Violence; artificial intelligence; beneficence; ethics; forensic psychiatry; human; machine learning; personal autonomy; procedures; risk assessment; social justice; violence},
	correspondence_address = {R.G. Cockerill; UCLA-Semel Institute for Neuroscience and Behavior, Los Angeles, 760 Westwood Plaza, 90095, United States; email: rcockerill@mednet.ucla.edu},
	publisher = {American Academy of Psychiatry and the Law},
	issn = {10936793},
	coden = {JAPLF},
	pmid = {32409300},
	language = {English},
	abbrev_source_title = {J. Am. Acad. Psychiatry Law},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Witoszek-Kubicka2020,
	author = {Witoszek-Kubicka, Aleksandra},
	title = {Implementation of gamification in Polish companies-stages, elements, ethics},
	year = {2020},
	journal = {Information (Switzerland)},
	volume = {11},
	number = {8},
	doi = {10.3390/INFO11080371},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089694949&doi=10.3390%2fINFO11080371&partnerID=40&md5=85087efc30f18b39d8b629477cf29817},
	affiliations = {Department of Organizational Behaviors, Cracow University of Economics, Kraków, 31-510, Poland},
	abstract = {Business gamification has been gaining in popularity in Poland in recent years and is indeed appearing in companies, especially large ones. However, the implementation of game-based solutions is still not sufficiently described. The technology allows the use of solutions such as AI or Machine Learning, but gamification is not only an IT project. The aim of the article is to determine the stages of implementation of business gamification according to various models, describe the existing differences and confront the results with business practice in Poland. To this end, a scoping review on the subject was carried out in terms of the existing methodologies for the implementation of gamification solutions. In the next stage, a scenario was created to conduct individual in-depth interviews (IDI) with companies implementing gamification projects in business. As a result of the research, the practice of implementing business gamification in Poland was described against the background of the methodologies proposed in the literature. This has led to the identification of several significant differences in implementation stages both between theory and practice and among the implementations proposed by the companies participating in the interviews. An attempt was made to explain these differences by taking the type of IT solution as a criterion. © 2020 by the author.},
	author_keywords = {Business gamification; Gamification implementation; Implementation stages},
	keywords = {Business practices; Game-Based; In-depth interviews; IT project; IT solution; Scoping review; Theory and practice; Gamification},
	correspondence_address = {A. Witoszek-Kubicka; Department of Organizational Behaviors, Cracow University of Economics, Kraków, 31-510, Poland; email: aleksandra.witoszek@uek.krakow.pl},
	publisher = {MDPI AG},
	issn = {20782489},
	language = {English},
	abbrev_source_title = {Information},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Basu2020358,
	author = {Basu, Treena and Engel-Wolf, Sebastian and Menzer, Olaf},
	title = {The ethics of machine learning in medical sciences: Where do we stand today?},
	year = {2020},
	journal = {Indian Journal of Dermatology},
	volume = {65},
	number = {5},
	pages = {358 – 364},
	doi = {10.4103/ijd.IJD_419_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096336698&doi=10.4103%2fijd.IJD_419_20&partnerID=40&md5=568472298e8ce49abad64be07c09decc},
	affiliations = {Department of Mathematics, Occidental College, 1600 Campus Road, Los Angeles, United States; Systems Biotechnology Group, Technical University of Munich, Boltzmannstr. 15, Garching, Germany; Department of Geography, University of California, Santa Barbara, CA, United States; Technology Department, Retirement Solutions Division, Pacific Life, Newport Beach, CA, United States},
	abstract = {Advances in Machine Learning and availability of state-of-the-art computational resources, along with digitized healthcare data, have set the stage for extensive application of artificial intelligence in the realm of diagnosis, prognosis, clinical decision support, personalized treatment options, drug development, and the field of biomedicine. Here, we discuss the application of Machine Learning algorithms in patient healthcare and dermatological domains along with the ethical complexities that are involved. In scientific studies, ethical challenges were initially not addressed proportionally (as assessed by keyword counts in PubMed) and just more recently (since 2016) this has started to improve. Few pioneering countries have created regulatory guidelines around how to respect matters of (1) privacy, (2) fairness, (3) accountability, (4) transparency and (5) conflict of interest when developing novel medical Machine Learning applications. While there is a strong promise of emerging medical applications to ultimately benefit both the patients and the medical practitioners, it is important to raise awareness on the five key ethical issues and incorporate them into medical practice in the near future. © 2020 Wolters Kluwer Medknow Publications. All rights reserved.},
	author_keywords = {Best practices; electronic health records; ethics; machine learning},
	keywords = {artificial intelligence; biomedicine; clinical decision support system; Conference Paper; deep neural network; drug development; electronic health record; electronic medical record; electronic patient record; epiluminescence microscopy; health insurance; human; learning algorithm; machine learning; medical care; medical practice; medicine; nuclear magnetic resonance imaging; personalized medicine; practice guideline; social responsibility},
	correspondence_address = {T. Basu; Department of Mathematics, Occidental College, Los Angeles, 1600 Campus Road, United States; email: basu@oxy.edu; O. Menzer; Department of Geography, University of California, Santa Barbara, United States; email: menzer@geog.ucsb.edu},
	publisher = {Wolters Kluwer Medknow Publications},
	issn = {00195154},
	language = {English},
	abbrev_source_title = {Indian J. Dermatol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{da Motta20205,
	author = {da Motta, Oswaldo Jesus Rodrigues and Silva, Eugênio and Siqueira-Batista, Rodrigo},
	title = {Bioethical aspects of artificial intelligence: COVID-19 & end of life},
	year = {2020},
	journal = {Revista da Associacao Medica Brasileira},
	volume = {66},
	pages = {5 – 6},
	doi = {10.1590/1806-9282.66.S2.5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091576843&doi=10.1590%2f1806-9282.66.S2.5&partnerID=40&md5=ffc7656bdd5697dce8e231fb418bb8d9},
	affiliations = {Universidade Federal do Rio de Janeiro (UFRJ), Rio de Janeiro, RJ, Brazil; Centro Universitário Estadual da Zona Oeste do Rio de Janeiro (UEZO), Rio de Janeiro, RJ, Brazil; Centro Universitário Serra dos Órgãos (UNIFESO), Teresópolis, RJ, Brazil; Centro Universitário Carioca (UNICARIOCA), Rio de Janeiro, RJ, Brazil; Universidade Federal de Viçosa (UFV), Viçosa, MG, Brazil; Faculdade Dinâmica do Vale do Piranga (FADIP), Ponte Nova, MG, Brazil},
	author_keywords = {Artificial Intelligence; Bioethics; Clinical; Coronavirus Infections; Decision Making; Decision Support Systems; Palliative Care},
	keywords = {Artificial Intelligence; Betacoronavirus; Bioethical Issues; Clinical Decision-Making; Coronavirus Infections; Delivery of Health Care; Humans; Pandemics; Pneumonia, Viral; Precision Medicine; Public Health; Terminal Care; analgesia; artificial intelligence; artificial ventilation; bioethics; coronavirus disease 2019; decision making; extubation; health care policy; hospital admission; human; intensive care unit; learning algorithm; lethality; Letter; machine learning; nonhuman; pandemic; patient care; patient transport; personalized medicine; screening test; Severe acute respiratory syndrome coronavirus 2; artificial intelligence; Betacoronavirus; clinical decision making; Coronavirus infection; ethics; health care delivery; mortality; pandemic; public health; terminal care; virus pneumonia},
	correspondence_address = {O.J.R. da Motta; Rio de Janeiro, RJ, Av. Horácio Macedo, S/N, 21941-901, Brazil; email: oswaldojrm@hotmail.com},
	publisher = {Associacao Medica Brasileira},
	issn = {01044230},
	coden = {RMDBA},
	pmid = {32965345},
	language = {English},
	abbrev_source_title = {Rev. Assoc. Med. Bras.},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Andaur Navarro2020,
	author = {Andaur Navarro, Constanza L and Damen, Johanna A A G and Takada, Toshihiko and Nijman, Steven W J and Dhiman, Paula and Ma, Jie and Collins, Gary S and Bajpai, Ram and Riley, Richard D and Moons, Karel Gm and Hooft, Lotty},
	title = {Protocol for a systematic review on the methodological and reporting quality of prediction model studies using machine learning techniques},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {11},
	doi = {10.1136/bmjopen-2020-038832},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096082705&doi=10.1136%2fbmjopen-2020-038832&partnerID=40&md5=1ef52af1e1056108b34e229993550fa3},
	affiliations = {Julius Center for Health Sciences and Primary Care, University Medical Center Utrecht, Utrecht University, Utrecht, Netherlands; Cochrane Netherlands, University Medical Center Utrecht, Utrecht University, Utrecht, Netherlands; Center for Statistics in Medicine, University of Oxford, Oxford, United Kingdom; School of Primary, Community and Social Care, Keele University, Keele, United Kingdom},
	abstract = {Introduction Studies addressing the development and/or validation of diagnostic and prognostic prediction models are abundant in most clinical domains. Systematic reviews have shown that the methodological and reporting quality of prediction model studies is suboptimal. Due to the increasing availability of larger, routinely collected and complex medical data, and the rising application of Artificial Intelligence (AI) or machine learning (ML) techniques, the number of prediction model studies is expected to increase even further. Prediction models developed using AI or ML techniques are often labelled as a 'black box' and little is known about their methodological and reporting quality. Therefore, this comprehensive systematic review aims to evaluate the reporting quality, the methodological conduct, and the risk of bias of prediction model studies that applied ML techniques for model development and/or validation. Methods and analysis A search will be performed in PubMed to identify studies developing and/or validating prediction models using any ML methodology and across all medical fields. Studies will be included if they were published between January 2018 and December 2019, predict patient-related outcomes, use any study design or data source, and available in English. Screening of search results and data extraction from included articles will be performed by two independent reviewers. The primary outcomes of this systematic review are: (1) the adherence of ML-based prediction model studies to the Transparent Reporting of a multivariable prediction model for Individual Prognosis Or Diagnosis (TRIPOD), and (2) the risk of bias in such studies as assessed using the Prediction model Risk Of Bias ASsessment Tool (PROBAST). A narrative synthesis will be conducted for all included studies. Findings will be stratified by study type, medical field and prevalent ML methods, and will inform necessary extensions or updates of TRIPOD and PROBAST to better address prediction model studies that used AI or ML techniques. Ethics and dissemination Ethical approval is not required for this study because only available published data will be analysed. Findings will be disseminated through peer-reviewed publications and scientific conferences. Systematic review registration PROSPERO, CRD42019161764.  © },
	author_keywords = {epidemiology; preventive medicine; statistics & research methods},
	keywords = {Bias; Humans; Machine Learning; Prognosis; Research Design; adult; article; artificial intelligence; data extraction; female; human; machine learning; male; Medline; narrative; prediction; preventive medicine; prognosis; risk assessment; synthesis; systematic review; methodology; statistical bias},
	correspondence_address = {C.L. Andaur Navarro; Julius Center for Health Sciences and Primary Care, University Medical Center Utrecht, Utrecht University, Utrecht, Netherlands; email: c.l.andaurnavarro@umcutrecht.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {33177137},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhong2020,
	author = {Zhong, Xiaorong and Luo, Ting and Deng, Ling and Liu, Pei and Hu, Kejia and Lu, Donghao and Zheng, Dan and Luo, Chuanxu and Xie, Yuxin and Li, Jiayuan and He, Ping and Pu, Tianjie and Ye, Feng and Bu, Hong and Fu, Bo and Zheng, Hong},
	title = {Multidimensional machine learning personalized prognostic model in an early invasive breast cancer population-based cohort in China: Algorithm validation study},
	year = {2020},
	journal = {JMIR Medical Informatics},
	volume = {8},
	number = {11},
	doi = {10.2196/19069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097459906&doi=10.2196%2f19069&partnerID=40&md5=8339e45d134342505a9a6e938a4227c6},
	affiliations = {Department of Head, Neck and Mammary Gland Oncology, Cancer Center, West China Hospital, Sichuan University, Chengdu, China; Laboratory of Molecular Diagnosis of Cancer, Clinical Research Center for Breast, West China Hospital, Sichuan University, Chengdu, China; Big Data Research Center, School of Computer Science and Engineering, University of Electronic Science and Technology of China, Chengdu, China; Department of Medical Epidemiology and Biostatistics, Karolinska Institutet, Stockholm, Sweden; Department of Epidemiology and Biostatistics, West China School of Public Health, Sichuan University, Chengdu, China; Laboratory of Pathology, West China Hospital, Sichuan University, Chengdu, China},
	abstract = {Background: Current online prognostic prediction models for breast cancer, such as Adjuvant! Online and PREDICT, are based on specific populations. They have been well validated and widely used in the United States and Western Europe; however, several validation attempts in non-European countries have revealed suboptimal predictions. Objective: We aimed to develop an advanced breast cancer prognosis model for disease progression, cancer-specific mortality, and all-cause mortality by integrating tumor, demographic, and treatment characteristics from a large breast cancer cohort in China. Methods: This study was approved by the Clinical Test and Biomedical Ethics Committee of West China Hospital, Sichuan University on May 17, 2012. Data collection for this project was started in May 2017 and ended in March 2019. Data on 5293 women diagnosed with stage I to III invasive breast cancer between 2000 and 2013 were collected. Disease progression, cancer-specific mortality, all-cause mortality, and the likelihood of disease progression or death within a 5-year period were predicted. Extreme gradient boosting was used to develop the prediction model. Model performance was assessed by calculating the area under the receiver operating characteristic curve (AUROC), and the model was calibrated and compared with PREDICT. Results: The training, test, and validation sets comprised 3276 (499 progressions, 202 breast cancer-specific deaths, and 261 all-cause deaths within 5-year follow-up), 1405 (211 progressions, 94 breast cancer-specific deaths, and 129 all-cause deaths), and 612 (109 progressions, 33 breast cancer-specific deaths, and 37 all-cause deaths) women, respectively. The AUROC values for disease progression, cancer-specific mortality, and all-cause mortality were 0.76, 0.88, and 0.82 for training set; 0.79, 0.80, and 0.83 for the test set; and 0.79, 0.84, and 0.88 for the validation set, respectively. Calibration analysis demonstrated good agreement between predicted and observed events within 5 years. Comparable AUROC and calibration results were confirmed in different age, residence status, and receptor status subgroups. Compared with PREDICT, our model showed similar AUROC and improved calibration values.; Conclusions: Our prognostic model exhibits high discrimination and good calibration. It may facilitate prognosis prediction and clinical decision making for patients with breast cancer in China. ©Xiaorong Zhong, Ting Luo, Ling Deng, Pei Liu, Kejia Hu, Donghao Lu, Dan Zheng, Chuanxu Luo, Yuxin Xie, Jiayuan Li, Ping He, Tianjie Pu, Feng Ye, Hong Bu, Bo Fu, Hong Zheng.},
	author_keywords = {Breast cancer; Machine learning; Prediction model; Prognosis},
	correspondence_address = {H. Zheng; Laboratory of Molecular Diagnosis of Cancer Clinical Research Center for Breast, West China Hospital Sichuan University, Wuhou District Chengdu, 37 Guoxuexiang, China; email: hzheng@scu.edu.cn},
	publisher = {JMIR Publications Inc.},
	issn = {22919694},
	language = {English},
	abbrev_source_title = {JMIR Med. Inform.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Fuller2020496,
	author = {Fuller, Clifton D. and van Dijk, Lisanne V. and Thompson, Reid F. and Scott, Jacob G. and Ludmir, Ethan B. and Thomas, Charles R.},
	title = {Meeting the Challenge of Scientific Dissemination in the Era of COVID-19: Toward a Modular Approach to Knowledge-Sharing for Radiation Oncology},
	year = {2020},
	journal = {International Journal of Radiation Oncology Biology Physics},
	volume = {108},
	number = {2},
	pages = {496 – 505},
	doi = {10.1016/j.ijrobp.2020.06.066},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090038105&doi=10.1016%2fj.ijrobp.2020.06.066&partnerID=40&md5=87e8438d44ca221a666f73997c7ddbdb},
	affiliations = {Department of Radiation Oncology, The University of Texas MD Anderson Cancer, Houston, TX, United States; Department of Radiation Medicine, Oregon Health & Science University, OR, United States; Department of Radiation Oncology, University Medical Center- Groningen, Groningen, Netherlands; Department of Radiation Oncology, Taussig Cancer Institute, Cleveland Clinic, Cleveland, OH, United States},
	keywords = {angiotensin receptor antagonist; chloroquine; dipeptidyl carboxypeptidase inhibitor; macrolide; access to information; clinical medicine; clinical research; clinical trial (topic); communication skill; coronavirus disease 2019; Editorial; electronic medical record; human; influenza; information dissemination; information processing; instrument sterilization; internal bias; internal validity; machine learning; medical ethics; medicine; narrative; national health organization; pandemic; peer review; priority journal; publication; publishing; radiation oncologist; radiation oncology; registration; research priority; scientific literature; Severe acute respiratory syndrome coronavirus 2; social media; ultraviolet radiation; vascular surgeon},
	correspondence_address = {C.D. Fuller; Department of Radiation Oncology, The University of Texas MD Anderson Cancer, Houston, United States; email: cdfuller@mdanderson.org},
	publisher = {Elsevier Inc.},
	issn = {03603016},
	coden = {IOBPD},
	pmid = {32890543},
	language = {English},
	abbrev_source_title = {Int. J. Radiat. Oncol. Biol. Phys.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Seif El-Nasr2020,
	author = {Seif El-Nasr, Magy and Kleinman, Erica},
	title = {Data-Driven Game Development: Ethical Considerations},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3402942.3402964},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092303915&doi=10.1145%2f3402942.3402964&partnerID=40&md5=8e9403332b9bbd5d8ef1d6e580c1f587},
	affiliations = {Northeastern University, United States},
	abstract = {In recent years, the games industry has made a major move towards data-driven development, using data analytics and player modeling to inform design decisions. Data-driven techniques are beneficial as they allow for the study of player behavior at scale, making them very applicable to modern digital game development. However, with this move towards data driven decision-making comes a number of ethical concerns. Previous work in player modeling [45] as well as work in the fields of AI and machine learning [9, 53] have demonstrated several ways in which algorithmic decision-making can be flawed due to data or algorithmic bias or lack of data from specific groups. Further, black box algorithms create a trust problem due to lack of interpretability and transparency of the results or models developed based on the data, requiring blind faith in the results. In this position paper, we discuss several factors affecting the use of game data in the development cycle. In addition to issues raised by previous work, we also raise issues with algorithms marginalizing certain player groups and flaws in the resulting models due to their inability to reason about situational factors affecting players' decisions. Further, we outline some work that seeks to address these problems and identify some open problems concerning ethics and game data science. © 2020 ACM.},
	author_keywords = {Ethics; Game Data; Game Design; Human-in-the-Loop; Player Modeling; Transparent Models},
	keywords = {Computer games; Data Analytics; Data Science; Decision making; Machine learning; Philosophical aspects; Black box algorithms; Data driven decision; Data driven technique; Design decisions; Development cycle; Ethical concerns; Ethical considerations; Situational factors; Software design},
	editor = {Yannakakis G.N. and Liapis A. and Penny K. and Volz V. and Khosmood F. and Lopes P.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145038807-8},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th International Conference on the Foundations of Digital Games, FDG 2020; Conference date: 15 September 2020 through 18 September 2020; Conference code: 163063; All Open Access, Green Open Access}
}

@ARTICLE{Friebe2020,
	author = {Friebe, Michael},
	title = {HealthTEC Innovation Design-A proposal for a novel Master degree program based on Unmet Clinical Need, global Healthcare Challenges, and 21st century skills},
	year = {2020},
	journal = {Current Directions in Biomedical Engineering},
	volume = {6},
	number = {3},
	doi = {10.1515/cdbme-2020-3153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097213760&doi=10.1515%2fcdbme-2020-3153&partnerID=40&md5=94d265ff8f69a63ae9b5277780ea474c},
	affiliations = {Inka-Application Driven Research, Otto-von-Guericke University, Magdeburg, Germany; Idtm GmbH, Recklinghausen, Germany},
	abstract = {The effectiveness, efficiency, availability, agility, and equality of global healthcare systems are in question. The COVID-19 pandemic have further highlighted some of these issues and also shown that healthcare provision is in many parts of the world paternalistic, nimble, and often governed too extensively by revenue and profit motivations. The 4th industrial revolution-the machine learning age-with data gathering, analysis, optimisation, and delivery changes has not yet reached Healthcare/Health provision. We are still treating patients when they are sick rather then to use advanced sensors, data analytics, machine learning, genetic information, and other exponential technologies to prevent people from becoming patients or to help and support a clinicians decision. We are trying to optimise and improve traditional medicine (incremental innovation) rather than to use technologies to find new medical and clinical approaches (disruptive innovation). Education of future stakeholders from the clinical and from the technology side has not been updated to Health 4.0 demands and the needed 21st century skills. This paper presents a novel proposal for a university and innovation lab based interdisciplinary Master education of HealthTEC innovation designers.  © 2020 by Walter de Gruyter Berlin/Boston 2020.},
	author_keywords = {21st century skills; Biodesign; Biomedical Entrepreneurship; Biomedicalengineering Education; Exponential Technologies; Health 4.0; Health Democratization; Healthcare Ethics; Healthcare Innovation; Healthtec Innovation Management; Prevention; Reverse Innovation},
	keywords = {Data Analytics; Genes; Machine learning; Advanced sensors; Data gathering; Disruptive innovations; Genetic information; Health-care system; Incremental innovation; Industrial revolutions; Innovation design; Health care},
	publisher = {Walter de Gruyter GmbH},
	issn = {23645504},
	language = {English},
	abbrev_source_title = {Curr. Dir. Biomed. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Six Dijkstra2020343,
	author = {Six Dijkstra, Marianne W. M. C. and Siebrand, Egbert and Dorrestijn, Steven and Salomons, Etto L. and Reneman, Michiel F. and Oosterveld, Frits G. J. and Soer, Remko and Gross, Douglas P. and Bieleman, Hendrik J.},
	title = {Ethical Considerations of Using Machine Learning for Decision Support in Occupational Health: An Example Involving Periodic Workers’ Health Assessments},
	year = {2020},
	journal = {Journal of Occupational Rehabilitation},
	volume = {30},
	number = {3},
	pages = {343 – 353},
	doi = {10.1007/s10926-020-09895-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086000142&doi=10.1007%2fs10926-020-09895-x&partnerID=40&md5=5ce877926febb2225ec6af8935698a97},
	affiliations = {School of Health, Saxion University of Applied Sciences/AGZ, M.H. Tromplaan 28, Enschede, 7500 KB, Netherlands; Research Group Ethics & Technology, Saxion University of Applied Sciences, Enschede, Netherlands; School of Ambient Intelligence, Saxion University of Applied Sciences, Enschede, Netherlands; Department of Rehabilitation Medicine, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; University Medical Center Groningen, Pain Centre, University of Groningen, Groningen, Netherlands; Department of Physical Therapy, University of Alberta, Edmonton, Canada; University of Groningen, Groningen, Netherlands},
	abstract = {Purpose Computer algorithms and Machine Learning (ML) will be integrated into clinical decision support within occupational health care. This will change the interaction between health care professionals and their clients, with unknown consequences. The aim of this study was to explore ethical considerations and potential consequences of using ML based decision support tools (DSTs) in the context of occupational health. Methods We conducted an ethical deliberation. This was supported by a narrative literature review of publications about ML and DSTs in occupational health and by an assessment of the potential impact of ML-DSTs according to frameworks from medical ethics and philosophy of technology. We introduce a hypothetical clinical scenario from a workers’ health assessment to reflect on biomedical ethical principles: respect for autonomy, beneficence, non-maleficence and justice. Results Respect for autonomy is affected by uncertainty about what future consequences the worker is consenting to as a result of the fluctuating nature of ML-DSTs and validity evidence used to inform the worker. A beneficent advisory process is influenced because the three elements of evidence based practice are affected through use of a ML-DST. The principle of non-maleficence is challenged by the balance between group-level benefits and individual harm, the vulnerability of the worker in the occupational context, and the possibility of function creep. Justice might be empowered when the ML-DST is valid, but profiling and discrimination are potential risks. Conclusions Implications of ethical considerations have been described for the socially responsible design of ML-DSTs. Three recommendations were provided to minimize undesirable adverse effects of the development and implementation of ML-DSTs. © 2020, The Author(s).},
	author_keywords = {Clinical decision support system; Ethics; Evidence based practice; Machine learning; Morals; Occupational health},
	keywords = {Decision Support Techniques; Humans; Machine Learning; Male; Occupational Health; algorithm; beneficence; clinical decision support system; equipment design; evidence based practice center; human; justice; machine learning; medical ethics; narrative; occupational health; protein fingerprinting; respect; review; uncertainty; validity; worker; decision support system; machine learning; male},
	correspondence_address = {M.W.M.C. Six Dijkstra; School of Health, Saxion University of Applied Sciences/AGZ, Enschede, M.H. Tromplaan 28, 7500 KB, Netherlands; email: w.m.c.sixdijkstra@saxion.nl},
	publisher = {Springer},
	issn = {10530487},
	coden = {JOCTE},
	pmid = {32500471},
	language = {English},
	abbrev_source_title = {J. Occup. Rehabil.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Cheng2020354,
	author = {Cheng, Andy S. K. and Ng, Peter H. F. and Sin, Zackary P. T. and Lai, Sun H. S. and Law, S.W.},
	title = {Smart Work Injury Management (SWIM) System: Artificial Intelligence in Work Disability Management},
	year = {2020},
	journal = {Journal of Occupational Rehabilitation},
	volume = {30},
	number = {3},
	pages = {354 – 361},
	doi = {10.1007/s10926-020-09886-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083168120&doi=10.1007%2fs10926-020-09886-y&partnerID=40&md5=9757a791298ee7d93e59fb42407806cf},
	affiliations = {Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong; Department of Computing, The Hong Kong Polytechnic University, Hung Hom, Kowloon, Hong Kong; Total Rehabilitaton Management (HK) Limited, Wanchai Road, Wanchai, Hong Kong; Department of Orthopaedics & Traumatology, Alice Ho Miu Ling Nethersole Hospital/Tai Po Hospital, Tai Po, NT, Hong Kong},
	abstract = {Purpose: This paper aims to illustrate an example of how to set up a work injury database: the Smart Work Injury Management (SWIM) system. It is a secure and centralized cloud platform containing a set of management tools for data storage, data analytics, and machine learning. It employs artificial intelligence to perform in-depth analysis via text-mining techniques in order to extract both dynamic and static data from work injury case files. When it is fully developed, this system can provide a more accurate prediction model for cost of work injuries. It can also predict return-to-work (RTW) trajectory and provide advice on medical care and RTW interventions to all RTW stakeholders. The project will comprise three stages. Stage one: to identify human factors in terms of both facilitators and barriers RTW through face-to-face interviews and focus group discussions with different RTW stakeholders in order to collect opinions related to facilitators, barriers, and essential interventions for RTW of injured workers; Stage two: to develop a machine learning model which employs artificial intelligence to perform in-depth analysis. The technologies used will include: 1. Text-mining techniques including English and Chinese work segmentation as well as N-Gram to extract both dynamic and static data from free-style text as well as sociodemographic information from work injury case files; 2. Principle component/independent component analysis to identify features of significant relationships with RTW outcomes or combine raw features into new features; 3. A machine learning model that combines Variational Autoencoder, Long and Short Term Memory, and Neural Turning Machines. Stage two will also include the development of an interactive dashboard and website to query the trained machine learning model. Stage three: to field test the SWIM system. Conclusion: SWIM ia secure and centralized cloud platform containing a set of management tools for data storage, data analytics, and machine learning. When it is fully developed, SWIM can provide a more accurate prediction model for the cost of work injuries and advice on medical care and RTW interventions to all RTW stakeholders. Ethics: The project has been approved by the Ethics Committee for Human Subjects at the Hong Kong Polytechnic University and is funded by the Innovation and Technology Commission (Grant # ITS/249/18FX). © 2020, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Artificial intelligence; Machine learning; Prediction; Return to work; Work disability management},
	keywords = {Artificial Intelligence; Disability Evaluation; Employment; Focus Groups; Hong Kong; Humans; Return to Work; artificial intelligence; disability; employment; Hong Kong; human; information processing; return to work},
	correspondence_address = {A.S.K. Cheng; Department of Rehabilitation Sciences, The Hong Kong Polytechnic University, Kowloon, Hung Hom, Hong Kong; email: andy.cheng@polyu.edu.hk},
	publisher = {Springer},
	issn = {10530487},
	coden = {JOCTE},
	pmid = {32236811},
	language = {English},
	abbrev_source_title = {J. Occup. Rehabil.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}@ARTICLE{Mackey2020,
	author = {Mackey, Tim K. and Cuomo, Raphael E.},
	title = {An interdisciplinary review of digital technologies to facilitate anti-corruption, transparency and accountability in medicines procurement},
	year = {2020},
	journal = {Global Health Action},
	volume = {13},
	number = {sup1},
	doi = {10.1080/16549716.2019.1695241},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082088358&doi=10.1080%2f16549716.2019.1695241&partnerID=40&md5=ec865792c40952fb01e49db8b6d513d8},
	affiliations = {Global Health Policy Institute, San Diego, CA, United States; Department of Anesthesiology and Division of Infectious Diseases and Global Public Health, University of California, San Diego–School of Medicine, San Diego, CA, United States; Department of Healthcare Research and Policy, University of California, San Diego–Extension, San Diego, CA, United States},
	abstract = {Background: Pharmaceutical corruption is a serious challenge in global health. Digital technologies that can detect and prevent fraud and corruption are particularly important to address barriers to access to medicines, such as medicines availability and affordability, stockouts, shortages, diversion, and infiltration of substandard and falsified medicines. Objectives: To better understand how digital technologies are used to combat corruption, increase transparency, and detect fraud in pharmaceutical procurement systems to improve population health outcomes. Methods: We conducted a multidisciplinary review of the health/medicine, engineering, and computer science literature. Our search queries included keywords associated with medicines procurement and digital technology in combination with terms associated with transparency and anti-corruption initiatives. Our definition of ‘digital technology’ focused on Internet-based communications, including online portals and management systems, supply chain tools, and electronic databases. Results: We extracted 37 articles for in-depth review based on our inclusion criteria focused on the utilization of digital technology to improve medicines procurement. The vast majority of articles focused on electronic data transfer and/or e-procurement systems with fewer articles discussing emerging technologies such as machine learning and blockchain distributed ledger solutions. In the context of e-procurement, slow adoption, justifying cost-savings, and need for technical standards setting were identified as key challenges for current and future utilization. Conclusions: Though there is a significant promise for digital technologies, particularly e-procurement, overall adoption of solutions that can enhance transparency, accountability and concomitantly combat corruption, is still underdeveloped. Future efforts should focus on tying cost-saving measurements with anti-corruption indicators, prioritizing centralization of e-procurement systems, establishing regulatory harmonization with standards setting, and incorporating additional anti-corruption technologies into procurement processes for improving access to medicines and to reach the overall goal of Universal Health Coverage. © 2020, © 2020 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {access to medicines; Anti-Corruption, Transparency and Accountability; corruption; e-procurement; global health; Medicines procurement; technology; transparency},
	keywords = {Fraud; Global Health; Humans; Interdisciplinary Studies; Inventions; Pharmaceutical Preparations; Social Responsibility; Universal Health Insurance; drug; economics; ethics; fraud; global health; human; interdisciplinary education; invention; organization and management; prevention and control; social responsibility},
	correspondence_address = {T.K. Mackey; University of California, San Diego, La Jolla, 8950 Villa La Jolla Drive, A124, La Jolla, 92037, United States; email: tmackey@ucsd.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {16549880},
	pmid = {32194014},
	language = {English},
	abbrev_source_title = {Global Health Action},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sibai2020,
	author = {Sibai, Fadi N.},
	title = {AI Crimes: A Classification},
	year = {2020},
	journal = {International Conference on Cyber Security and Protection of Digital Services, Cyber Security 2020},
	doi = {10.1109/CyberSecurity49315.2020.9138891},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092007351&doi=10.1109%2fCyberSecurity49315.2020.9138891&partnerID=40&md5=ff1e300388f8c9b60c1beef77830c72a},
	affiliations = {Prince Mohammad Bin Fahd University, College of Computer Engineering and Science, Al-Khobar, Saudi Arabia},
	abstract = {Intelligent and machine learning systems have infiltrated cyber-physical systems and smart cities with technologies such as internet of things, image processing, robotics, speech recognition, self-driving, and predictive maintenance. To gain user trust, such systems must be transparent and explainable. Regulations are required to control crimes associated with these technologies. Such regulations and legislations depend on the severity of the artificial intelligence (AI) crimes subject to these regulations, and on whether humans and/or intelligent systems are responsible for committing such crimes, and therefore can benefit from a classification tree of AI crimes. The aim of this paper to review prior work in ethics for AI, and classify AI crimes by producing a classification tree to assist in AI crime investigation and regulation.  © 2020 IEEE.},
	author_keywords = {AI; classification tree; crimes; ethics; explainable AI; privacy; transparency; trust},
	keywords = {Embedded systems; Image processing; Intelligent systems; Learning systems; Security of data; Speech recognition; Classification trees; Crime investigation; Self drivings; Crime},
	correspondence_address = {F.N. Sibai; Prince Mohammad Bin Fahd University, College of Computer Engineering and Science, Al-Khobar, Saudi Arabia; email: fsibai@pmu.edu.sa},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172816428-1},
	language = {English},
	abbrev_source_title = {Int. Conf. Cyber Secur. Prot. Digit. Serv., Cyber Security},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2020 International Conference on Cyber Security and Protection of Digital Services, Cyber Security 2020; Conference date: 15 June 2020 through 19 June 2020; Conference code: 161827}
}

@ARTICLE{Carrillo-Larco2020,
	author = {Carrillo-Larco, Rodrigo M and Tudor Car, Lorainne and Pearson-Stuttard, Jonathan and Panch, Trishan and Miranda, J Jaime and Atun, Rifat},
	title = {Machine learning health-related applications in low-income and middle-income countries: a scoping review protocol},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {5},
	doi = {10.1136/bmjopen-2019-035983},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084541360&doi=10.1136%2fbmjopen-2019-035983&partnerID=40&md5=9de29c31bf91d76f0e3ba9410fa00658},
	affiliations = {Department of Epidemiology and Biostatistics, School of Public Health, Imperial College London, London, United Kingdom; CRONICAS Centre of Excellence in Chronic Diseases, Universidad Peruana Cayetano Heredia, Lima, Peru; Family Medicine and Primary Care, Lee Kong Chian School of Medicine, Nanyang Technological University, Singapore; Department of Primary Care and Public Health, School of Public Health, Imperial College London, London, United Kingdom; Department of Epidemiology and Biostatistics, MRC-PHE Centre for Environment and Health, School of Public Health, Imperial College London, London, United Kingdom; Wellframe Inc, Boston, MA, United States; Facultad de Medicina 'Alberto Hurtado', Universidad Peruana Cayetano Heredia, Lima, Peru; Harvard T.H Chan School of Public Health and Harvard Medical School, Harvard University, Cambridge, MA, United States},
	abstract = {Introduction: Machine learning (ML) has been used in bio-medical research, and recently in clinical and public health research. However, much of the available evidence comes from high-income countries, where different health profiles challenge the application of this research to low/middle-income countries (LMICs). It is largely unknown what ML applications are available for LMICs that can support and advance clinical medicine and public health. We aim to address this gap by conducting a scoping review of health-related ML applications in LMICs. Methods and analysis: This scoping review will follow the methodology proposed by Levac et al. The search strategy is informed by recent systematic reviews of ML health-related applications. We will search Embase, Medline and Global Health (through Ovid), Cochrane and Google Scholar; we will present the date of our searches in the final review. Titles and abstracts will be screened by two reviewers independently; selected reports will be studied by two reviewers independently. Reports will be included if they are primary research where data have been analysed, ML techniques have been used on data from LMICs and they aimed to improve health-related outcomes. We will synthesise the information following evidence mapping recommendations. Ethics and dissemination: The review will provide a comprehensive list of health-related ML applications in LMICs. The results will be disseminated through scientific publications. We also plan to launch a website where ML models can be hosted so that researchers, policymakers and the general public can readily access them. © Author(s) (or their employer(s)) 2020.},
	author_keywords = {biotechnology & bioinformatics; epidemiology; health informatics; World Wide Web technology},
	keywords = {Delivery of Health Care; Developing Countries; Humans; Income; Machine Learning; Poverty; Review Literature as Topic; article; bioinformatics; biotechnology; clinical medicine; Embase; global health; high income country; human; Internet; lowest income group; machine learning; medical informatics; Medline; middle income country; outcome assessment; systematic review; developing country; health care delivery; income; literature; machine learning; poverty},
	correspondence_address = {R.M. Carrillo-Larco; Department of Epidemiology and Biostatistics, School of Public Health, Imperial College London, London, United Kingdom; email: r.carrillo-larco@imperial.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {32393612},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Neumann20201,
	author = {Neumann, Alexander and Strenge, Benjamin and Uhlich, Janne C. and Schlicher, Katharina D. and Maier, Günter W. and Schalkwijk, Lars and Waßmuth, Joachim and Essig, Kai and Schack, Thomas},
	title = {AVIKOM: Towards a mobile audiovisual cognitive assistance system for modern manufacturing and logistics},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {1 – 8},
	doi = {10.1145/3389189.3389191},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088367709&doi=10.1145%2f3389189.3389191&partnerID=40&md5=5cb410c36be01f88305b275691b5d3bf},
	affiliations = {Bielefeld University, Bielefeld, Germany; Bielefeld University of Applied Sciences, Bielefeld, Germany; Rhein-Waal University of Applied Sciences Communication and Environment, Kamp-Lintfort, Germany},
	abstract = {This paper introduces the novel Augmented Reality (AR) assistance system AVIKOM, a joint endeavour of three research groups together with four small and medium-sized enterprises (SME) as well as network partners and a diaconal institution. In particular, we investigate how AR-enabled assistance systems can be tailored to individual requirements of workers with diverse cognitive and physical capabilities for today's real-world industrial applications in the areas of (manual) assembly, logistics and operation of industrial machinery. We combine best practices from the domains of artificial intelligence, machine learning, user experience engineering, ethics research, and cognitive science with state-of-the-art insights for multi-modal system development to create a cognitive action assistance system that recognizes and adapts to individual users in various situational contexts, such as picking and training. Proven work and organizational psychology methods and worth-related evaluations will accompany the system introduction into working environments. Using user- and worth-centred system design and change management strategies (e.g. information and participation) right from the beginning of such a technological development facilitates proper involvement of future users in the development process. This can lead to better congruence of technology features with workers' requirements and positively shape future users' attitudes towards the system. © 2020 ACM.},
	author_keywords = {assistive systems; augmented reality (AR); eye tracking; individualized feedback; scene and action understanding},
	keywords = {Artificial intelligence; Augmented reality; Cognitive systems; Machinery; User experience; Cognitive assistance; Development process; Industrial machinery; Organizational psychology; Physical capabilities; Situational context; Small- and medium-sized enterprise; Technological development; Information management},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037773-7},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; Conference name: 13th ACM International Conference on PErvasive Technologies Related to Assistive Environments, PETRA 2020; Conference date: 30 June 2020 through 3 July 2020; Conference code: 161521}
}

@CONFERENCE{Zucker2020421,
	author = {Zucker, Julian and D'Leeuwen, Myraeka},
	title = {Arbiter: A domain-specific language for ethical machine learning},
	year = {2020},
	journal = {AIES 2020 - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {421 – 425},
	doi = {10.1145/3375627.3375858},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082168237&doi=10.1145%2f3375627.3375858&partnerID=40&md5=47a77e141ba9f4b19cda7d334ed0a72d},
	affiliations = {Northeastern University, United States},
	abstract = {The widespread deployment of machine learning models in highstakes decision making scenarios requires a code of ethics for machine learning practitioners. We identify four of the primary components required for the ethical practice of machine learning: transparency, fairness, accountability, and reproducibility. We introduce Arbiter, a domain-specific programming language for machine learning practitioners that is designed for ethical machine learning. Arbiter provides a notation for recording how machine learning models will be trained, and we show how this notation can encourage the four described components of ethical machine learning. © 2020 Copyright held by the owner/author(s).},
	author_keywords = {Domain-specific languages; Ethical machine learning},
	keywords = {Decision making; Ethical aspects; Machine components; Problem oriented languages; Code of Ethics; Domain specific languages; Domain specific programming languages; Ethical practices; Machine learning models; Reproducibilities; Machine learning},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145037110-0},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 3rd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2020, co-located with AAAI 2020; Conference date: 7 February 2020 through 8 February 2020; Conference code: 158220}
}

@ARTICLE{Ryan2020,
	author = {Ryan, Mark and Antoniou, Josephina and Brooks, Laurence and Jiya, Tilimbe and Macnish, Kevin and Stahl, Bernd},
	title = {The ethical balance of using smart information systems for promoting the United Nations' sustainable development goals},
	year = {2020},
	journal = {Sustainability (Switzerland)},
	volume = {12},
	number = {12},
	doi = {10.3390/SU12124826},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087696759&doi=10.3390%2fSU12124826&partnerID=40&md5=19b9149b634858719de2e1ad642886e1},
	affiliations = {KTH Royal Institute of Technology, Stockholm, 100 44, Sweden; UCLan Cyprus, Larnaka, 7080, Cyprus; Centre for Computing and Social Responsibility, De Montfort University, Leicester, LE1 9BH, United Kingdom; Centre for Sustainable Business Practices (CSBP), University of Northampton, Northampton, NN1 5PH, United Kingdom; Department of Philosophy, The University of Twente, Enschede, 7500 AE, Netherlands},
	abstract = {The Sustainable Development Goals (SDGs) are internationally agreed goals that allow us to determine what humanity, as represented by 193 member states, finds acceptable and desirable. The paper explores how technology can be used to address the SDGs and in particular Smart Information Systems (SIS). SIS, the technologies that build on big data analytics, typically facilitated by AI techniques such as machine learning, are expected to grow in importance and impact. Some of these impacts are likely to be beneficial, notably the growth in efficiency and profits, which will contribute to societal wellbeing. At the same time, there are significant ethical concerns about the consequences of algorithmic biases, job loss, power asymmetries and surveillance, as a result of SIS use. SIS have the potential to exacerbate inequality and further entrench the market dominance of big tech companies, if left uncontrolled. Measuring the impact of SIS on SDGs thus provides a way of assessing whether an SIS or an application of such a technology is acceptable in terms of balancing foreseeable benefits and harms. One possible approach is to use the SDGs as guidelines to determine the ethical nature of SIS implementation. While the idea of using SDGs as a yardstick to measure the acceptability of emerging technologies is conceptually strong, there should be empirical evidence to support such approaches. The paper describes the findings of a set of 6 case studies of SIS across a broad range of application areas, such as smart cities, agriculture, finance, insurance and logistics, explicitly focusing on ethical issues that SIS commonly raise and empirical insights from organisations using these technologies. © 2020 by the authors.},
	author_keywords = {Case studies; Ethics; Impact; Smart Information Systems (SIS); Sustainable Development Goals (SDGs)},
	keywords = {algorithm; asymmetry; ethics; information system; machine learning; market system; profitability; sustainability; sustainable development; United Nations},
	correspondence_address = {M. Ryan; KTH Royal Institute of Technology, Stockholm, 100 44, Sweden; email: mryan@kth.se},
	publisher = {MDPI},
	issn = {20711050},
	language = {English},
	abbrev_source_title = {Sustainability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Casebeer202081,
	author = {Casebeer, William D.},
	title = {Building an Artificial Conscience: Prospects for Morally Autonomous Artificial Intelligence},
	year = {2020},
	journal = {Artificial Intelligence and Global Security: Future Trends, Threats and Considerations},
	pages = {81 – 94},
	doi = {10.1108/978-1-78973-811-720201005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144351970&doi=10.1108%2f978-1-78973-811-720201005&partnerID=40&md5=1e1cf2984151daa0ea6129ded519bd4f},
	affiliations = {Scientific Systems Company, Inc, United States},
	abstract = {Discussions of ethics and Artificial Intelligence (AI) usually revolve around the ethical implications of the use of AI in multiple domains, ranging from whether machine learning trained algorithms may encode discriminatory standards for face recognition, to discussions of the implications of using AI as a substitute for human intelligence in warfare. In this chapter, I will focus on one particular strand of ethics and AI that is often neglected: whether we can use the methods of AI to build or train a system which can reason about moral issues and act on them. Here, I discuss (1) what an “artificial conscience” consists of and what it would do, (2) why we collectively should build one soon given the increasing use of AI in multiple areas, (3) how we might build one in both architecture and content, and (4) concerns about building an artificial conscience and my rejoinders. Given the increasing importance of artificially intelligent semi- or fully autonomous systems and platforms for contemporary warfare, I conclude that building an artificial conscience is not only possible but also morally required if our autonomous teammates are to collaborate fully with human soldiers on the battlefield. © 2020 Emerald Publishing Limited.},
	author_keywords = {artificial conscience; autonomy; Ethics; heuristics; moral development; moral judgment; morality},
	publisher = {Emerald Group Publishing Ltd.},
	isbn = {978-178973811-7; 978-178973812-4},
	language = {English},
	abbrev_source_title = {Artificial Intelligence and Global Security: Future Trends, Threats and Considerations},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Wagenaar20201149,
	author = {Wagenaar, Dennis and Curran, Alex and Balbi, Mariano and Bhardwaj, Alok and Soden, Robert and Hartato, Emir and Mestav Sarica, Gizem and Ruangpan, Laddaporn and Molinario, Giuseppe and Lallemant, David},
	title = {Invited perspectives: How machine learning will change flood risk and impact assessment},
	year = {2020},
	journal = {Natural Hazards and Earth System Sciences},
	volume = {20},
	number = {4},
	pages = {1149 – 1161},
	doi = {10.5194/nhess-20-1149-2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084644642&doi=10.5194%2fnhess-20-1149-2020&partnerID=40&md5=51427b8a50a9fd20153a866bc239acf6},
	affiliations = {Department of Flood Risk Management, Deltares, Delft, Netherlands; Institute for Environmental Studies, VU University, Amsterdam, Netherlands; Faculty of Civil Engineering and Geosciences, Delft University of Technology, Delft, Netherlands; Structural and Materials Lab, School of Engineering, Universidad de Buenos Aires, Buenos Aires, Argentina; Earth Observatory of Singapore, Nanyang Technological University, Singapore, Singapore; Columbia University, New York City, NY, United States; GFDRR, World Bank Group, Washington, DC, United States; Co-Risk Labs, Oakland, CA, United States; Planet, San Francisco, United States; Institute of Catastrophe Risk Management, Nanyang Technological University, Singapore, Singapore; Department of Water Resources and Ecosystems, IHE Delft Institute for Water Education, Delft, Netherlands},
	abstract = {<p>Increasing amounts of data, together with more computing power and better machine learning algorithms to analyse the data, are causing changes in almost every aspect of our lives. This trend is expected to continue as more data keep becoming available, computing power keeps improving and machine learning algorithms keep improving as well. Flood risk and impact assessments are also being influenced by this trend, particularly in areas such as the development of mitigation measures, emergency response preparation and flood recovery planning. Machine learning methods have the potential to improve accuracy as well as reduce calculating time and model development cost. It is expected that in the future more applications will become feasible and many process models and traditional observation methods will be replaced by machine learning. Examples of this include the use of machine learning on remote sensing data to estimate exposure and on social media data to improve flood response. Some improvements may require new data collection efforts, such as for the modelling of flood damages or defence failures. In other components, machine learning may not always be suitable or should be applied complementary to process models, for example in hydrodynamic applications. Overall, machine learning is likely to drastically improve future flood risk and impact assessments, but issues such as applicability, bias and ethics must be considered carefully to avoid misuse. This paper presents some of the current developments on the application of machine learning in this field and highlights some key needs and challenges.</p>. © 2020 Copernicus GmbH. All rights reserved.},
	keywords = {algorithm; environmental impact assessment; flood; hydrodynamics; machine learning; risk assessment},
	correspondence_address = {D. Wagenaar; Department of Flood Risk Management, Deltares, Delft, Netherlands; email: dennis.wagenaar@deltares.nl},
	publisher = {Copernicus GmbH},
	issn = {15618633},
	language = {English},
	abbrev_source_title = {Nat. Hazards Earth Syst. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hagendorff202099,
	author = {Hagendorff, Thilo},
	title = {The Ethics of AI Ethics: An Evaluation of Guidelines},
	year = {2020},
	journal = {Minds and Machines},
	volume = {30},
	number = {1},
	pages = {99 – 120},
	doi = {10.1007/s11023-020-09517-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078946650&doi=10.1007%2fs11023-020-09517-8&partnerID=40&md5=4a90182c8735c1cedf9d1cb78ebd6682},
	affiliations = {Cluster of Excellence “Machine Learning: New Perspectives for Science”, University of Tuebingen, Tübingen, Germany},
	abstract = {Current advances in research, development and application of artificial intelligence (AI) systems have yielded a far-reaching discourse on AI ethics. In consequence, a number of ethics guidelines have been released in recent years. These guidelines comprise normative principles and recommendations aimed to harness the “disruptive” potentials of new AI technologies. Designed as a semi-systematic evaluation, this paper analyzes and compares 22 guidelines, highlighting overlaps but also omissions. As a result, I give a detailed overview of the field of AI ethics. Finally, I also examine to what extent the respective ethical principles and values are implemented in the practice of research, development and application of AI systems—and how the effectiveness in the demands of AI ethics can be improved. © 2020, The Author(s).},
	author_keywords = {Artificial intelligence; Ethics; Guidelines; Implementation; Machine learning},
	keywords = {Artificial intelligence; Learning systems; AI systems; AI Technologies; Development and applications; Ethical principles; Ethics; Guidelines; Implementation; Systematic evaluation; Philosophical aspects},
	correspondence_address = {T. Hagendorff; Cluster of Excellence “Machine Learning: New Perspectives for Science”, University of Tuebingen, Tübingen, Germany; email: thilo.hagendorff@uni-tuebingen.de},
	publisher = {Springer},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 427; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Jacobson2020270,
	author = {Jacobson, Nicholas C. and Bentley, Kate H. and Walton, Ashley and Wang, Shirley B. and Fortgang, Rebecca G. and Millner, Alexander J. and Coombs, Garth and Rodman, Alexandra M. and Coppersmith, Daniel D L.},
	title = {Ethical dilemmas posed by mobile health and machine learning in psychiatry research; [Les dilemmes éthiques posés par la santé mobile et l'apprentissage automatique dans la recherche en psychiatrie]; [Los dilemas éticos planteados por la salud móvil y el aprendizaje automático dentro de la investigación en psiquiatría]},
	year = {2020},
	journal = {Bulletin of the World Health Organization},
	volume = {98},
	number = {4},
	pages = {270 – 276},
	doi = {10.2471/BLT.19.237107},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083161803&doi=10.2471%2fBLT.19.237107&partnerID=40&md5=554988da7636ea550cd9aaf9b478d591},
	affiliations = {Department of Biomedical Data Science and Psychiatry, Geisel School of Medicine, Dartmouth College, Suite 300, Office # 333S, 46 Centerra Parkway, Lebanon, N03766, United States; Department of Psychiatry, Massachusetts General Hospital, Harvard Medical School, Cambridge, United States; Department of Statistics, Harvard University, Cambridge, United States; Department of Psychology, Harvard University, Cambridge, United States},
	abstract = {The application of digital technology to psychiatry research is rapidly leading to new discoveries and capabilities in the field of mobile health. However, the increase in opportunities to passively collect vast amounts of detailed information on study participants coupled with advances in statistical techniques that enable machine learning models to process such information has raised novel ethical dilemmas regarding researchers’duties to: (i) monitor adverse events and intervene accordingly; (ii) obtain fully informed, voluntary consent; (iii) protect the privacy of participants; and (iv) increase the transparency of powerful, machine learning models to ensure they can be applied ethically and fairly in psychiatric care. This review highlights emerging ethical challenges and unresolved ethical questions in mobile health research and provides recommendations on how mobile health researchers can address these issues in practice. Ultimately, the hope is that this review will facilitate continued discussion on how to achieve best practice in mobile health research within psychiatry. © 2020, World Health Organization. All rights reserved.},
	keywords = {Ethics, Research; Informed Consent; Machine Learning; Privacy; Psychiatry; Telemedicine; detection method; machine learning; model; transparency; adult; article; human; machine learning; medical research; mental health care; privacy; psychiatry; ethics; informed consent; machine learning; research ethics; telemedicine},
	correspondence_address = {N.C. Jacobson; Department of Biomedical Data Science and Psychiatry, Geisel School of Medicine, Dartmouth College, Lebanon, Suite 300, Office # 333S, 46 Centerra Parkway, N03766, United States; email: nicholas.c.jacobson@dartmouth.edu},
	publisher = {World Health Organization},
	issn = {00429686},
	coden = {BWHOA},
	pmid = {32284651},
	language = {English},
	abbrev_source_title = {Bull. WHO},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Anwar202095,
	author = {Anwar, Mohammad Amir and Graham, Mark},
	title = {Digital labour at economic margins: African workers and the global information economy},
	year = {2020},
	journal = {Review of African Political Economy},
	volume = {47},
	number = {163},
	pages = {95 – 105},
	doi = {10.1080/03056244.2020.1728243},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083648116&doi=10.1080%2f03056244.2020.1728243&partnerID=40&md5=25c8303b45a55410701eb88625275ada},
	affiliations = {Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; School of Tourism and Hospitality, University of Johannesburg, Johannesburg, South Africa},
	abstract = {SUMMARY: The main aim of this briefing is to make visible the invisible and bring light to the role African workers are playing in developing key emergent and everyday digital technologies such as autonomous vehicles, machine learning systems, next-generation search engines and recommendations systems. Once we acknowledge that many contemporary digital technologies rely on a lot of human labour to drive their interfaces, we can begin to piece together what the new global division of labour for digital work looks like and build a greater socio-political response (both at the global and local scale) to make some of these value chains more transparent, ethical and rewarding. © 2020, ROAPE Publications Ltd.},
	keywords = {Africa; economic development; ethics; information and communication technology; labor division; labor market; political economy},
	correspondence_address = {M.A. Anwar; Oxford Internet Institute, University of Oxford, Oxford, United Kingdom; email: mohammad.anwar@ed.ac.uk},
	publisher = {Routledge},
	issn = {03056244},
	language = {English},
	abbrev_source_title = {Rev. Afr. Polit. Econ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Green Open Access}
}

@ARTICLE{Görges2020404,
	author = {Görges, Matthias and Ansermino, J. Mark},
	title = {Augmented intelligence in pediatric anesthesia and pediatric critical care},
	year = {2020},
	journal = {Current Opinion in Anaesthesiology},
	volume = {33},
	number = {3},
	pages = {404 – 410},
	doi = {10.1097/ACO.0000000000000845},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084721810&doi=10.1097%2fACO.0000000000000845&partnerID=40&md5=bda3b921979d1ed1d2309e8c1dc9d126},
	affiliations = {Department of Anesthesiology, Pharmacology and Therapeutics, University of British Columbia, Canada; Research Institute, BC Children's Hospital, Vancouver, Canada},
	abstract = {Purpose of review Acute care technologies, including novel monitoring devices, big data, increased computing capabilities, machine-learning algorithms and automation, are converging. This enables the application of augmented intelligence for improved outcome predictions, clinical decision-making, and offers unprecedented opportunities to improve patient outcomes, reduce costs, and improve clinician workflow. This article briefly explores recent work in the areas of automation, artificial intelligence and outcome prediction models in pediatric anesthesia and pediatric critical care. Recent findings Recent years have yielded little published research into pediatric physiological closed loop control (a type of automation) beyond studies focused on glycemic control for type 1 diabetes. However, there has been a greater range of research in augmented decision-making, leveraging artificial intelligence and machinelearning techniques, in particular, for pediatric ICU outcome prediction. Summary Most studies focusing on artificial intelligence demonstrate good performance on prediction or classification, whether they use traditional statistical tools or novel machine-learning approaches. Yet the challenges of implementation, user acceptance, ethics and regulation cannot be underestimated. Areas in which there is easy access to routinely labeled data and robust outcomes, such as those collected through national networks and quality improvement programs, are likely to be at the forefront of the adoption of these advances. © 2020 Endocrine Society. All rights reserved.},
	author_keywords = {Artificial intelligence; Augmented decision-making; Machine learning; Pediatrics; Physiologic closed-loop control},
	keywords = {Anesthesia; Artificial Intelligence; Child; Critical Care; Humans; Intelligence; Machine Learning; anesthesia; artificial intelligence; child; human; intelligence; intensive care; machine learning},
	correspondence_address = {M. Görges; Children's Hospital Research Institute, Vancouver, Rm V3-324, 950 West 28th Avenue, V5Z 4H4, Canada; email: mgorges@bcchr.ca},
	publisher = {Lippincott Williams and Wilkins},
	issn = {09527907},
	coden = {COAEE},
	pmid = {32324658},
	language = {English},
	abbrev_source_title = {Curr. Opin. Anaesthesiol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Goltz2020132,
	author = {Goltz, Nachshon and Zeleznikow, John and Dowdeswell, Tracey},
	title = {From the tree of knowledge and the golem of Prague to kosher autonomous cars: The ethics of artificial intelligence through jewish eyes},
	year = {2020},
	journal = {Oxford Journal of Law and Religion},
	volume = {9},
	number = {1},
	pages = {132 – 156},
	doi = {10.1093/ojlr/rwaa015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097271669&doi=10.1093%2fojlr%2frwaa015&partnerID=40&md5=01295c7568bb46d18632ae6e3ccf1a02},
	affiliations = {School of Business and Law, Edith Cowan University, Australia; School of Computer Science, Victoria University, Australia; School of Criminology, Douglas College, Canada},
	abstract = {This article discusses the regulation of artificial intelligence from a Jewish perspective, with an emphasis on the regulation of machine learning and its application to autonomous vehicles and machine learning. Through the Biblical story of Adam and Eve as well as Golem legends from Jewish folklore, we derive several basic principles that underlie a Jewish perspective on the moral and legal personhood of robots and other artificially intelligent agents. We argue that religious ethics in general, and Jewish ethics in particular, show us that the dangers of granting moral personhood to robots and in particular to autonomous vehicles lie not in the fact that they lack a soul-or consciousness or feelings or interests-but because to do so weakens our own ability to develop as fully autonomous legal and moral persons. Instead, we argue that existing legal persons should continue to maintain legal control over artificial agents, while natural persons assume ultimate moral responsibility for choices made by artificial agents they employ in their service. In the final section of the article we discuss the trolley dilemma in the context of governing autonomous vehicles and sketch out an application of Jewish ethics in a case where we are asking Artificial Intelligence to make life and death decisions. Our novel contribution is two-fold; first, we bring a religious approach to the discussion of the ethics of Artificial Intelligence which has hitherto been dominated by secular Western philosophies; second, we raise the idea that artificial entities who are trained through machine learning can be ethically trained in much the same way that human are-through reading and reflecting on core religious texts. This is both a way of ensuring the ethical regulation of artificial intelligence, but also promotes other core values of regulation, such as democratic engagement and user choice. © The Author(s) 2020. Published by Oxford University Press. All rights reserved.},
	correspondence_address = {N. Goltz; School of Business and Law, Edith Cowan University, Australia; email: n.goltz@ecu.edu.au},
	publisher = {Oxford University Press},
	issn = {20470770},
	language = {English},
	abbrev_source_title = {Oxf. J. Law Rel.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Garcelon2020676,
	author = {Garcelon, Nicolas and Burgun, Anita and Salomon, Rémi and Neuraz, Antoine},
	title = {Electronic health records for the diagnosis of rare diseases},
	year = {2020},
	journal = {Kidney International},
	volume = {97},
	number = {4},
	pages = {676 – 686},
	doi = {10.1016/j.kint.2019.11.037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080067503&doi=10.1016%2fj.kint.2019.11.037&partnerID=40&md5=974196a8feb00be5184400f99027680a},
	affiliations = {Inserm U1163, Imagine Institute, Paris Center University, Paris, France; Inserm, Cordeliers Research Center, U1138, eq 22, Paris Descartes University, Sorbonne Paris-Cite, Paris, France; Department of Medical Informatics, Necker–Enfants Malades Hospital, Assistance Publique–Hôpitaux de Paris (AP-HP), Paris, France; Department of Pediatric Nephrology, Necker–Enfants Malades Hospital, Assistance Publique–Hôpitaux de Paris (AP-HP), Paris, France},
	abstract = {With the emergence of electronic health records, the reuse of clinical data offers new perspectives for the diagnosis and management of patients with rare diseases. However, there are many obstacles to the repurposing of clinical data. The development of decision support systems depends on the ability to recruit patients, extract and integrate the patients’ data, mine and stratify these data, and integrate the decision support algorithm into patient care. This last step requires an adaptability of the electronic health records to integrate learning health system tools. In this literature review, we examine the research that provides solutions to unlock these barriers and accelerate translational research: structured electronic health records and free-text search engines to find patients, data warehouses and natural language processing to extract phenotypes, machine learning algorithms to classify patients, and similarity metrics to diagnose patients. Medical informatics is experiencing an impellent request to develop decision support systems, and this requires ethical considerations for clinicians and patients to ensure appropriate use of health data. © 2020 International Society of Nephrology},
	author_keywords = {artificial intelligence; education; electronic health record; pediatric nephrology; rare diseases},
	keywords = {artificial intelligence; ciliopathy; clinical decision support system; clinical pathway; clinical research; data warehouse; electronic health record; human; Internet; learning algorithm; machine learning; medical ethics; medical informatics; natural language processing; patient identification; personalized medicine; priority journal; rare disease; Review; search engine; translational research},
	correspondence_address = {N. Garcelon; UMR 1163, U1163, Data Science Platform, Imagine Institute for Genetic Diseases, Paris, France; email: nicolas.garcelon@institut.imagine.org},
	publisher = {Elsevier B.V.},
	issn = {00852538},
	coden = {KDYIA},
	pmid = {32111372},
	language = {English},
	abbrev_source_title = {Kidney Int.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Milstein20201537,
	author = {Milstein, Arnold and Topol, Eric J},
	title = {Computer vision's potential to improve health care},
	year = {2020},
	journal = {The Lancet},
	volume = {395},
	number = {10236},
	pages = {1537},
	doi = {10.1016/S0140-6736(20)31090-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084494719&doi=10.1016%2fS0140-6736%2820%2931090-4&partnerID=40&md5=b436dc2f6f0b5991dc7cf0cc44da74a6},
	affiliations = {Stanford Clinical Excellence Research Center, Stanford University School of Medicine, Stanford, 94305-6015, CA, United States; Scripps Research Translational Institute, Scripps Research, La Jolla, CA, United States},
	keywords = {Algorithms; Artificial Intelligence; Clinical Decision-Making; Computers; Delivery of Health Care; Electronic Health Records; Humans; Intensive Care Units; Medicare; Patient Harm; Surgeons; United States; Video Recording; Vision, Ocular; alert fatigue (health care); Article; artificial intelligence; computer vision; electronic health record; emergency ward; hand washing; health care quality; intensive care unit; machine learning; medical error; medicare; patient harm; physical examination; priority journal; self care; videorecording; algorithm; artificial intelligence; clinical decision making; computer; devices; economics; ethics; health care delivery; human; prevention and control; surgeon; United States; vision},
	publisher = {Lancet Publishing Group},
	issn = {01406736},
	coden = {LANCA},
	pmid = {32416778},
	language = {English},
	abbrev_source_title = {Lancet},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Bucher2020610,
	author = {Bucher, Taina},
	title = {Nothing to disconnect from? Being singular plural in an age of machine learning},
	year = {2020},
	journal = {Media, Culture and Society},
	volume = {42},
	number = {4},
	pages = {610 – 617},
	doi = {10.1177/0163443720914028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083167923&doi=10.1177%2f0163443720914028&partnerID=40&md5=70d5d29561ef13d2eff369d615061968},
	affiliations = {University of Oslo, Norway},
	abstract = {This essay makes the claim that there is nothing to disconnect from in the digital world, and that the logic of machine learning provides the most obvious empirical case for this. Drawing on Jean-Luc Nancy’s concept of Being as always already a being-with, the argument is made that the inescapability of others does not provide the end-point for a gesture towards disconnection but an opportunity to rethink the ethics of dis/connectivity in a more productive way. I situate these claims in the scholarly discussion on digital disconnection and privacy within media studies with the purpose of contributing a critique of a discourse predominantly concerned with framing disconnection as a form of voluntary and empowered form of media refusal. © The Author(s) 2020.},
	author_keywords = {being plural singular; community; disconnection; machine learning; Nancy; politics},
	correspondence_address = {T. Bucher; University of Oslo, Norway; email: taina.bucher@media.uio.no},
	publisher = {SAGE Publications Ltd},
	issn = {01634437},
	language = {English},
	abbrev_source_title = {Media Cult. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 35; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Thieme20206,
	author = {Thieme, Anja and Belgrave, Danielle and Sano, Akane and Doherty, Gavin},
	title = {Machine Learning Applications: Reflections on Mental Health Assessment and Ethics},
	year = {2020},
	journal = {Interactions},
	volume = {27},
	number = {2},
	pages = {6 – 7},
	doi = {10.1145/3381342},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081634299&doi=10.1145%2f3381342&partnerID=40&md5=d63b96ebcf7c4c6e488431a53962cbfc},
	affiliations = {Microsoft Research Cambridge, United Kingdom; Rice University, United States; Trinity College Dublin, Ireland},
	keywords = {Cambridge; Invited talk; Machine learning applications; Mental health; Machine learning},
	publisher = {Association for Computing Machinery},
	issn = {10725520},
	language = {English},
	abbrev_source_title = {Interactions},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Bronze Open Access}
}

@ARTICLE{Huebner2020,
	author = {Huebner, Tatjana and Steffens, Michael and Linder, Roland and Fracowiak, Jochen and Langner, Daria and Garling, Marco and Falkenberg, Felix and Roethlein, Christoph and Gomm, Willy and Haenisch, Britta and Stingl, Julia},
	title = {Influence of metabolic profiles on the safety of drug therapy in routine care in Germany: Protocol of the cohort study EMPAR},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {4},
	doi = {10.1136/bmjopen-2019-032624},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084169215&doi=10.1136%2fbmjopen-2019-032624&partnerID=40&md5=2b8104a30afb5e75f724c99e4e9af12f},
	affiliations = {Research Division, Federal Institute for Drugs and Medical Devices, Bonn North Rhine-Westphalia, Germany; Techniker Krankenkasse, Hamburg, Germany; Population Health Sciences, German Centre for Neurodegenerative Diseases, Bonn, North Rhine-Westphalia, Germany; Centre for Translational Medicine, University of Bonn, Bonn, North Rhine-Westphalia, Germany; Institute for Clinical Pharmacology, RWTH Aachen University, Aachen, North Rhine-Westphalia, Germany},
	abstract = {Introduction Pre-emptive testing of pharmacogenetically relevant single-nucleotide polymorphisms can be an effective tool in the prevention of adverse drug reactions and therapy resistance. However, most of the tests are not used as standard in routine care in Germany because of lacking evidence for the clinical and economical benefit and their impact on the usage of healthcare services. We address this issue by investigating the influence of pharmacogenetic profiles on the use of healthcare services over an extended period of several years using routine care data from a statutory health insurance company. The goal is to provide clinical evidence whether pre-emptive pharmacogenetic testing of metabolic profiles in routine care in Germany is beneficial and cost-effective. Methods and analysis The EMPAR (Einfluss metabolischer Profile auf die Arzneimitteltherapiesicherheit in der Routineversorgung) study is a non-interventional cohort study conducted to analyse pharmacogenetic risk factors that are important for drug therapy by means of endpoints relevant for healthcare. The analysis is based on pharmacogenetic profiles and statutory health insurance data. We perform pharmacogenetic, pharmacoepidemiological and pharmacoeconomic analyses using health care utilisation scores and machine learning techniques. Therefore, we aim to include about 10 000 patients (≥18 years) insured by the health insurance provider Techniker Krankenkasse. The study focuses on patients with prescriptions of anticoagulants and prescriptions of cholesterol-lowering drugs. Also, a screening for special pharmacogenetic characteristics will be performed in patients with at least one Y57.9! diagnosis (Complication of medical and surgical care: drug or medicament, unspecified). Outcomes include the utilisation of health insurance services, the incidence of incapacity for work and costs for drugs and treatment. Ethics and dissemination The protocol was approved by the Ethics Committee of the Medical Faculty, University of Bonn (Lfd. Nr. 339/17). The results of this research project will be published in scientific open access journals and at conferences. Trial registration number German Clinical Trials Register, DRKS00013909. © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {health care research; health economics; pharmacoepidemiology; pharmacogenetics; precision medicine},
	keywords = {Adult; Anticoagulants; Cohort Studies; Drug-Related Side Effects and Adverse Reactions; Germany; Health Services Needs and Demand; Humans; Hypolipidemic Agents; Insurance, Health; Machine Learning; Metabolome; Pharmacoepidemiology; Polymorphism, Single Nucleotide; anticoagulant agent; hypocholesterolemic agent; anticoagulant agent; antilipemic agent; Article; clinical outcome; cohort analysis; controlled study; cost effectiveness analysis; drug cost; drug metabolism; drug safety; drug therapy; Germany; health care utilization; health insurance; health service; human; machine learning; major clinical study; medical care; pharmacoeconomics; pharmacogenetic testing; prescription; risk factor; surgery; work disability; adult; adverse drug reaction; economics; genetics; metabolism; metabolome; pharmacoepidemiology; single nucleotide polymorphism},
	correspondence_address = {J. Stingl; Institute for Clinical Pharmacology, RWTH Aachen University, Aachen, North Rhine-Westphalia, Germany; email: jstingl@ukaachen.de},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {32345696},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Chen2020,
	author = {Chen, Y. and Tao, J. and Wang, J. and Chen, X. and Xie, J. and Xiong, J. and Yang, K.},
	title = {Retraction: The novel sensor network structure for classification processing based on the machine learning method of the ACGAN(Sensors 2019, 19, 3145)},
	year = {2020},
	journal = {Sensors (Switzerland)},
	volume = {20},
	number = {2},
	doi = {10.3390/s20020476},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078274224&doi=10.3390%2fs20020476&partnerID=40&md5=e871255a031ab3183d3f65f3b699b0d2},
	affiliations = {MDPI, St. Alban-Anlage 66, Basel, 4052, Switzerland},
	abstract = {It has been brought to our attention that the majority of the text, figures, structures, and references in the title paper [1] is copied from a previously published paper written in Chinese [2]. The paper [1] will therefore be marked as retracted. MDPI is a member of the Committee on Publication Ethics and takes seriously its responsibility to publish only high-quality research. We regret that this was not discovered during the review process and offer our apologies to the readers of Sensors. © 2020 by the author. Licensee MDPI, Basel, Switzerland.},
	publisher = {MDPI AG},
	issn = {14248220},
	language = {English},
	abbrev_source_title = {Sensors},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ienca202077,
	author = {Ienca, Marcello and Ignatiadis, Karolina},
	title = {Artificial Intelligence in Clinical Neuroscience: Methodological and Ethical Challenges},
	year = {2020},
	journal = {AJOB Neuroscience},
	volume = {11},
	number = {2},
	pages = {77 – 87},
	doi = {10.1080/21507740.2020.1740352},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082732869&doi=10.1080%2f21507740.2020.1740352&partnerID=40&md5=25d7d186b7854009d44a9658c3d697ad},
	affiliations = {Swiss Federal Institute of Technology, ETH Zurich, Department of Health Sciences and Technology, Switzerland},
	abstract = {Clinical neuroscience is increasingly relying on the collection of large volumes of differently structured data and the use of intelligent algorithms for data analytics. In parallel, the ubiquitous collection of unconventional data sources (e.g. mobile health, digital phenotyping, consumer neurotechnology) is increasing the variety of data points. Big data analytics and approaches to Artificial Intelligence (AI) such as advanced machine learning are showing great potential to make sense of these larger and heterogeneous data flows. AI provides great opportunities for making new discoveries about the brain, improving current preventative and diagnostic models in both neurology and psychiatry and developing more effective assistive neurotechnologies. Concurrently, it raises many new methodological and ethical challenges. Given their transformative nature, it is still largely unclear how AI-driven approaches to the study of the human brain will meet adequate standards of scientific validity and affect normative instruments in neuroethics and research ethics. This manuscript provides an overview of current AI-driven approaches to clinical neuroscience and an assessment of the associated key methodological and ethical challenges. In particular, it will discuss what ethical principles are primarily affected by AI approaches to human neuroscience, and what normative safeguards should be enforced in this domain. © 2020, © 2020 Taylor & Francis Group, LLC.},
	author_keywords = {Accountability; artificial intelligence; big data; discrimination; neuroethics; neuroprivacy; neuroscience},
	keywords = {Artificial Intelligence; Big Data; Bioethics; Humans; Neurosciences; artificial intelligence; bioethics; ethics; human; neuroscience; procedures},
	correspondence_address = {M. Ienca; Swiss Federal Institute of Technology, ETH Zurich, Department of Health Sciences and Technology, Zurich, Switzerland; email: marcello.ienca@hest.ethz.ch},
	publisher = {Taylor and Francis Inc.},
	issn = {21507740},
	pmid = {32228387},
	language = {English},
	abbrev_source_title = {AJOB Neurosci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Campbell2020227,
	author = {Campbell, Colin and Sands, Sean and Ferraro, Carla and Tsao, Hsiu-Yuan (Jody) and Mavrommatis, Alexis},
	title = {From data to action: How marketers can leverage AI},
	year = {2020},
	journal = {Business Horizons},
	volume = {63},
	number = {2},
	pages = {227 – 243},
	doi = {10.1016/j.bushor.2019.12.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077376160&doi=10.1016%2fj.bushor.2019.12.002&partnerID=40&md5=a5f07cbebaa90df66fe89e7701b43fd9},
	affiliations = {School of Business, University of San Diego, 5998 Alcala Park, San Diego, 92101, CA, United States; Swinburne University of Technology, Hawthorn, VIC 3122, Australia; National Chung Hsing University, Taiwan; EADA Business School, Barcelona, Spain},
	abstract = {Artificial intelligence (AI) is at the forefront of a revolution in business and society. AI affords companies a host of ways to better understand, predict, and engage customers. Within marketing, AI's adoption is increasing year-on-year and in varied contexts, from providing service assistance during customer interactions to assisting in the identification of optimal promotions. But just as questions about AI remain with regard to job automation, ethics, and corporate responsibility, the marketing domain faces its own concerns about AI. With this article, we seek to consolidate the growing body of knowledge about AI in marketing. We explain how AI can enhance the marketing function across nine stages of the marketing planning process. We also provide examples of current applications of AI in marketing. © 2019},
	author_keywords = {Artificial intelligence; Consumer engagement; Customer experience; Customer journey; Machine learning; Marketing function; Marketing mix},
	correspondence_address = {C. Campbell; School of Business, University of San Diego, San Diego, 5998 Alcala Park, 92101, United States; email: colincampbell@sandiego.edu},
	publisher = {Elsevier Ltd},
	issn = {00076813},
	coden = {BHORA},
	language = {English},
	abbrev_source_title = {Bus. Horiz.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 105}
}

@ARTICLE{Lillywhite2020,
	author = {Lillywhite, Aspen and Wolbring, Gregor},
	title = {Coverage of artificial intelligence and machine learning within academic literature, canadian newspapers, and twitter tweets: The case of disabled people},
	year = {2020},
	journal = {Societies},
	volume = {10},
	number = {1},
	doi = {10.3390/soc10010023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117385166&doi=10.3390%2fsoc10010023&partnerID=40&md5=2019fc96b3715c9f52cd77c94842d542},
	affiliations = {Community Rehabilitation and Disability Studies, Department of Community Health Sciences, Cumming School of Medicine, University of Calgary, Calgary, T2N4N1, AB, Canada},
	abstract = {Artificial intelligence (AI) and machine learning (ML) advancements increasingly impact society and AI/ML ethics and governance discourses have emerged. Various countries have established AI/ML strategies. “AI for good” and “AI for social good” are just two discourses that focus on using AI/ML in a positive way. Disabled people are impacted by AI/ML in many ways such as potential therapeutic and non-therapeutic users of AI/ML advanced products and processes and by the changing societal parameters enabled by AI/ML advancements. They are impacted by AI/ML ethics and governance discussions and discussions around the use of AI/ML for good and social good. Using identity, role, and stakeholder theories as our lenses, the aim of our scoping review is to identify and analyze to what extent, and how, AI/ML focused academic literature, Canadian newspapers, and Twitter tweets engage with disabled people. Performing manifest coding of the presence of the terms “AI”, or “artificial intelligence” or “machine learning” in conjunction with the term “patient”, or “disabled people” or “people with disabilities” we found that the term “patient” was used 20 times more than the terms “disabled people” and “people with disabilities” together to identify disabled people within the AI/ML literature covered. As to the downloaded 1540 academic abstracts, 234 full-text Canadian English language newspaper articles and 2879 tweets containing at least one of 58 terms used to depict disabled people (excluding the term patient) and the three AI terms, we found that health was one major focus, that the social good/for good discourse was not mentioned in relation to disabled people, that the tone of AI/ML coverage was mostly techno-optimistic and that disabled people were mostly engaged with in their role of being therapeutic or non-therapeutic users of AI/ML influenced products. Problems with AI/ML were mentioned in relation to the user having a bodily problem, the usability of AI/ML influenced technologies, and problems disabled people face accessing such technologies. Problems caused for disabled people by AI/ML advancements, such as changing occupational landscapes, were not mentioned. Disabled people were not covered as knowledge producers or influencers of AI/ML discourses including AI/ML governance and ethics discourses. Our findings suggest that AI/ML coverage must change, if disabled people are to become meaningful contributors to, and beneficiaries of, discussions around AI/ML. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Artificial intelligence; Disabled people; For good; Machine learning; People with disabilities; Scoping review; Social good},
	correspondence_address = {G. Wolbring; Community Rehabilitation and Disability Studies, Department of Community Health Sciences, Cumming School of Medicine, University of Calgary, Calgary, T2N4N1, Canada; email: gwolbrin@ucalgary.ca},
	publisher = {MDPI},
	issn = {20754698},
	language = {English},
	abbrev_source_title = {Soc.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Currie2020748,
	author = {Currie, Geoff and Hawk, K Elizabeth and Rohren, Eric M.},
	title = {Ethical principles for the application of artificial intelligence (AI) in nuclear medicine},
	year = {2020},
	journal = {European Journal of Nuclear Medicine and Molecular Imaging},
	volume = {47},
	number = {4},
	pages = {748 – 752},
	doi = {10.1007/s00259-020-04678-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078622375&doi=10.1007%2fs00259-020-04678-1&partnerID=40&md5=a481d1a2309c7eb9af4217ee4d630910},
	affiliations = {School of Dentistry and Health Sciences, Charles Sturt University, Wagga Wagga, Australia; Stanford University, California, United States; Baylor College of Medicine, Houston, United States},
	author_keywords = {Artificial intelligence; Deep learning; Intelligent imaging; Machine learning; Medical ethics; Nuclear Medicine; Synthetic intelligence},
	keywords = {Artificial Intelligence; Deep Learning; Humans; Nuclear Medicine; Radionuclide Imaging; artificial intelligence; beneficence; confidentiality; convolutional neural network; decision making; Editorial; justice; machine learning; medical ethics; molecular imaging; nuclear medicine; privacy; reliability; safety; statistical bias; artificial intelligence; human; scintiscanning},
	correspondence_address = {G. Currie; School of Dentistry and Health Sciences, Charles Sturt University, Wagga Wagga, Australia; email: gcurrie@csu.edu.au},
	publisher = {Springer},
	issn = {16197070},
	coden = {EJNMA},
	pmid = {31927637},
	language = {English},
	abbrev_source_title = {Eur. J. Nucl. Med. Mol. Imaging},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Bronze Open Access}
}

@BOOK{Mainali202077,
	author = {Mainali, Nischal and Meier, Liam and Ash, Elliott and Chen, Daniel L.},
	title = {Automated classification of modes of moral reasoning in judicial decisions},
	year = {2020},
	journal = {Computational Legal Studies: The Promise and Challenge of Data-Driven Research},
	pages = {77 – 94},
	doi = {10.4337/9781788977456.00009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139296248&doi=10.4337%2f9781788977456.00009&partnerID=40&md5=a354baf202031eab43ca276f40c802d5},
	affiliations = {NYU Abu Dhabi, United Arab Emirates; ETH Zurich, Switzerland; Toulouse School of Economics, France},
	abstract = {What modes of moral reasoning do judges employ? We attempt to automatically classify moral reasoning with a linear Support Vector Machine (SVM) trained on applied ethics articles. The model classifies paragraphs of text in holdout data with over 90 percent accuracy. We then apply the classifier to a corpus of circuit court opinions and find a significant increase in consequentialist reasoning over time. We report rankings of relative use of reasoning modes by legal topic, by judge, and by judge law school. Though statistical techniques inherently face significant limitations in this task, we show some of the promise of machine learning for understanding human moral reasoning. © The Editor and Contributors Severally 2020. All rights reserved.},
	publisher = {Edward Elgar Publishing Ltd.},
	isbn = {978-178897745-6; 978-178897744-9},
	language = {English},
	abbrev_source_title = {Computational Legal Studies: The Promise and Chall. of Data-Driven Research},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@BOOK{Lee20201,
	author = {Lee, Raymond S. T.},
	title = {Artificial Intelligence in Daily Life},
	year = {2020},
	journal = {Artificial Intelligence in Daily Life},
	pages = {1 – 394},
	doi = {10.1007/978-981-15-7695-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85113414207&doi=10.1007%2f978-981-15-7695-9&partnerID=40&md5=50a406d67c213063a6042fefc6441efb},
	affiliations = {Division of Science and Technology, Beijing Normal University-Hong Kong Baptist University United, International College, Guangdong, Zhuhai, China},
	abstract = {Given the exponential growth of Artificial Intelligence (AI) over the past few decades, AI and its related applications have become part of daily life in ways that we could never have dreamt of only a century ago. Our routines have been changed beyond measure by robotics and AI, which are now used in a vast array of services. Though AI is still in its infancy, we have already benefited immensely. This book introduces readers to basic Artificial Intelligence concepts, and helps them understand the relationship between AI and daily life. In the interest of clarity, the content is divided into four major parts. Part I (AI Concepts) presents fundamental concepts of and information on AI; while Part II (AI Technology) introduces readers to the five core AI Technologies that provide the building blocks for various AI applications, namely: Machine Learning (ML), Data Mining (DM), Computer Vision (CV), Natural Languages Processing (NLP), and Ontology-based Search Engine (OSE). In turn, Part III (AI Applications) reviews major contemporary applications that are impacting our ways of life, working styles and environment, ranging from intelligent agents and robotics to smart campus and smart city projects. Lastly, Part IV (Beyond AI) addresses related topics that are vital to the future development of AI. It also discusses a number of critical issues, such as AI ethics and privacy, the development of a conscious mind, and autonomous robotics in our daily lives. © The Editor(s) (if applicable) and The Author(s) 2021.},
	author_keywords = {Artificial Intelligence; Fuzzy Logics; Intelligence Campus; Intelligence City; Machine Learning; Neural Networks},
	publisher = {Springer Singapore},
	isbn = {978-981157695-9; 978-981157694-2},
	language = {English},
	abbrev_source_title = {Artificial Intelligence in Daily Life},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Garrett2020272,
	author = {Garrett, Natalie and Beard, Nathan and Fiesler, Casey},
	title = {More than "if time allows": The role of ethics in AI education},
	year = {2020},
	journal = {AIES 2020 - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {272 – 278},
	doi = {10.1145/3375627.3375868},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082175164&doi=10.1145%2f3375627.3375868&partnerID=40&md5=78987e08777b5a856a9dace0ef05d25f},
	affiliations = {Information Science, University of Colorado, Boulder, CO, United States; Information Studies, University of Maryland, College Park, MD, United States},
	abstract = {Even as public pressure mounts for technology companies to consider societal impacts of products, industries and governments in the AI race are demanding technical talent. To meet this demand, universities clamor to add technical artificial intelligence (AI) and machine learning (ML) courses into computing curriculum-but how are societal and ethical considerations part of this landscape? We explore two pathways for ethics content in AI education: (1) standalone AI ethics courses, and (2) integrating ethics into technical AI courses. For both pathways, we ask: What is being taught? As we train computer scientists who will build and deploy AI tools, how are we training them to consider the consequences of their work? In this exploratory work, we qualitatively analyzed 31 standalone AI ethics classes from 22 U.S. universities and 20 AI/ML technical courses from 12 U.S. universities to understand which ethics-related topics instructors include in courses. We identify and categorize topics in AI ethics education, share notable practices, and note omissions. Our analysis will help AI educators identify what topics should be taught and create scaffolding for developing future AI ethics education. © 2020 Copyright held by the owner/author(s).},
	author_keywords = {Artificial intelligence; Curriculum; Ethics education},
	keywords = {Artificial intelligence; Ethical aspects; Scaffolds; Computer scientists; Computing curricula; Ethical considerations; Ethics education; Societal impacts; Technical course; Technical talent; Technology companies; Curricula},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145037110-0},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43; Conference name: 3rd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2020, co-located with AAAI 2020; Conference date: 7 February 2020 through 8 February 2020; Conference code: 158220}
}

@ARTICLE{Grzybowski2020451,
	author = {Grzybowski, Andrzej and Brona, Piotr and Lim, Gilbert and Ruamviboonsuk, Paisan and Tan, Gavin S. W. and Abramoff, Michael and Ting, Daniel S. W.},
	title = {Artificial intelligence for diabetic retinopathy screening: a review},
	year = {2020},
	journal = {Eye (Basingstoke)},
	volume = {34},
	number = {3},
	pages = {451 – 460},
	doi = {10.1038/s41433-019-0566-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073776664&doi=10.1038%2fs41433-019-0566-0&partnerID=40&md5=69dcc77256252b14c920aa69892ee69b},
	affiliations = {Department of Ophthalmology, University of Warmia and Mazury, Olsztyn, Poland; Institute for Research in Ophthalmology, Foundation for Ophthalmology Development, Poznan, Poland; School of Computing, National University of Singapore, Singapore, Singapore; Singapore National Eye Center, Singapore Eye Research Institute, Singapore, Singapore; Department of Ophthalmology, Rajavithi Hospital, Bangkok, Thailand; Duke-NUS Medical School, National University of Singapore, Singapore, Singapore; Department of Ophthalmology and Visual Sciences, University of Iowa, Iowa City, IA, United States},
	abstract = {Diabetes is a global eye health issue. Given the rising in diabetes prevalence and ageing population, this poses significant challenge to perform diabetic retinopathy (DR) screening for these patients. Artificial intelligence (AI) using machine learning and deep learning have been adopted by various groups to develop automated DR detection algorithms. This article aims to describe the state-of-art AI DR screening technologies that have been described in the literature, some of which are already commercially available. All these technologies were designed using different training datasets and technical methodologies. Although many groups have published robust diagnostic performance of the AI algorithms for DR screening, future research is required to address several challenges, for examples medicolegal implications, ethics, and clinical deployment model in order to expedite the translation of these novel technologies into the healthcare setting. © 2019, The Author(s), under exclusive licence to The Royal College of Ophthalmologists.},
	keywords = {Algorithms; Artificial Intelligence; Diabetes Mellitus; Diabetic Retinopathy; Humans; Machine Learning; Mass Screening; artificial intelligence; artificial neural network; deep learning; detection algorithm; diabetic retinopathy; ethics; human; machine learning; medicolegal aspect; prevalence; Review; screening; support vector machine; algorithm; artificial intelligence; diabetes mellitus; diabetic retinopathy; mass screening},
	correspondence_address = {D.S.W. Ting; Department of Ophthalmology, Rajavithi Hospital, Bangkok, Thailand; email: daniel.ting45@gmail.com},
	publisher = {Springer Nature},
	issn = {0950222X},
	coden = {EYEEE},
	pmid = {31488886},
	language = {English},
	abbrev_source_title = {Eye},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 127; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Challa2020820,
	author = {Challa, Anup P. and Lavieri, Robert R. and Lippmann, Ethan S. and Goldstein, Jeffery A. and Bastarache, Lisa and Pulley, Jill M. and Aronoff, David M.},
	title = {EHRs could clarify drug safety in pregnant people},
	year = {2020},
	journal = {Nature Medicine},
	volume = {26},
	number = {6},
	pages = {820 – 821},
	doi = {10.1038/s41591-020-0925-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085286744&doi=10.1038%2fs41591-020-0925-1&partnerID=40&md5=d6dc0e15e60c06e44bad4a20d9056e7a},
	affiliations = {Vanderbilt Institute for Clinical and Translational Research, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Chemical and Biomolecular Engineering, Vanderbilt University, Nashville, TN, United States; Department of Pathology, Feinberg School of Medicine, Northwestern University, Chicago, IL, United States; Department of Biomedical Informatics, Vanderbilt University Medical Center, Nashville, TN, United States; Division of Infectious Diseases, Department of Medicine, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Obstetrics and Gynecology, Vanderbilt University Medical Center, Nashville, TN, United States; Department of Pathology, Microbiology and Immunology, Vanderbilt University Medical Center, Nashville, TN, United States},
	keywords = {Big Data; Clinical Trials as Topic; Computer Simulation; Drug Approval; Drug Therapy; Drug-Related Side Effects and Adverse Reactions; Electronic Health Records; Eligibility Determination; Female; Genomics; Humans; Pregnancy; United States; thalidomide; clinical trial (topic); drug contraindication; drug exposure; drug safety; electronic health record; ex vivo study; female; Food and Drug Administration; genome analysis; genomics; high risk pregnancy; human; machine learning; maternal morbidity; medical ethics; newborn morbidity; Note; outcome assessment; patient information; pregnancy; pregnant woman; prescription; priority journal; randomized controlled trial (topic); single nucleotide polymorphism; teratogenicity; adverse drug reaction; clinical trial (topic); computer simulation; drug approval; drug therapy; organization and management; United States},
	correspondence_address = {A.P. Challa; Vanderbilt Institute for Clinical and Translational Research, Vanderbilt University Medical Center, Nashville, United States; email: anup.p.challa.1@vumc.org},
	publisher = {Nature Research},
	issn = {10788956},
	coden = {NAMEF},
	pmid = {32457445},
	language = {English},
	abbrev_source_title = {Nat. Med.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Floridi202077,
	author = {Floridi, Luciano and Strait, Andrew},
	title = {Ethical Foresight Analysis: What it is and Why it is Needed?},
	year = {2020},
	journal = {Minds and Machines},
	volume = {30},
	number = {1},
	pages = {77 – 97},
	doi = {10.1007/s11023-020-09521-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081739233&doi=10.1007%2fs11023-020-09521-y&partnerID=40&md5=5bed884447ee03417c3087e2e12997b5},
	affiliations = {Oxford Internet Institute, University of Oxford, 1 St Giles, Oxford, OX1 3JS, United Kingdom; The Alan Turing Institute, 96 Euston Road, London, NW1 2DB, United Kingdom},
	abstract = {An increasing number of technology firms are implementing processes to identify and evaluate the ethical risks of their systems and products. A key part of these review processes is to foresee potential impacts of these technologies on different groups of users. In this article, we use the expression Ethical Foresight Analysis (EFA) to refer to a variety of analytical strategies for anticipating or predicting the ethical issues that new technological artefacts, services, and applications may raise. This article examines several existing EFA methodologies currently in use. It identifies the purposes of ethical foresight, the kinds of methods that current methodologies employ, and the strengths and weaknesses of each of these current approaches. The conclusion is that a new kind of foresight analysis on the ethics of emerging technologies is both feasible and urgently needed. © 2020, The Author(s).},
	author_keywords = {Artificial intelligence; Data science; Ethics; Foresight analysis; Innovation; Machine learning},
	keywords = {Artificial intelligence; Data Science; Learning systems; Analytical strategy; Emerging technologies; Ethical issues; Foresight analysis; Key parts; Potential impacts; Review process; Ethical aspects},
	correspondence_address = {L. Floridi; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles, OX1 3JS, United Kingdom; email: luciano.floridi@oii.ox.ac.uk},
	publisher = {Springer},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Torroja2020,
	author = {Torroja, Carlos and Sanchez-Cabo, Fatima},
	title = {Corrigendum: Digitaldlsorter: Deep-Learning on scRNA-Seq to Deconvolute Gene Expression Data (Frontiers in Genetics, (2019), 10, 10.3389/fgene.2019.00978)},
	year = {2020},
	journal = {Frontiers in Genetics},
	volume = {10},
	doi = {10.3389/fgene.2019.01373},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079620979&doi=10.3389%2ffgene.2019.01373&partnerID=40&md5=e7f118221a838f5d661dbc46b236c8b4},
	affiliations = {Bioinformatics Unit, Fundación Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain},
	abstract = {In the original article, the funder “Ministerio de Ciencia, Innovación, y Universidades (MCIU), RTI2018- 102084-B-I00” to “Fatima Sanchez-Cabo” wasmissing. The corrected Funding Statement follows below: “The results shown here are in part based upon data generated by the TCGA Research Network: https://www.cancer.gov/tcga. This work was supported by the European Union’s Horizon 2020 research and innovation program under grant agreement number 633592 (Project APERIM: Advanced bioinformatics platform for personalized cancer immunotherapy) and by the Ministerio de Ciencia, Innovación, y Universidades (MCIU) [grant no. RTI2018-102084-B-I00]. The CNIC is supported by MCIU and the Pro-CNIC Foundation and is a Severo Ochoa Center of Excellence [MCIU award SEV-2015-0505].” Additionally, the Ethics Statement, Author Contributions and Acknowledgements statement were not included in the original Article. The Statements follows below: Ethics Statement: “This study was carried with human open access data from with their corresponding ethics committee approval.” Author Contributions: “FS-C conceived the study, CT implemented all analysis and produced the figures. CT and FS-C wrote the manuscript.” Acknowledgements: “We would like to thank Francesca Finotello and Zlatko Trajanoski for fruitful discussions and to the CNIC Bioinformatics Unit members for continuous support and work.” The authors apologize for these errors and state that this does not change the scientific conclusions of the article in any way. The original article has been updated. © Copyright © 2020 Tkacz, Pini, Turner, Bestion, Simmonds, Howell, Greenland, Cheema, Emms, Uauy and Poole.},
	author_keywords = {cancer; deconvolution algorithm; immunology; machine learning; single-cell},
	keywords = {erratum},
	correspondence_address = {C. Torroja; Bioinformatics Unit, Fundación Centro Nacional de Investigaciones Cardiovasculares (CNIC), Madrid, Spain; email: ctorroja@cnic.es},
	publisher = {Frontiers Media S.A.},
	issn = {16648021},
	language = {English},
	abbrev_source_title = {Front. Genet.},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Herzog202017457,
	author = {Herzog, Christian and Hoffmann, Né},
	title = {Automating Morals - On the Morality of Automation Technology, Ironies of Automation and Responsible Research and Innovation},
	year = {2020},
	journal = {IFAC-PapersOnLine},
	volume = {53},
	number = {2},
	pages = {17457 – 17462},
	doi = {10.1016/j.ifacol.2020.12.2120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119718652&doi=10.1016%2fj.ifacol.2020.12.2120&partnerID=40&md5=bc9332c00985fced9ec210f7c1371555},
	affiliations = {Institute for Electrical Engineering in Medicine, Ethical Innovation Lab, University of Lübeck, Germany},
	abstract = {The prevalence and impact of morals in technology design is increasingly better understood. Likewise, advances in machine learning, systems theory and control continue to push the boundary with respect to the applications in which automation may be considered. The present paper is intended to act as a precursor to a lively debate about professional ethics within the control community regarding automation in morally charged situations and beyond. First, the paper provides a primer on the actualities of applications in which morals already play a significant role. It further claims that-in contrast to typical expositions-within the scope of systems in which automation is employed, there is a continuum between addressing morally charged contexts to actually performing a kind of automated moral deliberation, though technically and philosophically there may be a vast difference. Second, from this perspective, the paper presents a first indication about potential new and persistent "ironies" within the context of automating morals. Third, the paper draws conclusions, essentially calling for the community to open up and engaging in participatory research and development settings as a matter of professional ethics. © 2020 Elsevier B.V.. All rights reserved.},
	author_keywords = {Ethics; Sustainability; Value systems},
	keywords = {Ethical technology; Automation technology; Control community; Machine learning systems; Participatory research; Professional ethics; Research and development; Technology designs; Value systems; Automation},
	correspondence_address = {C. Herzog; Institute for Electrical Engineering in Medicine, Ethical Innovation Lab, University of Lübeck, Germany; email: christian.herzog@uni-luebeck.de},
	editor = {Findeisen R. and Hirche S. and Janschek K. and Martin M.},
	publisher = {Elsevier B.V.},
	issn = {24058963},
	language = {English},
	abbrev_source_title = {IFAC-PapersOnLine},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 21st IFAC World Congress 2020; Conference date: 12 July 2020 through 17 July 2020; Conference code: 145388; All Open Access, Bronze Open Access}
}

@ARTICLE{Youngmin20201,
	author = {Youngmin, Kim},
	title = {The poetics of artificial intelligence and posthumanism},
	year = {2020},
	journal = {Forum for World Literature Studies},
	volume = {12},
	number = {1},
	pages = {1 – 19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092902696&partnerID=40&md5=356fa99576962b1f14676d5cf3d7b287},
	affiliations = {Hangzhou Normal University, Hangzhou, China; Dongguk University, Seoul, South Korea},
	abstract = {Martin Heidegger posits a significant future-directed question concerning the human existence in relation to the essence of technology, a question which builds a way for anticipating the poetics of Artificial Intelligence and posthumanism. What is missing in the Heideggerian concept of modern technology is the part of the human activity, which represents the physical human embedded-embodied mind who thinks, reads, and writes, and acts with gestures and bodily movement. Human brain is the center of these activities. Maryanne Wolf in her Proust and the Squid (2007) posits reading as a human invention, and elaborates the human brain’s plastic ability in relation to the act of reading. Wolf’s models of Proust and the Squid in terms of the intellectual and the biological is closely related to the linguistic and the neurocognitive aspects of the Artificial Intelligence. The complementary examples of human brain’s reading processes have analogically elaborated how various neuro-cognitive processes will work algorithmically in the data-processing of the AI. Both cases of reading by Maryanne Wolf are referring to human intelligence’s information processing in terms of the human brain’s automatic learning which reminds us of machine learning and deep learning algorithms. The development of artificial intelligence in tandem with that of human intelligence may be the last great challenge of humanism and the first great endeavor of posthumanism. Cognitive neuroscience and artificial intelligence have undergone revolutionary changes in the past decades, and they now foreground the embodied and environmentally embedded nature of intelligent action. What is at stake is the ethical articulation of intelligence (both human and artificial) in this “second machine age.” © 2020 Shanghai Normal University. All rights reserved.},
	author_keywords = {Artificial Intelligence; Ethics,; Human brain; Martin Heidegger; Posthumanism},
	correspondence_address = {K. Youngmin; Hangzhou Normal University, Hangzhou, China; email: youngm@hznu.edu.cn},
	publisher = {Shanghai Normal University},
	issn = {19498519},
	language = {English},
	abbrev_source_title = {Forum. World Lit. Stud.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ha2020,
	author = {Ha, Minha R. and Racette, Joshua and Nagasaki, Shinya},
	title = {WIP: Ethical responsibility formation of students in a nuclear engineering course through inquiry learning},
	year = {2020},
	journal = {ASEE Annual Conference and Exposition, Conference Proceedings},
	volume = {2020-June},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095757036&partnerID=40&md5=bbad20016ea1304f1280abe80c8d8831},
	affiliations = {Department of Mechanical Engineering, Lassonde School of Engineering, York University, Canada; Department of Engineering Physics, Faculty of Engineering, McMaster University, Canada},
	abstract = {Engineering ethics - both in the nature of engineering practice and the impact of engineering work - intersects ethics of many dimensions including the philosophical, technical, business, professional, environmental, legal, and bioethics [1], [2]. The impact of engineering work, including energy systems, extends well beyond the immediate use of technology into the social institutions, distribution of resources, culture, health, and environment. The breadth of desired engineer competencies reveal the social, cultural, and political dimensions of an engineer's professional practice, despite the predominant perception of engineers as technical experts meeting business needs [3]-[5]. Even as the need increases for collaboration across disciplines, no longer can the technology experts be 'disconnected from the civil society' [6]. The critical theory perspective and systems paradigm challenge us to examine what it means to 'teach engineering ethics.' We acknowledge and accept that it cannot be expected that individual engineers will carry the entire responsibility for ethical and equitable decision making in engineering. The organizational culture and structure, the contractual arrangements within the industry, engineering teams, and policy instruments can either enhance or constrain responsibility in engineering decisions. In working towards presenting a solution to a problem, or the implementation of a new technology, engineers will need to acknowledge competing interests and act as a mediator to negotiate for a practical solution. In some aspects, engineers will have to reassert themselves as the stewards of public safety, and as co-decision makers, instead of being treated as commoditized instruments [7] of the business machinery. Simultaneously, we pay attention to the engineers' privileged position - e.g. as experts and high-income earners, with greater proximity to large-scale project decisions - and its role in the unequal influence relations engineers have with other knowledge disciplines and/or community stakeholders. Engineers can be important mediators or gatekeepers for the input of diverse stakeholders on the technology development (e.g. machine learning bias). Therefore, our working vision for engineering ethics education is two-fold: (1) to empower students as moral agents who effectively negotiate for social and ethical responsibility in the technology industry; and (2) to motivate and equip students to actively include and respond to the perspectives, concerns, experiences of the stakeholders whom, otherwise, are made invisible in the decisions regarding engineering projects. © American Society for Engineering Education 2020.},
	keywords = {Business machines; Decision making; Decision theory; Economic and social effects; Engineers; Environmental regulations; Nuclear engineering; Philosophical aspects; Students; Contractual arrangements; Engineering decisions; Engineering practices; Ethical responsibility; Nuclear engineering course; Organizational cultures; Professional practices; Technology development; Engineering education},
	publisher = {American Society for Engineering Education},
	issn = {21535965},
	language = {English},
	abbrev_source_title = {ASEE Annu. Conf. Expos. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 ASEE Virtual Annual Conference, ASEE 2020; Conference date: 22 June 2020 through 26 June 2020; Conference code: 164392}
}

@CONFERENCE{Milonas2020,
	author = {Milonas, Elizabeth},
	title = {How do WeRaise ethically minded computer students?},
	year = {2020},
	journal = {ASEE Annual Conference and Exposition, Conference Proceedings},
	volume = {2020-June},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095731241&partnerID=40&md5=42599ff4c176dfb24ae88f961230959a},
	affiliations = {NYC College of Technology, City University of New York, United States},
	abstract = {Intelligent technology is increasingly being woven into the fabric of everyday life. It is becoming more and more a seemingly necessary and somewhat trusted component of society for both personal and non-personal day-to-day interactions. Developing such intelligent systems requires technical expertise, such as an in-depth knowledge of natural language processing or machine learning. However, in addition to technical expertise, a deep awareness and understanding of ethics and societal impact are also essential. Mastering knowledge of ethics and societal impact falls on the shoulders of computer professionals and programmers, whose role is to design and implement the decision-making component of intelligent systems. The development of intelligent systems with embedded ethical and social awareness is of paramount importance as a lack of such awareness has biased or unethical consequences. Such consequences were recently demonstrated when an algorithmic decision-making system at Amazon.com disqualified female job candidates. Preparing computer students to meet the demand of intelligent technology implementation, requires incorporating the topics of ethics and societal impact into computer curriculum. These topics should be introduced and reinforced throughout the computer curriculum, beginning at the introductory courses, and continuing to the advanced courses. This method ensures that computer students acquire the necessary technical and ethical skills needed. The combination of these skills ensures effective design, implementation and deployment of intelligent systems that are both technologically advanced and ethically mindful. © American Society for Engineering Education 2020.},
	keywords = {Curricula; Decision making; Economic and social effects; Embedded systems; Intelligent systems; Philosophical aspects; Students; Weaving; Computer professionals; Decision-making systems; Design and implements; Intelligent technology; Introductory course; NAtural language processing; Technical expertise; Trusted components; Natural language processing systems},
	publisher = {American Society for Engineering Education},
	issn = {21535965},
	language = {English},
	abbrev_source_title = {ASEE Annu. Conf. Expos. Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 ASEE Virtual Annual Conference, ASEE 2020; Conference date: 22 June 2020 through 26 June 2020; Conference code: 164392}
}

@ARTICLE{Li2020,
	author = {Li, Sijia and Wang, Yilin and Xue, Jia and Zhao, Nan and Zhu, Tingshao},
	title = {The impact of covid-19 epidemic declaration on psychological consequences: A study on active weibo users},
	year = {2020},
	journal = {International Journal of Environmental Research and Public Health},
	volume = {17},
	number = {6},
	doi = {10.3390/ijerph17062032},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082137078&doi=10.3390%2fijerph17062032&partnerID=40&md5=4a1f75d6c389c549a7258eb86a840593},
	affiliations = {Institute of Psychology, Chinese Academy of Sciences, Beijing, 100101, China; Department of Psychology, University of Chinese Academy of Sciences, Beijing, 100049, China; Department of Psychology, Nankai University, Tianjin, 300071, China; Factor Inwentash Faculty of Social Work, University of Toronto, Toronto, M5S 1A1, Canada},
	abstract = {COVID-19 (Corona Virus Disease 2019) has significantly resulted in a large number of psychological consequences. The aim of this study is to explore the impacts of COVID-19 on people’s mental health, to assist policy makers to develop actionable policies, and help clinical practitioners (e.g., social workers, psychiatrists, and psychologists) provide timely services to affected populations. We sample and analyze the Weibo posts from 17,865 active Weibo users using the approach of Online Ecological Recognition (OER) based on several machine-learning predictive models. We calculated word frequency, scores of emotional indicators (e.g., anxiety, depression, indignation, and Oxford happiness) and cognitive indicators (e.g., social risk judgment and life satisfaction) from the collected data. The sentiment analysis and the paired sample t-test were performed to examine the differences in the same group before and after the declaration of COVID-19 on 20 January, 2020. The results showed that negative emotions (e.g., anxiety, depression and indignation) and sensitivity to social risks increased, while the scores of positive emotions (e.g., Oxford happiness) and life satisfaction decreased. People were concerned more about their health and family, while less about leisure and friends. The results contribute to the knowledge gaps of short-term individual changes in psychological conditions after the outbreak. It may provide references for policy makers to plan and fight against COVID-19 effectively by improving stability of popular feelings and urgently prepare clinical practitioners to deliver corresponding therapy foundations for the risk groups and affected people. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Cognition; Emotion; Mental health; Public health emergencies; Word frequency analysis},
	keywords = {Adult; Anxiety; Anxiety Disorders; Betacoronavirus; China; Coronavirus Infections; Depression; Disease Outbreaks; Emotions; Epidemics; Female; Happiness; Humans; Internet; Male; Mental Health; Pandemics; Personal Satisfaction; Pneumonia, Viral; Resilience, Psychological; Risk Factors; Severe Acute Respiratory Syndrome; Coronavirus; cognition; frequency analysis; machine learning; mental disorder; mental health; public health; adolescent; adult; anxiety; Article; attitude to health; child; China; coronavirus disease 2019; Coronavirus infection; depression; emergency care; emotion; epidemic; female; happiness; health care policy; health impact assessment; high risk population; human; indignation; infection control; life satisfaction; machine learning; male; medical ethics; mental health; occupational hazard; population research; psychiatrist; psychologic assessment; psychologist; public health service; school child; social worker; anxiety disorder; Betacoronavirus; complication; Coronavirus infection; Internet; mental health; pandemic; psychological resilience; psychology; risk factor; satisfaction; severe acute respiratory syndrome; virus pneumonia},
	correspondence_address = {N. Zhao; Institute of Psychology, Chinese Academy of Sciences, Beijing, 100101, China; email: zhaonan@psych.ac.cn},
	publisher = {MDPI AG},
	issn = {16617827},
	pmid = {32204411},
	language = {English},
	abbrev_source_title = {Int. J. Environ. Res. Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1041; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Banner2020995,
	author = {Banner, Natalie F.},
	title = {The human side of health data},
	year = {2020},
	journal = {Nature Medicine},
	volume = {26},
	number = {7},
	pages = {995},
	doi = {10.1038/s41591-020-0838-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083567201&doi=10.1038%2fs41591-020-0838-z&partnerID=40&md5=72538604111cf9504aaed215b0c21090},
	affiliations = {Wellcome Trust, London, United Kingdom},
	keywords = {Confidentiality; Ethics, Medical; Humans; Medical Records; Patients; clinical research; decision making; health care delivery; health care policy; health care system; health service; human; machine learning; misinformation; Note; patient advocacy; patient coding; priority journal; trust; confidentiality; ethics; legislation and jurisprudence; medical ethics; medical record; patient; psychology},
	correspondence_address = {N.F. Banner; Wellcome Trust, London, United Kingdom; email: n.banner@wellcome.ac.uk},
	publisher = {Nature Research},
	issn = {10788956},
	coden = {NAMEF},
	pmid = {32661398},
	language = {English},
	abbrev_source_title = {Nat. Med.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access}
}

@ARTICLE{Davis2020,
	author = {Davis, Dylan S.},
	title = {Geographic disparity in machine intelligence approaches for archaeological remote sensing research},
	year = {2020},
	journal = {Remote Sensing},
	volume = {12},
	number = {6},
	doi = {10.3390/rs12060921},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082303316&doi=10.3390%2frs12060921&partnerID=40&md5=fd8113ff444dbfb1c7c8036c212740f1},
	affiliations = {Department of Anthropology, The Pennsylvania State University, University Park, 16802, PA, United States},
	abstract = {A vast majority of the archaeological record, globally, is understudied and increasingly threatened by climate change, economic and political instability, and violent conflict. Archaeological data are crucial for understanding the past, and as such, documentation of this information is imperative. The development of machine intelligence approaches (including machine learning, artificial intelligence, and other automated processes) has resulted in massive gains in archaeological knowledge, as such computational methods have expedited the rate of archaeological survey and discovery via remote sensing instruments. Nevertheless, the progression of automated computational approaches is limited by distinct geographic imbalances in where these techniques are developed and applied. Here, I investigate the degree of this disparity and some potential reasons for this imbalance. Analyses from Web of Science and Microsoft Academic searches reveal that there is a substantial difference between the Global North and South in the output of machine intelligence remote sensing archaeology literature. There are also regional imbalances. I argue that one solution is to increase collaborations between research institutions in addition to data sharing efforts. © 2020 by the authors.},
	author_keywords = {Archaeology; Automated analysis; Data sharing; Ethics; Machine intelligence; Remote sensing},
	keywords = {Artificial intelligence; Automation; Climate change; Computational methods; Data Sharing; Ethical aspects; History; Surveys; Archaeological surveys; Archaeology; Automated analysis; Computational approach; Machine intelligence; Political instability; Remote sensing instruments; Research institutions; Remote sensing},
	correspondence_address = {D.S. Davis; Department of Anthropology, The Pennsylvania State University, University Park, 16802, United States; email: dsd40@psu.edu},
	publisher = {MDPI AG},
	issn = {20724292},
	language = {English},
	abbrev_source_title = {Remote Sens.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access}
}

@ARTICLE{Barn202038,
	author = {Barn, Balbir S.},
	title = {Mapping the public debate on ethical concerns: algorithms in mainstream media},
	year = {2020},
	journal = {Journal of Information, Communication and Ethics in Society},
	volume = {18},
	number = {1},
	pages = {38 – 53},
	doi = {10.1108/JICES-04-2019-0039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072110941&doi=10.1108%2fJICES-04-2019-0039&partnerID=40&md5=b0b1d4a9138fa5e117c54d4f0acdacf7},
	affiliations = {Department of Computer Science, Middlesex University, London, United Kingdom},
	abstract = {Purpose: Algorithms are in the mainstream media news on an almost daily basis. Their context is invariably artificial intelligence (AI) and machine learning decision-making. In media articles, algorithms are described as powerful, autonomous actors that have a capability of producing actions that have consequences. Despite a tendency for deification, the prevailing critique of algorithms focuses on ethical concerns raised by decisions resulting from algorithmic processing. However, the purpose of this paper is to propose that the ethical concerns discussed are limited in scope and suggest that it is not clear what concerns dominate the debate. Design/methodology/approach: The paper uses a systematic mapping study approach to review articles appearing in leading UK national papers from the perspective of the ethical concerns over a period of one year. The articles are categorised using a widely cited framework detailing a taxonomy of ethical concerns. The UK context is important because of UK public policy initiatives around AI. Findings: The research presented in this paper contributes the first systematic mapping study of articles appearing in leading UK national papers from the perspective of widely accepted ethical concerns such as inscrutable evidence, misguided evidence, unfair outcomes and transformative effects. Originality/value: The research presented in this paper contributes the first systematic mapping study of articles appearing in leading UK national papers from the perspective of the ethical concerns. The UK context is important because of UK public policy initiatives around AI. To review the media content from the perspective of ethical concerns, this paper uses the synthesised conceptual map of ethical concerns developed by Mittelstad et al. Given the dominance of that framework, this paper’s contribution is also an important instantiation and experimental validation of using that conceptual map. © 2019, Emerald Publishing Limited.},
	author_keywords = {Algorithms; Artificial intelligence; Bias; Ethics; Governance; Machine learning},
	correspondence_address = {B.S. Barn; Department of Computer Science, Middlesex University, London, United Kingdom; email: b.barn@mdx.ac.uk},
	publisher = {Emerald Group Holdings Ltd.},
	issn = {1477996X},
	language = {English},
	abbrev_source_title = {J. Inf. Commun. Ethics Soc.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Green Open Access}
}

@ARTICLE{Cardinal2020,
	author = {Cardinal, Héloïse and Ballesteros Gallego, Fabian and Affdal, Aliya and Fortin, Marie-Chantal},
	title = {Canadian transplant nephrologists’ perspectives on the decision-making process for accepting or refusing a kidney from a deceased organ donor},
	year = {2020},
	journal = {Clinical Transplantation},
	volume = {34},
	number = {3},
	doi = {10.1111/ctr.13793},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079129251&doi=10.1111%2fctr.13793&partnerID=40&md5=6eff4156be37d24ac5fd7fc82b522a4f},
	affiliations = {Centre de recherche du Centre hospitalier de l’Université de Montréal (CRCHUM), Montréal, QC, Canada; Canadian Donation and Transplantation Research Program, Edmonton, QC, Canada; Université de Montréal, Montréal, QC, Canada},
	abstract = {Background: Kidney transplantation is the best treatment for patients with end-stage renal disease. The decision to accept a kidney from a deceased donor can be a difficult one, especially when organs from high KDPI (>85%) donors are offered. This study aims to capture the perspectives of transplant nephrologists (TNs) on the decision-making process when an organ is offered. Methods: Fifteen Canadian TNs took part in semi-structured interviews between December 2017 and April 2018. The interviews were digitally recorded, transcribed, and analyzed using the thematic analysis method. Results: The decision to accept a deceased-donor kidney offer is a medical one for the participants. However, transplant candidates could be involved when the offered kidney is from a donor with a KDPI >85% or increased infectious risk donor. The TNs’ past experience, comprehensive data on the donor, and education of the transplant candidate could facilitate the decision-making process. A decision aid could also facilitate the decision-making process, but different concerns should be addressed. Conclusion: Although accepting a deceased-donor organ offer is often viewed as an opportunity for shared decision-making, participants in this study viewed the decision to accept or refuse an offer as a medical decision with little room for patient participation. © 2020 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd},
	author_keywords = {clinical decision-making; donors and donation: deceased; ethics},
	keywords = {Canada; Humans; Kidney; Kidney Transplantation; Nephrologists; Tissue and Organ Procurement; Tissue Donors; adult; Article; Canadian; deceased donor; female; graft survival; human; information dissemination; kidney transplantation; machine learning; male; nephrologist; organ donor; physician attitude; priority journal; semi structured interview; shared decision making; thematic analysis; transplant surgeon; Canada; donor; kidney; nephrologist; transplantation},
	correspondence_address = {M.-C. Fortin; Centre de recherche du Centre hospitalier de l’Université de Montréal (CRCHUM), Montréal, Canada; email: marie-chantal.fortin@umontreal.ca},
	publisher = {Blackwell Publishing Ltd},
	issn = {09020063},
	coden = {CLTRE},
	pmid = {31989699},
	language = {English},
	abbrev_source_title = {Clin. Transplant.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Kusner202034,
	author = {Kusner, Matt J. and Loftus, Joshua R.},
	title = {The long road to fairer algorithms},
	year = {2020},
	journal = {Nature},
	volume = {578},
	number = {7793},
	pages = {34 – 36},
	doi = {10.1038/d41586-020-00274-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078976878&doi=10.1038%2fd41586-020-00274-3&partnerID=40&md5=91a8b31e7a5b9ffe2b03a36b68f3efb2},
	abstract = {Build models that identify and mitigate the causes of discrimination. [Figure not available: see fulltext.]. © 2020, Nature.},
	author_keywords = {Computer science; Ethics; Society},
	keywords = {Algorithms; Bias; Data Science; Humans; Models, Statistical; agricultural worker; algorithm; artificial intelligence; causal model; ethnicity; human; machine learning; migrant; Note; priority journal; religion; social discrimination; ethics; statistical bias; statistical model},
	publisher = {Nature Research},
	issn = {00280836},
	coden = {NATUA},
	pmid = {32020122},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; All Open Access, Bronze Open Access}
}

@BOOK{Heinze20201,
	author = {Heinze, Aleksej and Fletcher, Gordon and Rashid, Tahir and Cruz, Ana},
	title = {Digital and social media marketing: A results-driven approach},
	year = {2020},
	journal = {Digital and Social Media Marketing: A Results-Driven Approach},
	pages = {1 – 336},
	doi = {10.4324/9780429280689},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117056212&doi=10.4324%2f9780429280689&partnerID=40&md5=ef738dbd5d98dec10820011ddfba46ab},
	affiliations = {KEDGE Business School, France; Salford Business School, University of Salford, United Kingdom; The University of Salford, United Kingdom; The University of Sheffield International Faculty, CITY College, Greece},
	abstract = {The second edition of Digital and Social Media Marketing is an up-to-date, industry-led results-driven guide to digital marketing. Mixing academic theory with practical examples from a range of different organisations worldwide, it provides insight into, and techniques to enable, the creation, development and maintenance of a successful digital presence. This highly regarded textbook has been fully revised to bring the content up-to-date with the newest digital technologies. With topics including developing an effective digital presence, search engine optimization, and measuring brand awareness, the new edition also looks at digital ethics, General Data Protection Regulation and privacy, artificial intelligence and machine learning, and voice strategies. New international case studies are explored, including Alibaba and Amazon, as well as revised practical exercises in each chapter, enabling students to see how the concepts underpinning digital and social media marketing support business success. The book's customisable Digital Business Maturity Model, and the Buyer Persona Spring, offer organisations a clear road map for understanding their own levels of technology adoption and digital strategy development. This accessible textbook provides a hands-on, user-friendly platform to turn skills and knowledge into strategic advantage. It is ideal for advanced undergraduate and postgraduate students of digital marketing and marketing strategy and for practitioners aiming to be at the cutting edge of digital and social media marketing. Alongside electronic resources for each chapter, this new edition also includes digital learning materials, case studies and exercises available in a supporting online learning environment. The online materials further enhance learners' experience and support a worldwide learning community. © 2020 Aleksej Heinze, Gordon Fletcher, Tahir Rashid and Ana Cruz. All rights reserved.},
	publisher = {Taylor and Francis},
	isbn = {978-100004164-4; 978-036723602-1},
	language = {English},
	abbrev_source_title = {Digit. and Soc. Media Mark.: A Results-Driv. Approach},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Salminen2020,
	author = {Salminen, Joni and Froneman, Willemien and Jung, Soon-Gyo and Chowdhury, Shammur and Jansen, Bernard J.},
	title = {The ethics of data-driven personas},
	year = {2020},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3334480.3382790},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090189052&doi=10.1145%2f3334480.3382790&partnerID=40&md5=a3e62bfb863e694174252440186c7bca},
	affiliations = {Hamad Bin Khalifa University and University of Turku, Doha, Qatar; Stellenbosch University, Stellenbosch, South Africa; Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar},
	abstract = {Quantitative methods are becoming more common for persona creation, but it is not clear to which extent online data and opaque machine learning algorithms introduce bias at various steps of data-driven persona creation (DDPC) and if these methods violate user rights. In this conceptual analysis, we use Gillespie's framework of algorithmic ethics to analyze DDPC for ethical considerations. We propose five design questions for evaluating the ethics of DDPC. DDPC should demonstrate the diversity of the user base but represent the actual data, be accompanied by explanations of their creation, and mitigate the possibility of unfair decisions. © 2020 Owner/Author.},
	author_keywords = {Data-driven personas; Ethics; Fairness; Personas},
	keywords = {Human engineering; Machine learning; Philosophical aspects; Conceptual analysis; Data driven; Design questions; Ethical considerations; Gillespie; Online data; Quantitative method; Learning algorithms},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036819-3},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2020 ACM CHI Conference on Human Factors in Computing Systems, CHI EA 2020; Conference date: 25 April 2020 through 30 April 2020; Conference code: 160405}
}

@BOOK{Liao20201,
	author = {Liao, S. Matthew},
	title = {A short introduction to the ethics of artificial intelligence},
	year = {2020},
	journal = {Ethics of Artificial Intelligence},
	pages = {1 – 42},
	doi = {10.1093/oso/9780190905033.003.0001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85111774056&doi=10.1093%2foso%2f9780190905033.003.0001&partnerID=40&md5=29221388803be854b4e2d62bf87ed206},
	affiliations = {Department of Philosophy, New York University, United States},
	abstract = {This introduction outlines in section I.1 some of the key issues in the study of the ethics of artificial intelligence (AI) and proposes ways to take these discussions further. Section I.2 discusses key concepts in AI, machine learning, and deep learning. Section I.3 considers ethical issues that arise because current machine learning is data hungry; is vulnerable to bad data and bad algorithms; is a black box that has problems with interpretability, explainability, and trust; and lacks a moral sense. Section I.4 discusses ethical issues that arise because current machine learning systems may be working too well and human beings can be vulnerable in the presence of these intelligent systems. Section I.5 examines ethical issues arising out of the long-term impact of superintelligence such as how the values of a superintelligent AI can be aligned with human values. Section I.6 presents an overview of the essays in this volume. © Oxford University Press 2020.},
	author_keywords = {Algorithmic bias; Black box; Deep learning; Ethics of artificial intelligence; Explainability; Interpretability; Machine learning; Superintelligence; Trust; Value alignment},
	publisher = {Oxford University Press},
	isbn = {978-019090503-3},
	language = {English},
	abbrev_source_title = {Ethics of Artificial Intelligence},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Wu2020302,
	author = {Wu, Wenjun and Huang, Tiejun and Gong, Ke},
	title = {Ethical Principles and Governance Technology Development of AI in China},
	year = {2020},
	journal = {Engineering},
	volume = {6},
	number = {3},
	pages = {302 – 309},
	doi = {10.1016/j.eng.2019.12.015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081263681&doi=10.1016%2fj.eng.2019.12.015&partnerID=40&md5=96ec788e5d4ae93186b2addb23365fb8},
	affiliations = {State Key Laboratory of Software Development Environment, Beihang University, Beijing, 100191, China; School of Electronics Engineering and Computer Science, Peking University, Beijing, 100871, China; Chinese Institute of New Generation Artificial Intelligence Development Strategie, Nankai University, Tianjin, 300071, China},
	abstract = {Ethics and governance are vital to the healthy and sustainable development of artificial intelligence (AI). With the long-term goal of keeping AI beneficial to human society, governments, research organizations, and companies in China have published ethical guidelines and principles for AI, and have launched projects to develop AI governance technologies. This paper presents a survey of these efforts and highlights the preliminary outcomes in China. It also describes the major research challenges in AI governance research and discusses future research directions. © 2020 THE AUTHORS},
	author_keywords = {AI ethical principles; AI governance technology; Fairness; Machine learning; Privacy; Safety},
	keywords = {Accident prevention; Artificial intelligence; Data privacy; Learning systems; Ethical principles; Fairness; Future research directions; Guidelines and Principles; Long-term goals; Research challenges; Research organization; Technology development; Philosophical aspects},
	correspondence_address = {W. Wu; State Key Laboratory of Software Development Environment, Beihang University, Beijing, 100191, China; email: wwj@nlsde.buaa.edu.cn},
	publisher = {Elsevier Ltd},
	issn = {20958099},
	language = {English},
	abbrev_source_title = {Engineering},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Gold Open Access}
}

@ARTICLE{Loftus2020456,
	author = {Loftus, Mary and Madden, Michael G.},
	title = {A pedagogy of data and Artificial Intelligence for student subjectification},
	year = {2020},
	journal = {Teaching in Higher Education},
	volume = {25},
	number = {4},
	pages = {456 – 475},
	doi = {10.1080/13562517.2020.1748593},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084353522&doi=10.1080%2f13562517.2020.1748593&partnerID=40&md5=f606f354a650bdf301f22bb1ce2bb5b8},
	affiliations = {Institute of Technology, Sligo, Ireland; National University of Ireland Galway, Galway, Ireland},
	abstract = {How do we teach and learn with our students about data literacy, at the same time as Biesta (2015) calls for an emphasis on ‘subjectification’ i.e. ‘the coming into presence of unique individual beings’? (Good Education in an Age of Measurement: Ethics, Politics, Democracy. Routledge) Our response to these challenges and the datafication of higher education, is a hands-on approach to building an open, collaborative pedagogy of data literacy, based on Bayesian Networks (BNs) (Pearl, J. 1985. Bayesian Networks: A Model of Self–Activated Memory for Evidential Reasoning. Los Angeles: University of California (Computer Science Department)). BNs can be used to merge subjective views of the learning process with objective data analysis from the learning environment; BNs are visual data constructs and, unlike other Machine Learning approaches that obfuscate and complexify, BNs can be developed to reveal relationships from observations. In this paper, we share ways in which teachers and students can work together in a praxis approach to use data to ‘read the world’ around them (Freire, P. 1970. Pedagogy of the Oppressed. New York: Continuum. 125). © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Bayesian networks; co-construction; constructionism; data literacy; datafication; machine learning; Subjectification},
	correspondence_address = {M. Loftus; Institute of Technology, Sligo, Ireland; email: loftus.mary@itsligo.ie},
	publisher = {Routledge},
	issn = {13562517},
	language = {English},
	abbrev_source_title = {Teach. High. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@ARTICLE{Oakey-Neate2020,
	author = {Oakey-Neate, Lydia and Schrader, Geoff and Strobel, Jörg and Bastiampillai, Tarun and Van Kasteren, Yasmin and Bidargaddi, Niranjan},
	title = {Using algorithms to initiate needs-based interventions for people on antipsychotic medication: Implementation protocol},
	year = {2020},
	journal = {BMJ Health and Care Informatics},
	volume = {27},
	number = {1},
	doi = {10.1136/bmjhci-2019-100084},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079338544&doi=10.1136%2fbmjhci-2019-100084&partnerID=40&md5=7bc5e365c3760235daebfd6236d95e33},
	affiliations = {Digital Psychiatry and Personal Health Informatics, Flinders University, Adelaide, SA, Australia; Country Health SA Local Health Network, Adelaide, SA, Australia; SA Health, Adelaide, SA, Australia; Digital Psychiatry and Personal Health Informatics, Flinders University, Adelaide, SA, Australia},
	abstract = {Introduction Non-adherence to antipsychotic medications for individuals with serious mental illness increases risk of relapse and hospitalisation. Real time monitoring of adherence would allow for early intervention. AI 2 is a both a personal nudging system and a clinical decision support tool that applies machine learning on Medicare prescription and benefits data to raise alerts when patients have discontinued antipsychotic medications without supervision, or when essential routine health checks have not been performed. Methods and analysis We outline two intervention models using AI 2. In the first use-case, the personal nudging system, patients receive text messages when an alert of a missed medication or routine health check is detected by AI 2. In the second use-case, as a clinical decision support tool, AI 2 generated alerts are presented as flags through a dashboard to the community mental health professionals. Implementation protocols for different scenarios of AI 2, along with a mixed-methods evaluation, are planned to identify pragmatic issues necessary to inform a larger randomised control trial, as well as improve the application. Ethics and dissemination This study protocol has been approved by The Southern Adelaide Clinical Human Research Ethics Committee. The dissemination of this trial will serve to inform further implementation of the AI 2 into daily personal and clinical practice. © © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {BMJ Health Informatics; healthcare; medical informatics; patient care; record systems},
	keywords = {Algorithms; Antipsychotic Agents; Artificial Intelligence; Humans; Medicare; Medication Adherence; Mental Disorders; United States; neuroleptic agent; algorithm; artificial intelligence; human; medicare; medication compliance; mental disease; United States},
	correspondence_address = {N. Bidargaddi; Digital Psychiatry and Personal Health Informatics, Flinders University, Adelaide, Australia; email: niranjan.bidargaddi@flinders.edu.au},
	publisher = {BMJ Publishing Group},
	issn = {26321009},
	pmid = {32051177},
	language = {English},
	abbrev_source_title = {BMJ Heal. care inf.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{O’Dell20203,
	author = {O’Dell, Liam M. and Jahankhani, Hamid},
	title = {The evolution of AI and the human-machine interface as a manager in Industry 4.0},
	year = {2020},
	journal = {Strategy, Leadership, and AI in the Cyber Ecosystem: The Role of Digital Societies in Information Governance and Decision Making},
	pages = {3 – 22},
	doi = {10.1016/B978-0-12-821442-8.00015-X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123584624&doi=10.1016%2fB978-0-12-821442-8.00015-X&partnerID=40&md5=c49a11169d44156ceeafc80c98757c2f},
	affiliations = {Member of the Association for Project, Management (MAPM), Associate of the Chartered Institute for Building (ACIOB), London, United Kingdom; Northumbria University, London, United Kingdom},
	abstract = {The role of project management is changing dramatically in the backdrop of Industry 4.0 and the digital revolution. This exciting transformation is taking place in the next few years whilst embracing artificial intelligence (AI) technology into the body of the knowledge competencies. With this intelligence explosion, the influence of AI technology and the key themes of machine learning, big data, and digital twin are evolving, creating the possibility of a cyber physical project professional. This brings with it further issues around ethics and governance with the development and use of AI technology. The aim of this chapter is to provides a useful initial insight whilst assisting the project management professional to gain further understanding of how AI innovation is entering the workplace and how to potentially engage with AI. In addition, this study will hopefully stimulate future researchers to develop ideas for innovation in the use of AI and the cyberphysical digital twin coworking relationships within the project management profession. © 2021 Elsevier Inc. All rights reserved.},
	author_keywords = {Artificial intelligence; Big data; Digital twin; Ethics and governance; Knowledge competency areas and frameworks; Machine learning},
	publisher = {Elsevier},
	isbn = {978-012821442-8},
	language = {English},
	abbrev_source_title = {Strategy, Leadersh., and AI in the Cyber Ecosystem: The Role of Digital Societies in Information Gov. and Decision Mak.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Mello2020951,
	author = {Mello, Michelle M. and Wang, C. Jason},
	title = {Ethics and governance for digital disease surveillance},
	year = {2020},
	journal = {Science},
	volume = {368},
	number = {6494},
	pages = {951 – 954},
	doi = {10.1126/science.abb9045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085630015&doi=10.1126%2fscience.abb9045&partnerID=40&md5=636bf0a26895ab8846d283bdae6b9b75},
	affiliations = {Center for Health Policy/Primary Care and Outcomes Research, Department of Medicine, Stanford University School of Medicine, Stanford, CA, United States; Stanford Law School, Stanford, CA, United States; Department of Pediatrics, Center for Policy, Outcomes and Prevention, Stanford University School of Medicine, Stanford, CA, United States},
	keywords = {Artificial Intelligence; Confidentiality; Coronavirus Infections; Datasets as Topic; Epidemiological Monitoring; Forecasting; Humans; Machine Learning; Pandemics; Pneumonia, Viral; detection method; digital mapping; disease prevalence; ethics; governance approach; artificial intelligence; contact examination; coronavirus disease 2019; disease model; disease surveillance; health care quality; health equity; human; infection risk; information processing; informed consent; machine learning; medical ethics; priority journal; privacy; quarantine; research ethics; Review; social media; social responsibility; confidentiality; Coronavirus infection; epidemiological monitoring; ethics; forecasting; pandemic; virus pneumonia},
	correspondence_address = {M.M. Mello; Center for Health Policy/Primary Care and Outcomes Research, Department of Medicine, Stanford University School of Medicine, Stanford, United States; email: mmello@law.stanford.edu},
	publisher = {American Association for the Advancement of Science},
	issn = {00368075},
	coden = {SCIEA},
	pmid = {32393527},
	language = {English},
	abbrev_source_title = {Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 72; All Open Access, Bronze Open Access}
}

@CONFERENCE{2020,
	title = {Tethics 2020 - Proceedings of the Conference on Technology Ethics},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2737},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099068380&partnerID=40&md5=4422ccdcb5457f8df15e586be95a7c5e},
	abstract = {The proceedings contain 9 papers. The topics discussed include: machine learning for prognosis of oral cancer: what are the ethical challenges?; students' perceptions about data safety and ethics in learning analytics; algorithmic fairness and its limits in group-formation; COVID-19: crisis management and promethean thinking in digital age; ethical justification of the value basis of the European data economy ecosystems; hard-coded censorship in open source mastodon clients — how free is open source?; conceptualizations towards an ethical framework for applying artificial intelligence in facility management; and towards patient-oriented transparency.},
	editor = {Koskinen J. and Rantanen M.M. and Tuikka A.-M. and Knaapi-Junnila S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 Conference on Technology Ethics, Tethics 2020; Conference date: 21 October 2020; Conference code: 164803}
}

@ARTICLE{Vollmer2020,
	author = {Vollmer, Sebastian and Mateen, Bilal A. and Bohner, Gergo and Király, Franz J. and Ghani, Rayid and Jonsson, Pall and Cumbers, Sarah and Jonas, Adrian and McAllister, Katherine S.L. and Myles, Puja and Granger, David and Birse, Mark and Branson, Richard and Moons, Karel G.M. and Collins, Gary S. and Ioannidis, John P.A. and Holmes, Chris and Hemingway, Harry},
	title = {Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness},
	year = {2020},
	journal = {The BMJ},
	volume = {368},
	doi = {10.1136/bmj.l6927},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082092444&doi=10.1136%2fbmj.l6927&partnerID=40&md5=f7d9d5b6a702a5df378c6aa222b486fd},
	affiliations = {Alan Turing Institute, Kings Cross, London, United Kingdom; Departments of Mathematics and Statistics, University of Warwick, Coventry, United Kingdom; Warwick Medical School, University of Warwick, Coventry, United Kingdom; Kings College Hospital, Denmark Hill, London, United Kingdom; Department of Statistical Science, University College London, London, United Kingdom; University of Chicago, Chicago, IL, United States; Science Policy and Research, National Institute for Health and Care Excellence, Manchester, United Kingdom; Health and Social Care Directorate, National Institute for Health and Care Excellence, London, United Kingdom; Data and Analytics Group, National Institute for Health and Care Excellence, London, United Kingdom; Clinical Practice Research Datalink, Medicines and Healthcare Products Regulatory Agency, London, United Kingdom; Medicines and Healthcare Products Regulatory Agency, London, United Kingdom; Julius Centre for Health Sciences and Primary Care, UMC Utrecht, Utrecht University, Utrecht, Netherlands; UK EQUATOR Centre, Centre for Statistics in Medicine, NDORMS, University of Oxford, Oxford, United Kingdom; Meta-Research Innovation Centre at Stanford, Stanford University, Stanford, CA, United States; Department of Statistics, University of Oxford, Oxford, OX1 3LB, United Kingdom; Health Data Research UK London, University College London, London, United Kingdom; Institute of Health Informatics, University College London, London, United Kingdom; National Institute for Health Research, University College London Hospitals Biomedical Research Centre, University College London, London, United Kingdom},
	abstract = {Machine learning, artificial intelligence, and other modern statistical methods are providing new opportunities to operationalise previously untapped and rapidly growing sources of data for patient benefit. Despite much promising research currently being undertaken, particularly in imaging, the literature as a whole lacks transparency, clear reporting to facilitate replicability, exploration for potential ethical concerns, and clear demonstrations of effectiveness. Among the many reasons why these problems exist, one of the most important (for which we provide a preliminary solution here) is the current lack of best practice guidance specific to machine learning and artificial intelligence. However, we believe that interdisciplinary groups pursuing research and impact projects involving machine learning and artificial intelligence for health would benefit from explicitly addressing a series of questions concerning transparency, reproducibility, ethics, and effectiveness (TREE). The 20 critical questions proposed here provide a framework for research groups to inform the design, conduct, and reporting; for editors and peer reviewers to evaluate contributions to the literature; and for patients, clinicians and policy makers to critically appraise where new findings may deliver patient benefit. © © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	keywords = {Algorithms; Artificial Intelligence; Data Collection; Humans; Machine Learning; Reproducibility of Results; Surveys and Questionnaires; adult; article; artificial intelligence; editor; ethics; human; machine learning; reproducibility; algorithm; artificial intelligence; information processing; machine learning; questionnaire},
	publisher = {BMJ Publishing Group},
	issn = {09598146},
	coden = {BMJOA},
	pmid = {32198138},
	language = {English},
	abbrev_source_title = {BMJ},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 180; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Greenhill202085,
	author = {Greenhill, Alexandra T. and Edmunds, Bethany R.},
	title = {A primer of artificial intelligence in medicine},
	year = {2020},
	journal = {Techniques and Innovations in Gastrointestinal Endoscopy},
	volume = {22},
	number = {2},
	pages = {85 – 89},
	doi = {10.1016/j.tgie.2019.150642},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104680660&doi=10.1016%2fj.tgie.2019.150642&partnerID=40&md5=ae76915d321faec0f535f9bb8d558200},
	affiliations = {Department of Family Medicine, University of British Columbia, Canada; Careteam Technologies, Vancouver, BC, Canada; Northeastern University, Vancouver, BC, Canada},
	abstract = {As AI becomes increasingly ubiquitous in our world, it is set to transform every aspect of how we do medical care, research and education. Physicians as a profession need to be active leaders and participants in this technology-driven transformation in order to ensure that the potential to dramatically improve health care is fulfilled. This article is focused on enabling that active participation by helping physicians gain understanding of the core concepts, issues, and trends related to AI (using the common board use of the term which includes Machine Learning, Deep Learning, Augmented Intelligence, and Artificial General Intelligence). © 2019},
	author_keywords = {20th Century History; 21st Century History; Artificial intelligence; Artificial Intelligence/ethics; Artificial Intelligence/history; Artificial Intelligence/terminology; Artificial Intelligence/trends; Augmented intelligence; Computer-Assisted; Decision Making; Deep learning; Digital health technology; Future of medicine; Humans; Machine learning; Terminology as Topic},
	keywords = {artificial intelligence; attitude to health; data science; deep learning; health care; health care organization; human; machine learning; physician; Review; statistical bias},
	correspondence_address = {A.T. Greenhill; Department of Family Medicine, University of British Columbia, Canada; email: agreenhill@careteam.me},
	publisher = {Elsevier B.V.},
	issn = {26665107},
	language = {English},
	abbrev_source_title = {Tech. Innov. Gastrointest. Endosc.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Bronze Open Access}
}

@ARTICLE{Shung2020585,
	author = {Shung, Dennis L. and Byrne, Michael F.},
	title = {How Artificial Intelligence Will Impact Colonoscopy and Colorectal Screening},
	year = {2020},
	journal = {Gastrointestinal Endoscopy Clinics of North America},
	volume = {30},
	number = {3},
	pages = {585 – 595},
	doi = {10.1016/j.giec.2020.02.010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083058281&doi=10.1016%2fj.giec.2020.02.010&partnerID=40&md5=f63340ad2a7140feae5c2e730b8594f5},
	affiliations = {Section of Digestive Diseases, Department of Medicine, Yale School of Medicine, P.O. Box 208019, New Haven, 06520-8019, CT, United States; Division of Gastroenterology, Vancouver General Hospital, University of British Columbia, 5153 - 2775 Laurel Street, Vancouver, British Columbia, Canada},
	abstract = {Artificial intelligence may improve value in colonoscopy-based colorectal screening and surveillance by improving quality and decreasing unnecessary costs. The quality of screening and surveillance as measured by adenoma detection rates can be improved through real-time computer-assisted detection of polyps. Unnecessary costs can be decreased with optical biopsies to identify low-risk polyps using computer-assisted diagnosis that can undergo the resect-and-discard or diagnose-and-leave strategy. Key challenges include the clinical integration of artificial intelligence-based technology into the endoscopists’ workflow, the effect of this technology on endoscopy center efficiency, and the interpretability of the underlying deep learning algorithms. The future for image-based artificial intelligence in gastroenterology will include applications to improve the diagnosis and treatment of cancers throughout the gastrointestinal tract. © 2020 Elsevier Inc.},
	author_keywords = {Artificial intelligence; Colonoscopy; Value-based care},
	keywords = {Adenoma; Artificial Intelligence; Colonoscopy; Colorectal Neoplasms; Diagnosis, Computer-Assisted; Early Detection of Cancer; Humans; Intestinal Polyps; adenomatous polyp; artificial intelligence; autofluorescence imaging; beneficence; cancer epidemiology; cancer screening; colonoscopy; colorectal cancer; computer security; convolutional neural network; deep neural network; discriminant analysis; endocytoscopy; ethics; health care cost; human; integration; justice; laser induced fluorescence spectroscopy; legal aspect; machine learning; narrow band imaging; patient autonomy; patient risk; priority journal; Review; risk assessment; social control; support vector machine; validation process; adenoma; colonoscopy; colorectal tumor; computer assisted diagnosis; early cancer diagnosis; intestine polyp; procedures},
	correspondence_address = {M.F. Byrne; Division of Gastroenterology, Vancouver General Hospital, University of British Columbia, Vancouver, 5153 - 2775 Laurel Street, Canada; email: michael.byrne@vch.ca},
	publisher = {W.B. Saunders},
	issn = {10525157},
	coden = {GECNE},
	pmid = {32439090},
	language = {English},
	abbrev_source_title = {Gastrointest. Endosc. Clin. North Am.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Ahmad202080,
	author = {Ahmad, Omer F. and Stoyanov, Danail and Lovat, Laurence B.},
	title = {Barriers and pitfalls for artificial intelligence in gastroenterology: Ethical and regulatory issues},
	year = {2020},
	journal = {Techniques and Innovations in Gastrointestinal Endoscopy},
	volume = {22},
	number = {2},
	pages = {80 – 84},
	doi = {10.1016/j.tgie.2019.150636},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85092151491&doi=10.1016%2fj.tgie.2019.150636&partnerID=40&md5=bbd4feece32b8a43cfb24dddb722613e},
	affiliations = {Wellcome/EPSRC Centre for Interventional & Surgical Sciences, University College London, London, W1W 7TS, United Kingdom; Division of Surgery & Interventional Science, University College London, London, United Kingdom},
	abstract = {Artificial intelligence (AI)-based technologies are developing rapidly, offering great promise for gastroenterology and particularly endoscopy. However, there are complex barriers and pitfalls that must be considered before widespread real-world clinical implementation can occur. This review highlights major ethical concerns related to data privacy and sharing that are essential for the development of AI models, through to practical clinical issues such as potential patient harm, accountability, bias in decisions, and impact on workforce. Finally, current regulatory pathways are discussed, recognizing that these need to evolve to deal with unique new challenges, such as the adaptive and rapidly iterative nature of AI-based technologies, while striking a balance between ensuring patient safety and promoting innovation. © 2019 Elsevier Inc.},
	author_keywords = {Artificial intelligence; Endoscopy; Ethics; Machine learning; Regulation},
	keywords = {adult; artificial intelligence; data privacy; drug safety; endoscopy; ethics; gastroenterology; human; machine learning; patient harm; review; workforce},
	correspondence_address = {O.F. Ahmad; Wellcome/EPSRC Centre for Interventional & Surgical Sciences, University College London, London, W1W 7TS, United Kingdom; email: o.ahmad@doctors.org.uk},
	publisher = {Elsevier B.V.},
	issn = {26665107},
	language = {English},
	abbrev_source_title = {Tech. Innov. Gastrointest. Endosc.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Chan2020319,
	author = {Chan, Lili and Vaid, Akhil and Nadkarni, Girish N.},
	title = {Applications of machine learning methods in kidney disease: Hope or hype?},
	year = {2020},
	journal = {Current Opinion in Nephrology and Hypertension},
	volume = {29},
	number = {3},
	pages = {319 – 326},
	doi = {10.1097/MNH.0000000000000604},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082790928&doi=10.1097%2fMNH.0000000000000604&partnerID=40&md5=2754965dc0a7361005cbf94006d996fe},
	affiliations = {Division of Nephrology, Department of Medicine; Charles Bronfman Institute of Personalized Medicine, United States; Hasso Plattner Institute for Digital Health; Bio Me Phenomics Center, Icahn School of Medicine at Mount Sinai, New York, NY, United States},
	abstract = {Purpose of review The universal adoption of electronic health records, improvement in technology, and the availability of continuous monitoring has generated large quantities of healthcare data. Machine learning is increasingly adopted by nephrology researchers to analyze this data in order to improve the care of their patients. Recent findings In this review, we provide a broad overview of the different types of machine learning algorithms currently available and how researchers have applied these methods in nephrology research. Current applications have included prediction of acute kidney injury and chronic kidney disease along with progression of kidney disease. Researchers have demonstrated the ability of machine learning to read kidney biopsy samples, identify patient outcomes from unstructured data, and identify subtypes in complex diseases. We end with a discussion on the ethics and potential pitfalls of machine learning. Summary Machine learning provides researchers with the ability to analyze data that were previously inaccessible. While still burgeoning, several studies show promising results, which will enable researchers to perform larger scale studies and clinicians the ability to provide more personalized care. However, we must ensure that implementation aids providers and does not lead to harm to patients. © 2020 Lippincott Williams and Wilkins. All rights reserved.},
	author_keywords = {acute kidney injury; CKD; machine learning; nephrology},
	keywords = {Algorithms; Humans; Kidney Diseases; Machine Learning; Natural Language Processing; Translational Medical Research; acute kidney failure; artificial intelligence; chronic kidney failure; clinical practice; drug development; human; kidney biopsy; kidney disease; machine learning; medical ethics; medical research; natural language processing; nephrology; nonhuman; pattern recognition; prediction; priority journal; Review; treatment outcome; algorithm; disease exacerbation; learning; recurrent neural network; reinforcement; kidney disease; translational research},
	correspondence_address = {G.N. Nadkarni; Icahn School of Medicine at Mount Sinai, New York, One Gustave L Levy Place, Box 1243, 10029, United States; email: girish.nadkarni@mountsinai.org},
	publisher = {Lippincott Williams and Wilkins},
	issn = {10624821},
	coden = {CNHYE},
	pmid = {32235273},
	language = {English},
	abbrev_source_title = {Curr. Opin. Nephrol. Hypertens.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Green Open Access}
}

@ARTICLE{Norval2020187,
	author = {Norval, Chris and Henderson, Tristan},
	title = {Automating Dynamic Consent Decisions for the Processing of Social Media Data in Health Research},
	year = {2020},
	journal = {Journal of Empirical Research on Human Research Ethics},
	volume = {15},
	number = {3},
	pages = {187 – 201},
	doi = {10.1177/1556264619883715},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075129506&doi=10.1177%2f1556264619883715&partnerID=40&md5=810362f952543cf0e9953d48990ae417},
	affiliations = {University of Cambridge, United Kingdom; The University of St Andrews, United Kingdom},
	abstract = {Social media have become a rich source of data, particularly in health research. Yet, the use of such data raises significant ethical questions about the need for the informed consent of those being studied. Consent mechanisms, if even obtained, are typically broad and inflexible, or place a significant burden on the participant. Machine learning algorithms show much promise for facilitating a “middle-ground” approach: using trained models to predict and automate granular consent decisions. Such techniques, however, raise a myriad of follow-on ethical and technical considerations. In this article, we present an exploratory user study (n = 67) in which we find that we can predict the appropriate flow of health-related social media data with reasonable accuracy, while minimizing undesired data leaks. We then attempt to deconstruct the findings of this study, identifying and discussing a number of real-world implications if such a technique were put into practice. © The Author(s) 2019.},
	author_keywords = {contextual integrity; health support networks; informed consent; privacy; social media},
	keywords = {Ethics, Research; Humans; Informed Consent; Morals; Social Media; human; informed consent; morality; research ethics; social media},
	correspondence_address = {C. Norval; University of Cambridge, United Kingdom; email: chris.norval@cl.cam.ac.uk},
	publisher = {SAGE Publications Inc.},
	issn = {15562646},
	pmid = {31691629},
	language = {English},
	abbrev_source_title = {J. Empir. Res. Hum. Res. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@ARTICLE{Mukherjee2020,
	author = {Mukherjee, Pritam and Cintra, Murilo and Huang, Chao and Zhou, Mu and Zhu, Shankuan and Colevas, A. Dimitrios and Fischbein, Nancy and Gevaert, Olivier},
	title = {Ct-based radiomic signatures for predicting histopathologic features in head and neck squamous cell carcinoma},
	year = {2020},
	journal = {Radiology: Imaging Cancer},
	volume = {2},
	number = {3},
	doi = {10.1148/rycan.2020190039},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85100528171&doi=10.1148%2frycan.2020190039&partnerID=40&md5=5a74e2cbd72df7d26b95df20e9f5be0a},
	affiliations = {Department of Medicine, Stanford Center for Biomedical Informatics Research (BMIR), Stanford, CA, United States; Department of Radiology, Ribeirão Preto Medical School, University of São Paulo, São Paulo, Brazil; Department of Nutrition and Food Hygiene, Chronic Disease Research Institute, School of Public Health, School of Medicine, Zhejiang University, Zhejiang, China; Division of Oncology, Department of Medicine, Stanford University, 1265 Welch Rd, Stanford, 94305-5479, CA, United States; Department of Radiology, Stanford University, 1265 Welch Rd, Stanford, 94305-5479, CA, United States; Department of Biomedical Data Science, Stanford University, 1265 Welch Rd, Stanford, 94305-5479, CA, United States},
	abstract = {Purpose: To determine the performance of CT-based radiomic features for noninvasive prediction of histopathologic features of tumor grade, extracapsular spread, perineural invasion, lymphovascular invasion, and human papillomavirus status in head and neck squa-mous cell carcinoma (HNSCC). Materials and Methods: In this retrospective study, which was approved by the local institutional ethics committee, CT images and clini-cal data from patients with pathologically proven HNSCC from The Cancer Genome Atlas (n = 113) and an institutional test cohort (n = 71) were analyzed. A machine learning model was trained with 2131 extracted radiomic features to predict tumor histopathologic characteristics. In the model, principal component analysis was used for dimensionality reduction, and regularized regression was used for classification. Results: The trained radiomic model demonstrated moderate capability of predicting HNSCC features. In the training cohort and the test cohort, the model achieved a mean area under the receiver operating characteristic curve (AUC) of 0.75 (95% confidence interval [CI]: 0.68, 0.81) and 0.66 (95% CI: 0.45, 0.84), respectively, for tumor grade; a mean AUC of 0.64 (95% CI: 0.55, 0.62) and 0.70 (95% CI: 0.47, 0.89), respectively, for perineural invasion; a mean AUC of 0.69 (95% CI: 0.56, 0.81) and 0.65 (95% CI: 0.38, 0.87), respectively, for lymphovascular invasion; a mean AUC of 0.77 (95% CI: 0.65, 0.88) and 0.67 (95% CI: 0.15, 0.80), respectively, for extracapsular spread; and a mean AUC of 0.71 (95% CI: 0.29, 1.0) and 0.80 (95% CI: 0.65, 0.92), respectively, for human papilloma-virus status. Conclusion: Radiomic CT models have the potential to predict characteristics typically identified on pathologic assessment of HNSCC. © RSNA, 2020.},
	keywords = {Humans; Papillomaviridae; Retrospective Studies; Squamous Cell Carcinoma of Head and Neck; Tomography, X-Ray Computed; diagnostic imaging; human; Papillomaviridae; pathology; retrospective study; x-ray computed tomography},
	correspondence_address = {O. Gevaert; Department of Medicine, Stanford Center for Biomedical Informatics Research (BMIR), Stanford, United States; email: ogevaert@stanford.edu},
	publisher = {Radiological Society of North America Inc.},
	issn = {2638616X},
	pmid = {32550599},
	language = {English},
	abbrev_source_title = {Radiology.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Ophir2020603,
	author = {Ophir, Dan},
	title = {Intellectual Capital-A Third Party's Point of View},
	year = {2020},
	journal = {Proceedings of the European Conference on Knowledge Management, ECKM},
	volume = {2020-December},
	pages = {603 – 611},
	doi = {10.34190/EKM.20.025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099882857&doi=10.34190%2fEKM.20.025&partnerID=40&md5=646924bb3af3977e1c173898e52ad8a3},
	affiliations = {Ariel University, Israel},
	abstract = {The four main participants concerning Intellectual Property are the owner, the receiver, the users, and the guards watching the ethicality. Generally, the disagreements between the IC owners and their receivers are resolved in the courts, where the ownership claims are investigated; the guard's role is to decrease the illegal transferring of the IC from the owners to illegal receivers (stealing the Intellectual Property). Such illegal IC acquisition causes damage to the IC's legal owners. However, this is not the case in IC transfer, in which the IC owners collaborate with the IC receivers and the guards make efforts to avoid such a transfer. Here the owners are not adversely affected and do not claim their ownership; on the contrary, they try to hide their ownership-the victims are third-party persons. An example of such illegal, collaborative IC transfer may serve students' interests in the context of an examination and their work submitted to the teacher for evaluation. The two stages of dealing with the above problems are as follows: 1. Avoiding the flow of information from outside the students' community and transferring it to the students themselves. Such avoidance may partially succeed, using some technical blocking methods; however, during classwork, the situation is more difficult, for example, dealing with homework. 2. Detection is the stage whereby the first line of security is inadequate, or it refers to increasing the protection level of the students' evaluation process. This stage requires more sophisticated methods for comparing two works and for estimating the probability that one work has been copied. The treatment of this issue depends on the types of work in various faculties. They may be divided into three main groups: 1. Humanities and Social Sciences-whose works are more verbal; 2. Natural Sciences and Engineering-in which the submitted works require some kind of formalization, including mathematical formulas and computing results. 3. Art-sculptures, paintings, and music-the results of the composers should be compared. © 2020 Academic Conferences Limited. All rights reserved.},
	author_keywords = {Copyrights; Cyber security; Ethics; Forging; Machine learning; Morphology processing; Patents' registration; Privacy; Signature; Steganography},
	keywords = {Crime; Intellectual property; Knowledge management; Students; Blocking method; Humanities and social science; Intellectual capital; Mathematical formulas; Natural sciences and engineerings; Protection level; Students' evaluations; Students' interests; Integrated circuits},
	correspondence_address = {D. Ophir; Ariel University, Israel; email: dano@ariel.ac.il},
	editor = {Garcia-Perez A. and Simkin L.},
	publisher = {Academic Conferences and Publishing International Limited},
	issn = {20488963},
	isbn = {978-191276481-5},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. Knowl. Manage., ECKM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 21st European Conference on Knowledge Management, ECKM 2020; Conference date: 2 December 2020 through 4 December 2020; Conference code: 166463}
}

@ARTICLE{Goldstein2020609,
	author = {Goldstein, Cathy A. and Berry, Richard B. and Kent, David T. and Kristo, David A. and Seixas, Azizi A. and Redline, Susan and Brandon Westover, M.},
	title = {Artificial intelligence in sleep medicine: Background and implications for clinicians},
	year = {2020},
	journal = {Journal of Clinical Sleep Medicine},
	volume = {16},
	number = {4},
	pages = {609 – 618},
	doi = {10.5664/jcsm.8388},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083624051&doi=10.5664%2fjcsm.8388&partnerID=40&md5=5b08cd93d978595b10f9911d4d64626b},
	affiliations = {Sleep Disorders Center, Department of Neurology, University of Michigan, Ann Arbor, MI, United States; Division of Pulmonary, Critical Care and Sleep Medicine, University of Florida, Gainesville, FL, United States; Department of Otolaryngology-Head and Neck Surgery, Vanderbilt University Medical Center, Nashville, TN, United States; University of Pittsburgh, Pittsburgh, PA, United States; Department of Population Health, Department of Psychiatry, NYU Langone Health, New York, NY, United States; Brigham and Women's Hospital, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; Neurology Department, Massachusetts General Hospital, Boston, MA, United States},
	abstract = {Polysomnography remains the cornerstone of objective testing in sleep medicine and results in massive amounts of electrophysiological data, which is well-suited for analysis with artificial intelligence (AI)-based tools. Combined with other sources of health data, AI is expected to provide new insights to inform the clinical care of sleep disorders and advance our understanding of the integral role sleep plays in human health. Additionally, AI has the potential to streamline day-to-day operations and therefore optimize direct patient care by the sleep disorders team. However, clinicians, scientists, and other stakeholders must develop best practices to integrate this rapidly evolving technology into our daily work while maintaining the highest degree of quality and transparency in health care and research. Ultimately, when harnessed appropriately in conjunction with human expertise, AI will improve the practice of sleep medicine and further sleep science for the health and well-being of our patients. © 2020 American Academy of Sleep Medicine. All rights reserved.},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; Physicians; Sleep; actimetry; Article; artificial intelligence; body movement; clinical classification; clinical evaluation; clinical medicine; consumer sleep technology; daytime somnolence; excessive daytime sleepiness; health care; health care delivery; human; machine learning; medical ethics; medical record; parasomnia; population health; respiratory tract disease; scoring system; sleep disorder; sleep disordered breathing; sleep medicine; sleep staging; software; physician; sleep},
	correspondence_address = {C.A. Goldstein; University of Michigan, Sleep Disorders Center, C728 Med Inn Building, Ann Arbor, 1500 E. Medical Center Drive, SPC5845, 48109-5845, United States; email: cathygo@med.umich.edu},
	publisher = {American Academy of Sleep Medicine},
	issn = {15509389},
	pmid = {32065113},
	language = {English},
	abbrev_source_title = {J. Clin. Sleep Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Heinrichs20201435,
	author = {Heinrichs, Bert and Eickhoff, Simon B.},
	title = {Your evidence? Machine learning algorithms for medical diagnosis and prediction},
	year = {2020},
	journal = {Human Brain Mapping},
	volume = {41},
	number = {6},
	pages = {1435 – 1444},
	doi = {10.1002/hbm.24886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076092985&doi=10.1002%2fhbm.24886&partnerID=40&md5=344c461f5dcdb9aa616fb72b8c7026c1},
	affiliations = {Institute of Neurosciences and Medicine, Ethics in the Neurosciences (INM-8), Research Center Jülich, Jülich, Germany; Institute of Science and Ethics (IWE), University of Bonn, Bonn, Germany; Institute of Systems Neuroscience, Medical Faculty, Heinrich Heine University Düsseldorf, Düsseldorf, Germany; Institute of Neuroscience and Medicine, Brain & Behaviour (INM-7), Research Center Jülich, Jülich, Germany},
	abstract = {Computer systems for medical diagnosis based on machine learning are not mere science fiction. Despite undisputed potential benefits, such systems may also raise problems. Two (interconnected) issues are particularly significant from an ethical point of view: The first issue is that epistemic opacity is at odds with a common desire for understanding and potentially undermines information rights. The second (related) issue concerns the assignment of responsibility in cases of failure. The core of the two issues seems to be that understanding and responsibility are concepts that are intrinsically tied to the discursive practice of giving and asking for reasons. The challenge is to find ways to make the outcomes of machine learning algorithms compatible with our discursive practice. This comes down to the claim that we should try to integrate discursive elements into machine learning algorithms. Under the title of “explainable AI” initiatives heading in this direction are already under way. Extensive research in this field is needed for finding adequate solutions. © 2019 The Authors. Human Brain Mapping published by Wiley Periodicals, Inc.},
	author_keywords = {discursive practice; epistemic opacity; explainability; machine learning; medical diagnosis; medical ethics; medical prediction; responsibility; understanding},
	keywords = {Algorithms; Artificial Intelligence; Confidentiality; Diagnosis, Computer-Assisted; Evidence-Based Medicine; Humans; Machine Learning; Magnetic Resonance Imaging; Article; artificial intelligence; brain mapping; cerebrovascular accident; comprehension; computer assisted diagnosis; convolutional neural network; deep neural network; human; knowledge; learning algorithm; machine learning; medical decision making; medical ethics; medical expert; medical practice; neuroimaging; physician; prediction; priority journal; publication; responsibility; science; shared decision making; algorithm; computer assisted diagnosis; confidentiality; ethics; evidence based medicine; machine learning; nuclear magnetic resonance imaging},
	correspondence_address = {B. Heinrichs; Institute of Neurosciences and Medicine, Ethics in the Neurosciences (INM-8), Research Center Jülich, Jülich, Germany; email: b.heinrichs@fz-juelich.de},
	publisher = {John Wiley and Sons Inc.},
	issn = {10659471},
	coden = {HBMAE},
	pmid = {31804003},
	language = {English},
	abbrev_source_title = {Hum. Brain Mapp.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 44; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Milne2020,
	author = {Milne, Richard and Brayne, Carol},
	title = {We need to think about data governance for dementia research in a digital era},
	year = {2020},
	journal = {Alzheimer's Research and Therapy},
	volume = {12},
	number = {1},
	doi = {10.1186/s13195-020-0584-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078825982&doi=10.1186%2fs13195-020-0584-y&partnerID=40&md5=0152b648b2d9718b29abaa4bdda1d8c4},
	affiliations = {Society and Ethics Research Group, Wellcome Genome Campus, Hinxton, United Kingdom; Institute of Public Health, University of Cambridge, Cambridge, United Kingdom},
	abstract = {Background: Research into Alzheimer's disease and other dementias increasingly involves large-scale data-sharing initiatives. The development of novel digital tools and assessments is likely to increase the need for these. This presents ethics and governance challenges to ensure the use of these data is able to maximise the benefit to patients and the public. Discussion: We consider the challenges associated with informed consent and governance in the context of dementia research. We set out the potential of novel data governance approaches for the future of data sharing for dementia. Summary: The data trust model proposed in discussions of data governance may have potentially valuable application for dementia research. Such inclusive approaches to trustworthy data governance should be considered as data-sharing initiatives are established and develop. © 2020 The Author(s).},
	author_keywords = {Data governance; Data sharing; Data trust; Dementia; Digital health; Ethics},
	keywords = {Big Data; Biomedical Research; Dementia; Humans; Information Dissemination; Informed Consent; Machine Learning; Article; clinical assessment; clinical research; conceptual framework; dementia; health care access; human; information dissemination; informed consent; medical record review; priority journal; prospective study; research ethics; ethics; information dissemination; informed consent; legislation and jurisprudence; machine learning; medical research; procedures},
	correspondence_address = {R. Milne; Society and Ethics Research Group, Wellcome Genome Campus, Hinxton, United Kingdom; email: rm23@sanger.ac.uk},
	publisher = {BioMed Central Ltd.},
	issn = {17589193},
	pmid = {32005135},
	language = {English},
	abbrev_source_title = {Alzheimers Res. Ther.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{McKee2020110,
	author = {McKee, Heidi A. and Porter, James E.},
	title = {Ethics for AI writing: The importance of rhetorical context},
	year = {2020},
	journal = {AIES 2020 - Proceedings of the AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {110 – 116},
	doi = {10.1145/3375627.3375811},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082176219&doi=10.1145%2f3375627.3375811&partnerID=40&md5=c9bbe9e9531ed14cd40f5e65ff91db74},
	affiliations = {English, Miami University, Oxford, OH, United States; English / Emerging Technology in Business and Design, Miami University, Oxford, OH, United States},
	abstract = {Implicit in any rhetorical interaction-between humans or between humans and machines-are ethical codes that shape the rhetorical context, the social situation in which communication happens and also the engine that drives communicative interaction. Such implicit codes are usually invisible to AI writing systems because the social factors shaping communication (the why and how of language, not the what) are not usually explicitly evident in databases the systems use to produce discourse. Can AI writing systems learn to learn rhetorical context, particularly the implicit codes for communication ethics? We see evidence that some systems do address issues of rhetorical context, at least in rudimentary ways. But we critique the information transfer communication model supporting many AI writing systems, arguing for a social context model that accounts for rhetorical context-what is, in a sense, "not there" in the data corpus but that is critical for the production of meaningful, significant, and ethical communication. We offer two ethical principles to guide design of AI writing systems: transparency about machine presence and critical data awareness, a methodological reflexivity about rhetorical context and omissions in the data that need to be provided by a human agent or accounted for in machine learning. © 2020 Copyright held by the owner/author(s).},
	author_keywords = {AI writing systems; Communication ethics; Critical date awareness; Ethics; Information transfer model; Language models; Machine ethics; Rhetoric; Rhetorical context; Social context model; Text generation; Transparency},
	keywords = {Codes (symbols); Digital storage; Ethical aspects; Transparency; Communication ethics; Critical date awareness; Information transfers; Language model; Rhetoric; Rhetorical context; Social context; Text generations; Writing systems; Data communication systems},
	correspondence_address = {H.A. McKee; English, Miami University, Oxford, United States; email: mckeeha@miamioh.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145037110-0},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 3rd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2020, co-located with AAAI 2020; Conference date: 7 February 2020 through 8 February 2020; Conference code: 158220}
}

@CONFERENCE{Lang2020655,
	author = {Lang, Charles and Woo, Charlotte and Sinclair, Jeanne},
	title = {Quantifying data sensitivity: Precise demonstration of care when building student prediction models},
	year = {2020},
	journal = {ACM International Conference Proceeding Series},
	pages = {655 – 664},
	doi = {10.1145/3375462.3375506},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082398785&doi=10.1145%2f3375462.3375506&partnerID=40&md5=fc43be996fa7abc3b64630f0bba27bfa},
	affiliations = {Teachers College, Columbia University, New York, NY, United States; Graduate School of Education, Stanford University, Stanford, CA, United States; Dreeben School of Education, University of the Incarnate Word, San Antonio, TX, United States},
	abstract = {Until recently an assumption within the predictive modelling community has been that collecting more student data is always better. But in reaction to recent high profile data privacy scandals, many educators, scholars, students and administrators have been questioning the ethics of such a strategy. Suggestions are growing that the minimum amount of data should be collected to aid the function for which a prediction is being made. Yet, machine learning algorithms are primarily judged on metrics derived from prediction accuracy or whether they meet probabilistic criteria for significance. They are not routinely judged on whether they utilize the minimum number of the least sensitive features, preserving what we name here as data collection parsimony. We believe the ability to assess data collection parsimony would be a valuable addition to the suite of evaluations for any prediction strategy and to that end, the following paper provides an introduction to data collection parsimony, describes a novel method for quantifying the concept using empirical Bayes estimates and then tests the metric on real world data. Both theoretical and empirical benefits and limitations of this method are discussed. We conclude that for the purpose of model building this metric is superior to others in several ways, but there are some hurdles to effective implementation. © 2020 Copyright held by the owner/author(s).},
	author_keywords = {Data collection parsimony; Data privacy; Data sensitivity; Empirical Bayes; Ethics; Prediction models; Student models},
	keywords = {Data privacy; Ethical aspects; Forecasting; Learning algorithms; Machine learning; Philosophical aspects; Predictive analytics; Students; Data collection; Data sensitivity; Empirical Bayes; Prediction model; Student Models; Data acquisition},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037712-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 10th International Conference on Learning Analytics and Knowledge: Shaping the Future of the Field, LAK 2020; Conference date: 23 March 2020 through 27 March 2020; Conference code: 158456}
}

@ARTICLE{Bauer2020263,
	author = {Bauer, William A.},
	title = {Virtuous vs. utilitarian artificial moral agents},
	year = {2020},
	journal = {AI and Society},
	volume = {35},
	number = {1},
	pages = {263 – 271},
	doi = {10.1007/s00146-018-0871-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85058244330&doi=10.1007%2fs00146-018-0871-3&partnerID=40&md5=8b045f4e5943275485b98f1a87dfd1cb},
	affiliations = {Department of Philosophy and Religious Studies, North Carolina State University, 340 Withers Hall, Campus Box 8103, Raleigh, 27695, NC, United States},
	abstract = {Given that artificial moral agents—such as autonomous vehicles, lethal autonomous weapons, and automated trading systems—are now part of the socio-ethical equation, we should morally evaluate their behavior. How should artificial moral agents make decisions? Is one moral theory better suited than others for machine ethics? After briefly overviewing the dominant ethical approaches for building morality into machines, this paper discusses a recent proposal, put forward by Don Howard and Ioan Muntean (2016, 2017), for an artificial moral agent based on virtue theory. While the virtuous artificial moral agent has various strengths, this paper argues that a rule-based utilitarian approach (in contrast to a strict act utilitarian approach) is superior, because it can capture the most important features of the virtue-theoretic approach while realizing additional significant benefits. Specifically, a two-level utilitarian artificial moral agent incorporating both established moral rules and a utility calculator is especially well suited for machine ethics. © 2018, Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Artificial moral agent; Machine ethics; Machine learning; Two-level utilitarianism; Virtue theory},
	keywords = {Learning systems; Philosophical aspects; Automated trading systems; Important features; Moral agents; Moral theory; Rule based; Two-level utilitarianism; Virtue theory; Autonomous agents},
	correspondence_address = {W.A. Bauer; Department of Philosophy and Religious Studies, North Carolina State University, Raleigh, 340 Withers Hall, Campus Box 8103, 27695, United States; email: wabauer@ncsu.edu},
	publisher = {Springer},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Villongco2020105,
	author = {Villongco, Christopher and Khan, Fazal},
	title = {“Sorry I Didn’t Hear You.” The Ethics of Voice Computing and AI in High Risk Mental Health Populations},
	year = {2020},
	journal = {AJOB Neuroscience},
	volume = {11},
	number = {2},
	pages = {105 – 112},
	doi = {10.1080/21507740.2020.1740355},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082790710&doi=10.1080%2f21507740.2020.1740355&partnerID=40&md5=df31592f9434501f87cfdadd2ff7651d},
	affiliations = {Morehouse School of Medicine, United States; University of Georgia School of Law, United States},
	abstract = {This article examines the ethical and policy implications of using voice computing and artificial intelligence to screen for mental health conditions in low income and minority populations. Mental health is unequally distributed among these groups, which is further exacerbated by increased barriers to psychiatric care. Advancements in voice computing and artificial intelligence promise increased screening and more sensitive diagnostic assessments. Machine learning algorithms have the capacity to identify vocal features that can screen those with depression. However, in order to screen for mental health pathology, computer algorithms must first be able to account for the fundamental differences in vocal characteristics between low income minorities and those who are not. While researchers have envisioned this technology as a beneficent tool, this technology could be repurposed to scale up discrimination or exploitation. Studies on the use of big data and predictive analytics demonstrate that low income minority populations already face significant discrimination. This article urges researchers developing AI tools for vulnerable populations to consider the full ethical, legal, and social impact of their work. Without a national, coherent framework of legal regulations and ethical guidelines to protect vulnerable populations, it will be difficult to limit AI applications to solely beneficial uses. Without such protections, vulnerable populations will rightfully be wary of participating in such studies which also will negatively impact the robustness of such tools. Thus, for research involving AI tools like voice computing, it is in the research community’s interest to demand more guidance and regulatory oversight from the federal government. © 2020, © 2020 Taylor & Francis Group, LLC.},
	author_keywords = {Computers; mental health; psychiatry; representations},
	keywords = {Artificial Intelligence; Bioethics; Humans; Mental Disorders; Mentally Ill Persons; Minority Groups; Poverty; Speech Recognition Software; artificial intelligence; automatic speech recognition; bioethics; ethics; human; mental disease; mental patient; minority group; poverty},
	correspondence_address = {C. Villongco; Morehouse School of Medicine, Atlanta, 30310-1458, United States; email: cvillongco@msm.edu},
	publisher = {Taylor and Francis Inc.},
	issn = {21507740},
	pmid = {32228383},
	language = {English},
	abbrev_source_title = {AJOB Neurosci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Bustreo2020232,
	author = {Bustreo, Flavia and Tanner, Marcel},
	title = {How do we reimagine health in a digital age?},
	year = {2020},
	journal = {Bulletin of the World Health Organization},
	volume = {98},
	number = {4},
	pages = {232},
	doi = {10.2471/BLT.19.235358},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083104384&doi=10.2471%2fBLT.19.235358&partnerID=40&md5=8f58e0d1d57afbef69071d3206e6d162},
	affiliations = {Fondation Botnar, St. Alban-Vorstadt 56, Basel, 4052, Switzerland},
	keywords = {Digital Divide; Digital Technology; Human Rights; Public Health; Public-Private Sector Partnerships; adolescence; age; artificial intelligence; decision making; Editorial; global health; health care; health care access; health care organization; health care quality; health equity; health service; human; human rights; machine learning; medical research; public health; sustainable development; technology; digital divide; ethics; public health; public-private partnership},
	correspondence_address = {F. Bustreo; Fondation Botnar, Basel, St. Alban-Vorstadt 56, 4052, Switzerland; email: flaviabustreo@gmail.com},
	publisher = {World Health Organization},
	issn = {00429686},
	coden = {BWHOA},
	pmid = {32284642},
	language = {English},
	abbrev_source_title = {Bull. WHO},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Robbins2020391,
	author = {Robbins, Scott},
	title = {AI and the path to envelopment: knowledge as a first step towards the responsible regulation and use of AI-powered machines},
	year = {2020},
	journal = {AI and Society},
	volume = {35},
	number = {2},
	pages = {391 – 400},
	doi = {10.1007/s00146-019-00891-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074574493&doi=10.1007%2fs00146-019-00891-1&partnerID=40&md5=7ebe8bbbc7560ad52df02b86b3d59cd6},
	affiliations = {Ethics and Philosophy of Technology, Faculty of Technology, Policy, and Management, Delft University of Technology, Jaffalaan 5, Delft, 2628 BX, Netherlands},
	abstract = {With Artificial Intelligence (AI) entering our lives in novel ways—both known and unknown to us—there is both the enhancement of existing ethical issues associated with AI as well as the rise of new ethical issues. There is much focus on opening up the ‘black box’ of modern machine-learning algorithms to understand the reasoning behind their decisions—especially morally salient decisions. However, some applications of AI which are no doubt beneficial to society rely upon these black boxes. Rather than requiring algorithms to be transparent we should focus on constraining AI and those machines powered by AI within microenvironments—both physical and virtual—which allow these machines to realize their function whilst preventing harm to humans. In the field of robotics this is called ‘envelopment’. However, to put an ‘envelope’ around AI-powered machines we need to know some basic things about them which we are often in the dark about. The properties we need to know are the: training data, inputs, functions, outputs, and boundaries. This knowledge is a necessary first step towards the envelopment of AI-powered machines. It is only with this knowledge that we can responsibly regulate, use, and live in a world populated by these machines. © 2019, The Author(s).},
	author_keywords = {AI ethics; Machine ethics; Meaningful human control; Robot ethics},
	keywords = {Ethical aspects; Learning algorithms; Virtual reality; Applications of AI; Black boxes; Ethical issues; Human control; Microenvironments; Modern machines; Robot ethics; Training data; Machine learning},
	correspondence_address = {S. Robbins; Ethics and Philosophy of Technology, Faculty of Technology, Policy, and Management, Delft University of Technology, Delft, Jaffalaan 5, 2628 BX, Netherlands; email: scott@scottrobbins.org},
	publisher = {Springer},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26; All Open Access, Hybrid Gold Open Access}
}

@BOOK{McCormick2020155,
	author = {McCormick, Kathleen A.},
	title = {Precision health and genomics},
	year = {2020},
	journal = {Emerging Technologies for Nurses: Implications for Practice},
	pages = {155 – 184},
	doi = {10.1891/9780826146519.0006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85109674561&doi=10.1891%2f9780826146519.0006&partnerID=40&md5=ed0a010396d13b9c4bfbe21a063df733},
	affiliations = {SciMind, LLC, MD, United States},
	abstract = {The force in this century that is bringing us into the Fourth Industrial Revolution requiring artificial intelligence (AI), machine learning, robotics, clouds, and Big Data is the human genome. The human genome has only been known since 2001, but it is now expanding in the areas of prevention, diagnosis, and treatment throughout the continuum of care from preconception to end of life. The volume of data is increasing and necessitating secure clouds for storage and AI to span the multiple databases containing genetic reference data, imaging data, and clinical electronic health records. This chapter describes the necessary definitions to understand Precision Health, genomics, pharmacogenomics, and some common examples of genomics throughout the continuum of care with a focus on symptom management and pharmacogenomics. It discusses informatics needs for bioinformatics and Precision Health. The chapter provides specific nursing recommendations. Barriers and challenges include nursing education, ethics, culture in society, and reimbursement. © 2021 Springer Publishing Company, LLC.},
	author_keywords = {Artificial intelligence; Bioinformatics; Continuum of care; Genomics; Human genome; Machine learning; Nursing education; Pharmacogenomics; Precision health; Symptom management},
	publisher = {Springer Publishing Company},
	isbn = {978-082614651-9; 978-082614649-6},
	language = {English},
	abbrev_source_title = {Emerg. Technologies for Nurses: Implications for Practice},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Vaisman2020288,
	author = {Vaisman, Alon and Linder, Nina and Lundin, Johan and Orchanian-Cheff, Ani and Coulibaly, Jean T. and Ephraim, Richard K. D. and Bogoch, Isaac I.},
	title = {Artificial intelligence, diagnostic imaging and neglected tropical diseases: Ethical implications},
	year = {2020},
	journal = {Bulletin of the World Health Organization},
	volume = {98},
	number = {4},
	pages = {288 – 289},
	doi = {10.2471/BLT.19.237560},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083245662&doi=10.2471%2fBLT.19.237560&partnerID=40&md5=d1e85cc44c47e6fcf36b47a4b231dfaa},
	affiliations = {Division Infectious Diseases, Toronto General Hospital, University of Toronto, 14EN 209, 200 Elizabeth Street, Toronto, M5G 2C4, ON, Canada; Department of Women's and Children's Health, International Maternal and Child health, Uppsala University, Sweden; Department of Global Public Health, Karolinska Institutet, Stockholm, Sweden; Health Sciences Library, University Health Network, Toronto, Canada; Unité de Formation et de Recherche Biosciences, Université Félix Houphouët-Boigny, Abidjan, Cote d'Ivoire; Department of Medical Laboratory Sciences, University of Cape Coast, Cape Coast, Ghana},
	keywords = {Artificial Intelligence; Diagnostic Imaging; Humans; Neglected Diseases; Tropical Medicine; artificial intelligence; clinical decision making; diagnostic imaging; disease surveillance; disease transmission; geographic distribution; government; health care delivery; health care planning; health survey; human; machine learning; medical research; morbidity; mortality; Note; public health; stakeholder engagement; tropical disease; artificial intelligence; diagnostic imaging; ethics; neglected disease; tropical medicine},
	correspondence_address = {I.I. Bogoch; Division Infectious Diseases, Toronto General Hospital, University of Toronto, Toronto, 14EN 209, 200 Elizabeth Street, M5G 2C4, Canada; email: isaac.bogoch@uhn.ca},
	publisher = {World Health Organization},
	issn = {00429686},
	coden = {BWHOA},
	pmid = {32284655},
	language = {English},
	abbrev_source_title = {Bull. WHO},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{2020,
	title = {Proceedings - 2020 7th Swiss Conference on Data Science, SDS 2020},
	year = {2020},
	journal = {Proceedings - 2020 7th Swiss Conference on Data Science, SDS 2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094982501&partnerID=40&md5=0073d4c3d82e7661b5d0b1da745fbbd1},
	abstract = {The proceedings contain 18 papers. The topics discussed include: annotating web tables through knowledge bases: a context-based approach; effects of graph pooling layers on classification with graph neural networks; improving sample efficiency and multi-agent communication in RL-based train rescheduling; data resources to create digital twins; uncertainty with deep learning: a practical view on out of distribution detection; a comparative assessment and synthesis of twenty ethics codes on AI and big data; same same but different: augmentation of tiny industrial datasets using generative adversarial networks; and assessing the democratic legitimacy of public decisions based on machine learning algorithms.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172817177-7},
	language = {English},
	abbrev_source_title = {Proc. - Swiss Conf. Data Sci., SDS},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 7th Swiss Conference on Data Science, SDS 2020; Conference date: 26 June 2020; Conference code: 161964}
}

@ARTICLE{Jin2020327,
	author = {Jin, Ik Sup and Yoon, Moon Sup and Park, Chun-Woong and Hong, Jin Tae and Chung, Youn Bok and Kim, Jin-Seok and Shin, Dae Hwan},
	title = {Replacement techniques to reduce animal experiments in drug and nanoparticle development},
	year = {2020},
	journal = {Journal of Pharmaceutical Investigation},
	volume = {50},
	number = {3},
	pages = {327 – 335},
	doi = {10.1007/s40005-020-00487-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084038922&doi=10.1007%2fs40005-020-00487-8&partnerID=40&md5=79c95398ab469929d11eb326ca136902},
	affiliations = {College of Pharmacy, Chungbuk National University, Cheongju, 28160, South Korea; Drug Information Research Institute, College of Pharmacy, Sookmyung Women’s University, Seoul, 04310, South Korea},
	abstract = {Background: Animals have been used for the testing of new drugs and nanoparticles to determine their safety and effectiveness before application in humans. Numerous drugs and nanoparticles have been developed through animal tests, and development in medical nanotechnology is progressing rapidly. However, a good experiment requires many animals. The primary measures to reduce animal experiments include reducing the number of animals used in each experiment and replacing laboratory animals with inanimate, cellular, or inferior animals to reduce sacrifices. Area covered: Developing nanoparticles using simulations rather than experiments may be another alternative. Instead of animals, human cells or animal-derived organs, tissues, or cells could be used in experiments. These methods allow rapid toxicity and efficacy testing at low cost. However, the disadvantage of these methods is that they cannot accurately replicate the complex interrelationships between human organs, biological reactions to specific routes of administration, or toxicity of substances resulting from metabolic processes. To overcome these shortcomings of in vitro tests, new technologies such as organoids and organ-on-chips are progressing. These can be used to quickly examine the efficacy of newly developed drugs and nanoparticles and can be useful in developing patient-tailored agents. Expert opinion: These technologies offer some promise but it is still difficult to entirely replace animal experiments. However, the scope of methods to replace experimental animals is widening, suggesting the potential to refine, reduce, and ultimately replace animal testing. © 2020, The Korean Society of Pharmaceutical Sciences and Technology.},
	author_keywords = {Animal ethics; Animal experiment replacement; Biochip; Drug development; Nanoparticle; Organoid},
	keywords = {capecitabine; cell penetrating peptide; cystic fibrosis transmembrane conductance regulator; erlotinib; fluorouracil; gold nanoparticle; hydrogel; interleukin 2; nanoparticle; olaparib; oxaliplatin; quercetin; animal experiment; blood brain barrier; cancer chemotherapy; cell proliferation; computer model; decision tree; drug delivery system; drug formulation; flow kinetics; gene editing; gene expression; IC50; immunogenicity; LD50; machine learning; microfluidic analysis; molecular dynamics; nanomedicine; nanotechnology; nonhuman; pH; pharmacy (shop); priority journal; quantitative structure activity relation; Review; shear stress; support vector machine; TD50; tissue engineering; toxicity testing; virus replication; Western blotting},
	correspondence_address = {D.H. Shin; College of Pharmacy, Chungbuk National University, Cheongju, 28160, South Korea; email: dshin@chungbuk.ac.kr},
	publisher = {Springer},
	issn = {20935552},
	language = {English},
	abbrev_source_title = {J. Pharma. Invest.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Sini2020,
	author = {Sini, Jacopo and Marceddu, Antonio Costantino and Violante, Massimo},
	title = {Automatic emotion recognition for the calibration of autonomous driving functions},
	year = {2020},
	journal = {Electronics (Switzerland)},
	volume = {9},
	number = {3},
	doi = {10.3390/electronics9030518},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084235012&doi=10.3390%2felectronics9030518&partnerID=40&md5=a0c76a1a22a9d63d2fd3976fcb7826e7},
	affiliations = {Department of Control and Computer Engineering, Politecnico di Torino, Turin, 10129, Italy},
	abstract = {The development of autonomous driving cars is a complex activity, which poses challenges about ethics, safety, cybersecurity, and social acceptance. The latter, in particular, poses new problems since passengers are used to manually driven vehicles; hence, they need to move their trust from a person to a computer. To smooth the transition towards autonomous vehicles, a delicate calibration of the driving functions should be performed, making the automation decision closest to the passengers’ expectations. The complexity of this calibration lies in the presence of a person in the loop: different settings of a given algorithm should be evaluated by assessing the human reaction to the vehicle decisions. With this work, we for an objective method to classify the people’s reaction to vehicle decisions. By adopting machine learning techniques, it is possible to analyze the passengers’ emotions while driving with alternative vehicle calibrations. Through the analysis of these emotions, it is possible to obtain an objective metric about the comfort feeling of the passengers. As a result, we developed a proof-of-concept implementation of a simple, yet effective, emotions recognition system. It can be deployed either into real vehicles or simulators, during the driving functions calibration. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Artificial neural networks; Automotive applications; Autonomous vehicles; Emotion recognition; Machine learning},
	correspondence_address = {J. Sini; Department of Control and Computer Engineering, Politecnico di Torino, Turin, 10129, Italy; email: jacopo.sini@polito.it},
	publisher = {MDPI AG},
	issn = {20799292},
	language = {English},
	abbrev_source_title = {Electronics (Switzerland)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access}
}

@ARTICLE{Nardini2020,
	author = {Nardini, Cecilia},
	title = {Machine learning in oncology: A review},
	year = {2020},
	journal = {ecancermedicalscience},
	volume = {14},
	doi = {10.3332/ECANCER.2020.1065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093884408&doi=10.3332%2fECANCER.2020.1065&partnerID=40&md5=4a57092f892121de9c5ded8c760006be},
	affiliations = {European School of Molecular Medicine (SEMM), Milan, 20139, Italy},
	abstract = {Machine learning is a set of techniques that promise to greatly enhance our data-processing capability. In the field of oncology, ML presents itself with a wealth of possible applications to the research and the clinical context, such as automated diagnosis and precise treatment modulation. In this paper, we will review the principal applications of ML techniques in oncology and explore in detail how they work. This will allow us to discuss the issues and challenges that ML faces in this field, and ultimately gain a greater understanding of ML techniques and how they can improve oncological research and practice. © 2020 ecancer Global Foundation. All rights reserved.},
	author_keywords = {Big data; Deep learning; Ethics; Image recognition; Machine learning; Methodology; Neural network},
	keywords = {artificial neural network; big data; cancer size; deep learning; ethics; review},
	correspondence_address = {C. Nardini; European School of Molecular Medicine (SEMM), Milan, 20139, Italy; email: nardini.folsatec@gmail.com},
	publisher = {ecancer Global Foundation},
	issn = {17546605},
	language = {English},
	abbrev_source_title = {ecancermedicalscience},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hunter2020,
	author = {Hunter, Philip},
	title = {The “industrial” revolution in biomedical research: Data explosion and reproducibility crisis drive changes in lab workflows},
	year = {2020},
	journal = {EMBO Reports},
	volume = {21},
	number = {2},
	doi = {10.15252/embr.202050003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078725609&doi=10.15252%2fembr.202050003&partnerID=40&md5=81cd2f1435b5a082f743c01a0c9ac49c},
	affiliations = {Freelance Journalist in, London, United Kingdom},
	keywords = {Biomedical Research; Explosions; Laboratories; Reproducibility of Results; Workflow; automation; human; machine learning; medical ethics; medical research; Note; priority journal; workflow; explosion; laboratory; reproducibility},
	correspondence_address = {P. Hunter; Freelance Journalist in, London, United Kingdom; email: ph@philiphunter.com},
	publisher = {Wiley-VCH Verlag},
	issn = {1469221X},
	coden = {ERMEA},
	pmid = {31984601},
	language = {English},
	abbrev_source_title = {EMBO Rep.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Card2020,
	author = {Card, Dallas and Smith, Noah A.},
	title = {On Consequentialism and Fairness},
	year = {2020},
	journal = {Frontiers in Artificial Intelligence},
	volume = {3},
	doi = {10.3389/frai.2020.00034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098421090&doi=10.3389%2ffrai.2020.00034&partnerID=40&md5=e54555fe9ae9458d148405e2255f7826},
	affiliations = {Computer Science Department, Stanford University, Stanford, CA, United States; Paul G. Allen School of Computer Science & Engineering, University of Washington, Seattle, WA, United States; Allen Institute for AI, Seattle, WA, United States},
	abstract = {Recent work on fairness in machine learning has primarily emphasized how to define, quantify, and encourage “fair” outcomes. Less attention has been paid, however, to the ethical foundations which underlie such efforts. Among the ethical perspectives that should be taken into consideration is consequentialism, the position that, roughly speaking, outcomes are all that matter. Although consequentialism is not free from difficulties, and although it does not necessarily provide a tractable way of choosing actions (because of the combined problems of uncertainty, subjectivity, and aggregation), it nevertheless provides a powerful foundation from which to critique the existing literature on machine learning fairness. Moreover, it brings to the fore some of the tradeoffs involved, including the problem of who counts, the pros and cons of using a policy, and the relative value of the distant future. In this paper we provide a consequentialist critique of common definitions of fairness within machine learning, as well as a machine learning perspective on consequentialism. We conclude with a broader discussion of the issues of learning and randomization, which have important implications for the ethics of automated decision making systems. © Copyright © 2020 Card and Smith.},
	author_keywords = {consequentialism; ethics; fairness; machine learning; randomization},
	correspondence_address = {D. Card; Computer Science Department, Stanford University, Stanford, United States; email: dcard@stanford.edu},
	publisher = {Frontiers Media S.A.},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Carter202060,
	author = {Carter, Denise},
	title = {Regulation and ethics in artificial intelligence and machine learning technologies: Where are we now? Who is responsible? Can the information professional play a role?},
	year = {2020},
	journal = {Business Information Review},
	volume = {37},
	number = {2},
	pages = {60 – 68},
	doi = {10.1177/0266382120923962},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084506551&doi=10.1177%2f0266382120923962&partnerID=40&md5=a20047a2efa9b7d2d31fcb11df94728c},
	affiliations = {DCision Consult, Switzerland},
	abstract = {Artificial intelligence (AI) and machine learning (ML) technologies are rapidly maturing and proliferating through all public and private sectors. The potential for these technologies to do good and to help us in our everyday lives is immense. But there is a risk that unless managed and controlled AI can also cause us harm. Questions about regulation, what form it takes and who is responsible for governance are only just beginning to be answered. In May 2019, 42 countries came together to support a global governance framework for AI. The Organisation for Economic Co-operation and Development (OECD) Principles on Artificial Intelligence (OECD (2019) OECD principles on AI. Available at: https://www.oecd.org/going-digital/ai/principles/ (accessed 2 March 2020)) saw like-minded democracies of the world commit to common AI values of trust and respect. In Europe, the European Commission’s (EC) new president, Ursula von der Leyen has made calls for a General Data Protection Regulation style. As a first step the EC has published a white paper: ‘On Artificial Intelligence – A European Approach to Excellence and Trust’ (European Commission (2020) Report, Europa, February). In February 2020, the UK government has published a report on ‘Artificial Intelligence in the Public Sector’ (The Committee on Standards in Public Life (2020) Artificial intelligence and public standards. Report, UK Government, February). This article discusses some of the potential threats AI may hold if left unregulated. It provides a brief overview of the regulatory activities for AI worldwide, and in more detail the current UK AI regulatory landscape. Finally, the article looks at the role that the information professional might play in AI and ML. © The Author(s) 2020.},
	author_keywords = {Artificial intelligence (AI); ethics; machine learning (ML); regulation; skills},
	correspondence_address = {D. Carter; DCision Consult, Switzerland; email: denise.carter@dcisionconsult.com},
	publisher = {SAGE Publications Ltd},
	issn = {02663821},
	language = {English},
	abbrev_source_title = {Bus. Inf. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Brady2020,
	author = {Brady, Adrian P. and Neri, Emanuele},
	title = {Artificial intelligence in radiology-ethical considerations},
	year = {2020},
	journal = {Diagnostics},
	volume = {10},
	number = {4},
	doi = {10.3390/diagnostics10040231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083756977&doi=10.3390%2fdiagnostics10040231&partnerID=40&md5=83e20b3ee8b8a17d5c4836898e8271ab},
	affiliations = {Radiology Department, Mercy University Hospital, Cork, T12 WE28, Ireland; European Society of Radiology (ESR), Am Gestade 1, Vienna, 1010, Austria; Diagnostic and Interventional Radiology, Department of Translational Research, University of Pisa, Via Roma, 67, Pisa, 56126, Italy},
	abstract = {Artificial intelligence (AI) is poised to change much about the way we practice radiology in the near future. The power of AI tools has the potential to offer substantial benefit to patients. Conversely, there are dangers inherent in the deployment of AI in radiology, if this is done without regard to possible ethical risks. Some ethical issues are obvious; others are less easily discerned, and less easily avoided. This paper explains some of the ethical difficulties of which we are presently aware, and some of the measures we may take to protect against misuse of AI. © 2020 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {Artificial intelligence; Machine learning; Radiology ethics},
	keywords = {article; artificial intelligence; ethics; human; machine learning; radiology},
	correspondence_address = {A.P. Brady; Radiology Department, Mercy University Hospital, Cork, T12 WE28, Ireland; email: adrianbrady@me.com},
	publisher = {MDPI},
	issn = {20754418},
	language = {English},
	abbrev_source_title = {Diagn.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 34; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Wanner2020,
	author = {Wanner, Jonas and Herm, Lukas-Valentin and Langer, Marvin and Imgrund, Florian and Janiesch, Christian},
	title = {A moral consensus mechanism for autonomous driving: Towards a law-compliant basis of logic programming},
	year = {2020},
	journal = {Proceedings of the 15th International Conference on Business Information Systems 2020 "Developments, Opportunities and Challenges of Digitization", WIRTSCHAFTSINFORMATIK 2020},
	doi = {10.30844/wi_2020_a2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101662310&doi=10.30844%2fwi_2020_a2&partnerID=40&md5=86dda63104369dd5b0ab27e9c3880277},
	affiliations = {Julius-Maximilians-Universität Würzburg, Würzburg, Germany},
	abstract = {Research into autonomous vehicles is making progress. While implementation is progressing through machine learning and efficient sensor technology, one key challenge remains dealing with moral disputes. In general, traffic requires for moral decisions that might even decide on the life or death of participants. While people make intuitive decisions in accidents, a decision of an autonomous vehicle is made already at the programming stage. Thus, a concrete handling for implementation is needed. Due to a lack of legislation, this is still missing and prevents car manufacturers from a practical solution. The paper at hand addresses this problem by presenting a consensus mechanism, combining moral convictions, legislation, and programming guidelines. Based on a study of dilemma situations, moral principles of the'correct action' of autonomous vehicles are derived. Of four principles, we confirm one, reject two, and propose one for further research investigation to form a basis for jurisdictions. © Proceedings of the 15th International Conference on Business Information Systems 2020 "Developments, Opportunities and Challenges of Digitization", WIRTSCHAFTSINFORMATIK 2020.},
	author_keywords = {Ai ethics; Ai programming guidelines; Autonomous driving; Dilemma situations; Moral machine},
	keywords = {Accidents; Automobile manufacture; Information systems; Information use; Logic programming; Autonomous driving; Car manufacturers; Dilemma situation; Practical solutions; Sensor technologies; Still missing; Autonomous vehicles},
	publisher = {GITO Verlag},
	isbn = {978-395545335-0},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Bus. Inf. Syst. "Dev., Oppor. Challenges Digit.", WIRTSCHAFTSINFORMATIK},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Business Information Systems 2020: Developments, Opportunities and Challenges of Digitization, WIRTSCHAFTSINFORMATIK 2020; Conference date: 8 March 2020 through 11 March 2020; Conference code: 166591}
}

@ARTICLE{Pizzi2020145,
	author = {Pizzi, Michael and Romanoff, Mila and Engelhardt, Tim},
	title = {AI for humanitarian action: Human rights and ethics},
	year = {2020},
	journal = {International Review of the Red Cross},
	volume = {102},
	number = {913},
	pages = {145 – 180},
	doi = {10.1017/S1816383121000011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101967528&doi=10.1017%2fS1816383121000011&partnerID=40&md5=7d01401712e0a3537f49aa6fb0f0083b},
	affiliations = {Jain Family Institute; UN Global Pulse; Office of the UN High Commissioner for Human Rights},
	abstract = {Artificial intelligence (AI)-supported systems have transformative applications in the humanitarian sector but they also pose unique risks for human rights, even when used with the best intentions. Drawing from research and expert consultations conducted across the globe in recent years, this paper identifies key points of consensus on how humanitarian practitioners can ensure that AI augments - rather than undermines - human interests while being rights-respecting. Specifically, these consultations emphasized the necessity of an anchoring framework based on international human rights law as an essential baseline for ensuring that human interests are embedded in AI systems. Ethics, in addition, can play a complementary role in filling gaps and elevating standards above the minimum requirements of international human rights law. This paper summarizes the advantages of this framework, while also identifying specific tools and best practices that either already exist and can be adapted to the AI context, or that need to be created, in order to operationalize this human rights framework. As the COVID crisis has laid bare, AI will increasingly shape the global response to the world's toughest problems, especially in the development and humanitarian sector. To ensure that AI tools enable human progress and contribute to achieving the Sustainable Development Goals, humanitarian actors need to be proactive and inclusive in developing tools, policies and accountability mechanisms that protect human rights. © The Author(s), 2021. Published by Cambridge University Press on behalf of the ICRC.},
	author_keywords = {AI ethics; Artificial intelligence; Human rights; Humanitarian organizations; Humanitarianism; Machine learning},
	publisher = {Cambridge University Press},
	issn = {18163831},
	language = {English},
	abbrev_source_title = {Int. Rev. Red Cross},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{McKay202022,
	author = {McKay, Carolyn},
	title = {Predicting risk in criminal procedure: actuarial tools, algorithms, AI and judicial decision-making},
	year = {2020},
	journal = {Current Issues in Criminal Justice},
	volume = {32},
	number = {1},
	pages = {22 – 39},
	doi = {10.1080/10345329.2019.1658694},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082061906&doi=10.1080%2f10345329.2019.1658694&partnerID=40&md5=78d6787d0984493c9c20dea039da0e32},
	affiliations = {University of Sydney Law School, University of Sydney, Sydney, NSW, Australia},
	abstract = {Risk assessments are conducted at a number of decision points in criminal procedure including in bail, sentencing and parole as well as in determining extended supervision and continuing detention orders of high-risk offenders. Such risk assessments have traditionally been the function of the human discretion and intuition of judicial officers, based on clinical assessments, framed by legislation and common-law principles, and encapsulating the concept of individualised justice. Yet, the progressive technologisation of criminal procedure is witnessing the incursion of statistical, data-driven evaluations of risk. Human judicial evaluative functions are increasingly complemented by a range of actuarial, algorithmic, machine learning and Artificial Intelligence (AI) tools that purport to provide accurate predictive capabilities and objective, consistent risk assessments. But ethical concerns have been raised globally regarding algorithms as proprietary products with in-built statistical bias as well as the diminution of judicial human evaluation in favour of the machine. This article focuses on risk assessment and what happens when decision-making is delegated to a predictive tool. Specifically, this article scrutinises the inscrutable proprietary nature of such risk tools and how that may render the calculation of the risk score opaque and unknowable to both the offender and the court. © 2019, © 2019 Sydney Institute of Criminology.},
	author_keywords = {actuarial tools; algorithms; Artificial Intelligence (AI); criminal procedure; ethics; risk assessment},
	correspondence_address = {C. McKay; University of Sydney, New Law Building F10, 2006, Australia; email: carolyn.mckay@sydney.edu.au},
	publisher = {Routledge},
	issn = {10345329},
	language = {English},
	abbrev_source_title = {Curr. Issues  Crim.  Justice},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@ARTICLE{Tang2020134,
	author = {Tang, Tao and Fan, Yuzhuo and Xu, Qiong and Peng, Zisu and Wang, Kai and Zhao, Mingwei},
	title = {A study of the predictive effects of machine learning for the relationship between axial length elongation and the progression of myopia in school-aged children; [机器学习对青少年近视眼轴增长与近视度数增加关联性的预测作用]},
	year = {2020},
	journal = {Zhonghua Shiyan Yanke Zazhi/Chinese Journal of Experimental Ophthalmology},
	volume = {38},
	number = {2},
	pages = {134 – 139},
	doi = {10.3760/cma.j.issn.2095-0160.2020.02.010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082434730&doi=10.3760%2fcma.j.issn.2095-0160.2020.02.010&partnerID=40&md5=9cae471e3261f6299db52b6e80244737},
	affiliations = {Department of Ophthalmology & Clinical Centre of Optometry, Peking University People's Hospital, Eye Diseases and Optometry Institute, Beijing Key Laboratory of Diagnosis and Therapy of Retinal and Choroid Diseases, College of Optometry, Peking University Health Science Center, Beijing, 100044, China},
	abstract = {Objective: To investigate the relationship between axial length (AL)elongation and the progression of spherical equivalent refraction (SER) and its influential factors in school-aged children with myopia based on machine learning (ML). Methods: A cross-sectional study evaluated 1 011 eyes of school-aged myopic children admitted to the optometry center of Peking University People's Hospital from January 2017 to December 2018, and data from the right eyes were used for analysis.All the collected data were used to train ML algorithms.When building predictive models, the input features included age, gender, central corneal thickness (CCT), mean K readings (K-mean), horizontal visible iris diameter (HIVD), lens power, and axial length (AL), and the output parameter was SER.A five-fold cross validation scheme randomly divided all the data into five groups, of which four were used as training data, and one group was used as validation data.This process was repeated five times so that all the data were validated by this model, which allowed a better prediction of the overall sample.The prediction accuracy of different models was evaluated by the R-value and R2.The best-performing algorithm was applied to investigate the relationship between AL elongation and the progression of SER and its influencing factors.Written informed consent was obtained from each guardian of each patient prior to entering the study cohort.This study followed the Declaration of Helsinki.The study protocol was approved by the Ethics Committee of Peking University People's Hospital (No.2019PHB280-01). Results: In the comparison of the R-value and R2 of six ML algorithms based on five-fold cross validation, among all models, the best was the quadratic SVM regression model, with an R-value and R2 of 0.99 and 0.98, respectively.The results of Pearson correlation analysis showed that lens power was negatively correlated with age (r=-0.301, P<0.01). According to the results calculated by the Bennett-Rabbetts formula, the average lens power of the 6-year-old myopic group was higher than that of the 18-year-old myopic group.According to this model, the SER change caused by AL elongation was not a constant value, which was estimated from plano to nearly -3.00 D, depending mainly on the time needed for 1-mm AL elongation.According to the results calculated by this model, the longer it took for the AL to grow by 1 mm, the smaller the corresponding SER change.In myopic children over an age span of one year, for example, from 6-7 years or 12-13 years, 1-mm elongation of the AL corresponded to -2.50 D and -2.33 D of SER change, respectively.Over a three years span, for example, from 6-9 years, a 1-mm elongation of the AL corresponded to -1.77 D of SER change. Conclusions: For myopic children, the longer the age span required for 1-mm elongation of the AL, the smaller the SER change.An ML algorithm can provide clinical practitioners with a relatively precise estimation for the relationship between AL elongation and myopia progression. Copyright © 2020 by the Chinese Medical Association.},
	author_keywords = {Axial length; Machine learning; Myopia; Spherical equivalent refraction},
	keywords = {Article; central corneal thickness; child; cross-sectional study; eye axis length; horizontal visible iris diameter; hospital admission; human; informed consent; lens power; machine learning; major clinical study; myopia; optometry; university hospital; validation study; visual system parameters},
	correspondence_address = {K. Wang; Department of Ophthalmology & Clinical Centre of Optometry, Peking University People's Hospital, Eye Diseases and Optometry Institute, Beijing Key Laboratory of Diagnosis and Therapy of Retinal and Choroid Diseases, College of Optometry, Peking University Health Science Center, Beijing, 100044, China; email: wang_kai@263.net},
	publisher = {Henan Institute of Ophthalmology},
	issn = {20950160},
	language = {Chinese},
	abbrev_source_title = {Zhonghua Shiyan Yanke Zazhi Chin. J. Exp. Ophthalmol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Mei2020,
	author = {Mei, Zubing and Li, Yue and Zhang, Zhijun and Zhou, Haikun and Liu, Suzhi and Han, Ye and Du, Peixin and Qin, Xiufang and Shao, Zhuo and Ge, Maojun and Wang, Qingming and Yang, Wei},
	title = {Development of screening tools to predict the risk of recurrence and related complications following anal fistula surgery: Protocol for a prospective cohort study},
	year = {2020},
	journal = {BMJ Open},
	volume = {10},
	number = {3},
	doi = {10.1136/bmjopen-2019-035134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081210361&doi=10.1136%2fbmjopen-2019-035134&partnerID=40&md5=3f482cd1a27026be67358d1960c3db25},
	affiliations = {Department of Anorectal Surgery, Shuguang Hospital, Shanghai University of Traditional Chinese Medicine, Anorectal Disease Institute of Shuguang Hospital, Shanghai, China; Department of Nursing, Shuguang Hospital, Shanghai University of Traditional Chinese Medicine, Shanghai, China; Department of General Surgery, Changhai Hospital, Second Military Medical University, Shanghai, China; Department of General Surgery, Shuguang Hospital, Shanghai University of Traditional Chinese Medicine, Shanghai, China},
	abstract = {Introduction Postoperative recurrence and related complications are common and related to poor outcomes in patients with anal fistula (AF). Due to being associated with short-term and long-term cure rates, perioperative complications have received widespread attention following AF surgery. This study aims to identify a set of predictive factors to develop risk prediction models for recurrence and related complications following AF surgery. We plan to develop and validate risk prediction models, using information collected through a WeChat patient-reported questionnaire system combined with clinical, laboratory and imaging findings from the perioperative period until 3-6 months following AF surgery. Methods and analysis This is a prospective hospital-based cohort study using a linked database of collected health data as well as the follow-up outcomes for all adult patients who suffered from AF at a tertiary referral hospital in Shanghai, China. We will perform logistic regression models to predict anal fistula recurrence (AFR) as well as related complications (eg, wound haemorrhage, faecal impaction, urinary retention, delayed wound healing and unplanned hospitalisation) during and after AF surgery, and machine learning approaches will also be applied to develop risk prediction models. This prospective study aims to develop the first risk prediction models for AFR and related complications using multidimensional variables. These tools can be used to warn, motivate and empower patients to avoid some modifiable risk factors to prevent postoperative complications early. This study will also provide alternative tools for the early screening of high-risk patients with AFR and related complications, helping surgeons better understand the aetiology and outcomes of AF in an earlier stage. Ethics and dissemination The study was approved by the Institutional Review Board of Shuguang Hospital affiliated with Shanghai University of Traditional Chinese Medicine (approval number: 2019-699-54-01). The results of this study will be submitted to international scientific peer-reviewed journals or conferences in surgery, anorectal surgery or anorectal diseases. Trial registration number ChiCTR1900025069; Pre-results. © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {colorectal surgery; protocols and guidelines; risk management; surgery},
	keywords = {Adult; China; Humans; Observational Studies as Topic; Prospective Studies; Rectal Fistula; Recurrence; Risk Assessment; Validation Studies as Topic; adult; anus fistula; anus surgery; Article; China; clinical laboratory; clinical trial; cohort analysis; follow up; hospitalization; human; machine learning; major clinical study; observational study; patient-reported outcome; perioperative period; postoperative complication; postoperative period; prediction; prospective study; questionnaire; recurrence risk; recurrent disease; screening test; surgical patient; tertiary care center; procedures; rectum fistula; recurrent disease; risk assessment; validation study},
	correspondence_address = {G. Mei; Department of Anorectal Surgery, Shuguang Hospital, Shanghai University of Traditional Chinese Medicine, Anorectal Disease Institute of Shuguang Hospital, Shanghai, China; email: herrmayor@126.com},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {32139494},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Carter202025,
	author = {Carter, Stacy M. and Rogers, Wendy and Win, Khin Than and Frazer, Helen and Richards, Bernadette and Houssami, Nehmat},
	title = {The ethical, legal and social implications of using artificial intelligence systems in breast cancer care},
	year = {2020},
	journal = {Breast},
	volume = {49},
	pages = {25 – 32},
	doi = {10.1016/j.breast.2019.10.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074099299&doi=10.1016%2fj.breast.2019.10.001&partnerID=40&md5=38101d7aec910b83dddc543cf02583f2},
	affiliations = {Australian Centre for Health Engagement, Evidence and Values (ACHEEV), School of Health and Society, Faculty of Social Science, University of Wollongong, Northfields Avenue, 2522, New South Wales, Australia; Department of Philosophy and Department of Clinical Medicine, Macquarie University, Balaclava Road, North Ryde, 2109, New South Wales, Australia; Centre for Persuasive Technology and Society, School of Computing and Information Technology, Faculty of Engineering and Information Technology, University of Wollongong, Northfields Avenue, 2522, New South Wales, Australia; Screening and Assessment Service, St Vincent's BreastScreen, 1st Floor Healy Wing, 41 Victoria Parade, Fitzroy, 3065, Victoria, Australia; Adelaide Law School, Faculty of the Professions, University of Adelaide, Adelaide, 5005, South Australia, Australia; Sydney School of Public Health, Faculty of Medicine and Health, The University of Sydney, Fisher Road, 2006, New South Wales, Australia},
	abstract = {Breast cancer care is a leading area for development of artificial intelligence (AI), with applications including screening and diagnosis, risk calculation, prognostication and clinical decision-support, management planning, and precision medicine. We review the ethical, legal and social implications of these developments. We consider the values encoded in algorithms, the need to evaluate outcomes, and issues of bias and transferability, data ownership, confidentiality and consent, and legal, moral and professional responsibility. We consider potential effects for patients, including on trust in healthcare, and provide some social science explanations for the apparent rush to implement AI solutions. We conclude by anticipating future directions for AI in breast cancer care. Stakeholders in healthcare AI should acknowledge that their enterprise is an ethical, legal and social challenge, not just a technical challenge. Taking these challenges seriously will require broad engagement, imposition of conditions on implementation, and pre-emptive systems of oversight to ensure that development does not run ahead of evaluation and deliberation. Once artificial intelligence becomes institutionalised, it may be difficult to reverse: a proactive role for government, regulators and professional groups will help ensure introduction in robust research contexts, and the development of a sound evidence base regarding real-world effectiveness. Detailed public discussion is required to consider what kind of AI is acceptable rather than simply accepting what is offered, thus optimising outcomes for health systems, professionals, society and those receiving care. © 2019 The Authors},
	author_keywords = {AI (Artificial Intelligence); Breast carcinoma; Ethical Issues; Social values; Technology Assessment, Biomedical},
	keywords = {Artificial Intelligence; Australia; Breast Neoplasms; Decision Support Systems, Clinical; Early Detection of Cancer; Female; Humans; Precision Medicine; Prognosis; Risk Assessment; Technology Assessment, Biomedical; algorithm; Article; artificial intelligence; breast cancer; cancer prognosis; cancer screening; clinical decision support system; confidentiality; deep learning; electronic health record; evidence based medicine; human; informed consent; legal aspect; legal liability; machine learning; mammography; medical ethics; medicolegal aspect; personalized medicine; priority journal; privacy; social aspect; trust; artificial intelligence; Australia; biomedical technology assessment; breast tumor; early cancer diagnosis; ethics; female; legislation and jurisprudence; procedures; prognosis; risk assessment},
	correspondence_address = {S.M. Carter; Australian Centre for Health Engagement, Evidence and Values (ACHEEV), School of Health and Society, Faculty of Social Science, University of Wollongong, Northfields Avenue, 2522, Australia; email: stacy_carter@uow.edu.au},
	publisher = {Churchill Livingstone},
	issn = {09609776},
	coden = {BREAE},
	pmid = {31677530},
	language = {English},
	abbrev_source_title = {Breast},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 80; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Thompson2020293,
	author = {Thompson, Claire Louise and Morgan, Heather May},
	title = {Ethical barriers to artificial intelligence in the national health service, United Kingdom of Great Britain and Northern Ireland},
	year = {2020},
	journal = {Bulletin of the World Health Organization},
	volume = {98},
	number = {4},
	pages = {293 – 295},
	doi = {10.2471/BLT.19.237230},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083184574&doi=10.2471%2fBLT.19.237230&partnerID=40&md5=64fb3e34acc8a5c60fce472bb1247077},
	affiliations = {School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Polwarth Building, Foresterhill, Aberdeen, AB25 2ZD, United Kingdom},
	keywords = {Algorithms; Artificial Intelligence; Diffusion of Innovation; Northern Ireland; Social Responsibility; State Medicine; Trust; Truth Disclosure; United Kingdom; algorithm; artificial intelligence; deep learning; health care; health care policy; human; information processing; machine learning; medical research; national health service; Northern Ireland; Note; ophthalmology; patient care; patient coding; patient information; public health; United Kingdom; artificial intelligence; ethics; interpersonal communication; mass communication; social responsibility; trust},
	correspondence_address = {H.M. Morgan; School of Medicine, Medical Sciences and Nutrition, University of Aberdeen, Aberdeen, Polwarth Building, Foresterhill, AB25 2ZD, United Kingdom; email: h.morgan@abdn.ac.uk},
	publisher = {World Health Organization},
	issn = {00429686},
	coden = {BWHOA},
	pmid = {32284657},
	language = {English},
	abbrev_source_title = {Bull. WHO},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Mahdavi20208,
	author = {Mahdavi, Mehrzad and Kazemi, Hossein},
	title = {It’s All About Data: How to Make Good Decisions in a World Awash with Information},
	year = {2020},
	journal = {Journal of Financial Data Science},
	volume = {2},
	number = {2},
	pages = {8 – 16},
	doi = {10.3905/jfds.2020.1.025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85124065451&doi=10.3905%2fjfds.2020.1.025&partnerID=40&md5=a8e44b10dacd4d1e58f655f0a2aa105d},
	affiliations = {FDP Institute, Amherst, MA, United States; Isenberg School of Management at the University of Massachusetts—Amherst, United States; CAIA Association, Amherst, MA, United States},
	abstract = {The rise of big and alternative data has created significant new business opportunities in the financial sector. As we start on this journey of fast-moving technology disruption, f inancial professionals have a rare opportunity to balance the exponential growth of artif icial intelligence (AI)/data science with ethics, bias, and privacy to create trusted data-driven decision making. In this article, the authors discuss the nuances of big data sets that are critical when one considers standards, processes, best practices, and modeling algorithms for the deployment of AI systems. In addition, this industry is widely guided by a fiduciary standard that puts the interests of the client above all else. It is therefore critical to have a thorough understanding of the limitations of our knowledge, because there are many known unknowns and unknown unknowns that can have a signif icant impact on outcomes. The authors emphasize key success factors for the deployment of AI initiatives: talent and bridging the skills gap. To achieve a lasting impact of big data initiatives, multidisciplinary teams with well-defined roles need to be established with continuing training and education. The prize is the finance of the future. © 2020, With intelligence. All rights reserved.},
	author_keywords = {Big data/machine learning*; TOPICS: Simulations},
	publisher = {With intelligence},
	issn = {26403943},
	language = {English},
	abbrev_source_title = {J. Financial. Data. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Grote2020205,
	author = {Grote, Thomas and Berens, Philipp},
	title = {On the ethics of algorithmic decision-making in healthcare},
	year = {2020},
	journal = {Journal of Medical Ethics},
	volume = {46},
	number = {3},
	pages = {205 – 211},
	doi = {10.1136/medethics-2019-105586},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075645401&doi=10.1136%2fmedethics-2019-105586&partnerID=40&md5=ee69a7dca265ea3d9ea4e70f7b13e2eb},
	affiliations = {Ethics and Philosophy Lab; Cluster of Excellence: Machine Learning: New Perspectives for Science, University of Tübingen, Tübingen, Germany; International Center for Ethics in the Sciences and Humanities (IZEW), University of Tübingen, Tübingen, Germany; Institute for Ophthalmic Research, University of Tübingen, Tubingen, Germany},
	abstract = {In recent years, a plethora of high-profile scientific publications has been reporting about machine learning algorithms outperforming clinicians in medical diagnosis or treatment recommendations. This has spiked interest in deploying relevant algorithms with the aim of enhancing decision-making in healthcare. In this paper, we argue that instead of straightforwardly enhancing the decision-making capabilities of clinicians and healthcare institutions, deploying machines learning algorithms entails trade-offs at the epistemic and the normative level. Whereas involving machine learning might improve the accuracy of medical diagnosis, it comes at the expense of opacity when trying to assess the reliability of given diagnosis. Drawing on literature in social epistemology and moral responsibility, we argue that the uncertainty in question potentially undermines the epistemic authority of clinicians. Furthermore, we elucidate potential pitfalls of involving machine learning in healthcare with respect to paternalism, moral responsibility and fairness. At last, we discuss how the deployment of machine learning algorithms might shift the evidentiary norms of medical diagnosis. In this regard, we hope to lay the grounds for further ethical reflection of the opportunities and pitfalls of machine learning for enhancing decision-making in healthcare. © Author(s) (or their employer(s)) 2020. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {autonomy; decision-making; machine learning; paternalism; uncertainty},
	keywords = {Decision Making; Delivery of Health Care; Ethics, Medical; Humans; Morals; Paternalism; Reproducibility of Results; Uncertainty; drawing; epistemology; ethics; human; human experiment; learning algorithm; morality; paternalism; reliability; responsibility; review; uncertainty; decision making; health care delivery; medical ethics; paternalism; reproducibility; uncertainty},
	correspondence_address = {T. Grote; Ethics and Philosophy Lab; Cluster of Excellence: Machine Learning: New Perspectives for Science, University of Tübingen, Tübingen, Germany; email: thomas.grote@uni-tuebingen.de},
	publisher = {BMJ Publishing Group},
	issn = {03066800},
	coden = {JMETD},
	pmid = {31748206},
	language = {English},
	abbrev_source_title = {J. Med. Ethics},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 134; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{McCradden2020e221,
	author = {McCradden, Melissa D and Joshi, Shalmali and Mazwi, Mjaye and Anderson, James A},
	title = {Ethical limitations of algorithmic fairness solutions in health care machine learning},
	year = {2020},
	journal = {The Lancet Digital Health},
	volume = {2},
	number = {5},
	pages = {e221 – e223},
	doi = {10.1016/S2589-7500(20)30065-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083696456&doi=10.1016%2fS2589-7500%2820%2930065-0&partnerID=40&md5=9896e8ed207223918c4157dcd56e700f},
	affiliations = {Department of Bioethics, The Hospital for Sick Children, Toronto, ON, Canada; Department of Critical Care Medicine, The Hospital for Sick Children, Toronto, ON, Canada; Vector Institute for Artificial Intelligence, Toronto, ON, Canada},
	keywords = {Algorithms; Delivery of Health Care; Female; Health Equity; Humans; Machine Learning; Male; Models, Biological; Social Justice; algorithm; artificial intelligence; clinical outcome; computer analysis; gender; health care; human; machine learning; mathematical model; medical decision making; medical ethics; motivation; Note; patient; patient referral; prediction; race; risk benefit analysis; sensitivity and specificity; sex difference; standardization; statistical analysis; uncertainty; validation study; biological model; ethics; female; health care delivery; health equity; machine learning; male; social justice},
	publisher = {Elsevier Ltd},
	issn = {25897500},
	pmid = {33328054},
	language = {English},
	abbrev_source_title = {Lancet Digit. Heal.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 69; All Open Access, Bronze Open Access}
}

@ARTICLE{Perry2020143,
	author = {Perry, Patsy and Ashman, Rachel and Stalker, Iain Duncan},
	title = {Special Session: Corporate Social Responsibility and AI: The Case of Fashion: An Abstract},
	year = {2020},
	journal = {Developments in Marketing Science: Proceedings of the Academy of Marketing Science},
	pages = {143 – 144},
	doi = {10.1007/978-3-030-42545-6_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125202663&doi=10.1007%2f978-3-030-42545-6_36&partnerID=40&md5=e2b9ba6e1914089470c04c6acc406768},
	affiliations = {The University of Manchester, Manchester, United Kingdom; University of Liverpool, Liverpool, United Kingdom},
	abstract = {This paper critically examines the ethical issues of current and predicted adoption of AI within fashion. AI is a branch of computer science that combines machine learning, logic and natural language processing to emulate human intelligence. By processing vast amounts of data and recognising patterns in the data, AI produces insights and analytics at or above human capability (IEEE 2017). It has been applied to fashion in trend forecasting, personalisation, customer interaction and the use of CGI models. For example, Amazon developed “Echo Look” which combines computer vision with predictive AI and human analysis to assess a consumer’s current wardrobe choices and provide recommendations of what to wear. Users can ask the machine to rate two different possible outfits in terms of current trends and actual appearance (Gibbs 2017). Online styling subscription Stitch Fix uses machine learning algorithms to determine its customers’ preferred styles and offer personalised recommendations. AI has also been developed to mimic the role of social media influencers and models. CGI character “Miquela” has 1.6 million Instagram followers, collaborates with luxury brands and launched her own clothing brand, but is not a real person. There is a dedicated digital modelling agency (Davis 2018). Such innovations are likely to further inflame the ongoing ethical debate about using digital technologies and virtual reality at the risk of opportunities for real people, for example diminishing already scarce opportunities for black models (Graham 2018), or introducing norms of artificial appearance and personal aesthetics impossible for ‘real’ people to achieve. AI has the potential to revolutionise fashion through greater precision, accuracy and effectiveness in decision-making, but at what cost? To what extent can and should AI replicate and replace human creativity and presence in an industry sector founded on human input in creating new trends? Yet, AI that predicts garment suitability and offers greater customisation for consumers may reduce waste and over-consumption (Snow 2017). Producing items which have greater relevance could reduce returns, markdowns and warehouse space, plus increase customer satisfaction and experience. Automating repetitive tasks could save money and time for greater value-added activities, for example through the use of chatbots for online customer service. This paper applies the lens of CSR to inform the debate on whether core fashion retailing functions can and should be replaced by AI. A CSR approach argues for businesses assuming social responsibilities beyond any economic, technical and legal obligations which constitute its existence, with the objective of reconciling economic, social and environmental objectives (Davis 1973). © 2020, The Academy of Marketing Science.},
	author_keywords = {AI; CSR; Ethics; Fashion},
	correspondence_address = {P. Perry; The University of Manchester, Manchester, United Kingdom; email: patsy.perry@manchester.ac.uk},
	publisher = {Springer Nature},
	issn = {23636165},
	language = {English},
	abbrev_source_title = {Dev. Mark. Sci.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jo2020306,
	author = {Jo, Eun Seo and Gebru, Timnit},
	title = {Lessons from archives: Strategies for collecting sociocultural data in machine learning},
	year = {2020},
	journal = {FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
	pages = {306 – 316},
	doi = {10.1145/3351095.3372829},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079607495&doi=10.1145%2f3351095.3372829&partnerID=40&md5=b9ad0c4126a4071c8f603b18a90d5c30},
	affiliations = {Stanford University, United States; Google, United States},
	abstract = {A growing body of work shows that many problems in fairness, accountability, transparency, and ethics in machine learning systems are rooted in decisions surrounding the data collection and annotation process. In spite of its fundamental nature however, data collection remains an overlooked part of the machine learning (ML) pipeline. In this paper, we argue that a new specialization should be formed within ML that is focused on methodologies for data collection and annotation: efforts that require institutional frameworks and procedures. Specifically for sociocultural data, parallels can be drawn from archives and libraries. Archives are the longest standing communal effort to gather human information and archive scholars have already developed the language and procedures to address and discuss many challenges pertaining to data collection such as consent, power, inclusivity, transparency, and ethics & privacy. We discuss these five key approaches in document collection practices in archives that can inform data collection in sociocultural ML. By showing data collection practices from another field, we encourage ML research to be more cognizant and systematic in data collection and draw from interdisciplinary expertise. © 2020 Copyright held by the owner/author(s). Publication rights licensed to the Association for Computing Machinery.},
	author_keywords = {Archives; Data collection; Datasets; Machine learning; ML fairness; Sociocultural data},
	keywords = {Ethical aspects; Learning systems; Machine learning; Transparency; Archives; Data collection; Datasets; ML fairness; Sociocultural data; Data acquisition},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036936-7},
	language = {English},
	abbrev_source_title = {FAT* - Proc. Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 114; Conference name: 3rd ACM Conference on Fairness, Accountability, and Transparency, FAT* 2020; Conference date: 27 January 2020 through 30 January 2020; Conference code: 157226; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Wang2020539,
	author = {Wang, Hongrui and Liu, Chang and Yu, Dong},
	title = {Construction of a Chinese Moral Dictionary for Artificial Intelligence Ethical Computing; [面向人工智能伦理计算的中文道德词典构建方法研究]},
	year = {2020},
	journal = {19th Chinese National Conference on Computational Linguistic, CCL 2020},
	pages = {539 – 549},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85123920481&partnerID=40&md5=3dc53da63b374b140887c47c12fd8ff8},
	affiliations = {Beijing Language and Culture University, China},
	abstract = {The construction of the moral dictionary is based on artificial intelligence ethical computing. Moral behavior is complex and varied. The existing moral dictionary classification system for English language is still under development. Meanwhile, there are currently no relevant dictionary resources in Chinese. The theoretical system and construction method are still to be explored. In this paper, the task of constructing a Chinese moral dictionary for artificial intelligence ethics calculation is proposed. Four polar labels and four types of labels are designed to obtain a Chinese moral dictionary resource containing 25,012 words. Experimental results show that the dictionary resource can not only enable the machine to learn moral knowledge and judge the moral polarity and type of words, but also provide data support for the analysis of moral text at the sentence level. © 2020 China National Conference on Computational Linguistics Published under Creative Commons Attribution 4.0 International License},
	author_keywords = {Ethical computing; Machine learning; Moral judgment},
	keywords = {Classification (of information); Computational linguistics; Ethical technology; Classification system; Construction method; Data support; English languages; Ethical computing; Learn+; Moral judgment; Sentence level; System methods; Theoretical system; Machine learning},
	editor = {Sun M. and Li S. and Zhang Y. and Liu Y.},
	publisher = {Chinese National Conference on Computational Linguistic},
	language = {Chinese},
	abbrev_source_title = {Chin. Nat. Conf. Comput. Linguist., CCL},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 19th Chinese National Conference on Computational Linguistic, CCL 2020; Conference date: 30 October 2020 through 1 November 2020; Conference code: 174261}
}

@ARTICLE{Fourneret2020,
	author = {Fourneret, Eric and Yvert, Blaise},
	title = {Digital Normativity: A Challenge for Human Subjectivation},
	year = {2020},
	journal = {Frontiers in Artificial Intelligence},
	volume = {3},
	doi = {10.3389/frai.2020.00027},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117907554&doi=10.3389%2ffrai.2020.00027&partnerID=40&md5=33f5e014465581f583a6b4ffaca10bb6},
	affiliations = {Inserm and Univ Grenoble Alpes, BrainTech Lab U1205, Gières, France},
	author_keywords = {agency; artificial intelligence; education; ethics; free will (freedom); governance; machine learning; normativity},
	correspondence_address = {B. Yvert; Inserm and Univ Grenoble Alpes, BrainTech Lab U1205, Gières, France; email: blaise.yvert@inserm.fr},
	publisher = {Frontiers Media S.A.},
	issn = {26248212},
	language = {English},
	abbrev_source_title = {Frontier. Artif. Intell.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Núñez Reiz2020320,
	author = {Núñez Reiz, A. and Sánchez García, M.},
	title = {In reply to «Big Data Analysis and Machine Learning in Intensive Care Medicine: Identifying new ethical and legal challenges»; [En respuesta a «Big Data Analysis y Machine Learning en medicina intensiva: identificando nuevos retos ético-jurídicos»]},
	year = {2020},
	journal = {Medicina Intensiva},
	volume = {44},
	number = {5},
	pages = {320},
	doi = {10.1016/j.medin.2020.01.004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084651308&doi=10.1016%2fj.medin.2020.01.004&partnerID=40&md5=dfe27794ffd532f6e9f4f5ac5cfa0a13},
	affiliations = {Unidad de Cuidados Intensivos, Hospital Clínico San Carlos, Madrid, Spain},
	keywords = {Big Data; Critical Care; Data Analysis; Humans; Intensive Care Units; Machine Learning; data analysis; ethics; intensive care medicine; legal aspect; Letter; machine learning; medicine; human; intensive care; intensive care unit; machine learning},
	correspondence_address = {A. Núñez Reiz; Unidad de Cuidados Intensivos, Hospital Clínico San Carlos, Madrid, Spain; email: anunezreiz@gmail.com},
	publisher = {Ediciones Doyma, S.L.},
	issn = {02105691},
	coden = {MDINE},
	pmid = {32113732},
	language = {English},
	abbrev_source_title = {Med. Intensiva},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Peterson2020541,
	author = {Peterson, Andrew and Owen, Adrian M. and Karlawish, Jason},
	title = {Translating the Discovery of Covert Consciousness into Clinical Practice},
	year = {2020},
	journal = {JAMA Neurology},
	volume = {77},
	number = {5},
	pages = {541 – 542},
	doi = {10.1001/jamaneurol.2020.0232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081649847&doi=10.1001%2fjamaneurol.2020.0232&partnerID=40&md5=db26b0ae8ef5f430e671a3edd673195c},
	affiliations = {Institute for Philosophy and Public Policy, George Mason University, 4400 University Dr, 3F1, Fairfax, 22030, VA, United States; Brain and Mind Institute, University of Western Ontario, London, ON, Canada; Penn Memory Center, University of Pennsylvania, Philadelphia, United States; Department of Medical Ethics and Health Policy, University of Pennsylvania, Philadelphia, United States},
	keywords = {Consciousness; Consciousness Disorders; Decision Making; Electroencephalography; Humans; Neurology; Professional-Patient Relations; Truth Disclosure; Alzheimer disease; caregiver; clinical practice; cognition; consciousness; electroencephalogram; emergency care; evidence based practice; family counseling; family decision making; follow up; functional status; health care personnel; human; intensive care unit; intensivist; machine learning; medical information; mental health; motor cortex; neuroimaging; neurologist; Note; practice guideline; priority journal; prognosis; quality of life; religion; terminal care; United States; wellbeing; consciousness; consciousness disorder; decision making; electroencephalography; ethics; interpersonal communication; neurology; pathophysiology; physiology; procedures; professional-patient relationship},
	correspondence_address = {A. Peterson; Institute for Philosophy and Public Policy, George Mason University, Fairfax, 4400 University Dr, 3F1, 22030, United States; email: apeter31@gmu.edu},
	publisher = {American Medical Association},
	issn = {21686149},
	pmid = {32176251},
	language = {English},
	abbrev_source_title = {JAMA Neurol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access}
}

@ARTICLE{Khan2020634,
	author = {Khan, Sikandar Hayat},
	title = {ARTIFICIAL INTELLIGENCE IN HEALTHCARE SETUPS: PROS AND CONS AND WAY FOR WARD TO MANAGE},
	year = {2020},
	journal = {Pakistan Armed Forces Medical Journal},
	volume = {70},
	number = {2},
	pages = {634 – 638},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128113543&partnerID=40&md5=c75ca2c2835f0ba0719bbe989b06b4d4},
	affiliations = {Pakistan Naval Ship, Hafeez Hospital, Islamabad, Pakistan},
	abstract = {Artificial intelligence employs machine base algorithmic processes which are now entering into the clinical domain. While the medical doctors and paramedical staff are usually not formally taught the subject in their primaries so a little understanding about various machine learning processes are essential. Apart from staff the requirements, knowledge, systems, training and understanding the best possible utility of the processes is also needed. This article attempts to address the processes linked within this new via of patient-doctor interface leading to decision making by taking the help of algorithmic approaches with input details guiding them about regulatory guidelines, ethics, links to requisite data repository and applicable evidence based practices. The article further elaborates upon the needs of such artificial intelligence interfaced healthcare system in terms of patient related understanding requirements, technical human resource, systems to establish, physician clientele focus along with some novel added features for healthcare expanding domains. Following this the pros and cons as perceived by newly introduced clientele have been discussed with their concerns and a way forward for installing such system. The articles primarily focus on the beginner’s need especially those living in resource-bound countries. © 2020, Army Medical College. All rights reserved.},
	author_keywords = {Artificial intelligence; Healthcare; Machine learning},
	correspondence_address = {S.H. Khan; PNS Hafeez, Islamabad, Pakistan; email: sik_cpsp@yahoo.com},
	publisher = {Army Medical College},
	issn = {00309648},
	language = {English},
	abbrev_source_title = {Pak. Armed. Forces. Med. J.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2020,
	title = {Erratum: Machine learning and artificial intelligence research for patient benefit: 20 critical questions on transparency, replicability, ethics, and effectiveness (BMJ (2020) 368 (l6927) DOI: 10.1136/bmj.l6927)},
	year = {2020},
	journal = {The BMJ},
	volume = {369},
	doi = {10.1136/bmj.m1312},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082979177&doi=10.1136%2fbmj.m1312&partnerID=40&md5=3b81a4a2b02a070d11e46261dc850f0b},
	abstract = {An error was included in the accepted version of this paper by Vollmer and colleagues (BMJ 2020;368:l6927, doi:10.1136/ bmj.l6927, published 20 March 2020), and was not picked up before publication. In the author list, David Grainger was spelt incorrectly. The paper will be amended in due course. © 2020 BMJ.},
	keywords = {erratum},
	publisher = {BMJ Publishing Group},
	issn = {09598146},
	coden = {BMJOA},
	pmid = {32238345},
	language = {English},
	abbrev_source_title = {BMJ},
	type = {Erratum},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Campbell202021,
	author = {Campbell, Cara G. and Ting, Daniel S.W. and Keane, Pearse A. and Foster, Paul J.},
	title = {The potential application of artificial intelligence for diagnosis and management of glaucoma in adults},
	year = {2020},
	journal = {British Medical Bulletin},
	volume = {134},
	number = {1},
	pages = {21 – 33},
	doi = {10.1093/bmb/ldaa012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088206119&doi=10.1093%2fbmb%2fldaa012&partnerID=40&md5=3c131915eff3f3e05bd0a753bae2a2e7},
	affiliations = {UCL Institute of Ophthalmology, Faculty of Brain Science, University College London, 11-43 Bath Street, London, EC1V 9EL, United Kingdom; Medical Retina Service, Moorfields Eye Hospital NHS Foundation Trust, 162 City Road, London, EC1V 2PD, United Kingdom; National Institute for Health Research Biomedical Research Centre, Moorfields Eye Hospital NHS Foundation Trust NHS Foundation Trust, 2/12 Wolfson Building, UCL Institute of Ophthalmology, 11-43 Bath Street, London, EC1V 9EL, United Kingdom},
	abstract = {Background: Glaucoma is the most frequent cause of irreversible blindness worldwide. There is no cure, but early detection and treatment can slow the progression and prevent loss of vision. It has been suggested that artificial intelligence (AI) has potential application for detection and management of glaucoma. Sources of data: This literature review is based on articles published in peer-reviewed journals. Areas of agreement: There have been significant advances in both AI and imaging techniques that are able to identify the early signs of glaucomatous damage. Machine and deep learning algorithms show capabilities equivalent to human experts, if not superior. Areas of controversy: Concerns that the increased reliance on AI may lead to deskilling of clinicians. Growing points: AI has potential to be used in virtual review clinics, telemedicine and as a training tool for junior doctors. Unsupervised AI techniques offer the potential of uncovering currently unrecognized patterns of disease. If this promise is fulfilled, AI may then be of use in challenging cases or where a second opinion is desirable. Areas timely for developing research: There is a need to determine the external validity of deep learning algorithms and to better understand how the 'black box' paradigm reaches results. © The Author(s) 2020. Published by Oxford University Press. All rights reserved.},
	author_keywords = {'black box' algorithm; Artificial intelligence; Deep learning; Glaucoma; Machine learning; Machine learning classifiers},
	keywords = {Algorithms; Artificial Intelligence; Disease Management; Early Diagnosis; Glaucoma; Humans; adult disease; artificial intelligence; deep learning; deep neural network; external validity; glaucoma; human; machine learning; priority journal; Review; sensitivity and specificity; algorithm; disease management; early diagnosis; ethics; glaucoma},
	correspondence_address = {P.J. Foster; UCL Institute of Ophthalmology, London, 11-43 Bath Street, EC1V 9EL, United Kingdom; email: p.foster@ucl.ac.uk},
	publisher = {Oxford University Press},
	issn = {00071420},
	coden = {BMBUA},
	pmid = {32518944},
	language = {English},
	abbrev_source_title = {Br. Med. Bull.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Kedra2020107,
	author = {Kedra, Joanna and Gossec, Laure},
	title = {Big Data and artificial intelligence: Will they change our practice?},
	year = {2020},
	journal = {Joint Bone Spine},
	volume = {87},
	number = {2},
	pages = {107 – 109},
	doi = {10.1016/j.jbspin.2019.09.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073170132&doi=10.1016%2fj.jbspin.2019.09.001&partnerID=40&md5=c567c47bc72e13ef3b32949d9d7abd5b},
	affiliations = {Sorbonne Université, Institut Pierre-Louis d’Épidémiologie et de Santé Publique, Inserm, Paris, 75646, France; Rheumatology unit, Pitié Salpêtrière Hospital, AP–HP, Paris, 75013, France},
	author_keywords = {Artificial intelligence; Big data; Machine learning; Medicine; Rheumatology},
	keywords = {Artificial Intelligence; Big Data; Humans; access to information; artificial intelligence; big data; clinical practice; Editorial; human; information processing; information storage; medical ethics; medical expert; omics; personalized medicine; rheumatology; scientist},
	correspondence_address = {J. Kedra; Service de rhumatologie, hôpital Pitié Salpêtrière, AP–HP, Paris, 47-83, boulevard de l'Hôpital, 75013, France; email: jkedra.pro@gmail.com},
	publisher = {Elsevier Masson SAS},
	issn = {1297319X},
	coden = {JBSPF},
	pmid = {31520738},
	language = {English},
	abbrev_source_title = {Jt. Bone Spine},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Carney2020,
	author = {Carney, Michelle and Webster, Barron and Alvarado, Irene and Phillips, Kyle and Howell, Noura and Griffith, Jordan and Jongejan, Jonas and Pitaru, Amit and Chen, Alexander},
	title = {Teachable machine: Approachable web-based tool for exploring machine learning classification},
	year = {2020},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3334480.3382839},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090234693&doi=10.1145%2f3334480.3382839&partnerID=40&md5=6e2df4ee5c1dd02a66fd42762f762644},
	affiliations = {Google Inc., San Francisco, CA, United States; University of California, Berkeley, Berkeley, CA, United States},
	abstract = {Teachable Machine (teachablemachine.withgoogle.com) is a web-based GUI tool for creating custom machine learning classification models without specialized technical expertise. (Machine learning, or ML, lets systems learn to analyze data without being explicitly programmed.) We created it to help students, teachers, designers, and others learn about ML by creating and using their own classification models. Its broad uptake suggests it has empowered people to learn, teach, and explore ML concepts: People have created curriculum, tutorials, and other resources using Teachable Machine on topics like AI ethics at institutions including the Stanford d.school, NYU's Interactive Telecommunications Program, the MIT Media Lab, as well as creative experiments. Users in 201 countries have created over 125,000 classification models. Here we outline the project and its key contributions of (1) a flexible, approachable interface for ML classification models without ML or coding expertise, (2) a set of technical and design decisions that can inform future interactive machine learning tools, and (3) an example of how structured learning content surrounding the tool supports people accessing ML concepts. © 2020 Owner/Author.},
	author_keywords = {Human-centered ML; Interactive ML},
	keywords = {Curricula; E-learning; Human engineering; Websites; Classification models; Design decisions; Interactive machine learning; Machine learning classification; MIT Media Lab; Structured learning; Technical expertise; Web-based tools; Machine learning},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036819-3},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 83; Conference name: 2020 ACM CHI Conference on Human Factors in Computing Systems, CHI EA 2020; Conference date: 25 April 2020 through 30 April 2020; Conference code: 160405}
}

@ARTICLE{Wachter2020507,
	author = {Wachter, Robert M. and Cassel, Christine K.},
	title = {Sharing Health Care Data with Digital Giants: Overcoming Obstacles and Reaping Benefits while Protecting Patients},
	year = {2020},
	journal = {JAMA - Journal of the American Medical Association},
	volume = {323},
	number = {6},
	pages = {507 – 508},
	doi = {10.1001/jama.2019.21215},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077998873&doi=10.1001%2fjama.2019.21215&partnerID=40&md5=b7dedc3f1f6e712118b755ef16ddfe24},
	affiliations = {Department of Medicine, University of California, San Francisco, 505 Parnassus Ave, San Francisco, 94143, CA, United States},
	keywords = {Cloud Computing; Computer Security; Electronic Health Records; Health Care Sector; Humans; Information Dissemination; Machine Learning; artificial intelligence; cancer therapy; clinical decision support system; clinical study; computer security; data collection method; dementia; drug hypersensitivity; electronic health record; forensic intelligence; health care cost; health care delivery; health care facility; health care need; health care organization; health care personnel; health care quality; health care system; health insurance; human; information storage; informed consent; intersectoral collaboration; law suit; machine learning; pathology; patient advocacy; patient identification; patient information; prediction; prescription; priority journal; privacy; public health message; sepsis; Short Survey; therapy effect; treatment outcome; tumor volume; web browser; cloud computing; computer security; economics; electronic health record; ethics; information dissemination; legislation and jurisprudence},
	correspondence_address = {R.M. Wachter; Department of Medicine, University of California, San Francisco, San Francisco, 505 Parnassus Ave, 94143, United States; email: robert.wachter@ucsf.edu},
	publisher = {American Medical Association},
	issn = {00987484},
	coden = {JAMAA},
	pmid = {31944216},
	language = {English},
	abbrev_source_title = {JAMA},
	type = {Short survey},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@ARTICLE{King202089,
	author = {King, Thomas C. and Aggarwal, Nikita and Taddeo, Mariarosaria and Floridi, Luciano},
	title = {Artificial Intelligence Crime: An Interdisciplinary Analysis of Foreseeable Threats and Solutions},
	year = {2020},
	journal = {Science and Engineering Ethics},
	volume = {26},
	number = {1},
	pages = {89 – 120},
	doi = {10.1007/s11948-018-00081-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061660930&doi=10.1007%2fs11948-018-00081-0&partnerID=40&md5=aa6688a9c968473de6ef5401f3b46836},
	affiliations = {Oxford Internet Institute, University of Oxford, 1 St Giles, Oxford, OX1 3JS, United Kingdom; Faculty of Law, University of Oxford, St Cross Building St. Cross Rd, Oxford, OX1 3UL, United Kingdom; The Alan Turing Institute, 96 Euston Road, London, NW1 2DB, United Kingdom},
	abstract = {Artificial intelligence (AI) research and regulation seek to balance the benefits of innovation against any potential harms and disruption. However, one unintended consequence of the recent surge in AI research is the potential re-orientation of AI technologies to facilitate criminal acts, term in this article AI-Crime (AIC). AIC is theoretically feasible thanks to published experiments in automating fraud targeted at social media users, as well as demonstrations of AI-driven manipulation of simulated markets. However, because AIC is still a relatively young and inherently interdisciplinary area—spanning socio-legal studies to formal science—there is little certainty of what an AIC future might look like. This article offers the first systematic, interdisciplinary literature analysis of the foreseeable threats of AIC, providing ethicists, policy-makers, and law enforcement organisations with a synthesis of the current problems, and a possible solution space. © 2019, The Author(s).},
	author_keywords = {AI and law; AI-Crime; Artificial intelligence; Dual-use; Ethics; Machine learning},
	keywords = {Artificial Intelligence; Commerce; Crime; Drug Trafficking; Forecasting; Fraud; Humans; Interdisciplinary Research; Liability, Legal; Sex Offenses; Social Media; artificial intelligence; commercial phenomena; crime; drug traffic; forecasting; fraud; human; interdisciplinary research; legal liability; legislation and jurisprudence; sexual crime; social media},
	correspondence_address = {L. Floridi; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles, OX1 3JS, United Kingdom; email: luciano.floridi@oii.ox.ac.uk},
	publisher = {Springer},
	issn = {13533452},
	pmid = {30767109},
	language = {English},
	abbrev_source_title = {Sci. Eng. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 67; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Hancox-Li2020640,
	author = {Hancox-Li, Leif},
	title = {Robustness in machine learning explanations: Does it matter?},
	year = {2020},
	journal = {FAT* 2020 - Proceedings of the 2020 Conference on Fairness, Accountability, and Transparency},
	pages = {640 – 647},
	doi = {10.1145/3351095.3372836},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079695215&doi=10.1145%2f3351095.3372836&partnerID=40&md5=68eab6a77b5e01ba928af02719c8ce89},
	affiliations = {Capital One, New York, NY, United States},
	abstract = {The explainable AI literature contains multiple notions of what an explanation is and what desiderata explanations should satisfy. One implicit source of disagreement is how far the explanations should reflect real patterns in the data or the world. This disagreement underlies debates about other desiderata, such as how robust explanations are to slight perturbations in the input data. I argue that robustness is desirable to the extent that we're concerned about finding real patterns in the world. The import of real patterns differs according to the problem context. In some contexts, non-robust explanations can constitute a moral hazard. By being clear about the extent to which we care about capturing real patterns, we can also determine whether the Rashomon Effect is a boon or a bane. © 2020 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Artificial intelligence; Epistemology; Ethics; Explanation; Machine learning; Methodology; Objectivity; Philosophy; Robustness},
	keywords = {Artificial intelligence; Ethical aspects; Learning systems; Risk management; Robustness (control systems); Transparency; Epistemology; Explanation; Methodology; Objectivity; Philosophy; Machine learning},
	correspondence_address = {L. Hancox-Li; Capital One, New York, United States; email: leif.hancox-li@capitalone.com},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036936-7},
	language = {English},
	abbrev_source_title = {FAT* - Proc. Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 33; Conference name: 3rd ACM Conference on Fairness, Accountability, and Transparency, FAT* 2020; Conference date: 27 January 2020 through 30 January 2020; Conference code: 157226; All Open Access, Green Open Access}
}@ARTICLE{Dai2019,
	author = {Dai, Liang and Zhang, Jia and Li, Candong and Zhou, Changen and Li, Shaozi},
	title = {Multi-label feature selection with application to TCM state identification},
	year = {2019},
	journal = {Concurrency and Computation: Practice and Experience},
	volume = {31},
	number = {23},
	doi = {10.1002/cpe.4634},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074873777&doi=10.1002%2fcpe.4634&partnerID=40&md5=b0ec700402bc6bdaeb835ad72869d76e},
	affiliations = {Department of Cognitive Science, Xiamen University, Xiamen, 361005, China; Fujian Key Laboratory of Brain-inspired Computing Technique and Applications, Xiamen University, Xiamen, 361005, China; College of Traditional Chinese Medicine, Fujian University of Traditional Chinese Medicine, Fuzhou, 350122, China},
	abstract = {The goal of TCM state identification is to identify the patient's syndromes and locations and natures of diseases according to symptoms. Generally, symptoms of a patient are associated with several syndromes and multiple locations and natures of diseases; hence, the TCM state identification is a typical multi-label problem. In this paper, a new method is proposed to predict syndromes and locations and natures of diseases according to the diagnostic information of TCM. In detail, the correlation between features and the correlation between class labels are combined into a new uniform feature space. After that, the MDMR algorithm is used to select the most discriminatory features from the new uniform feature space, which is helpful to reduce the data dimensionality. Lastly, a KNN-like algorithm is modified to calculate the label similarity of test data, and the finite set of labels of test data is predicted by ML-KNN. In this paper, the test data is collected by Fujian University of Traditional Chinese Medicine according to the theory of TCM and medical ethics. The experiments show that the performance of the proposed method is superior to some other popular methods and is helpful in the identification of health state in TCM. © 2018 John Wiley & Sons, Ltd.},
	author_keywords = {feature selection; K-nearest neighbor; machine learning; multi-label learning; TCM state identification},
	keywords = {Diagnosis; Learning algorithms; Learning systems; Location; Nearest neighbor search; Correlation between features; Data dimensionality; Feature space; K-nearest neighbors; Multi-label learning; Multi-label problems; State identification; Traditional Chinese Medicine; Feature extraction},
	correspondence_address = {S. Li; Department of Cognitive Science, Xiamen University, Xiamen, 361005, China; email: szlig@xmu.edu.cn},
	publisher = {John Wiley and Sons Ltd},
	issn = {15320626},
	coden = {CCPEB},
	language = {English},
	abbrev_source_title = {Concurr. Comput. Pract. Exper.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Morsy20192,
	author = {Morsy, Ahmed},
	title = {From the Editor},
	year = {2019},
	journal = {IEEE Pulse},
	volume = {10},
	number = {6},
	pages = {2 – 3},
	doi = {10.1109/MPULS.2019.2958023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078954674&doi=10.1109%2fMPULS.2019.2958023&partnerID=40&md5=ec1f9b27bccfd366cde80182a460abaf},
	keywords = {algorithm; cost effectiveness analysis; early diagnosis; Editorial; false negative result; false positive result; health care cost; machine learning; mammography; medical ethics; social media},
	correspondence_address = {A. Morsy; email: amorsy@ieee.org},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21542287},
	language = {English},
	abbrev_source_title = {IEEE Pulse},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pereira2020108,
	author = {Pereira, Anabela},
	title = {Ethical challenges in collecting and analysing biometric data},
	year = {2020},
	journal = {Proceedings of the European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2020},
	pages = {108 – 114},
	doi = {10.34190/EAIR.20.034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097817391&doi=10.34190%2fEAIR.20.034&partnerID=40&md5=de740ad47e411151b68bd76b1bfc42a9},
	affiliations = {Iscte, Instituto Universitário de Lisboa, Portugal},
	abstract = {This paper is a theoretical discussion of the technical, ethical, legal and social implications of the biotechnological (e.g., using AI and robotics) to neuroscience research and neuroethics. In particular, reflection will be made on the responsible use of neurotechnological devices directed to the consumer as well as on the advanced machine learning and brain imaging techniques which involve the recording, testing and analysis of biometric data. According to recent theories, the architecture of our brains determines our social behaviour and our inclusive moral dispositions, influencing the type of society we create, and vice versa. (cf., Damasio, 2017). It is now accepted that both reason and emotion influence moral judgment, as the degree of automaticity in decision-making process (analytic vs. heuristic) influence human choices and actions (cf. Greene et al., 2001; Ferreira et al., 2016). Thus, ethical challenges in collecting and analysing biometric data involve the discussion of the benefits of working with this type of data, but also, of the risks involved in their uses and applications. Such risks display levels of vulnerability related to the privacy of the mental and physical states of the users (as some technologies are used directly by consumers), and raise questions of whether biometric data has suitable treatment, as well as on the existence of legislative frameworks against which their uses can be displayed. To what extent is risk management capacity – considering risk as a constitutive condition of modernity (Beck, 1992) –, important to the implementation and results of programs when dealing with such a sensitive type of data, and what is the role of advance technologies and neuroscience research in this process? Questions of access and literacy, the use of technological tools in civil society, and regulatory issues on how to protect the privacy of biometric data collection and analysis will be addressed. The main contribution of such discussion is to point out how emergent changes caused by the biotechnological uses in society are affecting the formation of contemporary culture and humans as beings, for some of these objects can also be seen as technological extensions of the human body biological process. © ECIAIR 2020.All right reserved.},
	author_keywords = {Biometric data; Biotechnology; Cognitive science; Ethics; Neuroscience},
	keywords = {Agricultural robots; Biometrics; Brain mapping; Decision making; Laws and legislation; Neurology; Philosophical aspects; Risk management; Robotics; Well testing; Biological process; Biometric data collection; Brain imaging techniques; Decision making process; Legislative frameworks; Regulatory issues; Social implication; Technological tools; Data privacy},
	correspondence_address = {A. Pereira; Iscte, Instituto Universitário de Lisboa, Portugal; email: anabela_c_pereira@iscte.pt},
	editor = {Matos F.},
	publisher = {Academic Conferences International },
	isbn = {978-191276474-7},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. Impact Artif. Intell. Robot., ECIAIR},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2nd European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2020; Conference date: 22 October 2020 through 23 October 2020; Conference code: 165513}
}

@CONFERENCE{Vazquez2019458,
	author = {Vazquez, Miguel Angel and Pallois, Jean Paul and Debbah, Merouane and Masouros, Christos and Kenyon, Tony and Deng, Yansha and Mekuria, Fisseha and Perez-Neira, Ana and Erfanian, Javan},
	title = {Deploying artificial intelligence in the wireless infrastructure: The challenges ahead},
	year = {2019},
	journal = {IEEE 5G World Forum, 5GWF 2019 - Conference Proceedings},
	pages = {458 – 459},
	doi = {10.1109/5GWF.2019.8911693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076802921&doi=10.1109%2f5GWF.2019.8911693&partnerID=40&md5=b76948a4a8a593001f45c2c9899dc44f},
	affiliations = {Centre Tecnològic de Telecomunicacions de Catalunya, Castelldefels, Spain; Huawei Technologies, Paris, France; University College London, London, United Kingdom; King's College London, London, United Kingdom; Council for Scientific and Industrial Research, Pretoria, South Africa; Bell Mobility, ON, Canada},
	abstract = {The adoption of artificial intelligence (AI) techniques entails a substantial change in the wireless ecosystem where data as well as their owners become crucial. As a result, the roll out of AI techniques in wireless systems raises a plethora of questions. In this context, we describe the challenges observed by the wireless stakeholders when deploying AI. Furthermore, we introduce the recent discussion in field of ethics that appear when managing wireless communications data. © 2019 IEEE.},
	author_keywords = {Artificial Intelligence; Machine Learning; Wireless Infrastructure},
	keywords = {Learning systems; AI techniques; In-field; Wireless communications; Wireless infrastructures; Wireless systems; Artificial intelligence},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172813627-1},
	language = {English},
	abbrev_source_title = {IEEE 5G World Forum, 5GWF - Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 2nd IEEE 5G World Forum, 5GWF 2019; Conference date: 30 September 2019 through 2 October 2019; Conference code: 155597; All Open Access, Green Open Access}
}

@ARTICLE{Song2019,
	author = {Song, Chengyun and Liu, Weiyi and Liu, Zhining and Liu, Xiaoyang},
	title = {User abnormal behavior recommendation via multilayer network},
	year = {2019},
	journal = {PLoS ONE},
	volume = {14},
	number = {12},
	doi = {10.1371/journal.pone.0224684},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076168156&doi=10.1371%2fjournal.pone.0224684&partnerID=40&md5=ef350d4e568aa3037949e439db62fabf},
	affiliations = {School of Computer Science and Engineering, Chongqing University of Technology, Chongqing, China; JD Urban Computing Business Unit, Chengdu, China; School of Information and Communication Engineering, University of Electronic Science and Technology of China, Chengdu, China},
	abstract = {With the growing popularity of online services such as online banking and online shopping, one of the essential research topics is how to build a privacy-preserving user abnormal behavior recommendation system. However, a machine-learning based system may present a dilemma. On one aspect, such system requires large volume of features to pre-train the model, but on another aspect, it is challenging to design usable features without looking to plaintext private data. In this paper, we propose an unorthodox approach involving graph analysis to resolve this dilemma and build a novel private-preserving recommendation system under a multilayer network framework. In experiments, we use a large, state-of-the-art dataset (containing more than 40,000 nodes and 43 million encrypted features) to evaluate the recommendation ability of our system on abnormal user behavior, yielding an overall precision rate of around 0.9, a recall rate of 1.0, and an F1-score of around 0.94. Also, we have also reported a linear time complexity for our system. Last, we deploy our system on the “Wenjuanxing” crowd-sourced system and “Amazon Mechanical Turk” for other users to evaluate in all aspects. The result shows that almost all feedbacks have achieved up to 85% satisfaction. © 2019 Song et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Algorithms; Behavior Rating Scale; Humans; Internet; Machine Learning; Privacy; Security Measures; abnormal behavior; Article; biofeedback; controlled study; learning algorithm; measurement precision; multilayer perceptron; physical performance; satisfaction; algorithm; behavior assessment; ethics; human; Internet; machine learning; organization and management; privacy},
	correspondence_address = {W. Liu; JD Urban Computing Business Unit, Chengdu, China; email: jrliuweiyi@jd.com},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {31794555},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Dorobantu20191004,
	author = {Dorobantu, Marius and Wilks, Yorick},
	title = {MORAL ORTHOSES: A NEW APPROACH TO HUMAN AND MACHINE ETHICS},
	year = {2019},
	journal = {Zygon},
	volume = {54},
	number = {4},
	pages = {1004 – 1021},
	doi = {10.1111/zygo.12560},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075171196&doi=10.1111%2fzygo.12560&partnerID=40&md5=256b365bd80fe11eac9cd45f31e683c4},
	affiliations = {University of Strasbourg, Strasbourg, France; University of Sheffield, Oxford, United Kingdom},
	abstract = {Machines are increasingly involved in decisions with ethical implications, which require ethical explanations. Current machine learning algorithms are ethically inscrutable, but not in a way very different from human behavior. This article looks at the role of rationality and reasoning in traditional ethical thought and in artificial intelligence, emphasizing the need for some explainability of actions. It then explores Neil Lawrence's embodiment factor as an insightful way of looking at the differences between human and machine intelligence, connecting it to the theological understanding of embodiment, relationality, and personhood. Finally, it proposes the notion of artificial moral orthoses, which could provide ethical explanations for both artificial and human agents, as a more promising unifying approach to human and machine ethics. © 2019 by the Joint Publication Board of Zygon},
	author_keywords = {artificial companions; artificial intelligence; David Hume; embodiment; ethics; explainable AI; machine learning; Neil Lawrence; relationality; theology},
	publisher = {Blackwell Publishing Ltd},
	issn = {05912385},
	language = {English},
	abbrev_source_title = {Zygon},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Martins2020392,
	author = {Martins, Thiago Gonçalves Dos Santos},
	title = {Comment on: “Artificial intelligence and ophthalmology”},
	year = {2020},
	journal = {Turkish Journal of Ophthalmology},
	volume = {50},
	number = {6},
	pages = {392},
	doi = {10.4274/tjo.galenos.2020.98354},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099063013&doi=10.4274%2ftjo.galenos.2020.98354&partnerID=40&md5=17cd0d0449a8d3cb94deafcef6da06fe},
	affiliations = {Federal University of São Paulo, Department of Ophthalmology, Brazil},
	author_keywords = {Artificial intelligence; Deep learning; Machine learning; Medical ethics; Ophthalmology},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Ophthalmology; algorithm; artificial intelligence; diabetic retinopathy; drug efficacy; dystrophy; Letter; macular degeneration; ophthalmology; prematurity; reliability; training; validation process; human; machine learning},
	correspondence_address = {T.G.D.S. Martins; Federal University of São Paulo, Department of Ophthalmology, Brazil; email: thiagogsmartins@yahoo.com.br},
	publisher = {Turkish Ophthalmology Society},
	issn = {21498709},
	pmid = {33389943},
	language = {English},
	abbrev_source_title = {Turk. Jour. of Ophthalmol.},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Simon2019,
	author = {Simon, Charles J.},
	title = {Ethics and Artificial General Intelligence: Technological Prediction as a Groundwork for Guidelines},
	year = {2019},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2019-November},
	doi = {10.1109/ISTAS48451.2019.8937913},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077767359&doi=10.1109%2fISTAS48451.2019.8937913&partnerID=40&md5=13ecd6c2d3f7275f34b779c5a35bd487},
	affiliations = {Future AI, Washington, DC, United States},
	abstract = {Artificial General Intelligence (AGI) is the possible future of computer systems which are as capable as humans across a broad range of intellectual requirements. In order to establish an ethical position or guidelines for the development of AGI, it is important to explore anticipated characteristics about the emergence of AGI: How sudden it could be (jolt), how soon it could be (timing), and how dangerous it could be (risk). By extrapolating today's trends in development and limitations of current AI algorithms, informed speculation can help set ethical positions and guidelines on the proper course. This paper concludes that the emergence of AGI will be gradual, soon, and only moderately dangerous and begins to address how ethical issues will change as AGI emerges from narrow AI. © 2019 IEEE.},
	author_keywords = {artificial general intelligence; artificial intelligence; deep learning; ethics; machine learning; neural networks; robotics; semantic network},
	keywords = {Artificial intelligence; Deep learning; Deep neural networks; Learning systems; Neural networks; Robotics; Semantics; AI algorithms; Artificial general intelligences; Ethical issues; ethics; Possible futures; Semantic network; Philosophical aspects},
	correspondence_address = {C.J. Simon; Future AI, Washington, United States; email: charles@futureAI.guru},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172815480-0},
	language = {English},
	abbrev_source_title = {Int Symp Technol Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2019 IEEE International Symposium on Technology and Society, ISTAS 2019; Conference date: 15 November 2019 through 16 November 2019; Conference code: 156182}
}

@CONFERENCE{Iftimie2020262,
	author = {Iftimie, Ion A. and Wilson, Richard L.},
	title = {The use of signals intelligence in offensive cyberspace operations: An anticipatory ethical analysis},
	year = {2020},
	journal = {Proceedings of the 15th International Conference on Cyber Warfare and Security, ICCWS 2020},
	pages = {262 – 269},
	doi = {10.34190/ICCWS.20.078},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083382091&doi=10.34190%2fICCWS.20.078&partnerID=40&md5=dea749082761407a77ac0162f842828a},
	affiliations = {NATO Defense College, Rome, Italy; European Union Research Center, George Washington School of Business, Washington, DC, United States; Central European University, Vienna, Austria; Hoffberger Center for Professional Ethics, University of Baltimore, Baltimore, MD, United States; Towson University, Baltimore, MD, United States},
	abstract = {This paper discusses the anticipatory ethical and social issues associated with the use of signals intelligence in support of offensive cyberspace operations. Real time raw signals intelligence analytics is quickly becoming an imperative to defending forward in cyberspace (that is, to predict, detect, and deter cyber threats before they reach their intended targets). Signals intelligence analytics in support of offensive cyberspace operations requires, however, the development and integration of a wide variety of new artificial intelligence and machine learning technologies capable of handling data across networks and at different levels of classification. In this article we pose that understanding how signals intelligence collection and processing technologies will be developed, how they will work, and how they will transform the future of offensive cyberspace operations are anticipatory ethical considerations that need further attention by multiple stakeholders-to include military/government, industry and academia involved in development of said technologies-of NATO member states. These stakeholders will need to address an increasing number of anticipatory ethical dillemmas, especially given the sensitivities and complex social ramifications of government entities employing signals intelligence analytics in support of offensive cyberspace operations. © 2020. the authors. All Rights Reserved.},
	author_keywords = {Anticipatory Ethics; Artificial Intelligence (AI); North Atlantic Treaty Alliance (NATO); Offensive Cyberspace Operations (OCO); Signals Intelligence (SIGINT)},
	keywords = {Artificial intelligence; Computer crime; Data handling; Engineering education; Philosophical aspects; Cyber threats; Ethical considerations; Government entities; Machine learning technology; Multiple stakeholders; Processing technologies; Signals intelligence; Social issues; Computers},
	editor = {Payne B.K. and Wu H.},
	publisher = {Academic Conferences and Publishing International Limited},
	isbn = {978-191276452-5},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Cyber Warf. Secur., ICCWS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 15th International Conference on Cyber Warfare and Security, ICCWS 2020; Conference date: 12 March 2020 through 13 March 2020; Conference code: 158670}
}

@ARTICLE{Graham2019,
	author = {Graham, Sarah and Depp, Colin and Lee, Ellen E. and Nebeker, Camille and Tu, Xin and Kim, Ho-Cheol and Jeste, Dilip V.},
	title = {Artificial Intelligence for Mental Health and Mental Illnesses: an Overview},
	year = {2019},
	journal = {Current Psychiatry Reports},
	volume = {21},
	number = {11},
	doi = {10.1007/s11920-019-1094-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074727113&doi=10.1007%2fs11920-019-1094-0&partnerID=40&md5=7fccad8e9cefa1a81979329b7e84d1ba},
	affiliations = {Department of Psychiatry, University of California San Diego, La Jolla, CA, United States; Sam and Rose Stein Institute for Research on Aging, University of California La Jolla, La Jolla, CA, United States; VA San Diego Healthcare System, San Diego, CA, United States; Department of Family Medicine and Public Health, University of California La Jolla, La Jolla, CA, United States; Scalable Knowledge Intelligence, IBM Research-Almaden, San Jose, CA, United States; Department of Neurosciences, University of California La Jolla, La Jolla, CA, United States; University of California San Diego, 9500 Gilman Drive, Mail Code #0664, La Jolla, 92093-0664, CA, United States},
	abstract = {Purpose of Review: Artificial intelligence (AI) technology holds both great promise to transform mental healthcare and potential pitfalls. This article provides an overview of AI and current applications in healthcare, a review of recent original research on AI specific to mental health, and a discussion of how AI can supplement clinical practice while considering its current limitations, areas needing additional research, and ethical implications regarding AI technology. Recent Findings: We reviewed 28 studies of AI and mental health that used electronic health records (EHRs), mood rating scales, brain imaging data, novel monitoring systems (e.g., smartphone, video), and social media platforms to predict, classify, or subgroup mental health illnesses including depression, schizophrenia or other psychiatric illnesses, and suicide ideation and attempts. Collectively, these studies revealed high accuracies and provided excellent examples of AI’s potential in mental healthcare, but most should be considered early proof-of-concept works demonstrating the potential of using machine learning (ML) algorithms to address mental health questions, and which types of algorithms yield the best performance. Summary: As AI techniques continue to be refined and improved, it will be possible to help mental health practitioners re-define mental illnesses more objectively than currently done in the DSM-5, identify these illnesses at an earlier or prodromal stage when interventions may be more effective, and personalize treatments based on an individual’s unique characteristics. However, caution is necessary in order to avoid over-interpreting preliminary results, and more work is required to bridge the gap between AI in mental health research and clinical care. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Bioethics; Deep learning; Depression; Machine learning; Natural language processing; Research ethics; Schizophrenia; Suicide; Technology},
	keywords = {Algorithms; Artificial Intelligence; Humans; Machine Learning; Mental Disorders; Mental Health; algorithm; artificial intelligence; biological monitoring; clinical practice; conceptual framework; depression; diagnostic accuracy; disease classification; DSM-5; electronic health record; health practitioner; human; medical ethics; mental disease; mental health; natural language processing; neuroimaging; prediction; psychological rating scale; Review; schizophrenia; social media; suicidal ideation; suicide attempt; supervised machine learning; unsupervised machine learning; machine learning; mental disease},
	correspondence_address = {D.V. Jeste; University of California San Diego, La Jolla, 9500 Gilman Drive, Mail Code #0664, 92093-0664, United States; email: djeste@ucsd.edu},
	publisher = {Current Medicine Group LLC 1},
	issn = {15233812},
	coden = {CPRUB},
	pmid = {31701320},
	language = {English},
	abbrev_source_title = {Curr. Psychiatry Rep.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 175; All Open Access, Green Open Access}
}

@CONFERENCE{Rivas2019361,
	author = {Rivas, Pablo and Chelsi, Chelsi and Nishit, Nishit and Ravula, Laharika},
	title = {Application-agnostic chatbot deployment considerations: A case study},
	year = {2019},
	journal = {Proceedings - 6th Annual Conference on Computational Science and Computational Intelligence, CSCI 2019},
	pages = {361 – 365},
	doi = {10.1109/CSCI49370.2019.00070},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084749148&doi=10.1109%2fCSCI49370.2019.00070&partnerID=40&md5=ce6ceda234cec32d03fa775cd1251137},
	affiliations = {Department of Computer Science, School of Computer Science and Mathematics, Marist College, 3399 North Road, Poughkeepsie, 12601, New York, United States},
	abstract = {Advances in machine learning are making possible the interaction between humans and machines, coming closer to passing the Turing test. Chatbots, specifically, are a technology that uses the latest advances in natural language processing and machine learning to understand text and produce text in response to input. While this is an important achievement today, we must consider specific challenges that chatbot deployments might pose. This paper looks back to a historical event that took place in 2016 with the purpose of extracting important, memorable, lessons. The study suggests that certain assumptions with respect to societal values are of paramount importance and need to be considered carefully along with a proper platform selection. © 2019 IEEE.},
	author_keywords = {Artificial intelligence; Chatbots; Emerging technologies; Ethics; Society; Technology},
	keywords = {Machine learning; Natural language processing systems; Chatbot; Chatbots; NAtural language processing; Platform selection; Turing tests; Learning algorithms},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172815584-5},
	language = {English},
	abbrev_source_title = {Proc. - Annu. Conf. Comput. Sci. Comput. Intell., CSCI},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 6th Annual International Conference on Computational Science and Computational Intelligence, CSCI 2019; Conference date: 5 December 2019 through 7 December 2019; Conference code: 159441}
}

@CONFERENCE{Kuwajima201913,
	author = {Kuwajima, Hiroshi and Ishikawa, Fuyuki},
	title = {Adapting square for quality assessment of artificial intelligence systems},
	year = {2019},
	journal = {Proceedings - 2019 IEEE 30th International Symposium on Software Reliability Engineering Workshops, ISSREW 2019},
	pages = {13 – 18},
	doi = {10.1109/ISSREW.2019.00035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080861178&doi=10.1109%2fISSREW.2019.00035&partnerID=40&md5=dc8eaabf2d5a6ec47bb4b44643a5c3fa},
	affiliations = {DENSO CORPORATION and Tokyo Institute of Technology, Tokyo, Japan; National Institute of Informatics, Tokyo, Japan},
	abstract = {More and more software practitioners are tackling towards industrial applications of artificial intelligence (AI) systems, especially those based on machine learning (ML). However, many of existing principles and approaches to traditional software systems do not work effectively for the system behavior obtained by training not by logical design. In addition, unique kinds of requirements are emerging such as fairness and explainability. To provide clear guidance to understand and tackle these difficulties, we present an analysis on what quality concepts we should evaluate for AI systems. We base our discussion on ISO/IEC 25000 series, known as SQuaRE, and identify how it should be adapted for the unique nature of ML and Ethics guidelines for trustworthy AI from European Commission. We thus provide holistic insights for quality of AI systems by incorporating the ML nature and AI ethics to the traditional software quality concepts. © 2019 IEEE.},
	author_keywords = {artificial intelligence; ethics; machine learning; software quality; SQuaRE},
	keywords = {Application programs; Artificial intelligence; Computer software selection and evaluation; Ethical aspects; Learning systems; Machine learning; Quality control; Software quality; Technical presentations; Artificial intelligence systems; European Commission; Industrial applications of artificial intelligences; Quality assessment; Quality concepts; Software practitioners; SQuaRE; System behaviors; Software reliability},
	editor = {Wolter K. and Schieferdecker I. and Gallina B. and Cukier M. and Natella R. and Ivaki N. and Laranjeiro N.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172815138-0},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Symp. Softw. Reliab. Eng. Workshops, ISSREW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 30th IEEE International Symposium on Software Reliability Engineering Workshops, ISSREW 2019; Conference date: 28 October 2019 through 31 October 2019; Conference code: 157721; All Open Access, Green Open Access}
}

@ARTICLE{Karagül Yildiz2020949,
	author = {Karagül Yildiz, Tuba and Demirci, Hüseyin and Yurtay, Nilüfer},
	title = {Effect of the Clonal Selection Algorithm on Classifiers},
	year = {2020},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {43},
	pages = {949 – 959},
	doi = {10.1007/978-3-030-36178-5_84},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083458158&doi=10.1007%2f978-3-030-36178-5_84&partnerID=40&md5=0b865c3ee35c250e5521830310febc47},
	affiliations = {Department of Computer and Information Sciences, Institute of Natural Sciences, Sakarya University, Sakarya, 54187, Turkey; Department of Computer Engineering, Computer and Information Sciences Faculty, Sakarya University, Sakarya, 54187, Turkey},
	abstract = {To be able to make the classification process, there should be a sufficient number of samples. Collecting a sufficient number of samples, especially for those dealing with medical data, is a laborious task. To obtain the approval of the ethics committee in our country, patient data coming from a certain time interval rather than a sample number can be requested. Therefore, there are difficulties in reaching a sufficient number of samples. In this study, the effect of the clonal selection algorithm which is one of the artificial immune system algorithms on standard classifiers was investigated. The chronic kidney disease dataset from the university of California Irvine machine learning repository was chosen as the dataset. Among the commonly used methods for classification, methods of k nearest neighbor, decision trees and artificial neural networks were selected as classifiers. While k nearest neighbor is a distance-based algorithm, a decision tree is a regression-based method and the artificial neural network which is quite popular nowadays is a nature-inspired method. According to the results of the experiments, it is found that the data reproduction process by using the clonal selection algorithm has increased the performances of the classifiers. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Artificial immune system; Chronic kidney disease; Classification; Clonal selection algorithm; Data mining},
	keywords = {Biomimetics; Cell proliferation; Decision trees; Genetic algorithms; Hospital data processing; Motion compensation; Nearest neighbor search; Neural networks; Artificial immune system algorithms; Chronic kidney disease; Classification process; Clonal selection algorithms; Distance based algorithm; K-nearest neighbors; Machine learning repository; University of California; Trees (mathematics)},
	correspondence_address = {T. Karagül Yildiz; Department of Computer and Information Sciences, Institute of Natural Sciences, Sakarya University, Sakarya, 54187, Turkey; email: tkaragul@sakarya.edu.tr},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {23674512},
	language = {English},
	abbrev_source_title = {Lecture. Notes. Data Eng. Commun. Tech.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cho20201,
	author = {Cho, Soohyun and Vasarhelyi, Miklos A. and Sun, Ting and Zhang, Chanyuan},
	title = {Learning from machine learning in accounting and assurance},
	year = {2020},
	journal = {Journal of Emerging Technologies in Accounting},
	volume = {17},
	number = {1},
	pages = {1 – 10},
	doi = {10.2308/jeta-10718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090629575&doi=10.2308%2fjeta-10718&partnerID=40&md5=35ba36e1b57d4c4447989354df3300b9},
	affiliations = {Rutgers, The State University of New Jersey, United States; The College of New Jersey, United States; Rutgers, The State University of New Jersey, United States; Southwestern University of Finance and Economics, China},
	abstract = {Machine learning is a subset of artificial intelligence, and it is a computational method that learns patterns from large and complex data. The learning processes enable us to make predictions for future events. In the accounting and assurance profession, machine learning is gradually being applied to various tasks like reviewing source documents, analyzing business transactions or activities, and assessing risks. In academic research, machine learning has been used to make predictions of fraud, bankruptcy, material misstatements, and accounting estimates. More importantly, machine learning is generating awareness about the inductive reasoning methodology, which has long been undervalued in the mainstream of academic research in accounting and auditing. The use of machine learning in accounting/auditing research and practice is also raising concerns about its potential bias and ethical implications. Therefore, this editorial aims to call the readers’ attention to these issues and encourage scholars to perform research in this domain. © 2020, American Accounting Association. All rights reserved.},
	author_keywords = {Accounting; Assurance; Biases and ethics of machine learning; Inductive reasoning; Machine learning},
	publisher = {American Accounting Association},
	issn = {15541908},
	language = {English},
	abbrev_source_title = {J. Emerg. Technol. Account.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@ARTICLE{Salminen202082,
	author = {Salminen, Joni and Jung, Soon-gyo and Chowdhury, Shammur A. and Jansen, Bernard J.},
	title = {Rethinking personas for fairness: Algorithmic transparency and accountability in data-driven personas},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12217 LNCS},
	pages = {82 – 100},
	doi = {10.1007/978-3-030-50334-5_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088753434&doi=10.1007%2f978-3-030-50334-5_6&partnerID=40&md5=22a06b28713ff05731938e0c28d76885},
	affiliations = {Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar; University of Turku, Turku, Finland},
	abstract = {Algorithmic fairness criteria for machine learning models are gathering widespread research interest. They are also relevant in the context of data-driven personas that rely on online user data and opaque algorithmic processes. Overall, while technology provides lucrative opportunities for the persona design practice, several ethical concerns need to be addressed to adhere to ethical standards and to achieve end user trust. In this research, we outline the key ethical concerns in data-driven persona generation and provide design implications to overcome these ethical concerns. Good practices of data-driven persona development include (a) creating personas also from outliers (not only majority groups), (b) using data to demonstrate diversity within a persona, (c) explaining the methods and their limitations as a form of transparency, and (d) triangulating the persona information to increase truthfulness. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Algorithms; Data; Ethics; Fairness; Personas; Transparency},
	keywords = {Human computer interaction; Philosophical aspects; Transparency; Algorithmic process; Design implications; Design practice; Ethical concerns; Ethical standards; Fairness criteria; Machine learning models; Research interests; Machine learning},
	correspondence_address = {J. Salminen; Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar; email: jsalminen@hbku.edu.qa},
	editor = {Degen H. and Reinerman-Jones L.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303050333-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 1st International Conference on Artificial Intelligence in HCI, AI-HCI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020; Conference date: 19 July 2020 through 24 July 2020; Conference code: 242489}
}

@ARTICLE{Burke2019319,
	author = {Burke, Victoria I. and Burke, Robin D.},
	title = {Powerlessness and personalization},
	year = {2019},
	journal = {International Journal of Applied Philosophy},
	volume = {33},
	number = {2},
	pages = {319 – 343},
	doi = {10.5840/ijap202034131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099025549&doi=10.5840%2fijap202034131&partnerID=40&md5=f4d3a39b3c7439018c00431e8d519919},
	affiliations = {University of Guelph, Canada; University of Colorado, Boulder, United States},
	abstract = {Is privacy the key ethical issue of the internet age? This coauthored essay argues that even if all of a user's privacy concerns were met through secure communication and computation, there are still ethical problems with personalized information systems. Our objective is to show how computer-mediated life generates what Ernesto Laclou and Chantal Mouffe call an “atypical form of social struggle.” Laclau and Mouffe develop a politics of contingent identity and transient articulation (or social integration) by means of the notions of absent, symbolic, hegemonic power and antagonistic transitions or relations. In this essay, we introduce a critical approach to one twenty-first-century atypical social struggle that, we claim, has a disproportionate effect on those who experience themselves as powerless. Our aim is to render explicit the forms of social mediation and distortion that result from large-scale machine learning as applied to personal preference information. We thus bracket privacy in order to defend some aspects of the EU GDPR that will give individuals more control over their experience of the internet if they want to use it and, thereby, decrease the unwanted epistemic effects of the internet. Our study is thus a micropolitics in in the Deleuzian micropolitical sense and a preliminary analysis of an atypical social struggle. © 2019 Philosophy Documentation Center. All rights reserved.},
	author_keywords = {Business ethics; Digital ethics; Epistemic injustice; Feminist politics; Limits of privacy; Power; Property; Right to contingency},
	publisher = {Philosophy Documentation Center},
	issn = {0739098X},
	language = {English},
	abbrev_source_title = {Int. J. Appl. Philos.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Murukannaiah20201706,
	author = {Murukannaiah, Pradeep K. and Ajmeri, Nirav and Jonker, Catholijn M. and Singh, Munindar P.},
	title = {New foundations of ethical multiagent systems blue sky ideas track},
	year = {2020},
	journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
	volume = {2020-May},
	pages = {1706 – 1710},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096719484&partnerID=40&md5=ce1b21b0aee2af7f5a04f42ab497ce47},
	affiliations = {Delft University of Technology, Delft, Netherlands; North Carolina State University, Raleigh, NC, United States},
	abstract = {Ethics is inherently a multiagent concern. However, research on AI ethics today is dominated by work on individual agents: (1) how an autonomous robot or car may harm or (differentially) benefit people in hypothetical situations (the so-called trolley problems) and (2) how a machine learning algorithm may produce biased decisions or recommendations. The societal framework is largely omitted. To develop new foundations for ethics in AI, we adopt a sociotechnical stance in which agents (as technical entities) help autonomous social entities or principals (people and organizations). This multiagent conception of a sociotechnical system (STS) captures how ethical concerns arise in the mutual interactions of multiple stakeholders. These foundations would enable us to realize ethical STSs that incorporate social and technical controls to respect stated ethical postures of the agents in the STSs. The envisioned foundations require new thinking, along two broad themes, on how to realize (1) an STS that reflects its stakeholders' values and (2) individual agents that function effectively in such an STS. © 2020 International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS). All rights reserved.},
	author_keywords = {Ethics; Norms; Preferences; Sociotechnical systems; Values},
	keywords = {Foundations; Learning algorithms; Machine learning; Multi agent systems; Philosophical aspects; Turing machines; Ethical concerns; Individual agent; Multiple stakeholders; Mutual interaction; Social entities; Sociotechnical; Sociotechnical systems; Technical control; Autonomous agents},
	editor = {An B. and El Fallah Seghrouchni A. and Sukthankar G.},
	publisher = {International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS)},
	issn = {15488403},
	isbn = {978-145037518-4},
	language = {English},
	abbrev_source_title = {Proc. Int. Joint Conf. Auton. Agents Multiagent Syst., AAMAS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; Conference name: 19th International Conference on Autonomous Agents and Multiagent Systems, AAMAS 2020; Conference date: 19 May 2020 through 13 May 2020; Conference code: 164997}
}

@ARTICLE{Kestens2019,
	author = {Kestens, Yan and Winters, Meghan and Fuller, Daniel and Bell, Scott and Berscheid, Janelle and Brondeel, Ruben and Cantinotti, Michael and Datta, Geetanjali and Gauvin, Lise and Gough, Margot and Laberee, Karen and Lewis, Paul and Lord, Sébastien and Luan, Hui and McKay, Heather and Morency, Catherine and Muhajarine, Nazeem and Nelson, Trisalyn and Ottoni, Callista and Stephens, Zoe Poirier and Pugh, Caitlin and Rancourt, Gabrielle and Shareck, Martin and Sims-Gould, Joanie and Sones, Meridith and Stanley, Kevin and Thierry, Benoit and Thigpen, Calvin and Wasfi, Rania},
	title = {INTERACT: A comprehensive approach to assess urban form interventions through natural experiments},
	year = {2019},
	journal = {BMC Public Health},
	volume = {19},
	number = {1},
	doi = {10.1186/s12889-018-6339-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059829611&doi=10.1186%2fs12889-018-6339-z&partnerID=40&md5=dd207caf0ef7bd8bb37176eb2076c7b4},
	affiliations = {École de Santé Publique de l'Université de Montréal, Centre de Recherche du CHUM, Pavillon S, Tour St-Antoine - 850 St-Denis - S03-280, Montreal, H2X 0A9, QC, Canada; Simon Fraser University, 8888 University Drive, Burnaby, V5A 1S6, BC, Canada; Memorial University of Newfoundland, 230 Elizabeth Avenue, St. John's, A1C 5S7, NF, Canada; University of Saskatchewan, 105 Administration Place, Saskatoon, S7N 5A2, SK, Canada; Université du Québec À Trois-Rivières, 3351 Boulevard des Forges, Trois-Rivières, G9A 5H7, QC, Canada; University of British Columbia, 2329 West Mall, Vancouver, V6T 1Z4, BC, Canada; Polytechnique Montréal, 2900 Edouard Montpetit Blvd, Montreal, H3T 1J4, QC, Canada; Arizona State University, PO Box 875302, Tempe, 85287-5302, AZ, United States; University of Toronto, 155 College Street, Toronto, M5T 1P8, ON, Canada},
	abstract = {Background: Urban form interventions can result in positive and negative impacts on physical activity, social participation, and well-being, and inequities in these outcomes. Natural experiment studies can advance our understanding of causal effects and processes related to urban form interventions. The INTErventions, Research, and Action in Cities Team (INTERACT) is a pan-Canadian collaboration of interdisciplinary scientists, urban planners, and public health decision makers advancing research on the design of healthy and sustainable cities for all. Our objectives are to use natural experiment studies to deliver timely evidence about how urban form interventions influence health, and to develop methods and tools to facilitate such studies going forward. Methods: INTERACT will evaluate natural experiments in four Canadian cities: the Arbutus Greenway in Vancouver, British Columbia; the All Ages and Abilities Cycling Network in Victoria, BC; a new Bus Rapid Transit system in Saskatoon, Saskatchewan; and components of the Sustainable Development Plan 2016-2020 in Montreal, Quebec, a plan that includes urban form changes initiated by the city and approximately 230 partnering organizations. We will recruit a cohort of between 300 and 3000 adult participants, age 18 or older, in each city and collect data at three time points. Participants will complete health and activity space surveys and provide sensor-based location and physical activity data. We will conduct qualitative interviews with a subsample of participants in each city. Our analysis methods will combine machine learning methods for detecting transportation mode use and physical activity, use temporal Geographic Information Systems to quantify changes to urban intervention exposure, and apply analytic methods for natural experiment studies including interrupted time series analysis. Discussion: INTERACT aims to advance the evidence base on population health intervention research and address challenges related to big data, knowledge mobilization and engagement, ethics, and causality. We will collect ~ 100 TB of sensor data from participants over 5 years. We will address these challenges using interdisciplinary partnerships, training of highly qualified personnel, and modern methodologies for using sensor-based data. © 2019 The Author(s).},
	author_keywords = {Accelerometer; big data; Equity; GPS; Natural experiment; Physical activity; public health; Social participation; Urban form intervention; Well-being},
	keywords = {Adolescent; Adult; British Columbia; Cities; Cohort Studies; Environment Design; Evaluation Studies as Topic; Exercise; Geographic Information Systems; Humans; Interrupted Time Series Analysis; Public Health; Quebec; Research Design; Saskatchewan; Social Participation; Surveys and Questionnaires; Transportation; Urban Population; adolescent; adult; British Columbia; city; cohort analysis; environmental planning; epidemiology; evaluation study; exercise; geographic information system; human; methodology; public health; Quebec; questionnaire; Saskatchewan; social participation; traffic and transport; urban population},
	correspondence_address = {Y. Kestens; École de Santé Publique de l'Université de Montréal, Centre de Recherche du CHUM, Montreal, Pavillon S, Tour St-Antoine - 850 St-Denis - S03-280, H2X 0A9, Canada; email: yan.kestens@umontreal.ca},
	publisher = {BioMed Central Ltd.},
	issn = {14712458},
	pmid = {30630441},
	language = {English},
	abbrev_source_title = {BMC Public Health},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Hagen2020109,
	author = {Hagen, Loni},
	title = {Teaching undergraduate data science for information schools},
	year = {2020},
	journal = {Education for Information},
	volume = {36},
	number = {2},
	pages = {109 – 117},
	doi = {10.3233/EFI-200372},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089572100&doi=10.3233%2fEFI-200372&partnerID=40&md5=d4eec4088a6b6ea25efa598885ede3f0},
	affiliations = {School of Information, University of South Florida, FL, United States},
	abstract = {Using the Conway model of data science education as a guide, this paper introduces a model for undergraduate data science education for information schools. The core idea of the suggested model is that data science programs in information schools are unique due to their particular substantive expertise, which includes data management, information behavior, and ethics. This paper also suggests that, to create a data science program within an information school, it may be useful to expand curriculums by adding programming, statistics, and machine learning requirements. © 2020 - IOS Press and the authors. All rights reserved.},
	author_keywords = {Conway; Data science; data science curriculum; data science education; information science; information science education; iSchools},
	keywords = {Information management; Information behavior; Science education; Science programs; Data Science},
	correspondence_address = {L. Hagen; School of Information, University of South Florida, United States; email: lonihagen@usf.edu},
	publisher = {IOS Press},
	issn = {01678329},
	coden = {EDINE},
	language = {English},
	abbrev_source_title = {Educ Inf},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Geis2019329,
	author = {Geis, J. Raymond and Brady, Adrian P. and Wu, Carol C. and Spencer, Jack and Ranschaert, Erik and Jaremko, Jacob L. and Langer, Steve G. and Kitts, Andrea Borondy and Birch, Judy and Shields, William F. and van den Hoven van Genderen, Robert and Kotter, Elmar and Gichoya, Judy Wawira and Cook, Tessa S. and Morgan, Matthew B. and Tang, An and Safdar, Nabile M. and Kohli, Marc},
	title = {Ethics of Artificial Intelligence in Radiology: Summary of the Joint European and North American Multisociety Statement},
	year = {2019},
	journal = {Canadian Association of Radiologists Journal},
	volume = {70},
	number = {4},
	pages = {329 – 334},
	doi = {10.1016/j.carj.2019.08.010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073005240&doi=10.1016%2fj.carj.2019.08.010&partnerID=40&md5=eae1e4b70aec19c77580035e7525f43a},
	affiliations = {American College of Radiology Data Science Institute, Reston, VA, United States; Department of Radiology, National Jewish Health, Denver, CO, United States; Mercy University Hospital, Cork, Ireland; University of Texas MD Anderson Cancer Center, Houston, TX, United States; MIT, Department of Linguistics and Philosophy, Cambridge, MA, United States; Netherlands Cancer Institute, Amsterdam, Netherlands; Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Alberta, Canada; Radiology Department-Mayo Clinic, Rochester, MN, United States; Lahey Hospital & Medical Center, Burlington, MA, United States; Pelvic Pain Support Network, Poole, United Kingdom; General Counsel, American College of Radiology, Reston, VA, United States; Center of Law and Internet, Vrije Universiteit Amsterdam, Amsterdam, Netherlands; Department of Radiology, University Medical Center, Freiburg, Germany; Department of Interventional Radiology, Oregon Health & Science University, Portland, OR, United States; Department of Radiology and Imaging Sciences, Emory University, Atlanta, Georgia; Department of Radiology, University of Pennsylvania, Philadelphia, PA, United States; Department of Radiology and Imaging Sciences, University of Utah, Salt Lake City, UT, United States; Centre de Recherche du Centre Hospitalier de L'Université de Montréal, Quebec, Canada; Department of Radiology and Biomedical Imaging, UCSF, San Francisco, CA, United States},
	abstract = {This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine. AI has great potential to increase efficiency and accuracy throughout radiology, but it also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice. This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future. The radiology community should start now to develop codes of ethics and practice for AI that promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes. © 2019 The Author(s)},
	author_keywords = {Artificial intelligence; Data; Ethics; Machine learning; Radiology},
	keywords = {Artificial Intelligence; Canada; Consensus; Europe; Humans; Radiologists; Radiology; Societies, Medical; United States; adult; algorithm; article; artificial intelligence; clinical practice; consensus; diagnostic imaging; human; human dignity; information science; machine learning; medical ethics; patient care; physicist; privacy; radiologist; radiology; wellbeing; artificial intelligence; Canada; ethics; Europe; medical society; radiology; United States},
	correspondence_address = {J.R. Geis; National Jewish Health, Department of Radiology, Fort Collins, 3401 Shore Rd, 80524, United States; email: raym.geis@gmail.com},
	publisher = {Canadian Medical Association},
	issn = {08465371},
	coden = {JCARA},
	pmid = {31573399},
	language = {English},
	abbrev_source_title = {Can. Assoc. Radiol. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 52; All Open Access, Bronze Open Access}
}

@ARTICLE{Cannesson2019,
	author = {Cannesson, Maxime and Hofer, Ira and Rinehart, Joseph and Lee, Christine and Subramaniam, Kathirvel and Baldi, Pierre and Dubrawski, Artur and Pinsky, Michael R.},
	title = {Machine learning of physiological waveforms and electronic health record data to predict, diagnose and treat haemodynamic instability in surgical patients: Protocol for a retrospective study},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {12},
	doi = {10.1136/bmjopen-2019-031988},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076090024&doi=10.1136%2fbmjopen-2019-031988&partnerID=40&md5=346b94c9b45fb6547155b3430f740082},
	affiliations = {Anesthesiology, UCLA, Los Angeles, CA, United States; Anesthesiology, UC Irvine, Irvine, CA, United States; Bioengineering, UC Irvine, Irvine, CA, United States; Anesthesiology, UPMC, Pittsburgh, PA, United States; Computer Sciences, UC Irvine, Irvine, CA, United States; Computer Sciences, Carnegie Mellon University, Pittsburgh, PA, United States; Critical Care Medicine, University of Pittsburgh, School of Medicine, Pittsburgh, PA, United States},
	abstract = {Introduction About 42 million surgeries are performed annually in the USA. While the postoperative mortality is less than 2%, 12% of all patients in the high-risk surgery group account for 80% of postoperative deaths. New onset of haemodynamic instability is common in surgical patients and its delayed treatment leads to increased morbidity and mortality. The goal of this proposal is to develop, validate and test real-time intraoperative risk prediction tools based on clinical data and high-fidelity physiological waveforms to predict haemodynamic instability during surgery. Methods and analysis We will initiate our work using an existing annotated intraoperative database from the University of California Irvine, including clinical and high-fidelity waveform data. These data will be used for the training and development of the machine learning model (Carnegie Mellon University) that will then be tested on prospectively collected database (University of California Los Angeles). Simultaneously, we will use existing knowledge of haemodynamic instability patterns derived from our intensive care unit cohorts, medical information mart for intensive care II data, University of California Irvine data and animal studies to create smart alarms and graphical user interface for a clinical decision support. Using machine learning, we will extract a core dataset, which characterises the signatures of normal intraoperative variability, various haemodynamic instability aetiologies and variable responses to resuscitation. We will then employ clinician-driven iterative design to create a clinical decision support user interface, and evaluate its effect in simulated high-risk surgeries. Ethics and dissemination We will publish the results in a peer-reviewed publication and will present this work at professional conferences for the anaesthesiology and computer science communities. Patient-level data will be made available within 6 months after publication of the primary manuscript. The study has been approved by University of California, Los Angeles Institutional review board. (IRB #19-0 00 354). © 2019 Author(s) (or their employer(s)). Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {blood pressure; haemodynamics; Machine learning; physiology; safety; surgery},
	keywords = {California; Decision Support Systems, Clinical; Electronic Health Records; Hemodynamics; Humans; Intensive Care Units; Machine Learning; Postoperative Complications; Research Design; Retrospective Studies; Article; clinical decision support system; clinical protocol; decision support system; electronic health record; hemodynamic monitoring; hemodynamics; human; intensive care unit; machine learning; patient safety; physiology; postoperative complication; prediction; resuscitation; retrospective study; surgical mortality; surgical patient; surgical risk; waveform; California; electronic health record; methodology; postoperative complication},
	correspondence_address = {M. Cannesson; Anesthesiology, UCLA, Los Angeles, United States; email: MCannesson@mednet.ucla.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31796483},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kott2019,
	author = {Kott, Katharine A. and Vernon, Stephen T. and Hansen, Thomas and Yu, Christine and Bubb, Kristen J. and Coffey, Sean and Sullivan, David and Yang, Jean and O'Sullivan, John and Chow, Clara and Patel, Sanjay and Chong, James and Celermajer, David S. and Kritharides, Leonard and Grieve, Stuart M. and Figtree, Gemma A.},
	title = {Biobanking for discovery of novel cardiovascular biomarkers using imaging-quantified disease burden: Protocol for the longitudinal, prospective, BioHEART-CT cohort study},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {9},
	doi = {10.1136/bmjopen-2018-028649},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072392375&doi=10.1136%2fbmjopen-2018-028649&partnerID=40&md5=f054df70ce267b88ec1a5896de6a520b},
	affiliations = {Cardiothoracic and Vascular Health, Kolling Institute of Medical Research, St. Leonards, NSW, Australia; Department of Cardiology, Royal North Shore Hospital, St. Leonards, NSW, Australia; Faculty of Medicine and Health, University of Sydney, Sydney, NSW, Australia; School of Medicine, University of Otago, Dunedin, New Zealand; Charles Perkins Centre, University of Sydney, Sydney, NSW, Australia; Department of Biochemistry, Royal Prince Alfred Hospital, Sydney, NSW, Australia; School of Mathematics and Statistics, University of Sydney, Sydney, NSW, Australia; Heart Research Institute, Sydney, NSW, Australia; Westmead Applied Research Centre, Faculty of Medicine and Health, University of Sydney, Sydney, NSW, Australia; Department of Cardiology, Westmead Hospital, Sydney, NSW, Australia; Department of Cardiology, Royal Prince Alfred Hospital, Camperdown, NSW, Australia; Department of Cardiology, Concord Hospital, Sydney, NSW, Australia; ANZAC Research Institute, Sydney, NSW, Australia; Department of Radiology, Royal Prince Alfred Hospital, Sydney, NSW, Australia},
	abstract = {Introduction Coronary artery disease (CAD) persists as a major cause of morbidity and mortality worldwide despite intensive identification and treatment of traditional risk factors. Data emerging over the past decade show a quarter of patients have disease in the absence of any known risk factor, and half have only one risk factor. Improvements in quantification and characterisation of coronary atherosclerosis by CT coronary angiography (CTCA) can provide quantitative measures of subclinical atherosclerosis - enhancing the power of unbiased â € omics' studies to unravel the missing biology of personal susceptibility, identify new biomarkers for early diagnosis and to suggest new targeted therapeutics. Methods and analysis BioHEART-CT is a longitudinal, prospective cohort study, aiming to recruit 5000 adult patients undergoing clinically indicated CTCA. After informed consent, patient data, blood samples and CTCA imaging data are recorded. Follow-up for all patients is conducted 1 month after recruitment, and then annually for the life of the study. CTCA data provide volumetric quantification of total calcified and non-calcified plaque, which will be assessed using established and novel scoring systems. Comprehensive molecular phenotyping will be performed using state-of-the-art genomics, metabolomics, proteomics and immunophenotyping. Complex network and machine learning approaches will be applied to biological and clinical datasets to identify novel pathophysiological pathways and to prioritise new biomarkers. Discovery analysis will be performed in the first 1000 patients of BioHEART-CT, with validation analysis in the following 4000 patients. Outcome data will be used to build improved risk models for CAD. Ethics and dissemination The study protocol has been approved by the human research ethics committee of North Shore Local Health District in Sydney, Australia. All findings will be published in peer-reviewed journals or at scientific conferences. Trial registration number ACTRN12618001322224. © 2019 Author(s).},
	author_keywords = {Cardiovascular imaging; Clinical chemistry; Coronary heart disease; Ischaemic heart disease; MOLECULAR BIOLOGY; Risk management},
	keywords = {Australia; Biological Specimen Banks; Biomarkers; Computational Biology; Computed Tomography Angiography; Coronary Angiography; Coronary Artery Disease; Humans; Longitudinal Studies; Plaque, Atherosclerotic; Prospective Studies; Research Design; Risk Assessment; Risk Factors; biological marker; biological marker; adult; Article; blood sampling; cardiac imaging; cardiovascular risk; clinical outcome; cohort analysis; computed tomographic angiography; coronary angiography; coronary artery atherosclerosis; coronary artery disease; disease burden; female; follow up; human; immunophenotyping; informed consent; longitudinal study; major clinical study; male; metabolomics; multicenter study; patient coding; prospective study; proteomics; risk factor; scoring system; volumetry; atherosclerotic plaque; Australia; biobank; biology; blood; clinical trial; computed tomographic angiography; coronary angiography; coronary artery disease; diagnostic imaging; genetics; methodology; risk assessment},
	correspondence_address = {G.A. Figtree; Cardiothoracic and Vascular Health, Kolling Institute of Medical Research, St. Leonards, Australia; email: gemma.figtree@sydney.edu.au},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31537558},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Sethi20203,
	author = {Sethi, Tavpritesh and Kalia, Anushtha and Sharma, Arjun and Nagori, Aditya},
	title = {Interpretable artificial intelligence: Closing the adoption gap in healthcare},
	year = {2020},
	journal = {Artificial Intelligence in Precision Health: From Concept to Applications},
	pages = {3 – 29},
	doi = {10.1016/B978-0-12-817133-2.00001-X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095316422&doi=10.1016%2fB978-0-12-817133-2.00001-X&partnerID=40&md5=cdf10cc25c2ac7d4e2dd0f0bc5bed333},
	affiliations = {Indraprastha Institute of Information Technology, New Delhi, India; Cluster Innovation Center, University of Delhi, New Delhi, India; CSIR-Institute of Genomics and Integrative Biology, New Delhi, India},
	abstract = {Healthcare is poised to enter a new era of intelligent systems and enhanced human connection. The potential of artificial intelligence (AI) and machine learning (ML) technologies to assist decisions, optimize operations, and to free up quality human time will revolutionize how humans deliver and receive care. The success and expert-level performance of AI-based diagnostic systems have ushered in unprecedented optimism. However, there is a growing concern, about the ethics, safety, and equity in the delivery of care. The lack of clarity about its workings and the subsequent distrust has adversely affected the relationship of AI with the caregivers and receivers, thus precluding adoption. In this chapter we discuss interpretable AI as a road map toward building trusted AI that gets adopted in healthcare. The emphasis on the accuracy of AI alone needs to be revisited. Useful models will not only be accurate, but will also fulfill auxiliary criteria such as safety, fairness, privacy, accountability, and transparency. We will discuss why interpretability is key to adoption, what are its evolving meanings, and how it is realized across different classes of AI. We also compare some of these methods through concrete examples and a road map for the future for building toward the goal of trusted AI in healthcare, one paradigm at a time. © 2020 Elsevier Inc. All rights reserved.},
	author_keywords = {Artificial intelligence; Equity and inclusion; Healthcare; Machine learning; Trusted AI},
	publisher = {Elsevier},
	isbn = {978-012817133-2; 978-012817338-1},
	language = {English},
	abbrev_source_title = {Artificial Intelligence in Precis. Health: From Concept to Applications},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Resman2020,
	author = {Resman, Fredrik},
	title = {Antimicrobial stewardship programs; a two-part narrative review of step-wise design and issues of controversy. Part II: Ten questions reflecting knowledge gaps and issues of controversy in the field of antimicrobial stewardship},
	year = {2020},
	journal = {Therapeutic Advances in Infectious Disease},
	volume = {7},
	doi = {10.1177/2049936120945083},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089665414&doi=10.1177%2f2049936120945083&partnerID=40&md5=047ca2d3de76cfefc10e8f02d28c0eab},
	affiliations = {Clinical Infection Medicine, Department of Translational Medicine, Lund University, Rut Lundskogs gata 3, plan 6, Malmö, 20502, Sweden},
	abstract = {Regardless of one’s opinion on antimicrobial stewardship programs (ASPs), it is hardly possible to work in hospital care and not be exposed to the term or its practical effects. Despite the term being relatively new, the number of publications in the field is vast, including several excellent reviews of general and specific aspects. Work in antimicrobial stewardship is complex, and include aspects not only of infectious disease and microbiology, but also of epidemiology, genetics, behavioural psychology, systems science, economics and ethics, to name but a few. This review aims to take several of these aspects and the scientific evidence from antimicrobial stewardship studies and merge them into two questions: How should we design ASPs based on what we know today? and Which are the most essential unanswered questions regarding antimicrobial stewardship on a broader scale? This narrative review is written in two separate parts aiming to provide answers to the two questions. The first part, published separately, is written as a step-wise approach to designing a stewardship intervention based on the pillars of unmet need, feasibility, scientific evidence and necessary core elements. It is written mainly as a guide to someone new to the field. It is sorted into five distinct steps; (a) focusing on designing aims; (b) assessing performance and local barriers to rational antimicrobial use; (c) deciding on intervention technique; (d) practical, tailored design including core element inclusion; and (e) evaluation and sustainability. This second part formulates 10 critical questions on controversies in the field of antimicrobial stewardship. It is aimed at clinicians and researchers with stewardship experience and strives to promote discussion, not to provide answers. © The Author(s), 2020.},
	author_keywords = {antimicrobial resistance; Antimicrobial stewardship},
	keywords = {antibiotic agent; broadly neutralizing antibody; prescription drug; anti-infective therapy; antibiotic resistance; antimicrobial stewardship; antimicrobial therapy; clinical decision making; clinical outcome; confusion (uncertainty); cost effectiveness analysis; doctor patient relationship; drug cost; drug dose reduction; drug elimination; drug industry; dysbiosis; early diagnosis; health care; health care cost; health service; human; infection; machine learning; multidrug resistant bacterium; patient education; patient participation; pharmacovigilance; physician; practice guideline; priority journal; prophylaxis; respiratory tract infection; Review; risk assessment; risk factor; sensitivity and specificity; sepsis; systematic review; treatment duration; treatment outcome},
	correspondence_address = {F. Resman; Clinical Infection Medicine, Department of Translational Medicine, Lund University, Malmö, Rut Lundskogs gata 3, plan 6, 20502, Sweden; email: fredrik.resman@med.lu.se},
	publisher = {SAGE Publications Ltd},
	issn = {20499361},
	language = {English},
	abbrev_source_title = {Ther. Adv. Infect. Dis.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Courtney202015,
	author = {Courtney, Alona and Howell, Ann-Marie and Daulatzai, Najib and Savva, Nicos and Warren, Oliver and Mills, Sarah and Rasheed, Shahnawaz and Milind, Goel and Tekkis, Nicholas and Gardiner, Matthew and Dai, Tinglong and Safar, Bashar and Efron, Jonathan E and Darzi, Ara and Tekkis, Paris and Kontovounisios, Christos},
	title = {CRC COVID: Colorectal cancer services during COVID-19 pandemic. Study protocol for service evaluation},
	year = {2020},
	journal = {International Journal of Surgery Protocols},
	volume = {23},
	pages = {15 – 19},
	doi = {10.1016/j.isjp.2020.07.005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089554315&doi=10.1016%2fj.isjp.2020.07.005&partnerID=40&md5=9a3449dc774a9cd5863c9175b56504a4},
	affiliations = {Imperial College London, Department of Surgery and Cancer, Chelsea & Westminster Campus, 369 Fulham Rd, Chelsea, London, SW10 9NH, United Kingdom; Chelsea & Westminster Hospital, 369 Fulham Rd, Chelsea, London, SW10 9NH, United Kingdom; London Business School, Regent's Park, London, NW1 4SA, United Kingdom; Royal Marsden Hospital, 203 Fulham Rd, Chelsea, London, SW3 6JJ, United Kingdom; University of Cambridge School of Clinical Medicine, Hills Road, Cambridge, CB2 0SP, United Kingdom; Kennedy Institute of Rheumatology, University of Oxford, Roosevelt Drive, Headington, Oxford, OX3 7FY, United Kingdom; Johns Hopkins University Carey Business School, The Charm'tastic Mile, 100 International Drive, Baltimore, 21202, MD, United States; Johns Hopkins Hospital, 1800 Orleans St, Baltimore, 21287, MD, United States; Imperial College London, Department of Surgery and Cancer, Queen Elizabeth the Queen Mother Wing (QEQM), St Mary's Campus, Praed St, Paddington, London, W2 1NY, United Kingdom},
	abstract = {Introduction: COVID-19 has had an impact on the provision of colorectal cancer care. The aim of the CRC COVID study is to describe the changes in colorectal cancer services in the UK and USA in response to the pandemic and to understand the long-term impact. Methods and analysis: This study comprises 4 phases. Phase 1 is a survey of colorectal units that aims to evaluate adherences and deviations from the best practice guidelines during the COVID-19 pandemic. Phase 2 is a monthly prospective data collection of service provision that aims to determine the impact of the service modifications on the long-term cancer specific outcomes compared to the national standards. Phase 3 aims to predict costs attributable to the modifications of the CRC services and additional resources required to treat patients whose treatment has been affected by the pandemic. Phase 4 aims to compare the impact of COVID-19 on the NHS and USA model of healthcare in terms of service provision and cost, and to propose a standardised model of delivering colorectal cancer services for future outbreaks. Ethics and dissemination: This study is a service evaluation and does not require HRA Approval or Ethical Approval in the UK. Local service evaluation registration is required for each participating centre. In the USA, Ethical Approval was granted by the Research and Development Committee. The results of this study will be disseminated to stakeholders, submitted for peer review publications, conference presentations and circulated via social media. Registration details: Nil. © 2020},
	author_keywords = {Colorectal cancer; COVID-19; Guidelines; Service evaluation},
	keywords = {Article; cancer center; colorectal cancer; coronavirus disease 2019; data analysis; disease exacerbation; health care cost; health care delivery; health care quality; health service; human; multicenter study; pandemic; practice guideline; priority journal; prospective study; questionnaire; social media; time series analysis; unsupervised machine learning},
	correspondence_address = {C. Kontovounisios; Department of Surgery and Cancer, Imperial College London, Chelsea and Westminster and the Royal Marsden Campus, United Kingdom; email: c.kontovounisios@imperial.ac.uk},
	publisher = {Elsevier Ltd},
	issn = {24683574},
	language = {English},
	abbrev_source_title = {Int. J. Surg. Protoc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Colling2019143,
	author = {Colling, Richard and Pitman, Helen and Oien, Karin and Rajpoot, Nasir and Macklin, Philip and Bachtiar, Velicia and Booth, Richard and Bryant, Alyson and Bull, Joshua and Bury, Jonathan and Carragher, Fiona and Collins, Graeme and Craig, Clare and da Silva, Maria Freitas and Gosling, Daniel and Jacobs, Jaco and Kajland-Wilén, Lena and Karling, Johanna and Lawler, Darragh and Lee, Stephen and Miller, Keith and Mozolowski, Guy and Nicholson, Richard and O'Connor, Daniel and Rahbek, Mikkel and Sumner, Alan and Vossen, Dirk and White, Kieron and Wing, Charlotte and Wright, Corrina and Snead, David and Sackville, Tony and Verrill, Clare},
	title = {Artificial intelligence in digital pathology: a roadmap to routine use in clinical practice},
	year = {2019},
	journal = {Journal of Pathology},
	volume = {249},
	number = {2},
	pages = {143 – 150},
	doi = {10.1002/path.5310},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069855827&doi=10.1002%2fpath.5310&partnerID=40&md5=8434b272516197102fb54fd489d79e6a},
	affiliations = {Nuffield Department of Surgical Sciences, University of Oxford, John Radcliffe Hospital, Oxford, United Kingdom; National Cancer Research Institute, London, United Kingdom; Institute of Cancer Sciences, University of Glasgow, Glasgow, United Kingdom; Department of Computer Science, University of Warwick, Coventry, United Kingdom; Nuffield Department of Medicine, University of Oxford, Oxford, United Kingdom; PathLAKE (Director) and Histopathology, University Hospitals Coventry and Warwickshire NHS Trust, University Hospital, Coventry, United Kingdom; British In Vitro Diagnostics Association, London, United Kingdom; PathLAKE (Principal Investigator), Nuffield Department of Surgical Sciences and Oxford NIHR Biomedical Research Centre, University of Oxford, John Radcliffe Hospital, Oxford, United Kingdom},
	abstract = {The use of artificial intelligence will transform clinical practice over the next decade and the early impact of this will likely be the integration of image analysis and machine learning into routine histopathology. In the UK and around the world, a digital revolution is transforming the reporting practice of diagnostic histopathology and this has sparked a proliferation of image analysis software tools. While this is an exciting development that could discover novel predictive clinical information and potentially address international pathology workforce shortages, there is a clear need for a robust and evidence-based framework in which to develop these new tools in a collaborative manner that meets regulatory approval. With these issues in mind, the NCRI Cellular Molecular Pathology (CM-Path) initiative and the British In Vitro Diagnostics Association (BIVDA) have set out a roadmap to help academia, industry, and clinicians develop new software tools to the point of approved clinical use. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd. © 2019 Pathological Society of Great Britain and Ireland. Published by John Wiley & Sons, Ltd.},
	author_keywords = {analysis; artificial; digital; evidence-based; image; intelligence; pathology},
	keywords = {Artificial Intelligence; Diagnosis, Computer-Assisted; Diffusion of Innovation; Forecasting; Humans; Image Interpretation, Computer-Assisted; Pathology; Predictive Value of Tests; Reproducibility of Results; Workflow; Article; artificial intelligence; clinical practice; concept formation; evidence based practice; funding; histopathology; human; image analysis; machine learning; medical ethics; molecular pathology; priority journal; validation study; computer assisted diagnosis; forecasting; mass communication; pathology; predictive value; reproducibility; workflow},
	correspondence_address = {R. Colling; Nuffield Department of Surgical Sciences, University of Oxford, John Radcliffe Hospital, Oxford, United Kingdom; email: richard.colling@nds.ox.ac.uk},
	publisher = {John Wiley and Sons Ltd},
	issn = {00223417},
	coden = {JPTLA},
	pmid = {31144302},
	language = {English},
	abbrev_source_title = {J. Pathol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 116; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Van Calster20191651,
	author = {Van Calster, Ben and Wynants, Laure and Timmerman, Dirk and Steyerberg, Ewout W and Collins, Gary S},
	title = {Predictive analytics in health care: how can we know it works?},
	year = {2019},
	journal = {Journal of the American Medical Informatics Association},
	volume = {26},
	number = {12},
	pages = {1651 – 1654},
	doi = {10.1093/jamia/ocz130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075094658&doi=10.1093%2fjamia%2focz130&partnerID=40&md5=245db70504ae0e01a361c4dcc518de95},
	affiliations = {Department of Development and Regeneration, KU Leuven, Herestraat 49 box 805, Leuven, 3000, Belgium; Department of Biomedical Data Sciences, Leiden University Medical Center (LUMC), Leiden, Netherlands; Department of Obstetrics and Gynaecology, University Hospitals Leuven, Leuven, Belgium; Centre for Statistics in Medicine, Nuffield, Department of Orthopaedics, Rheumatology and Musculoskeletal Sciences, University of Oxford, United Kingdom; Oxford University Hospitals NHS Foundation Trust, Oxford, United Kingdom},
	abstract = {There is increasing awareness that the methodology and findings of research should be transparent. This includes studies using artificial intelligence to develop predictive algorithms that make individualized diagnostic or prognostic risk predictions. We argue that it is paramount to make the algorithm behind any prediction publicly available. This allows independent external validation, assessment of performance heterogeneity across settings and over time, and algorithm refinement or updating. Online calculators and apps may aid uptake if accompanied with sufficient information. For algorithms based on "black box" machine learning methods, software for algorithm implementation is a must. Hiding algorithms for commercial exploitation is unethical, because there is no possibility to assess whether algorithms work as advertised or to monitor when and how algorithms are updated. Journals and funders should demand maximal transparency for publications on predictive algorithms, and clinical guidelines should only recommend publicly available algorithms. © 2019 The Author(s) 2019. Published by Oxford University Press on behalf of the American Medical Informatics Association.},
	author_keywords = {artificial intelligence; external validation; machine learning; model performance; predictive analytics},
	keywords = {Algorithms; Forecasting; Humans; Machine Learning; Mobile Applications; Models, Theoretical; Ownership; Prognosis; Software; artificial intelligence; machine learning; practice guideline; review; software; algorithm; ethics; forecasting; human; mobile application; organization and management; prognosis; theoretical model},
	correspondence_address = {B. Van Calster; Department of Development and Regeneration, KU Leuven, Leuven, Herestraat 49 box 805, 3000, Belgium; email: ben.vancalster@kuleuven.be},
	publisher = {Oxford University Press},
	issn = {10675027},
	coden = {JAMAF},
	pmid = {31373357},
	language = {English},
	abbrev_source_title = {J. Am. Med. Informatics Assoc.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 64; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Bridge2019S27,
	author = {Bridge, Pete and Bridge, Robert},
	title = {Artificial Intelligence in Radiotherapy: A Philosophical Perspective},
	year = {2019},
	journal = {Journal of Medical Imaging and Radiation Sciences},
	volume = {50},
	number = {4},
	pages = {S27 – S31},
	doi = {10.1016/j.jmir.2019.09.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073006210&doi=10.1016%2fj.jmir.2019.09.003&partnerID=40&md5=bf69c47d65d33205925e61a160b23e73},
	affiliations = {Radiotherapy Department, School of Health Sciences, University of Liverpool, Liverpool, United Kingdom; Retired},
	abstract = {The increasing uptake of machine learning solutions for segmentation and planning leaves no doubt that artificial intelligence (AI) will soon be providing input into a range of radiotherapy procedures. Although this promises to deliver increased speed and accuracy, the future role of AI in relation to radiotherapy should be thought through carefully. There is currently a gap between published developments and widespread adoption, which provides some space to prepare the workforce and to consider the implications on practice. It is rare to find philosophical input into a medical journal, but the advent of AI makes this perspective increasingly important. Philosophical insight can help explore the potential impact of AI, in particular, on human creativity and oversight. Without this perspective, we run the risk of focusing solely on the immediate logistical impact on patients and departments. This commentary identifies three key aspects of radiotherapy that the authors feel would suffer most under AI control: creativity, innovation, and patient safety, which all demand uniquely human attributes. The article also provides insight from a philosophical perspective with regard to human consciousness, ethics, and empathy. Philosophically we should, perhaps, retain ethical concerns about the widening role of AI in radiotherapy beyond simple quantitative interpretation and image processing. As developments continue, we have time to determine how our roles will evolve and to establish a framework for ensuring appropriate human input into patient care. Most importantly, we must start to embed a philosophical approach to adoption of AI technology from the outset if we are to prepare ourselves for the challenge that lies ahead. © 2019},
	author_keywords = {Artificial intelligence; philosophy; radiotherapy},
	keywords = {Animals; Artificial Intelligence; Chickens; Consciousness; Creativity; Humans; Patient Safety; Philosophy, Medical; Radiotherapy; adoption; adult; artificial intelligence; consciousness; creativity; drug safety; empathy; ethics; human; image processing; machine learning; medical literature; note; patient care; patient safety; plant leaf; radiotherapy; velocity; workforce; animal; chicken; ethics; philosophy; procedures; radiotherapy},
	correspondence_address = {P. Bridge; School of Health Sciences, University of Liverpool, Liverpool, Brownlow Hill, L69 3GB, United Kingdom; email: pete.bridge@liverpool.ac.uk},
	publisher = {Elsevier Inc.},
	issn = {19398654},
	pmid = {31591033},
	language = {English},
	abbrev_source_title = {J. Med. Imaging Radiat. Sci.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Bronze Open Access}
}

@ARTICLE{Zhai2019,
	author = {Zhai, Donghui and Schiavone, Giuseppina and Van Diest, Ilse and Vrieze, Elske and DeRaedt, Walter and Van Hoof, Chris},
	title = {Ambulatory Smoking Habits Investigation based on Physiology and Context (ASSIST) using wearable sensors and mobile phones: Protocol for an observational study},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {9},
	doi = {10.1136/bmjopen-2018-028284},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071896960&doi=10.1136%2fbmjopen-2018-028284&partnerID=40&md5=976db3d21fa63f707717708060e10f0b},
	affiliations = {Connected Health Solution Group, IMEC, Leuven, Belgium; Department of Electrical Engineering (ESAT), KU Leuven, Leuven, Belgium; Connected Health Solution Group, Holst Centre, Eindhoven, Netherlands; Health Psychology, Faculty of Psychology and Educational Sciences, KU Leuven, Leuven, Belgium; Department of Neurosciences, Psychiatry Research Group, KU Leuven, Leuven, Belgium},
	abstract = {Introduction: Smoking prevalence continues to be high over the world and smoking-induced diseases impose a heavy burden on the medical care system. As believed by many researchers, a promising way to promote healthcare and well-being at low cost for the large vulnerable smoking population is through eHealth solutions by providing self-help information about smoking cessation. But in the absence of first-hand knowledge about smoking habits in daily life settings, systems built on these methods often fail to deliver proactive and tailored interventions for different users and situations over time, thus resulting in low efficacy. To fill the gap, an observational study has been developed on the theme of objective and non-biased monitoring of smoking habits in a longitudinal and ambulatory mode. This paper presents the study protocol. The primary objective of the study is to reveal the contextual and physiological pattern of different smoking behaviours using wearable sensors and mobile phones. The secondary objectives are to (1) analyse cue factors and contextual situations of smoking events; (2) describe smoking types with regard to users' characteristics and (3) compare smoking types between and within subjects. Methods and analyses: This is an observational study aimed at reaching 100 participants. Inclusion criteria are adults aged between 18 and 65 years, current smoker and office worker. The primary outcome is a collection of a diverse and inclusive data set representing the daily smoking habits of the general smoking population from similar social context. Data analysation will revolve around our primary and secondary objectives. First, linear regression and linear mixed model will be used to estimate whether a factor or pattern have consistent (p value<0.05) correlation with smoking. Furthermore, multivariate multilevel analysis will be used to examine the influence of smokers' characteristics (sex, age, education, socioeconomic status, nicotine dependence, attitudes towards smoking, quit attempts, etc), contextual factors, and physical and emotional statuses on their smoking habits. Most recent machine learning techniques will also be explored to combine heterogeneous data for classification of smoking events and prediction of craving. Ethics and dissemination: The study was designed together by an interdisciplinary group of researchers, including psychologist, psychiatrist, engineer and user involvement coordinator. The protocol was reviewed and approved by the ethical review board of UZ Leuven on 18 April 2016, with an approval number S60078. The study will allow us to characterise the types of smokers and triggering events. These findings will be disseminated through peer-reviewed articles. © Author(s) (or their employer(s)) 2019.},
	author_keywords = {biotechnology and bioinformatics; epidemiology; protocols and guidelines; public health; rehabilitation medicine; substance misuse},
	keywords = {Adolescent; Adult; Aged; Cell Phone; Female; Humans; Male; Middle Aged; Monitoring, Ambulatory; Observational Studies as Topic; Research Design; Smoking; Smoking Cessation; Wearable Electronic Devices; Young Adult; adolescent; adult; aged; ambulatory monitoring; devices; electronic device; epidemiology; female; human; male; methodology; middle aged; mobile phone; observational study; procedures; smoking; smoking cessation; young adult},
	correspondence_address = {D. Zhai; Connected Health Solution Group, IMEC, Leuven, Belgium; email: donghui.zhai@kuleuven.be},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31492781},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Watney2020398,
	author = {Watney, M.M.},
	title = {Artificial intelligence and its’ legal risk to cybersecurity},
	year = {2020},
	journal = {European Conference on Information Warfare and Security, ECCWS},
	volume = {2020-June},
	pages = {398 – 405},
	doi = {10.34190/EWS.20.026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094646915&doi=10.34190%2fEWS.20.026&partnerID=40&md5=18cd88e285e4b9ad05d4cab40d3d46ba},
	affiliations = {University of Johannesburg, South Africa},
	abstract = {The risk pertaining to data and technology are continuously growing in scale and severity as the dependence on, and advancement in technology grows. The last decade has seen hundreds of cases of identity theft, loss of money and data breaches. It is estimated that by the year 2021, cybercrime losses may cost upwards of $6 million annually. Due to the constant risk of intrusions, the tech industry, businesses and government bodies must safeguard technology and data and this is where cybersecurity plays a major and critical role. It may be considered as the first line of defense against intrusions. The tools and techniques developed and supported by AI and machine learning (ML) are now expanding to cybersecurity to protect against cybercrime. There are many advantages in using AI-ML technology for cybersecurity but it is a double-edged sword. Just as AI cybersecurity technology may be used to more accurately identify and stop intrusions, the AI systems may be exploited for the commission of cybercrime. Cybersecurity is not an issue that a government can address on its own; it requires multi-stakeholders to work together in addressing the legal risk AI-ML technology presents to cybersecurity. The discussion is divided into two parts: Part 1 explores the beneficial use of AI cybersecurity technology; and Part 2 considers the harmful use of AI such as data breaches and the commission of cybercrimes. Cybersecurity and cybercrime are issues that cannot be separated from each other. AI-driven cybersecurity technology must keep pace with the legal risk that the use of AI in the commission of cybercrime poses otherwise it cannot effectively prevent, detect, respond to and recover from an intrusion. A preventative approach rather than a detection-focused approach should be applied to cybersecurity. The discussion identifies the legal risk that the use of AI for cybersecurity presents and how it may be addressed by means of ethics, policies and laws. © 2020 Curran Associates Inc.. All rights reserved.},
	author_keywords = {AI-driven cybersecurity; AI-driven cybercrime; Data breach; The legal risk AI-ML technology presents to cybersecurity},
	keywords = {Computer crime; Cybersecurity; AI-driven cybercrime; AI-driven cybersecurity;; Cyber security; Cyber-crimes; Data breach; Identity theft; Legal risks; Machine learning technology; The legal risk AI-machine learning technology present to cybersecurity; Artificial intelligence},
	correspondence_address = {M.M. Watney; University of Johannesburg, South Africa; email: mwatney@uj.ac.za},
	editor = {Eze T. and Speakman L. and Onwubiko C.},
	publisher = {Curran Associates Inc.},
	issn = {20488602},
	isbn = {978-191276461-7},
	language = {English},
	abbrev_source_title = {European Conf. Inf. Warfare Security, ECCWS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 19th European Conference on Cyber Warfare and Security, ECCWS 2020; Conference date: 25 June 2020 through 26 June 2020; Conference code: 163901; All Open Access, Bronze Open Access}
}

@ARTICLE{Chancellor2019,
	author = {Chancellor, Stevie and Baumer, Eric P.S. and De Choudhury, Munmun},
	title = {Who is the “human” in human-centered machine learning: The case of predicting mental health from social media},
	year = {2019},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	volume = {3},
	number = {CSCW},
	doi = {10.1145/3359249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075076270&doi=10.1145%2f3359249&partnerID=40&md5=33078f28e52f0c3507d68807ba38e044},
	affiliations = {Georgia Tech, Atlanta, GA, United States; Lehigh University, Bethlehem, PA, United States},
	abstract = {“Human-centered machine learning” (HCML) combines human insights and domain expertise with data-driven predictions to answer societal questions. This area’s inherent interdisciplinarity causes tensions in the obligations researchers have to the humans whose data they use. This paper studies how scientific papers represent human research subjects in HCML. Using mental health status prediction on social media as a case study, we conduct thematic discourse analysis on 55 papers to examine these representations. We identify five discourses that weave a complex narrative of who the human subject is in this research: Disorder/Patient, Social Media, Scientific, Data/Machine Learning, and Person. We show how these five discourses create paradoxical subject and object representations of the human, which may inadvertently risk dehumanization. We also discuss the tensions and impacts of interdisciplinary research; the risks of this work to scientific rigor, online communities, and mental health; and guidelines for stronger HCML research in this nascent area. © 2019 Association for Computing Machinery.},
	author_keywords = {Human-centered machine learning; Machine learning; Mental health; Research ethics; Social media},
	keywords = {Forecasting; Health; Health risks; Learning systems; Machine learning; Discourse analysis; Interdisciplinarity; Interdisciplinary research; Mental health; Object representations; On-line communities; Research ethics; Social media; Social networking (online)},
	publisher = {Association for Computing Machinery},
	issn = {25730142},
	language = {English},
	abbrev_source_title = {Proc. ACM Hum. Comput. Interact.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 80; All Open Access, Bronze Open Access}
}

@BOOK{Girasa20201,
	author = {Girasa, Rosario},
	title = {Artificial intelligence as a disruptive technology: Economic transformation and government regulation},
	year = {2020},
	journal = {Artificial Intelligence as a Disruptive Technology: Economic Transformation and Government Regulation},
	pages = {1 – 331},
	doi = {10.1007/978-3-030-35975-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085450298&doi=10.1007%2f978-3-030-35975-1&partnerID=40&md5=2260b223a400c03f1e7ec496aa3a6abe},
	affiliations = {Goldstein Academic Center 203, Pace University, Pleasantville, NY, United States},
	abstract = {Introduction Artificial intelligence (AI) is the latest technological evolution which is transforming the global economy and is a major part of the “Fourth Industrial Revolution.” This book covers the meaning, types, subfields and applications of AI, including U.S. governmental policies and regulations, ethical and privacy issues, particularly as they pertain and affect facial recognition programs and the Internet-of Things (IoT). There is a lengthy analysis of bias, AI’s effect on the current and future job market, and how AI precipitated fake news. In addition, the text covers basics of intellectual property rights and how AI will transform their protection. The author then moves on to explore international initiatives from the European Union, China’s New Generation Development Plan, other regional areas, and international conventions. The book concludes with a discussion of super intelligence and the question and applicability of consciousness in machines. The interdisciplinary scope of the text will appeal to any scholars, students and general readers interested in the effects of AI on our society, particularly in the fields of STS, economics, law and politics. © The Editor(s) (if applicable) and The Author(s), under exclusive licence to Springer Nature Switzerland AG 2020.},
	author_keywords = {AI ethics; Artificial intelligence; Blockchain machine learning; DARPA; Disruptive technology; Facial recognition programs; Fourth industrial revolution; General data protection regulation; Government regulation; INTELLECTUAL PROPERTY RIGHTS AND AI; Internet-of-things; Privacy; Transformative technologies},
	publisher = {Palgrave Macmillan},
	isbn = {978-303035975-1; 978-303035974-4},
	language = {English},
	abbrev_source_title = {Artificial Intelligence as a Disruptive Technology: Economic Transformation and Government Regulation},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20}
}

@ARTICLE{Geis2019,
	author = {Geis, J. Raymond and Brady, Adrian and Wu, Carol C. and Spencer, Jack and Ranschaert, Erik and Jaremko, Jacob L. and Langer, Steve G. and Kitts, Andrea Borondy and Birch, Judy and Shields, William F. and van den Hoven van Genderen, Robert and Kotter, Elmar and Gichoya, Judy Wawira and Cook, Tessa S. and Morgan, Matthew B. and Tang, An and Safdar, Nabile M. and Kohli, Marc},
	title = {Ethics of artificial intelligence in radiology: summary of the joint European and North American multisociety statement},
	year = {2019},
	journal = {Insights into Imaging},
	volume = {10},
	number = {1},
	doi = {10.1186/s13244-019-0785-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073982110&doi=10.1186%2fs13244-019-0785-8&partnerID=40&md5=00706e751ac4522dc5f85b47624361f8},
	affiliations = {American College of Radiology Data Science Institute, Reston, VA, United States; Department of Radiology, National Jewish Health, Denver, CO, United States; Mercy University Hospital, Cork, Ireland; University of Texas MD Anderson Cancer Center, Houston, TX, United States; Department of Linguistics and Philosophy, MIT, Cambridge, MA, United States; Netherlands Cancer Institute, Amsterdam, Netherlands; Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, AB, Canada; Radiology Department-Mayo Clinic, Rochester, MN, United States; Lahey Hospital & Medical Center, Burlington, MA, United States; Pelvic Pain Support Network, Poole, United Kingdom; General Counsel, American College of Radiology, Reston, VA, United States; Center of Law and Internet, Vrije Universiteit Amsterdam, Amsterdam, Netherlands; Department of Radiology, University Medical Center, Freiburg, Germany; Department of Interventional Radiology, Oregon Health & Science University, Portland, OR, United States; Department of Radiology and Imaging Sciences, Emory University, Atlanta, GA, United States; Department of Radiology, University of Pennsylvania, Philadelphia, PA, United States; Department of Radiology and Imaging Sciences, University of Utah, Salt Lake City, UT, United States; Centre de Recherche du Centre Hospitalier de L’Université de Montréal, QC, Canada; Department of Radiology and Biomedical Imaging, UCSF, San Francisco, CA, United States},
	abstract = {This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine. AI has great potential to increase efficiency and accuracy throughout radiology, but also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence, and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice. This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future. The radiology community should start now to develop codes of ethics and practice for AI which promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes. © 2019, The Author(s).},
	author_keywords = {Artificial Intelligence; Data; Ethics; Machine Learning; Radiology},
	correspondence_address = {J.R. Geis; American College of Radiology Data Science Institute, Reston, United States; email: raym.geis@gmail.com},
	publisher = {Springer Verlag},
	issn = {18694101},
	language = {English},
	abbrev_source_title = {Insights Imaging},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 43; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Misra2020100,
	author = {Misra, Santosh K. and Das, Satyasiba and Gupta, Sumeet and Sharma, Sujeet K.},
	title = {Public Policy and Regulatory Challenges of Artificial Intelligence (AI)},
	year = {2020},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {617},
	pages = {100 – 111},
	doi = {10.1007/978-3-030-64849-7_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098170799&doi=10.1007%2f978-3-030-64849-7_10&partnerID=40&md5=ea7080fe9dda785be9fdb97af1472d9b},
	affiliations = {CEO, Tamil Nadu e-Governance Agency, Chennai, India; Indian Institute of Management, Raipur, India; Indian Institute of Management, Tiruchirappalli, India},
	abstract = {Artificial Intelligence (AI) usage is rapidly expanding in our society. Private sector has already taken the leap of faith in using AI for efficiency and for generating better value for the customers and shareholders. The promise of AI is quite alluring for the governments as well. It promises to be the breakthrough technology which can catapult public sector to hitherto unseen efficiency and productivity. It has the potential to truly transform the public service delivery and the way government interfaces with citizens – from a demand driven model to a predictive model of public service delivery. However, there are a large number of pitfalls and blind-spots associated with AI, which make its adoption in government particularly challenging. For successful adoption of AI in public sector, governments must understand these challenges clearly and lay down regulatory public policies to ensure that the possible adverse impacts (such as exclusion, bias etc.) of AI are mitigated. This paper attempts to systematically explore these challenges with a view to enable public policy makers to respond to them. © 2020, IFIP International Federation for Information Processing.},
	author_keywords = {ANN; Artificial intelligence; Autonomous systems; Bias; Challenges of AI; Equity; Ethics; Fairness; IoT; Machine learning; Privacy; Public policy; Regulation of AI; Regulatory challenges of AI; Safety},
	keywords = {Diffusion; Efficiency; Predictive analytics; Public policy; Breakthrough technology; Demand-driven; Leap of faiths; Predictive modeling; Private sectors; Public policy makers; Public sector; Public service deliveries; Artificial intelligence},
	correspondence_address = {S.K. Misra; CEO, Tamil Nadu e-Governance Agency, Chennai, India; email: santoshmisraias@gmail.com},
	editor = {Sharma S.K. and Dwivedi Y.K. and Metri B. and Rana N.P.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {18684238},
	isbn = {978-303064848-0},
	language = {English},
	abbrev_source_title = {IFIP Advances in Information and Communication Technology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: IFIP WG 8.6 International Conference on Transfer and Diffusion of IT, TDIT 2020; Conference date: 18 December 2020 through 19 December 2020; Conference code: 253189; All Open Access, Green Open Access}
}

@ARTICLE{Kaplan202037,
	author = {Kaplan, Andreas and Haenlein, Michael},
	title = {Rulers of the world, unite! The challenges and opportunities of artificial intelligence},
	year = {2020},
	journal = {Business Horizons},
	volume = {63},
	number = {1},
	pages = {37 – 50},
	doi = {10.1016/j.bushor.2019.09.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073998760&doi=10.1016%2fj.bushor.2019.09.003&partnerID=40&md5=88e97bf401a478d2a8f7039d2022b94b},
	affiliations = {ESCP Europe, Heubnerweg 8-10, Berlin, D-14059, Germany; ESCP Europe, 79 Avenue de la République, Paris, F-75011, France},
	abstract = {A decade ago, we published an article in Business Horizons about the challenges and opportunities of social media with a call to action: “Users of the world, unite!” To celebrate its anniversary, we look at artificial intelligence and the need to create the rules necessary for peaceful coexistence between humanity and AI. Hence, we now are urging: “Rulers of the world, unite!” In this article, we outline six debates surrounding AI in areas like artificial superintelligence, geographical progress, and robotics; in doing so, we shed light on what is fact and what is utopia. Then, using the PESTEL framework, we talk about the six dilemmas of AI and its potential threat and use. Finally, we provide six directions on the future of AI regarding its requirements and expectations, looking at enforcement, employment, ethics, education, entente, and evolution. Understanding AI's potential future will enable governments, corporations, and societies at large (i.e., the rulers of this world) to prepare for its challenges and opportunities. This way, we can avoid a scenario in which we return in 10 years to write the article: “Dreamers of the world, unite!” © 2019 Kelley School of Business, Indiana University},
	author_keywords = {Artificial intelligence; Artificial superintelligence; Human-machine symbiosis; Machine learning; Robotics; Work displacement},
	correspondence_address = {A. Kaplan; ESCP Europe, Berlin, Heubnerweg 8-10, D-14059, Germany; email: kaplan@escpeurope.eu},
	publisher = {Elsevier Ltd},
	issn = {00076813},
	coden = {BHORA},
	language = {English},
	abbrev_source_title = {Bus. Horiz.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 154}
}

@ARTICLE{Lori2020309,
	author = {Lori, Nicolas and Ferreira, Diana and Alves, Victor and Machado, José},
	title = {Bridging the Gap of Neuroscience, Philosophy, and Evolutionary Biology to Propose an Approach to Machine Learning of Human-Like Ethics},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12490 LNCS},
	pages = {309 – 321},
	doi = {10.1007/978-3-030-62365-4_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097195726&doi=10.1007%2f978-3-030-62365-4_30&partnerID=40&md5=453b756311f0c2c8bfb5432cb1eeb4a2},
	affiliations = {Centre Algoritmi, University of Minho, Braga, 4710-057, Portugal},
	abstract = {The growing explosion of ideas such as Artificial Intelligence (AI), smart environments and ubiquitous computing has led to the creation of the Ambient Intelligence (AmI) paradigm. As AmI begins to take place, moving from a futuristic idea to a reality, we are gradually witnessing the creation of an omnipresent, responsive, and intelligent atmosphere in which thousands of tiny sensors and natural user interfaces will be embedded in our natural movements and in our social and physical interactions. Hence, a key challenge in this multi-disciplinary approach is to get machines to act according to ethical priorities that make sense to human beings. In this study, we improve the capacity for machine ethics to approach human ethics by assessing the computation of transaction values and we argue that it is possible to perform such a computation using recent work that describes the effects of human decision-making using an axiomatic framework. This paper clarifies the relationship between the brain’s 3-axes of neuroscience, the 3 Plato’s Transcendentals of philosophy and the biological evolution’s 3-components, as well as the top-down vs. bottom-up approaches to machine ethics. © 2020, Springer Nature Switzerland AG.},
	author_keywords = {Aesthetics evolution; Ambient Intelligence; Artificial Intelligence; Axiomatic systems; Machine ethics; Plato’s Transcendentals; Transaction value},
	keywords = {Biology; Decision making; Machine learning; Neurology; Philosophical aspects; User interfaces; Axiomatic framework; Biological evolution; Bottom up approach; Evolutionary biology; Human decision making; Multi-disciplinary approach; Natural user interfaces; Physical interactions; Ambient intelligence},
	correspondence_address = {N. Lori; Centre Algoritmi, University of Minho, Braga, 4710-057, Portugal; email: nicolas.lori@algoritmi.uminho.pt},
	editor = {Analide C. and Novais P. and Camacho D. and Yin H.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303062364-7},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 21th International Conference on Intelligent Data Engineering and Automated Learning, IDEAL 2020; Conference date: 4 November 2020 through 6 November 2020; Conference code: 251049}
}

@ARTICLE{Green2019,
	author = {Green, Ben and Chen, Yiling},
	title = {The principles and limits of algorithm-in-the-loop decision making},
	year = {2019},
	journal = {Proceedings of the ACM on Human-Computer Interaction},
	volume = {3},
	number = {CSCW},
	doi = {10.1145/3359152},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075059554&doi=10.1145%2f3359152&partnerID=40&md5=4f93a08d7b6e20a6482d2ff6c637549e},
	affiliations = {Harvard University, United States},
	abstract = {The rise of machine learning has fundamentally altered decision making: rather than being made solely by people, many important decisions are now made through an “algorithm-in-the-loop” process where machine learning models inform people. Yet insufficient research has considered how the interactions between people and models actually influence human decisions. Society lacks both clear normative principles regarding how people should collaborate with algorithms as well as robust empirical evidence about how people do collaborate with algorithms. Given research suggesting that people struggle to interpret machine learning models and to incorporate them into their decisions—sometimes leading these models to produce unexpected outcomes—it is essential to consider how different ways of presenting models and structuring human-algorithm interactions affect the quality and type of decisions made. This paper contributes to such research in two ways. First, we posited three principles as essential to ethical and responsible algorithm-in-the-loop decision making. Second, through a controlled experimental study on Amazon Mechanical Turk, we evaluated whether people satisfy these principles when making predictions with the aid of a risk assessment. We studied human predictions in two contexts (pretrial release and financial lending) and under several conditions for risk assessment presentation and structure. Although these conditions did influence participant behaviors and in some cases improved performance, only one desideratum was consistently satisfied. Under all conditions, our study participants 1) were unable to effectively evaluate the accuracy of their own or the risk assessment’s predictions, 2) did not calibrate their reliance on the risk assessment based on the risk assessment’s performance, and 3) exhibited bias in their interactions with the risk assessment. These results highlight the urgent need to expand our analyses of algorithmic decision making aids beyond evaluating the models themselves to investigating the full sociotechnical contexts in which people and algorithms interact. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Behavioral experiment; Ethics; Fairness; Mechanical Turk; Risk assessment},
	keywords = {Behavioral research; Decision making; Forecasting; Learning algorithms; Machine learning; Philosophical aspects; Amazon mechanical turks; Behavioral experiment; Decision-making aids; Ethics; Fairness; Human decisions; Machine learning models; Mechanical turks; Risk assessment},
	publisher = {Association for Computing Machinery},
	issn = {25730142},
	language = {English},
	abbrev_source_title = {Proc. ACM Hum. Comput. Interact.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 111; All Open Access, Bronze Open Access}
}

@ARTICLE{Saltz2019,
	author = {Saltz, Jeffrey and Skirpan, Michael and Fiesler, Casey and Gorelick, Micha and Yeh, Tom and Heckman, Robert and Dewar, Neil and Beard, Nathan},
	title = {Integrating ethics within machine learning courses},
	year = {2019},
	journal = {ACM Transactions on Computing Education},
	volume = {19},
	number = {4},
	doi = {10.1145/3341164},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074423018&doi=10.1145%2f3341164&partnerID=40&md5=2aaa1c9e733911a16fdfbba06a6a0e92},
	affiliations = {Hinds Hall, Syracuse University, Syracuse, 13244, NY, United States; Department of Philosophy, Carnegie Mellon University, Baker Hall 161, 5000 Forbes Avenue, Pittsburgh, 15213, PA, United States; University of Colorado Boulder, UCB 315, Boulder, 80309, CO, United States; Probable Models, 502 Berlin Road, Pittsburgh, 15221, PA, United States},
	abstract = {This article establishes and addresses opportunities for ethics integration into Machine Learning (ML) courses. Following a survey of the history of computing ethics and the current need for ethical consideration within ML, we consider the current state of ML ethics education via an exploratory analysis of course syllabi in computing programs. The results reveal that though ethics is part of the overall educational landscape in these programs, it is not frequently a part of core technical ML courses. To help address this gap, we offer a preliminary framework, developed via a systematic literature review, of relevant ethics questions that should be addressed within an ML project. A pilot study with 85 students confirms that this framework helped them identify and articulate key ethical considerations within their ML projects. Building from this work, we also provide three example ML course modules that bring ethical thinking directly into learning core ML content. Collectively, this research demonstrates: (1) the need for ethics to be taught as integrated within ML coursework, (2) a structured set of questions useful for identifying and addressing potential issues within an ML project, and (3) novel course models that provide examples for how to practically teach ML ethics without sacrificing core course content. An additional by-product of this research is the collection and integration of recent publications in the emerging field of ML ethics education. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Education; Ethics; Machine learning},
	keywords = {Curricula; Education; Education computing; Learning systems; Machine learning; Computing program; Ethical considerations; Ethics; Ethics education; Exploratory analysis; History of computing; Set of questions; Systematic literature review; Philosophical aspects},
	publisher = {Association for Computing Machinery},
	issn = {19466226},
	language = {English},
	abbrev_source_title = {ACM J. Trans. Comput. Educ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 69}
}

@ARTICLE{Beil2019,
	author = {Beil, Michael and Proft, Ingo and van Heerden, Daniel and Sviri, Sigal and van Heerden, Peter Vernon},
	title = {Ethical considerations about artificial intelligence for prognostication in intensive care},
	year = {2019},
	journal = {Intensive Care Medicine Experimental },
	volume = {7},
	number = {1},
	doi = {10.1186/s40635-019-0286-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85085986301&doi=10.1186%2fs40635-019-0286-6&partnerID=40&md5=cd505c2e47b0cfab373a21494ceaba14},
	affiliations = {Institute of Health Sciences at PTHV, Pallottistr. 3, Vallendar, 56179, Germany; Institute of Ethics at PTHV, Pallottistr. 3, Vallendar, 56179, Germany; Melbourne, Australia; Hadassah - Hebrew University Medical Center, POB 12000, Jerusalem, 9112001, Israel},
	abstract = {Background: Prognosticating the course of diseases to inform decision-making is a key component of intensive care medicine. For several applications in medicine, new methods from the field of artificial intelligence (AI) and machine learning have already outperformed conventional prediction models. Due to their technical characteristics, these methods will present new ethical challenges to the intensivist. Results: In addition to the standards of data stewardship in medicine, the selection of datasets and algorithms to create AI prognostication models must involve extensive scrutiny to avoid biases and, consequently, injustice against individuals or groups of patients. Assessment of these models for compliance with the ethical principles of beneficence and non-maleficence should also include quantification of predictive uncertainty. Respect for patients’ autonomy during decision-making requires transparency of the data processing by AI models to explain the predictions derived from these models. Moreover, a system of continuous oversight can help to maintain public trust in this technology. Based on these considerations as well as recent guidelines, we propose a pathway to an ethical implementation of AI-based prognostication. It includes a checklist for new AI models that deals with medical and technical topics as well as patient- and system-centered issues. Conclusion: AI models for prognostication will become valuable tools in intensive care. However, they require technical refinement and a careful implementation according to the standards of medical ethics. © 2019, The Author(s).},
	author_keywords = {Artificial intelligence; Intensive care; Machine learning; Medical ethics; Prognostication},
	keywords = {algorithm; architecture; artificial intelligence; artificial neural network; beneficence; decision making; electronic health record; human; intensive care; justice; machine learning; maleficence; medical ethics; patient autonomy; practice guideline; priority journal; prognostic assessment; quality of life; Review; social aspect},
	correspondence_address = {M. Beil; Institute of Health Sciences at PTHV, Vallendar, Pallottistr. 3, 56179, Germany; email: beil@doctors.org.uk},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {2197425X},
	language = {English},
	abbrev_source_title = {Intensive Care Med. Exp.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 39; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Gerlach2020521,
	author = {Gerlach, Tobias and Danner, Michael and Peng, Le Ping and Kaminickas, Aidas and Fei, Wu and Rätsch, Matthias},
	title = {Who loves virtue as much as he loves beauty?: Deep learning based estimator for aesthetics of portraits},
	year = {2020},
	journal = {VISIGRAPP 2020 - Proceedings of the 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications},
	volume = {5},
	pages = {521 – 528},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083493457&partnerID=40&md5=f6e44565ab7f1f653e7a93b30c31d8e9},
	affiliations = {ViSiR, Reutlingen University, Reutlingen, Germany; Centre for Vision, Speech and Signal Processing, University of Surrey, Guildford, United Kingdom; School of Computer Science, Xi’an Polytechnic University, Xi’an, 710048, China; Philosophy, Hunan University of Science and Technology, Xiangtan, China},
	abstract = {”I have never seen one who loves virtue as much as he loves beauty,” Confucius once said. If beauty is more important as goodness, it becomes clear why people invest so much effort in their first impression. The aesthetic of faces has many aspects and there is a strong correlation to all characteristics of humans, like age and gender. Often, research on aesthetics by social and ethic scientists lacks sufficient labelled data and the support of machine vision tools. In this position paper we propose the Aesthetic-Faces dataset, containing training data which is labelled by Chinese and German annotators. As a combination of three image subsets, the AF-dataset consists of European, Asian and African people. The research communities in machine learning, aesthetics and social ethics can benefit from our dataset and our toolbox. The toolbox provides many functions for machine learning with state-of-the-art CNNs and an Extreme-Gradient-Boosting regressor, but also 3D Morphable Model technologies for face shape evaluation and we discuss how to train an aesthetic estimator considering culture and ethics. Copyright © 2020 by SCITEPRESS – Science and Technology Publications, Lda. All rights reserved},
	author_keywords = {3D Morphable Model; Attractiveness of Faces; Benchmark Testing; Deep Learning; ELO Rating; Extreme-Gradient-Boosting Regressor; Facial Databases; Predictive Models; Social Ethics},
	keywords = {3D modeling; Adaptive boosting; Computer graphics; Computer vision; Ethical aspects; Learning systems; 3D Morphable model; First impressions; Gradient boosting; Position papers; Research communities; State of the art; Strong correlation; Training data; Deep learning},
	editor = {Farinella G.M. and Radeva P. and Braz J.},
	publisher = {SciTePress},
	isbn = {978-989758402-2},
	language = {English},
	abbrev_source_title = {VISIGRAPP - Proc. Int. Jt. Conf. Comput. Vis., Imaging Comput. Graph. Theory Appl.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Joint Conference on Computer Vision, Imaging and Computer Graphics Theory and Applications, VISIGRAPP 2020; Conference date: 27 February 2020 through 29 February 2020; Conference code: 158743}
}

@ARTICLE{Parmentier201953,
	author = {Parmentier, Florent},
	title = {Healthcare data and artificial intelligence: a geostrategic vision; [Données de santé et intelligence artificielle: une vision géostratégique]},
	year = {2019},
	journal = {Soins},
	volume = {64},
	number = {838},
	pages = {53 – 55},
	doi = {10.1016/j.soin.2019.06.013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072301855&doi=10.1016%2fj.soin.2019.06.013&partnerID=40&md5=590efcdacd784288a3e867150b6c4f74},
	affiliations = {Sciences Po, 27, rue Saint-Guillaume, Paris Cedex 07, 75337, France},
	abstract = {The rapid deployment of artificial intelligence (AI) and automation in healthcare is highlighting the importance of health data-driven management as a geostrategic lever. From this point of view, the progress made by the United States and China requires a strong European response to develop a responsible vision which adopts an approach aiming at the positive regulation of AI in healthcare. © 2019 Elsevier Masson SAS},
	author_keywords = {artificial intelligence; ethics; geopolitics; health data; IoT; sovereignty},
	keywords = {Artificial Intelligence; China; Europe; Government Regulation; Humans; Medical Records; United States; Article; artificial intelligence; automation; information processing; machine learning; medical record; robotics; artificial intelligence; China; Europe; government regulation; human; legislation and jurisprudence; United States},
	publisher = {Elsevier Masson SAS},
	issn = {00380814},
	pmid = {31542124},
	language = {English},
	abbrev_source_title = {Soins},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@ARTICLE{Tuncer202084532,
	author = {Tuncer, Turker and Dogan, Sengul and Ozyurt, Fatih and Belhaouari, Samir Brahim and Bensmail, Halima},
	title = {Novel multi center and threshold ternary pattern based method for disease detection method using voice},
	year = {2020},
	journal = {IEEE Access},
	volume = {8},
	pages = {84532 – 84540},
	doi = {10.1109/ACCESS.2020.2992641},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084959476&doi=10.1109%2fACCESS.2020.2992641&partnerID=40&md5=a31a2445e02d3996f435e8ad1b790dc3},
	affiliations = {Department of Digital Forensics Engineering, Technology Faculty, Firat University, Elaziǧ, 23119, Turkey; Department of Software Engineering, Engineering Faculty, Firat University, Elaziǧ, 23119, Turkey; College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; Qatar Computing Research Institute, Hamad Bin Khalifa University, Doha, Qatar},
	abstract = {Smart health is one of the most popular and important components of smart cities. It is a relatively new context-aware healthcare paradigm influenced by several fields of expertise, such as medical informatics, communications and electronics, bioengineering, ethics, to name a few. Smart health is used to improve healthcare by providing many services such as patient monitoring, early diagnosis of disease and so on. The artificial neural network (ANN), support vector machine (SVM) and deep learning models, especially the convolutional neural network (CNN), are the most commonly used machine learning approaches where they proved to be performance in most cases. Voice disorders are rapidly spreading especially with the development of medical diagnostic systems, although they are often underestimated. Smart health systems can be an easy and fast support to voice pathology detection. The identification of an algorithm that discriminates between pathological and healthy voices with more accuracy is needed to obtain a smart and precise mobile health system. The main contribution of this paper consists of proposing a multiclass-pathologic voice classification using a novel multileveled textural feature extraction with iterative feature selector. Our approach is a simple and efficient voice-based algorithm in which a multi-center and multi threshold based ternary pattern is used (MCMTTP). A more compact multileveled features are then obtained by sample-based discretization techniques and Neighborhood Component Analysis (NCA) is applied to select features iteratively. These features are finally integrated with MCMTTP to achieve an accurate voice-based features detection. Experimental results of six classifiers with three diagnostic diseases (frontal resection, cordectomy and spastic dysphonia) show that the fused features are more suitable for describing voice-based disease detection. © 2013 IEEE.},
	author_keywords = {discrete wavelet transform; machine learning; MCMTTP; smart health; voice disease detection},
	keywords = {Classification (of information); Convolutional neural networks; Deep learning; Diagnosis; Feature extraction; Health care; Iterative methods; Medical informatics; Pathology; Patient monitoring; Support vector machines; Context-aware healthcare; Features detections; Machine learning approaches; Medical diagnostics; Mobile health systems; Neighborhood component analysis; Pattern based method; Voice pathology detection; Speech recognition},
	correspondence_address = {S.B. Belhaouari; College of Science and Engineering, Hamad Bin Khalifa University, Doha, Qatar; email: sbelhaouari@hbku.edu.qa},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21693536},
	language = {English},
	abbrev_source_title = {IEEE Access},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 64; All Open Access, Gold Open Access}
}

@ARTICLE{Abels2019286,
	author = {Abels, Esther and Pantanowitz, Liron and Aeffner, Famke and Zarella, Mark D and van der Laak, Jeroen and Bui, Marilyn M and Vemuri, Venkata NP and Parwani, Anil V and Gibbs, Jeff and Agosto-Arroyo, Emmanuel and Beck, Andrew H and Kozlowski, Cleopatra},
	title = {Computational pathology definitions, best practices, and recommendations for regulatory guidance: a white paper from the Digital Pathology Association},
	year = {2019},
	journal = {Journal of Pathology},
	volume = {249},
	number = {3},
	pages = {286 – 294},
	doi = {10.1002/path.5331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070884507&doi=10.1002%2fpath.5331&partnerID=40&md5=77d57ee7002193fa37af82b216127942},
	affiliations = {Regulatory and Clinical Affairs, PathAI, Boston, MA, United States; Department of Pathology, University of Pittsburgh Medical Center, Pittsburgh, PA, United States; Amgen Research, Comparative Biology and Safety Sciences, Amgen Inc., South San Francisco, CA, United States; Department of Pathology and Laboratory Medicine, Drexel University College of Medicine, Philadelphia, PA, United States; Department of Pathology, Radboud University Medical Center, Nijmegen, Netherlands; Center for Medical Image Science and Visualization, Linköping University, Linköping, Sweden; Department of Pathology, Moffitt Cancer Center, Tampa, FL, United States; Data Science Department, Chan Zuckerberg Biohub, San Francisco, CA, United States; Department of Pathology, The Ohio State University, Columbus, OH, United States; Hyman, Phelps & McNamara, P.C, Washington, DC, United States; PathAI, Boston, MA, United States; Department of Development Sciences, Genentech Inc., South San Francisco, CA, United States},
	abstract = {In this white paper, experts from the Digital Pathology Association (DPA) define terminology and concepts in the emerging field of computational pathology, with a focus on its application to histology images analyzed together with their associated patient data to extract information. This review offers a historical perspective and describes the potential clinical benefits from research and applications in this field, as well as significant obstacles to adoption. Best practices for implementing computational pathology workflows are presented. These include infrastructure considerations, acquisition of training data, quality assessments, as well as regulatory, ethical, and cyber-security concerns. Recommendations are provided for regulators, vendors, and computational pathology practitioners in order to facilitate progress in the field. © 2019 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of Pathological Society of Great Britain and Ireland. © 2019 The Authors. The Journal of Pathology published by John Wiley & Sons Ltd on behalf of Pathological Society of Great Britain and Ireland.},
	author_keywords = {artificial intelligence; computational pathology; convolutional neural networks; deep learning; digital pathology; image analysis; machine learning},
	keywords = {Artificial Intelligence; Benchmarking; Computer Security; Diagnosis, Computer-Assisted; Humans; Image Interpretation, Computer-Assisted; Pathology; Policy Making; Predictive Value of Tests; Terminology as Topic; Workflow; adoption; adult; artificial intelligence; computer security; convolutional neural network; data quality assessment; deep learning; histology; histopathology; human; human tissue; image analysis; nomenclature; patient coding; physician; review; workflow; artificial intelligence; benchmarking; classification; computer assisted diagnosis; ethics; management; nomenclature; pathology; practice guideline; predictive value},
	correspondence_address = {C. Kozlowski; Department of Development Sciences, Genentech Inc., South San Francisco, United States; email: cleopatk@gene.com},
	publisher = {John Wiley and Sons Ltd},
	issn = {00223417},
	coden = {JPTLA},
	pmid = {31355445},
	language = {English},
	abbrev_source_title = {J. Pathol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 169; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Altavilla2020187,
	author = {Altavilla, Annagrazia},
	title = {Introduction: Special Issue on Innovative Medicine and Research: Ethical, Legal and Regulatory Issues},
	year = {2020},
	journal = {European Journal of Health Law},
	volume = {27},
	number = {3},
	pages = {187 – 193},
	doi = {10.1163/15718093-BJA10019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088466600&doi=10.1163%2f15718093-BJA10019&partnerID=40&md5=6b55295eaf65f707d950c5e014b83396},
	affiliations = {Fondazione per la Ricerca Farmacologica Gianni Benzi Onlus, Italy; Espace Ãthique Maditerranaen/PACA-Corse, AP-HM, France; Teddy European Network for Paediatric Research},
	keywords = {Biomedical Research; Biomedical Technology; Congresses as Topic; Diffusion of Innovation; Europe; European Union; Female; Health Services Accessibility; Human Rights; Humans; Information Dissemination; Machine Learning; Male; Patient Rights; ethics; Europe; European Union; female; health care delivery; human; human rights; information dissemination; legislation and jurisprudence; machine learning; male; mass communication; medical research; medical technology; organization; patient right},
	publisher = {Brill Nijhoff},
	issn = {09290273},
	coden = {EJHLE},
	pmid = {32697739},
	language = {English},
	abbrev_source_title = {Eur. J. Health Law},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Tom20201,
	author = {Tom, Elysse and Keane, Pearse A. and Blazes, Marian and Pasquale, Louis R. and Chiang, Michael F. and Lee, Aaron Y. and Lee, Cecilia S.},
	title = {Protecting data privacy in the age of ai-enabled ophthalmology},
	year = {2020},
	journal = {Translational Vision Science and Technology},
	volume = {9},
	number = {2},
	pages = {1 – 7},
	doi = {10.1167/tvst.9.2.36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089115566&doi=10.1167%2ftvst.9.2.36&partnerID=40&md5=a082a9d4eb0aead6cda7cdd048e7226a},
	affiliations = {Department of Ophthalmology, University of Washington, Seattle, WA, United States; Medical Retina Service, Moorfields Eye Hospital NHS Foundation Trust, London, United Kingdom; Institute of Ophthalmology, University College London, London, United Kingdom; Eye and Vision Research Institute, Icahn School of Medicine at Mount Sinai, New York, NY, United States; Departments of Ophthalmology and Medical Informatics & Clinical Epidemiology, Casey Eye Institute, Oregon Health & Science University, Portland, OR, United States},
	author_keywords = {Artificial Intelligence; Biomedical Ethics; Machine Learning; Privacy},
	keywords = {Article; artificial intelligence; beneficence; big data; computer assisted tomography; computer heuristics; facial recognition; financial information system; health care personnel; health care quality; health insurance; learning algorithm; legal database; medical information; national health service; ophthalmology; optical coherence tomography; privacy; professional secrecy; research ethics; risk factor; social security},
	correspondence_address = {A.Y. Lee; Department of Ophthalmology, University of Washington, Seattle, United States; email: leeay@uw.edu},
	publisher = {Association for Research in Vision and Ophthalmology Inc.},
	issn = {21642591},
	language = {English},
	abbrev_source_title = {Translational Vis. Sci. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ferreri2019,
	author = {Ferreri, Florian and Bourla, Alexis and Peretti, Charles-Siegfried and Segawa, Tomoyuki and Jaafari, Nemat and Mouchabac, Stéphane},
	title = {How new technologies can improve prediction, assessment, and intervention in obsessive-compulsive disorder (e-ocd): Review},
	year = {2019},
	journal = {JMIR Mental Health},
	volume = {6},
	number = {12},
	doi = {10.2196/11643},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072087482&doi=10.2196%2f11643&partnerID=40&md5=d8f477a3b57f9f0513d7fd17a3b05b67},
	affiliations = {Sorbonne Université, Department of Adult Psychiatry and Medical Psychology, APHP, Saint-Antoine Hospital, Paris, France; Jeanne d'Arc Hospital, INICEA Group, Saint Mandé, France; INSERM, Pierre Deniker Clinical Research Unit, Henri Laborit Hospital, Experimental and Clinical Neuroscience Laboratory, Poitiers University Hospital, Poitier, France},
	abstract = {Background: New technologies are set to profoundly change the way we understand and manage psychiatric disorders, including obsessive-compulsive disorder (OCD). Developments in imaging and biomarkers, along with medical informatics, may well allow for better assessments and interventions in the future. Recent advances in the concept of digital phenotype, which involves using computerized measurement tools to capture the characteristics of a given psychiatric disorder, is one paradigmatic example. Objective: The impact of new technologies on health professionals' practice in OCD care remains to be determined. Recent developments could disrupt not just their clinical practices, but also their beliefs, ethics, and representations, even going so far as to question their professional culture. This study aimed to conduct an extensive review of new technologies in OCD. Methods: We conducted the review by looking for titles in the PubMed database up to December 2017 that contained the following terms: [Obsessive] AND [Smartphone] OR [phone] OR [Internet] OR [Device] OR [Wearable] OR [Mobile] OR [Machine learning] OR [Artificial] OR [Biofeedback] OR [Neurofeedback] OR [Momentary] OR [Computerized] OR [Heart rate variability] OR [actigraphy] OR [actimetry] OR [digital] OR [virtual reality] OR [Tele] OR [video]. Results: We analyzed 364 articles, of which 62 were included. Our review was divided into 3 parts: Prediction, assessment (including diagnosis, screening, and monitoring), and intervention. Conclusions: The review showed that the place of connected objects, machine learning, and remote monitoring has yet to be defined in OCD. Smartphone assessment apps and the Web Screening Questionnaire demonstrated good sensitivity and adequate specificity for detecting OCD symptoms when compared with a full-length structured clinical interview. The ecological momentary assessment procedure may also represent a worthy addition to the current suite of assessment tools. In the field of intervention, CBT supported by smartphone, internet, or computer may not be more effective than that delivered by a qualified practitioner, but it is easy to use, well accepted by patients, reproducible, and cost-effective. Finally, new technologies are enabling the development of new therapies, including biofeedback and virtual reality, which focus on the learning of coping skills. For them to be used, these tools must be properly explained and tailored to individual physician and patient profiles. © 2020 Universitetet i Oslo. All rights reserved.},
	author_keywords = {Biofeedback; Digital biomarkers; Digital phenotyping; Ecological momentary assessment; Machine learning; Mobile health; Obsessive-compulsive disorder; Virtual reality},
	correspondence_address = {A. Bourla; Sorbonne Université, Department of Adult Psychiatry and Medical Psychology, APHP, Saint-Antoine Hospital, Paris, 184 rue du Faubourg Saint-Antoine, 75012, France; email: alexis.bourla@aphp.fr},
	publisher = {JMIR Publications Inc.},
	issn = {23687959},
	language = {English},
	abbrev_source_title = {JMIR Ment. Heal.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Amoore2019147,
	author = {Amoore, Louise},
	title = {Doubt and the Algorithm: On the Partial Accounts of Machine Learning},
	year = {2019},
	journal = {Theory, Culture and Society},
	volume = {36},
	number = {6},
	pages = {147 – 169},
	doi = {10.1177/0263276419851846},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068356996&doi=10.1177%2f0263276419851846&partnerID=40&md5=30be8de86e1d3674b746af57f950ba6d},
	affiliations = {University of Durham, United Kingdom},
	abstract = {In a 1955 lecture the physicist Richard Feynman reflected on the place of doubt within scientific practice. ‘Permit us to question, to doubt, to not be sure’, proposed Feynman, ‘it is possible to live and not to know’. In our contemporary world, the science of machine learning algorithms appears to transform the relations between science, knowledge and doubt, to make even the most doubtful event amenable to action. What might it mean to ‘leave room for doubt’ or ‘to live and not to know’ in our contemporary culture, where the algorithm plays a major role in the calculability of doubts? I propose a posthuman mode of doubt that decentres the liberal humanist subject. In the science of machine learning algorithms the doubts of human and technological beings nonetheless dwell together, opening onto a future that is never fully reduced to the single output signal, to the optimised target. © The Author(s) 2019.},
	author_keywords = {algorithm; ethics; Feynman; machine learning; politics; posthuman; technology},
	correspondence_address = {L. Amoore; University of Durham, United Kingdom; email: louise.amoore@durham.ac.uk},
	publisher = {SAGE Publications Ltd},
	issn = {02632764},
	language = {English},
	abbrev_source_title = {Theory Cult. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 45; All Open Access, Green Open Access}
}

@CONFERENCE{Schelter2020395,
	author = {Schelter, Sebastian and He, Yuxuan and Khilnani, Jatin and Stoyanovich, Julia},
	title = {FairPrep: Promoting data to a first-class citizen in studies on fairness-enhancing interventions},
	year = {2020},
	journal = {Advances in Database Technology - EDBT},
	volume = {2020-March},
	pages = {395 – 398},
	doi = {10.5441/002/edbt.2020.41},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084183336&doi=10.5441%2f002%2fedbt.2020.41&partnerID=40&md5=e95ea61aedd3c9418659f8607d90d7a9},
	affiliations = {New York University, United States},
	abstract = {The importance of incorporating ethics and legal compliance into machine-assisted decision-making is broadly recognized. Further, several lines of recent work have argued that critical opportunities for improving data quality and representativeness, controlling for bias, and allowing humans to oversee and impact computational processes are missed if we do not consider the lifecycle stages upstream from model training and deployment. Yet, very little has been done to date to provide system-level support to data scientists who wish to develop responsible machine learning methods. We aim to fill this gap and present FairPrep, a design and evaluation framework for fairness-enhancing interventions, which helps data scientists follow best practices in ML experimentation. We identify shortcomings in existing empirical studies for analyzing fairness-enhancing interventions and show how FairPrep can be used to measure their impact. Our results suggest that the high variability of the outcomes of fairness-enhancing interventions observed in previous studies is often an artifact of a lack of hyperparameter tuning, and that the choice of a data cleaning method can impact the effectiveness of fairness-enhancing interventions. © 2020 Copyright held by the owner/author(s). Published in Proceedings of the 23rd International Conference on Extending Database Technology (EDBT), March 30-April 2, 2020, ISBN 978-3-89318-083-7 on OpenProceedings.org. Distribution of this paper is permitted under the terms of the Creative Commons license CC-by-nc-nd 4.0.},
	keywords = {Database systems; Decision making; Life cycle; Quality control; Computational process; Design and evaluations; Empirical studies; Hyper-parameter; Legal compliance; Life cycle stages; Machine learning methods; System-level support; Learning systems},
	editor = {Bonifati A. and Zhou Y. and Vaz Salles M.A. and Bohm A. and Olteanu D. and Fletcher G. and Khan A. and Yang B.},
	publisher = {OpenProceedings.org},
	issn = {23672005},
	isbn = {978-389318083-7},
	language = {English},
	abbrev_source_title = {Adv.  Database Technol. - EDBT},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 20; Conference name: 23rd International Conference on Extending Database Technology, EDBT 2020; Conference date: 30 March 2020 through 2 April 2020; Conference code: 159421}
}

@ARTICLE{Mazurowski2020127,
	author = {Mazurowski, Maciej A.},
	title = {Artificial Intelligence in Radiology: Some Ethical Considerations for Radiologists and Algorithm Developers},
	year = {2020},
	journal = {Academic Radiology},
	volume = {27},
	number = {1},
	pages = {127 – 129},
	doi = {10.1016/j.acra.2019.04.024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075369891&doi=10.1016%2fj.acra.2019.04.024&partnerID=40&md5=00a21e558d8de8933d8b3c0462e0cd57},
	affiliations = {Departments of Radiology, Electrical and Computer Engineering, and Biostatistics and Bioinformatics, Duke University, 2424 Erwin Rd, Durham, 27707, NC, United States},
	abstract = {As artificial intelligence (AI) is finding its place in radiology, it is important to consider how to guide the research and clinical implementation in a way that will be most beneficial to patients. Although there are multiple aspects of this issue, I consider a specific one: a potential misalignment of the self-interests of radiologists and AI developers with the best interests of the patients. Radiologists know that supporting research into AI and advocating for its adoption in clinical settings could diminish their employment opportunities and reduce respect for their profession. This provides an incentive to oppose AI in various ways. AI developers have an incentive to hype their discoveries to gain attention. This could provide short-term personal gains, however, it could also create a distrust toward the field if it became apparent that the state of the art was far from where it was promised to be. The future research and clinical implementation of AI in radiology will be partially determined by radiologist and AI researchers. Therefore, it is very important that we recognize our own personal motivations and biases and act responsibly to ensure the highest benefit of the AI transformation to the patients. © 2019},
	author_keywords = {Algorithm development; Artificial intelligence; Ethics; Machine learning},
	keywords = {Algorithms; Artificial Intelligence; Forecasting; Humans; Radiologists; Radiology; adoption; adult; artificial intelligence; attention; employment; ethics; human; machine learning; motivation; note; radiologist; radiology; algorithm; forecasting; radiologist},
	correspondence_address = {M.A. Mazurowski; Departments of Radiology, Electrical and Computer Engineering, and Biostatistics and Bioinformatics, Duke University, Durham, 2424 Erwin Rd, 27707, United States; email: maciej.mazurowski@duke.edu},
	publisher = {Elsevier USA},
	issn = {10766332},
	coden = {ARADF},
	pmid = {31818378},
	language = {English},
	abbrev_source_title = {Acad. Radiol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Chomanski20191389,
	author = {Chomanski, Bartek},
	title = {Massive Technological Unemployment Without Redistribution: A Case for Cautious Optimism},
	year = {2019},
	journal = {Science and Engineering Ethics},
	volume = {25},
	number = {5},
	pages = {1389 – 1407},
	doi = {10.1007/s11948-018-0070-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055931917&doi=10.1007%2fs11948-018-0070-0&partnerID=40&md5=59fe1eeb27e4178a2a82810eb8d020b3},
	affiliations = {Department of Philosophy and Religion, Northeastern University, 360 Huntington Avenue, Boston, 02115, MA, United States},
	abstract = {This paper argues that even though massive technological unemployment will likely be one of the results of automation, we will not need to institute mass-scale redistribution of wealth (such as would be involved in, e.g., instituting universal basic income) to deal with its consequences. Instead, reasons are given for cautious optimism about the standards of living the newly unemployed workers may expect in the (almost) fully-automated future. It is not claimed that these predictions will certainly bear out. Rather, they are no less likely to come to fruition than the predictions of those authors who predict that massive technological unemployment will lead to the suffering of the masses on such a scale that significant redistributive policies will have to be instituted to alleviate it. Additionally, the paper challenges the idea that the existence of a moral obligation to help the victims of massive unemployment justifies the coercive taking of anyone else’s property. © 2018, Springer Nature B.V.},
	author_keywords = {Artificial intelligence; Automation; Basic income; Technological unemployment},
	keywords = {Ethical Analysis; Forecasting; Humans; Income; Machine Learning; Moral Obligations; Social Change; Social Conditions; Technology; Unemployment; economics; ethics; forecasting; human; income; machine learning; morality; social change; social status; technology; unemployment},
	correspondence_address = {B. Chomanski; Department of Philosophy and Religion, Northeastern University, Boston, 360 Huntington Avenue, 02115, United States; email: b.chomanski@gmail.com},
	publisher = {Springer Netherlands},
	issn = {13533452},
	pmid = {30357558},
	language = {English},
	abbrev_source_title = {Sci. Eng. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{2020,
	title = {33rd Australasian Joint Conference on Artificial Intelligence, AI 2020},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12576 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097680128&partnerID=40&md5=86709068e646105a177770e9fb3bcf84},
	abstract = {The proceedings contain 36 papers. The special focus in this conference is on Artificial Intelligence. The topics include: A Tri-level Programming Framework for Modelling Attacks and Defences in Cyber-Physical Systems; a Mixed-Integer Programming Approach for Scheduling Roadworks in Urban Regions; reducing Traffic Congestion in Urban Areas via Real-Time Re-Routing: A Simulation Study; Analysis and Prediction of Player Population Changes in Digital Games During the COVID-19 Pandemic; a Comparison of Machine Learning Methods for Cross-Domain Few-Shot Learning; an Elastic Gradient Boosting Decision Tree for Concept Drift Learning; online Semi-supervised Learning in Contextual Bandits with Episodic Reward; activity-Independent Person Identification Based on Daily Activities Using Wearable Sensors; real-Time Decision Making for Train Carriage Load Prediction via Multi-stream Learning; how to Encode Dynamic Gaussian Bayesian Networks as Gaussian Processes?; an Information-Theoretic Perspective on Overfitting and Underfitting; exploring a Learning Architecture for General Game Playing; autonomous Recognition of Collective Behaviour in Robot Swarms; train Small, Deploy Big: Do Relative World Views Permit Swarm-Safety During Policy Transplantation for Multi-Agent Reinforcement Learning Problems?; Improving StarCraft II Player League Prediction with Macro-Level Features; comparing Three Data Representations for Music with a Sequence-to-Sequence Model; Designing Curriculum for Deep Reinforcement Learning in StarCraft II; can Lethal Autonomous Robots Learn Ethics?; building Fair Predictive Models; non-monotonic Reasoning for Machine Ethics with Situation Calculus; improving Distribution-Based Discrete Particle Swarm Optimization Using Lévy Flight; a Novel Mutation Operator for Variable Length Algorithms; genetic Programming-Based Selection of Imputation Methods in Symbolic Regression with Missing Values; multi-diseases Classification from Chest-X-ray: A Federated Deep Learning Approach.},
	editor = {Gallagher M. and Moustafa N. and Lakshika E.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {03029743},
	isbn = {978-303064983-8},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 33rd Australasian Joint Conference on Artificial Intelligence, AI 2020; Conference date: 29 November 2020 through 30 November 2020; Conference code: 252419}
}

@CONFERENCE{Ilhami Arsyah2019,
	author = {Ilhami Arsyah, Ulya and Husna Arsyah, Rahmatul and Pratiwi, Mutiana and Lestari, Novia},
	title = {Strengthening character education with the implementation of machine learning in the millennial era industrial revolution 4.0},
	year = {2019},
	journal = {Journal of Physics: Conference Series},
	volume = {1339},
	number = {1},
	doi = {10.1088/1742-6596/1339/1/012036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077814360&doi=10.1088%2f1742-6596%2f1339%2f1%2f012036&partnerID=40&md5=f936fb724b904efdb9a80ccdef3b11e8},
	affiliations = {Universitas Negeri Padang1, Indonesia; Universitas Putra Indonesia YPTK Padang, Indonesia; UMMY Solok, Indonesia},
	abstract = {Education is a part that cannot be separated from human life. There is a relationship between education and prosperity and patterns of human life. In the context of human life, education has a significant role in aspects of social, economic, environmental, political and security safeguards. In terms of welfare, education has a large influence. One education actor who plays a very important role is the teacher, who will teach and become an example for his students. And things that should not be eroded by the development of the age are the cultivation of good character in educating students, including those that must be prevented are acts of violence against students maybe it can happen in the world of education, either by the teacher or fellow students. In this study a web-based Expert System will be designed using the Forward Chaining method. Forward Chaining is a search method or a forward tracking technique with information and merging rules to produce conclusions. With this system the teachers can conduct online consultations that will be applied in machine learning in the learning process, so that the teachers can find out whether their actions in the teaching and learning process are in accordance with the ethics of an educator. © Published under licence by IOP Publishing Ltd.},
	keywords = {Expert systems; Machine learning; Human lives; Industrial revolutions; Learning process; Search method; Teaching and learning; Tracking techniques; Web based expert system; Students},
	editor = {Rahim R. and Dharma R. and Hendrik B. and Muhammad A.},
	publisher = {Institute of Physics Publishing},
	issn = {17426588},
	language = {English},
	abbrev_source_title = {J. Phys. Conf. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 1st International Conference Computer Science and Engineering, IC2SE 2019; Conference date: 26 April 2019 through 27 April 2019; Conference code: 156297; All Open Access, Gold Open Access}
}

@CONFERENCE{Sahlgren202038,
	author = {Sahlgren, Otto and Laitinen, Arto},
	title = {Algorithmic fairness and its limits in group-formation},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2737},
	pages = {38 – 54},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099028721&partnerID=40&md5=5d99e6008bc5ddc3bacb23acd3d464d4},
	affiliations = {Department of Philosophy, Tampere University, Tampere, Finland},
	abstract = {Algorithmic group formation has become a flourishing research area in the computer sciences, and more recently in the field of data mining and fair machine learning. Application domains for algorithmic solutions to grouping span wide, from team-recommendation and formation in work settings to abilitygrouping in education. Recent work has also focused on fairness in groupformation. We briefly review literature on algorithmic team-formation and consider fairness in different group-formation contexts. We articulate different dimensions and constraints that are relevant for fair group-formation and discuss the tension between utility and fairness. Many problems and limitations regarding formal definitions of fairness explicated in the fair machine learning literature apply also in the context of group-formation. We suggest some limits to the relevance of fairness in general and algorithmic fairness, in particular. We argue that algorithmic fairness is less relevant to some groups because of the way they come to existence or because fairness is not a central value for them. Other central values are subjective rights; autonomy or liberty; legitimacy and authority; solidarity; and diversity, each of which can be in tension with optimal fairnessand- utility. But within acceptable limits, we argue that fairness is indeed a valuable goal that may be in tension with maximization of the relevant types of utility. Copyright © 2020 for this paper by its authors.},
	author_keywords = {Algorithmic group-formation; Ethics; Fairness; Machine learning; Political philosophy; Team-recommendation},
	keywords = {Data mining; Philosophical aspects; Acceptable limit; Algorithmic solutions; Formal definition; Group formations; Machine learning literature; Team formation; Machine learning},
	correspondence_address = {O. Sahlgren; Department of Philosophy, Tampere University, Tampere, Finland; email: otto.sahlgren@tuni.fi},
	editor = {Koskinen J. and Rantanen M.M. and Tuikka A.-M. and Knaapi-Junnila S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2020 Conference on Technology Ethics, Tethics 2020; Conference date: 21 October 2020; Conference code: 164803}
}

@ARTICLE{Gibney2020609,
	author = {Gibney, Elizabeth},
	title = {The battle for ethical AI at the world's biggest machine-learning conference},
	year = {2020},
	journal = {Nature},
	volume = {577},
	number = {7792},
	pages = {609},
	doi = {10.1038/d41586-020-00160-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078688078&doi=10.1038%2fd41586-020-00160-y&partnerID=40&md5=50c961a082c52cd6322dcfeab580c25b},
	author_keywords = {Ethics; Mathematics and computing},
	keywords = {Bias; Biometric Identification; Congresses as Topic; Humans; Machine Learning; Prejudice; Social Change; biometry; ethics; human; machine learning; organization; prejudice; prevention and control; social change; statistical bias},
	publisher = {NLM (Medline)},
	issn = {14764687},
	pmid = {31992885},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Bronze Open Access}
}

@ARTICLE{Etienne20201,
	author = {Etienne, Harry and Hamdi, Sarah and Le Roux, Marielle and Camuset, Juliette and Khalife-Hocquemiller, Theresa and Giol, Mihaela and Debrosse, Denis and Assouad, Jalal},
	title = {Artificial intelligence in thoracic surgery: Past, present, perspective and limits},
	year = {2020},
	journal = {European Respiratory Review},
	volume = {29},
	number = {157},
	pages = {1 – 11},
	doi = {10.1183/16000617.0010-2020},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089769017&doi=10.1183%2f16000617.0010-2020&partnerID=40&md5=d7ab6444eae4586722b079cbf50d1524},
	affiliations = {AP-HP, Dept of Thoracic and Vascular Surgery, Tenon University Hospital, Paris, France; Sorbonne Université, INSERM, UMRS1158 Neurophysiologie Respiratoire Expérimentale et Clinique, Paris, France; Dept of Thoracic and Vascular Surgery, Le Raincy-Montfermeil Hospital, Montfermeil, France},
	abstract = {Artificial intelligence (AI) technology is becoming prevalent in many areas of everyday life. The healthcare industry is concerned by it even though its widespread use is still limited. Thoracic surgeons should be aware of the new opportunities that could affect their daily practice, by direct use of AI technology or indirect use via related medical fields (radiology, pathology and respiratory medicine). The objective of this article is to review applications of AI related to thoracic surgery and discuss the limits of its application in the European Union. Key aspects of AI will be developed through clinical pathways, beginning with diagnostics for lung cancer, a prognostic-aided programme for decision making, then robotic surgery, and finishing with the limitations of AI, the legal and ethical issues relevant to medicine. It is important for physicians and surgeons to have a basic knowledge of AI to understand how it impacts healthcare, and to consider ways in which they may interact with this technology. Indeed, synergy across related medical specialties and synergistic relationships between machines and surgeons will likely accelerate the capabilities of AI in augmenting surgical care. © ERS 2020.},
	keywords = {Artificial Intelligence; Humans; Thoracic Surgery; algorithm; artificial intelligence; artificial neural network; big data; cancer prognosis; cancer surgery; classifier; computer assisted radiography; decision making; deep learning; ethics; European Union; human; law; lung cancer; machine; machine learning; natural language processing; prognostic aided program; Review; robot assisted surgery; surgeon; surgical technique; thorax surgery},
	correspondence_address = {H. Etienne; AP-HP, Dept of Thoracic and Vascular Surgery, Tenon University Hospital, Paris, France; email: h.etienne@hotmail.fr; H. Etienne; Sorbonne Université, INSERM, UMRS1158 Neurophysiologie Respiratoire Expérimentale et Clinique, Paris, France; email: h.etienne@hotmail.fr},
	publisher = {European Respiratory Society},
	issn = {09059180},
	coden = {EREWE},
	pmid = {32817112},
	language = {English},
	abbrev_source_title = {Eur. Respir. Rev.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Nordling2019S103,
	author = {Nordling, Linda},
	title = {A fairer way forward for AI in health care},
	year = {2019},
	journal = {Nature},
	volume = {573},
	number = {7775},
	pages = {S103 – S105},
	doi = {10.1038/d41586-019-02872-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072661304&doi=10.1038%2fd41586-019-02872-2&partnerID=40&md5=e876a96b49af79d6a75c0616f92d1ffa},
	abstract = {Without careful implementation, artificial intelligence could widen health-care inequality. [Figure not available: see fulltext.]. © 2019, Nature.},
	author_keywords = {Computer science; Ethics; Health care; Technology},
	keywords = {Algorithms; Artificial Intelligence; Chicago; Delivery of Health Care; Healthcare Disparities; Hospitals; Humans; artificial intelligence; health care; health care planning; health care quality; health equity; hospital discharge; human; learning algorithm; length of stay; machine learning; Note; patient information; priority journal; algorithm; artificial intelligence; ethics; health care delivery; health care disparity; hospital; Illinois},
	publisher = {Nature Publishing Group},
	issn = {00280836},
	coden = {NATUA},
	pmid = {31554993},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32; All Open Access, Bronze Open Access}
}

@ARTICLE{Khisamova20195159,
	author = {Khisamova, Zarina I. and Begishev, Ildar R. and Gaifutdinov, Ramil R.},
	title = {On methods to legal regulation of artificial intelligence in the world},
	year = {2019},
	journal = {International Journal of Innovative Technology and Exploring Engineering},
	volume = {9},
	number = {1},
	pages = {5159 – 5162},
	doi = {10.35940/ijitee.A9220.119119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075304864&doi=10.35940%2fijitee.A9220.119119&partnerID=40&md5=8f32b00c744aec2fa41d7dbc5becfe4b},
	affiliations = {Department of Planning and Coordination of Research Activities, Research Department, Krasnodar University of the Ministry of Internal Affairs of the Russian Federation, Russian Federation; Kazan Innovative University named after VG Timiryasov (IEML), Russian Federation; Kazan Federal University, Faculty of Law, Criminal Law Department, Russian Federation},
	abstract = {In the modern digital age, the issues of using artificial intelligence and the field of development of intelligent technologies are extremely important and relevant. Over the past few years, there have been attempts of state regulation of artificial intelligence, both in Russia and in other countries of the world. Artificial intelligence poses new challenges to various areas of law: from patent to criminal law, from privacy to antitrust law. Among the current approaches, the most optimal is the creation of a separate legal regulation mechanism that creates a clear distinction between areas of responsibility of developers and users of systems with artificial intelligence and the technology itself. Today, the development of the legal framework for the existence of artificial intelligence can be conditionally divided into two approaches: the creation of a legal framework for the introduction of applied systems with artificial intelligence and stimulate their development; regulation of the sphere of creating artificial “super intelligence”, in particular, compliance of the developed technologies with generally recognized standards in the field of ethics and law. A separate area should be the introduction of uniform ethical principles for all developers and users of systems with artificial intelligence. The most optimal in this aspect is the approach implemented within the framework of the Asilomar principles. In these circumstances, the appeal to the problem of legal regulation of artificial intelligence is becoming more relevant than ever. This paper presents the results of a detailed analysis of existing approaches to the legal regulation of artificial intelligence. © BEIESP.},
	author_keywords = {Artificial intelligence; Asilomar principles; Digital economy; Information law; Intellectual technologies; Law; Legal regulation; Legislation; Machine learning; Robot; Superintelligence; Technological singularity},
	publisher = {Blue Eyes Intelligence Engineering and Sciences Publication},
	issn = {22783075},
	language = {English},
	abbrev_source_title = {Int. J. Innov. Technol. Explor. Eng.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Bronze Open Access}
}

@ARTICLE{Carter201995,
	author = {Carter, Denise},
	title = {New technologies and new data sources: The business information survey 2019},
	year = {2019},
	journal = {Business Information Review},
	volume = {36},
	number = {3},
	pages = {95 – 105},
	doi = {10.1177/0266382119871848},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072104319&doi=10.1177%2f0266382119871848&partnerID=40&md5=d3db9ddaee12af8fa26a906d05af8891},
	affiliations = {DCision Consult, Switzerland},
	abstract = {The topics explored with the 2019 business information survey participants concern the challenges and opportunities that new and expanding sources of data and content, and new tools and technologies have already brought to the table. And a look ahead at how they might continue to change the business information landscape. Specific questions and topics raised during the primary survey interviews ranged from: How can the information professional make sure the right skills are available to their organization to manage these effectively? Is a potential role of the information professional individual or team to be the organizational strategic advisor for data and information? The integrity and ethics of data, particularly new sources: Where does the data come from? How is it being manipulated? Through to: How critical will good ethical standards be in the future? The survey report doesn’t answer all the questions raised, but it does give a clear indication that today’s information professional is continuously looking for the best response to each challenge. © The Author(s) 2019.},
	author_keywords = {Artificial intelligence (AI); data; data literacy; data quality; machine learning (ML); skills; training; vendors},
	correspondence_address = {D. Carter; DCision Consult, Switzerland; email: denise.carter@dcisionconsult.com},
	publisher = {SAGE Publications Ltd},
	issn = {02663821},
	language = {English},
	abbrev_source_title = {Bus. Inf. Rev.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Watson2019417,
	author = {Watson, David},
	title = {The Rhetoric and Reality of Anthropomorphism in Artificial Intelligence},
	year = {2019},
	journal = {Minds and Machines},
	volume = {29},
	number = {3},
	pages = {417 – 440},
	doi = {10.1007/s11023-019-09506-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073681664&doi=10.1007%2fs11023-019-09506-6&partnerID=40&md5=74ca5be4edab24daa126b2e03e7b75bf},
	affiliations = {Oxford Internet Institute, University of Oxford, 41 Saint Giles’, Oxford, OX1 3LW, United Kingdom; Alan Turing Institute, London, United Kingdom},
	abstract = {Artificial intelligence (AI) has historically been conceptualized in anthropomorphic terms. Some algorithms deploy biomimetic designs in a deliberate attempt to effect a sort of digital isomorphism of the human brain. Others leverage more general learning strategies that happen to coincide with popular theories of cognitive science and social epistemology. In this paper, I challenge the anthropomorphic credentials of the neural network algorithm, whose similarities to human cognition I argue are vastly overstated and narrowly construed. I submit that three alternative supervised learning methods—namely lasso penalties, bagging, and boosting—offer subtler, more interesting analogies to human reasoning as both an individual and a social phenomenon. Despite the temptation to fall back on anthropomorphic tropes when discussing AI, however, I conclude that such rhetoric is at best misleading and at worst downright dangerous. The impulse to humanize algorithms is an obstacle to properly conceptualizing the ethical challenges posed by emerging technologies. © 2019, The Author(s).},
	author_keywords = {Artificial intelligence; Cognitive science; Digital ethics; Epistemology; Machine learning; Social epistemology},
	keywords = {Artificial intelligence; Biomimetics; Learning systems; Machine learning; Biomimetic design; Cognitive science; Digital ethics; Emerging technologies; Epistemology; Neural network algorithm; Social epistemology; Supervised learning methods; Philosophical aspects},
	correspondence_address = {D. Watson; Oxford Internet Institute, University of Oxford, Oxford, 41 Saint Giles’, OX1 3LW, United Kingdom; email: david.watson@oii.ox.ac.uk},
	publisher = {Springer Netherlands},
	issn = {09246495},
	coden = {MMACE},
	language = {English},
	abbrev_source_title = {Minds Mach},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 46; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Geis20191516,
	author = {Geis, J. Raymond and Brady, Adrian P. and Wu, Carol C. and Spencer, Jack and Ranschaert, Erik and Jaremko, Jacob L. and Langer, Steve G. and Kitts, Andrea Borondy and Birch, Judy and Shields, William F. and van den Hoven van Genderen, Robert and Kotter, Elmar and Gichoya, Judy Wawira and Cook, Tessa S. and Morgan, Matthew B. and Tang, An and Safdar, Nabile M. and Kohli, Marc},
	title = {Ethics of Artificial Intelligence in Radiology: Summary of the Joint European and North American Multisociety Statement},
	year = {2019},
	journal = {Journal of the American College of Radiology},
	volume = {16},
	number = {11},
	pages = {1516 – 1521},
	doi = {10.1016/j.jacr.2019.07.028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073960863&doi=10.1016%2fj.jacr.2019.07.028&partnerID=40&md5=1db9d632a9db9c6ba39e46bdd59a61a0},
	affiliations = {American College of Radiology Data Science Institute, Reston, VA, United States; Department of Radiology, National Jewish Health, Denver, CO, United States; Mercy University Hospital, Cork, Ireland; University of Texas MD Anderson Cancer Center, Houston, TX, United States; MIT, Department of Linguistics and Philosophy, Cambridge, MA, United States; Netherlands Cancer Institute, Amsterdam, Netherlands; Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Alberta, Canada; Radiology Department-Mayo Clinic, Rochester, MN, United States; Lahey Hospital & Medical Center, Burlington, MA, United States; Pelvic Pain Support Network, Poole, United Kingdom; General Counsel, American College of Radiology, Reston, VA, United States; Center of Law and Internet, Vrije Universiteit Amsterdam, Amsterdam, Netherlands; Department of Radiology, University Medical Center, Freiburg, Germany; Department of Interventional Radiology, Oregon Health & Science University, Portland, OR, United States; Department of Radiology and Imaging Sciences, Emory University, Atlanta, United States; Department of Radiology, University of Pennsylvania, Philadelphia, PA, United States; Department of Radiology and Imaging Sciences, University of Utah, Salt Lake City, UT, United States; Centre de Recherche du Centre Hospitalier de L'Université de Montréal, Quebec, Canada; Department of Radiology and Biomedical Imaging, UCSF, San Francisco, CA, United States},
	abstract = {This is a condensed summary of an international multisociety statement on ethics of artificial intelligence (AI) in radiology produced by the ACR, European Society of Radiology, RSNA, Society for Imaging Informatics in Medicine, European Society of Medical Imaging Informatics, Canadian Association of Radiologists, and American Association of Physicists in Medicine. AI has great potential to increase efficiency and accuracy throughout radiology, but it also carries inherent pitfalls and biases. Widespread use of AI-based intelligent and autonomous systems in radiology can increase the risk of systemic errors with high consequence and highlights complex ethical and societal issues. Currently, there is little experience using AI for patient care in diverse clinical settings. Extensive research is needed to understand how to best deploy AI in clinical practice. This statement highlights our consensus that ethical use of AI in radiology should promote well-being, minimize harm, and ensure that the benefits and harms are distributed among stakeholders in a just manner. We believe AI should respect human rights and freedoms, including dignity and privacy. It should be designed for maximum transparency and dependability. Ultimate responsibility and accountability for AI remains with its human designers and operators for the foreseeable future. The radiology community should start now to develop codes of ethics and practice for AI that promote any use that helps patients and the common good and should block use of radiology data and algorithms for financial gain without those two attributes. © 2019 The Author(s)},
	author_keywords = {Artificial intelligence; data; ethics; machine learning; radiology},
	keywords = {Artificial Intelligence; Codes of Ethics; Europe; Humans; North America; Practice Guidelines as Topic; Radiology; Societies, Medical; adult; algorithm; article; artificial intelligence; clinical practice; consensus; diagnostic imaging; human; human dignity; information science; machine learning; medical ethics; patient care; physicist; privacy; radiologist; radiology; wellbeing; artificial intelligence; ethics; Europe; medical society; North America; practice guideline; radiology},
	correspondence_address = {J.R. Geis; National Jewish Health, Department of Radiology, Fort Collins, 3401 Shore Rd, 80524, United States; email: raym.geis@gmail.com},
	publisher = {Elsevier B.V.},
	issn = {15461440},
	pmid = {31585696},
	language = {English},
	abbrev_source_title = {J. Am. Coll. Radiol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 35; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Passos2019582,
	author = {Passos, Ives C. and Ballester, Pedro L. and Barros, Rodrigo C. and Librenza-Garcia, Diego and Mwangi, Benson and Birmaher, Boris and Brietzke, Elisa and Hajek, Tomas and Lopez Jaramillo, Carlos and Mansur, Rodrigo B. and Alda, Martin and Haarman, Bartholomeus C. M. and Isometsa, Erkki and Lam, Raymond W. and McIntyre, Roger S. and Minuzzi, Luciano and Kessing, Lars V. and Yatham, Lakshmi N. and Duffy, Anne and Kapczinski, Flavio},
	title = {Machine learning and big data analytics in bipolar disorder: A position paper from the International Society for Bipolar Disorders Big Data Task Force},
	year = {2019},
	journal = {Bipolar Disorders},
	volume = {21},
	number = {7},
	pages = {582 – 594},
	doi = {10.1111/bdi.12828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073987808&doi=10.1111%2fbdi.12828&partnerID=40&md5=bc8e3d0b9c791435d64885fa85ed7842},
	affiliations = {Laboratory of Molecular Psychiatry and Bipolar Disorder Program, Programa de Pós-Graduação em Psiquiatria e Ciências do Comportamento, Hospital de Clínicas de Porto Alegre, Universidade Federal do Rio Grande do Sul, Porto Alegre, Brazil; School of Technology, Pontifícia Universidade Católica do Rio Grande do Sul, Rio Grande do Sul, Brazil; Department of Psychiatry and Behavioural Neurosciences, McMaster University, Hamilton, ON, Canada; Department of Psychiatry and Behavioral Sciences, UT Center of Excellence on Mood Disorders, McGovern Medical School, The University of Texas Health Science Center at Houston, Houston, TX, United States; Department of Psychiatry, Western Psychiatric Institute and Clinic, University of Pittsburgh School of Medicine, Pittsburgh, PA, United States; Department of Psychiatry, Queen's University School of Medicine, Kingston, ON, Canada; Department of Psychiatry, Dalhousie University, Halifax, NS, Canada; National Institute of Mental Health, Klecany, Czech Republic; Research Group in Psychiatry, Department of Psychiatry, Faculty of Medicine, University of Antioquia, Medellín, Colombia; Mood Disorders Program, Hospital Universitario San Vicente Fundación, Medellín, Colombia; Mood Disorders Psychopharmacology Unit (MDPU), University Health Network, University of Toronto, Toronto, ON, Canada; Department of Psychiatry, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Department of Psychiatry, University of Helsinki and Helsinki University Central Hospital, Helsinki, Finland; Department of Psychiatry, University of British Columbia, Vancouver, BC, Canada; Department of Psychiatry, University of Toronto, Toronto, ON, Canada; Copenhagen Affective Disorder Research Center (CADIC), Psychiatric Center Copenhagen, Copenhagen University Hospital, Copenhagen, Denmark},
	abstract = {Objectives: The International Society for Bipolar Disorders Big Data Task Force assembled leading researchers in the field of bipolar disorder (BD), machine learning, and big data with extensive experience to evaluate the rationale of machine learning and big data analytics strategies for BD. Method: A task force was convened to examine and integrate findings from the scientific literature related to machine learning and big data based studies to clarify terminology and to describe challenges and potential applications in the field of BD. We also systematically searched PubMed, Embase, and Web of Science for articles published up to January 2019 that used machine learning in BD. Results: The results suggested that big data analytics has the potential to provide risk calculators to aid in treatment decisions and predict clinical prognosis, including suicidality, for individual patients. This approach can advance diagnosis by enabling discovery of more relevant data-driven phenotypes, as well as by predicting transition to the disorder in high-risk unaffected subjects. We also discuss the most frequent challenges that big data analytics applications can face, such as heterogeneity, lack of external validation and replication of some studies, cost and non-stationary distribution of the data, and lack of appropriate funding. Conclusion: Machine learning-based studies, including atheoretical data-driven big data approaches, provide an opportunity to more accurately detect those who are at risk, parse-relevant phenotypes as well as inform treatment selection and prognosis. However, several methodological challenges need to be addressed in order to translate research findings to clinical settings. © 2019 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd},
	author_keywords = {big data; bipolar disorder; data mining; deep learning; machine learning; personalized psychiatry; predictive psychiatry; risk prediction},
	keywords = {Advisory Committees; Big Data; Bipolar Disorder; Clinical Decision-Making; Data Science; Humans; Machine Learning; Phenotype; Prognosis; Risk Assessment; Suicidal Ideation; lithium; neuroleptic agent; big data; bipolar depression; bipolar disorder; bipolar mania; confidentiality; data clustering; data quality; deep learning; differential diagnosis; electronic medical record; family history; first-degree relative; human; machine learning; medical ethics; mood disorder; neuroimaging; personalized medicine; prediction; priority journal; privacy; prognosis; relapse; Review; risk assessment; suicidal behavior; treatment response; advisory committee; bipolar disorder; clinical decision making; phenotype; suicidal ideation},
	correspondence_address = {F. Kapczinski; Department of Psychiatry and Behavioural Neurosciences, McMaster University, Hamilton, Canada; email: flavio.kapczinski@gmail.com},
	publisher = {Blackwell Publishing Inc.},
	issn = {13985647},
	coden = {BDIIA},
	pmid = {31465619},
	language = {English},
	abbrev_source_title = {Bipolar Disord.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 40; All Open Access, Green Open Access}
}

@BOOK{Kabza2020183,
	author = {Kabza, Milena},
	title = {Artificial intelligence in financial services-benefits and costs},
	year = {2020},
	journal = {Innovation in Financial Services: Balancing Public and Private Interests},
	pages = {183 – 198},
	doi = {10.4324/9781003051664-14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096248907&doi=10.4324%2f9781003051664-14&partnerID=40&md5=e724e68282d2ade182a6fb5eedf1e887},
	affiliations = {Centre for Consumer Research, Faculty of Management, Warsaw University of Technology, Poland},
	abstract = {Artificial intelligence and machine learning are changing the face of the financial sector. They modify the existing connections between entities operating on the financial market, open possibilities for completely new operational models and introduce new rules of competition. The potential of these technologies is therefore a great challenge for the economy and the financial system, which is why it is becoming increasingly important to consider the consequences of new technologies for financial stability and protection of the financial consumer. Proper understanding and regulation of data privacy and ethics issues will play a significant role. Moreover, since artificial intelligence and machine learning are increasingly important in the functioning of the financial system, they are also a new source of systemic risk. These new technologies will therefore force re-analysis of the principles and techniques of supervision and regulation, including financial regulation, in order to avoid possible distortions for both the national and global economy. JEL: A12, C63, D18, G20, G28, O33. © 2021 selection and editorial matter, Lech Gąsiorkiewicz and Jan Monkiewicz.},
	publisher = {Taylor and Francis},
	isbn = {978-100020407-0; 978-036750891-3},
	language = {English},
	abbrev_source_title = {Innovation in Financial Services: Balancing Public and Private Interests},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Begen2020336,
	author = {Begen, Petr and Misnikov, Yuri and Filatova, Olga},
	title = {Application of automated tools in researching internet discourses: Experience of using the recurrent neural networks for studying discussions on pension reform},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2543},
	pages = {336 – 344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078464907&partnerID=40&md5=608fb877eccba461b23e53a9b9bc8c9a},
	affiliations = {ITMO University, Kronverksky pr., 49, St. Petersburg, 197101, Russian Federation; St. Petersburg State University, Universitetskaya nab., 7–9, St. Petersburg, 199034, Russian Federation},
	abstract = {The paper presents the results of an experiment that applied the Recurrent Neural Network (RNN) and long short-term memory (LSTM) networks to assess how accurately they can determine the attitude of 998 participants towards the pension reform policy in Russia who posted 10,592 comments on 16 online forums in 11 cities. The training set was assembled and coded according to a proposed conceptual model of a moral discourse based on Jurgen Habermas’s discourse ethics theory. The main conclusion of this experiment is that the discourse-based approach — based on the identification of basic validity claims — can be instrumental in building training datasets for deep machine learning on a socially salient topic. The experiment also shows benefits and limitations of using artificial neural networks for a deeper understanding of the results of public discussions in an online environment. The main benefit was that the built neural networks have proven to be sufficiently accurate in predicting positions of discourse participants towards the pension reform policy, with almost 90% in the case of binary classification (two “For” and “Against” positions). However, the accuracy level drops with the inclusion of a third “Neutral” category (to 78%), which was a major limitation of the research; that is, the variation in the prediction accuracy is due to the uneven distribution of data among categories and an increase of new data. Yet this indicator is still acceptable when working with Internet discourse data. Copyright © 2020 for this paper by its authors.},
	author_keywords = {Deliberation; E-participation; Internet discourse; Machine learning; Recurrent neural networks; Validity claims},
	keywords = {Deep learning; Learning systems; Machine learning; Recurrent neural networks; Web services; Binary classification; Deliberation; E-participation; Online environments; Prediction accuracy; Recurrent neural network (RNN); Training data sets; Validity claims; Long short-term memory},
	editor = {Gorbunov-Posadov M. and Elizarov A. and Yakobovskiy M.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 21st Conference on Scientific Services and Internet, SSI 2019; Conference date: 23 September 2019 through 28 September 2019; Conference code: 157007}
}

@ARTICLE{Li2020358,
	author = {Li, Ya-Wen and Liu, Fang and Zhang, Tian-Nan and Xu, Fang and Gao, Yu-Chen and Wu, Tian},
	title = {Artificial intelligence in pediatrics},
	year = {2020},
	journal = {Chinese Medical Journal},
	volume = {133},
	number = {3},
	pages = {358 – 360},
	doi = {10.1097/CM9.0000000000000563},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079022993&doi=10.1097%2fCM9.0000000000000563&partnerID=40&md5=4fc1b42d137b2e59de6aa9b4e70b9c99},
	affiliations = {School of Economics and Management, Beijing University of Posts and Telecommunications, Beijing, 100876, China; Department of Stomatology, Capital Medical University, National Center for Children's Health, Beijing, 100045, China; Department of Pediatrics, Peking Union Medical College Hospital, Chinese Academy of Medical Sciences, Beijing, 100730, China; School of Banking and Finance, University of International Business and Economics, Beijing, 100029, China; School of Economics and Management, Tsinghua University, Beijing, 100084, China; NCMIS, Academy of Mathematics and Systems Science, Chinese Academy of Sciences, Beijing, 100190, China; School of Economics and Management, University of Chinese Academy of Sciences, Beijing, 100190, China; Key Laboratory of Big Data Mining and Knowledge Management, Chinese Academy of Sciences, Beijing, 100190, China},
	keywords = {Artificial Intelligence; Child; Deep Learning; Diagnosis, Computer-Assisted; Humans; Infant, Newborn; Pediatrics; bilirubin; artificial intelligence; asthma; autism; big data; bilirubin blood level; bootstrapping; brain size; clinical decision making; cloud computing; community acquired pneumonia; confidentiality; data mining; data processing; decision tree; disease association; doctor patient relationship; electronic medical record; health care delivery; health care system; human; information processing; information technology; interrater reliability; k nearest neighbor; machine learning; medical information system; medical research; natural language processing; newborn care; newborn jaundice; pediatrics; predictive value; pulmonary hypertension; quality control; research ethics; Review; sensitivity and specificity; statistical analysis; treatment planning; child; computer assisted diagnosis; newborn},
	correspondence_address = {Y.-C. Gao; School of Economics and Management, Tsinghua University, Beijing, 100084, China; email: gaoych@sem.tsinghua.edu.cn},
	publisher = {Lippincott Williams and Wilkins},
	issn = {03666999},
	coden = {CMDJA},
	pmid = {31929357},
	language = {English},
	abbrev_source_title = {Chin. Med. J.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Keskinbora2020393,
	author = {Keskinbora, Kadircan H. and Güven, Fatih},
	title = {Reply to letter to the editor},
	year = {2020},
	journal = {Turkish Journal of Ophthalmology},
	volume = {50},
	number = {6},
	pages = {393},
	doi = {10.4274/tjo.galenos.2020.11455},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099019473&doi=10.4274%2ftjo.galenos.2020.11455&partnerID=40&md5=871c43d701e59b7f5534704f3e84de76},
	affiliations = {Bahçeşehir University, Faculty of Medicine, Department of Ophthalmology, İstanbul, Turkey; Bahçeşehir University, Faculty of Medicine, Department of Medical Ethics and History of Medicine, İstanbul, Turkey; University of Health Sciences Turkey, Bakırköy Training and Research Hospital, Clinic of Ophthalmology, İstanbul, Turkey},
	author_keywords = {Artificial intelligence; Machine learning; Medical ethics; Ophthalmology},
	keywords = {Artificial Intelligence; Cataract; Dry Eye Syndromes; Humans; Machine Learning; Risk Factors; artificial intelligence; human; Letter; machine learning; medical ethics; ophthalmology; scientific literature; cataract; dry eye; risk factor},
	correspondence_address = {K.H. Keskinbora; Bahçeşehir University, Faculty of Medicine, Department of Ophthalmology, İstanbul, Turkey; email: kadircan.keskinbora@gmail.com; K.H. Keskinbora; Bahçeşehir University, Faculty of Medicine, Department of Medical Ethics and History of Medicine, İstanbul, Turkey; email: kadircan.keskinbora@gmail.com},
	publisher = {Turkish Ophthalmology Society},
	issn = {21498709},
	pmid = {33389944},
	language = {English},
	abbrev_source_title = {Turk. Jour. of Ophthalmol.},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Branley-Bell2020382,
	author = {Branley-Bell, Dawn and Whitworth, Rebecca and Coventry, Lynne},
	title = {User trust and understanding of explainable ai: Exploring algorithm visualisations and user biases},
	year = {2020},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {12183 LNCS},
	pages = {382 – 399},
	doi = {10.1007/978-3-030-49065-2_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088747762&doi=10.1007%2f978-3-030-49065-2_27&partnerID=40&md5=0dd4dee0e32195aa66d0a057a7ee16d2},
	affiliations = {Northumbria University, Newcastle upon Tyne, NE1 8ST, United Kingdom; Red Hat, The Catalyst, Newcastle upon Tyne, NE4 5TG, United Kingdom},
	abstract = {Artificial intelligence (AI) is increasingly being integrated into different areas of our lives. AI has the potential to increase productivity and relieve workload on staff in high-pressure jobs such as healthcare. However, most AI healthcare tools have failed. For AI to be effective, it is vital that users can understand how the system is processing data. Explainable AI (XAI) moves away from the traditional ‘black box’ approach, aiming to make the processes behind the system more transparent. This experimental study uses real healthcare data – and combines a computer science and psychological approach – to investigate user trust and understanding of three popular XAI algorithms (Decision Trees, Logistic Regression and Neural Networks). The results question the contribution of understanding towards user trust; Suggesting that understanding and explainability are not the only factors contributing to trust in AI. Users also show biases in trust and understanding – with a particular bias towards malignant results. This raises important issues around how humans can be encouraged to make more accurate judgements when using XAI systems. These findings have implications in relation to ethics, future XAI design, healthcare and further research. © Springer Nature Switzerland AG 2020.},
	author_keywords = {Artificial intelligence; Cognitive biases; Explainable AI; Health; Healthcare; Machine Learning; Medical diagnoses; Trust; Understanding},
	keywords = {Artificial intelligence; Data handling; Decision trees; Health care; Logistic regression; Medical computing; Trees (mathematics); Black boxes; High pressure; Human computer interaction},
	correspondence_address = {D. Branley-Bell; Northumbria University, Newcastle upon Tyne, NE1 8ST, United Kingdom; email: dawn.branley-bell@northumbria.ac.uk},
	editor = {Kurosu M.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303049064-5},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: Thematic Area on Human Computer Interaction, HCI 2020, held as part of the 22nd International Conference on Human-Computer Interaction, HCII 2020; Conference date: 19 July 2020 through 24 July 2020; Conference code: 242229}
}

@ARTICLE{Poliak202058,
	author = {Poliak, Milos and Baker, Andrew and Konecny, Vladimir and Nica, Elvira},
	title = {Regulatory and governance mechanisms for self-driving cars: Social equity benefits and machine learning-based ethical judgments},
	year = {2020},
	journal = {Contemporary Readings in Law and Social Justice},
	volume = {12},
	number = {1},
	pages = {58 – 64},
	doi = {10.22381/CRLSJ12120208},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090646516&doi=10.22381%2fCRLSJ12120208&partnerID=40&md5=bda0d1ce315832e17aac08e237eb6802},
	affiliations = {Faculty of Operation and Economics of Transport and Communications, Department of Road and Urban Transport, University of Zilina, Zilina, Slovakia; The Cyber-Physical Production Networks Research Unit at AAER, Wellington, New Zealand; Faculty of Administration and Public Management, The Bucharest University of Economic Studies, Romania},
	abstract = {The aim of this paper is to synthesize and analyze existing evidence on regulatory and governance mechanisms for self-driving cars. Using and replicating data from AUDI AG, Axios, BikePGH, Deloitte, Ipsos, Kennedys, McKinsey, and Statista, we performed analyses and made estimates regarding social equity benefits and machine learning-based ethical judgments. Data were analyzed using structural equation modeling. © 2020, Addleton Academic Publishers. All rights reserved.},
	author_keywords = {Car; Ethics; Governance; Machine learning; Regulatory; Self-driving},
	correspondence_address = {A. Baker; The Cyber-Physical Production Networks Research Unit at AAER, Wellington, New Zealand; email: a.baker@aa-er.org},
	publisher = {Addleton Academic Publishers},
	issn = {19489137},
	language = {English},
	abbrev_source_title = {Contemp. Read. Law Soc. Justice},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@ARTICLE{Johnson2019427,
	author = {Johnson, Sandra L J},
	title = {AI, Machine Learning, and Ethics in Health Care},
	year = {2019},
	journal = {The Journal of legal medicine},
	volume = {39},
	number = {4},
	pages = {427 – 441},
	doi = {10.1080/01947648.2019.1690604},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077941401&doi=10.1080%2f01947648.2019.1690604&partnerID=40&md5=d6325097b078ef28702079703c8f4c06},
	keywords = {Artificial Intelligence; Beneficence; Bioethics; Confidentiality; Congresses as Topic; Data Science; Health Equity; Informed Consent; Legislation as Topic; Machine Learning; Neural Networks, Computer; Personal Autonomy; Social Justice; Social Responsibility; artificial intelligence; beneficence; bioethics; confidentiality; ethics; health equity; informed consent; law; machine learning; organization; personal autonomy; social justice; social responsibility},
	publisher = {NLM (Medline)},
	issn = {1521057X},
	pmid = {31940250},
	language = {English},
	abbrev_source_title = {J Leg Med},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Dominguez2019,
	author = {Dominguez, Hector and Mowry, Judith and Perez, Elisabeth and Kendrick, Christine and Martin, Kevin},
	title = {Privacy and information protection for a new generation of city services},
	year = {2019},
	journal = {Proceedings of the 2nd ACM/EIGSCC Symposium on Smart Cities and Communities, SCC 2019},
	doi = {10.1145/3357492.3358628},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074329127&doi=10.1145%2f3357492.3358628&partnerID=40&md5=4d7f18a2ea1f68aa24ac717a6cabd364},
	affiliations = {Bureau of Planning and Sustainability, City of Portland, Portland, OR, United States; Office of Equity and Human Rights, City of Portland, Portland, OR, United States; Office of Community Technology, City of Portland, Portland, OR, United States},
	abstract = {This paper will showcase the work that the City of Portland has done around developing Privacy and Information Protection Principles considering the current state of technology, the social digital age, and advance inference algorithms like machine learning or other Artificial Intelligence tools. By creating more responsible data stewardship in the public sector, municipalities are set to build trusted information networks involving communities and complex social issues. Particularly, the promotion of data privacy can lead to the emergence of anti-poverty and economic development strategies. The City of Portland has developed seven Privacy and Information Protection Principles: Transparency and accountability, full lifecycle stewardship, equitable data management, ethical and non-discriminatory use of data, data openness, automated decision systems, and data utility. These principles have implications in social equity and the future of technology management in smart cities projects. Principle implementation involves the collaboration of different agencies, particularly focused on ethics and human rights supporting sustainable development. This work is part of emergent strategies for a new generation of city services based on data and information, which aim to improve civic engagement, social benefits to communities in city neighborhoods and better collaboration with partners and other government agencies. © 2019 Copyright is held by the owner/author(s).},
	author_keywords = {Automatic decision systems; Digital equity; Digital inclusion; Government services; Privacy},
	keywords = {Data privacy; Economic and social effects; Inference engines; Information services; Life cycle; Machine learning; Philosophical aspects; Planning; Smart city; Social aspects; Artificial intelligence tools; Automatic decision; Digital equity; Digital inclusion; Government services; Information networks; Information protection; Technology managements; Information management},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036978-7},
	language = {English},
	abbrev_source_title = {Proc. ACM/EIGSCC Symp. Smart Cities Communities, SCC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; Conference name: 2nd ACM/EIGSCC Symposium on Smart Cities and Communities, SCC 2019; Conference date: 10 September 2019 through 12 September 2019; Conference code: 152684}
}

@CONFERENCE{Alabi20201,
	author = {Alabi, Rasheed Omobolaji and Vartiainen, Tero and Elmusrati, Mohammed},
	title = {Machine learning for prognosis of oral cancer: What are the ethical challenges?},
	year = {2020},
	journal = {CEUR Workshop Proceedings},
	volume = {2737},
	pages = {1 – 22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85099035322&partnerID=40&md5=35471c1c646b4303e8565c937b4fc545},
	affiliations = {Department of Industrial Digitalization, School of Technology and Innovations, University of Vaasa, Vaasa, Finland; Department of Computer Science, School of Technology and Innovations, University of Vaasa, Vaasa, Finland},
	abstract = {Background: Machine learning models have shown high performance, particularly in the diagnosis and prognosis of oral cancer. However, in actual everyday clinical practice, the diagnosis and prognosis using these models remain limited. This is due to the fact that these models have raised several ethical and morally laden dilemmas. Purpose: This study aims to provide a systematic stateof- the-art review of the ethical and social implications of machine learning models in oral cancer management. Methods: We searched the OvidMedline, PubMed, Scopus, Web of Science and Institute of Electrical and Electronics Engineers databases for articles examining the ethical issues of machine learning or artificial intelligence in medicine, healthcare or care providers. The Preferred Reporting Items for Systematic Review and Meta-Analysis was used in the searching and screening processes. Findings: A total of 33 studies examined the ethical challenges of machine learning models or artificial intelligence in medicine, healthcare or diagnostic analytics. Some ethical concerns were data privacy and confidentiality, peer disagreement (contradictory diagnostic or prognostic opinion between the model and the clinician), patient's liberty to decide the type of treatment to follow may be violated, patients-clinicians' relationship may change and the need for ethical and legal frameworks. Conclusion: Government, ethicists, clinicians, legal experts, patients' representatives, data scientists and machine learning experts need to be involved in the development of internationally standardised and structured ethical review guidelines for the machine learning model to be beneficial in daily clinical practice. Copyright © 2020 for this paper by its authors.},
	author_keywords = {Ethics; Machine learning; Oral tongue cancer; Systematic review},
	keywords = {Data privacy; Diseases; Machine learning; Patient treatment; Philosophical aspects; Artificial intelligence in medicine; Clinical practices; Diagnosis and prognosis; Institute of Electrical and Electronics Engineers; Machine learning models; Social implication; State-of-the art reviews; Systematic Review; Diagnosis},
	correspondence_address = {R.O. Alabi; Department of Industrial Digitalization, School of Technology and Innovations, University of Vaasa, Vaasa, Finland; email: rasheed.alabi@student.uwasa.fi},
	editor = {Koskinen J. and Rantanen M.M. and Tuikka A.-M. and Knaapi-Junnila S.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; Conference name: 2020 Conference on Technology Ethics, Tethics 2020; Conference date: 21 October 2020; Conference code: 164803}
}

@ARTICLE{Bonifazi2020242,
	author = {Bonifazi, Fedele and Volpe, Elisabetta and Digregorio, Giuseppe and Giannuzzi, Viviana and Ceci, Adriana},
	title = {Machine Learning Systems Applied to Health Data and System},
	year = {2020},
	journal = {European Journal of Health Law},
	volume = {27},
	number = {3},
	pages = {242 – 258},
	doi = {10.1163/15718093-BJA10009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091636446&doi=10.1163%2f15718093-BJA10009&partnerID=40&md5=43cd13510e868d444875c1291540e936},
	affiliations = {Fondazione per la Ricerca Farmacologica Gianni Benzi Onlus, Bari, Italy},
	abstract = {The use of machine learning (ML) in medicine is becoming increasingly fundamental to analyse complex problems by discovering associations among different types of information and to generate knowledge for medical decision support. Many regulatory and ethical issues should be considered. Some relevant EU provisions, such as the General Data Protection Regulation, are applicable. However, the regulatory framework for developing and marketing a new health technology implementing ML may be quite complex. Other issues include the legal liability and the attribution of negligence in case of errors. Some of the above-mentioned concerns could be, at least partially, resolved in case the ML software is classified as a 'medical device', a category covered by EU/national provisions. Concluding, the challenge is to understand how sustainable is the regulatory system in relation to the ML innovation and how legal procedures should be revised in order to adapt them to the current regulatory framework. © 2020 Copyright 2020 by Koninklijke Brill NV, Leiden, The Netherlands.},
	author_keywords = {artificial intelligence; ethical issues; health data; machine learning (ML); regulatory issues},
	keywords = {Bias; Confidentiality; Decision Making; Drug Development; Drug Discovery; Humans; Machine Learning; Malpractice; Medical Device Legislation; Medical Informatics; Precision Medicine; Risk Management; Safety; Software; Trust; confidentiality; decision making; drug development; ethics; human; legislation and jurisprudence; machine learning; malpractice; medical device regulation; medical informatics; personalized medicine; risk management; safety; software; statistical bias; trust},
	publisher = {Brill Nijhoff},
	issn = {09290273},
	coden = {EJHLE},
	pmid = {33652397},
	language = {English},
	abbrev_source_title = {Eur. J. Health Law},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Greiman2020204,
	author = {Greiman, Virginia A.},
	title = {Artificially intelligent systems and human rights: A global perspective},
	year = {2020},
	journal = {Proceedings of the 15th International Conference on Cyber Warfare and Security, ICCWS 2020},
	pages = {204 – 210},
	doi = {10.34190/ICCWS.20.139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083358750&doi=10.34190%2fICCWS.20.139&partnerID=40&md5=0ff3c5d89bdec3c99729ac9b6eb46754},
	affiliations = {Boston University, MA, United States},
	abstract = {Recently, there has been increased research on the topic of artificially intelligent programs having the capability of developing advanced systems that are presently used by governments and organizations to analyze highly complex structures across sectors in ways not possible with conventional information technology. While some AI is subject to rigid testing and ethical reviews, other applications raise questions as to what governance structures are in place to control the risks to humanity and long term harmful economic and social consequences. This paper raises awareness about how governments and private industry face an unprecedented challenge in managing these complex systems that include regulators, markets, and special interests that all play a role in influencing the development of AI in different contexts without a full appreciation of the impact of AI on human rights and other consequences. The research focuses on three primary areas: (1) How AI technologies have evolved; (2) What are the major ethical and human rights issues evolving from the use of AI in the public and business environment; and (3) how can we improve our frameworks and governance structure for AI regulation. Through empirical evidence this paper explores the legal implications including the rights and duties of the government and private industry in protecting against unlawful intrusions into people's lives, while at the same time advancing recommendations for accountability frameworks and regulations essential to ensure safety and security in advancing artificially intelligent systems. © 2020. the authors. All Rights Reserved.},
	author_keywords = {Algorithms; Artificial Intelligence; Ethics; Human Rights; Machine Learning},
	keywords = {Accident prevention; Computer crime; Intelligent systems; Philosophical aspects; Social aspects; Accountability framework; Business environments; Global perspective; Governance structures; Intelligent programs; Legal implications; Safety and securities; Social consequences; Laws and legislation},
	correspondence_address = {V.A. Greiman; Boston University, United States; email: ggreiman@bu.edu},
	editor = {Payne B.K. and Wu H.},
	publisher = {Academic Conferences and Publishing International Limited},
	isbn = {978-191276452-5},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Cyber Warf. Secur., ICCWS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 15th International Conference on Cyber Warfare and Security, ICCWS 2020; Conference date: 12 March 2020 through 13 March 2020; Conference code: 158670}
}

@ARTICLE{Resnick2019457,
	author = {Resnick, Kimberly S. and Appelbaum, Paul S.},
	title = {Passive monitoring of mental health status in the criminal forensic population},
	year = {2019},
	journal = {Journal of the American Academy of Psychiatry and the Law},
	volume = {47},
	number = {4},
	pages = {457 – 466},
	doi = {10.29158/JAAPL.003865-19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076326717&doi=10.29158%2fJAAPL.003865-19&partnerID=40&md5=5e10623cee8475963329e7692284e840},
	affiliations = {Weill Cornell Medical College, Department of Psychiatry, New York-Presbyterian Hospital, New York, NY, United States; Department of Psychiatry, Columbia University College of Physicians & Surgeons, New York, NY, United States},
	abstract = {Current approaches to monitoring patients’ mental status rely heavily on self-reported symptomatology, clinician observation, and self-rated symptom scales. The limitations inherent in these methodologies have implications for the accuracy of diagnosis, treatment planning, and prognosis. Certain populations are particularly affected by these limitations because of their unique situations, including criminal forensic patients, who have a history of both criminal behavior and mental disorder, and experience increased stigma and restrictions in their access to mental health care. This population may benefit particularly from recent developments in technology and the growing use of mobile devices and sensors to collect behavioral information via passive monitoring. These technologies offer objective parameters that correlate with mental health status and create an opportunity to use Big Data and machine learning to refine diagnosis and predict behavior in a way that represents a marked shift from current practices. This article reviews the approaches to and limitations of psychiatric assessment and contrasts this with the promise of these new technologies. It then discusses the ethics concerns associated with these technologies and explores their potential relevance to criminal forensic psychiatry and the broader implications they carry for health and criminal justice policy. © 2019, American Academy of Psychiatry and the Law. All rights reserved.},
	keywords = {Big Data; Criminals; Forensic Psychiatry; Health Status; Humans; Machine Learning; Mental Health; Mobile Applications; Remote Sensing Technology; Risk Assessment; Self Report; Smartphone; ethics; forensic psychiatry; health status; human; machine learning; mental health; mobile application; offender; psychology; remote sensing; risk assessment; self report; smartphone},
	correspondence_address = {K.S. Resnick; New York, East 68th Street, Box 140, 10065, United States; email: kir9041@med.cornell.edu},
	publisher = {American Academy of Psychiatry and the Law},
	issn = {10936793},
	coden = {JAPLF},
	pmid = {31533994},
	language = {English},
	abbrev_source_title = {J. Am. Acad. Psychiatry Law},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Safdar2020,
	author = {Safdar, Nabile M. and Banja, John D. and Meltzer, Carolyn C.},
	title = {Ethical considerations in artificial intelligence},
	year = {2020},
	journal = {European Journal of Radiology},
	volume = {122},
	doi = {10.1016/j.ejrad.2019.108768},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075567948&doi=10.1016%2fj.ejrad.2019.108768&partnerID=40&md5=6e491233c2126bdfa5d8c1755a43e386},
	affiliations = {Department of Radiology and Imaging Sciences, Emory University, Atlanta, Georgia; Department of Rehabilitation Medicine, Emory University, Atlanta, Georgia; Department of Biomedical Informatics, Emory University, Atlanta, Georgia; Department of Psychiatry and Behavioral Sciences, Emory University, Atlanta, Georgia; Department of Neurology, Emory University, Atlanta, Georgia; Center for Ethics, Emory University, Atlanta, Georgia},
	abstract = {With artificial intelligence (AI) precipitously perched at the apex of the hype curve, the promise of transforming the disparate fields of healthcare, finance, journalism, and security and law enforcement, among others, is enormous. For healthcare – particularly radiology – AI is anticipated to facilitate improved diagnostics, workflow, and therapeutic planning and monitoring. And, while it is also causing some trepidation among radiologists regarding its uncertain impact on the demand and training of our current and future workforce, most of us welcome the potential to harness AI for transformative improvements in our ability to diagnose disease more accurately and earlier in the populations we serve. © 2019 Elsevier B.V.},
	author_keywords = {Artificial intelligence; Ethics; Machine learning; Radiology},
	keywords = {Artificial Intelligence; Forecasting; Humans; Radiologists; Radiology; Workflow; access to information; algorithm; artificial intelligence; automation; electronic medical record; machine learning; patient information; priority journal; Review; artificial intelligence; ethics; forecasting; human; radiologist; radiology; workflow},
	correspondence_address = {C.C. Meltzer; Emory University Hospital, Atlanta, 1364 Clifton Rd, Suite D-112, 30322, Georgia; email: cmeltze@emory.edu},
	publisher = {Elsevier Ireland Ltd},
	issn = {0720048X},
	coden = {EJRAD},
	pmid = {31786504},
	language = {English},
	abbrev_source_title = {Eur. J. Radiol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 47}
}

@ARTICLE{Kononov2020,
	author = {Kononov, Aleksandr and Korotetsky, Boris and Jahatspanian, Igor and Gubal, Anna and Vasiliev, Alexey and Arsenjev, Andrey and Nefedov, Andrey and Barchuk, Anton and Gorbunov, Ilya and Kozyrev, Kirill and Rassadina, Anna and Iakovleva, Evgenia and Sillanpaä, Mika and Safaei, Zahra and Ivanenko, Natalya and Stolyarova, Nadezhda and Chuchina, Victoria and Ganeev, Alexandr},
	title = {Online breath analysis using metal oxide semiconductor sensors (electronic nose) for diagnosis of lung cancer},
	year = {2020},
	journal = {Journal of Breath Research},
	volume = {14},
	number = {1},
	doi = {10.1088/1752-7163/ab433d},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073764300&doi=10.1088%2f1752-7163%2fab433d&partnerID=40&md5=f802117d2a2e9d35424cb824b745f95c},
	affiliations = {St Petersburg State University, Universitetskaya nab.7/9, St Petersburg, 199034, Russian Federation; Institute of Toxicology, Federal Medical-Biological Agency, Bechtereva st 1, St Petersburg, 192019, Russian Federation; Joint-Stock Company 'Scientific and Production Association 'PRIBOR', 17 line of Vasilievsky island 4-6, St Petersburg, 199034, Russian Federation; ITMO University, Kronverksky pr. 49, St Petersburg, 197101, Russian Federation; National Research Center, «Kurchatov Institute», Kurchatova sq. 1, Moscow, 123182, Russian Federation; N.N. Petrov National Medical Research Center of Oncology, Ministry of Health of Russia, pos. Pesochnoye ul. Leningradskaya 68, St Petersburg, 197758, Russian Federation; Federal State Budgetary Institution, 'St Petersburg Scientific Research Institute of Phthisiopulmonology', Ministry of Health of the Russian Federation, Ligovsky pr. 2-4, St Petersburg, 191036, Russian Federation; University of Tampere, Faculty of Social Sciences, Health Sciences, Arvo Ylpön katu 34, Tampere, 33520, Finland; Saint Petersburg Electrotechnical University, 'LETI', ul. Professora Popova 5, St Petersburg, 197376, Russian Federation; Department of Green Chemistry, School of Engineering Science, LUT University, Sammonkatu 12, Mikkeli, FI-50130, Finland},
	abstract = {The analysis of exhaled breath is drawing a high degree of interest in the diagnostics of various diseases, including lung cancer. Electronic nose (E-nose) technology is one of the perspective approaches in the field due to its relative simplicity and cost efficiency. The use of an E-nose together with pattern recognition algorithms allow 'breath-prints' to be discriminated. The aim of this study was to develop an efficient online E-nose-based lung cancer diagnostic method via exhaled breath analysis with the use of some statistical classification methods. A developed multisensory system consisting of six metal oxide chemoresistance gas sensors was employed in three temperature regimes. This study involved 118 individuals: 65 in the lung cancer group (cytologically verified) and 53 in the healthy control group. The exhaled breath samples of the volunteers were analysed using the developed E-nose system. The dataset obtained, consisting of the sensor responses, was pre-processed and split into training (70%) and test (30%) subsets. The training data was used to fit the classification models; the test data was used for the estimation of prediction possibility. Logistic regression was found to be an adequate data-processing approach. The performance of the developed method was promising for the screening purposes (sensitivity-95.0%, specificity-100.0%, accuracy-97.2%). This shows the applicability of the gas-sensitive sensor array for the exhaled breath diagnostics. Metal oxide sensors are highly sensitive, low-cost and stable, and their poor sensitivity can be enhanced by integrating them with machine learning algorithms, as can be seen in this study. All experiments were carried out with the permission of the N.N. Petrov Research Institute of Oncology ethics committee no. 15/83 dated March 15, 2017. © 2019 IOP Publishing Ltd.},
	author_keywords = {breath analysis; early diagnostics; electronic nose; lung cancer; metal oxide sensors; volatile organic compounds},
	keywords = {Aged; Algorithms; Breath Tests; Calibration; Case-Control Studies; Electric Conductivity; Electronic Nose; Exhalation; Humans; Internet; Logistic Models; Lung Neoplasms; Metals; Middle Aged; Oxides; ROC Curve; Semiconductors; metal; oxide; adult; Article; breath analysis; cancer diagnosis; controlled study; diagnostic accuracy; diagnostic test accuracy study; expired air; female; human; lung cancer; major clinical study; male; online system; priority journal; sensitivity and specificity; aged; algorithm; breath analysis; calibration; case control study; chemistry; electric conductivity; electronic nose; exhalation; Internet; lung tumor; middle aged; procedures; receiver operating characteristic; semiconductor; statistical model},
	correspondence_address = {V. Chuchina; St Petersburg State University, St Petersburg, Universitetskaya nab.7/9, 199034, Russian Federation; email: v.chuchina@spbu.ru},
	publisher = {Institute of Physics Publishing},
	issn = {17527155},
	pmid = {31505480},
	language = {English},
	abbrev_source_title = {J. Breath Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 47}
}

@ARTICLE{Clapton2019531,
	author = {Clapton, William and Shepherd, Laura J.},
	title = {Ethics Ex Machina: popular culture and the plural futures of politics},
	year = {2019},
	journal = {Australian Journal of Political Science},
	volume = {54},
	number = {4},
	pages = {531 – 542},
	doi = {10.1080/10361146.2019.1663400},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074139196&doi=10.1080%2f10361146.2019.1663400&partnerID=40&md5=58cef5e5b07b667c414e1631b8ef6139},
	affiliations = {School of Social Sciences, University of New South Wales, Sydney, Australia; Department of Government and International Relations, School of Social and Political Science, The University of Sydney, Sydney, Australia},
	abstract = {The articulation of ethical responsibility can be conceived as a condition of ethical practice that brings into being a human subject to whom we owe consideration, and the reverse must also hold: we are brought into being–subjectified–through these relational connections. But can these connections exist between human and non-human subjects? In this short paper, we analyse the representation of artificially intelligent machines in the popular television series Westworld and the movie Ex Machina and elaborate on the boundary between human and non-human as a complex and contested ethical space. We argue that taking popular cultural representations of machine learning seriously can offer significant insight into how futures of human subjectivity and ethicopolitical responsibility might unfold. (117 words). © 2019, © 2019 Australian Political Studies Association.},
	author_keywords = {artificial intelligence; ethical responsibility; ethicopolitics; ethics; machine learning; Popular culture},
	correspondence_address = {L.J. Shepherd; Department of Government and International Relations, School of Social and Political Science, The University of Sydney, Sydney, Australia; email: laura.shepherd@sydney.edu.au},
	publisher = {Routledge},
	issn = {10361146},
	language = {English},
	abbrev_source_title = {Aust. J. Polit. Sci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Batista20207,
	author = {Batista, Raynel and Villar, Oscar and González, Héctor and Milián, Vladimir},
	title = {Cultural challenges of the malicious use of artificial intelligence in Latin American regional balance},
	year = {2020},
	journal = {Proceedings of the European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2020},
	pages = {7 – 13},
	doi = {10.34190/EAIR.20.029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097844996&doi=10.34190%2fEAIR.20.029&partnerID=40&md5=359ac726c48deb6d4161b7b60aba16b7},
	affiliations = {Universidad de las Ciencias Informáticas, Havana, Cuba; Gzhel State University, Russian Federation; Universidad de las Ciencias Informáticas, Presidential Board of Big Data Analysis, Cuba},
	abstract = {This paper surveys the landscape of potential security threats from malicious use of artificial intelligence technologies (MUAI) in Latin America. This study is based on scenario analysis to identify the MUAI-related cultural threats for region geopolitical balance. The development of artificial intelligence (AI) and machine learning capabilities stimulates the transition to a new technological order. These technologies with indeed many social applications benefits also transform nations power relations and lead to the new threats and vulnerabilities in the field of international psychological security (IPS), turning artificial intelligence and geopolitics more closer and challenging democracy and national security traditional models. AI-based technologies interact with peoples cognitive assumptions and provide any individual, group, organisation or nation-state to influence on public consciousness as a new kind of weapon in the global system. Research results look at how behavior, self-efficacy and privacy attitude are affected by culture compared to other psychological and demographics variables. It also examines what kind of data people tend to share online and how culture affects these choices. This study presents a multi-cultural view of MUAI for regional balance in Latin America, supports the idea of cultural competency as a mechanism of social influence and sets the distribution of power from the notion of security as a socio-cultural phenomenon. AI is highly likely to have different social impacts for region geopolitical balance depending on people cultural settings traced by customs, values and behaviours. This paper confirms that MUAI elevates threats to IPS to a qualitatively new level, which requires an adequate assessment and reaction from society. The comprehension of cross-cultural new threats of MUAI lead to formulate large-scale strategies to protect the sovereignty and enforce regional roles for building consensus, engagement and international collaboration, and forced experts to assume the ethic implications of surveillance, persuasion, and physical target identification for region balance. © ECIAIR 2020.All right reserved.},
	author_keywords = {Artificial intelligence; Big data; Cibersecurity; Culture; Political stability},
	keywords = {Agricultural robots; International cooperation; National security; Robotics; Uninterruptible power systems; Artificial intelligence technologies; Cultural competency; Cultural settings; International collaborations; Social applications; Target identification; Threats and vulnerabilities; Traditional models; Economic and social effects},
	editor = {Matos F.},
	publisher = {Academic Conferences International },
	isbn = {978-191276474-7},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. Impact Artif. Intell. Robot., ECIAIR},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2nd European Conference on the Impact of Artificial Intelligence and Robotics, ECIAIR 2020; Conference date: 22 October 2020 through 23 October 2020; Conference code: 165513}
}

@ARTICLE{Stark2019442,
	author = {Stark, Luke and Crawford, Kate},
	title = {The work of art in the age of artificial intelligence: What artists can teach us about the ethics of data practice},
	year = {2019},
	journal = {Surveillance and Society},
	volume = {17},
	number = {3-4},
	pages = {442 – 455},
	doi = {10.24908/ss.v17i3/4.10821},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073460912&doi=10.24908%2fss.v17i3%2f4.10821&partnerID=40&md5=abdbb1fee0745c133b55ef86349a7c79},
	affiliations = {Microsoft Research, Montreal, Canada; New York University, United States},
	abstract = {Problematic use of data, patterns of bias emerging in AI systems, and the role of platforms like Facebook and Twitter during elections have thrown the issue of data ethics into sharp relief. Yet the focus of conversations about data ethics has centered on computer scientists, engineers, and designers, with far less attention paid to the digital practices of artists and others in the cultural sector. Artists have historically deployed new technologies in unexpected and often prescient ways, making them a community able to speak directly to the changing and nuanced ethical questions faced by those who use data and machine learning systems. We conducted interviews with thirty-three artists working with digital data, with a focus on how artists prefigure and commonly challenge data practices and ethical concerns of computer scientists, researchers, and the wider population. We found artists were frequently working to produce a sense of defamiliarization and critical distance from contemporary digital technologies in their audiences. The ethics of using large-scale data and AI systems for these artists were generally developed in ongoing conversations with other practitioners in their communities and in relation to a longer history of art practice. © The author(s), 2019.},
	publisher = {Surveillance Studies Network},
	issn = {14777487},
	language = {English},
	abbrev_source_title = {Surveill. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access}
}

@ARTICLE{2019164,
	title = {Look out for potential bias in chemical data sets},
	year = {2019},
	journal = {Nature},
	volume = {573},
	number = {7773},
	pages = {164},
	doi = {10.1038/d41586-019-02670-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072113859&doi=10.1038%2fd41586-019-02670-w&partnerID=40&md5=5975701c7d5fc84c20449ff2af681205},
	abstract = {Materials science has embraced machine learning. As with other disciplines, researchers must be alert to the risks of biased data. [Figure not available: see fulltext.] © 2019, Nature.},
	author_keywords = {Chemistry; Ethics; Materials science; Research data},
	keywords = {Bias; Chemistry Techniques, Synthetic; Ethics, Research; editorial; ethics; machine learning; materials science; research ethics; statistical bias; synthesis},
	publisher = {Nature Research},
	issn = {00280836},
	coden = {NATUA},
	pmid = {31511688},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Singh20191259,
	author = {Singh, Ajay Vikram and Ansari, Mohammad Hasan Dad and Laux, Peter and Luch, Andreas},
	title = {Micro-nanorobots: important considerations when developing novel drug delivery platforms},
	year = {2019},
	journal = {Expert Opinion on Drug Delivery},
	volume = {16},
	number = {11},
	pages = {1259 – 1275},
	doi = {10.1080/17425247.2019.1676228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074119355&doi=10.1080%2f17425247.2019.1676228&partnerID=40&md5=e8590fdaf6723abc9ce84e0f76bce74e},
	affiliations = {Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; Department of Chemical and Product Safety, German Federal Institute for Risk Assessment (BfR), Berlin, Germany; The BioRobotics Institute, Scuola Superiore Sant’Anna Pisa, Pontedera, Italy; Institute of Pharmacy, Freie Universität Berlin, Berlin, Germany},
	abstract = {Introduction: There is growing emphasis on the development of bioinspired and biohybrid micro/nanorobots for the targeted drug delivery (TDD). Particularly, stimuli-responsive materials and magnetically triggered systems, identified as the most promising materials and design paradigms. Despite the advances made in fabrication and control, there remains a significant gap in clinical translation. Areas covered: This review discusses the opportunities and challenges about micro/nanorobotics for the TDD as evolutionary evidence in bio-nanotechnology, material science, biohybrid robotics, and many more. Important consideration in context with the material’s compatibility/immunogenicity, ethics, and security risk are reported based on the development in artificial intelligence (AI)/machine learning described in literature. The versatility and sophistication of biohybrid components design are being presented, highlighting stimuli-responsive biosystems as smart mechanisms and on-board sensing and control elements. Expert opinion: Focusing on key issues for high controllability at micro- and nano-scale systems in TDD, biohybrid integration strategies, and bioinspired key competences shall be adopted. The promising outlook portraying the commercialization potential and economic viability of micro/nanorobotics will benefit to clinical translation. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {biohybrid; drug delivery; MEMS/NEMS; Micro/nanorobots; microswimmer},
	keywords = {Drug Delivery Systems; Humans; Nanotechnology; Robotics; artificial intelligence; biocompatibility; biodegradability; drug delivery system; ethics; immunogenicity; machine learning; microrobot; nanobiotechnology; nanorobot; reproducibility; Review; robotics; socioeconomics; standardization; targeted drug delivery; human; nanotechnology},
	correspondence_address = {A.V. Singh; Physical Intelligence Department, Max Planck Institute for Intelligent Systems, Stuttgart, Germany; email: Ajay-Vikram.Singh@bfr.bund.de},
	publisher = {Taylor and Francis Ltd},
	issn = {17425247},
	pmid = {31580731},
	language = {English},
	abbrev_source_title = {Expert Opin. Drug Deliv.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 65}
}

@ARTICLE{Mei2019555,
	author = {Mei, Jie and Banneke, Stefanie and Lips, Janet and Kuffner, Melanie T.C. and Hoffmann, Christian J. and Dirnagl, Ulrich and Endres, Matthias and Harms, Christoph and Emmrich, Julius V.},
	title = {Refining humane endpoints in mouse models of disease by systematic review and machine learning-based endpoint definition},
	year = {2019},
	journal = {Altex},
	volume = {36},
	number = {4},
	pages = {555 – 571},
	doi = {10.14573/altex.1812231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074303802&doi=10.14573%2faltex.1812231&partnerID=40&md5=1b9d0f6b93cda53e7aeb5fe9ba198714},
	affiliations = {Department of Neurology, Department of Experimental Neurology, Neurocure Cluster of Excellence, Charité - Universitätsmedizin Berlin, Corporate Member of Freie Universität Berlin, Humboldt Universität zu Berlin, Berlin Institute of Health, Berlin, Germany; German Federal Institute for Risk Assessment, German Center for the Protection of Laboratory Animals (Bf3R), Berlin, Germany; QUEST - Center for Transforming Biomedical Research, Berlin Institute of Health (BIH), Germany; Center for Stroke Research, Charité - Universitätsmedizin Berlin, Berlin, Germany; Berlin-Brandenburg School for Regenerative Therapies (BSRT), Berlin, Germany; Berlin Institute of Health (BIH), Berlin, Germany; German Center for Neurodegenerative Diseases (DZNE), Berlin, Germany; German Center for Cardiovascular Research (DZHK), Berlin, Germany},
	abstract = {Ideally, humane endpoints allow early termination of experiments by minimizing an animal's discomfort, distress and pain while ensuring that scientific objectives are reached. Yet, lack of commonly agreed methodology and heterogeneity of cut-off values published in the literature remain a challenge to the accurate determination and application of humane endpoints. With the aim to synthesize and appraise existing humane endpoint definitions for commonly used physiological parameters, we conducted a systematic review of mouse studies of acute and chronic disease models that used body weight, temperature and/or sickness scores for endpoint definition. We searched for studies in two electronic databases (MEDLINE/Pubmed and Embase). Out of 110 retrieved full-text manuscripts, 34 studies were included. We found large intra- and inter-model variance in humane endpoint determination and application due to varying animal models, lack of standardized experimental protocols, and heterogeneity of performance metrics (part 1). We then used previously published and unpublished data on weight, temperature, and sickness scores from mouse models of sepsis and stroke and applied machine learning models to assess the usefulness of this method for parameter selection and endpoint definition across models. Machine learning models trained with physiological data and sickness severity score or modified DeSimoni neuroscore identified animals with a high risk of death at an early time point in both mouse models of stroke (male: 93.2% at 72 h post-treatment; female: 93.0% at 48 h post-treatment) and sepsis (96.2% at 24 h post-treatment), thus demonstrating generalizability of endpoint determination across models (part 2). © The Authors, 2019.},
	keywords = {Animal Welfare; Animals; Body Temperature; Body Weight; Disease Models, Animal; Ethical Review; Female; Male; Mice; Mice, Inbred C57BL; Mice, Knockout; Random Allocation; Sepsis; Severity of Illness Index; Stroke; Supervised Machine Learning; Systematic Reviews as Topic; Time Factors; animal welfare; apnea hypopnea index; Article; bioassay; body temperature; body weight; cerebrovascular accident; chronic disease; clinical outcome; comparative study; controlled study; decision tree; disease severity; emaciation; female; food intake; genotype; inflammation; machine learning; male; measurement accuracy; measurement precision; meta analysis; middle cerebral artery occlusion; modified DeSimoni neuroscore; mouse; nonhuman; occlusive cerebrovascular disease; physiological process; predictive value; sample size; support vector machine; systematic review; thermogenesis; threshold limit value; tumor growth; animal; animal welfare; C57BL mouse; disease model; ethics; knockout mouse; pathophysiology; randomization; sepsis; severity of illness index; supervised machine learning; time factor},
	correspondence_address = {J.V. Emmrich; Charité Universitätsmedizin Berlin, Department of Neurology, Department of Experimental Neurology, Berlin, Charitéplatz 1, 10117, Germany; email: julius.emmrich@charite.de; C. Harms; Center for Stroke Research, Department of Experimental Neurology, Berlin, Charitéplatz 1, 10117, Germany; email: christoph.harms@charite.de},
	publisher = {ALTEX Edition},
	issn = {1868596X},
	coden = {ALTEE},
	pmid = {31026040},
	language = {English},
	abbrev_source_title = {Altex},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sykora2020298,
	author = {Sykora, Martin and Elayan, Suzanne and Barbour, Nicole and Jackson, Tom},
	title = {A survey of the ethics of social media analytics},
	year = {2020},
	journal = {Proceedings of the 7th European Conference on Social Media, ECSM 2020},
	pages = {298 – 305},
	doi = {10.34190/ESM.20.047},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85097779059&doi=10.34190%2fESM.20.047&partnerID=40&md5=94bb102eac63bc3f933f0cb0f4d7d7a8},
	affiliations = {Centre for Information Management, Loughborough University, United Kingdom},
	abstract = {Following the Cambridge Analytica scandal and with the popularity and uptake of social media applications, computational machine learning and data mining approaches within big data analytics, there has been an increasing realisation that ethical issues are not always dealt with in appropriate and meaningful ways. Previous literature reports that the proportion of business ethics violations that occur through improper use of big data analytics, are as high as 50 percent. Unfortunately, the perceptions of average social media users around the ethics of potential invasiveness of social media analytics is fairly little understood. In this paper we conduct a study examining ethical expectations and perceptions of social media users, in relation to the increasing adoption of computational analytics systems on their social media generated datasets. The contribution of this paper is two-fold; first an extensive review of recent literature on codes of ethics, as well as expectations of privacy and questions of consent are presented. Second, a qualitatively driven survey of average social media users, assessing their awareness of social media analytics, is conducted in order to better understand how social media users perceive big data analytics as ethical, and what the related concerns are. This includes an in-depth focus group and an online survey of over 100 respondents, which were conducted on a UK based sample of participants. Our results reveal a variety of views, although interestingly it is found difficult to determine the depth of users understanding of what was being analysed from their social media profiles. Importantly, we find that respondents were broadly aware of data analysis occurring, however, users were unaware of the reasons as to why their data is analysed, by whom and for what specific purposes. This paper advances the dialogue between moral philosophy and the field of emerging information and communication technology of social media platforms. It will serve as a foundation for future research discussions around social media ethics and the desires of its users. © European Conference on Social Media, ECSM 2020.},
	author_keywords = {Big data; Ethics; Informed consent; Social media analytics},
	keywords = {Big data; Data Analytics; Data mining; Philosophical aspects; Social networking (online); Surveys; Analytics systems; Business ethics; Ethical issues; Information and Communication Technologies; Moral philosophy; Online surveys; Social media analytics; Social media platforms; Advanced Analytics},
	editor = {Karpasitis C. and Varda C.},
	publisher = {Academic Conferences International },
	isbn = {978-191276463-1},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. Soc. Media, ECSM},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 7th European Conference on Social Media, ECSM 2020; Conference date: 2 July 2020 through 3 July 2020; Conference code: 165515}
}

@ARTICLE{Takeda20191248,
	author = {Takeda, Mizuki and Hirata, Yasuhisa and Weng, Yueh-Hsuan and Katayama, Takahiro and Mizuta, Yasuhide and Koujina, Atsushi},
	title = {Accountable system design architecture for embodied AI: a focus on physical human support robots},
	year = {2019},
	journal = {Advanced Robotics},
	volume = {33},
	number = {23},
	pages = {1248 – 1263},
	doi = {10.1080/01691864.2019.1689168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075135772&doi=10.1080%2f01691864.2019.1689168&partnerID=40&md5=e5637d96b14fd3fe24033f8c367fa5f5},
	affiliations = {Department of Robotics, Tohoku University, Sendai, Japan; The Frontier Research Institute for Interdisciplinary Sciences, Tohoku University, Sendai, Japan; RT.WORKS CO., Ltd., Osaka, Japan},
	abstract = {Although the development of robot-based support systems for elderly people has become more popular, it is difficult for humans to understand the actions, plans, and behavior of autonomous robots and the reasons behind them, particularly when the robots include learning algorithms. Learning-based autonomous systems which are called AI are treated as an inherently untrustworthy ‘black box,’ because machine learning or deep learning algorithms are difficult for humans to understand. Robot systems such as assistive robots, which work closely with humans, however, should be trusted. Systems should therefore achieve accountability for all stakeholders. However, most research in this field has focused on particular systems and situations, and no general design architecture exists. In this study, we propose a new design method, focused on accountability and transparency, for learning-based robot systems. Describing the entire system is a necessary first step, and transcribing the described system for each stakeholder based on several principles is effective for achieving accountability. The method improves transparency for systems, including learning algorithms. A standing assistive robot is used as an example of the entire system to clarify which system parts require greater transparency. This study adopted the Systems Modeling Language (SysML) to describe the system and the described system is used for the information representation. Information should be represented considering the relationships between stakeholders, information, and the system interface. Because of their complexity, it is difficult for humans to understand the complete set of information available in robot systems. Systems should therefore present only the information required, depending on the situation. The stakeholder–interface relationship is also important because it is more beneficial for professionals to view information relevant to their specialized field, which would be difficult for others to understand. By contrast, the interface should be intuitive for general users. Visualization and sound are very useful means of transmitting information, with advantages and disadvantages for different circumstances. These relationships are important for achieving accountability. Finally, we show an example of implementation with a developed support system. It is confirmed that accountable systems can be designed based on the proposed design architecture. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group and The Robotics Society of Japan.},
	author_keywords = {black box; Health care management; physically assistive devices; robot ethics},
	keywords = {Deep learning; Machine design; Machine learning; Modeling languages; Robots; Transparency; Assistive devices; Black boxes; Design architecture; Health-care managements; Human support robot; Information representation; Robot ethics; Systems modeling languages; Learning algorithms},
	correspondence_address = {M. Takeda; Department of Robotics, Tohoku University, Sendai, 6-6-01 Aramaki-Aoba, Aoba-ku, 980-8579, Japan; email: m.takeda@srd.mech.tohoku.ac.jp},
	publisher = {Robotics Society of Japan},
	issn = {01691864},
	coden = {ADROE},
	language = {English},
	abbrev_source_title = {Adv .Rob.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Cahill2020313,
	author = {Cahill, Joan and Crowley, Katie and Cromie, Sam and Kay, Alison and Gormley, Michael and Kenny, Eamonn and Hermann, Sonja and Doyle, Ciaran and Hever, Ann and Ross, Robert},
	title = {Driver Persistence, Safety and Older Adult Self-efficacy: Addressing Driving Challenges Using Innovative Multimodal Communication Concepts},
	year = {2020},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {1205 AISC},
	pages = {313 – 319},
	doi = {10.1007/978-3-030-50838-8_43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85088244316&doi=10.1007%2f978-3-030-50838-8_43&partnerID=40&md5=1087183bfc664d109ea9e77c5d92683a},
	affiliations = {School of Psychology, Trinity College Dublin, College Green, Dublin 2, Ireland; Adapt Centre, Trinity College Dublin, College Green, Dublin 2, Ireland; Department of Physical Education and Sport Sciences, University College Limerick, Limerick, Ireland; The Irish Longitudinal Study on Ageing, Trinity College Dublin, College Green, Dublin 2, Ireland; School of Computing, Dublin Institute of Technology, College Green, Dublin 2, Ireland},
	abstract = {New assisted driving technology provides a solution to enabling driver persistence while also addressing older adult fitness to drive issues. The proposed driver assistance system follows a detailed literature review, an analysis of secondary data, and the specification of a solution using human machine interaction (HMI) design methods. Overall, the assisted driving concept follows from a principled/ethical perspective in relation to promoting self-efficacy and enablement for older adults. The system is conceptualized as a supportive friend or ‘co-pilot’. It is argued that the use of new car-based sensors, along with machine learning intelligence and novel multimodal HMI communication methods will enable driver persistence while also promoting older adult self-efficacy and positive ageing. © 2020, The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Active ageing; Adaption; Automated driving; Driver task; Ethics; Human factors; Older adult; Self-efficacy; User acceptability},
	keywords = {Artificial intelligence; Automobile drivers; Digital storage; Ergonomics; Health care; Assisted drivings; Communication method; Driver assistance system; Fitness to drives; Human-machine interaction; Literature reviews; Multimodal communications; Secondary datum; Automobile safety devices},
	correspondence_address = {J. Cahill; School of Psychology, Trinity College Dublin, Dublin 2, College Green, Ireland; email: Joan.Cahill@tcd.ie},
	editor = {Kalra J. and Lightner N.J.},
	publisher = {Springer},
	issn = {21945357},
	isbn = {978-303050837-1},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: AHFE Virtual Conference on Human Factors and Ergonomics in Healthcare and Medical Devices, and the International Conference on Human Factors in Aging and Special Needs, 2020; Conference date: 16 July 2020 through 20 July 2020; Conference code: 241759; All Open Access, Green Open Access}
}

@ARTICLE{Carroll20201,
	author = {Carroll, Stephanie Russo and Garba, Ibrahim and Figueroa-Rodríguez, Oscar L. and Holbrook, Jarita and Lovett, Raymond and Materechera, Simeon and Parsons, Mark and Raseroka, Kay and Rodriguez-Lonebear, Desi and Rowe, Robyn and Sara, Rodrigo and Walker, Jennifer D. and Anderson, Jane and Hudson, Maui},
	title = {The CARE principles for indigenous data governance},
	year = {2020},
	journal = {Data Science Journal},
	volume = {19},
	number = {1},
	pages = {1 – 12},
	doi = {10.5334/DSJ-2020-043},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85098057197&doi=10.5334%2fDSJ-2020-043&partnerID=40&md5=7dfc8612c5bb89d8465f40c0f1ac2b9f},
	affiliations = {University of Arizona, United States; COLPOS, Campus Montecillo, MX, United States; University of Western Cape, South Africa; Australian National University, Australia; North West University, South Africa; Rensselaer Polytechnic Institute, United States; Joint Minds Consult, Botswana; University of California, Los Angeles, United States; Laurentian University, Canada; One Planet Solutions, France; New York University, United States; University of Waikato, New Zealand},
	abstract = {Concerns about secondary use of data and limited opportunities for benefit-sharing have focused attention on the tension that Indigenous communities feel between (1) protecting Indigenous rights and interests in Indigenous data (including traditional knowledges) and (2) supporting open data, machine learning, broad data sharing, and big data initiatives. The International Indigenous Data Sovereignty Interest Group (within the Research Data Alliance) is a network of nation-state based Indigenous data sovereignty networks and individuals that developed the ‘CARE Principles for Indigenous Data Governance’ (Collective Benefit, Authority to Control, Responsibility, and Ethics) in consultation with Indigenous Peoples, scholars, non-profit organizations, and governments. The CARE Principles are people- and purpose-oriented, reflecting the crucial role of data in advancing innovation, governance, and self-determination among Indigenous Peoples. The Principles complement the existing data-centric approach represented in the ‘FAIR Guiding Principles for scientific data management and stewardship’ (Findable, Accessible, Interoperable, Reusable). The CARE Principles build upon earlier work by the Te Mana Raraunga Maori Data Sovereignty Network, US Indigenous Data Sovereignty Network, Maiam nayri Wingara Aboriginal and Torres Strait Islander Data Sovereignty Collective, and numerous Indigenous Peoples, nations, and communities. The goal is that stewards and other users of Indigenous data will ‘Be FAIR and CARE.' In this first formal publication of the CARE Principles, we articulate their rationale, describe their relation to the FAIR Principles, and present examples of their application. © 2020 The Author(s).},
	author_keywords = {Data governance; Data principles; Data sovereignty; FAIR principles; Indigenous},
	keywords = {Behavioral research; Computer software reusability; Information management; International law; Nonprofit organization; Open Data; Benefit sharing; Data governances; Data-centric approaches; Guiding principles; Indigenous community; Indigenous people; Non profit organizations; Scientific data management; Data Sharing},
	correspondence_address = {S.R. Carroll; University of Arizona, United States; email: stephaniecarroll@email.arizona.edu},
	publisher = {Ubiquity Press},
	issn = {16831470},
	language = {English},
	abbrev_source_title = {Data Sci. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 158; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Ossorio2020203,
	author = {Ossorio, Pilar N.},
	title = {The ethics of translating high-throughput science into clinical practice},
	year = {2020},
	journal = {The Ethical Challenges of Emerging Medical Technologies},
	pages = {203 – 204},
	doi = {10.4324/9781003074984-16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85096263668&doi=10.4324%2f9781003074984-16&partnerID=40&md5=707080243a7b14e378c60fe24c7bedd8},
	abstract = {Biomedical research is increasingly data intensive and computational, and “big data science” is migrating into the clinical arena. Teaching hospitals are making substantial investments in DNA sequencing capacity, and some now advertise their use of sequencing to help guide medical treatment. Institutional review boards (IRBs) and research ethicists need to understand and evaluate the analytical approaches used in big data research. Consider, for instance, the phenomenon of imputation, which involves computationally inferring missing data points. Novel programming approaches may challenge the Food and Drug Administration, IRBs, and ethicists. Machine learning adds layers of complexity to analytical processes and to the ethical and regulatory issues. In machine learning, the program, rather than the programmer, builds the predictive model. Computational scientists, ethicists, and regulators will need some agreement on how to validate these models and determine when they are robust enough to enter human trials. © 2017 Arthur L. Caplan and Brendan Parent; individual owners retain copyright in their own material.},
	publisher = {Taylor and Francis},
	isbn = {978-100010895-8; 978-147242915-5},
	language = {English},
	abbrev_source_title = {The Ethical Challenges of Emerg. Medical Technologies},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Asaro20201,
	author = {Asaro, Peter and Wallach, Wendell},
	title = {Introduction: The emergence of robot ethics and machine ethics},
	year = {2020},
	journal = {Machine Ethics and Robot Ethics},
	pages = {1 – 15},
	doi = {10.4324/9781003074991-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095922635&doi=10.4324%2f9781003074991-1&partnerID=40&md5=972219e2576e3a26e38943315187b612},
	affiliations = {New School for Public Engagement, United States; Yale University, United States},
	abstract = {Once the stuff of science fiction, recent progress in artificial intelligence, robotics, and machine learning has raised public concern and academic interest in the safety and ethics of the new tools and techniques emerging from these fields of research. The speculative worlds of science fiction have given rise to imaginative technologies, fueled consumer desires, and guided the design of real products suited for everyday life. Like most new fields of knowledge, machine ethics and robot ethics emerged from work in other disciplines. Questions that have become foundational for machine ethics and robot ethics began to intrigue scholars in the 1980s and 1990s. Robot ethics emerged out of the broader field of engineering ethics and its subfield computer ethics. The new field of research that is focused on the prospects for designing computer and robotic systems that demonstrate sensitivity to human values, and factor these into making decisions in morally significant situations, goes by various names. © 2017 Peter Asaro and Wendell Wallach.},
	publisher = {Taylor and Francis},
	isbn = {978-100010893-4; 978-147243039-7},
	language = {English},
	abbrev_source_title = {Machine Ethics and Robot Ethics},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Coleman20191397,
	author = {Coleman, C. Norman and Wendling, Eugenia Nina and Pistenmaa, David A.},
	title = {A Broad Impact for Global Oncology},
	year = {2019},
	journal = {JAMA Oncology},
	volume = {5},
	number = {10},
	pages = {1397 – 1398},
	doi = {10.1001/jamaoncol.2019.2387},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070554761&doi=10.1001%2fjamaoncol.2019.2387&partnerID=40&md5=f8cd6a9714b0b613d3a3a5602340ef99},
	affiliations = {International Cancer Expert Corps Inc, 1608 Rhode Island Ave, NW, Ste 243, Washington, 20036, DC, United States},
	keywords = {cancer survivor; death; follow up; funding; geography; geometry; global health; health care; health care need; health care policy; health program; low income country; machine learning; medical ethics; mentor; middle income country; Note; oncology; patient care; risk factor; sepsis; social conflict; sustainable development; technology; World Health Organization},
	correspondence_address = {C.N. Coleman; International Cancer Expert Corps Inc, Washington, 1608 Rhode Island Ave, NW, Ste 243, 20036, United States; email: norm.coleman@iceccancer.org},
	publisher = {American Medical Association},
	issn = {23742437},
	pmid = {31393528},
	language = {English},
	abbrev_source_title = {JAMA Oncol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Lam2019,
	author = {Lam, Alice D. and Cole, Andrew J. and Cash, Sydney S.},
	title = {New Approaches to Studying Silent Mesial Temporal Lobe Seizures in Alzheimer's Disease},
	year = {2019},
	journal = {Frontiers in Neurology},
	volume = {10},
	doi = {10.3389/fneur.2019.00959},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85072831481&doi=10.3389%2ffneur.2019.00959&partnerID=40&md5=9835ca148dd0eede777b89dfe1c48405},
	affiliations = {Massachusetts General Hospital, Department of Neurology, Boston, MA, United States; Harvard Medical School, Boston, MA, United States},
	abstract = {Silent seizures were discovered in mouse models of Alzheimer's disease over 10 years ago, yet it remains unclear whether these seizures are a salient feature of Alzheimer's disease in humans. Seizures that arise early in the course of Alzheimer's disease most likely originate from the mesial temporal lobe, one of the first structures affected by Alzheimer's disease pathology and one of the most epileptogenic regions of the brain. Several factors greatly limit our ability to identify mesial temporal lobe seizures in patients with Alzheimer's disease, however. First, mesial temporal lobe seizures can be difficult to recognize clinically, as their accompanying symptoms are often subtle or even non-existent. Second, electrical activity arising from the mesial temporal lobe is largely invisible on the scalp electroencephalogram (EEG), the mainstay of diagnosis for epilepsy in this population. In this review, we will describe two new approaches being used to study silent mesial temporal lobe seizures in Alzheimer's disease. We will first describe the methodology and application of foramen ovale electrodes, which captured the first recordings of silent mesial temporal lobe seizures in humans with Alzheimer's disease. We will then describe machine learning approaches being developed to non-invasively identify silent mesial temporal lobe seizures on scalp EEG. Both of these tools have the potential to elucidate the role of silent seizures in humans with Alzheimer's disease, which could have important implications for early diagnosis, prognostication, and development of targeted therapies for this population. © Copyright © 2019 Lam, Cole and Cash.},
	author_keywords = {Alzheimer; epilepsy; foramen ovale electrode; machine learning; temporal lobe},
	keywords = {Alzheimer disease; artificial intelligence; cognitive defect; comorbidity; delirium; dementia; disease exacerbation; disease severity; early diagnosis; electroencephalography; functional magnetic resonance imaging; general anesthesia; high risk patient; human; intermethod comparison; machine learning; medical ethics; mesial temporal lobe epilepsy; mild cognitive impairment; non invasive procedure; nonREM sleep; patient selection; personalized medicine; prognostic assessment; Review; scalp; sphenoidal electrode},
	correspondence_address = {A.D. Lam; Massachusetts General Hospital, Department of Neurology, Boston, United States; email: lam.alice@mgh.harvard.edu},
	publisher = {Frontiers Media S.A.},
	issn = {16642295},
	language = {English},
	abbrev_source_title = {Front. Neurol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Fernández-Martínez2020199,
	author = {Fernández-Martínez, Carmen and Fernández, Alberto},
	title = {AI and recruiting software: Ethical and legal implications},
	year = {2020},
	journal = {Paladyn},
	volume = {11},
	number = {1},
	pages = {199 – 216},
	doi = {10.1515/pjbr-2020-0030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85086574661&doi=10.1515%2fpjbr-2020-0030&partnerID=40&md5=b62d0f2cab3c8db247698263b5a2674d},
	affiliations = {CETINIA, University Rey Juan Carlos, Madrid, Spain},
	abstract = {In this article, we examine the state-of-the-art and current applications of artificial intelligence (AI), specifically for human resources (HR). We study whether, due to the experimental state of the algorithms used and the nature of training and test samples, a further control and auditing in the research community is necessary to guarantee fair and accurate results. In particular, we identify the positive and negative consequences of the usage of video-interview analysis via AI in recruiting processes as well as the main machine learning techniques used and their degrees of efficiency. We focus on some controversial characteristics that could lead to ethical and legal consequences for candidates, companies and states regarding discrimination in the job market (e.g. gender and race). There is a lack of regulation and a need for external and neutral auditing for the type of analyses done in interviews. We present a multi-agent architecture that aims at total legal compliance and more effective HR processes management. © 2020 Carmen Fernández-Martínez and Alberto Fernández, published by De Gruyter 2020.},
	author_keywords = {domain-specific AI; ethics; human resources; recruiting},
	keywords = {Ethical technology; Learning systems; Multi agent systems; 'current; Domain specific; Domain-specific artificial intelligence; Ethical implications; Legal implications; Recruiting; Research communities; State of the art; Test samples; Training sample; Personnel},
	correspondence_address = {C. Fernández-Martínez; CETINIA, University Rey Juan Carlos, Madrid, Spain; email: carmen.urjc@gmail.com},
	publisher = {De Gruyter Open Ltd},
	issn = {20814836},
	language = {English},
	abbrev_source_title = {Paladyn},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Gold Open Access}
}

@ARTICLE{Khan202027,
	author = {Khan, Yunus and Varma, Sunita},
	title = {Development and Design Strategies of Evidence Collection Framework in Cloud Environment},
	year = {2020},
	journal = {Lecture Notes in Networks and Systems},
	volume = {100},
	pages = {27 – 37},
	doi = {10.1007/978-981-15-2071-6_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083957275&doi=10.1007%2f978-981-15-2071-6_3&partnerID=40&md5=cf91615224f575ac278542c0cf0e7a25},
	affiliations = {Shri Govindram Seksaria Institute of Technology and Science, Indore, Madhya Pradesh, India},
	abstract = {Nowadays, cloud computing is one of the popular and widely used concepts in information technology paradigm. It is committed to improving the IT business technically and economically. On the other hand, digital forensic is the process of collection, identification, preservation, examination, and analysis of data or information for the proof in the court of law as an evidence. It is very difficult and challenging to apply digital forensic operation in a cloud environment because CSPs are dependent on each other either they provide IaaS, PaaS, or SaaS. So the cloud forensic, one of the applications of digital forensic in a cloud environment, is just a subset of network forensic. It is a cross-field of digital forensic and cloud computing. In this paper, we investigate all the research issues, problems, and implementation ethics of cloud forensic from the initial level. We found that lots of issues and challenges are remaining to address in this domain. Some major research domains are architectures, data collection and analysis, anti-forensic, incident first responders, roles and responsibilities, legal, standards, and some learning issues. In our research work, we mainly focus on the data collection and cloud forensic architectures and also implement a cloud forensic framework in the context of cloud service models. This research work is tested using different private cloud solutions such as eucalyptus, OpenNebula, VMware, vCloud, and Hadoop platform. In our research work, we implement pattern search facility using the proposed approach in open-source software called digital forensic framework. We also implement in near future digital forensic triage using Amazon Elastic MapReduce. In this research, we also implement designed and development of forensic method for the PaaS and SaaS delivery models of cloud computing, also apply machine learning principles to design and develop new digital forensic methods, and improve the efficiency of investigation using machine learning algorithms for feature extraction and priority of evidence classification of evidence in virtual machines. © Springer Nature Singapore Pte Ltd. 2020.},
	author_keywords = {Data collection; Dependency chains; Digital forensic; Evidence segregation; IaaS; IDS; Multiple jurisdictions and tenancy; PaaS; SaaS; SLA; Virtual environment; VMware},
	correspondence_address = {S. Varma; Shri Govindram Seksaria Institute of Technology and Science, Indore, India; email: sunita.varma19@gmail.com},
	publisher = {Springer},
	issn = {23673370},
	language = {English},
	abbrev_source_title = {Lect. Notes Networks Syst.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@BOOK{Wallach20201,
	author = {Wallach, Wendell and Asaro, Peter M.},
	title = {Machine ethics and robot ethics},
	year = {2020},
	journal = {Machine Ethics and Robot Ethics},
	pages = {1 – 551},
	doi = {10.4324/9781003074991},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85095927001&doi=10.4324%2f9781003074991&partnerID=40&md5=255b9623cc72f244af79b9632db967fc},
	affiliations = {Yale University, United States; New School for Public Engagement, United States},
	abstract = {Once the stuff of science fiction, recent progress in artificial intelligence, robotics, and machine learning means that these rapidly advancing technologies are finally coming into widespread use within everyday life. Such rapid development in these areas also brings with it a host of social, political and legal issues, as well as a rise in public concern and academic interest in the ethical challenges these new technologies pose. This volume is a collection of scholarly work from leading figures in the development of both robot ethics and machine ethics; it includes essays of historical significance which have become foundational for research in these two new areas of study, as well as important recent articles. The research articles selected focus on the control and governance of computational systems; the exploration of ethical and moral theories using software and robots as laboratories or simulations; inquiry into the necessary requirements for moral agency and the basis and boundaries of rights; and questions of how best to design systems that are both useful and morally sound. Collectively the articles ask what the practical ethical and legal issues, arising from the development of robots, will be over the next twenty years and how best to address these future considerations. © 2017 Wendell Wallach and Peter Asaro.},
	publisher = {Taylor and Francis},
	isbn = {978-100010893-4; 978-147243039-7},
	language = {English},
	abbrev_source_title = {Machine Ethics and Robot Ethics},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Fleischmann2019461,
	author = {Fleischmann, Kenneth R. and Greenberg, Sherri R. and Gurari, Danna and Stangl, Abigale and Verma, Nitin and Day, Jaxsen R. and Simons, Rachel N. and Yeh, Tom},
	title = {Good systems: Ethical AI for CSCW},
	year = {2019},
	journal = {Proceedings of the ACM Conference on Computer Supported Cooperative Work, CSCW},
	pages = {461 – 467},
	doi = {10.1145/3311957.33594367},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076119218&doi=10.1145%2f3311957.33594367&partnerID=40&md5=f2c5f47070128907a27b2401e8367616},
	affiliations = {University of Texas at Austin, Austin, 78701, TX, United States; Texas Woman's University, Denton, 76204, TX, United States; University of Colorado Boulder, Boulder, 80309, CO, United States},
	abstract = {Artificial intelligence is revolutionizing work, including what it means for cooperative work to be supported by computers. The increased use of AI in CSCW can lead to many advantages, including increased productivity and efficiency, but it can also include several potential ethical trade-offs, such as invasions of privacy, loss of autonomy, and job displacement. This workshop will explore the ethical dimensions of AI in CSCW, building on Good Systems, a UT Grand Challenge. Specifically, the first half of the workshop will focus on the need to design AI to work for all users and to avoid bias through the use of universal design as well as the need for AI and CSCW researchers to interact with policy and legal experts to work together to ensure that AI will be developed in an ethical manner with sufficient consideration of its societal implications, and also that AI will be regulated and legislated in ways that will maximize its benefits to all people. © 2019 Copyright is held by the author/owner(s).},
	author_keywords = {Artificial intelligence; Automation; Ethics; Human values; Machine learning; Policy; Universal design; Work},
	keywords = {Artificial intelligence; Automation; Design; Economic and social effects; Interactive computer systems; Learning systems; Philosophical aspects; Public policy; Cooperative works; Ethics; Human values; Increased productivity; Job displacement; Societal implications; Universal Design; Work; Groupware},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036692-2},
	language = {English},
	abbrev_source_title = {Proc. ACM Conf. Comput. Support. Coop. Work CSCW},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 22nd ACM Conference on Computer-Supported Cooperative Work and Social Computing, CSCW 2019; Conference date: 9 November 2019 through 13 November 2019; Conference code: 155036}
}

@ARTICLE{Keskinbora202037,
	author = {Keskinbora, Kadircan and Güven, Fatih},
	title = {Artificial intelligence and ophthalmology},
	year = {2020},
	journal = {Turkish Journal of Ophthalmology},
	volume = {50},
	number = {1},
	pages = {37 – 43},
	doi = {10.4274/tjo.galenos.2020.78989},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081890303&doi=10.4274%2ftjo.galenos.2020.78989&partnerID=40&md5=da1d01519662fc01a465c4d38d70168e},
	affiliations = {Bahçeşehir University, Department of Ophthalmology, Division of Medical Ethics and History of Medicine, İstanbul, Turkey; Health Sciences University, Bakırköy Training and Research Hospital, Clinic of Ophthalmology, İstanbul, Turkey},
	abstract = {Artificial intelligence is advancing rapidly and making its way into all areas of our lives. This review discusses developments and potential practices regarding the use of artificial intelligence in the field of ophthalmology, and the related topic of medical ethics. Various artificial intelligence applications related to the diagnosis of eye diseases were researched in books, journals, search engines, print and social media. Resources were cross-checked to verify the information. Artificial intelligence algorithms, some of which were approved by the US Food and Drug Administration, have been adopted in the field of ophthalmology, especially in diagnostic studies. Studies are being conducted that prove that artificial intelligence algorithms can be used in the field of ophthalmology, especially in diabetic retinopathy, age-related macular degeneration, and retinopathy of prematurity. Some of these algorithms have come to the approval stage. The current point in artificial intelligence studies shows that this technology has advanced considerably and shows promise for future work. It is believed that artificial intelligence applications will be effective in identifying patients with preventable vision loss and directing them to physicians, especially in developing countries where there are fewer trained professionals and physicians are difficult to reach. When we consider the possibility that some future artificial intelligence systems may be candidates for moral/ethical status, certain ethical issues arise. Questions about moral/ethical status are important in some areas of applied ethics. Although it is accepted that current intelligence systems do not have moral/ethical status, it has yet to be determined what the exact the characteristics that confer moral/ethical status are or will be. © 2020 by Turkish Ophthalmological Association Turkish Journal of Ophthalmology, published by Galenos Publishing House.},
	author_keywords = {Artificial intelligence; Deep learning; Machine learning; Medical ethics; Ophthalmology},
	keywords = {Algorithms; Artificial Intelligence; Deep Learning; Humans; Ophthalmology; age related macular degeneration; artificial intelligence; cognition; deep learning; diabetic retinopathy; glaucoma; human; keratoconus; learning algorithm; machine learning; medical ethics; nonhuman; ophthalmology; optical coherence tomography; peripheral occlusive artery disease; retinitis pigmentosa; retrolental fibroplasia; Review; sensitivity and specificity; spectral domain optical coherence tomography; thorax radiography; tuberculosis; visual acuity; visual impairment; algorithm; ophthalmology; procedures},
	correspondence_address = {K. Keskinbora; Bahçeşehir University, Department of Ophthalmology, Division of Medical Ethics and History of Medicine, İstanbul, Turkey; email: kadircan.keskinbora@gmail.com},
	publisher = {Turkish Ophthalmology Society},
	issn = {21498709},
	pmid = {32167262},
	language = {English},
	abbrev_source_title = {Turk. Jour. of Ophthalmol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Wiens20191337,
	author = {Wiens, Jenna and Saria, Suchi and Sendak, Mark and Ghassemi, Marzyeh and Liu, Vincent X. and Doshi-Velez, Finale and Jung, Kenneth and Heller, Katherine and Kale, David and Saeed, Mohammed and Ossorio, Pilar N. and Thadaney-Israni, Sonoo and Goldenberg, Anna},
	title = {Do no harm: a roadmap for responsible machine learning for health care},
	year = {2019},
	journal = {Nature Medicine},
	volume = {25},
	number = {9},
	pages = {1337 – 1340},
	doi = {10.1038/s41591-019-0548-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071331458&doi=10.1038%2fs41591-019-0548-6&partnerID=40&md5=2296b1d581d63a9e9a94df564c2b4ffb},
	affiliations = {Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, MI, United States; Departments of Computer Science and Statistics, Whiting School of Engineering, Johns Hopkins University, Baltimore, MD, United States; Department of Health Policy and Management, Bloomberg School of Public Health, Johns Hopkins University, Baltimore, MD, United States; Bayesian Health, New York, NY, United States; Duke Institute for Health Innovation, Duke University School of Medicine, Durham, NC, United States; Department of Computer Science, University of Toronto, Toronto, ON, Canada; Department of Medicine, University of Toronto, Toronto, ON, Canada; Vector Institute, Toronto, ON, Canada; Kaiser Permanente Division of Research, Oakland, CA, United States; School of Engineering and Applied Science, Harvard University, Cambridge, MA, United States; Center for Biomedical Informatics Research, Stanford University, Stanford, CA, United States; Google Inc., Mountain View, CA, United States; Department of Statistical Science, Duke University, Durham, NC, United States; Information Sciences Institute, University of Southern California, Los Angeles, CA, United States; Department of Internal Medicine, University of Michigan, Ann Arbor, MI, United States; Law School, University of Wisconsin–Madison, Madison, WI, United States; Presence and Program in Bedside Medicine, Stanford University School of Medicine, Stanford, CA, United States; SickKids Research Institute, Toronto, ON, Canada},
	abstract = {Interest in machine-learning applications within medicine has been growing, but few studies have progressed to deployment in patient care. We present a framework, context and ultimately guidelines for accelerating the translation of machine-learning-based interventions in health care. To be successful, translation will require a team of engaged stakeholders and a systematic process from beginning (problem formulation) to end (widespread deployment). © 2019, Springer Nature America, Inc.},
	keywords = {Clinical Decision-Making; Delivery of Health Care; Humans; Machine Learning; adult; article; human; machine learning; patient care; practice guideline; clinical decision making; ethics; health care delivery; machine learning},
	correspondence_address = {J. Wiens; Department of Electrical Engineering and Computer Science, University of Michigan, Ann Arbor, United States; email: wiensj@umich.edu},
	publisher = {Nature Publishing Group},
	issn = {10788956},
	coden = {NAMEF},
	pmid = {31537911},
	language = {English},
	abbrev_source_title = {Nat. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 311}
}

@ARTICLE{Cheng2019,
	author = {Cheng, Dan and Liu, Dianbo and Philpotts, Lisa Liang and Turner, Dana P. and Houle, Timothy T. and Chen, Lucy and Zhang, Miaomiao and Yang, Jianjun and Zhang, Wei and Deng, Hao},
	title = {Current state of science in machine learning methods for automatic infant pain evaluation using facial expression information: Study protocol of a systematic review and meta-analysis},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {12},
	doi = {10.1136/bmjopen-2019-030482},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076439172&doi=10.1136%2fbmjopen-2019-030482&partnerID=40&md5=2adb0c2badb92acf9afe15cddf77c8af},
	affiliations = {Department of Anesthesiology Pain and Perioperative Medicine, First Affiliated Hospital of Zhengzhou University, Zhengzhou, Henan, China; Department of Anesthesia Critical Care and Pain Medicine, Massachusetts General Hospital, Boston, MA, United States; Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute of Technology, Cambridge, MA, United States; Treadwell Library, Massachusetts General Hospital, Boston, MA, United States; Department of Engineering, University of Virginia, Charlottesville, VA, United States; DRPH Program, Johns Hopkins University Bloomberg School of Public Health, Baltimore, MD, United States},
	abstract = {Introduction Infants can experience pain similar to adults, and improperly controlled pain stimuli could have a long-term adverse impact on their cognitive and neurological function development. The biggest challenge of achieving good infant pain control is obtaining objective pain assessment when direct communication is lacking. For years, computer scientists have developed many different facial expression-centred machine learning (ML) methods for automatic infant pain assessment. Many of these ML algorithms showed rather satisfactory performance and have demonstrated good potential to be further enhanced for implementation in real-world clinical settings. To date, there is no prior research that has systematically summarised and compared the performance of these ML algorithms. Our proposed meta-analysis will provide the first comprehensive evidence on this topic to guide further ML algorithm development and clinical implementation. Methods and analysis We will search four major public electronic medical and computer science databases including Web of Science, PubMed, Embase and IEEE Xplore Digital Library from January 2008 to present. All the articles will be imported into the Covidence platform for study eligibility screening and inclusion. Study-level extracted data will be stored in the Systematic Review Data Repository online platform. The primary outcome will be the prediction accuracy of the ML model. The secondary outcomes will be model utility measures including generalisability, interpretability and computational efficiency. All extracted outcome data will be imported into RevMan V.5.2.1 software and R V3.3.2 for analysis. Risk of bias will be summarised using the latest Prediction Model Study Risk of Bias Assessment Tool. Ethics and dissemination This systematic review and meta-analysis will only use study-level data from public databases, thus formal ethical approval is not required. The results will be disseminated in the form of an official publication in a peer-reviewed journal and/or presentation at relevant conferences. PROSPERO registration number CRD42019118784. © 2019 Author(s) (or their employer(s)). Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {artificial intelligence; facial expression; infant; machine learning; pain},
	keywords = {Facial Expression; Humans; Infant; Machine Learning; Meta-Analysis as Topic; Pain Measurement; Research Design; Systematic Reviews as Topic; algorithm; artificial intelligence; Embase; facial expression; female; human; human experiment; infant; machine learning; male; Medline; meta analysis; outcome assessment; pain measurement; prediction; review; risk assessment; software; systematic review; Web of Science; meta analysis (topic); methodology; pain measurement; procedures},
	correspondence_address = {H. Deng; Department of Anesthesia Critical Care and Pain Medicine, Massachusetts General Hospital, Boston, United States; email: hdeng1@mgh.harvard.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31831532},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sathiyanarayanan2019142,
	author = {Sathiyanarayanan, Mithileysh and Sokkanarayanan, Sumathi},
	title = {Understanding the Emergence and Importance of Blockchain-based Cyber-physical Social Machines: A Proposal},
	year = {2019},
	journal = {Proceedings of the 4th International Conference on Contemporary Computing and Informatics, IC3I 2019},
	pages = {142 – 147},
	doi = {10.1109/IC3I46837.2019.9055513},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083575261&doi=10.1109%2fIC3I46837.2019.9055513&partnerID=40&md5=ab6f4018e681b5d8c900d073cd11cf19},
	affiliations = {Srishti i2i Biz Solutions TalentBiz, Research Development, London, United Kingdom; Sri Sairam Engineering College, Department of Electronics and Communication Engineering, Chennai, India},
	abstract = {Cyber-physical Social Machines (CPSM) is a new socio-Technical system, which has a dynamic network of various devices connected together through sensors and communicating devices embedded in them making humans interact using the networked digital technology through web applications. The main aim of the project is to understand the dynamics, emergence and importance of cyber-physical social machines (CPSMs) in terms of characterising emergent behaviours and analysing threats such as privacy, security, ethics, trust, reliability, usability, accessibility and acceptability by developing a decision-making framework. Though there are many advantages and benefits using CPSM there are several issues and challenges associated with them as well. We aim to identify all the threats, issues and challenges faced by the consumers in the CPSM and discuss the potential use of blockchain based solutions to overcome these threats, issues and challenges. © 2019 IEEE.},
	author_keywords = {acceptability; artificial intelligence; big data; blockchain; data analytics; ethics; human data interaction; human factors; human-computer interaction; Internet of Things (IoT); machine learning; privacy; provenance; reliability; security; trust; web science},
	keywords = {Blockchain; Decision making; Digital devices; Cyber physicals; Decision-making frameworks; Digital technologies; Dynamic network; Emergent behaviours; Issues and challenges; Sociotechnical systems; WEB application; Cyber Physical System},
	editor = {Rana A. and Khurana H.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172815529-6},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Contemp. Comput. Inf., IC3I},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 4th International Conference on Contemporary Computing and Informatics, IC3I 2019; Conference date: 12 December 2019 through 14 December 2019; Conference code: 159023}
}

@CONFERENCE{Greiman2020621,
	author = {Greiman, Virginia A.},
	title = {Artificial intelligence in megaprojects: The next frontier},
	year = {2020},
	journal = {European Conference on Information Warfare and Security, ECCWS},
	volume = {2020-June},
	pages = {621 – 628},
	doi = {10.34190/EWS.20.123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85094682693&doi=10.34190%2fEWS.20.123&partnerID=40&md5=152fff437d7b2bd4b8c3c74689260780},
	affiliations = {Boston University, Boston, MA, United States},
	abstract = {Megaprojects are continuing to capture worldwide attention from India’s Smart Cities, to the $4.75 billion Hadron Collider at CERN, to the US $150 billion International Space Station, and Europe’s largest railway infrastructure project, Crossrail in London. The Organization for Economic Cooperation and Development (OECD) estimates global investment needs of $6.3 trillion per year from 2016-2030 (Mirabile, et al. 2017). To meet this growing demand, there has been a recent call, within the megaproject scholarship, for a better understanding of “what goes on in megaprojects – how they are managed and organized, from within, by the managers who are tasked with bringing them to fruition.” (Söderlund, et al. 2017). Studies about megaprojects have generally concentrated on the cost conflicts between the stakeholders and cost overrun issues (Adam et al., 2014; Flyvbjerg, 2017), however these have been superseded by more important issues in recent years such as project security, protecting the health and safety of its workers, project sustainability and value creation, and managing the impact of climate change and presently a global pandemic. All of these require a more agile approach to project management and a more sophisticated intelligence that can be generated through Algorithms that are used to generate artificially intelligent systems. Through an analysis of the AI and Project Management literature, ethnographic studies, and semi-structured interviews with project management professionals, this paper explores the growing use of Artificial Intelligence to manage megaprojects including the obligations of private industry, and the government as the guardian of the public interest, while at the same time exploring the technical, managerial and ethical considerations in the deployment of AI. © 2020 Curran Associates Inc.. All rights reserved.},
	author_keywords = {Algorithms; Artificial Intelligence; Ethics; Machine Learning; Megaprojects},
	keywords = {Climate change; Intelligent systems; Investments; Machine learning; Philosophical aspects; Project management; Railroad transportation; Space stations; Global investments; Growing demand; Hadron colliders; Infrastructure project; International Space stations; Machine-learning; Mega projects; Megaprojects; Organization for economic co-operation and development; Railway infrastructure; Managers},
	correspondence_address = {V.A. Greiman; Boston University, Boston, United States; email: ggreiman@bu.edu},
	editor = {Eze T. and Speakman L. and Onwubiko C.},
	publisher = {Curran Associates Inc.},
	issn = {20488602},
	isbn = {978-191276461-7},
	language = {English},
	abbrev_source_title = {European Conf. Inf. Warfare Security, ECCWS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 19th European Conference on Cyber Warfare and Security, ECCWS 2020; Conference date: 25 June 2020 through 26 June 2020; Conference code: 163901}
}

@ARTICLE{West20201,
	author = {West, Ruth and Burbano, Andrés},
	title = {Ai, arts & design: Questioning learning machines; [Ia, arte y diseño: Cuestionando el aprendizaje automático]},
	year = {2020},
	journal = {Artnodes},
	volume = {2020},
	number = {26},
	pages = {1 – 9},
	doi = {10.7238/a.v0i26.3368},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85090712904&doi=10.7238%2fa.v0i26.3368&partnerID=40&md5=5de823879fb91193dd70811adcdec793},
	affiliations = {xREZ Art + Science Lab-University of North Texas, United States; Leonardo/The International Society of Art, Science and Technology, Italy; School of Architecture and Design-Universidad de los Andes, Colombia; LEAF International Liaison, Leonardo/The International Society of Art, Science and Technology, Italy},
	abstract = {Explorations of the relationship between Artificial Intelligence (AI), the arts, and design have existed throughout the historical development of AI. We are currently witnessing exponential growth in the application of Machine Learning (ML) and AI in all domains of art (visual, sonic, performing, spatial, transmedia, audiovisual, and narrative) in parallel with activity in the field that is so rapid that publication can not keep pace. In dialogue with our contemplation about this development in the arts, authors in this issue answer with questions of their own. Through questioning authorship and ethics, autonomy and automation, exploring the contribution of art to AI, algorithmic bias, control structures, machine intelligence in public art, formalization of aesthetics, the production of culture, socio-technical dimensions, relationships to games and aesthetics, and democratization of machine-based creative tools the contributors provide a multifaceted view into crucial dimensions of the present and future of creative AI. In this Artnodes special issue, we pose the question: Does generative and machine creativity in the arts and design represent an evolution of “artistic intelligence,” or is it a metamorphosis of creative practice yielding fundamentally distinct forms and modes of authorship?. © 2020, Ruth West Andrés Burbano.},
	author_keywords = {Artificial intelligence; Arts; Design; Machine learning: AI; ML},
	publisher = {Universitat Oberta de Catalunya},
	issn = {16955951},
	language = {English},
	abbrev_source_title = {Artnodes},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Minssen2020,
	author = {Minssen, Timo and Gerke, Sara and Aboy, Mateo and Price, Nicholson and Cohen, Glenn},
	title = {Regulatory responses to medical machine learning},
	year = {2020},
	journal = {Journal of Law and the Biosciences},
	volume = {7},
	number = {1},
	doi = {10.1093/jlb/lsaa002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087057978&doi=10.1093%2fjlb%2flsaa002&partnerID=40&md5=b42a9cb0eb3b17bc94dafbc2c9fdbaac},
	affiliations = {Centre for Advanced Studies in Biomedical Innovation Law, Copenhagen, Denmark; Petrie-Flom Center for Health Law Policy, Biotechnology, and Bioethics, Harvard Law School, Cambridge, United States; Centre for Law, Medicine, and Life Sciences (LML), Faculty of Law, University of Cambridge, Cambridge, United Kingdom; University of Michigan Law School, Ann Arbor, MI, United States; Harvard Law School and Petrie-Flom Center for Health Law Policy, Biotechnology, and Bioethics, Harvard Law School, Cambridge, United States},
	abstract = {Companies and healthcare providers are developing and implementing new applications of medical artificial intelligence, including the artificial intelligence sub-type of medical machine learning (MML). MML is based on the application of machine learning (ML) algorithms to automatically identify patterns and act on medical data to guide clinical decisions. MML poses challenges and raises important questions, including (1) How will regulators evaluate MML-based medical devices to ensure their safety and effectiveness? and (2) What additional MML considerations should be taken into account in the international context? To address these questions, we analyze the current regulatory approaches to MML in the USA and Europe. We then examine international perspectives and broader implications, discussing considerations such as data privacy, exportation, explanation, training set bias, contextual bias, and trade secrecy.  © 2020 The Author(s) 2020. Published by Oxford University Press on behalf of Duke University School of Law, Harvard Law School, Oxford University Press, and Stanford Law School.},
	author_keywords = {artificial intelligence; ethics; medical devices; medical machine learning; regulation},
	correspondence_address = {T. Minssen; Centre for Advanced Studies in Biomedical Innovation Law, Copenhagen, Denmark; email: Timo.Minssen@jur.ku.dk},
	publisher = {Oxford University Press},
	issn = {20539711},
	language = {English},
	abbrev_source_title = {J.  Law  Biosci.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 37; All Open Access, Gold Open Access, Green Open Access}
}@ARTICLE{Casacuberta2019313,
	author = {Casacuberta, David and Guersenzvaig, Ariel},
	title = {Using Dreyfus’ legacy to understand justice in algorithm-based processes},
	year = {2019},
	journal = {AI and Society},
	volume = {34},
	number = {2},
	pages = {313 – 319},
	doi = {10.1007/s00146-018-0803-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040862791&doi=10.1007%2fs00146-018-0803-2&partnerID=40&md5=c4a1a1edd9b9a4cf12b7f4ad9003884d},
	affiliations = {Philosophy Department, Universitat Autònoma de Barcelona, Barcelona, Spain; ELISAVA, Barcelona School of Design and Engineering, Barcelona, Spain},
	abstract = {As AI is linked to more and more aspects of our lives, the need for algorithms that can take decisions that are not only accurate but also fair becomes apparent. It can be seen both in discussions of future trends such as autonomous vehicles or the issue of superintelligence, as well as actual implementations of machine learning used to decide whether a person should be admitted in certain university or will be able to return a credit. In this paper, we will use Dreyfus’ account on ethical expertise to show that, to give an AI some ability to make ethical judgements, a pure symbolic, conceptual approach is not enough. We also need the ability to make sense of the surroundings to reframe and define situations in a dynamic way, using multiple perspectives in a pre-reflective way. © 2018, Springer-Verlag London Ltd., part of Springer Nature.},
	author_keywords = {Algorithmic biases; Autonomous driving; Autopoiesis; Computer ethics; Dreyfus; Expertise; Prereflective knowledge},
	keywords = {Learning systems; Algorithmic biases; Auto-poiesis; Autonomous driving; Computer ethics; Dreyfus; Expertise; Prereflective knowledge; Philosophical aspects},
	correspondence_address = {D. Casacuberta; Philosophy Department, Universitat Autònoma de Barcelona, Barcelona, Spain; email: david.casacuberta@uab.cat},
	publisher = {Springer London},
	issn = {09515666},
	language = {English},
	abbrev_source_title = {AI Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Connolly2019,
	author = {Connolly, John F. and Reilly, James P. and Fox-Robichaud, Alison and Britz, Patrick and Blain-Moraes, Stefanie and Sonnadara, Ranil and Hamielec, Cindy and Herrera-Díaz, Adianes and Boshra, Rober},
	title = {Development of a point of care system for automated coma prognosis: A prospective cohort study protocol},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {7},
	doi = {10.1136/bmjopen-2019-029621},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069532029&doi=10.1136%2fbmjopen-2019-029621&partnerID=40&md5=24d226aab73ba83aaef91a5200488bd3},
	affiliations = {School of Biomedical Engineering, McMaster University, Hamilton, ON, Canada; Vector Institute, MaRS Discovery District, ON, Canada; Department of Psychology Neuroscience and Behaviour, McMaster University, Hamilton, ON, Canada; ARiEAL Research Centre, McMaster University, Hamilton, ON, Canada; Department of Linguistics and Languages, McMaster University, Hamilton, ON, Canada; Neuroscience Graduate Program, McMaster University, Hamilton, ON, Canada; Department of Electrical and Computer Engineering, McMaster University, Hamilton, ON, Canada; Department of Medicine, McMaster University, Hamilton, ON, Canada; Critical Care Medicine, Hamilton Health Sciences, ON, Canada; Brain Vision Solutions, Montreal, QC, Canada; School of Physical and Occupational Therapy, McGill University, Montreal, QC, Canada; Department of Surgery, McMaster University, Hamilton, ON, Canada},
	abstract = {Introduction Coma is a deep state of unconsciousness that can be caused by a variety of clinical conditions. Traditional tests for coma outcome prediction are based mainly on a set of clinical observations. Recently, certain event-related potentials (ERPs), which are transient electroencephalogram (EEG) responses to auditory, visual or tactile stimuli, have been introduced as useful predictors of a positive coma outcome (ie, emergence). However, such tests require the skills of clinical neurophysiologists, who are not commonly available in many clinical settings. Additionally, none of the current standard clinical approaches have sufficient predictive accuracies to provide definitive prognoses. Objective The objective of this study is to develop improved machine learning procedures based on EEG/ERP for determining emergence from coma. Methods and analysis Data will be collected from 50 participants in coma. EEG/ERP data will be recorded for 24 consecutive hours at a maximum of five time points spanning 30 days from the date of recruitment to track participants' progression. The study employs paradigms designed to elicit brainstem potentials, middle-latency responses, N100, mismatch negativity, P300 and N400. In the case of patient emergence, data are recorded on that occasion to form an additional basis for comparison. A relevant data set will be developed from the testing of 20 healthy controls, each spanning a 15-hour recording period in order to formulate a baseline. Collected data will be used to develop an automated procedure for analysis and detection of various ERP components that are salient to prognosis. Salient features extracted from the ERP and resting-state EEG will be identified and combined to give an accurate indicator of prognosis. Ethics and dissemination This study is approved by the Hamilton Integrated Research Ethics Board (project number 4840). Results will be disseminated through peer-reviewed journal articles and presentations at scientific conferences. Trial registration number NCT03826407. © 2019 Author(s).},
	author_keywords = {neurological injury; neurophysiology},
	keywords = {Brain; Coma; Electroencephalography; Evoked Potentials; Humans; Machine Learning; Point-of-Care Systems; Prognosis; Prospective Studies; Research Design; adult; Article; auditory evoked potential; automation; clinical article; clinical protocol; cohort analysis; coma; controlled study; electroencephalography; event related potential; human; machine learning; medical decision making; mismatch negativity; point of care system; prognosis; prospective study; brain; coma; evoked response; methodology; pathology; pathophysiology},
	correspondence_address = {J.F. Connolly; School of Biomedical Engineering, McMaster University, Hamilton, Canada; email: jconnol@mcmaster.ca},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31320356},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Wouters2019447,
	author = {Wouters, Niels and Kelly, Ryan and Velloso, Eduardo and Wolf, Katrin and Ferdous, Hasan Shahid and Newn, Joshua and Joukhadar, Zaher and Vetere, Frank},
	title = {Biometric mirror: Exploring values and attitudes towards facial analysis and automated decision-making},
	year = {2019},
	journal = {DIS 2019 - Proceedings of the 2019 ACM Designing Interactive Systems Conference},
	pages = {447 – 461},
	doi = {10.1145/3322276.3322304},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070644150&doi=10.1145%2f3322276.3322304&partnerID=40&md5=f1430552e0146b790ebd23393925af12},
	affiliations = {School of Computing and Information Systems, University of Melbourne, Australia; Hamburg University of Applied Sciences, Hamburg, Germany},
	abstract = {Facial analysis applications are increasingly being applied to inform decision-making processes. However, as global reports of unfairness emerge, governments, academia and industry have recognized the ethical limitations and societal implications of this technology. Alongside initiatives that aim to formulate ethical frameworks, we believe that the public should be invited to participate in the debate. In this paper, we discuss Biometric Mirror, a case study that explored opinions about the ethics of an emerging technology. The interactive application distinguished demographic and psychometric information from people's facial photos and presented speculative scenarios with potential consequences based on their results. We analyzed the interactions with Biometric Mirror and media reports covering the study. Our findings demonstrate the nature of public opinion about the technology's possibilities, reliability, and privacy implications. Our study indicates an opportunity for case study-based digital ethics research, and we provide practical guidelines for designing future studies. © 2019 ACM.},
	author_keywords = {Accountability; Digital ethics; Facial analysis; Fairness; Field study; Machine learning; Public space; Transparency},
	keywords = {Behavioral research; Biometrics; Learning systems; Mirrors; Philosophical aspects; Social aspects; Transparency; Accountability; Digital ethics; Facial analysis; Fairness; Field studies; Public space; Decision making},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145035850-7},
	language = {English},
	abbrev_source_title = {DIS - Proc. ACM Des. Interact. Syst. Conf.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; Conference name: 2019 ACM Conference on Designing Interactive Systems, DIS 2019; Conference date: 23 June 2019 through 28 June 2019; Conference code: 148984; All Open Access, Green Open Access}
}

@ARTICLE{Anderson2019526,
	author = {Anderson, Michael and Anderson, Susan Leigh and Berenz, Vincent},
	title = {A Value-Driven Eldercare Robot: Virtual and Physical Instantiations of a Case-Supported Principle-Based Behavior Paradigm},
	year = {2019},
	journal = {Proceedings of the IEEE},
	volume = {107},
	number = {3},
	pages = {526 – 540},
	doi = {10.1109/JPROC.2018.2840045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055214687&doi=10.1109%2fJPROC.2018.2840045&partnerID=40&md5=6bb719b209211e9467d6e21ca858cb33},
	affiliations = {Department of Computer Science, University of Hartford, West Hartford, 06117-1599, CT, United States; Department of Philosophy, University of Connecticut, Storrs, CT, United States; Autonomous Motion Department, Max Planck Institute for Intelligent Systems, Tubingen, Germany},
	abstract = {In this paper, a case-supported principle-based behavior paradigm is proposed to help ensure ethical behavior of autonomous machines. We argue that ethically significant behavior of autonomous systems should be guided by explicit ethical principles determined through a consensus of ethicists. Such a consensus is likely to emerge in many areas in which autonomous systems are apt to be deployed and for the actions they are liable to undertake. We believe that this is the case since we are more likely to agree on how machines ought to treat us than on how human beings ought to treat one another. Given such a consensus, particular cases of ethical dilemmas where ethicists agree on the ethically relevant features and the right course of action can be used to help discover principles that balance these features when they are in conflict. Such principles not only help ensure ethical behavior of complex and dynamic systems but also can serve as a basis for justification of this behavior. The requirements, methods, implementation, and evaluation components of the paradigm are detailed as well as its instantiation in both a simulated and real robot functioning in the domain of eldercare. © 1963-2012 IEEE.},
	author_keywords = {Artificial intelligence; machine ethics; machine learning; ocmputer science; robotics},
	keywords = {Artificial intelligence; Automatic guided vehicles; Learning systems; Petroleum reservoir evaluation; Robotics; Autonomous machines; Autonomous systems; Course of action; Ethical behavior; Ethical dilemma; Ethical principles; ocmputer science; Relevant features; Philosophical aspects},
	correspondence_address = {M. Anderson; Department of Computer Science, University of Hartford, West Hartford, 06117-1599, United States; email: anderson@hartford.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {00189219},
	coden = {IEEPA},
	language = {English},
	abbrev_source_title = {Proc. IEEE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Bronze Open Access}
}

@ARTICLE{Broughton2019596,
	author = {Broughton, Vanda},
	title = {The respective roles of intellectual creativity and automation in representing diversity: Human and machine generated bias},
	year = {2019},
	journal = {Knowledge Organization},
	volume = {46},
	number = {8},
	pages = {596 – 606},
	doi = {10.5771/0943-7444-2019-8-596},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85081596639&doi=10.5771%2f0943-7444-2019-8-596&partnerID=40&md5=c0b6754e83719ffd3d204fcdadae518e},
	affiliations = {Department of Information Studies, University College London, Gower Street, London, WC1E 6BT, United Kingdom},
	abstract = {The paper traces the development of the discussion around ethical issues in artificial intelligence, and considers the way in which humans have affected the knowledge bases used in machine learning The phenomenon of bias or discrimination in machine ethics is seen as inherited from humans, either through the use of biased data or through the semantics inherent in intellectually-built tools sourced by intelligent agents. The kind of biases observed in AI are compared with those identified in the field of knowledge organization, using religious adherents as an example of a community potentially marginalized by bias. A practical demonstration is given of apparent religious prejudice inherited from source material in a large database deployed widely in computational linguistics and automatic indexing Methods to address the problem of bias are discussed, including the modelling of the moral process on neuroscientific understanding of brain function. The question is posed whether it is possible to model religious belief in a similar way, so that robots of the future may have both an ethical and a religious sense and themselves address the problem of prejudice. © 2019 International Society for Knowledge Organization. All rights reserved.},
	author_keywords = {Artificial intelligence; Bias; Data; Human; Machine intelligence},
	correspondence_address = {V. Broughton; Department of Information Studies, University College London, London, Gower Street, WC1E 6BT, United Kingdom; email: v.broughton@ucl.ac.uk},
	publisher = {International Society for Knowledge Organization},
	issn = {09437444},
	language = {English},
	abbrev_source_title = {Knowl. Organ.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Devaraj2019S2,
	author = {Devaraj, Harsha and Makhija, Simran and Basak, Suryoday},
	title = {On the implications of artificial intelligence and its responsible growth},
	year = {2019},
	journal = {Journal of Scientometric Research},
	volume = {8},
	number = {2},
	pages = {S2 – S6},
	doi = {10.5530/jscires.8.2.21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091238864&doi=10.5530%2fjscires.8.2.21&partnerID=40&md5=45ca222fc3fd38b21de176b67921601c},
	affiliations = {University of Michigan Ann Arbor, United States; Astroinformatics Research Group, IEEE Computer Society Bangalore Chapter and Center for Mathematical Modeling and Simulation (CAMMS), University of Texas, Arlington, United States; Department of Computer Science and Engineering, University of Texas, Arlington, United States},
	abstract = {As a set of technologies, Artificial Intelligence (AI) has received growing interest from a variety of fields. However, many fundamental questions about AI are still mysteries to the everyday person. This paper seeks to address the history of AI, the current state of the field, important distinctions between related fields, misconceptions birthed by popular media, and irresponsible applications of AI. The authors believe this basic understanding of AI and its shortcomings is vital, and the advancement of the field should be matched by the advancement in public understanding of AI. Copyright © The Author(s). 2019.},
	author_keywords = {Artificial intelligence; Ethics; Machine learning},
	correspondence_address = {S. Basak; Department of Computer Science and Engineering, University of Texas at Arlington, Arlington, Box 19015, United States; email: suryodaybasak@gmail.com},
	publisher = {Phcog.Net},
	issn = {23216654},
	language = {English},
	abbrev_source_title = {J. Scientometr. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Saba201914,
	author = {Saba, Luca and Biswas, Mainak and Kuppili, Venkatanareshbabu and Cuadrado Godia, Elisa and Suri, Harman S. and Edla, Damodar Reddy and Omerzu, Tomaž and Laird, John R. and Khanna, Narendra N. and Mavrogeni, Sophie and Protogerou, Athanasios and Sfikakis, Petros P. and Viswanathan, Vijay and Kitas, George D. and Nicolaides, Andrew and Gupta, Ajay and Suri, Jasjit S.},
	title = {The present and future of deep learning in radiology},
	year = {2019},
	journal = {European Journal of Radiology},
	volume = {114},
	pages = {14 – 24},
	doi = {10.1016/j.ejrad.2019.02.038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062451021&doi=10.1016%2fj.ejrad.2019.02.038&partnerID=40&md5=7f50b3a7356f099786b7585685ed6a23},
	affiliations = {Department of Radiology, Policlinico Universitario, Cagliari, Italy; National Institute of Technology Goa, India; IMIM – Hospital del Mar, Passeig Marítim 25-29, Barcelona, Spain; Brown University, Providence, RI, United States; Department of Neurology, University Medical Centre Maribor, Slovenia; Cardiology Department, St. Helena Hospital, St. Helena, CA, United States; Cardiology Department, Apollo Hospitals, New Delhi, India; Cardiology Clinic, Onassis Cardiac Surgery Center, Athens, Greece; Department of Cardiovascular Prevention & Research Unit Clinic & Laboratory of Pathophysiology, National and Kapodistrian Univ. of Athens, Greece; Rheumatology Unit, National Kapodistrian University of Athens, Greece; MV Hospital for Diabetes and Professor M Viswanathan Diabetes Research Centre, Chennai, India; Arthritis Research UK Centre for Epidemiology, Manchester University, Manchester, United Kingdom; Department of Rheumatology, Dudley Group NHS Foundation Trust, Dudley, United Kingdom; Vascular Screening and Diagnostic Centre, London, United Kingdom; Department of Biological Sciences, University of Cyprus, Nicosia, Cyprus; Brain and Mind Research Institute and Department of Radiology, Weill Cornell Medical College, NY, United States; Stroke Monitoring and Diagnostic Division, AtheroPoint™, Roseville, CA, United States},
	abstract = {The advent of Deep Learning (DL) is poised to dramatically change the delivery of healthcare in the near future. Not only has DL profoundly affected the healthcare industry it has also influenced global businesses. Within a span of very few years, advances such as self-driving cars, robots performing jobs that are hazardous to human, and chat bots talking with human operators have proved that DL has already made large impact on our lives. The open source nature of DL and decreasing prices of computer hardware will further propel such changes. In healthcare, the potential is immense due to the need to automate the processes and evolve error free paradigms. The sheer quantum of DL publications in healthcare has surpassed other domains growing at a very fast pace, particular in radiology. It is therefore imperative for the radiologists to learn about DL and how it differs from other approaches of Artificial Intelligence (AI). The next generation of radiology will see a significant role of DL and will likely serve as the base for augmented radiology (AR). Better clinical judgement by AR will help in improving the quality of life and help in life saving decisions, while lowering healthcare costs. A comprehensive review of DL as well as its implications upon the healthcare is presented in this review. We had analysed 150 articles of DL in healthcare domain from PubMed, Google Scholar, and IEEE EXPLORE focused in medical imagery only. We have further examined the ethic, moral and legal issues surrounding the use of DL in medical imaging. © 2019},
	author_keywords = {Deep learning; Machine learning; Medical imaging; Radiology},
	keywords = {Artificial Intelligence; Deep Learning; Delivery of Health Care; Forecasting; Humans; Quality of Life; Radiologists; Radiology; arterial wall thickness; artificial intelligence; brain ischemia; cardiology; computer assisted tomography; decision making; deep learning; fatty liver; health care cost; human; priority journal; privacy; prognosis; prostate cancer; quality of life; radiologist; radiology; respiratory tract disease; Review; risk factor; safety; urology; forecasting; health care delivery; radiology; standards; statistics and numerical data; trends},
	correspondence_address = {J.S. Suri; Stroke Monitoring and Diagnostic Division, Roseville, AtheroPoint™, United States; email: jasjit.suri@atheropoint.com},
	publisher = {Elsevier Ireland Ltd},
	issn = {0720048X},
	coden = {EJRAD},
	pmid = {31005165},
	language = {English},
	abbrev_source_title = {Eur. J. Radiol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 202; All Open Access, Green Open Access}
}

@ARTICLE{Guan201976,
	author = {Guan, Jian},
	title = {Artificial Intelligence in Healthcare and Medicine: Promises, Ethical Challenges and Governance},
	year = {2019},
	journal = {Chinese Medical Sciences Journal},
	volume = {34},
	number = {2},
	pages = {76 – 83},
	doi = {10.24920/003611},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068830066&doi=10.24920%2f003611&partnerID=40&md5=7cd9d9ea3198958968a91a45f2de1689},
	affiliations = {Clinical Center, the National Scientific Data Sharing Platform for Population and Health, Beijing, 100730, China; Peking Union Medical College Hospital, Chinese Academy of Medical Sciences & Peking Union Medical College, Beijing, 100730, China},
	abstract = {Artificial intelligence (AI) is rapidly being applied to a wide range of fields, including medicine, and has been considered as an approach that may augment or substitute human professionals in primary healthcare. However, AI also raises several challenges and ethical concerns. In this article, the author investigates and discusses three aspects of AI in medicine and healthcare: the application and promises of AI, special ethical concerns pertaining to AI in some frontier fields, and suggestive ethical governance systems. Despite great potentials of frontier AI research and development in the field of medical care, the ethical challenges induced by its applications has put forward new requirements for governance. To ensure “trustworthy” AI applications in healthcare and medicine, the creation of an ethical global governance framework and system as well as special guidelines for frontier AI applications in medicine are suggested. The most important aspects include the roles of governments in ethical auditing and the responsibilities of stakeholders in the ethical governance system. © 2019 Chinese Academy Medical Sciences},
	author_keywords = {artificial intelligence; biohybrids; brain-computer interaction; brain-inspired computer; ethical governance; machine learning; medical ethics; robots},
	keywords = {Artificial Intelligence; Delivery of Health Care; Humans; article; artificial intelligence; brain; government; human; machine learning; medical care; medical ethics; practice guideline; primary health care; robotics; ethics; health care delivery; procedures},
	correspondence_address = {J. Guan; Clinical Center, the National Scientific Data Sharing Platform for Population and Health, Beijing, 100730, China; email: gjpumch@126.com},
	publisher = {Elsevier Ltd},
	issn = {10019294},
	coden = {CMSJE},
	pmid = {31315747},
	language = {English},
	abbrev_source_title = {Chin. Med. Sci. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 41; All Open Access, Bronze Open Access}
}

@BOOK{Glass201979,
	author = {Glass, Zachary and Cahn, E. Susanna},
	title = {Classifying Ethics Codes Using Natural Language Processing},
	year = {2019},
	journal = {Responsible Organizations in the Global Context: Current Challenges and Forward-Thinking Perspectives},
	pages = {79 – 96},
	doi = {10.1007/9783030114589-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148835491&doi=10.1007%2f9783030114589-5&partnerID=40&md5=c0eedb94c83305d47930e1b5cbe578af},
	affiliations = {Pace University, Lubin School of Business, United States},
	abstract = {Business ethics scholars have varied opinions of corporate ethics codes. Many advocate them as a way to contribute to an organizational environment in which ethics will be a regular consideration in the decision-making process. Critics assert that codes of ethics are mere window dressings written to protect the company from litigation or to comply with regulations. The authors maintain that language is a key to distinguishing between these two properties and an aid to how employees and other stakeholders should view a code’s intent. However, language is often ambiguous to the reader and results of research on ethics codes are often in conflict. This chapter addresses the issue of intent by quantifying the content of ethics codes. Methodologies from natural language processing (NLP) and machine learning are applied in a novel way to classify ethics codes. Codes from companies selected from lists of “Ethical” companies are compared with codes from the Fortune 500 companies. The model’s findings indicate that ethics codes for some of these groups of companies can be distinguishable. © The Editor(s) (if applicable) and The Author(s), under exclusive licence to Springer Nature Switzerland AG 2019.},
	author_keywords = {Codes of conduct; Corporate social responsibility; Ethics codes; Machine learning; Natural language processing},
	publisher = {Springer International Publishing},
	isbn = {978-303011458-9; 978-303011457-2},
	language = {English},
	abbrev_source_title = {Responsible Organizations in the Global Context: Current Challenges and Forward-Thinking Perspectives},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ngiam2019e262,
	author = {Ngiam, Kee Yuan and Khor, Ing Wei},
	title = {Big data and machine learning algorithms for health-care delivery},
	year = {2019},
	journal = {The Lancet Oncology},
	volume = {20},
	number = {5},
	pages = {e262 – e273},
	doi = {10.1016/S1470-2045(19)30149-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064899814&doi=10.1016%2fS1470-2045%2819%2930149-4&partnerID=40&md5=84f271a943324b454fbc5266b45e55e4},
	affiliations = {Department of Surgery, National University of Singapore, Singapore; Department of Medicine, Yong Loo Lin School of Medicine, National University of Singapore, Singapore; Division of General Surgery (Thyroid and Endocrine Surgery), University Surgical Cluster, National University Hospital, Singapore; National University Health System Corporate Office, Singapore},
	abstract = {Analysis of big data by machine learning offers considerable advantages for assimilation and evaluation of large amounts of complex health-care data. However, to effectively use machine learning tools in health care, several limitations must be addressed and key issues considered, such as its clinical implementation and ethics in health-care delivery. Advantages of machine learning include flexibility and scalability compared with traditional biostatistical methods, which makes it deployable for many tasks, such as risk stratification, diagnosis and classification, and survival predictions. Another advantage of machine learning algorithms is the ability to analyse diverse data types (eg, demographic data, laboratory findings, imaging data, and doctors' free-text notes) and incorporate them into predictions for disease risk, diagnosis, prognosis, and appropriate treatments. Despite these advantages, the application of machine learning in health-care delivery also presents unique challenges that require data pre-processing, model training, and refinement of the system with respect to the actual clinical problem. Also crucial are ethical considerations, which include medico-legal implications, doctors' understanding of machine learning tools, and data privacy and security. In this Review, we discuss some of the benefits and challenges of big data and machine learning in health care. © 2019 Elsevier Ltd},
	keywords = {Big Data; Data Mining; Delivery of Health Care, Integrated; Diagnosis, Computer-Assisted; Health Services Research; Humans; Machine Learning; Medical Oncology; Neoplasms; Neural Networks, Computer; Therapy, Computer-Assisted; algorithm; biostatistics; classification; colorectal polyp; data processing; esophagus cancer; eye disease; fracture; health care delivery; heart disease; human; lung cancer; lung disease; machine learning; man machine interaction; medical ethics; medicolegal aspect; melanoma; neurologic disease; pancreas cancer; prediction; priority journal; prostate cancer; Review; septic shock; stomach cancer; survival; computer assisted diagnosis; computer assisted therapy; data mining; health services research; integrated health care system; neoplasm; oncology},
	correspondence_address = {K.Y. Ngiam; National University Health System Corporate Office, 119228, Singapore; email: kee_yuan_ngiam@nuhs.edu.sg},
	publisher = {Lancet Publishing Group},
	issn = {14702045},
	coden = {LOANB},
	pmid = {31044724},
	language = {English},
	abbrev_source_title = {Lancet Oncol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 490}
}

@ARTICLE{Margetts2019163,
	author = {Margetts, Helen and Dorobantu, Cosmina},
	title = {Rethink government with AI},
	year = {2019},
	journal = {Nature},
	volume = {568},
	number = {7751},
	pages = {163 – 165},
	doi = {10.1038/d41586-019-01099-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064082720&doi=10.1038%2fd41586-019-01099-5&partnerID=40&md5=11a2179e7958e6c078789913b8fa4f9e},
	abstract = {Policymakers should harness data to deliver public services that are responsive, efficient and fair, urge Helen Margetts and Cosmina Dorobantu. © 2019, Nature.},
	author_keywords = {Government; Mathematics and computing; Policy},
	keywords = {Administrative Personnel; Artificial Intelligence; Big Data; Computer Simulation; Facial Recognition; Federal Government; Foodborne Diseases; Forecasting; Government Regulation; Homeless Persons; Housing; Humans; Inventions; Machine Learning; Minority Groups; Models, Theoretical; Police; Policy Making; Prejudice; Social Media; Social Work; government; mathematics; note; administrative personnel; artificial intelligence; computer simulation; economics; ethics; facial recognition; food poisoning; forecasting; government regulation; homeless person; housing; human; invention; machine learning; management; minority group; organization and management; police; prejudice; procedures; social media; social work; theoretical model},
	publisher = {Nature Publishing Group},
	issn = {00280836},
	coden = {NATUA},
	pmid = {30967667},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 50; All Open Access, Bronze Open Access}
}

@BOOK{García20191,
	author = {García, Oscar A. and Kotturi, Prashanth},
	title = {Information and Communication Technologies for Development Evaluation},
	year = {2019},
	journal = {Information and Communication Technologies for Development Evaluation},
	pages = {1 – 157},
	doi = {10.4324/9780429028236},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135680970&doi=10.4324%2f9780429028236&partnerID=40&md5=7f0ecbb19fa39f86e81ac49247e0c9af},
	affiliations = {Independent Office of Evaluation (IOE), International Fund for Agricultural Development (IFAD), Italy},
	abstract = {Written by a team of expert practitioners at the Independent Office of Evaluation of International Fund for Agricultural Development (IFAD), this book gives an insight into the implications of new and emerging technologies in development evaluation. Growing technologies such as big data analytics, machine learning and remote sensing present new opportunities for development practitioners and development evaluators, particularly when measuring indicators of the Sustainable Development Goals. The volume provides an overview of information and communication technologies (ICTs) in the context of evaluation, looking at the theory and practice, and discussing how the landscape may unfold. It also considers concerns about privacy, ethics and inclusion, which are crucial issues for development practitioners and evaluators working in the interests of vulnerable populations across the globe. Among the contributions are case studies of seven organizations using various technologies for data collection, analysis, dissemination and learning. This valuable insight into practice will be of interest to researchers, practitioners and policymakers in development economics, development policy and ICT. © 2020 selection and editorial matter, Oscar A. García and Prashanth Kotturi.},
	publisher = {Taylor and Francis},
	isbn = {978-042965054-3; 978-036713714-4},
	language = {English},
	abbrev_source_title = {Information and Communication Technologies for Development Evaluation},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Fothergill2019,
	author = {Fothergill, B. Tyr and Knight, William and Stahl, Bernd Carsten and Ulnicane, Inga},
	title = {Responsible data governance of neuroscience big data},
	year = {2019},
	journal = {Frontiers in Neuroinformatics},
	volume = {13},
	doi = {10.3389/fninf.2019.00028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067396846&doi=10.3389%2ffninf.2019.00028&partnerID=40&md5=d191ddbfe2fbfdf09fe9075aff69bcbd},
	affiliations = {Centre for Computing and Social Responsibility, School of Computer Science and Informatics, Faculty of Computing, Engineering and Media, De Montfort University, Leicester, United Kingdom},
	abstract = {Current discussions of the ethical aspects of big data are shaped by concerns regarding the social consequences of both the widespread adoption of machine learning and the ways in which biases in data can be replicated and perpetuated. We instead focus here on the ethical issues arising from the use of big data in international neuroscience collaborations. Neuroscience innovation relies upon neuroinformatics, large-scale data collection and analysis enabled by novel and emergent technologies. Each step of this work involves aspects of ethics, ranging from concerns for adherence to informed consent or animal protection principles and issues of data re-use at the stage of data collection, to data protection and privacy during data processing and analysis, and issues of attribution and intellectual property at the data-sharing and publication stages. Significant dilemmas and challenges with far-reaching implications are also inherent, including reconciling the ethical imperative for openness and validation with data protection compliance and considering future innovation trajectories or the potential for misuse of research results. Furthermore, these issues are subject to local interpretations within different ethical cultures applying diverse legal systems emphasising different aspects. Neuroscience big data require a concerted approach to research across boundaries, wherein ethical aspects are integrated within a transparent, dialogical data governance process. We address this by developing the concept of “responsible data governance,” applying the principles of Responsible Research and Innovation (RRI) to the challenges presented by the governance of neuroscience big data in the Human Brain Project (HBP). © 2019 Fothergill, Knight, Stahl and Ulnicane.},
	author_keywords = {Big data; Data governance; Ethics; Human brain project; Neuroscience; RRI},
	keywords = {article; big data; brain; human; informed consent; neuroscience; patent; privacy; publication; validation process},
	correspondence_address = {B.T. Fothergill; Centre for Computing and Social Responsibility, School of Computer Science and Informatics, Faculty of Computing, Engineering and Media, De Montfort University, Leicester, United Kingdom; email: tyr.fothergill@dmu.ac.uk},
	publisher = {Frontiers Media S.A.},
	issn = {16625196},
	language = {English},
	abbrev_source_title = {Front. Neuroinformatics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Reardon201919,
	author = {Reardon, Sara},
	title = {How machine learning could keep dangerous DNA out of terrorists' hands},
	year = {2019},
	journal = {Nature},
	volume = {566},
	number = {7742},
	pages = {19},
	doi = {10.1038/d41586-019-00277-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061148303&doi=10.1038%2fd41586-019-00277-9&partnerID=40&md5=bebdb7e1af44fe532dc0a676dbb00bc3},
	author_keywords = {Synthetic biology; Systems biology; Virology},
	keywords = {Anthrax; Bacillus anthracis; Bioterrorism; DNA; Genetic Engineering; Machine Learning; Security Measures; Sequence Analysis, DNA; Software; United States; Variola virus; DNA; anthrax; Bacillus anthracis; biosynthesis; bioterrorism; comparative study; DNA sequence; ethics; genetic engineering; genetics; machine learning; microbiology; organization and management; prevention and control; Smallpox virus; software; statistics and numerical data; United States},
	publisher = {NLM (Medline)},
	issn = {14764687},
	pmid = {30723344},
	language = {English},
	abbrev_source_title = {Nature},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Misnikov2019320,
	author = {Misnikov, Yury G. and Filatova, Olga G.},
	title = {Online discussion as a form of e-participation: Russian specifics},
	year = {2019},
	journal = {Monitoring Obshchestvennogo Mneniya: Ekonomicheskie i Sotsial'nye Peremeny},
	volume = {153},
	number = {5},
	pages = {320 – 340},
	doi = {10.14515/monitoring.2019.5.15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078977321&doi=10.14515%2fmonitoring.2019.5.15&partnerID=40&md5=251b52315446837c50522a45270828f3},
	affiliations = {TMO University, St Petersburg, Russian Federation; St Petersburg State University, St Petersburg, Russian Federation},
	abstract = {The paper offers conceptually and methodologically well-grounded approaches towards discourse analysis of people's everyday political discussions on the Internet with the aim to determine how deliberative such discussions are. The discourse ethics theory of Jurgen Habermas serves as the conceptual foundation of the study presented in the paper within his model of deliberative democracy, i.e. a democracy that advocates a need to discuss publicly different worldviews from the normative and ethical perspectives. The authors test the applicability of such an approach to online discussions focused on the politically charged topics of destroying the embargoed western food products and increasing retirement age in Russia. Over 5,000 comments posted on the discussion forums by residents of the cities of different type and size were coded and analyzed. The coding included the key deliberative features of internet-discussions. The research generates empirical evidence pointing out that the analysis of internet-discussions as online deliberative practices helps reveal certain essential aspects of people's interpretation of the publicly salient events that would be problematic to obtain through more traditional sociological methods to study social moods or computer-based text mining, such as sentiment-analysis, which do not necessarily include the moral and ethical justification of the analyzed utterances. These empirical datasets generated following the claim-based discourse-analysis were further fed, as an experiment, into the recurrent neural network in order to train it to predict positions of discourse participants in connection with the claims they made with the support of respective argumentation. The experiment demonstrates opportunities, conditions and limitations of using the artificial intelligence technologies for better understanding of public debates. © 2019 Russian Public Opinion Research Center, VCIOM. All rights reserved.},
	author_keywords = {Discourse analysis; E-participation; Internet discourse; Machine learning; Neural networks; Online discussions; Pension reform; Research methods; Sentiment analysis},
	publisher = {Russian Public Opinion Research Center, VCIOM},
	issn = {22195467},
	language = {Russian},
	abbrev_source_title = {Monit. Obsestven. Mnenia: Ekon. Soc. Perem.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Rivas2019156,
	author = {Rivas, Pablo and Holzmayer, Kerstin and Hernandez, Cristian and Grippaldi, Charles},
	title = {Excitement and concerns about machine learning-based chatbots and talkbots: A survey},
	year = {2019},
	journal = {International Symposium on Technology and Society, Proceedings},
	volume = {2018-November},
	pages = {156 – 162},
	doi = {10.1109/ISTAS.2018.8638280},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062869941&doi=10.1109%2fISTAS.2018.8638280&partnerID=40&md5=934a70abc7b331c905e503b14ccc1c47},
	affiliations = {Department of Computer Science, School of Computer Science and Mathematics, New York, United States},
	abstract = {Chatbots and talkbots are intelligent programs that can establish written and oral communication with human beings, usually with the purpose of helping them achieve a specific goal. More and more companies are now implementing bots in order to reduce operational costs. Most bots use machine learning algorithms that are deployed on companies websites, cloud services, or distributed mobile systems so that customers are always able to speak with 'someone' to inquire about products or services. Most bots are trained using data from interactions among human beings so that they can learn speech patterns and answer questions. In this paper we present the results of an experiment designed to survey people's perception of these bots and how much people trust them. We present a moral dilemma to the respondents and ask questions about permissiveness and assess if bots are judged and blamed differently than their human counterparts. In this paper we reveal such differences in judgement, which suggest that many people hold the chatbots to similar behavioral standards than human beings; however, bots receive blame just as humans do. © 2018 IEEE.},
	author_keywords = {chatbots; ethics; machine learning; survey; talkbots},
	keywords = {Behavioral research; Botnet; Learning algorithms; Learning systems; Surveying; Surveys; Chatbots; Cloud services; Distributed mobile systems; ethics; Intelligent programs; Oral communication; Speech patterns; talkbots; Machine learning},
	editor = {Cunningham M. and Cunningham P.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153869479-4},
	language = {English},
	abbrev_source_title = {Int Symp Technol Soc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 24th Annual IEEE International Symposium on Technology and Society, ISTAS 2018; Conference date: 13 November 2018 through 14 November 2018; Conference code: 145086}
}

@BOOK{Raftree2019111,
	author = {Raftree, Linda},
	title = {Technology, Biases and Ethics: Exploring the Soft Sides of Information and Communication Technologies for Evaluation (ICT4Eval)},
	year = {2019},
	journal = {Information and Communication Technologies for Development Evaluation},
	pages = {111 – 127},
	doi = {10.4324/9780429028236-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135643388&doi=10.4324%2f9780429028236-5&partnerID=40&md5=efa32de94d3b2f386c4d055686ab86db},
	abstract = {This chapter discusses the ethical aspects related to inclusion, bias and privacy in New information technology, data science and digital data, and explores how they impact on evaluation and programmatic decision-making in the area of development. Biases that intervene in the course of using information and communication technologies in general and data sciences in particular could be tackled using social as well as technological measures. In terms of using technology to combat biases in datasets and machine learning models, new tools such as IBM AI Fairness 360 are being introduced. Such tools can check for biases at several points along the machine learning pipeline, using the appropriate bias metric for their circumstances. As development agencies incorporate more digital tools and data processes into their work, data ownership, protection, privacy and security have come to the forefront. Even if development agencies were allowed to access the “black box” algorithms, they lack the skills to examine, assess and question them. © 2020 selection and editorial matter, Oscar A. García and Prashanth Kotturi.},
	publisher = {Taylor and Francis},
	isbn = {978-042965054-3; 978-036713714-4},
	language = {English},
	abbrev_source_title = {Information and Communication Technologies for Development Evaluation},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Van Hamersvelt2019,
	author = {Van Hamersvelt, Robbert Willem and Išgum, Ivana and De Jong, Pim A and Cramer, Maarten Jan Maria and Leenders, Geert E H and Willemink, Martin J and Voskuil, Michiel and Leiner, Tim},
	title = {Application of speCtraL computed tomogrAphy to impRove specIficity of cardiac compuTed tomographY (CLARITY study): Rationale and design},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {3},
	doi = {10.1136/bmjopen-2018-025793},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062415550&doi=10.1136%2fbmjopen-2018-025793&partnerID=40&md5=e1ecaf1409d6acf52f54e4e02f4f32ef},
	affiliations = {Department of Radiology, University Medical Centre Utrecht, Utrecht University, Utrecht, Netherlands; Image Sciences Institute, University Medical Centre Utrecht, Utrecht University, Utrecht, Netherlands; Department of Cardiology, University Medical Centre Utrecht, Utrecht University, Utrecht, Netherlands},
	abstract = {Introduction Anatomic stenosis evaluation on coronary CT angiography (CCTA) lacks specificity in indicating the functional significance of a stenosis. Recent developments in CT techniques (including dual-layer spectral detector CT [SDCT] and static stress CT perfusion [CTP]) and image analyses (including fractional flow reserve [FFR] derived from CCTA images [FFR CT ] and deep learning analysis [DL]) are potential strategies to increase the specificity of CCTA by combining both anatomical and functional information in one investigation. The aim of the current study is to assess the diagnostic performance of (combinations of) SDCT, CTP, FFR CT and DL for the identification of functionally significant coronary artery stenosis. Methods and analysis Seventy-five patients aged 18 years and older with stable angina and known coronary artery disease and scheduled to undergo clinically indicated invasive FFR will be enrolled. All subjects will undergo the following SDCT scans: coronary calcium scoring, static stress CTP, rest CCTA and if indicated (history of myocardial infarction) a delayed enhancement acquisition. Invasive FFR of ≤0.80, measured within 30 days after the SDCT scans, will be used as reference to indicate a functionally significant stenosis. The primary study endpoint is the diagnostic performance of SDCT (including CTP) for the identification of functionally significant coronary artery stenosis. Secondary study endpoint is the diagnostic performance of SDCT, CTP, FFR CT and DL separately and combined for the identification of functionally significant coronary artery stenosis. Ethics and dissemination Ethical approval was obtained. All subjects will provide written informed consent. Study findings will be disseminated through peer-reviewed conference presentations and journal publications. Trial registration number NCT03139006; Pre-results. © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {cardiovascular imaging; Computed tomography; coronary artery disease; fractional flow reserve; machine learning; perfusion},
	keywords = {Adolescent; Adult; Aged; Cardiac Imaging Techniques; Computed Tomography Angiography; Controlled Clinical Trials as Topic; Coronary Angiography; Coronary Stenosis; Fractional Flow Reserve, Myocardial; Humans; Machine Learning; Middle Aged; Multimodal Imaging; Prospective Studies; Sample Size; Young Adult; iopromide; adult; Article; cardiac imaging; computed tomographic angiography; computer assisted tomography; coronary artery calcium score; coronary artery disease; coronary artery obstruction; deep learning; diagnostic accuracy; diagnostic test accuracy study; dual layer spectral detector computed tomography; fractional flow reserve; functionally significant coronary artery stenosis; heart muscle perfusion; human; image analysis; invasive procedure; major clinical study; predictive value; prospective study; receiver operating characteristic; sensitivity and specificity; stable angina pectoris; static stress computed tomography perfusion imaging; adolescent; aged; cardiac imaging; controlled clinical trial (topic); coronary angiography; coronary artery obstruction; diagnostic imaging; fractional flow reserve; machine learning; middle aged; multimodal imaging; procedures; sample size; young adult},
	correspondence_address = {R.W. Van Hamersvelt; Department of Radiology, University Medical Centre Utrecht, Utrecht University, Utrecht, Netherlands; email: r.w.vanhamersvelt-3@umcutrecht.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {30826767},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Amoore20193,
	author = {Amoore, Louise},
	title = {Introduction: Thinking with Algorithms: Cognition and Computation in the Work of N. Katherine Hayles},
	year = {2019},
	journal = {Theory, Culture and Society},
	volume = {36},
	number = {2},
	pages = {3 – 16},
	doi = {10.1177/0263276418818884},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061751228&doi=10.1177%2f0263276418818884&partnerID=40&md5=b875c31daaecf98959991d564138c142},
	affiliations = {University of Durham, United Kingdom},
	abstract = {In our contemporary moment, when machine learning algorithms are reshaping many aspects of society, the work of N. Katherine Hayles stands as a powerful corpus for understanding what is at stake in a new regime of computation. A renowned literary theorist whose work bridges the humanities and sciences among her many works, Hayles has detailed ways to think about embodiment in an age of virtuality (How We Became Posthuman, 1999), how code as performative practice is located (My Mother Was a Computer, 2005), and the reciprocal relations among human bodies and technics (How We Think, 2012). This special issue follows the 2017 publication of her book Unthought: The Power of the Cognitive Nonconscious, in which Hayles traces the nonconscious cognition of biological life-forms and computational media. The articles in the special issue respond in different ways to Hayles’ oeuvre, mapping the specific contours of computational regimes and developing some of the ‘inflection points’ she advocates in the deep engagement with technical systems. © The Author(s) 2019.},
	author_keywords = {algorithms; cognition; computation; ethics; technology},
	correspondence_address = {L. Amoore; University of Durham, United Kingdom; email: louise.amoore@durham.ac.uk},
	publisher = {SAGE Publications Ltd},
	issn = {02632764},
	language = {English},
	abbrev_source_title = {Theory Cult. Soc.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@CONFERENCE{Raji2019429,
	author = {Raji, Inioluwa Deborah and Buolamwini, Joy},
	title = {Actionable auditing: Investigating the impact of publicly naming biased performance results of commercial AI products},
	year = {2019},
	journal = {AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {429 – 435},
	doi = {10.1145/3306618.3314244},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070651363&doi=10.1145%2f3306618.3314244&partnerID=40&md5=3b17640599caf4227f52b99133beff81},
	affiliations = {University of Toronto, Toronto, ON, Canada; Massachusetts Institute of Technology, Cambridge, MA, United States},
	abstract = {Although algorithmic auditing has emerged as a key strategy to expose systematic biases embedded in software platforms, we struggle to understand the real-world impact of these audits, as scholarship on the impact of algorithmic audits on increasing algorithmic fairness and transparency in commercial systems is nascent. To analyze the impact of publicly naming and disclosing performance results of biased AI systems, we investigate the commercial impact of Gender Shades, the first algorithmic audit of gender and skin type performance disparities in commercial facial analysis models. This paper 1) outlines the audit design and structured disclosure procedure used in the Gender Shades study, 2) presents new performance metrics from targeted companies IBM, Microsoft and Megvii (Face++) on the Pilot Parliaments Benchmark (PPB) as of August 2018, 3) provides performance results on PPB by non-target companies Amazon and Kairos and, 4) explores differences in company responses as shared through corporate communications that contextualize differences in performance on PPB. Within 7 months of the original audit, we find that all three targets released new API versions. All targets reduced accuracy disparities between males and females and darker and lighter-skinned subgroups, with the most significant update occurring for the darker-skinned female subgroup, that underwent a 17.7% - 30.4% reduction in error between audit periods. Minimizing these disparities led to a 5.72% to 8.3% reduction in overall error on the Pilot Parliaments Benchmark (PPB) for target corporation APIs. The overall performance of non-targets Amazon and Kairos lags significantly behind that of the targets, with error rates of 8.66% and 6.60% overall, and error rates of 31.37% and 22.50% for the darker female subgroup, respectively. © 2019 Association for Computing Machinery.},
	author_keywords = {Artificial Intelligence; Commercial Applications; Computer Vision; Ethics; Facial Recognition; Fairness; Machine Learning},
	keywords = {Artificial intelligence; Computer vision; Embedded systems; Errors; Face recognition; Learning systems; Philosophical aspects; Commercial applications; Commercial systems; Corporate communications; Ethics; Facial recognition; Fairness; Performance metrics; Software platforms; Benchmarking},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036324-2},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 184; Conference name: 2nd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2019; Conference date: 27 January 2019 through 28 January 2019; Conference code: 149526}
}

@ARTICLE{Jayakumar20191777,
	author = {Jayakumar, Prakash and Moore, Meredith L.G. and Bozic, Kevin J.},
	title = {Value-based Healthcare: Can Artificial Intelligence Provide Value in Orthopaedic Surgery?},
	year = {2019},
	journal = {Clinical Orthopaedics and Related Research},
	volume = {477},
	number = {8},
	pages = {1777 – 1780},
	doi = {10.1097/CORR.0000000000000873},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070478379&doi=10.1097%2fCORR.0000000000000873&partnerID=40&md5=451296d9756119fd1d37e56718ed44bc},
	affiliations = {Value Institute for Health and Care, Department of Surgery and Perioperative Care, Dell Medical School, University of Texas at Austin, 1701 Trinity Street, Austin, 78712, TX, United States},
	keywords = {Artificial Intelligence; Cost-Benefit Analysis; Data Mining; Decision Support Systems, Clinical; Decision Support Techniques; Diagnosis, Computer-Assisted; Health Care Costs; Humans; Orthopedic Procedures; Orthopedics; Therapy, Computer-Assisted; Value-Based Health Insurance; Article; artificial intelligence; clinical practice; cost effectiveness analysis; data extraction; decision support system; diagnosis; ethics; human; machine learning; medical education; orthopedic surgery; prediction; priority journal; randomized controlled trial (topic); artificial intelligence; clinical decision support system; computer assisted diagnosis; computer assisted therapy; cost benefit analysis; data mining; economics; health care cost; orthopedic surgery; orthopedics},
	correspondence_address = {K.J. Bozic; Value Institute for Health and Care, Department of Surgery and Perioperative Care, Dell Medical School, University of Texas at Austin, Austin, 1701 Trinity Street, 78712, United States; email: kevin.bozic@austin.utexas.edu},
	publisher = {Lippincott Williams and Wilkins},
	issn = {0009921X},
	coden = {CORTB},
	pmid = {31335596},
	language = {English},
	abbrev_source_title = {Clin. Orthop. Relat. Res.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Gong2019658,
	author = {Gong, Yan and Gu, Zaiwang and Hu, Yan and Liao, Yanhong and Ye, Ting and Liu, Dong and Liu, Jiang},
	title = {The application value of deep learning OCT on wet age-related macular degeneration assisted diagnosis; [基于深度学习OCT辅助诊断湿性年龄相关性黄斑变性算法的应用]},
	year = {2019},
	journal = {Zhonghua Shiyan Yanke Zazhi/Chinese Journal of Experimental Ophthalmology},
	volume = {37},
	number = {8},
	pages = {658 – 662},
	doi = {10.3760/cma.j.issn.2095-0160.2019.08.014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074652044&doi=10.3760%2fcma.j.issn.2095-0160.2019.08.014&partnerID=40&md5=76caf25b0c8d84efb772d8af582c83fd},
	affiliations = {Ningbo Eye Hospital, Ningbo, 315041, China; Cixi Institute of BioMedical Engineering, CNITECH, CAS, Ningbo, 315201, China; Department of Computer Science and Engineering, Southern University of Science and Technology, Shenzhen, 518055, China},
	abstract = {Objective: To investigate the application value of deep learning optical coherence tomography (OCT) on wet age-related macular degeneration (wAMD) assisted diagnosis. Methods: Weakly supervised deep learning algorithms was applied on the premise that only disease or not can be provided as a marker.The OCT image automatically assisted in the diagnosis of diseased areas of wAMD, and thermograms were applied to provide a basis for doctors to detect disease areas.Based on the deep learning of weak supervision, a new network algorithm structure was proposed for detecting disease area in ophthalmic OCT images.At the same time, thermograms were adopted to improve the accuracy of the lesion map, which is the location of the lesion area.This study followed the Declaration of Helsinki.This study protocol was approved by Ethic Committee of Ningbo Eye Hospital (No.2018-YJ05). Written informed consent was obtained from each subject before entering study cohort. Results: Resnet-based deep learning algorithm gave a diagnostic accuracy rate of 94.9% for the disease, which was much higher than that of AlexNet 85.3%, VGG 88.7%, and Google-Net 89.2%.The thermograms with different colors provided a more convenient auxiliary diagnosis basis for doctors. Conclusions: Compared with the original classification network, which needs disease area markers as empirical knowledge, deep learning algorithm model not only provides better results in the classification of retinal diseases, but also marks potential disease areas.The lesion area provides a basis for judging the area of the lesion for the diagnosis of wAMD. Copyright © 2019 by the Chinese Medical Association.},
	author_keywords = {Disease classification; Lesion area detection; Weak supervision deep learning; Wet age-related macular degeneration},
	keywords = {Article; automation; cohort analysis; controlled study; deep learning; diagnostic accuracy; diagnostic test accuracy study; diagnostic value; human; learning algorithm; optical coherence tomography; supervised machine learning; thermography; wet macular degeneration},
	correspondence_address = {Y. Hu; Cixi Institute of BioMedical Engineering, CNITECH, CAS, Ningbo, 315201, China; email: huyan@nimte.ac.cn},
	publisher = {Henan Institute of Ophthalmology},
	issn = {20950160},
	language = {Chinese},
	abbrev_source_title = {Zhonghua Shiyan Yanke Zazhi Chin. J. Exp. Ophthalmol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jain2019xv,
	author = {Jain, Lucky},
	title = {Perinatal Pharmacology at Crossroads},
	year = {2019},
	journal = {Clinics in Perinatology},
	volume = {46},
	number = {2},
	pages = {xv – xvi},
	doi = {10.1016/j.clp.2019.03.002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063570251&doi=10.1016%2fj.clp.2019.03.002&partnerID=40&md5=9efc068a76135c0cec1068a4756a6d89},
	affiliations = {Emory University School of Medicine, and Children's Healthcare of Atlanta, 1760 Haygood Drive, W409, Atlanta, 30322, GA, United States},
	keywords = {Drug Discovery; Humans; Induced Pluripotent Stem Cells; Infant, Newborn; Machine Learning; Organoids; Perinatology; child advocacy; coculture; drug industry; drug marketing; drug research; Editorial; gene editing; induced pluripotent stem cell; law; machine learning; perinatal period; priority journal; publication; research ethics; drug development; human; newborn; organoid; perinatology},
	publisher = {W.B. Saunders},
	issn = {00955108},
	coden = {CLPED},
	pmid = {31010568},
	language = {English},
	abbrev_source_title = {Clin. Perinatol.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Linthicum2019214,
	author = {Linthicum, Kathryn P. and Schafer, Katherine Musacchio and Ribeiro, Jessica D.},
	title = {Machine learning in suicide science: Applications and ethics},
	year = {2019},
	journal = {Behavioral Sciences and the Law},
	volume = {37},
	number = {3},
	pages = {214 – 222},
	doi = {10.1002/bsl.2392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059535158&doi=10.1002%2fbsl.2392&partnerID=40&md5=b60b4f8f57321461b07f817b26ae06ac},
	affiliations = {Department of Psychology, Florida State University, Tallahassee, 32306-4301, FL, United States},
	abstract = {For decades, our ability to predict suicide has remained at near-chance levels. Machine learning has recently emerged as a promising tool for advancing suicide science, particularly in the domain of suicide prediction. The present review provides an introduction to machine learning and its potential application to open questions in suicide research. Although only a few studies have implemented machine learning for suicide prediction, results to date indicate considerable improvement in accuracy and positive predictive value. Potential barriers to algorithm integration into clinical practice are discussed, as well as attendant ethical issues. Overall, machine learning approaches hold promise for accurate, scalable, and effective suicide risk detection; however, many critical questions and issues remain unexplored. © 2019 John Wiley & Sons, Ltd.},
	keywords = {Algorithms; Cluster Analysis; Decision Support Techniques; Ethics, Medical; Humans; Longitudinal Studies; Machine Learning; Probability; Research; Risk Assessment; Suicide; Unsupervised Machine Learning; algorithm; cluster analysis; decision support system; ethics; human; legislation and jurisprudence; longitudinal study; machine learning; medical ethics; probability; research; risk assessment; suicide; unsupervised machine learning},
	correspondence_address = {J.D. Ribeiro; Department of Psychology, Florida State University, Tallahassee, 32306-4301, United States; email: ribeiro@psy.fsu.edu},
	publisher = {John Wiley and Sons Ltd},
	issn = {07353936},
	coden = {BSLAD},
	pmid = {30609102},
	language = {English},
	abbrev_source_title = {Behav. Sci. Law},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 66}
}

@ARTICLE{Zhang20192,
	author = {Zhang, Zihao and Bowes, Ben},
	title = {The future of artificial intelligence (AI) and machine learning (ML) in landscape design: A case study in Coastal Virginia, USA},
	year = {2019},
	journal = {Journal of Digital Landscape Architecture},
	volume = {2019},
	number = {4},
	pages = {2 – 9},
	doi = {10.14627/537663001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083506284&doi=10.14627%2f537663001&partnerID=40&md5=97a0136e4cc5da65e3fbd9089022eab4},
	affiliations = {University of Virginia, VA, United States},
	abstract = {There have been theory-based endeavours that directly engage with AI and ML in the landscape discipline. By presenting a case that uses machine learning techniques to predict variables in a coastal environment, this paper provides empirical evidence of the forthcoming cybernetic environ-ment, in which designers are conceptualized not as authors but as choreographers, catalyst agents, and conductors among many other intelligent agents. Drawing ideas from posthumanism, this paper argues that, to truly understand the cybernetic environment, we have to take on posthumanist ethics and over-come human exceptionalism. © Wichmann Verlag, VDE VERLAG GMBH · Berlin · Offenbach.},
	author_keywords = {Artificial intelligence; Cybernetics; Landscape design; Machine learning},
	publisher = {VDE VERLAG GMBH},
	issn = {23674253},
	language = {English},
	abbrev_source_title = {J. Digital Landsc. Arch.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Galbusera2019,
	author = {Galbusera, Fabio and Casaroli, Gloria and Bassani, Tito},
	title = {Artificial intelligence and machine learning in spine research},
	year = {2019},
	journal = {JOR Spine},
	volume = {2},
	number = {1},
	doi = {10.1002/jsp2.1044},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105832283&doi=10.1002%2fjsp2.1044&partnerID=40&md5=55eee3f77e2b911a17cfd437f3cdb312},
	affiliations = {Laboratory of Biological Structures Mechanics, IRCCS Istituto Ortopedico Galeazzi, Milan, Italy},
	abstract = {Artificial intelligence (AI) and machine learning (ML) techniques are revolutionizing several industrial and research fields like computer vision, autonomous driving, natural language processing, and speech recognition. These novel tools are already having a major impact in radiology, diagnostics, and many other fields in which the availability of automated solution may benefit the accuracy and repeatability of the execution of critical tasks. In this narrative review, we first present a brief description of the various techniques that are being developed nowadays, with special focus on those used in spine research. Then, we describe the applications of AI and ML to problems related to the spine which have been published so far, including the localization of vertebrae and discs in radiological images, image segmentation, computer-aided diagnosis, prediction of clinical outcomes and complications, decision support systems, content-based image retrieval, biomechanics, and motion analysis. Finally, we briefly discuss major ethical issues related to the use of AI in healthcare, namely, accountability, risk of biased decisions as well as data privacy and security, which are nowadays being debated in the scientific community and by regulatory agencies. © 2019 The Authors. JOR Spine published by Wiley Periodicals, Inc. on behalf of Orthopaedic Research Society},
	author_keywords = {artificial neural networks; deep learning; ethical implications; outcome prediction; segmentation},
	keywords = {artificial intelligence; artificial neural network; biomechanics; clinical decision support system; clinical outcome; decision tree; deep learning; gait; human; image processing; image retrieval; image segmentation; imaging; intervertebral disk; machine learning; medical ethics; motion; priority journal; Review; spine; support vector machine; vertebra},
	correspondence_address = {F. Galbusera; Laboratory of Biological Structures Mechanics, IRCCS Istituto Ortopedico Galeazzi, Milan, Italy; email: fabio.galbusera@grupposandonato.it},
	publisher = {John Wiley and Sons Inc},
	issn = {25721143},
	language = {English},
	abbrev_source_title = {JOR Spine},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 115; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Dray2019319,
	author = {Dray, Xavier and Leenhardt, Romain and Histace, Aymeric and Becq, Aymeric},
	title = {The brave new world of artificial intelligence for digestive endoscopy; [Intelligence artificielle et endoscopie: le meilleur des mondes ?]},
	year = {2019},
	journal = {Hepato-Gastro et Oncologie Digestive},
	volume = {26},
	number = {3},
	pages = {319 – 331},
	doi = {10.1684/hpg.2019.1754},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066083560&doi=10.1684%2fhpg.2019.1754&partnerID=40&md5=2a3ecd59a3a6c1fedb0c29e4da6e9966},
	affiliations = {Sorbonne Université and APHP, Hôpital Saint Antoine, 184, rue du Faubourg Saint-Antoine, Paris, 75012, France; ETIS, Université Paris-Seine, Université de Cergy-Pontoise, ENSEA, CNRS, Cergy-Pontoise, France},
	abstract = {Artificial intelligence (AI) aims to simulate the human intelligence. It is a cognitive science which relies on neurobiology, logical and critical thinking (problem solving, deep learning, neural networks), computing sciences (calculation, internet), and on databases. Big data exploitation (epidemiology, predictive medicine) and “signals” analysis (EKG, EEG, imaging, pathology, dermatology, ophthalmology. . .) were the first successful application of AI in healthcare, followed by government approval. AI has a vast spectrum of potential applications in digestive endoscopy as well. AI can be used for screening, diagnosis, characterization, treatment, and prognosis evaluation, in a wide array of procedures. The quantity of published work in this field is thriving. Computer-assisted detection and characterization of colonic polyps for instance, were amongst the first successful applications of AI, and should be commercially available shortly. The automated reading of a capsule endoscopy, based on a network of machine learning systems, is also very demonstrative of what AI will be able to accomplish in the next future. It is believed that AI will significantly improve diagnostic performances and thus the quality of care. Today, endoscopists should not only promote this technological revolution, but also address new issues in the field of AI, regarding the respective roles of physicians (focused on ethics and patient-relations) and AI-machines(assistants vs autonomous), as well as responsibility (physicians vs. manufacturing companies), and reimbursement(physician vs manufacturing companies). © 2019 John Libbey Eurotext. All rights reserved.},
	keywords = {artificial intelligence; colon polyp; computer assisted diagnosis; digestive endoscopy; endoscopy; human; machine learning; prognosis; Review},
	correspondence_address = {X. Dray; Sorbonne Université and APHP, Hôpital Saint Antoine, Paris, 184, rue du Faubourg Saint-Antoine, 75012, France; email: xavier.dray@aphp.fr},
	publisher = {John Libbey Eurotext},
	issn = {21153310},
	language = {French},
	abbrev_source_title = {Hepato-Gastro Oncol. Dig.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ure2019217,
	author = {Ure, Benno},
	title = {Esophageal atresia, Europe, and the future: BAPS Journal of Pediatric Surgery Lecture},
	year = {2019},
	journal = {Journal of Pediatric Surgery},
	volume = {54},
	number = {2},
	pages = {217 – 222},
	doi = {10.1016/j.jpedsurg.2018.10.071},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057988849&doi=10.1016%2fj.jpedsurg.2018.10.071&partnerID=40&md5=31cb54d36b473ee7fbc37881156b8945},
	affiliations = {Department of Pediatric Surgery, Hannover Medical School, Carl-Neuberg-Straße 130625, Hannover, Germany},
	abstract = {Europe has changed remarkably over the past decades and so have concepts and outcomes of esophageal atresia repair. In this article, both the efforts to create a united Europe and the achievements in dealing with esophageal atresia from the 1950s on are outlined. Furthermore, this paper deals with the future of pediatric surgery and is focused on two aspects: the “Fourth Industrial Revolution” which builds on the digital revolution, artificial intelligence and robotics, and its potential impact on pediatric surgery and the life of patients. I suggest that pediatric surgeons should participate and lead in the development of machine learning, data control, assuring appropriate use of machines, control misuse, and in particular ensure appropriate maintenance of ethical standards. Changes in health care structures within Europe, in particular the effect of centralization, will affect the concept of treatment for patients with rare diseases. © 2018},
	author_keywords = {Esophageal atresia; History of surgery},
	keywords = {Delivery of Health Care; Esophageal Atresia; Europe; History, 20th Century; History, 21st Century; Humans; Internationality; Rare Diseases; anastomosis; anesthesiologist; artificial intelligence; atmosphere; centralization; cognition; community care; economics; endoscopy; esophagus atresia; ethics; Europe; evaluation and follow up; facilitated communication; gastroesophageal reflux; government; graft survival; health care; health program; histopathology; human; hydronephrosis; laparoscopy; literature; liver transplantation; machine learning; mortality; outcome assessment; pediatric surgery; politics; portoenterostomy; Review; scientific literature; surgical technique; survival rate; technology; thoracoscopy; esophagus atresia; Europe; health care delivery; history; international cooperation; organization and management; rare disease; trends},
	correspondence_address = {B. Ure; Department of Pediatric Surgery, Hannover Medical School, Hannover, Carl-Neuberg-Straße 130625, Germany; email: ure.benno@mh-hannover.de},
	publisher = {W.B. Saunders},
	issn = {00223468},
	coden = {JPDSA},
	pmid = {30545729},
	language = {English},
	abbrev_source_title = {J. Pediatr. Surg.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Cho2019e85,
	author = {Cho, Soo Ick and Na, Jung-Im and Han, Seung Seog and Chung, Jin Ho},
	title = {Comment on “Just a quick pic: Ethics of medical photography:” Generative adversarial networks could be a solution},
	year = {2019},
	journal = {Journal of the American Academy of Dermatology},
	volume = {81},
	number = {3},
	pages = {e85 – e86},
	doi = {10.1016/j.jaad.2019.05.074},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070542354&doi=10.1016%2fj.jaad.2019.05.074&partnerID=40&md5=c48b02fc52def1e27bcc765d8aa3808a},
	affiliations = {Department of Dermatology, Seoul National University College of Medicine, Seoul, South Korea; Department of Dermatology, Seoul National University Bundang Hospital, Seongnam, South Korea; I Dermatology Clinic, Seoul, South Korea},
	keywords = {Image Processing, Computer-Assisted; Photography; Physical Examination; deep learning; dermatologist; generative adversarial network; human; learning algorithm; Letter; machine learning; medical ethics; medical photography; priority journal; image processing; photography; physical examination},
	correspondence_address = {J.H. Chung; Department of Dermatology, Seoul National University Hospital, Seoul, 101 Daehak-ro, Jongno-gu, South Korea; email: jhchung@snu.ac.kr},
	publisher = {Mosby Inc.},
	issn = {01909622},
	coden = {JAADD},
	pmid = {31163239},
	language = {English},
	abbrev_source_title = {J. Am. Acad. Dermatol.},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@CONFERENCE{Chandak2019,
	author = {Chandak, Trupti and Ghorpade, Chaitanya and Shukla, Sanyam},
	title = {Effective Analysis of Feature Selection Algorithms for Network based Intrusion Detection System},
	year = {2019},
	journal = {2019 IEEE Bombay Section Signature Conference, IBSSC 2019},
	volume = {2019January},
	doi = {10.1109/IBSSC47189.2019.8973103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084458802&doi=10.1109%2fIBSSC47189.2019.8973103&partnerID=40&md5=9562e401380185f9617501a1aefe3558},
	affiliations = {Computer Science and Engineering, MANIT, Bhopal, 462003, India},
	abstract = {Malicious activities can harm the security of the system. These activities must be avoided. Network traffic data can be monitored and analyzed by using intrusion detection system. Different data mining classification techniques are used to detect network attacks. Dimensionality reduction performs key role in the Intrusion Detection System, since detecting anomalies is time-consuming. Recently a lot of work has been done in feature selection. But, most of the authors have modified the KDD99 test dataset. Modification of training dataset is valid but modifying test dataset is against the machine learning ethics. This work comprises some of the recently proposed feature selection algorithm such as Information gain, Gain Ratio and Correlation-based feature selection with the objective of determining the reduced feature set. The performance is evaluated using a combination of any two feature selection technique. This study proposes a new heuristic based feature selection algorithm using naive Bayes classifier to detect the important reduced feature set. The results are evaluated on c4.5 decision tree classifier and the results are compared with the existing works. The evaluated results show that the proposed reduced feature set gives the effective and efficient performance. © 2019 IEEE.},
	author_keywords = {c4.5 Decision tree; Feature Reduction; Intrusion Detection System (IDS); KDD99 Dataset; Naive Bayes Classifier},
	keywords = {Classification (of information); Classifiers; Computer crime; Data mining; Decision trees; Dimensionality reduction; Intrusion detection; Learning systems; Statistical tests; C4.5 Decision tree classifier; Feature selection algorithm; Intrusion Detection Systems; Malicious activities; Mining classification; Naive Bayes classifiers; Network based intrusion detection systems; Selection techniques; Feature extraction},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153867401-7},
	language = {English},
	abbrev_source_title = {IEEE Bombay Sect. Signat. Conf., IBSSC},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2019 IEEE Bombay Section Signature Conference, IBSSC 2019; Conference date: 26 July 2019 through 28 July 2019; Conference code: 157291}
}

@CONFERENCE{Barbosa2019,
	author = {Barbosa, Natã M. and Chen, Monchu},
	title = {Rehumanized crowdsourcing: A labeling framework addressing bias and ethics in machine learning},
	year = {2019},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3290605.3300773},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067622552&doi=10.1145%2f3290605.3300773&partnerID=40&md5=c9dab544fc18197c690b69327c2e4d44},
	affiliations = {Syracuse University, Syracuse, 13244, NY, United States; Figure Eight Inc, San Francisco, 94103, CA, United States},
	abstract = {The increased use of machine learning in recent years led to large volumes of data being manually labeled via crowdsourcing microtasks completed by humans. This brought about dehumanization efects, namely, when task requesters overlook the humans behind the task, leading to issues of ethics (e.g., unfair payment) and amplifcation of human biases, which are transferred into training data and afect machine learning in the real world. We propose a framework that allocates microtasks considering human factors of workers such as demographics and compensation. We deployed our framework to a popular crowdsourcing platform and conducted experiments with 1,919 workers collecting 160,345 human judgments. By routing microtasks to workers based on demographics and appropriate pay, our framework mitigates biases in the contributor sample and increases the hourly pay given to contributors. We discuss potential extensions and how it can promote transparency in crowdsourcing. © 2019 Association for Computing Machinery.},
	author_keywords = {Bias; Crowdsourcing; Ethics; Machine learning},
	keywords = {Human computer interaction; Human engineering; Learning systems; Machine learning; Philosophical aspects; Population statistics; Bias; Crowdsourcing platforms; Ethics; Human bias; Human judgments; Large volumes; Real-world; Training data; Crowdsourcing},
	publisher = {Association for Computing Machinery},
	isbn = {978-145035970-2},
	language = {English},
	abbrev_source_title = {Conf Hum Fact Comput Syst Proc},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 46; Conference name: 2019 CHI Conference on Human Factors in Computing Systems, CHI 2019; Conference date: 4 May 2019 through 9 May 2019; Conference code: 147770}
}

@ARTICLE{Shaw2019,
	author = {Shaw, James and Rudzicz, Frank and Jamieson, Trevor and Goldfarb, Avi},
	title = {Artificial Intelligence and the Implementation Challenge},
	year = {2019},
	journal = {Journal of Medical Internet Research},
	volume = {21},
	number = {7},
	doi = {10.2196/13659},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069551590&doi=10.2196%2f13659&partnerID=40&md5=93d1414c9b5bc483b20ef58d9df41fb4},
	affiliations = {Women's College Hospital, Institute for Health System Solutions and Virtual Care, 76 Grenville Street, Toronto, M5G2A2, ON, Canada; Joint Centre for Bioethics, University of Toronto, Toronto, ON, Canada; International Centre for Surgical Safety, Li Ka Shing Knowledge Institute, St Michael's Hospital, Toronto, ON, Canada; St Michael's Hospital, Toronto, ON, Canada; Rotman School of Management, University of Toronto, Toronto, ON, Canada},
	abstract = {Background: Applications of artificial intelligence (AI) in health care have garnered much attention in recent years, but the implementation issues posed by AI have not been substantially addressed. Objective: In this paper, we have focused on machine learning (ML) as a form of AI and have provided a framework for thinking about use cases of ML in health care. We have structured our discussion of challenges in the implementation of ML in comparison with other technologies using the framework of Nonadoption, Abandonment, and Challenges to the Scale-Up, Spread, and Sustainability of Health and Care Technologies (NASSS). Methods: After providing an overview of AI technology, we describe use cases of ML as falling into the categories of decision support and automation. We suggest these use cases apply to clinical, operational, and epidemiological tasks and that the primary function of ML in health care in the near term will be decision support. We then outline unique implementation issues posed by ML initiatives in the categories addressed by the NASSS framework, specifically including meaningful decision support, explainability, privacy, consent, algorithmic bias, security, scalability, the role of corporations, and the changing nature of health care work. Results: Ultimately, we suggest that the future of ML in health care remains positive but uncertain, as support from patients, the public, and a wide range of health care stakeholders is necessary to enable its meaningful implementation. Conclusions: If the implementation science community is to facilitate the adoption of ML in ways that stand to generate widespread benefits, the issues raised in this paper will require substantial attention in the coming years. © 2019 Linda Tizek, Maximilian Schielein, Melvin Ruth, Sonja Stander, Manuel Pedro Pereira, Bernadette Eberlein, Tilo Biedermann, Alexander Zink. Originally published in the Journal of Medical Internet Research (http://www.jmir.org), 14.07.2019.},
	author_keywords = {Artificial intelligence; Ethics; Implementation science; Machine learning},
	keywords = {Artificial Intelligence; Humans; Machine Learning; Telemedicine; adoption; adult; artificial intelligence; attention; automation; case report; clinical article; decision support system; ethics; female; human; implementation science; machine learning; male; privacy; review; scale up; thinking; artificial intelligence; machine learning; procedures; telemedicine},
	correspondence_address = {J. Shaw; Women's College Hospital, Institute for Health System Solutions and Virtual Care, Toronto, 76 Grenville Street, M5G2A2, Canada; email: jay.shaw@wchospital.ca},
	publisher = {JMIR Publications Inc.},
	issn = {14388871},
	pmid = {31293245},
	language = {English},
	abbrev_source_title = {J. Med. Internet Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 111; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Jaremko2019107,
	author = {Jaremko, Jacob L. and Azar, Marleine and Bromwich, Rebecca and Lum, Andrea and Alicia Cheong, Li Hsia and Gibert, Martin and Laviolette, François and Gray, Bruce and Reinhold, Caroline and Cicero, Mark and Chong, Jaron and Shaw, James and Rybicki, Frank J. and Hurrell, Casey and Lee, Emil and Tang, An},
	title = {Canadian Association of Radiologists White Paper on Ethical and Legal Issues Related to Artificial Intelligence in Radiology},
	year = {2019},
	journal = {Canadian Association of Radiologists Journal},
	volume = {70},
	number = {2},
	pages = {107 – 118},
	doi = {10.1016/j.carj.2019.03.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063882867&doi=10.1016%2fj.carj.2019.03.001&partnerID=40&md5=d4ac0a6228c9d094a4312a377136c898},
	affiliations = {Department of Radiology and Diagnostic Imaging, University of Alberta, Edmonton, Alberta, Canada; Department of Medicine, Université de Montréal, Montréal, Quebec, Canada; Department of Law and Legal Studies, Carleton University, Ottawa, Canada; Department of Medical Imaging, Western University, London, Ontario, Canada; Department of Medical Imaging, University of Toronto, Toronto, Ontario, Canada; Centre de recherche en éthique, Université de Montréal, Montréal, Quebec, Canada; Department of Computer Science, Université Laval, Québec, Quebec, Canada; Department of Medical Imaging, St Michael's Hospital, University of Toronto, Toronto, Ontario, Canada; Department of Radiology, McGill University Health Center, Montreal, Quebec, Canada; 16 Bit Inc., Toronto, Ontario, Canada; Institute for Health System Solutions and Virtual Care, Women's College Hospital, Toronto, Ontario, Canada; Department of Radiology, The University of Ottawa Faculty of Medicine and The Ottawa Hospital Research Institute, Ottawa, Ontario, Canada; Imagia Cybernetics, Montreal, Quebec, Canada; Canadian Association of Radiologists, Ottawa, Ontario, Canada; Department of Radiology, Valley Medical Imaging, Langley, British Columbia, Canada; Department of Medical Imaging, Fraser Health Authority, British Columbia, Canada; Department of Radiology, Radio-oncology, and Nuclear Medicine, Université de Montréal, Montréal, Quebec, Canada},
	abstract = {Artificial intelligence (AI) software that analyzes medical images is becoming increasingly prevalent. Unlike earlier generations of AI software, which relied on expert knowledge to identify imaging features, machine learning approaches automatically learn to recognize these features. However, the promise of accurate personalized medicine can only be fulfilled with access to large quantities of medical data from patients. This data could be used for purposes such as predicting disease, diagnosis, treatment optimization, and prognostication. Radiology is positioned to lead development and implementation of AI algorithms and to manage the associated ethical and legal challenges. This white paper from the Canadian Association of Radiologists provides a framework for study of the legal and ethical issues related to AI in medical imaging, related to patient data (privacy, confidentiality, ownership, and sharing); algorithms (levels of autonomy, liability, and jurisprudence); practice (best practices and current legal framework); and finally, opportunities in AI from the perspective of a universal health care system. © 2019 The Authors},
	author_keywords = {Artificial intelligence; Ethics; Imaging; Legal; Machine learning; Radiology},
	keywords = {Artificial Intelligence; Canada; Humans; Practice Guidelines as Topic; Radiologists; Radiology; Societies, Medical; anonymization; artificial intelligence; Canadian; computer security; ethics; health care system; human; identifiable information; legal aspect; machine learning; medical society; patent; patient coding; personalized medicine; practice guideline; public health service; radiologist; radiology; radiology department; Review; social acceptance; artificial intelligence; Canada; legislation and jurisprudence; radiology},
	correspondence_address = {A. Tang; Montreal, 1051, rue Sanguinet, H2X 0C1, Canada; email: an.tang@umontreal.ca},
	publisher = {Canadian Medical Association},
	issn = {08465371},
	coden = {JCARA},
	pmid = {30962048},
	language = {English},
	abbrev_source_title = {Can. Assoc. Radiol. J.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 75; All Open Access, Bronze Open Access}
}

@ARTICLE{Griffiths20199,
	author = {Griffiths, Catherine},
	title = {Computational visualization for critical thinking},
	year = {2019},
	journal = {Journal of Science and Technology of the Arts},
	volume = {11},
	number = {2 Special Issue},
	pages = {9 – 17},
	doi = {10.7559/citarj.v11i2.666},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85078736520&doi=10.7559%2fcitarj.v11i2.666&partnerID=40&md5=4d03e8aa3f4f5d0b07b266019e37821f},
	affiliations = {School of Cinematic Arts, University of Southern California, Los Angeles, United States},
	abstract = {This paper looks at several historical precedents for how computational systems and ideas have been visualized, both as a means of access to and engagement with a broader audience, and to develop a more tangible language to address abstraction. Such precedents share a subversive ground in using a visual language to provoke ways of engaging with complex ideas. The author proposes two approaches to visualizing algorithmic systems for the emerging context of algorithmic ethics in society, looking at prototypical algorithms in computer vision and machine learning systems, to think through the meaning created by algorithmic structure and process. The aim is to use visual design to provoke different kinds of thinking and criticality to address algorithms in their increasingly more politicized role today. The two proposed approaches are developed from an arts research perspective to support critical thinking and arts knowledge through creative coding and interactive design. © 2019, Universidade Catolica Portuguesa. All rights reserved.},
	author_keywords = {Computation; Computer vision; Critical technologies; Ethics; Machine learning; Precedent studies; Surveillance; Visualization},
	correspondence_address = {C. Griffiths; School of Cinematic Arts, University of Southern California, Los Angeles, United States; email: griffitc@usc.edu},
	publisher = {Universidade Catolica Portuguesa},
	issn = {16469798},
	language = {English},
	abbrev_source_title = {J. Sci. Technol.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Kanuck20193,
	author = {Kanuck, Sean},
	title = {Humor, ethics, and dignity: Being human in the age of artificial intelligence},
	year = {2019},
	journal = {Ethics and International Affairs},
	volume = {33},
	number = {1},
	pages = {3 – 12},
	doi = {10.1017/S0892679418000928},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062674562&doi=10.1017%2fS0892679418000928&partnerID=40&md5=1d1de6b46427e79231e402e671e9791c},
	affiliations = {Hoover Institution, Center for International Security and Cooperation, Stanford University, United States},
	abstract = {The growing adoption of artificial intelligence (AI) raises questions about what comparative advantage, if any, human beings will have over machines in the future. This essay explores what it means to be human and how those unique characteristics relate to the digital age. Humor and ethics both rely upon higher-level cognition that accounts for unstructured and unrelated data. That capability is also vital to decision-making processes—such as jurisprudence and voting systems. Since machine learning algorithms lack the ability to understand context or nuance, reliance on them could lead to undesired results for society. By way of example, two case studies are used to illustrate the legal and moral considerations regarding the software algorithms used by driverless cars and lethal autonomous weapons systems. Social values must be encoded or introduced into training data sets if AI applications are to be expected to produce results similar to a “human in the loop.” There is a choice to be made, then, about whether we impose limitations on these new technologies in favor of maintaining human control, or whether we seek to replicate ethical reasoning and lateral thinking in the systems we create. The answer will have profound effects not only on how we interact with AI but also on how we interact with one another and perceive ourselves. Copyright © Carnegie Council for Ethics in International Affairs 2019Â.},
	author_keywords = {Artificial intelligence; Dignity; Driverless cars; Ethics; Human rights; Humor; Law; Lethal autonomous weapons; Philippa Foot; Philosophy},
	correspondence_address = {S. Kanuck; Hoover Institution, Center for International Security and Cooperation, Stanford University, United States; email: sean@kanuck.comd},
	publisher = {Cambridge University Press},
	issn = {08926794},
	language = {English},
	abbrev_source_title = {Ethics Int. Aff.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Krishna2019,
	author = {Krishna, Ragil and Pathirana, Pubudu N. and Horne, Malcolm and Power, Laura and Szmulewicz, David J.},
	title = {Quantitative assessment of cerebellar ataxia, through automated limb functional tests},
	year = {2019},
	journal = {Journal of NeuroEngineering and Rehabilitation},
	volume = {16},
	number = {1},
	doi = {10.1186/s12984-019-0490-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062326202&doi=10.1186%2fs12984-019-0490-3&partnerID=40&md5=220c39f8ac0df2d5801710317b788d72},
	affiliations = {School of Engineering, Deakin University, Waurn Ponds, 3216, Australia; Florey Institute of Neuroscience and Mental Health, Parkville, 3052, Australia; Balance Disorders and Ataxia Service, Royal Victorian Eye and Ear Hospital, St Andrews Place, East Melbourne, 3002, Australia; Cerebellar Ataxia Clinic, Caufield Hospital, Alfred Health, Caufield, 3162, Australia},
	abstract = {Background: Cerebellar damage can often result in disabilities affecting the peripheral regions of the body. These include poor and inaccurate coordination, tremors and irregular movements that often manifest as disorders associated with balance, gait and speech. The severity assessment of Cerebellar ataxia (CA) is determined by expert opinion and is likely to be subjective in nature. This paper investigates automated versions of three commonly used tests: Finger to Nose test (FNT), test for upper limb Dysdiadochokinesia Test (DDK) and Heel to Shin Test (HST), in evaluating disability due to CA. Methods: Limb movements associated with these tests are measured using Inertial Measurement Units (IMU) to capture the disability. Kinematic parameters such as acceleration, velocity and angle are considered in both time and frequency domain in three orthogonal axes to obtain relevant disability related information. The collective dominance in the data distributions of the underlying features were observed though the Principal Component Analysis (PCA). The dominant features were combined to substantiate the correlation with the expert clinical assessments through Linear Discriminant Analysis. Here, the Pearson correlation is used to examine the relationship between the objective assessments and the expert clinical scores while the performance was also verified by means of cross validation. Results: The experimental results show that acceleration is a major feature in DDK and HST, whereas rotation is the main feature responsible for classification in FNT. Combining the features enhanced the correlations in each domain. The subject data was classified based on the severity information based on expert clinical scores. Conclusion: For the predominantly translational movement in the upper limb FNT, the rotation captures disability and for the DDK test with predominantly rotational movements, the linear acceleration captures the disability but cannot be extended to the lower limb HST. The orthogonal direction manifestation of ataxia attributed to sensory measurements was determined for each test. Trial registration: Human Research and Ethics Committee, Royal Victorian Eye and Ear Hospital, East Melbourne, Australia (HREC Reference Number: 11/994H/16). © 2019 The Author(s).},
	author_keywords = {Diadochokinesia (DDK); Fast fourier transforms (FFT); Finger-to-nose (FNT); Heel shin test (HST); Principal component analysis (PCA)},
	keywords = {Acceleration; Accelerometry; Adult; Aged; Aged, 80 and over; Automation; Biomechanical Phenomena; Cerebellar Ataxia; Disability Evaluation; Discriminant Analysis; Female; Humans; Lower Extremity; Male; Middle Aged; Movement; Principal Component Analysis; Reproducibility of Results; Upper Extremity; acceleration; adult; aged; Article; automation; cerebellar ataxia; clinical assessment; clinical feature; cohort analysis; controlled study; correlation coefficient; data analysis; discriminant analysis; Dysdiadochokinesia Test; female; Finger to Nose test; functional status assessment; Heel to Shin Test; human; Inertial Measurement Unit; kinematics; limb movement; machine learning; major clinical study; male; neurologic examination; principal component analysis; priority journal; quantitative analysis; time; velocity; accelerometry; biomechanics; cerebellar ataxia; disability; lower limb; middle aged; movement (physiology); pathophysiology; reproducibility; upper limb; very elderly},
	correspondence_address = {R. Krishna; School of Engineering, Deakin University, Waurn Ponds, 3216, Australia; email: ragi@deakin.edu.au},
	publisher = {BioMed Central Ltd.},
	issn = {17430003},
	pmid = {30813963},
	language = {English},
	abbrev_source_title = {J. NeuroEng. Rehabil.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Koimizu2019,
	author = {Koimizu, Jungen and Numajiri, Toshiaki and Kato, Kazuto},
	title = {Machine Learning and Ethics in Plastic Surgery},
	year = {2019},
	journal = {Plastic and Reconstructive Surgery - Global Open},
	volume = {7},
	number = {3},
	doi = {10.1097/GOX.0000000000002162},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85073728841&doi=10.1097%2fGOX.0000000000002162&partnerID=40&md5=b40b93833d45179ee47f10d846ea7a0c},
	affiliations = {Department of Plastic Surgery, Kyoto Prefectural University of Medicine, 465 Kajii-cho, Kamigyo-ku, Kyoto, Japan; Department of Biomedical Ethics and Public Policy, Graduate Schools of Medicine, Osaka University, Suita, Japan},
	publisher = {Lippincott Williams and Wilkins},
	issn = {21697574},
	language = {English},
	abbrev_source_title = {Plast. Reconstr. Surg., Glob. Open},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Domanski2019409,
	author = {Domanski, Robert J.},
	title = {The A.I. Pandorica: Linking Ethically-challenged Technical Outputs to Prospective Policy Approaches},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {409 – 416},
	doi = {10.1145/3325112.3325267},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068603110&doi=10.1145%2f3325112.3325267&partnerID=40&md5=4904c9a2d285df73453cc1be88ab126b},
	affiliations = {City of New York, New York, NY, United States},
	abstract = {Artificial intelligence increasingly drives the modern world. Its rapid and continuous integration into the economic and political fabric of societies across the globe has placed the ethical challenges associated with A.I. onto national political agendas. This paper will deconstruct both the technical and regulatory challenges wrought by A.I. through an ethical lens. By providing a brief overview of how modern A.I. works, and defining and mapping its associated ethical issues to specific technical outputs, this paper will explore several promising paths forward. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Algorithmic bias; Artificial intelligence; Digital government; Ethics; Machine learning},
	keywords = {Artificial intelligence; Ethical aspects; Learning systems; Philosophical aspects; Algorithmic bias; Continuous integrations; Digital government; Ethical issues; Policy approach; Political agenda; Machine learning},
	correspondence_address = {R.J. Domanski; City of New York, New York, United States; email: robert.domanski@cuny.edu},
	editor = {Chen Y.-C. and Salem F. and Zuiderwijk A.},
	publisher = {Association for Computing Machinery},
	isbn = {978-145037204-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 20th Annual International Conference on Digital Government Research: Governance in the Age of Artificial Intelligence, dg.o 2019; Conference date: 18 June 2019 through 20 June 2019; Conference code: 148822}
}

@ARTICLE{Hauer2019222,
	author = {Hauer, Tomas},
	title = {Society Caught in a Labyrinth of Algorithms: Disputes, Promises, and Limitations of the New Order of Things},
	year = {2019},
	journal = {Society},
	volume = {56},
	number = {3},
	pages = {222 – 230},
	doi = {10.1007/s12115-019-00358-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067940915&doi=10.1007%2fs12115-019-00358-5&partnerID=40&md5=8d49f229f9cfc9041418f6b1c32954f2},
	affiliations = {Department of Social Sciences, VSB - Technical University of Ostrava, 17 November 15/2172, Ostrava, 708 33, Poruba, Czech Republic},
	abstract = {We are in the interim of the massive expansion of the new and fundamental technology, which is represented by the advanced algorithms of AI. No one knows the real potential of machine learning and AI. Letting the algorithms drive autonomous vehicles (driverless cars) is like running the Boston Marathon. Creating an ethically completely autonomous AI system is like a piloted flight to Alpha Centauri. Nevertheless, we still live in the world of algorithms. Today there are algorithms in every corner of civilization, as quantum fluctuations they are integrally interwoven into the structure of everyday life. They are not just in your mobile phone or laptop. Algorithms plan flights and then fly with planes. Algorithms run factories, the bank is a vast array of algorithms, evaluating our credit score, algorithms collect revenue and keep records, read medical images, diagnose cancer, drive cars, write scientific texts, compose music, conduct symphony orchestras, navigate drones, speak to us and for us, write film scenarios, invent chemical formulations for a new cosmetic cream, order, advise, paint pictures. Climate models decide what is a safe carbon dioxide level in the atmosphere, NSA algorithms decide whether you are a potential terrorist. If every algorithm suddenly stopped working, it would be the end of the world as we know it. How did this new alliance, this interim world come into existence, does it suit us, and how and where will it develop? What AI algorithms have shown and offered to us so far is just a prelude, and even today it turns out that politics, ethics and law do not know what to do with the consequences of these changes. However, when we experience computer control by a mere idea, complex genetic modifications, and DNA enhancement using CRISPR, or perhaps flying cars, we can expect real challenges related to the power of algorithms. Then AI ​​algorithms will really transform everything. The study analyzes the social contradictions, promises and limitations associated with how the desire to move higher on technological prominence in the realm of artificial intelligence faces the ethical, legal and political barriers of the existing order of things. © 2019, Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Algorithm; Autonomous AI system; Big data; Driverless cars; Ethical issues of AI; Existing order of things; Machine learning},
	correspondence_address = {T. Hauer; Department of Social Sciences, VSB - Technical University of Ostrava, Ostrava, 17 November 15/2172, 708 33, Czech Republic; email: tomas.hauer@vsb.cz},
	publisher = {Springer New York LLC},
	issn = {01472011},
	language = {English},
	abbrev_source_title = {Society},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Jalal201910,
	author = {Jalal, Sabeena and Nicolaou, Savvas and Parker, William},
	title = {Artificial Intelligence, Radiology, and the Way Forward},
	year = {2019},
	journal = {Canadian Association of Radiologists Journal},
	volume = {70},
	number = {1},
	pages = {10 – 12},
	doi = {10.1016/j.carj.2018.09.004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060454604&doi=10.1016%2fj.carj.2018.09.004&partnerID=40&md5=7c023a4747ef59084c2859b94b9412fe},
	affiliations = {Department of Radiology, University of British Columbia, Vancouver, British Columbia, Canada},
	author_keywords = {Artificial intelligence and ethics; Artificial intelligence and future; Artificial intelligence and way forward},
	keywords = {Artificial Intelligence; Humans; Radiology; algorithm; Article; artificial intelligence; computer assisted tomography; diagnostic accuracy; differential diagnosis; emergency ward; health care system; human; machine learning; mammography; nuclear magnetic resonance imaging; patient care; radiology; screening test; thorax radiography; procedures; radiology},
	correspondence_address = {S. Jalal; Department of Radiology, Vancouver General Hospital, Vancouver, 899 W 12th Ave, V5Z 1M9, Canada; email: sjalalkhan@yahoo.com},
	publisher = {Canadian Medical Association},
	issn = {08465371},
	coden = {JCARA},
	pmid = {30691556},
	language = {English},
	abbrev_source_title = {Can. Assoc. Radiol. J.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Bronze Open Access}
}

@CONFERENCE{Croeser2019423,
	author = {Croeser, Sky and Eckersley, Peter},
	title = {Theories of parenting and their application to artificial intelligence},
	year = {2019},
	journal = {AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {423 – 428},
	doi = {10.1145/3306618.3314231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070588828&doi=10.1145%2f3306618.3314231&partnerID=40&md5=57ce3774c532f2dd19d92ec8b94cb0c3},
	affiliations = {Internet Studies, Curtin University, Australia; Partnership on AI and EFF},
	abstract = {As machine learning (ML) systems have advanced, they have acquired more power over humans' lives, and questions about what values are embedded in them have become more complex and fraught. It is conceivable that in the coming decades, humans may succeed in creating artificial general intelligence (AGI) that thinks and acts with an open-endedness and autonomy comparable to that of humans. The implications would be profound for our species; they are now widely debated not just in science fiction and speculative research agendas but increasingly in serious technical and policy conversations. Much work is underway to try to weave ethics into advancing ML research. We think it useful to add the lens of parenting to these efforts, and specifically radical, queer theories of parenting that consciously set out to nurture agents whose experiences, objectives and understanding of the world will necessarily be very different from their parents'. We propose a spectrum of principles which might underpin such an effort; some are relevant to current ML research, while others will become more important if AGI becomes more likely. These principles may encourage new thinking about the development, design, training, and release into the world of increasingly autonomous agents. © 2019 Copyright is held by the owner/author(s).},
	keywords = {Artificial intelligence; Embedded systems; Philosophical aspects; Artificial general intelligences; Research agenda; Science fictions; Autonomous agents},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036324-2},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; Conference name: 2nd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2019; Conference date: 27 January 2019 through 28 January 2019; Conference code: 149526; All Open Access, Green Open Access}
}

@BOOK{García20191,
	author = {García, Oscar A. and Kotturi, Prashanth},
	title = {Information and Communication Technologies for Development Evaluation: World Bank Series on Evaluation and Development, Volume 10},
	year = {2019},
	journal = {Information and Communication Technologies for Development Evaluation: World Bank Series on Evaluation and Development, Volume 10},
	pages = {1 – 157},
	doi = {10.4324/9780429028236},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85128026665&doi=10.4324%2f9780429028236&partnerID=40&md5=e8275914675b12b9de42ac1db711c563},
	abstract = {Written by a team of expert practitioners at the Independent Office of Evaluation of International Fund for Agricultural Development (IFAD), this book gives an insight into the implications of new and emerging technologies in development evaluation. Growing technologies such as big data analytics, machine learning and remote sensing present new opportunities for development practitioners and development evaluators, particularly when measuring indicators of the Sustainable Development Goals. The volume provides an overview of information and communication technologies (ICTs) in the context of evaluation, looking at the theory and practice, and discussing how the landscape may unfold. It also considers concerns about privacy, ethics and inclusion, which are crucial issues for development practitioners and evaluators working in the interests of vulnerable populations across the globe. Among the contributions are case studies of seven organizations using various technologies for data collection, analysis, dissemination and learning. This valuable insight into practice will be of interest to researchers, practitioners and policymakers in development economics, development policy and ICT. © 2020 selection and editorial matter, Oscar A. García and Prashanth Kotturi. All rights reserved.},
	publisher = {Taylor and Francis},
	isbn = {978-042965054-3; 978-036713714-4},
	language = {English},
	abbrev_source_title = {Inf. and Commun. Technol. for Dev. Eval.: World Bank Ser. on Eval. and Dev., Vol. 10},
	type = {Book},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Skobe20193,
	author = {Skobe, Catherine},
	title = {Ethical obligations in an innovative world},
	year = {2019},
	journal = {Current Medical Research and Opinion},
	volume = {35},
	number = {sup2},
	pages = {3 – 4},
	doi = {10.1080/03007995.2019.1580486},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064541940&doi=10.1080%2f03007995.2019.1580486&partnerID=40&md5=0b1373396d885cba4c427f928dce09a9},
	affiliations = {International Society for Medical Publication Professionals (ISMPP), Tarrytown, NY, United States},
	keywords = {big data; creativity; Editorial; human; machine learning; medical research; open access publishing; publication; research ethics; responsibility; scientific literature; treatment outcome},
	correspondence_address = {C. Skobe; Chair, ISMPP Board of Trustees (2019–2020), International Society for Medical Publication Professionals (ISMPP), Tarrytown, 8 Fabian Place 520 White Plains Road, Suite 500, 10591, United States; email: Catherine.Skobe@pfizer.com},
	publisher = {Taylor and Francis Ltd},
	issn = {03007995},
	coden = {CMROC},
	pmid = {30982365},
	language = {English},
	abbrev_source_title = {Curr. Med. Res. Opin.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Millar2019,
	author = {Millar, Lindsay and McConnachie, Alex and Minnis, Helen and Wilson, Philip and Thompson, Lucy and Anzulewicz, Anna and Sobota, Krzysztof and Rowe, Philip and Gillberg, Christopher and Delafield-Butt, Jonathan},
	title = {Phase 3 diagnostic evaluation of a smart tablet serious game to identify autism in 760 children 3-5 years old in Sweden and the United Kingdom},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {7},
	doi = {10.1136/bmjopen-2018-026226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069521298&doi=10.1136%2fbmjopen-2018-026226&partnerID=40&md5=2d09d821ccd5a69c0d3ab42b380c3131},
	affiliations = {Laboratory for Innovation in Autism, University of Strathclyde, Glasgow, United Kingdom; Biomedical Engineering, University of Strathclyde, Glasgow, United Kingdom; Robertson Centre for Biostatistics, University of Glasgow, Glasgow, United Kingdom; Mental Health and Wellbeing, University of Glasgow, Glasgow, United Kingdom; Centre for Rural Health, University of Aberdeen, Aberdeen, United Kingdom; Gillberg Neuropsychiatry Centre, Sahlgrenska Academy, University of Gothenburg, Gothenburg, Sweden; Harimata Sp. Z O.o., Kraków, Poland},
	abstract = {Introduction Recent evidence suggests an underlying movement disruption may be a core component of autism spectrum disorder (ASD) and a new, accessible early biomarker. Mobile smart technologies such as iPads contain inertial movement and touch screen sensors capable of recording subsecond movement patterns during gameplay. A previous pilot study employed machine learning analysis of motor patterns recorded from children 3-5 years old. It identified those with ASD from age-matched and gender-matched controls with 93% accuracy, presenting an attractive assessment method suitable for use in the home, clinic or classroom. Methods and analysis This is a phase III prospective, diagnostic classification study designed according to the Standards for Reporting Diagnostic Accuracy Studies guidelines. Three cohorts are investigated: children typically developing (TD); children with a clinical diagnosis of ASD and children with a diagnosis of another neurodevelopmental disorder (OND) that is not ASD. The study will be completed in Glasgow, UK and Gothenburg, Sweden. The recruitment target is 760 children (280 TD, 280 ASD and 200 OND). Children play two games on the iPad then a third party data acquisition and analysis algorithm (Play.Care, Harimata) will classify the data as positively or negatively associated with ASD. The results are blind until data collection is complete, when the algorithm's classification will be compared against medical diagnosis. Furthermore, parents of participants in the ASD and OND groups will complete three questionnaires: Strengths and Difficulties Questionnaire; Early Symptomatic Syndromes Eliciting Neurodevelopmental Clinical Examinations Questionnaire and the Adaptive Behavioural Assessment System-3 or Vineland Adaptive Behavior Scales-II. The primary outcome measure is sensitivity and specificity of Play.Care to differentiate ASD children from TD children. Secondary outcomes measures include the accuracy of Play.Care to differentiate ASD children from OND children. Ethics and dissemination This study was approved by the West of Scotland Research Ethics Service Committee 3 and the University of Strathclyde Ethics Committee. Results will be disseminated in peer-reviewed publications and at international scientific conferences. Trial registration number NCT03438994; Pre-results. © 2019 Author(s).},
	author_keywords = {autism; diagnosis; digital health; machine learning; motor control; smart technology},
	keywords = {Autistic Disorder; Child, Preschool; Clinical Trials, Phase III as Topic; Female; Humans; Male; Prospective Studies; Sweden; United Kingdom; Video Games; Adaptive Behavioural Assessment System 3; Article; autism; autism assessment; Autism Diagnostic Interview Revised; child; clinical assessment; clinical evaluation; cohort analysis; comparative study; controlled study; developmental disorder; diagnostic accuracy; diagnostic value; disease association; Early Symptomatic Syndrome Eliciting Neurodevelopmental Clinical Examinations Questionnaire; Glasgow coma scale; human; machine learning; major clinical study; mental function assessment; outcome assessment; phase 3 clinical trial; practice guideline; prospective study; questionnaire; recreational game; sensitivity and specificity; strengths and difficulties questionnaire; Sweden; United Kingdom; Vineland Adaptive Behavior Scale 2; autism; female; male; pathophysiology; phase 3 clinical trial (topic); preschool child; video game},
	correspondence_address = {J. Delafield-Butt; Laboratory for Innovation in Autism, University of Strathclyde, Glasgow, United Kingdom; email: jonathan.delafield-butt@strath.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31315858},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Ramalatha201987,
	author = {Ramalatha, M. and Shivappriya, S.N. and Malarvizhi, K.},
	title = {Machine learning-based cognitive support system for healthcare},
	year = {2019},
	journal = {EAI/Springer Innovations in Communication and Computing},
	pages = {87 – 103},
	doi = {10.1007/978-3-030-00865-9_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089472307&doi=10.1007%2f978-3-030-00865-9_5&partnerID=40&md5=a1897354d91a74e8fb9243d46a75d1fa},
	affiliations = {Department of Electronics and Communication, Kumaraguru College of Technology, Coimbatore, Tamil Nadu, India; Kumaraguru College of Technology, Coimbatore, Tamil Nadu, India},
	abstract = {Body area networks are widely used for monitoring critical illnesses and providing continuous healthcare when the patients and caretakers are not always in proximity. The three components of the closed loop system of healthcare are information of patients collected through sensors, physical tests, and questions; storage and connectivity of the knowledge base with medical experts; and final diagnosis and treatment. The accuracy of a system is challenged by the accuracy of the sensors used; diagnosis with insufficient information; compatibility, feasibility, and availability of technology; storage, speed, power requirements; and security. Designing a cognitive support system using machine learning algorithms to do an initial analysis and narrow down the possibilities of ailments will help physicians to accurately diagnose and recommend appropriate treatment. The support system has to be trained with historical data beforehand and the same made use of in connecting with medical experts. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Cognitive support system for healthcare; Ethics; Invasive and non-invasive sensors; Machine learning; Machine learning; Medical data; Wireless body area network},
	keywords = {Closed loop systems; Diagnosis; Digital storage; Knowledge based systems; Learning algorithms; Medical information systems; Patient treatment; Body Area Network; Cognitive support; Historical data; Medical experts; Physical tests; Power requirement; Support systems; Three component; Machine learning},
	correspondence_address = {M. Ramalatha; Department of Electronics and Communication, Kumaraguru College of Technology, Coimbatore, India; email: ramalatha.m.it@kct.ac.in},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {25228595},
	language = {English},
	abbrev_source_title = {EAI/Springer Inno. Comm. Comp.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Christias2019597,
	author = {Christias, Panagiotis and Mocanu, Mariana},
	title = {Information Technology for Ethical Use of Water},
	year = {2019},
	journal = {Lecture Notes in Business Information Processing},
	volume = {373 LNBIP},
	pages = {597 – 607},
	doi = {10.1007/978-3-030-36691-9_50},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85077491092&doi=10.1007%2f978-3-030-36691-9_50&partnerID=40&md5=8d5289b5c06f1af02b860ed60b90132b},
	affiliations = {University Politehnica of Bucharest, Bucharest, 060042, Romania},
	abstract = {In this article, ethical considerations dealing with the proper use and the quality of water are examined based on literature resources. Principles of ethics and challenges when managing water resources are discussed. Subsequently, proposals are made on how information technology can assist assessments and decisions related to water. Additional proposals in the context of water well use relate information systems and artificial intelligence with citizens’ participation and machine learning to predict unexpected or disastrous events. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Artificial intelligence; Ethics; Information systems; Water resources management},
	keywords = {Artificial intelligence; Information systems; Information use; Philosophical aspects; Water quality; Water wells; Ethical considerations; Ethics; Quality of water; Water resources management; Information management},
	correspondence_address = {P. Christias; University Politehnica of Bucharest, Bucharest, 060042, Romania; email: panagiotis.christias@cti.pub.ro},
	editor = {Abramowicz W. and Corchuelo R.},
	publisher = {Springer},
	issn = {18651348},
	isbn = {978-303036690-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Bus. Inf. Process.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 22nd International Conference on Business Information Systems, BIS 2019; Conference date: 26 June 2019 through 28 June 2019; Conference code: 227439}
}

@ARTICLE{Tibble2019,
	author = {Tibble, Holly and Tsanas, Athanasios and Horne, Elsie and Horne, Robert and Mizani, Mehrdad and Simpson, Colin R. and Sheikh, Aziz},
	title = {Predicting asthma attacks in primary care: Protocol for developing a machine learning-based prediction model},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {7},
	doi = {10.1136/bmjopen-2018-028375},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068879485&doi=10.1136%2fbmjopen-2018-028375&partnerID=40&md5=11286cfef7c9bab8ccc4c4955746f02b},
	affiliations = {Usher Institute of Population Health Sciences and Informatics, Edinburgh Medical School, College of Medicine and Veterinary Medicine, University of Edinburgh, Edinburgh, United Kingdom; Asthma UK Centre for Applied Research, Edinburgh, United Kingdom; University College London, London, United Kingdom; School of Health, Victoria University of Wellington, Wellington, United Kingdom},
	abstract = {Introduction: Asthma is a long-term condition with rapid onset worsening of symptoms ('attacks') which can be unpredictable and may prove fatal. Models predicting asthma attacks require high sensitivity to minimise mortality risk, and high specificity to avoid unnecessary prescribing of preventative medications that carry an associated risk of adverse events. We aim to create a risk score to predict asthma attacks in primary care using a statistical learning approach trained on routinely collected electronic health record data. Methods and analysis: We will employ machine-learning classifiers (naïve Bayes, support vector machines, and random forests) to create an asthma attack risk prediction model, using the Asthma Learning Health System (ALHS) study patient registry comprising 500 000 individuals across 75 Scottish general practices, with linked longitudinal primary care prescribing records, primary care Read codes, accident and emergency records, hospital admissions and deaths. Models will be compared on a partition of the dataset reserved for validation, and the final model will be tested in both an unseen partition of the derivation dataset and an external dataset from the Seasonal Influenza Vaccination Effectiveness II (SIVE II) study. Ethics and dissemination: Permissions for the ALHS project were obtained from the South East Scotland Research Ethics Committee 02 [16/SS/0130] and the Public Benefit and Privacy Panel for Health and Social Care (1516-0489). Permissions for the SIVE II project were obtained from the Privacy Advisory Committee (National Services NHS Scotland) [68/14] and the National Research Ethics Committee West Midlands-Edgbaston [15/WM/0035]. The subsequent research paper will be submitted for publication to a peer-reviewed journal and code scripts used for all components of the data cleaning, compiling, and analysis will be made available in the open source GitHub website (https://github.com/hollytibble). © 2019 Author(s).},
	author_keywords = {asthma; asthma attacks; machine learning; prediction; primary care},
	keywords = {Asthma; Bayes Theorem; Clinical Decision Rules; Emergency Service, Hospital; Hospitalization; Humans; Machine Learning; Primary Health Care; Risk Assessment; Scotland; Support Vector Machine; Symptom Flare Up; corticosteroid; adult; Article; asthma; cohort analysis; controlled study; corticosteroid therapy; death; electronic health record; female; general practice; hospital admission; human; learning; major clinical study; male; prediction; prescription; primary medical care; random forest; register; Scotsman; support vector machine; asthma; Bayes theorem; hospital emergency service; hospitalization; machine learning; primary health care; recurrent disease; risk assessment; Scotland; support vector machine},
	correspondence_address = {H. Tibble; Usher Institute of Population Health Sciences and Informatics, Edinburgh Medical School, College of Medicine and Veterinary Medicine, University of Edinburgh, Edinburgh, United Kingdom; email: holly.tibble@ed.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31292179},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Al-Omran2019940,
	author = {Al-Omran, Ghada and Al-Abdulhadi, Sarah and Jan, Ms. Roohi},
	title = {Ethics in artificial intelligence},
	year = {2019},
	journal = {Proceedings of the International Conference on Industrial Engineering and Operations Management},
	number = {November},
	pages = {940 – 949},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85080856356&partnerID=40&md5=9e546b8e142d592a5db750d93605f35c},
	affiliations = {Prince Sultan University, Riyadh, Saudi Arabia},
	abstract = {Artificial intelligence systems are the new generation of machines, by discovering the answers to various difficult problems in a manner that is exactly like humans. AI systems are so smart, they exceed humans; as they detect and solve complex tasks quickly. Due to the vast development of artificial intelligence machines, it can be seen that they are widely used various domains such as medicine and education. Because of the ubiquity of such systems, ethics has been an ongoing discussion in this particular field, with researchers investigating how to apply ethical standards in the practice of AI. Computer professions already have different ethical codes, Software Engineering Code of Ethics and Professional Practice, IEEE Code of conduct and ACM Code of Ethics, particularly were discussed in this paper, as they are codes we studied in this course. The ethical issues in Machine Learning, Self-Driving Cars and Robotics were discussed, and the ethical principles concerned with such issues were applied in order to achieve an optimal solution. Our research is aimed at investigating whether these existing ethics codes are sufficient for artificial intelligence or whether we need a new ethics code pertaining to only the artificial intelligence field. © IEOM Society International.},
	publisher = {IEOM Society},
	issn = {21698767},
	language = {English},
	abbrev_source_title = {Proc. Int. Conf. Ind. Eng. Oper. Manage.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st GCC International Conference on Industrial Engineering and Operations Management, IEOM 2019; Conference date: 26 November 2019 through 28 November 2019; Conference code: 141928}
}

@ARTICLE{Kumar201933,
	author = {Kumar, Nikhil and Kumar, Laya and Limaye, Anmol},
	title = {Precision Medicine – From Moonshot to Reality},
	year = {2019},
	journal = {Pharma Times},
	volume = {51},
	number = {3},
	pages = {33 – 37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125930564&partnerID=40&md5=26754b705c8e11178d3523e9d78561e8},
	affiliations = {Applied Technology Solutions, Inc, United States; Nymro Clinical Consulting Services, United States},
	abstract = {Precision medicine, leveraging the evolving fields of the various omics, lifestyles, health history and other factors in the expression of phenotypes, combined with traditional clinical medicine is defining the new healthcare landscape and the data-centric healthcare ecosystem. Companion diagnostics are being used to supplement traditional differential diagnosis in the identification of disease and its treatment. This new world hinges on data – its interoperability, collation and interpretation. This paper discusses that role of the ecosystem, the science and the implementation of precision medicine and the role of data. © 2019, Indian Pharmaceutical Association. All rights reserved.},
	keywords = {acute lymphoblastic leukemia; Article; artificial intelligence; computer human interaction; degenerative disease; ecosystem; epigenetics; ethics; evolution of disease; evolution of jurisprudence; health care concepts; health care cost; health care system; health care time; Helicobacter pylori; human; information processing; interoperability and data; intestine flora; machine learning; metagenomics; modern healthcare; mortality; mouth flora; new models of medicine; patient care; personalized medicine; proteomics; stomach disease; survival rate; traditional medicine; transcriptomics},
	correspondence_address = {N. Kumar; Applied Technology Solutions, Inc, United States; email: nikhil@ap-tech-solns.com; L. Kumar; Applied Technology Solutions, Inc, United States; email: lkumarcc@gmail.com},
	publisher = {Indian Pharmaceutical Association},
	issn = {00316849},
	language = {English},
	abbrev_source_title = {Pharma Times},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Scaffidi2019,
	author = {Scaffidi, Michael A. and Khan, Rishad and Walsh, Catharine M. and Pearl, Matthew and Winger, Kathleen and Kalaichandran, Ruben and Lin, Peter and Grover, Samir C.},
	title = {Protocol for a randomised trial evaluating the effect of applying gamification to simulation-based endoscopy training},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {2},
	doi = {10.1136/bmjopen-2018-024134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062174277&doi=10.1136%2fbmjopen-2018-024134&partnerID=40&md5=f82582a69c0c87a9800bc19bbdaae671},
	affiliations = {Division of Gastroenterology, St. Michael's Hospital, Toronto, Canada; Division of Gastroenterology, Hepatology, and Nutrition, Learning Institute, and Research Institute, Hospital for Sick Children, Toronto, ON, Canada; Wilson Centre, University of Toronto, Toronto, Canada; Li Ka Shing Knowledge Institute, St. Michael's Hospital, Toronto, ON, Canada},
	abstract = {Background Simulation-based training (SBT) provides a safe environment and effective means to enhance skills development. Simulation-based curricula have been developed for a number of procedures, including gastrointestinal endoscopy. Gamification, which is the application of game-design principles to non-game contexts, is an instructional strategy with potential to enhance learning. No studies have investigated the effects of a comprehensive gamification curriculum on the acquisition of endoscopic skills among novice endoscopists. Methods and analysis Thirty-six novice endoscopists will be randomised to one of two endoscopy SBT curricula: (1) the Conventional Curriculum Group, in which participants will receive 6 hours of one-on-one simulation training augmented with expert feedback and interlaced with 4 hours of small group teaching on the theory of colonoscopy or (2) the Gamified Curriculum Group, in which participants will receive the same curriculum with integration of the following game-design elements: A leaderboard summarising participants' performance, game narrative, achievement badges and rewards for top performance. In line with a progressive learning approach, simulation training for participants will progress from low to high complexity simulators, starting with a bench-top model and then moving to the EndoVR virtual reality simulator. Performance will be assessed at three points: Pretraining, immediately post-training and 4-6 weeks after training. Assessments will take place on the simulator at all three time points and transfer of skills will be assessed during two clinical colonoscopies 4-6 weeks post-training. Mixed factorial ANOVAs will be used to determine if there is a performance difference between the two groups during simulated and clinical assessments. Ethics and dissemination Ethical approval was obtained at St. Michael's Hospital. Results of this trial will be submitted for presentation at academic meetings and for publication in a peer-reviewed journal. Trial registration number NCT03176251. © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC.},
	author_keywords = {endoscopy; simulation},
	keywords = {Curriculum; Educational Measurement; Endoscopy, Gastrointestinal; Humans; Simulation Training; Surveys and Questionnaires; User-Computer Interface; Video Games; Article; clinical assessment; clinical effectiveness; clinical evaluation; clinical protocol; colonoscopy; computer aided design; controlled study; curriculum; endoscopist; endoscopy; human; machine learning; medical education; randomized controlled trial; simulation training; single blind procedure; tactile feedback; computer interface; education; gastrointestinal endoscopy; procedures; questionnaire; simulation training; video game},
	correspondence_address = {S.C. Grover; Division of Gastroenterology, St. Michael's Hospital, Toronto, Canada; email: samir.grover@utoronto.ca},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {30804029},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@BOOK{Rijcken2019119,
	author = {Rijcken, Claudia},
	title = {Sequoias of artificial intelligence},
	year = {2019},
	journal = {Pharmaceutical Care in Digital Revolution: Insights Towards Circular Innovation},
	pages = {119 – 134},
	doi = {10.1016/B978-0-12-817638-2.00011-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082083028&doi=10.1016%2fB978-0-12-817638-2.00011-0&partnerID=40&md5=77181de0cf4324d29b6a223b9382a7d9},
	affiliations = {Philips High Tech Campus, Eindhoven, Netherlands; University of Utrecht, Netherlands},
	abstract = {In this chapter you discover how artificial intelligence (AI) technology can offer pharmaceutical care providers smart support systems, given that it has access to complete, adequate, and holistic health data sets. AI can support trend analysis and decision making that augment pharmaceutical care expertise. This is what we may call “apothecary intelligence.” This chapter provides examples of big platforms as well as startup concepts related to AI healthcare. The chapter also dives into transparency, detection of data bias, competency building, and ethical considerations. With AI-driven pharmacy-as-a-service platforms, pharmaceutical care providers can spend more time working on what they do best: using human judgment, empathy, and consideration to provide good patient care. © 2019 Elsevier Inc. All rights reserved.},
	author_keywords = {Ai; Apothecary intelligence; Augmented healthcare; Data bias; Ethics; Machine learning; Precision medicine; Supervised and unsupervised algorithms},
	publisher = {Elsevier},
	isbn = {978-012817638-2},
	language = {English},
	abbrev_source_title = {Pharmaceutical Care in Digital Revolut.: Insights Towards Circular Innovation},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hind2019123,
	author = {Hind, Michael and Wei, Dennis and Campbell, Murray and Codella, Noel C.F. and Dhurandhar, Amit and Mojsilović, Aleksandra and Natesan Ramamurthy, Karthikeyan and Varshney, Kush R.},
	title = {TED: Teaching AI to explain its decisions},
	year = {2019},
	journal = {AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {123 – 129},
	doi = {10.1145/3306618.3314273},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070631559&doi=10.1145%2f3306618.3314273&partnerID=40&md5=b6ff007b1a2c4d6ca4d208df49d46097},
	affiliations = {IBM Research AI, Yorktown Heights, NY, United States},
	abstract = {Artificial intelligence systems are being increasingly deployed due to their potential to increase the efficiency, scale, consistency, fairness, and accuracy of decisions. However, as many of these systems are opaque in their operation, there is a growing demand for such systems to provide explanations for their decisions. Conventional approaches to this problem attempt to expose or discover the inner workings of a machine learning model with the hope that the resulting explanations will be meaningful to the consumer. In contrast, this paper suggests a new approach to this problem. It introduces a simple, practical framework, called Teaching Explanations for Decisions (TED), that provides meaningful explanations that match the mental model of the consumer. We illustrate the generality and effectiveness of this approach with two different examples, resulting in highly accurate explanations with no loss of prediction accuracy for these two examples. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {AI Ethics; Elicitation; Explainable AI; Machine Learning; Meaningful Explanation; Supervised Classification},
	keywords = {Learning systems; Machine learning; Philosophical aspects; Artificial intelligence systems; Conventional approach; Elicitation; Highly accurate; Machine learning models; Meaningful Explanation; Prediction accuracy; Supervised classification; Supervised learning},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036324-2},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55; Conference name: 2nd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2019; Conference date: 27 January 2019 through 28 January 2019; Conference code: 149526}
}

@CONFERENCE{Klincewicz2019,
	author = {Klincewicz, Michal and Frank, Lily},
	title = {Consequences of unexplainable machine learning for the notions of a trusted doctor and patient autonomy},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2681},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85093364612&partnerID=40&md5=b4adf15935c732a29d68297adb01f69a},
	affiliations = {Cognitive Science and Artificial Intelligence, Tilburg University, Netherlands; Ethics and Philosophy, Technical University of Eindhoven, Netherlands},
	abstract = {This paper provides an analysis of the way in which two foundational principles of medical ethics-the trusted doctor and patient autonomy-can be undermined by the use of machine learning (ML) algorithms and addresses its legal significance. This paper can be a guide to both health care providers and other stakeholders about how anticipate and in some cases mitigate ethical conflicts caused by the use of ML in healthcare. It can also be read as a road map as to what needs to be done to achieve an acceptable level of explainability in an ML algorithm when it is used in a healthcare context. Copyright © 2019 for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Ethics; Explainability; Health care; Machine learning},
	keywords = {Health care; Philosophical aspects; Health care providers; Ml algorithms; Road-maps; Machine learning},
	correspondence_address = {M. Klincewicz; Cognitive Science and Artificial Intelligence, Tilburg University, Netherlands; email: m.w.klincewicz@uvt.nl},
	editor = {Nalepa G.J. and Atzmueller M. and Araszkiewicz M. and Novais P.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd EXplainable AI in Law Workshop, XAILA 2019; Conference date: 11 December 2019; Conference code: 163236}
}

@CONFERENCE{Chancellor201979,
	author = {Chancellor, Stevie and Birnbaum, Michael L. and Caine, Eric D. and Silenzio, Vincent M.B. and De Choudhury, Munmun},
	title = {A taxonomy of ethical tensions in inferring mental health states from social media},
	year = {2019},
	journal = {FAT* 2019 - Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency},
	pages = {79 – 88},
	doi = {10.1145/3287560.3287587},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061824457&doi=10.1145%2f3287560.3287587&partnerID=40&md5=8fcb4a69f17ee2f82b81c9712a65ec43},
	affiliations = {Georgia Tech, Atlanta, GA, United States; Northwell Health Glen, Oaks, NY, United States; University of Rochester, Rochester, NY, United States},
	abstract = {Powered by machine learning techniques, social media provides an unobtrusive lens into individual behaviors, emotions, and psychological states. Recent research has successfully employed social media data to predict mental health states of individuals, ranging from the presence and severity of mental disorders like depression to the risk of suicide. These algorithmic inferences hold great potential in supporting early detection and treatment of mental disorders and in the design of interventions. At the same time, the outcomes of this research can pose great risks to individuals, such as issues of incorrect, opaque algorithmic predictions, involvement of bad or unaccountable actors, and potential biases from intentional or inadvertent misuse of insights. Amplifying these tensions, there are also divergent and sometimes inconsistent methodological gaps and under-explored ethics and privacy dimensions. This paper presents a taxonomy of these concerns and ethical challenges, drawing from existing literature, and poses questions to be resolved as this research gains traction. We identify three areas of tension: ethics committees and the gap of social media research; questions of validity, data, and machine learning; and implications of this research for key stakeholders. We conclude with calls to action to begin resolving these interdisciplinary dilemmas. © 2019 Association for Computing Machinery.},
	author_keywords = {Algorithms; Ethics; Machine learning; Mental health; Social media},
	keywords = {Algorithms; Health; Health risks; Learning systems; Philosophical aspects; Social networking (online); Taxonomies; Transparency; Algorithmic Inference; Algorithmic prediction; Ethics; Individual behavior; Machine learning techniques; Mental health; Psychological state; Social media; Machine learning},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036125-5},
	language = {English},
	abbrev_source_title = {FAT* - Proc. Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 101; Conference name: 2019 ACM Conference on Fairness, Accountability, and Transparency, FAT* 2019; Conference date: 29 January 2019 through 31 January 2019; Conference code: 144666}
}

@CONFERENCE{Crockett20193227,
	author = {Crockett, Keeley and Goltz, Sean and Garratt, Matt and Latham, Annabel},
	title = {Trust in Computational Intelligence Systems: A Case Study in Public Perceptions},
	year = {2019},
	journal = {2019 IEEE Congress on Evolutionary Computation, CEC 2019 - Proceedings},
	pages = {3227 – 3234},
	doi = {10.1109/CEC.2019.8790147},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071306714&doi=10.1109%2fCEC.2019.8790147&partnerID=40&md5=c360e6613078f0b6096f20c45614c821},
	affiliations = {School of Computing, Mathematics and Digital Technology, Manchester Metropolitan University, Manchester, M1 5GD, United Kingdom; Business Law School, Edith Cowan University, Perth, Australia; School of Engineering and IT, University of New South Wales, Canberra, 2610, BC, Australia},
	abstract = {The public debate and discussion about trust in Computational Intelligence (CI) systems is not new, but a topic that has seen a recent rise. This is mainly due to the explosion of technological innovations that have been brought to the attention of the public, from lab to reality usually through media reporting. This growth in the public attention was further compounded by the 2018 GDPR legislation and new laws regarding the right to explainable systems, such as the use of "accurate data", "clear logic" and the "use of appropriate mathematical and statistical procedures for profiling". Therefore, trust is not just a topic for debate - it must be addressed from the onset, through the selection of fundamental machine learning processes that are used to create models embedded within autonomous decision-making systems, to the selection of training, validation and testing data. This paper presents current work on trust in the field of Computational Intelligence systems and discusses the legal framework we should ascribe to trust in CI systems. A case study examining current public perceptions of recent CI inspired technologies which took part at a national science festival is presented with some surprising results. Finally, we look at current research underway that is aiming to increase trust in Computational Intelligent systems and we identify a clear educational gap. © 2019 IEEE.},
	author_keywords = {Computational Intelligence; Ethics; Explainability; GDPR; Morality; Trust},
	keywords = {Artificial intelligence; Decision making; Embedded systems; Intelligent systems; Laws and legislation; Ethics; Explainability; GDPR; Morality; Trust; Computation theory},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-172812153-6},
	language = {English},
	abbrev_source_title = {IEEE Congr. Evol.. Comput., CEC - Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 2019 IEEE Congress on Evolutionary Computation, CEC 2019; Conference date: 10 June 2019 through 13 June 2019; Conference code: 150626; All Open Access, Green Open Access}
}

@ARTICLE{Battaglini2019331,
	author = {Battaglini, Manuela and Rasmussen, Steen},
	title = {Transparency, automated decision-making processes and personal profiling},
	year = {2019},
	journal = {Journal of Data Protection and Privacy},
	volume = {2},
	number = {4},
	pages = {331 – 349},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091376143&partnerID=40&md5=701a61c0c39b5289fb589bcd93bb035d},
	affiliations = {Transparent Internet, Tårup Bygade 30, Mesinge, DK-5370, Denmark; Center for Fundamental Living Technology (FLinT), University of Southern Denmark, Odense, DK-5230, Denmark},
	abstract = {Automated decision-making and profiling techniques provide tremendous opportunities to companies and organizations; however, they can also be harmful to individuals, because current laws and their interpretations neither provide data subjects with sufficient control over assessments made by automated decision-making processes nor with sufficient control over how these profiles are used. Initially, we briefly discuss how recent technological innovations led to big data analytics, which through machine learning algorithms can extract behaviours, preferences and feelings of individuals. This automatically generated knowledge can both form the basis for effective business decisions and result in discriminatory and biased perceptions of individuals’ lives. We next observe how the consequences of this situation lead to lack of transparency in automated decision-making and profiling, and discuss the legal framework of this situation. © Henry Stewart Publications.},
	author_keywords = {data ethics; digital infrastructure; GDPR; machine learning; open source; transparency},
	publisher = {Henry Stewart Publications},
	issn = {23981679},
	language = {English},
	abbrev_source_title = {J. Data. Prot. Priv.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{Dent2019178,
	author = {Dent, Kyle and Dumond, Richelle and Kuniavsky, Mike},
	title = {A Framework for Systematically Applying Humanistic Ethics when Using AI as a Design Material; [Marc per aplicar sistemàticament l'ètica humanista quan s'utilitza la IA com a material de disseny]; [Marco para aplicar sistemáticamente la ética humanista cuando se utiliza la IA como material de diseño]},
	year = {2019},
	journal = {Temes de Disseny},
	volume = {2019},
	number = {35},
	pages = {178 – 197},
	doi = {10.46467/TdD35.2019.178-197},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85148601810&doi=10.46467%2fTdD35.2019.178-197&partnerID=40&md5=77cf04e86f2ac7db9d71f874b8701109},
	affiliations = {Palo Alto Research Center (PARC), United States},
	abstract = {As machine learning and AI systems gain greater capabilities and are deployed more widely, we — as designers, developers, and researchers — must consider both the positive and negative implications of their use. In light of this, PARC’s researchers recognize the need to be vigilant against the potential for harm caused by artificial intelligence through intentional or inadvertent discrimination, unjust treatment, or physical danger that might occur against individuals or groups of people. Because AI-supported and autonomous decision making has the potential for widespread negative personal, social, and environmental effects, we aim to take a proactive stance to uphold human rights, respect individuals’ privacy, protect personal data, and enable freedom of expression and equality. Technology is not inherently neutral and reflects decisions and trade-offs made by the designers, researchers, and engineers developing it and using it in their work. Datasets often reflect historical biases. AI technologies that hire people, evaluate their job performance, deliver their healthcare, and mete out penalties are obvious examples of possible areas for systematic algorithmic errors that result in unfair or unjust treatment. Because nearly all technology includes trade-offs and embodies the values and judgments of the people creating it, it is imperative that researchers are aware of the value judgments they make and are transparent about them with all stakeholders involved. © 2019, Elisava Barcelona School of Design and Engineering. All rights reserved.},
	author_keywords = {AI Design; Ethics; Technology and Society},
	publisher = {Elisava Barcelona School of Design and Engineering},
	issn = {26049155},
	language = {English},
	abbrev_source_title = {Temes. Disseny.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Gilbert201961,
	author = {Gilbert, Thomas Krendl and Mintz, Yonatan},
	title = {Epistemic therapy for bias in automated decision-making},
	year = {2019},
	journal = {AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {61 – 67},
	doi = {10.1145/3306618.3314294},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070620418&doi=10.1145%2f3306618.3314294&partnerID=40&md5=0c4743ef2fc8963ae29f7b6e26f68a26},
	affiliations = {University of California, Berkeley, Berkeley, CA, United States; Georgia Institute of Technology, Atlanta, GA, United States},
	abstract = {Despite recent interest in both the critical and machine learning literature on “bias” in artificial intelligence (AI) systems, the nature of specific biases stemming from the interaction of machines, humans, and data remains ambiguous. Influenced by Gendler's work on human cognitive biases, we introduce the concept of alief-discordant belief, the tension between the intuitive moral dispositions of designers and the explicit representations generated by algorithms. Our discussion of alief-discordant belief diagnoses the ethical concerns that arise when designing AI systems atop human biases. We furthermore codify the relationship between data, algorithms, and engineers as components of this cognitive discordance, comprising a novel epistemic framework for ethics in AI. © 2019 Association for Computing Machinery.},
	author_keywords = {AI; Artificial intelligence; Fairness; Moral cognition},
	keywords = {Artificial intelligence; Behavioral research; Decision making; Professional aspects; Automated decision making; Cognitive bias; Ethical concerns; Explicit representation; Fairness; Human bias; Machine learning literature; Moral cognition; Philosophical aspects},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036324-2},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 2nd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2019; Conference date: 27 January 2019 through 28 January 2019; Conference code: 149526}
}

@ARTICLE{2019,
	title = {20th International Conference on Product-Focused Software Process Improvement, PROFES 2019},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11915 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076541990&partnerID=40&md5=ce125964603b630e1543356b5f1858ae},
	abstract = {The proceedings contain 57 papers. The special focus in this conference is on Product-Focused Software Process Improvement. The topics include: When NFR Templates Pay Back? A Study on Evolution of Catalog of NFR Templates; improving Quality of Data Exchange Files. An Industrial Case Study; containers in Software Development: A Systematic Mapping Study; empirical Analysis of Hidden Technical Debt Patterns in Machine Learning Software; constraining the Implementation Through Architectural Security Rules: An Expert Study; technical Debt and Waste in Non-functional Requirements Documentation: An Exploratory Study; Technical Debt in Costa Rica: An InsighTD Survey Replication; exploring Preference of Chronological and Relevancy Filtering in Effort Estimation; automated Functional Size Measurement: A Multiple Case Study in the Industry; applying Surveys and Interviews in Software Test Tool Evaluation; can Expert Opinion Improve Effort Predictions When Exploiting Cross-Company Datasets? - A Case Study in a Small/Medium Company; excellence in Exploratory Testing: Success Factors in Large-Scale Industry Projects; comparison Framework for Team-Based Communication Channels; devOps in Practice – A Preliminary Analysis of Two Multinational Companies; Implementing Ethics in AI: Initial Results of an Industrial Multiple Case Study; How Agile Is Hybrid Agile? An Analysis of the HELENA Data; challenges of Scaled Agile for Safety-Critical Systems; on the Benefits of Corporate Hackathons for Software Ecosystems – A Systematic Mapping Study; agile in the Era of Digitalization: A Finnish Survey Study; what’s Hot in Product Roadmapping? Key Practices and Success Factors; test-Case Quality – Understanding Practitioners’ Perspectives; integrating Data Protection into the Software Life Cycle.},
	editor = {Franch X. and Männistö T. and Martínez-Fernández S.},
	publisher = {Springer},
	issn = {03029743},
	isbn = {978-303035332-2},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th International Conference on Product-Focused Software Process Improvement, PROFES 2019; Conference date: 27 November 2019 through 29 November 2019; Conference code: 234099}
}

@CONFERENCE{Susser2019403,
	author = {Susser, Daniel},
	title = {Invisible influence: Artificial intelligence and the ethics of adaptive choice architectures},
	year = {2019},
	journal = {AIES 2019 - Proceedings of the 2019 AAAI/ACM Conference on AI, Ethics, and Society},
	pages = {403 – 408},
	doi = {10.1145/3306618.3314286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067389036&doi=10.1145%2f3306618.3314286&partnerID=40&md5=ace64adb4ecdc5f6d01002c327b0dcc6},
	affiliations = {Penn State University, State College, PA, United States},
	abstract = {For several years, scholars have (for good reason) been largely preoccupied with worries about the use of artificial intelligence and machine learning (AI/ML) tools to make decisions about us. Only recently has significant attention turned to a potentially more alarming problem: the use of AI/ML to influence our decision-making. The contexts in which we make decisions-what behavioral economists call our choice architectures-are increasingly technologically-laden. Which is to say: algorithms increasingly determine, in a wide variety of contexts, both the sets of options we choose from and the way those options are framed. Moreover, artificial intelligence and machine learning (AI/ML) makes it possible for those options and their framings-the choice architectures-to be tailored to the individual chooser. They are constructed based on information collected about our individual preferences, interests, aspirations, and vulnerabilities, with the goal of influencing our decisions. At the same time, because we are habituated to these technologies we pay them little notice. They are, as philosophers of technology put it, transparent to us-effectively invisible. I argue that this invisible layer of technological mediation, which structures and influences our decision-making, renders us deeply susceptible to manipulation. Absent a guarantee that these technologies are not being used to manipulate and exploit, individuals will have little reason to trust them. © 2019 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Accountability; Choice architecture; Data ethics; Influence; Manipulation; Transparency},
	keywords = {Decision making; Machine learning; Transparency; Accountability; Data ethics; Individual preference; Influence; Manipulation; Technological mediations; Philosophical aspects},
	correspondence_address = {D. Susser; Penn State University, State College, United States; email: daniel.susser@psu.edu},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036324-2},
	language = {English},
	abbrev_source_title = {AIES - Proc. AAAI/ACM Conf. AI, Ethics, Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; Conference name: 2nd AAAI/ACM Conference on AI, Ethics, and Society, AIES 2019; Conference date: 27 January 2019 through 28 January 2019; Conference code: 149526}
}

@ARTICLE{Conway2019208,
	author = {Conway, Mike and Hu, Mengke and Chapman, Wendy W.},
	title = {Recent Advances in Using Natural Language Processing to Address Public Health Research Questions Using Social Media and ConsumerGenerated Data},
	year = {2019},
	journal = {Yearbook of medical informatics},
	volume = {28},
	number = {1},
	pages = {208 – 217},
	doi = {10.1055/s-0039-1677918},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071973510&doi=10.1055%2fs-0039-1677918&partnerID=40&md5=dd2599f7859f1af28dc8e6f758afeac8},
	affiliations = {Department of Biomedical Informatics, University of Utah, Salt Lake City, UT, United States},
	abstract = {OBJECTIVE: We present a narrative review of recent work on the utilisation of Natural Language Processing (NLP) for the analysis of social media (including online health communities) specifically for public health applications. METHODS: We conducted a literature review of NLP research that utilised social media or online consumer-generated text for public health applications, focussing on the years 2016 to 2018. Papers were identified in several ways, including PubMed searches and the inspection of recent conference proceedings from the Association of Computational Linguistics (ACL), the Conference on Human Factors in Computing Systems (CHI), and the International AAAI (Association for the Advancement of Artificial Intelligence) Conference on Web and Social Media (ICWSM). Popular data sources included Twitter, Reddit, various online health communities, and Facebook. RESULTS: In the recent past, communicable diseases (e.g., influenza, dengue) have been the focus of much social media-based NLP health research. However, mental health and substance use and abuse (including the use of tobacco, alcohol, marijuana, and opioids) have been the subject of an increasing volume of research in the 2016 - 2018 period. Associated with this trend, the use of lexicon-based methods remains popular given the availability of psychologically validated lexical resources suitable for mental health and substance abuse research. Finally, we found that in the period under review "modern" machine learning methods (i.e. deep neural-network-based methods), while increasing in popularity, remain less widely used than "classical" machine learning methods. Georg Thieme Verlag KG Stuttgart.},
	keywords = {Bibliometrics; Health Services Research; Humans; Natural Language Processing; Patient Generated Health Data; Public Health; Public Health Surveillance; Social Media; bibliometrics; ethics; health services research; health survey; human; medical record; natural language processing; procedures; public health; social media},
	publisher = {NLM (Medline)},
	issn = {23640502},
	pmid = {31419834},
	language = {English},
	abbrev_source_title = {Yearb Med Inform},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 38; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Looi201975,
	author = {Looi, Jeffrey CL},
	title = {Be like water: a personal strategy for clinical psychiatric research},
	year = {2019},
	journal = {Australasian Psychiatry},
	volume = {27},
	number = {1},
	pages = {75 – 79},
	doi = {10.1177/1039856218789776},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052280451&doi=10.1177%2f1039856218789776&partnerID=40&md5=90dee2bf4fab482874630104bd9eee12},
	affiliations = {Academic Unit of Psychiatry and Addiction Medicine, Australian National University Medical School, Garran, ACT, Australia; Neuropsychiatry Unit, Department of Psychiatry, Royal Melbourne Hospital, Melbourne Medical School, Melbourne, VIC, Australia},
	abstract = {Objectives: This paper describes, from the personal perspective of a mid-career researcher, principles and advice regarding the development of an embedded clinical psychiatric research program within a medical school and public sector mental health service. From this experience, some general principles are drawn. Conclusions: Through careful strategic planning, together with collaboration with the mental health service, it is possible to bootstrap and develop an embedded clinical research program. © The Royal Australian and New Zealand College of Psychiatrists 2018.},
	author_keywords = {development; psychiatry; research; strategy},
	keywords = {Biomedical Research; Humans; Mental Health Services; Physicians; Psychiatry; Schools, Medical; water; Article; career planning; clinical outcome; clinical research; competition; degenerative disease; environment; funding; health belief; health service; human; intersectoral collaboration; knowledge; learning; machine learning; medical education; medical ethics; medical school; mental disease; mental health; mental health service; neuroimaging; nuclear magnetic resonance imaging; personal value; psychiatry; psychotherapy; publication; skill; social support; study design; symposium; workshop; economics; medical research; organization and management; physician},
	correspondence_address = {J.C.L. Looi; Academic Unit of Psychiatry and Addiction Medicine, Australian National University Medical School, Garran, Australia; email: jeffrey.looi@anu.edu.au},
	publisher = {SAGE Publications Inc.},
	issn = {10398562},
	coden = {AUPSF},
	pmid = {30058350},
	language = {English},
	abbrev_source_title = {Australas. Psychiatry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Meng2019,
	author = {Meng, Fanqi and Zhang, Zhihua and Hou, Xiaofeng and Qian, Zhiyong and Wang, Yao and Chen, Yanhong and Wang, Yilian and Zhou, Ye and Chen, Zhen and Zhang, Xiwen and Yang, Jing and Zhang, Jinlong and Guo, Jianghong and Li, Kebei and Chen, Lu and Zhuang, Ruijuan and Jiang, Hai and Zhou, Weihua and Tang, Shaowen and Wei, Yongyue and Zou, Jiangang},
	title = {Machine learning for prediction of sudden cardiac death in heart failure patients with low left ventricular ejection fraction: Study protocol for a retroprospective multicentre registry in China},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {5},
	doi = {10.1136/bmjopen-2018-023724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065894757&doi=10.1136%2fbmjopen-2018-023724&partnerID=40&md5=fac965756956c814dbef632c1e6df575},
	affiliations = {Department of Cardiology, First Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; Department of Cardiology, Xiamen Cardiovascular Hospital, Xiamen University, Xiamen, Fujian, China; Department of Cardiology, Jiangning Hospital Affiliated to Nanjing Medical University, Nanjing, Jiangsu, China; Department of Cardiology, Wuhan Asia Heart Hospital, Wuhan, Hubei, China; Department of Cardiology, Second People's Hospital of Lianyungang, Lianyungang, Jiangsu, China; Department of Cardiology, Affiliated Hospital of Jiangsu University, Zhenjiang, Jiangsu, China; Department of Cardiology, Taixing People's Hospital, Taixing, Jiangsu, China; Department of Cardiology, First People's Hospital of Huaian, Huaian, Jiangsu, China; Department of Cardiology, First People's Hospital of Yancheng, Yancheng, Jiangsu, China; Department of Cardiology, Rugao People's Hospital, Rugao, Jiangsu, China; Department of Cardiology, First People's Hospital of Zhangjiagang, Zhangjiagang, Jiangsu, China; Department of Cardiology, Third People's Hospital of Suzhou, Suzhou, Jiangsu, China, China; Department of Cardiology, Third People's Hospital of Wuxi, Wuxi, Jiangsu, China; Department of Cardiology, Second Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; School of Computing, University of Southern Mississippi, Hattiesburg, Mississippi, United States; Department of Epidemiology, Nanjing Medical University, Nanjing, Jiangsu, China; Department of Biostatistics, Nanjing Medical University, Nanjing, Jiangsu, China; Key Laboratory of Targeted Intervention of Cardiovascular Disease, Collaborative Innovation Center for Cardiovascular Disease Translational Medicine, Nanjing Medical University, Nanjing, Jiangsu, China},
	abstract = {Introduction Left ventricular ejection fraction (LVEF) ≤35%, as current significant implantable cardioverter-defibrillator (ICD) indication for primary prevention of sudden cardiac death (SCD) in heart failure (HF) patients, has been widely recognised to be inefficient. Improvement of patient selection for low LVEF (≤35%) is needed to optimise deployment of ICD. Most of the existing prediction models are not appropriate to identify ICD candidates at high risk of SCD in HF patients with low LVEF. Compared with traditional statistical analysis, machine learning (ML) can employ computer algorithms to identify patterns in large datasets, analyse rules automatically and build both linear and non-linear models in order to make data-driven predictions. This study is aimed to develop and validate new models using ML to improve the prediction of SCD in HF patients with low LVEF. Methods and analysis We will conduct a retroprospective, multicentre, observational registry of Chinese HF patients with low LVEF. The HF patients with LVEF ≤35% after optimised medication at least 3 months will be enrolled in this study. The primary endpoints are all-cause death and SCD. The secondary endpoints are malignant arrhythmia, sudden cardiac arrest, cardiopulmonary resuscitation and rehospitalisation due to HF. The baseline demographic, clinical, biological, electrophysiological, social and psychological variables will be collected. Both ML and traditional multivariable Cox proportional hazards regression models will be developed and compared in the prediction of SCD. Moreover, the ML model will be validated in a prospective study. Ethics and dissemination The study protocol has been approved by the Ethics Committee of the First Affiliated Hospital of Nanjing Medical University (2017-SR-06). All results of this study will be published in international peer-reviewed journals and presented at relevant conferences. Trial registration number ChiCTR-POC-17011842; Pre-results. © Author(s) (or their employer(s)) 2018. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {Heart Failure; Machine Learning; Risk Model; Sudden Cardiac Death},
	keywords = {China; Death, Sudden, Cardiac; Heart Failure; Humans; Machine Learning; Multicenter Studies as Topic; Prospective Studies; Registries; Research Design; Retrospective Studies; Stroke Volume; Ventricular Function, Left; aldosterone antagonist; angiotensin receptor antagonist; antiarrhythmic agent; anticoagulant agent; antithrombocytic agent; beta adrenergic receptor blocking agent; calcium channel blocking agent; digoxin; diuretic agent; hydroxymethylglutaryl coenzyme A reductase inhibitor; ivabradine; Article; cardiac resynchronization therapy; China; clinical protocol; controlled study; disease registry; echocardiography; follow up; Hamilton Depression Rating Scale; health insurance; heart failure; heart left ventricle ejection fraction; human; machine learning; multicenter study; New York Heart Association class; observational study; prediction; primary prevention; prognosis; prospective study; QRS interval; QT interval; resuscitation; sudden cardiac death; complication; heart failure; heart left ventricle function; heart stroke volume; methodology; multicenter study (topic); pathophysiology; register; retrospective study; sudden cardiac death},
	correspondence_address = {J. Zou; Department of Cardiology, First Affiliated Hospital of Nanjing Medical University, Nanjing, Jiangsu, China; email: jgzou@njmu.edu.cn},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31101692},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 24; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Keskinbora2019277,
	author = {Keskinbora, Kadircan H.},
	title = {Medical ethics considerations on artificial intelligence},
	year = {2019},
	journal = {Journal of Clinical Neuroscience},
	volume = {64},
	pages = {277 – 282},
	doi = {10.1016/j.jocn.2019.03.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062805450&doi=10.1016%2fj.jocn.2019.03.001&partnerID=40&md5=69035016951a061a4a903fd55c5b6a1f},
	affiliations = {Medical Ethics and History of Medicine, Bahcesehir University, School of Medicine, Istanbul, Turkey},
	abstract = {Artificial intelligence (AI) is currently one of the mostly controversial matters of the world. This article discusses AI in terms of the medical ethics issues involved, both existing and potential. Once artificial intelligence is fully developed within electronic systems, it will afford many useful applications in many sectors ranging from banking, agriculture, medical procedures to military operations, especially by decreasing the involvement of humans in critically dangerous activities. Robots as well as computers themselves are embodiments of values inasmuch as they entail actions and choices, but their practical applications are modelled or programmed by the engineers building the systems. AI will need algorithmic procedures to ensure safety in the implementation of such systems. The AI algorithms written could naturally contain errors that may result in unforeseen consequences and unfair outcomes along economic and racial class lines. It is crucial that measures be taken to monitor technological developments ensuring preventative and precautionary safeguards are in place to safeguard the rights of those involved against direct or indirect coercion. While it is the responsibility of AI researchers to ensure that the future impact is more positive than negative, ethicists and philosophers need to be deeply involved in the development of such technologies from the beginning. © 2019 Elsevier Ltd},
	author_keywords = {Artificial intelligence; Machine learning; Medical ethics},
	keywords = {artificial intelligence; beneficence; brain computer interface; human rights; justice; machine learning; medical ethics; medical research; patient autonomy; persuasive communication; priority journal; privacy; research ethics; Review; robotics; safety; software; technology; trust},
	correspondence_address = {K.H. Keskinbora; Istanbul, Incirli Cad. 43-5, Bakirkoy, 34147, Turkey; email: hidirkadircan.keskinbora@med.bau.edu.tr},
	publisher = {Churchill Livingstone},
	issn = {09675868},
	coden = {JCNUE},
	pmid = {30878282},
	language = {English},
	abbrev_source_title = {J. Clin. Neurosci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 63}
}

@ARTICLE{Tran2019,
	author = {Tran, Bach Xuan and Vu, Giang Thu and Ha, Giang Hai and Vuong, Quan-Hoang and Ho, Manh-Tung and Vuong, Thu-Trang and La, Viet-Phuong and Ho, Manh-Toan and Nghiem, Kien-Cuong P. and Nguyen, Huong Lan Thi and Latkin, Carl A. and Tam, Wilson W. S. and Cheung, Ngai-Man and Nguyen, Hong-Kong T. and Ho, Cyrus S. H. and Ho, Roger C. M.},
	title = {Global evolution of research in artificial intelligence in health and medicine: A bibliometric study},
	year = {2019},
	journal = {Journal of Clinical Medicine},
	volume = {8},
	number = {3},
	doi = {10.3390/jcm8030360},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068482219&doi=10.3390%2fjcm8030360&partnerID=40&md5=bc8dcf6d97300189749d291c4ca9fd07},
	affiliations = {Institute for Preventive Medicine and Public Health, Hanoi Medical University, Hanoi, 100000, Viet Nam; Bloomberg School of Public Health, Johns Hopkins University, Baltimore, 21205, MD, United States; Center of Excellence in Artificial Intelligence in Medicine, Nguyen Tat Thanh University, Ho Chi Minh City, 700000, Viet Nam; Center of Excellence in Evidence-based Medicine, Nguyen Tat Thanh University, Ho Chi Minh City, 700000, Viet Nam; Institute for Global Health Innovations, Duy Tan University, Da Nang, 550000, Viet Nam; Center for Interdisciplinary Social Research, Phenikaa University, Yen Nghia, Ha Dong District, Hanoi, 100803, Viet Nam; Faculty of Economics and Finance, Phenikaa University, Yen Nghia, Ha Dong district, Hanoi, 100803, Viet Nam; Sciences Po Paris, Campus de Dijon, Dijon, 21000, France; Vietnam-Germany Hospital, 16 Phu Doan street, Hoan Kiem district, Hanoi, 100000, Viet Nam; Alice Lee Centre for Nursing Studies, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 119228, Singapore; Information Systems Technology and Design (ISTD) pillar, Singapore University of Technology and Design, Singapore, 487372, Singapore; A.I. for Social Data Lab (AISDL), Vuong & Associates, 3/161 Thinh Quang, Dong Da District, Hanoi, 100000, Viet Nam; Department of Psychological Medicine, National University Hospital, Singapore, 119228, Singapore; Center of Excellence in Behavioral Medicine, Nguyen Tat Thanh University, Ho Chi Minh City, 700000, Viet Nam; Department of Psychological Medicine, Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 119228, Singapore; Biomedical Global Institute of Healthcare Research & Technology (BIGHEART), National University of Singapore, Singapore, 117599, Singapore},
	abstract = {The increasing application of Artificial Intelligence (AI) in health and medicine has attracted a great deal of research interest in recent decades. This study aims to provide a global and historical picture of research concerning AI in health and medicine. A total of 27, 451 papers that were published between 1977 and 2018 (84.6% were dated 2008-2018) were retrieved from the Web of Science platform. The descriptive analysis examined the publication volume, and authors and countries collaboration. A global network of authors’ keywords and content analysis of related scientific literature highlighted major techniques, including Robotic, Machine learning, Artificial neural network, Artificial intelligence, Natural language process, and their most frequent applications in Clinical Prediction and Treatment. The number of cancer-related publications was the highest, followed by Heart Diseases and Stroke, Vision impairment, Alzheimer’s, and Depression. Moreover, the shortage in the research of AI application to some high burden diseases suggests future directions in AI research. This study offers a first and comprehensive picture of the global efforts directed towards this increasingly important and prolific field of research and suggests the development of global and national protocols and regulations on the justification and adaptation of medical AI products. © 2019 by the authors. Licensee MDPI, Basel, Switzerland.},
	author_keywords = {AI ethics; Artificial intelligence; Bibliometric analysis; Global; Health; Mapping; Medicine},
	keywords = {alternative medicine; Alzheimer disease; Article; artificial intelligence; artificial neural network; bibliometrics; computer model; computer prediction; content analysis; deep learning; depression; disability-adjusted life year; expert system; fuzzy logic; global health; health program; heart disease; human; indocyanine green angiography; information storage; laparoscopy; machine learning; natural language processing; parasympathetic tone; robotics; visual impairment; Web of Science},
	correspondence_address = {B.X. Tran; Institute for Preventive Medicine and Public Health, Hanoi Medical University, Hanoi, 100000, Viet Nam; email: bach.ipmph@gmail.com},
	publisher = {MDPI},
	issn = {20770383},
	language = {English},
	abbrev_source_title = {J. Clin. Med.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 167; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Greene20192122,
	author = {Greene, Daniel and Hoffmann, Anna Lauren and Stark, Luke},
	title = {Better, nicer, clearer, fairer: A critical assessment of the movement for ethical artificial intelligence and machine learning},
	year = {2019},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	volume = {2019-January},
	pages = {2122 – 2131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85108287099&partnerID=40&md5=ed0e415ff788664e3845cf8b417b7b0d},
	affiliations = {College of Information Studies, University of Maryland; The Information School, University of Washington; Microsoft Research Montreal},
	abstract = {This paper uses frame analysis to examine recent high-profile values statements endorsing ethical design for artificial intelligence and machine learning (AI/ML). Guided by insights from values in design and the sociology of business ethics, we uncover the grounding assumptions and terms of debate that make some conversations about ethical design possible while forestalling alternative visions. Vision statements for ethical AI/ML co-opt the language of some critics, folding them into a limited, technologically deterministic, expert-driven view of what ethical AI/ML means and how it might work. © 2019 IEEE Computer Society. All rights reserved.},
	keywords = {Machine learning; Sociology; Business ethics; Critical assessment; Ethical designs; Frame analysis; Philosophical aspects},
	editor = {Bui T.X.},
	publisher = {IEEE Computer Society},
	issn = {15301605},
	isbn = {978-099813312-6},
	language = {English},
	abbrev_source_title = {Proc. Annu. Hawaii Int. Conf. Syst. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 116; Conference name: 52nd Annual Hawaii International Conference on System Sciences, HICSS 2019; Conference date: 8 January 2019 through 11 January 2019; Conference code: 169517}
}

@ARTICLE{Gruson20191,
	author = {Gruson, Damien and Helleputte, Thibault and Rousseau, Patrick and Gruson, David},
	title = {Data science, artificial intelligence, and machine learning: Opportunities for laboratory medicine and the value of positive regulation},
	year = {2019},
	journal = {Clinical Biochemistry},
	volume = {69},
	pages = {1 – 7},
	doi = {10.1016/j.clinbiochem.2019.04.013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064733267&doi=10.1016%2fj.clinbiochem.2019.04.013&partnerID=40&md5=cce26d6737067c2331477aef7f23f030},
	affiliations = {Department of Laboratory Medicine, Cliniques Universitaires St-Luc and Université Catholique de Louvain, Brussels, Belgium; Pôle de recherche en Endocrinologie, Diabète et Nutrition, Institut de Recherche Expérimentale et Clinique, Cliniques Universitaires St-Luc and Université Catholique de Louvain, Brussels, Belgium; Data-Driven Precision Medicine, DNAlytics, Louvain-la-Neuve, Belgium; Genetics Regulation for Paris Descartes-University, Paris, France},
	abstract = {Artificial intelligence (AI) and data science are rapidly developing in healthcare, as is their translation into laboratory medicine. Our review article presents an overview of the data science domain while discussing the reasons for its emergence. We also present several perspectives of its applications in clinical laboratories, along with potential ethical challenges related to AI and data science. © 2019 The Canadian Society of Clinical Chemists},
	author_keywords = {Artificial intelligence; Big data; Biomarker; Deep learning; Ethics; Health; Machine learning},
	keywords = {Artificial Intelligence; Big Data; Data Science; Humans; Machine Learning; Medical Laboratory Science; artificial intelligence; clinical trial (topic); cloud computing; data science; early diagnosis; health care practice; human; laboratory test; machine learning; omics; patient information; priority journal; privacy; Review; medical technology},
	correspondence_address = {D. Gruson; Pôle de recherche en Endocrinologie, Diabète et Nutrition (EDIN), Université Catholique de Louvain, Brussels, Tour Claude Bernard, 54 Avenue Hippocrate, B-1200, Belgium; email: damien.gruson@uclouvain.be},
	publisher = {Elsevier Inc.},
	issn = {00099120},
	coden = {CLBIA},
	pmid = {31022391},
	language = {English},
	abbrev_source_title = {Clin. Biochem.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 65}
}

@CONFERENCE{Allen2019116,
	author = {Allen, Laura K. and Perret, Cecile and Mills, Caitlin and McNamara, Danielle S.},
	title = {Are you talking to me? Multi-dimensional language analysis of explanations during reading},
	year = {2019},
	journal = {ACM International Conference Proceeding Series},
	pages = {116 – 120},
	doi = {10.1145/3303772.3303835},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062782008&doi=10.1145%2f3303772.3303835&partnerID=40&md5=fc38cbbe30432d1a365672259b640c8c},
	affiliations = {Mississippi State University, PO Box 872111, 39762, MS, United States; Arizona State University, PO Box 872111, Tempe, 85287, AZ, United States; University of New Hampshire, 15 Academic Way, Durham, 03824, NH, United States},
	abstract = {This study examines the extent to which instructions to selfexplain vs. other-explain a text lead readers to produce different forms of explanations. Natural language processing was used to examine the content and characteristics of the explanations produced as a function of instruction condition. Undergraduate students (n = 146) typed either self-explanations or other-explanations while reading a science text. The linguistic properties of these explanations were calculated using three automated text analysis tools. Machine learning classifiers in combination with the features were used to predict instruction condition (i.e., self- or other-explanation). The best machine learning model performed at rates above chance (kappa = .247; accuracy = 63%). Follow-up analyses indicated that students in the self-explanation condition generated explanations that were more cohesive and that contained words that were more related to social order (e.g., ethics). Overall, the results suggest that natural language processing techniques can be used to detect subtle differences in students' processing of complex texts. © 2019 Association for Computing Machinery.},
	author_keywords = {Comprehension; Corpus linguistics; Intelligent tutoring systems; Natural language processing; Reading},
	keywords = {Computer aided instruction; Linguistics; Machine learning; Students; Comprehension; Corpus linguistics; Intelligent tutoring system; NAtural language processing; Reading; Natural language processing systems},
	publisher = {Association for Computing Machinery},
	isbn = {978-145036256-6},
	language = {English},
	abbrev_source_title = {ACM Int. Conf. Proc. Ser.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 9th International Conference on Learning Analytics and Knowledge, LAK 2019; Conference date: 4 March 2019 through 8 March 2019; Conference code: 145666}
}

@ARTICLE{Prabhu2019621,
	author = {Prabhu, Sanjay P},
	title = {Ethical challenges of machine learning and deep learning algorithms},
	year = {2019},
	journal = {The Lancet Oncology},
	volume = {20},
	number = {5},
	pages = {621 – 622},
	doi = {10.1016/S1470-2045(19)30230-X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064819948&doi=10.1016%2fS1470-2045%2819%2930230-X&partnerID=40&md5=73fe0fab6c9df155599ec27d658dc05c},
	affiliations = {Dr Sanjay P Prabhu Department of Radiology, Boston Children's Hospital and Harvard Medical School, Boston, 02115, MA, United States},
	keywords = {Clinical Decision-Making; Decision Support Systems, Clinical; Deep Learning; Diagnosis, Computer-Assisted; Humans; Machine Learning; Patient Safety; Physician's Role; Predictive Value of Tests; Reproducibility of Results; Therapy, Computer-Assisted; algorithm; artificial intelligence; automation; bone radiography; clinical practice; deep learning; diabetic retinopathy; doctor patient relationship; food and drug administration; health care access; health care cost; human; information processing; law; machine learning; medical decision making; medical ethics; Note; online system; patient advocacy; priority journal; radius fracture; wrist fracture; clinical decision making; clinical decision support system; computer assisted diagnosis; computer assisted therapy; ethics; machine learning; patient safety; physician attitude; predictive value; reproducibility},
	publisher = {Lancet Publishing Group},
	issn = {14702045},
	coden = {LOANB},
	pmid = {31044701},
	language = {English},
	abbrev_source_title = {Lancet Oncol.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Chapalain2019337,
	author = {Chapalain, X. and Huet, O.},
	title = {Is artificial intelligence (AI) at the doorstep of Intensive Care Units (ICU) and operating room (OR)?},
	year = {2019},
	journal = {Anaesthesia Critical Care and Pain Medicine},
	volume = {38},
	number = {4},
	pages = {337 – 338},
	doi = {10.1016/j.accpm.2019.05.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065913641&doi=10.1016%2fj.accpm.2019.05.003&partnerID=40&md5=9ec567cff4dc6f3ca212c6db59140623},
	affiliations = {Department of Anaesthesiology and Surgical ICU, boulevard Tanguy-Prigent, Brest cedex, 29609, France},
	author_keywords = {Artificial intelligence; Big data; Monitoring devices; Personalised medicine},
	keywords = {Artificial Intelligence; Critical Care; Humans; Intensive Care Units; Intraoperative Care; Operating Rooms; oxygen; artificial intelligence; brain blood flow; brain metabolism; brain oxygen consumption; brain perfusion; cloud computing; convalescence; data analysis; data analysis software; Editorial; electroencephalography; human; information processing; intensive care unit; intracranial hypertension; intracranial pressure monitoring; learning; machine learning; medical assessment; medical decision making; microdialysis; mortality; personalized medicine; prediction; reinforcement; research ethics; sepsis; somatosensory evoked potential; survival rate; time series analysis; traumatic brain injury; white matter injury; intensive care; operating room; peroperative care; procedures},
	correspondence_address = {O. Huet; Department of Anaesthesiology and Surgical ICU, Brest cedex, boulevard Tanguy-Prigent, 29609, France; email: olivier.huet@chu-brest.fr},
	publisher = {Elsevier Masson SAS},
	issn = {23525568},
	pmid = {31102792},
	language = {English},
	abbrev_source_title = {Anaesth. Crit. Care Pain Med.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{O'Sullivan2019,
	author = {O'Sullivan, Shane and Nevejans, Nathalie and Allen, Colin and Blyth, Andrew and Leonard, Simon and Pagallo, Ugo and Holzinger, Katharina and Holzinger, Andreas and Sajid, Mohammed Imran and Ashrafian, Hutan},
	title = {Legal, regulatory, and ethical frameworks for development of standards in artificial intelligence (AI) and autonomous robotic surgery},
	year = {2019},
	journal = {International Journal of Medical Robotics and Computer Assisted Surgery},
	volume = {15},
	number = {1},
	doi = {10.1002/rcs.1968},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059739836&doi=10.1002%2frcs.1968&partnerID=40&md5=cbbb62d767531d8bfa21576a49ef1535},
	affiliations = {Department of Pathology, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; Research Center in Law, Ethics and Procedures, Faculty of Law of Douai, University of Artois, France; Department of History and Philosophy of Science, University of Pittsburgh, United States; Department of Computing and Mathematics, Faculty of Computing, Engineering and Science, University of South Wales, United Kingdom; Department of Computer Science, Johns Hopkins University, Baltimore, United States; Department of Jurisprudence, University of Turin, Italy; Secure Business Austria, SBA Research gGmbH, Vienna, Austria; Holzinger Group, HCI-KDD, Institute for Medical Informatics/Statistics. Medical University of Graz, Austria; Department of Upper GI Surgery, Wirral University Teaching Hospital, United Kingdom; Department of Surgery and Cancer and Institute of Global Health Innovation Imperial College London, United Kingdom},
	abstract = {Background: This paper aims to move the debate forward regarding the potential for artificial intelligence (AI) and autonomous robotic surgery with a particular focus on ethics, regulation and legal aspects (such as civil law, international law, tort law, liability, medical malpractice, privacy and product/device legislation, among other aspects). Methods: We conducted an intensive literature search on current or emerging AI and autonomous technologies (eg, vehicles), military and medical technologies (eg, surgical robots), relevant frameworks and standards, cyber security/safety- and legal-systems worldwide. We provide a discussion on unique challenges for robotic surgery faced by proposals made for AI more generally (eg, Explainable AI) and machine learning more specifically (eg, black box), as well as recommendations for developing and improving relevant frameworks or standards. Conclusion: We classify responsibility into the following: (1) Accountability; (2) Liability; and (3) Culpability. All three aspects were addressed when discussing responsibility for AI and autonomous surgical robots, be these civil or military patients (however, these aspects may require revision in cases where robots become citizens). The component which produces the least clarity is Culpability, since it is unthinkable in the current state of technology. We envision that in the near future a surgical robot can learn and perform routine operative tasks that can then be supervised by a human surgeon. This represents a surgical parallel to autonomously driven vehicles. Here a human remains in the ‘driving seat’ as a ‘doctor-in-the-loop’ thereby safeguarding patients undergoing operations that are supported by surgical machines with autonomous capabilities. © 2018 John Wiley & Sons, Ltd.},
	keywords = {Algorithms; Artificial Intelligence; Computer Security; Ethics, Medical; Europe; Humans; Medical Errors; Robotic Surgical Procedures; United States; Ethical technology; Intelligent robots; Surgical equipment; Artificial intelligence technologies; Autonomous robotics; Autonomous technology; Civil laws; Legal aspects; Literature search; On currents; On-currents; Robotics surgery; Vehicle technology; adult; army; artificial intelligence; ethics; human; international law; machine learning; malpractice; medical technology; privacy; responsibility; review; robot assisted surgery; surgeon; surgery; algorithm; computer security; ethics; Europe; legislation and jurisprudence; medical error; medical ethics; robotic surgical procedure; United States; Robotic surgery},
	correspondence_address = {S. O'Sullivan; Department of Pathology, Faculdade de Medicina, Universidade de São Paulo, São Paulo, Brazil; email: doctorshaneosullivan@gmail.com},
	publisher = {John Wiley and Sons Ltd},
	issn = {14785951},
	pmid = {30397993},
	language = {English},
	abbrev_source_title = {Int. J. Med. Rob. Comput. Assisted Surg.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 131}
}

@ARTICLE{Maouche2019447,
	author = {Maouche, Seraya},
	title = {Google AI: Opportunities, Risks, and Ethical Challenges},
	year = {2019},
	journal = {Contemporary French and Francophone Studies},
	volume = {23},
	number = {4},
	pages = {447 – 455},
	doi = {10.1080/17409292.2019.1705012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85082558011&doi=10.1080%2f17409292.2019.1705012&partnerID=40&md5=f8ddf6876d91ab24a5a3bb5380cb1c79},
	affiliations = {Ethique & Intégrité, 6 rue de Douai, Paris, 75009, France},
	abstract = {Emerging technologies (ET) are novel and relatively fast-growing technologies that can have massive socio-economic impact and bring new ethical and regulatory challenges. Although they cannot be considered as new technologies, artificial intelligence (AI) and related data driven technologies are examples of ET. AI is advancing at a rapid pace, in both public and private sectors, and being more widely deployed in different domains, including healthcare and education. In today’s digital age, our societies are facing rapid and massive technological transformations. It is important to ensure that the behavior of AI systems is beneficial to humanity. Policymakers and the research community need to identify the greatest barriers to AI adoption and related risks. In recent years, Google’s plans and visions to use ET gained serious and intense criticism. This situation pushed Google in March 2019 to announce an AI ethics panel which is supposed to offer guidance on ethical issues relating to AI, machine learning, and related technologies. This AI ethics panel was shut down just days after it was launched. The episode illustrates how ethical debates relating to ET are often characterized by ambiguity, dishonesty, and demagoguery. In this paper, I discuss the ethics of ET, focusing on Google and its AI platform. © 2020, © 2020 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {artificial intelligence; Emerging technologies; ethics of technology; Google AI; machine ethics; technology adoption},
	publisher = {Routledge},
	issn = {17409292},
	language = {English},
	abbrev_source_title = {Contemp. Fr. Francoph. Stud.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Kellmeyer2019329,
	author = {Kellmeyer, Philipp},
	title = {Ethical issues in the application of machine learning to brain disorders},
	year = {2019},
	journal = {Machine Learning: Methods and Applications to Brain Disorders},
	pages = {329 – 342},
	doi = {10.1016/B978-0-12-815739-8.00018-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85079478049&doi=10.1016%2fB978-0-12-815739-8.00018-3&partnerID=40&md5=6cbc3471f02abd252de6d3f94688891f},
	affiliations = {Neuromedical AI Lab, Department of Neurosurgery, Freiburg, Germany; Institute for Biomedical Ethics and History of Medicine, University of Zurich, Zurich, Switzerland; Freiburg Institute for Advanced Studies (FRIAS), Research Focus: Responsible Artificial Intelligence, University of Freiburg, Freiburg, Germany},
	abstract = {Leveraging machine learning methods for analyzing large amounts of digitized health-related data is one of the fastest growing areas of biomedical research and innovation. At the same time, these emerging technologies create important ethical and legal tensions. The aim of this chapter is to discuss these tensions, focusing on the following three issues: (i) increasing amount of health-related digital data creates challenges for protecting individual and group privacy; (ii) intelligent neurotechnological systems may adversely affect human agency, autonomy, and personal identity; and (iii) inherent biases in the data structures and ontologies may be replicated or amplified by algorithmic decision-support systems. In light of these tensions, multistakeholder discourse and deliberation are required to ensure effective and responsible development and implementation of these emerging technologies. © 2020 Elsevier Inc. All rights reserved.},
	author_keywords = {Accountability; Ai ethics; Brain disorders; Digital ethics; Machine learning; Neuroethics; Neuroimaging; Neurologic disorders; Neurotechnology; Psychiatric disorders},
	publisher = {Elsevier},
	isbn = {978-012815739-8},
	language = {English},
	abbrev_source_title = {Machine Learning: Methods and Applications to Brain Disorders},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Di Nucci2019556,
	author = {Di Nucci, Ezio},
	title = {Should we be afraid of medical AI?},
	year = {2019},
	journal = {Journal of Medical Ethics},
	volume = {45},
	number = {8},
	pages = {556 – 558},
	doi = {10.1136/medethics-2018-105281},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068009029&doi=10.1136%2fmedethics-2018-105281&partnerID=40&md5=12871f7777509a03df6aa43fef0f2811},
	affiliations = {University of Copenhagen, Copenhagen, Denmark},
	abstract = {I analyse an argument according to which medical artificial intelligence (AI) represents a threat to patient autonomy - recently put forward by Rosalind McDougall in the Journal of Medical Ethics. The argument takes the case of IBM Watson for Oncology to argue that such technologies risk disregarding the individual values and wishes of patients. I find three problems with this argument: (1) it confuses AI with machine learning; (2) it misses machine learning's potential for personalised medicine through big data; (3) it fails to distinguish between evidence-based advice and decision-making within healthcare. I conclude that how much and which tasks we should delegate to machine learning and other technologies within healthcare and beyond is indeed a crucial question of our time, but in order to answer it, we must be careful in analysing and properly distinguish between the different systems and different delegated tasks. © Author(s) (or their employer(s)) 2019. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {ethics},
	keywords = {Artificial Intelligence; Ethics, Medical; Humans; Machine Learning; Medical Oncology; adult; artificial intelligence; big data; decision making; human; machine learning; medical ethics; oncology; patient autonomy; personalized medicine; review; artificial intelligence; machine learning; medical ethics},
	correspondence_address = {E. Di Nucci; University of Copenhagen, Copenhagen, Denmark; email: ezio@sund.ku.dk},
	publisher = {BMJ Publishing Group},
	issn = {03066800},
	coden = {JMETD},
	pmid = {31227547},
	language = {English},
	abbrev_source_title = {J. Med. Ethics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@ARTICLE{De La Fuente Garcia2019,
	author = {De La Fuente Garcia, Sofia and Ritchie, Craig W. and Luz, Saturnino},
	title = {Protocol for a conversation-based analysis study: PREVENT-ED investigates dialogue features that may help predict dementia onset in later life},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {3},
	doi = {10.1136/bmjopen-2018-026254},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063629126&doi=10.1136%2fbmjopen-2018-026254&partnerID=40&md5=c5827dcbfa131d78f97b4478156c76e8},
	affiliations = {Usher Institute of Population Health Sciences and Informatics, University of Edinburgh, School of Molecular Genetic and Population Health Sciences, Edinburgh, United Kingdom; Centre for Clinical Brain Sciences, Department of Psychiatry, University of Edinburgh, Edinburgh, United Kingdom},
	abstract = {Introduction Decreasing the incidence of Alzheimer's disease (AD) is a global public health priority. Early detection of AD is an important requisite for the implementation of prevention strategies towards this goal. While it is plausible that patients at the early stages of AD may exhibit subtle behavioural signs of neurodegeneration, neuropsychological testing seems unable to detect these signs in preclinical AD. Recent studies indicate that spontaneous speech data, which can be collected frequently and naturally, provide good predictors for AD detection in cohorts with a clinical diagnosis. The potential of models based on such data for detecting preclinical AD remains unknown. Methods and analysis The PREVENT-Elicitation of Dialogues (PREVENT-ED) study builds on the PREVENT Dementia project to investigate whether early behavioural signs of AD may be detected through dialogue interaction. Participants recruited through PREVENT, aged 40-59 at baseline, will be included in this study. We will use speech processing and machine learning methods to assess how well speech and visuospatial markers agree with neuropsychological, biomarker, clinical, lifestyle and genetic data from the PREVENT cohort. Ethics and dissemination There are no expected risks or burdens to participants. The procedures are not invasive and do not raise significant ethical issues. We only approach healthy consenting adults and all participants will be informed that this is an exploratory study and therefore has no diagnostic aim. Confidentiality aspects such as data encryption and storage comply with the General Data Protection Regulation and with the requirements from sponsoring bodies and ethical committees. This study has been granted ethical approval by the London-Surrey Research Ethics Committee (REC reference No: 18/LO/0860), and by Caldicott and Information Governance (reference No: CRD18048). PREVENT-ED results will be published in peer-reviewed journals. © 2019 Author(s) (or their employer(s)). Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {computational paralinguistics; dementia prevention; dialogue analysis; dialogue analysis; early detection of Alzheimer's disease; psycholinguistics; screening; speech processing},
	keywords = {Adult; Cognitive Dysfunction; Dementia; Early Diagnosis; Female; Humans; Language Disorders; Machine Learning; Male; Middle Aged; Neuropsychological Tests; Speech; amyloid beta protein[1-42]; apolipoprotein E; adult; Alzheimer disease; Article; behavior change; brain atrophy; clinical assessment; clinical feature; clinical protocol; cognition; cohort analysis; communication skill; confidentiality; conversation; dementia; disease burden; human; lifestyle modification; machine learning; medial temporal lobe; middle aged; neuropsychology; risk assessment; risk factor; social interaction; spatial orientation; speech analysis; speech articulation; white matter lesion; cognitive defect; dementia; early diagnosis; female; language disability; male; neuropsychological test; psychology; speech},
	correspondence_address = {C.W. Ritchie; Centre for Clinical Brain Sciences, Department of Psychiatry, University of Edinburgh, Edinburgh, United Kingdom; email: sofia.delafuente@ed.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {30918035},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Miller20191,
	author = {Miller, Seumas},
	title = {Machine Learning, Ethics and Law},
	year = {2019},
	journal = {Australasian Journal of Information Systems},
	volume = {23},
	pages = {1 – 13},
	doi = {10.3127/ajis.v23i0.1893},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85104722392&doi=10.3127%2fajis.v23i0.1893&partnerID=40&md5=a617dcda10fdf41a421482c6c6cfe9ed},
	affiliations = {Charles Sturt University, TU Delft, University of Oxford},
	abstract = {Recent revelations concerning data firm Cambridge Analytica’s illegitimate use of the data of millions of Facebook users highlights the ethical and, relatedly, legal issues arising from the use of machine learning techniques. Cambridge Analytica is, or was – the revelations brought about its demise - a firm that used machine learning processes to try to influence elections in the US and elsewhere by, for instance, targeting ‘vulnerable’ voters in marginal seats with political advertising. Of course, there is nothing new about political candidates and parties employing firms to engage in political advertising on their behalf, but if a data firm has access to the personal information of millions of voters, and is skilled in the use of machine learning techniques, then it can develop detailed, fine-grained voter profiles that enable political actors to reach a whole new level of manipulative influence over voters. My focus in this paper is not with the highly publicised ethical and legal issues arising from Cambridge Analytic’s activities but rather with some important ethical issues arising from the use of machine learning techniques that have not received the attention and analysis that they deserve. I focus on three areas in which machine learning techniques are used or, it is claimed, should be used, and which give rise to problems at the interface of law and ethics (or law and morality, I use the terms “ethics” and “morality” interchangeably). The three areas are profiling and predictive policing (Saunders et al. 2016), legal adjudication (Zeleznikow, 2017), and machines’ compliance with legally enshrined moral principles (Arkin 2010). I note that here, as elsewhere, new and emerging technologies are developing rapidly making it difficult to predict what might or might not be able to be achieved in the future. For this reason, I have adopted the conservative stance of restricting my ethical analysis to existing machine learning techniques and applications rather than those that are the object of speculation or even informed extrapolation (Mittelstadt et al. 2015). This has the consequence that what I might regard as a limitation of machine learning techniques, e.g. in respect of predicting novel outcomes or of accommodating moral principles, might be thought by others to be merely a limitation of currently available techniques. After all, has not the history of AI recently shown the naysayers to have been proved wrong? Certainly, AI has seen some impressive results, including the construction of computers that can defeat human experts in complex games, such as chess and Go (Silver et al. 2017), and others that can do a better job than human medical experts at identifying the malignancy of moles and the like (Esteva et al. 2017). However, since by definition future machine learning techniques and applications are not yet with us the general claim that current limitations will be overcome cannot at this time be confirmed or disconfirmed on the basis of empirical evidence. © 2019 Miller. This is an open-access article distributed under the terms of the Creative Commons Attribution-NonCommercial 3.0 Australia License, which permits non-commercial use, distribution, and reproduction in any medium, provided the original author and AJIS are credited.},
	author_keywords = {applied ethics; law; machine-learning},
	correspondence_address = {S. Miller; Charles Sturt University, TU Delft, University of Oxford; email: semiller@csu.edu.au},
	publisher = {Australasian Association for Information Systems},
	issn = {14498618},
	language = {English},
	abbrev_source_title = {Australas. J. Inf. Syst.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Agavanakis2019,
	author = {Agavanakis, Kyriakos N. and Karpetas, George. E. and Taylor, Michael and Pappa, Evangelia and Michail, Christos M. and Filos, John and Trachana, Varvara and Kontopoulou, Lamprini},
	title = {Practical machine learning based on cloud computing resources},
	year = {2019},
	journal = {AIP Conference Proceedings},
	volume = {2123},
	doi = {10.1063/1.5117023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069761004&doi=10.1063%2f1.5117023&partnerID=40&md5=7802f8f7977c0856019cb378165ea674},
	affiliations = {ATRINNO, Attica Research and Innovation, Athens, 11631, Greece; Department of Medical Physics, Faculty of Medicine, School of Health Sciences, University of Thessaly, Larissa, 41110, Greece; Department of Meteorology, University of Reading, RG6 6BB, United Kingdom; Department of Public Administration School of Economy and Public Administration, Panteion University of Social and Political Sciences, Athens, 17671, Greece; University of West Attica, Department of Biomedical Engineering Radiation Physics, Materials Technology and Biomedical Imaging Laboratory, Ag. Spyridonos, Athens, 12210, Greece; Department of Biology, Faculty of Medicine, School of Health Sciences, University of Thessaly, Larisa, 41500, Greece; General Department, University of Thessaly, Larissa, 41110, Greece},
	abstract = {Machine learning is a domain highly influenced by the rapid evolution of cloud computing and has reached a maturity point where a plethora of data processing capabilities is now widely available. The aim of the present study is to investigate the potential for building a common platform to support direct end-user application of machine learning algorithms across diverse scientific areas, emphasizing not only the suitability of appropriate tools, but also how results can be disseminated and utilized in a shared data environment. Three case studies are presented: i) quality evaluation metrics for tomographic image reconstruction in positron emission tomography (PET), ii) health impacts of surface UV radiation and iii) demographic determinants that influence the perception of fraud and corruption incidents within different industry sectors. Tests showed that commercially available cloud resources are over-sufficient to consolidate results from a variety of teams and applications and are able to contribute to the build-up of a valuable shared knowledge repository. The cloud service platform exploits machine learning models and helps automate the training and prediction process. The suggested approach makes optimization more efficient and supports the transition to a more sustainable global information environment by breaking knowledge silos. © 2019 Author(s).},
	author_keywords = {big data; business ethics; cloud computing; DaaS; health; knowledge sharing; Machine learning; NoSQL; PaaS; PET; SaaS; web services},
	editor = {Salame C.-T. and Shaban A.H. and Papageorgas P. and Aillerie M.},
	publisher = {American Institute of Physics Inc.},
	issn = {0094243X},
	isbn = {978-073541863-9},
	language = {English},
	abbrev_source_title = {AIP Conf. Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: International Conference on Technologies and Materials for Renewable Energy, Environment and Sustainability 2019, TMREES 2019; Conference date: 10 April 2019 through 12 April 2019; Conference code: 149660}
}

@ARTICLE{Asaro201940,
	author = {Asaro, Peter M.},
	title = {AI ethics in predictive policing: From models of threat to an ethics of care},
	year = {2019},
	journal = {IEEE Technology and Society Magazine},
	volume = {38},
	number = {2},
	pages = {40 – 53},
	doi = {10.1109/MTS.2019.2915154},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067188723&doi=10.1109%2fMTS.2019.2915154&partnerID=40&md5=901ec69becc07fd06a1c89d8d19f2145},
	abstract = {The adoption of data-driven organizational management - which includes big data, machine learning, and artificial intelligence (AI) techniques - is growing rapidly across all sectors of the knowledge economy. There is little doubt that the collection, dissemination, analysis, and use of data in government policy formation, strategic planning, decision execution, and the daily performance of duties can improve the functioning of government and the performance of public services. This is as true for law enforcement as any other government service. © 1982-2012 IEEE.},
	keywords = {Artificial intelligence; Learning systems; Data driven; Government services; Knowledge economy; Organizational management; Public services; Philosophical aspects},
	correspondence_address = {P.M. Asaro; email: asarop@newschool.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {02780097},
	coden = {ITSMD},
	language = {English},
	abbrev_source_title = {IEEE Technol Soc Mag},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 44}
}

@ARTICLE{Bertsimas20191109,
	author = {Bertsimas, Dimitris and Kung, Jerry and Trichakis, Nikolaos and Wang, Yuchen and Hirose, Ryutaro and Vagefi, Parsia A.},
	title = {Development and validation of an optimized prediction of mortality for candidates awaiting liver transplantation},
	year = {2019},
	journal = {American Journal of Transplantation},
	volume = {19},
	number = {4},
	pages = {1109 – 1118},
	doi = {10.1111/ajt.15172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057967735&doi=10.1111%2fajt.15172&partnerID=40&md5=66c590a8d32b6233a904fa1cc66e3d1f},
	affiliations = {Operations Research Center, Massachusetts Institute of Technology, Cambridge, MA, United States; Department of Surgery, University of California, San Francisco, United States; Department of Surgery, University of Texas Southwestern Medical Center, Dallas, TX, United States},
	abstract = {Since 2002, the Model for End-Stage Liver Disease (MELD) has been used to rank liver transplant candidates. However, despite numerous revisions, MELD allocation still does not allow for equitable access to all waitlisted candidates. An optimized prediction of mortality (OPOM) was developed (http://www.opom.online) utilizing machine-learning optimal classification tree models trained to predict a candidate's 3-month waitlist mortality or removal utilizing the Standard Transplant Analysis and Research (STAR) dataset. The Liver Simulated Allocation Model (LSAM) was then used to compare OPOM to MELD-based allocation. Out-of-sample area under the curve (AUC) was also calculated for candidate groups of increasing disease severity. OPOM allocation, when compared to MELD, reduced mortality on average by 417.96 (406.8-428.4) deaths every year in LSAM analysis. Improved survival was noted across all candidate demographics, diagnoses, and geographic regions. OPOM delivered a substantially higher AUC across all disease severity groups. OPOM more accurately and objectively prioritizes candidates for liver transplantation based on disease severity, allowing for more equitable allocation of livers with a resultant significant number of additional lives saved every year. These data demonstrate the potential of machine learning technology to help guide clinical practice, and potentially guide national policy. © 2018 The American Society of Transplantation and the American Society of Transplant Surgeons},
	author_keywords = {ethics and public policy; liver transplantation/hepatology; liver transplantation: auxiliary; simulation; statistics},
	keywords = {Female; Humans; Liver Diseases; Liver Transplantation; Machine Learning; Male; Models, Statistical; Waiting Lists; Article; deterioration; development; disease severity; dying; female; human; liver graft; liver transplantation; major clinical study; male; mortality; prediction; priority journal; probability; hospital admission; liver disease; machine learning; statistical model},
	correspondence_address = {D. Bertsimas; Operations Research Center, Massachusetts Institute of Technology, Cambridge, United States; email: dbertsim@mit.edu},
	publisher = {Blackwell Publishing Ltd},
	issn = {16006135},
	coden = {AJTMB},
	pmid = {30411495},
	language = {English},
	abbrev_source_title = {Am. J. Transplant.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{El-Bahnasawi2019933,
	author = {El-Bahnasawi, M. and Tekkis, P. and Kontovounisios, C.},
	title = {Is it the surgeon or the technology performing the operation?},
	year = {2019},
	journal = {Techniques in Coloproctology},
	volume = {23},
	number = {9},
	pages = {933 – 934},
	doi = {10.1007/s10151-019-02063-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071262189&doi=10.1007%2fs10151-019-02063-1&partnerID=40&md5=95ee3bad15c40fffb734132cdb3b6bb1},
	affiliations = {Department of Surgery and Cancer, Imperial College, London, United Kingdom; Department of Colorectal Surgery, Royal Marsden hospital, London, United Kingdom; Department of Colorectal Surgery, Chelsea Westminster hospital, London, United Kingdom},
	keywords = {Biomedical Technology; Clinical Competence; Colorectal Surgery; Humans; Surgeons; algorithm; artificial intelligence; decision making; deep learning; health care; image reconstruction; Letter; machine learning; medical education; medical ethics; medical expert; medical technology; patient monitoring; patient referral; pattern recognition; preoperative period; problem solving; professional competence; robotics; surgeon; three dimensional imaging; three dimensional printing; treatment planning; clinical competence; colorectal surgery; human; medical technology; surgeon},
	correspondence_address = {C. Kontovounisios; Department of Surgery and Cancer, Imperial College, London, United Kingdom; email: c.kontovounisios@imperial.ac.uk},
	publisher = {Springer-Verlag Italia s.r.l.},
	issn = {11236337},
	coden = {TECOF},
	pmid = {31432334},
	language = {English},
	abbrev_source_title = {Tech. Coloproctol.},
	type = {Letter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Das201958,
	author = {Das, Anubrata and Anjum, Samreen and Gurari, Danna},
	title = {Dataset bias: A case study for visual question answering},
	year = {2019},
	journal = {Proceedings of the Association for Information Science and Technology},
	volume = {56},
	number = {1},
	pages = {58 – 67},
	doi = {10.1002/pra2.7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076111044&doi=10.1002%2fpra2.7&partnerID=40&md5=635cde9dee7e8325f596eb1a73a090e6},
	affiliations = {School of Information, University of Texas at Austin, United States},
	abstract = {We examine the issue of bias in datasets designed to train visual question answering (VQA) algorithms. These datasets include a collection of natural language questions about images (aka - visual questions). We consider three popular datasets that are captured by people with sight, people who are blind, and generated by computers. We first demonstrate that machine learning algorithms can be trained to recognize each dataset's bias, and so determine the source of a novel visual question. We then discuss potential risks and benefits of biased VQA datasets and corresponding machine learning algorithms that can identify the source of a visual question; e.g., whether it comes from a person with sight, a person who is blind, or bot (aka - computer). Our ultimate aim is to inspire the development of more inclusive VQA systems. Author(s) retain copyright, but ASIS&T receives an exclusive publication license},
	author_keywords = {Assistive Technologies; Bias in Machine Learning; Ethics of Artificial Intelligence; Visual Question Answering},
	publisher = {John Wiley and Sons Inc},
	issn = {23739231},
	language = {English},
	abbrev_source_title = {Proceedings of the Association for Information Science and Technology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Zerka2019,
	author = {Zerka, Fadila and Barakat, Samir and Walsh, Sean and Bogowicz, Marta and Leijenaar, Ralph T.H. and Jochems, Arthur and Miraglio, Benjamin and Townend, David and Lambin, Philippe},
	title = {Systematic Review of Privacy-Preserving Distributed Machine Learning from Federated Databases in Health Care},
	year = {2019},
	journal = {JCO Clinical Cancer Informatics},
	volume = {3},
	doi = {10.1200/CCI.19.00047},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85087069318&doi=10.1200%2fCCI.19.00047&partnerID=40&md5=15339d1f7bc1694e4661861853a3e1e7},
	affiliations = {D-Lab, Department of Precision Medicine, GROW School for Oncology and Developmental Biology, Maastricht University Medical Centre, Maastricht, Netherlands; Oncoradiomics, Liège, Belgium; Department of Radiation Oncology, University Hospital Zurich, University of Zurich, Zurich, Switzerland; Department of Health, Ethics, and Society, CAPHRI (Care and Public Health Research Institute), Maastricht University, Maastricht, Netherlands},
	abstract = {Big data for health care is one of the potential solutions to deal with the numerous challenges of health care, such as rising cost, aging population, precision medicine, universal health coverage, and the increase of noncommunicable diseases. However, data centralization for big data raises privacy and regulatory concerns. Covered topics include (1) an introduction to privacy of patient data and distributed learning as a potential solution to preserving these data, a description of the legal context for patient data research, and a definition of machine/deep learning concepts; (2) a presentation of the adopted review protocol; (3) a presentation of the search results; and (4) a discussion of the findings, limitations of the review, and future perspectives. Distributed learning from federated databases makes data centralization unnecessary. Distributed algorithms iteratively analyze separate databases, essentially sharing research questions and answers between databases instead of sharing the data. In other words, one can learn from separate and isolated datasets without patient data ever leaving the individual clinical institutes. Distributed learning promises great potential to facilitate big data for medical application, in particular for international consortiums. Our purpose is to review the major implementations of distributed learning in health care. © 2020 by American Society of Clinical Oncology},
	keywords = {Algorithms; Data Management; Data Mining; Databases, Factual; Delivery of Health Care; Electronic Health Records; Humans; Machine Learning; Precision Medicine; Privacy; big data; clinical research; data integration; deep learning; electronic medical record; human; law; machine learning; medical ethics; medical informatics; oncology; patient coding; priority journal; privacy; Review; systematic review; algorithm; data mining; electronic health record; ethics; factual database; health care delivery; information processing; personalized medicine; procedures},
	correspondence_address = {F. Zerka; Universiteit Maastricht, Maastricht, Postbus 616, 6200 MD, Netherlands; email: f.zerka@maastrichtuniversity.nl},
	publisher = {American Society of Clinical Oncology},
	issn = {24734276},
	pmid = {32134684},
	language = {English},
	abbrev_source_title = {JCO Clin. Cancer Inform.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 58; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Chattopadhyay2019,
	author = {Chattopadhyay, Ankur and Christian, David and Ulman, Adam and Sawyer, Caleb},
	title = {A Middle-School Case Study: Piloting A Novel Visual Privacy Themed Module for Teaching Societal and Human Security Topics Using Social Media Apps},
	year = {2019},
	journal = {Proceedings - Frontiers in Education Conference, FIE},
	volume = {2018-October},
	doi = {10.1109/FIE.2018.8659278},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063486026&doi=10.1109%2fFIE.2018.8659278&partnerID=40&md5=fc65989c461bac4149d0f65731114afc},
	affiliations = {Department of Information and Computing Sciences, University of Wisconsin - Green Bay, Green Bay, WI, United States},
	abstract = {This Full paper in the Innovative Practice Category introduces an innovative visual privacy themed pre-university educational module using social media apps for creating privacy awareness as well as teaching societal and human security topics. With the advent of internet (World Wide Web) and social media, and the extensive use of these resources by naïve young users, privacy issues pop up every now and then. The lack of privacy and security awareness may lead to confidential information leaks during the use of online contents, particularly social media. The current IEEE/ACM curricular guidelines in CS, IT and cybersecurity clearly point to a need for inclusion of societal and human security topics at the college level, so that a general awareness can be created regarding today's growing privacy concerns, including privacy issues with media sharing. However, there is still a gap within the K-12 curriculum in regard to these security and privacy topics. Even though there has been some computing educational research work on the topic of data privacy at the K-12 level, the visual privacy theme under the societal and human security domain has hardly been explored within K-12. None of the K-12 cybersecurity educational modules have employed the privacy-enhanced computer vision theme along with a social media platform. This paper intends to address the this gap by presenting a visual privacy themed lesson plan using social media apps for teaching privacy, ethics and machine learning. Its main contribution is a unique visual privacy education based hands-on outreach module that utilizes the PVA (Privacy through Visual Anonymity) notion to teach privacy, ethics and machine learning using media images and videos. Our module uses two freely accessible apps, namely an Obscura Cam and YouTube - Face Blur. These apps are utilized to illustrate the concept of visual privacy and demonstrate PVA in pictures and media clips. Additionally, this paper describes our research case study conducted by piloting our PVA workshop module at the middle-school level. This paper discusses and analyzes the learner data obtained from the workshop participants as part of our Google IgniteCS outreach project. The learning analytics survey data collected during our PVA workshop sessions with various middle-school participants indicate that the described visual privacy module can become a simple yet effective tool for privacy literacy, as it can help build privacy perceptions in young minds. Our acquired results also suggest that that this PVA themed outreach lesson plan can be used as a potential medium for recruiting K-12 students into computing and cybersecurity disciplines. © 2018 IEEE.},
	author_keywords = {Awareness; Computing; CS; Cyber security; Educational workshop module; Ethics; Human security; IT; K-12; Machine learning; Middle-school; Outreach; Privacy-enhanced computer vision; PVA; Social media apps; Societal security; Visual privacy},
	keywords = {Cesium; Computer privacy; Computer vision; Learning systems; Machine learning; Philosophical aspects; Planning; Social networking (online); Surveys; Teaching; Awareness; Computing; Cyber security; Educational workshops; Ethics; Human securities; Middle school; Outreach; Social media; Societal securities; Data privacy},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {15394565},
	isbn = {978-153861173-9},
	coden = {PFECD},
	language = {English},
	abbrev_source_title = {Proc. Front. Educ. Conf. FIE},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 48th Frontiers in Education Conference, FIE 2018; Conference date: 3 October 2018 through 6 October 2018; Conference code: 145840}
}

@ARTICLE{Melero-Alegria2019,
	author = {Melero-Alegria, Jose Ignacio and Cascon, Manuel and Romero, Alfonso and Vara, Pedro Pablo and Barreiro-Perez, Manuel and Vicente-Palacios, Victor and Perez-Escanilla, Fernando and Hernandez-Hernandez, Jesus and Garde, Beatriz and Cascon, Sara and Martin-Garcia, Ana and Diaz-Pelaez, Elena and De Dios, Jose Maria and Uribarri, Aitor and Jimenez-Candil, Javier and Cruz-Gonzalez, Ignacio and Blazquez, Baltasara and Hernandez, Jose Manuel and Sanchez-Pablo, Clara and Santolino, Inmaculada and Ledesma, Maria Concepcion and Muriel, Paz and Dorado-Diaz, P. Ignacio and Sanchez, Pedro L.},
	title = {SALMANTICOR study. Rationale and design of a population-based study to identify structural heart disease abnormalities: A spatial and machine learning analysis},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {2},
	doi = {10.1136/bmjopen-2018-024605},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061562299&doi=10.1136%2fbmjopen-2018-024605&partnerID=40&md5=39592665fe08c5496cc135f5f4eae195},
	affiliations = {Department of Cardiology, Hospital Universitario de Salamanca, Instituto de Investigación Biomédica de Salamanca (IBSAL), Facultad de Medicina, Universidad de Salamanca, CIBERCV, Salamanca, Spain; Miguel Armijo Primary Care Centre, Salamanca, Spain; San Juan Primary Care Centre, Salamanca, Spain; Robleda Primary Care Center, Salamanca, Spain; Salamanca Primary Care Centre Management, Salamanca, Spain; Miranda del Castañar Primary Care Centre, Salamanca, Spain; Santa Marta Primary Care Centre, Salamanca, Spain; Peñaranda de Bracamonte Primary Care Centre, Salamanca, Spain},
	abstract = {Introduction: This study aims to obtain data on the prevalence and incidence of structural heart disease in a population setting and, to analyse and present those data on the application of spatial and machine learning methods that, although known to geography and statistics, need to become used for healthcare research and for political commitment to obtain resources and support effective public health programme implementation. Methods and analysis: We will perform a cross-sectional survey of randomly selected residents of Salamanca (Spain). 2400 individuals stratified by age and sex and by place of residence (rural and urban) will be studied. The variables to analyse will be obtained from the clinical history, different surveys including social status, Mediterranean diet, functional capacity, ECG, echocardiogram, VASERA and biochemical as well as genetic analysis. Ethics and dissemination: The study has been approved by the ethical committee of the healthcare community. All study participants will sign an informed consent for participation in the study. The results of this study will allow the understanding of the relationship between the different influencing factors and their relative importance weights in the development of structural heart disease. For the first time, a detailed cardiovascular map showing the spatial distribution and a predictive machine learning system of different structural heart diseases and associated risk factors will be created and will be used as a regional policy to establish effective public health programmes to fight heart disease. At least 10 publications in the first-quartile scientific journals are planned. © 2019 Author(s).},
	author_keywords = {machine learning; population; rural; spatial analysis; structural heart disease; urban},
	keywords = {Adolescent; Adult; Aged; Cross-Sectional Studies; Female; Heart Diseases; Humans; Incidence; Machine Learning; Male; Middle Aged; Prevalence; Prospective Studies; Research Design; Risk Factors; Spain; Spatial Analysis; Surveys and Questionnaires; Young Adult; adult; Article; cardiovascular risk; controlled study; cross-sectional study; female; health care planning; heart disease; human; incidence; machine learning; major clinical study; middle aged; nonhuman; prevalence; public health service; Spain; spatial analysis; structural heart disease; adolescent; aged; heart disease; machine learning; male; methodology; prospective study; questionnaire; risk factor; spatial analysis; young adult},
	correspondence_address = {P.L. Sanchez; Department of Cardiology, Hospital Universitario de Salamanca, Instituto de Investigación Biomédica de Salamanca (IBSAL), Facultad de Medicina, Universidad de Salamanca, CIBERCV, Salamanca, Spain; email: pedrolsanchez@secardiologia.es},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {30765403},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Caliebe2019765,
	author = {Caliebe, Amke and Scherag, André and Strech, Daniel and Mansmann, Ulrich},
	title = {Scientific and ethical evaluation of projects in data-driven medicine; [Wissenschaftliche und ethische Bewertung von Projekten in der datengetriebenen Medizin]},
	year = {2019},
	journal = {Bundesgesundheitsblatt - Gesundheitsforschung - Gesundheitsschutz},
	volume = {62},
	number = {6},
	pages = {765 – 772},
	doi = {10.1007/s00103-019-02958-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85065658806&doi=10.1007%2fs00103-019-02958-2&partnerID=40&md5=0b79fa840b8887833e62ed67239a0319},
	affiliations = {Institut für Medizinische Informatik und Statistik, Universitätsklinikum Schleswig-Holstein, Christian-Albrechts-Universität zu Kiel, Kiel, Germany; Institut für Medizinische Statistik, Informatik und Datenwissenschaften, Universitätsklinikum Jena, Jena, Germany; AG „Translationale Bioethik“, QUEST – Center, Berliner Institut für Gesundheitsforschung (BIG/BIH), Charité – Universitätsmedizin Berlin, Berlin, Germany; Institut für Medizinische Informationsverarbeitung, Biometrie und Epidemiologie, Lehrstuhl Medizinische Biometrie und Bioinformatik, LMU München, Marchioninistraße 15, München, 81377, Germany},
	abstract = {The generation and usage of extensive data from medical care aims at answering crucial medical research questions. Buzzwords in this area are learning health system, data-driven medicine and big data. In addition to classical biostatistical methods, machine learning approaches are frequently applied for analysis. In the evaluation of projects from data-driven medicine by research ethics committees, the question arises of how to assess the benefit-risk ratio and the scientific and social value. Which knowledge is required for that purpose? How can research ethics committees prepare for these challenges? Scientific approaches from the area of observational studies and the consideration of agreed-upon ethical aspects (consent, validity, justice, benefit-risk ratio and transparency) can help to answer the above-mentioned questions. One has to bear in mind that data-driven medicine is no paradigm shift that in principle challenges the established scientific and ethical evaluation procedures. Nevertheless, the evaluation of projects from data-driven medicine requires enhanced specialisation and comprehensive methodical expertise from the areas of machine learning and observational studies. Empirical research of the progression and governance of data-driven medicine will support the development and continual adaptation of effective strategies for evaluation by research ethics committees. Training and networking of experts will enable us to meet the challenges of data-driven medicine. © 2019, Springer-Verlag GmbH Deutschland, ein Teil von Springer Nature.},
	author_keywords = {Big data in medicine; Data-driven medicine; Ethical review; Research ethics committee; Scientific review},
	keywords = {Biomedical Research; Data Science; Ethics Committees, Research; Germany; big data; empirical research; human; justice; machine learning; medical care; medical research; observational study; research ethics; review; risk assessment; specialization; validity; Germany; medical research; professional standard},
	correspondence_address = {U. Mansmann; Institut für Medizinische Informationsverarbeitung, Biometrie und Epidemiologie, Lehrstuhl Medizinische Biometrie und Bioinformatik, LMU München, München, Marchioninistraße 15, 81377, Germany; email: Ulrich.Mansmann@lmu.de},
	publisher = {Springer Verlag},
	issn = {14369990},
	pmid = {31073661},
	language = {German},
	abbrev_source_title = {Bundesgesund.blatt. Gesund.forschung. Gesund.schutz.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Cross2019,
	author = {Cross, Emily S. and Hortensius, Ruud and Wykowska, Agnieszka},
	title = {From social brains to social robots: Applying neurocognitive insights to human-robot interaction},
	year = {2019},
	journal = {Philosophical Transactions of the Royal Society B: Biological Sciences},
	volume = {374},
	number = {1771},
	doi = {10.1098/rstb.2018.0024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062702438&doi=10.1098%2frstb.2018.0024&partnerID=40&md5=ea74cb628e66d5b10b64417ba83f8ae1},
	affiliations = {Institute of Neuroscience and Psychology, School of Psychology, University of Glasgow, 58 Hillhead Street, Glasgow, G12 8QB, United Kingdom; Istituto Italiano di Tecnologia, Via Morego, Genoa, 30 16163, Italy},
	abstract = {Amidst the fourth industrial revolution, social robots are resolutely moving from fiction to reality. With sophisticated artificial agents becoming ever more ubiquitous in daily life, researchers across different fields are grappling with the questions concerning how humans perceive and interact with these agents and the extent to which the human brain incorporates intelligent machines into our social milieu. This theme issue surveys and discusses the latest findings, current challenges and future directions in neuroscience- and psychology-inspired human-robot interaction (HRI). Critical questions are explored from a transdisciplinary perspective centred around four core topics in HRI: technical solutions for HRI, development and learning for HRI, robots as a tool to study social cognition, and moral and ethical implications of HRI. Integrating findings from diverse but complementary research fields, including social and cognitive neurosciences, psychology, artificial intelligence and robotics, the contributions showcase ways in which research from disciplines spanning biological sciences, social sciences and technology deepen our understanding of the potential and limits of robotic agents in human social life. This article is part of the theme issue 'From social brains to social robots: applying neurocognitive insights to human-robot interaction'. © 2019 The Author(s) Published by the Royal Society. All rights reserved.},
	author_keywords = {Artificial intelligence; Ethics; Human-brain; Robotics; Social neuroscience; Social robotics},
	keywords = {Artificial Intelligence; Brain; Cognition; Humans; Neurosciences; Robotics; Social Behavior; artificial intelligence; brain; ethics; machine learning; research work; robotics; science and technology; artificial intelligence; brain; cognition; human; neuroscience; physiology; procedures; robotics; social behavior},
	correspondence_address = {E.S. Cross; Institute of Neuroscience and Psychology, School of Psychology, University of Glasgow, Glasgow, 58 Hillhead Street, G12 8QB, United Kingdom; email: emily.cross@glasgow.ac.uk},
	publisher = {Royal Society Publishing},
	issn = {09628436},
	coden = {PTRBA},
	pmid = {30852997},
	language = {English},
	abbrev_source_title = {Philos. Trans. R. Soc. B Biol. Sci.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 55; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Banerjee20191012,
	author = {Banerjee, Debanjana and Prabhat, Gyan and Bhowal, Riyanka},
	title = {ICASSTLE : IImbalanced Classification Algorithm for Semi Supervised Text Learning},
	year = {2019},
	journal = {Proceedings - 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018},
	pages = {1012 – 1016},
	doi = {10.1109/ICMLA.2018.00165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062225185&doi=10.1109%2fICMLA.2018.00165&partnerID=40&md5=f88d42c487c4b5fc98ea22fb21e2ba95},
	affiliations = {Walmart Labs, Bangalore, India},
	abstract = {Information in the form of text can be found in abundance in the web today, which can be mined to solve multifarious problems. Customer reviews, for instance, flow in across multiple sources in thousands per day which can be leveraged to obtain several insights. Our goal is to extract cases of a rare event e.g., recall of products, allegations of ethics or, legal concerns or, threats to product-safety, etc. from this enormous amount of data. Manual identification of such cases to be reported is extremely labour-intensive as well as time-sensitive, but failure to do so can have fatal impact on the industry's overall health and dependability; missing out on even a single case may lead to huge penalties in terms of customer experience, product liability and industry reputation. In this paper, we will discuss classification through Positive and Unlabeled data, PU classification, where the only class, for which instances are available, is a rare event. In iCASSTLE, we propose a two-staged approach where Stage I leverages three unique components of text mining to procure representative training data containing instances of both classes in the right proportion, and Stage II uses results from Stage I to run a semi-supervised classification. We applied this to multiple datasets differing in nature of Product Safety as well as nature of imbalance and iCASSTLE is proven to perform better than the state-of-the-art methods for the relevant use-cases. © 2018 IEEE.},
	author_keywords = {Class Imbalance; Data Prioritization; Latent Semantic Analysis; PU Classification; Recall Maximization; Semi Supervised Text Classification; Sentiment Analysis; Sparsity Treatment; Text Mining; Word Frequency},
	keywords = {Data mining; Machine learning; Product liability; Semantics; Sentiment analysis; Supervised learning; Tellurium compounds; Class imbalance; Data prioritization; Latent Semantic Analysis; Sparsity Treatment; Text classification; Text mining; Word frequencies; Classification (of information)},
	editor = {Wani M.A. and Sayed-Mouchaweh M. and Lughofer E. and Gama J. and Kantardzic M.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153866804-7},
	language = {English},
	abbrev_source_title = {Proc. - IEEE Int. Conf. Mach. Learn. Appl., ICMLA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; Conference name: 17th IEEE International Conference on Machine Learning and Applications, ICMLA 2018; Conference date: 17 December 2018 through 20 December 2018; Conference code: 144456}
}

@ARTICLE{Martinez-Martin201995,
	author = {Martinez-Martin, Nicole and Magnus, David},
	title = {Privacy and ethical challenges in next-generation sequencing},
	year = {2019},
	journal = {Expert Review of Precision Medicine and Drug Development},
	volume = {4},
	number = {2},
	pages = {95 – 104},
	doi = {10.1080/23808993.2019.1599685},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064923110&doi=10.1080%2f23808993.2019.1599685&partnerID=40&md5=9fb868c3883964f8dfc8b0dcbb5a8b1d},
	affiliations = {Stanford Center for Biomedical Ethics, Stanford University, Stanford, CA, United States},
	abstract = {Introduction: Next-generation sequencing (NGS) is expected to revolutionize health care. NGS allows for sequencing of the whole genome more cheaply and quickly than previous techniques. NGS offers opportunities to advance medical diagnostics and treatments, but also raises complicated ethical questions that need to be addressed. Areas considered: This article draws from the literature on research and clinical ethics, as well as next-generation sequencing, in order to provide an overview of the ethical challenges involved in next-generation sequencing. This article includes a discussion of the ethics of NGS in research and clinical contexts. Expert opinion: The use of NGS in clinical and research contexts has features that pose challenges for traditional ethical frameworks for protecting research participants and patients. NGS generates massive amounts of data and results that vary in terms of known clinical relevance. It is important to determine appropriate processes for protecting, managing and communicating the data. The use of machine learning for sequencing and interpretation of genomic data also raises concerns in terms of the potential for bias and potential implications for fiduciary obligations. NGS poses particular challenges in three main ethical areas: privacy, informed consent, and return of results. © 2019, © 2019 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {ethics; Next generation sequencing; privacy},
	keywords = {adult; genome; human; informed consent; machine learning; next generation sequencing; privacy; review},
	correspondence_address = {N. Martinez-Martin; Stanford Center for Biomedical Ethics, Stanford University, Stanford, United States; email: nicolemz@stanford.edu},
	publisher = {Taylor and Francis Ltd.},
	issn = {23808993},
	language = {English},
	abbrev_source_title = {Expert Rev. Precis. Med. Drug Dev.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Green Open Access}
}

@BOOK{Hanson2019115,
	author = {Hanson, Kirk O.},
	title = {Next-Generation Business Ethics: The Impact of Artificial Intelligence},
	year = {2019},
	journal = {Next-Generation Ethics: Engineering a Better Society},
	pages = {115 – 128},
	doi = {10.1017/9781108616188.009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85135679447&doi=10.1017%2f9781108616188.009&partnerID=40&md5=2ce1e8fc6de8cb6ab2cddf3b52cd5a9a},
	affiliations = {Santa Clara University, United States},
	abstract = {The concerns and corporate practice of business ethics have evolved over the past sixty years. But none of the changes of the past are as great as those that will occur in the next ten years as artificial intelligence (AI) and machine learning become ubiquitous tools in American society. This chapter presents a concise history of corporate attention to business ethics over this historical period in order to identify how “next-generation business ethics” will demonstrate both continuity with and divergence from past attention to business ethics. © Cambridge University Press 2020.},
	publisher = {Cambridge University Press},
	isbn = {978-110861618-8; 978-110848041-3},
	language = {English},
	abbrev_source_title = {Next-Generation Ethics: Engineering a Better Society},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hu2019153,
	author = {Hu, Tao and Xiao, Chunxia},
	title = {Data-driven main color map feature learning, design and simulation for smart ethnic cloth},
	year = {2019},
	journal = {Future Generation Computer Systems},
	volume = {97},
	pages = {153 – 164},
	doi = {10.1016/j.future.2019.02.054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062450417&doi=10.1016%2fj.future.2019.02.054&partnerID=40&md5=e414a99b4c64817c7f63fb3a0ba93d5f},
	affiliations = {School of Computer Science, Wuhan University, Hubei, Wuhan, China; School of Information Engineering, Hubei University for Nationalities, Enshi, Hubei, China},
	abstract = {How to protect and develop traditional ethnic cloth culture are the key problems of current societal interest. Through earlier research of smart techniques of pattern layout and texture appearance simulation of traditional Ethnic cloth, a data-driven intelligent design and simulation model based on main color feature learning is proposed in this paper. We employ a combination-based design technique, which uses pattern elements data and skeletons data to design a digital layout for ethnic cloth. We use Octree to quantize the color map for the designed ethnic cloth layout and extract main color map based on k-means clustering. Using a cubic convolution interpolation algorithm with yarn structure template, we render each region that is segmented through the main color map. Then, we can generate a good representation of the texture appearance of the designed layout which is shown as a realistic fabric material. Finally, the designed layout will be transferred to intelligent loom produced based on industrial Internet of things. We design several traditional Ethic cloths (Tujia brocade) layouts and simulate their textures based on our method to analyze its applicability and validity. We also compare the design and simulation results with previously proposed algorithms, which indicate that our model can design complex patterns and simulate exquisite material of Tujia brocade. © 2019 Elsevier B.V.},
	author_keywords = {Data-driven design; Main color map; Smart ethnic cloth; Yarn texture simulation},
	keywords = {Color; K-means clustering; Machine learning; Silk; Textures; Wool; Yarn; Color map; Cubic convolution interpolations; Data-driven design; Design and simulation; Design technique; Feature learning; Intelligent designs; Texture simulation; Design},
	correspondence_address = {C. Xiao; School of Computer Science, Wuhan University, Hubei, China; email: cxxiao@whu.edu.cn},
	publisher = {Elsevier B.V.},
	issn = {0167739X},
	coden = {FGCSE},
	language = {English},
	abbrev_source_title = {Future Gener Comput Syst},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Leong2019299,
	author = {Leong, Brenda and Selinger, Evan},
	title = {Robot eyes wide shut: Understanding dishonest anthropomorphism},
	year = {2019},
	journal = {FAT* 2019 - Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency},
	pages = {299 – 308},
	doi = {10.1145/3287560.3287591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061767936&doi=10.1145%2f3287560.3287591&partnerID=40&md5=84a8d57be2b3befe10b129eff4416743},
	affiliations = {Future of Privacy Forum, Washington, DC, United States; Department of Philosophy, Rochester Institute of Technology, Rochester, NY, United States},
	abstract = {The goal of this paper is to advance design, policy, and ethics scholarship on how engineers and regulators can protect consumers from deceptive robots and artificial intelligences that exhibit the problem of dishonest anthropomorphism. The analysis expands upon ideas surrounding the principle of honest anthropomorphism originally formulated by Margot Kaminsky, Mathew Ruben, William D. Smart, and Cindy M. Grimm in their groundbreaking Maryland Law Review article, “Averting Robot Eyes.” Applying boundary management theory and philosophical insights into prediction and perception, we create a new taxonomy that identifies fundamental types of dishonest anthropomorphism and pinpoints harms that they can cause. To demonstrate how the taxonomy can be applied as well as clarify the scope of the problems that it can cover, we critically consider a representative series of ethical issues, proposals, and questions concerning whether the principle of honest anthropomorphism has been violated. © 2019 Association for Computing Machinery.},
	author_keywords = {Anthropomorphism; Artificial Intelligence; Ethics; Machine Learning; Robots},
	keywords = {Artificial intelligence; Learning systems; Machine design; Philosophical aspects; Robots; Taxonomies; Transparency; Anthropomorphism; Ethical issues; Ethics; Management theory; Maryland; Intelligent robots},
	publisher = {Association for Computing Machinery, Inc},
	isbn = {978-145036125-5},
	language = {English},
	abbrev_source_title = {FAT* - Proc. Conf. Fairness, Account., Transpar.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; Conference name: 2019 ACM Conference on Fairness, Accountability, and Transparency, FAT* 2019; Conference date: 29 January 2019 through 31 January 2019; Conference code: 144666}
}

@ARTICLE{Bernstein2019284,
	author = {Bernstein, Joseph},
	title = {Not the Last Word: Big Data Will Make You Confront Big Ethical Questions - Here's Why},
	year = {2019},
	journal = {Clinical Orthopaedics and Related Research},
	volume = {477},
	number = {2},
	pages = {284 – 287},
	doi = {10.1097/CORR.0000000000000625},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060160357&doi=10.1097%2fCORR.0000000000000625&partnerID=40&md5=2e7f60887313ebc5d7ed3188ea025f8f},
	affiliations = {Department of Orthopaedic Surgery, University of Pennsylvania, 424 Stemmler Hall, Philadelphia, 19104, PA, United States},
	keywords = {Attitude of Health Personnel; Big Data; Data Mining; Decision Support Techniques; Evidence-Based Medicine; Health Knowledge, Attitudes, Practice; Humans; Machine Learning; Orthopedic Surgeons; Orthopedics; Practice Patterns, Physicians'; algorithm; big data; clinical decision making; data analysis; human; knee replacement; machine learning; medical ethics; orthopedics; priority journal; Review; total knee arthroplasty; attitude to health; clinical practice; data mining; decision support system; ethics; evidence based medicine; health personnel attitude; orthopedic surgeon; orthopedics; psychology},
	correspondence_address = {J. Bernstein; Department of Orthopaedic Surgery, University of Pennsylvania, Philadelphia, 424 Stemmler Hall, 19104, United States; email: orthodoc@uphs.upenn.edu},
	publisher = {Lippincott Williams and Wilkins},
	issn = {0009921X},
	coden = {CORTB},
	pmid = {30624324},
	language = {English},
	abbrev_source_title = {Clin. Orthop. Relat. Res.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access, Green Open Access}
}

@BOOK{Golubnitschaja2019403,
	author = {Golubnitschaja, Olga and Andrews, Russell J.},
	title = {Patient-Centered Care: Making the Modern Hospital Truly Modern},
	year = {2019},
	journal = {The Modern Hospital: Patients Centered, Disease Based, Research Oriented, Technology Driven},
	pages = {403 – 409},
	doi = {10.1007/978-3-030-01394-3_37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85089288338&doi=10.1007%2f978-3-030-01394-3_37&partnerID=40&md5=6111bebb26c22d215d085fd03dffe40f},
	affiliations = {Radiological Clinic, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany; Breast Cancer Research Centre, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany; Centre for Integrated Oncology, Rheinische Friedrich-Wilhelms-Universität Bonn, Cologne-Bonn, Bonn, Germany; European Association for Predictive, Preventive and Personalised Medicine, EPMA, Brussels, Belgium; Department of Nanotechnology and Smart System, NASA Ames Research Centre, Moffett Field, CA, United States},
	abstract = {The innovative concept of predictive, preventive, and personalized medicine (PPPM) was presented in detail in the chapter on wound healing. This chapter incorporates PPPM into the evolutionary framework of the modern hospital. The example of diabetes illustrates the disastrous consequences - both medical and economical - of reactive “disease care” rather than proactive “healthcare.” Implementing PPPM into the modern hospital requires dedication to both long-term planning (e.g., infrastructure such as novel information technology (IT) and cutting-edge clinically relevant biomedical research) and daily implementation and updating of programs designed to optimize personalized patient care. Healthcare system-wide themes for the future include international biobanking, multiomics, big data collection and analysis, and machine learning (with multilevel neural networks). At the level of hospital organization, it is essential to shift from reactive “administering” (i.e., meeting goals that often address symptoms rather than causes or that are motivated by short-term financial gain - “maximize profit this quarter”) to proactive “managing” (i.e., utilizing all the resources at hand - financial, infrastructure, personnel, research - to optimize patient outcomes in the long run). Progressive and innovative hospitals in the past have required multidisciplinary collaboration among innovative leaders - both managerial and medical - who have complementary backgrounds, as well as a working environment that recognizes and supports “team players” who value long-term hospital progress over immediate personal prestige or financial gain. Finally, as the modern hospital becomes more digital and cloud-based, the need to address proactively rather than reactively the threat of system hacking and “crashes” - such as the “WannaCry” ransomware worm that affected the National Health System in the United Kingdom in May 2017 - cannot be ignored. We may not have a “planet B, " but the modern hospital must have a “plan B.”. © Springer Nature Switzerland AG 2019.},
	author_keywords = {Biomarker panels; Ethics; Hospital administration; Medical economics; Multilevel diagnostics; Predictive preventive personalized medicine},
	correspondence_address = {O. Golubnitschaja; Radiological Clinic, Rheinische Friedrich-Wilhelms-Universität Bonn, Bonn, Germany; email: olga.golubnitschaja@ukbonn.de},
	publisher = {Springer International Publishing},
	isbn = {978-303001394-3; 978-303001393-6},
	language = {English},
	abbrev_source_title = {The Modern Hospital: Patients Centered, Disease Based, Research Oriented, Technology Driven},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Smaïl-Tabbone2019190,
	author = {Smaïl-Tabbone, Malika and Rance, Bastien},
	title = {Contributions from the 2018 Literature on Bioinformatics and Translational Informatics},
	year = {2019},
	journal = {Yearbook of medical informatics},
	volume = {28},
	number = {1},
	pages = {190 – 193},
	doi = {10.1055/s-0039-1677945},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071982843&doi=10.1055%2fs-0039-1677945&partnerID=40&md5=2455d0644f15a5e963fcb39e1842f60d},
	affiliations = {CNRS, Inria Nancy Grand-Est, Loria UMR 7503 ,Université de Lorraine, Nancy, France; HEGP, AP-HP; Université Paris Descartes, Université de Paris; UMRS 1138 Centre de Recherche des Cordeliers INSERM, Paris, France},
	abstract = {OBJECTIVES: To summarize recent research and select the best papers published in 2018 in the field of Bioinformatics and Translational Informatics (BTI) for the corresponding section of the International Medical Informatics Association (IMIA) Yearbook. METHODS: A literature review was performed for retrieving from PubMed papers indexed with keywords and free terms related to BTI. Independent review allowed the two section editors to select a list of 14 candidate best papers which were subsequently peer-reviewed. A final consensus meeting gathering the whole IMIA Yearbook editorial committee was organized to finally decide on the selection of the best papers. RESULTS: Among the 636 retrieved papers published in 2018 in the various subareas of BTI, the review process selected four best papers. The first paper presents a computational method to identify molecular markers for targeted treatment of acute myeloid leukemia using multi-omics data (genome-wide gene expression profiles) and in vitro sensitivity to 160 chemotherapy drugs. The second paper describes a deep neural network approach to predict the survival of patients suffering from glioma on the basis of digitalised pathology images and genomics biomarkers. The authors of the third paper adopt a pan-cancer approach to take benefit of multi-omics data for drug repurposing. The fourth paper presents a graph-based semi-supervised method to accurate phenotype classification applied to ovarian cancer. CONCLUSIONS: Thanks to the normalization of open data and open science practices, research in BTI continues to develop and mature. Noteworthy achievements are sophisticated applications of leading edge machine-learning methods dedicated to personalized medicine. Georg Thieme Verlag KG Stuttgart.},
	keywords = {Artificial Intelligence; Computational Biology; Humans; Machine Learning; Medical Informatics; Neoplasms; Prognosis; Translational Medical Research; artificial intelligence; biology; ethics; genetics; human; machine learning; medical informatics; neoplasm; pathology; prognosis; translational research},
	publisher = {NLM (Medline)},
	issn = {23640502},
	pmid = {31419831},
	language = {English},
	abbrev_source_title = {Yearb Med Inform},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Olatosi2019,
	author = {Olatosi, Bankole and Zhang, Jiajia and Weissman, Sharon and Hu, Jianjun and Haider, Mohammad Rifat and Li, Xiaoming},
	title = {Using big data analytics to improve HIV medical care utilisation in South Carolina: A study protocol},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {7},
	doi = {10.1136/bmjopen-2018-027688},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069523438&doi=10.1136%2fbmjopen-2018-027688&partnerID=40&md5=f08cf6154bf62f6c7e76a627246da457},
	affiliations = {Health Services Policy and Management, Arnold School of Public Health, University of South Carolina, Columbia, SC, United States; Department of Epidemiology and Biostatistics, University of South Carolina, Columbia, SC, United States; Internal Medicine, School of Medicine, University of South Carolina, Columbia, SC, United States; Department of Computer Science and Engineering, College of Engineering, University of South Carolina, Columbia, SC, United States; Department of Health Promotion Education and Behavior, Arnold School of Public Health, University of South Carolina, Columbia, SC, United States; Health Promotion Education and Behavior, Arnold School of Public Health, University of South Carolina, Columbia, SC, United States},
	abstract = {Introduction Linkage and retention in HIV medical care remains problematic in the USA. Extensive health utilisation data collection through electronic health records (EHR) and claims data represent new opportunities for scientific discovery. Big data science (BDS) is a powerful tool for investigating HIV care utilisation patterns. The South Carolina (SC) office of Revenue and Fiscal Affairs (RFA) data warehouse captures individual-level longitudinal health utilisation data for persons living with HIV (PLWH). The data warehouse includes EHR, claims and data from private institutions, housing, prisons, mental health, Medicare, Medicaid, State Health Plan and the department of health and human services. The purpose of this study is to describe the process for creating a comprehensive database of all SC PLWH, and plans for using BDS to explore, identify, characterise and explain new predictors of missed opportunities for HIV medical care utilisation. Methods and analysis This project will create person-level profiles guided by the Gelberg-Andersen Behavioral Model and describe new patterns of HIV care utilisation. The population for the comprehensive database comes from statewide HIV surveillance data (2005-2016) for all SC PLWH (N≈18000). Surveillance data are available from the state health department's enhanced HIV/AIDS Reporting System (e-HARS). Additional data pulls for the e-HARS population will include Ryan White HIV/AIDS Program Service Reports, Health Sciences SC data and Area Health Resource Files. These data will be linked to the RFA data and serve as sources for traditional and vulnerable domain Gelberg-Anderson Behavioral Model variables. The project will use BDS techniques such as machine learning to identify new predictors of HIV care utilisation behaviour among PLWH, and â € missed opportunities' for re-engaging them back into care. Ethics and dissemination The study team applied for data from different sources and submitted individual Institutional Review Board (IRB) applications to the University of South Carolina (USC) IRB and other local authorities/agencies/state departments. This study was approved by the USC IRB (#Pro00068124) in 2017. To protect the identity of the persons living with HIV (PLWH), researchers will only receive linked deidentified data from the RFA. Study findings will be disseminated at local community forums, community advisory group meetings, meetings with our state agencies, local partners and other key stakeholders (including PLWH, policy-makers and healthcare providers), presentations at academic conferences and through publication in peer-reviewed articles. Data security and patient confidentiality are the bedrock of this study. Extensive data agreements ensuring data security and patient confidentiality for the deidentified linked data have been established and are stringently adhered to. The RFA is authorised to collect and merge data from these different sources and to ensure the privacy of all PLWH. The legislatively mandated SC data oversight council reviewed the proposed process stringently before approving it. Researchers will get only the encrypted deidentified dataset to prevent any breach of privacy in the data transfer, management and analysis processes. In addition, established secure data governance rules, data encryption and encrypted predictive techniques will be deployed. In addition to the data anonymisation as a part of privacy-preserving analytics, encryption schemes that protect running prediction algorithms on encrypted data will also be deployed. Best practices and lessons learnt about the complex processes involved in negotiating and navigating multiple data sharing agreements between different entities are being documented for dissemination. © 2019 Author(s).},
	author_keywords = {big data science; health care utilisation; HIV/AIDS; machine learning; predictive modeling},
	keywords = {Big Data; Confidentiality; Data Science; Electronic Health Records; HIV Infections; Humans; Insurance Coverage; Logistic Models; Patient Acceptance of Health Care; Population Surveillance; Research Design; South Carolina; adult; anonymised data; article; big data; computer security; confidentiality; controlled study; data warehouse; electronic health record; ethics; health care personnel; health care utilization; health science; housing; human; Human immunodeficiency virus; Human immunodeficiency virus infected patient; identity; institutional review; interpersonal communication; machine learning; medicaid; medical care; medicare; mental health; nonhuman; prediction; prison; privacy; psychological model; public health service; publication; running; scientist; South Carolina; health survey; Human immunodeficiency virus infection; insurance; methodology; patient attitude; procedures; South Carolina; statistical model},
	correspondence_address = {B. Olatosi; Health Services Policy and Management, Arnold School of Public Health, University of South Carolina, Columbia, United States; email: olatosi@mailbox.sc.edu},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31326931},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Ayele20191113,
	author = {Ayele, Workneh Y. and Juell-Skielse, Gustaf},
	title = {Unveiling Topics from Scientific Literature on the Subject of Self-driving Cars using Latent Dirichlet Allocation},
	year = {2019},
	journal = {2018 IEEE 9th Annual Information Technology, Electronics and Mobile Communication Conference, IEMCON 2018},
	pages = {1113 – 1119},
	doi = {10.1109/IEMCON.2018.8615056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062068001&doi=10.1109%2fIEMCON.2018.8615056&partnerID=40&md5=e50e66f585e841ae16eaf14235a3e6e4},
	affiliations = {Department of Computer and Systems Sciences, Stockholm University, Stockholm, Sweden},
	abstract = {Self-driving cars are becoming popular topics in academia. Consumers of self-driving cars and vehicles have different concerns, for example, safety and security, to name a few. Also, the public sector has interests in self-driving cars such as amending policies to enable the management of self-driving vehicles in cities, urban planning, traffic management and, etc. In this paper, more than 2700 corpus are extracted from literature from several subject areas to identify latent (hidden) topics of self-driving cars. Latent Dirichlet Allocation (LDA) is used for topic identification. The result of this study shows that topics identified are valid research areas such as urban planning, driver car (computer) interaction, self-driving control and system design, ethics in self-driving cars, safety and risk assessment, training dataset quality and machine learning in self-driving cars are among the topics identified. Furthermore, the network visualization of association graph of terms shows that the most frequently discussed concepts reveal that control of self-driving cars is based on algorithms, data, design, method, and model. The methods used in this study and the results can be used as decision tools, if carefully applied, in diverse disciplines that are disrupted by the introduction of self-driving cars. For future study, we plan to extend this study with a larger dataset and other data mining techniques. © 2018 IEEE.},
	author_keywords = {self-driving cars; topic modeling; unsupervised topic modeling; unveiling hidden topics},
	keywords = {Autonomous vehicles; Computer control systems; Data visualization; Large dataset; Learning systems; Mobile telecommunication systems; Quality control; Risk assessment; Safety engineering; Statistics; Urban planning; Latent Dirichlet allocation; Latent dirichlet allocations; Network visualization; Safety and risk assessment; Safety and securities; Scientific literature; Topic Modeling; unveiling hidden topics; Data mining},
	editor = {Chakrabarti S. and Saha H.N.},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	isbn = {978-153867266-2},
	language = {English},
	abbrev_source_title = {IEEE Annu. Inf. Technol., Electron. Mob. Commun. Conf., IEMCON},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 9th IEEE Annual Information Technology, Electronics and Mobile Communication Conference, IEMCON 2018; Conference date: 1 November 2018 through 3 November 2018; Conference code: 144366}
}

@ARTICLE{Pintér201977,
	author = {Pintér, Dániel Gergő and Ihász, Péter Lajos},
	title = {Bridging natural language processing AI techniques and corporate communications: Towards an integrative model},
	year = {2019},
	journal = {Informacios Tarsadalom},
	volume = {19},
	number = {4},
	pages = {77 – 99},
	doi = {10.22503/INFTARS.XIX.2019.4.6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85107630531&doi=10.22503%2fINFTARS.XIX.2019.4.6&partnerID=40&md5=a0885e90df2f483e9d4ba6e319f5a60c},
	abstract = {Today's communication channels and media platforms generate a huge amount of data, which - through advanced AI- (Machine Learning) based techniques - can be leveraged to significantly enhance business networking, improve the efficiency of public relations, management, and extend the possible application areas of communication components. As a sub-discipline of AI, Natural Language Processing (NLP) is frequently utilized in the field of corporate communications (CC) to boost target-group satisfaction through information retrieval and automated dialogue services. This paper gives an overview of the use of NLP in different disciplines of CC, discusses general corporational/organizational practices, and identifies promising research topics for the future while pointing out the ethical aspects of user-data handling and customer engagement. The findings of this synthesizing study are based on primer qualitative research building on the methodology of deep interviews and focus group research involving experts practicing in the fields of CC and NLP. Based on the feedbacks of the participants, a refined CC model was developed, as well as a model mapping conventional NLP techniques onto CC disciplines and tasks they are utilized for. © 2019 Infonia. All rights reserved.},
	author_keywords = {AI ethics; Artificial intelligence; Business management; Corporate communication; Deep learning; Information society; Natural language processing; Public relations},
	publisher = {Infonia},
	issn = {15878694},
	language = {English},
	abbrev_source_title = {Informacios Tars.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Ma2019,
	author = {Ma, Hui and Guo, Xuyang and Ping, Yuan and Wang, Baocang and Yang, Yuehua and Zhang, Zhili and Zhou, Jingxian},
	title = {PPCD: Privacy-preserving clinical decision with cloud support},
	year = {2019},
	journal = {PLoS ONE},
	volume = {14},
	number = {5},
	doi = {10.1371/journal.pone.0217349},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066447729&doi=10.1371%2fjournal.pone.0217349&partnerID=40&md5=d1db3e49f4d18b4bb97d75e83dc5ecf2},
	affiliations = {School of Information Engineering, Xuchang University, Xuchang, Henan, China; No.1 Middle School of Zhengzhou, Zhengzhou, Henan, China; Information Technology Research Base of Civil Aviation Administration of China, Civil Aviation University of China, Tianjin, China; State Key Laboratory of Integrated Service Networks, Xidian University, Xi'an, China},
	abstract = {With the prosperity of machine learning and cloud computing, meaningful information can be mined from mass electronic medical data which help physicians make proper disease diagnosis for patients. However, using medical data and disease information of patients frequently raise privacy concerns. In this paper, based on single-layer perceptron, we propose a scheme of privacy-preserving clinical decision with cloud support (PPCD), which securely conducts disease model training and prediction for the patient. Each party learns nothing about the other's private information. In PPCD, a lightweight secure multiplication is presented and introduced to improve the model training. Security analysis and experimental results on real data confirm the high accuracy of disease prediction achieved by the proposed PPCD without the risk of privacy disclosure. © 2019 Ma et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Algorithms; Cloud Computing; Computer Security; Confidentiality; Decision Making; Decision Making, Computer-Assisted; Disclosure; Electronic Health Records; Humans; Machine Learning; Medical Records; Privacy; Article; clinical decision support system; human; interpersonal communication; measurement accuracy; medical information system; perceptron; prediction; privacy; risk factor; algorithm; cloud computing; computer security; confidentiality; decision making; decision support system; electronic health record; ethics; machine learning; medical record},
	publisher = {Public Library of Science},
	issn = {19326203},
	coden = {POLNC},
	pmid = {31141561},
	language = {English},
	abbrev_source_title = {PLoS ONE},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Helbich2019,
	author = {Helbich, Marco},
	title = {Dy n amic Urban e nvironmental e xposures on D epression and S uicide (NEEDS) in the Netherlands: A protocol for a cross-sectional smartphone tracking study and a longitudinal population register study},
	year = {2019},
	journal = {BMJ Open},
	volume = {9},
	number = {8},
	doi = {10.1136/bmjopen-2019-030075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070674048&doi=10.1136%2fbmjopen-2019-030075&partnerID=40&md5=a7b3d67cd5829f20d9a0d95d6927a86f},
	affiliations = {Department of Human Geography and Spatial Planning, Utrecht University, Utrecht, Netherlands},
	abstract = {Introduction Environmental exposures are intertwined with mental health outcomes. People are exposed to the environments in which they currently live, and to a multitude of environments along their daily movements and through their residential relocations. However, most research assumes that people are immobile, disregarding that such dynamic exposures also serve as stressors or buffers potentially associated with depression and suicide risk. The aim of the Dynamic Urban Environmental Exposures on Depression and Suicide (NEEDS) study is to examine how dynamic environmental exposures along people's daily movements and over their residential histories affect depression and suicide mortality in the Netherlands. Methods and analysis The research design comprises two studies emphasising the temporality of exposures. First, a cross-sectional study is assessing how daily exposures correlate with depression. A nationally representative survey was administered to participants recruited through stratified random sampling of the population aged 18-65 years. Survey data were enriched with smartphone-based data (eg, Global Positioning System tracking, Bluetooth sensing, social media usage, communication patterns) and environmental exposures (eg, green and blue spaces, noise, air pollution). Second, a longitudinal population register study is addressing the extent to which past environmental exposures over people's residential history affect suicide risk later in life. Statistical and machine learning-based models are being developed to quantify environment-health relations. Ethics and dissemination Ethical approval (FETC17-060) was granted by the Ethics Review Board of Utrecht University, The Netherlands. Project-related findings will be disseminated at conferences and in peer-reviewed journal papers. Other project outcomes will be made available through the project's web page, http://www.needs.sites.uu.nl. © Author(s) (or their employer(s)) 2019. Re-use permitted under CC BY-NC. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {depression; dynamic exposures; environment; geographic information system; life course of place; mental health; register; smartphone sensing; suicide mortality},
	keywords = {Adolescent; Adult; Aged; Built Environment; Cross-Sectional Studies; Depression; Environmental Exposure; Female; Geographic Information Systems; Humans; Longitudinal Studies; Male; Middle Aged; Netherlands; Registries; Risk Factors; Smartphone; Suicide; Urban Population; Young Adult; adult; Article; cross-sectional study; depression; environmental exposure; female; global positioning system; human; longitudinal study; major clinical study; male; mortality; Netherlands; population research; register; social media; suicide; urban area; adolescent; adverse event; aged; depression; environmental exposure; geographic information system; middle aged; risk factor; smartphone; suicide; urban population; young adult},
	correspondence_address = {M. Helbich; Department of Human Geography and Spatial Planning, Utrecht University, Utrecht, Netherlands; email: m.helbich@uu.nl},
	publisher = {BMJ Publishing Group},
	issn = {20446055},
	pmid = {31401609},
	language = {English},
	abbrev_source_title = {BMJ Open},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 25; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Sangüesa20196,
	author = {Sangüesa, Ramon and Guersenzvaig, Ariel},
	title = {AI as a Design Material: Dealing with New Agencies; [La intel·ligència artificial com a material de disseny: treballar amb noves agències]; [La inteligencia artificial como material de diseño: trabajar con nuevas agencias]},
	year = {2019},
	journal = {Temes de Disseny},
	volume = {2019},
	number = {35},
	pages = {6 – 25},
	doi = {10.46467/TdD35.2019.6-25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85152141870&doi=10.46467%2fTdD35.2019.6-25&partnerID=40&md5=44fe15768a04e70e4923916e5ecb72d0},
	affiliations = {Technical University of Catalonia, Spain; Elisava School of Design and Engineering, Spain},
	abstract = {As Artificial Intelligence, Machine Learning, Big Data, and other technologies become widespread they could be seen as new materials for design. But what are the special traits of these materials? How should design incorporate them in its practices? How does it change design research? HCI? UX? What are their ethical implications? © 2019, The Authors. All rights reserved.},
	author_keywords = {Agency; Artificial Intelligence; Design; Ethics; Machine Learning; Materials},
	publisher = {Elisava Barcelona School of Design and Engineering},
	issn = {26049155},
	language = {English},
	abbrev_source_title = {Temes. Disseny.},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}@CONFERENCE{Zanzotto201984,
	author = {Zanzotto, Fabio Massimo},
	title = {Viewpoint: Human-in-the-loop artificial intelligence},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2495},
	pages = {84 – 94},
	doi = {10.1613/jair.1.11345},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075105195&doi=10.1613%2fjair.1.11345&partnerID=40&md5=83886a5fd0e8d2d3b652d8de80d4a51b},
	affiliations = {University of Rome, Tor Vergata, Italy},
	abstract = {Little by little, newspapers are revealing the bright future that Artificial Intelligence (AI) is building. Intelligent machines will help everywhere. However, this bright future may have a possible dark side: a dramatic job market contraction before its unpredictable transformation. Hence, in a near future, large numbers of job seekers may need financial support while catching up with these novel unpredictable jobs. This possible job market crisis has an antidote inside. In fact, the rise of AI is sustained by the biggest knowledge theft of the recent years. Many learning AI machines are extracting knowledge from unaware skilled or unskilled workers by analyzing their interactions. By passionately doing their jobs, many of these workers are shooting themselves in the feet. In this paper, we propose Human-in-the-loop Artificial Intelligence (HIT-AI) as a fairer paradigm for AI systems. Recognizing that any AI system has humans in the loop, HIT-AI will reward these aware and unaware knowledge producers with a different scheme: decisions of AI systems generating revenues will repay the legitimate owners of the knowledge used for taking those decisions. As modern Merry Men, HIT-AI researchers should fight for a fairer Robin Hood Artificial Intelligence that gives back what it steals. Copyright © 2019 for this paper by its authors.},
	author_keywords = {AI&Ethics; Data Driven Economy; Machine Learning&Ethics},
	keywords = {Commerce; Employment; Learning systems; Philosophical aspects; Catching-up; Data driven; Financial support; Human-in-the-loop; Intelligent machine; Job market; Job seekers; Robin Hood; Artificial intelligence},
	correspondence_address = {F.M. Zanzotto; University of Rome, Tor Vergata, Italy; email: fabio.massimo.zanzotto@uniroma2.it},
	editor = {Alviano M. and Greco G. and Maratea M. and Scarcello F.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: Discussion and Doctoral Consortium Papers of AI*IA - 18th International Conference of the Italian Association for Artificial Intelligence, AI*IA-DDC 2019; Conference date: 19 November 2019 through 22 November 2019; Conference code: 154116; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Riegler201915,
	author = {Riegler, Carolyn},
	title = {The moral decision-making capacity of self-driving cars: Socially responsible technological development, algorithm-driven sensing devices, and autonomous vehicle ethics},
	year = {2019},
	journal = {Contemporary Readings in Law and Social Justice},
	volume = {11},
	number = {1},
	pages = {15 – 20},
	doi = {10.22381/CRLSJ11120192},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85070420091&doi=10.22381%2fCRLSJ11120192&partnerID=40&md5=44aa14647ae2a00005df21d13c7d321d},
	affiliations = {The Social Science Research Unit at CSA, Bristol, United Kingdom},
	abstract = {The purpose of this study was to empirically examine the moral decision-making capacity of self-driving cars. Building my argument by drawing on data collected from the AUVSI, Black & Veatch, Capgemini Research Institute, Ipsos/GenPop, Perkins Coie, Pew Research Center, Statista, I performed analyses and made estimates regarding how much consumers agree or disagree that self-driving cars will make driving more relaxing/ safer/faster/easier/friendlier to the environment/more economical/more enjoyable/more comfortable, the most attractive technologies for investment for autonomous vehicles over the next five years (5G technology/vehicle-to-vehicle and vehicle-to-infrastructure communication technology/advanced driver assistance systems/precision mapping platforms and location technology/machine learning and driving data analysis/connectivity and infotainment features), and % of U.S. adults who say the number of people killed or injured in traffic accidents will increase/decrease/stay about the same if driverless vehicles become widespread. The structural equation modeling technique was used to test the research model. © 2019, Addleton Academic Publishers. All rights reserved.},
	author_keywords = {Algorithm-driven sensing device; Decision-making capacity; Self-driving car},
	correspondence_address = {C. Riegler; The Social Science Research Unit at CSA, Bristol, United Kingdom; email: c.riegler@aa-er.org},
	publisher = {Addleton Academic Publishers},
	issn = {19489137},
	language = {English},
	abbrev_source_title = {Contemp. Read. Law Soc. Justice},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Bacciu2019455,
	author = {Bacciu, Davide and Biggio, Battista and Lisboa, Paulo J.G. and Martín, José D. and Oneto, Luca and Vellido, Alfredo},
	title = {Societal issues in machine learning: When learning from data is not enough},
	year = {2019},
	journal = {ESANN 2019 - Proceedings, 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
	pages = {455 – 464},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85071283068&partnerID=40&md5=f0f9994d8b282a17d8349660e33b8cd0},
	affiliations = {Department of Computer Science, University of Pisa, Italy; University of Cagliari - Italy, Pluribus One, Italy; Department of Applied Mathematics, Liverpool John Moores University, United Kingdom; Department of Electronic Engineering, Universitat de València, Spain; Intelligent Data Science and Artificial Intelligence Research Center (IDEAI), Universitat Politècnica de Catalunya-BarcelonaTech, Spain; Centro de Investigación Biomédica en Red - CIBER-BBN, Spain},
	abstract = {It has been argued that Artificial Intelligence (AI) is experiencing a fast process of commodification. Such characterization is on the interest of big IT companies, but it correctly reflects the current industrialization of AI. This phenomenon means that AI systems and products are reaching the society at large and, therefore, that societal issues related to the use of AI and Machine Learning (ML) cannot be ignored any longer. Designing ML models from this human-centered perspective means incorporating human-relevant requirements such as safety, fairness, privacy, and interpretability, but also considering broad societal issues such as ethics and legislation. These are essential aspects to foster the acceptance of ML-based technologies, as well as to ensure compliance with an evolving legislation concerning the impact of digital technologies on ethically and privacy sensitive matters. The ESANN special session for which this tutorial acts as an introduction aims to showcase the state of the art on these increasingly relevant topics among ML theoreticians and practitioners. For this purpose, we welcomed both solid contributions and preliminary relevant results showing the potential, the limitations and the challenges of new ideas, as well as refinements, or hybridizations among the different fields of research, ML and related approaches in facing real-world problems involving societal issues. © 2019 ESANN (i6doc.com). All rights reserved.},
	keywords = {Neural networks; AI systems; Digital technologies; Fast process; Interpretability; IT companies; Real-world problem; Societal issues; State of the art; Machine learning},
	publisher = {ESANN (i6doc.com)},
	isbn = {978-287587065-0},
	language = {English},
	abbrev_source_title = {ESANN - Proc., Euro. Symp. Artif. Neural Networks, Comput. Intell. Mach. Learn.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; Conference name: 27th European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning, ESANN 2019; Conference date: 24 April 2019 through 26 April 2019; Conference code: 149793}
}

@ARTICLE{Fabiano201979,
	author = {Fabiano, Nicola},
	title = {Robotics, big data, ethics and data protection: A matter of approach},
	year = {2019},
	journal = {Intelligent Systems, Control and Automation: Science and Engineering},
	volume = {95},
	pages = {79 – 87},
	doi = {10.1007/978-3-030-12524-0_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064948881&doi=10.1007%2f978-3-030-12524-0_8&partnerID=40&md5=9eda9b5a4ffdc1051057bbc2f5f778c7},
	affiliations = {Studio Legale Fabiano, Rome, Italy},
	abstract = {In Europe, the protection of personal data is a fundamental right. Within this framework, the relationship among robotics, Artificial Intelligence (AI), Machine Learning (ML), data protection and privacy has been receiving particular attention, recently, being the most important topics related to data protection and privacy those of Big Data, Internet of Things (IoT), Liability and Ethics. The present paper describes the main legal issues related to privacy and data protection highlighting the relationship among Big Data, Robotics, Ethics and data protection, trying to address the solution correctly through the European General Data Protection Regulation (GDPR) principles. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Big Data; Data protection; Ethics; Robotics},
	correspondence_address = {N. Fabiano; Studio Legale Fabiano, Rome, Italy; email: info@fabiano.law},
	publisher = {Springer Netherlands},
	issn = {22138986},
	language = {English},
	abbrev_source_title = {Intelligent Syst. Control Autom. Sci. Eng.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Silomon2019388,
	author = {Silomon, Jantje and Kaminska, Monica},
	title = {Artificial intelligence: Playing the imitation game},
	year = {2019},
	journal = {14th International Conference on Cyber Warfare and Security, ICCWS 2019},
	pages = {388 – 395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066022674&partnerID=40&md5=baa10a92e0a206797f974f954e99c097},
	affiliations = {University of Oxford, United Kingdom},
	abstract = {Almost 70 years ago, Alan Turing first questioned whether machines could think and how this could be examined given the ambiguity of terms. He proposed a test for a related question: could a machine imitate a human during a text-only natural language conversation. He predicted that by the turn of the century, language would have changed to the point that speaking about thinking machines would be nothing out of the ordinary. Whilst we are not quite there yet, Google did present a recording of its new Assistant making a hair-dresser’s appointment onstage at I/O 2018, sounding natural and even throwing in an ‘mmhmmm’. Dubbed a new generation of Artificial Intelligence (AI), it is clearly far ahead of current of Internet of Things (IoT) devices interacting with users, such as Alexa, Cortana, or Siri. Two other prominent examples include Deep Blue and AlphaGo, yet there are numerous other examples and applications that are used daily, such as email spam filters, plagiarism checkers, image recognition on social media, speech recognition or online shopping. It is clear that AI has become the new buzzword taking over from all things cyber, but what do we actually mean when we use the term? This article argues that there are three main reasons for the inconsistent use of AI: a lack of understanding, leading to AI being a magical solution, a doomsday device, neither and both at the same time; a heated, often ethical, debate on the application of AI to armed conflict; and the opportunity that AI presents for financial gain. © 2019 14th International Conference on Cyber Warfare and Security, ICCWS 2019. All rights reserved.},
	author_keywords = {AI; Artificial intelligence; Ethics; Machine learning},
	keywords = {Computer crime; Image recognition; Internet of things; Learning systems; Philosophical aspects; Speech recognition; Supercomputers; Armed conflict; Ethics; Financial gains; Imitation games; Internet of Things (IOT); Natural languages; Online shopping; Social media; Artificial intelligence},
	editor = {Leenen L. and van der Waag-Cowling N. and van der Waag-Cowling N.},
	publisher = {Academic Conferences and Publishing International Limited},
	isbn = {978-151088292-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Cyber Warf. Secur., ICCWS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 14th International Conference on Cyber Warfare and Security, ICCWS 2019; Conference date: 28 February 2019 through 1 March 2019; Conference code: 147886}
}

@ARTICLE{Roff2019127,
	author = {Roff, Heather M.},
	title = {Artificial Intelligence: Power to the People},
	year = {2019},
	journal = {Ethics and International Affairs},
	volume = {33},
	number = {2},
	pages = {127 – 140},
	doi = {10.1017/S0892679419000121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066930655&doi=10.1017%2fS0892679419000121&partnerID=40&md5=f1d5e78007e30f6417733da8a6cbd1fc},
	affiliations = {Johns Hopkins Applied Physics Lab, United States; Leverhulme Centre for the Future of Intelligence, University of Cambridge, United Kingdom},
	abstract = {To adequately estimate the beneficial and harmful effects of artificial intelligence (AI), we must first have a clear understanding of what AI is and what it is not. We need to draw important conceptual and definitional boundaries to ensure we accurately estimate and measure the impacts of AI from both empirical and normative standpoints. This essay argues that we should not conflate AI with automation or autonomy but keep them conceptually separate. Moreover, it suggests that once we have a broad understanding of what constitutes AI, we will see that it can be applied to all sectors of the economy and in warfare. However, it cautions that we must be careful where we apply AI, for in some cases there are serious epistemological concerns about whether we have an appropriate level of knowledge to create such systems. Opening the aperture to include such questions allows us to further see that while AI systems will be deployed in a myriad of forms, with greater or lesser cognitive abilities, these systems ought never to be considered moral agents. They cannot possess rights, and they do not have any duties. © 2019 Carnegie Council for Ethics in International Affairs.},
	author_keywords = {artificial intelligence; automation; autonomy; epistemology; ethics; machine learning},
	correspondence_address = {H.M. Roff; Johns Hopkins Applied Physics Lab, United States; email: heather.roff@jhuapl.edu},
	publisher = {Cambridge University Press},
	issn = {08926794},
	language = {English},
	abbrev_source_title = {Ethics Int. Aff.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@ARTICLE{Baig201943,
	author = {Baig, Mansoor Ali and Alzahrani, Somayah J.},
	title = {Revisiting the Skills of a Healthcare Data Scientist as a Field Expert},
	year = {2019},
	journal = {Studies in Health Technology and Informatics},
	volume = {262},
	pages = {43 – 46},
	doi = {10.3233/SHTI190012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068550523&doi=10.3233%2fSHTI190012&partnerID=40&md5=2fa3ba2129b0f155b8d2f801b0838634},
	affiliations = {King Faisal Specialist Hospital and Research Center, Riyadh, Saudi Arabia; Department of Biostatistics Epidemiology and Scientific Computing, KFSHRC, Riyadh, Saudi Arabia},
	abstract = {The buzz words 'Data Science' and 'Data Scientist' are trending high in this age of information. The boundaries are still undefined, the exact skill sets are unclear, and the job description is still murky. This is an attempt to identify some mandatory or desired skills based on what data science demands from a data scientist. A very generic job description for a data scientist is 'A person who can perform advanced analytics on the institutional data', this gives a very unclear picture to the decision maker to identify the right resources within their data science activity. Practically the data scientist should be the one who can understand and moreover be involved with the data life cycle starting from inception > collection > operation > extraction > observation > preparation > description > prediction > prescription > Archival. Each of these aspects of data has a science behind it. An old team 'Jack of all trades' briefly defines this job description. A good data scientist essentially needs to be a good programmer, a good business/system/data analyst, a good statistician, one who can seamlessly visualize data, and is empowered with a vision to use and apply the necessary tools, techniques and methodologies in a scientific and applicable realistic way. Healthcare/Research environment is a complicated vertical when it comes to data, hence having domain knowledge is almost critical, complying with aspects of data governance such as patient privacy, consent, ethics etc. © 2019 The authors and IOS Press. All rights reserved.},
	author_keywords = {Advanced Analytics; Data Management; Data Science; Data science skills; Data Scientist; Job description; Machine Learning},
	keywords = {Comprehension; Data Science; Decision Making; Delivery of Health Care; Humans; Job Description; Data Science; Decision making; Employment; Health care; Information management; Job analysis; Learning systems; Life cycle; Medical informatics; Data governances; Data life cycle; Data Scientist; Decision makers; Domain knowledge; Job description; Patient privacies; Science activities; adult; conference paper; data science; ethics; extraction; human; life cycle; machine learning; prediction; prescription; privacy; skill; statistician; vision; work; comprehension; decision making; health care delivery; Advanced Analytics},
	correspondence_address = {M.A. Baig; King Faisal Specialist Hospital and Research Center, Riyadh, Saudi Arabia; email: mansoorbaig@hotmail.com},
	editor = {Mantas J. and Hasman A. and Gallos P. and Kolokathi A. and Househ M.S. and Liaskos J.},
	publisher = {IOS Press},
	issn = {09269630},
	isbn = {978-161499986-7},
	pmid = {31349261},
	language = {English},
	abbrev_source_title = {Stud. Health Technol. Informatics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Bazziconi201989,
	author = {Bazziconi, Pierre-François and Bleton, Laure and Berrouiguet, Sofian and Thierry, Alexia and Walter, Michel and Lemey, Christophe},
	title = {Abstract. The use of linguistic markers and machine learning methods for speech in predicting a transition towards psychosis: What are the ethical challenges for patients and psychiatrists?.; [L’utilisation de marqueurs linguistiques et de méthodes d’apprentissage automatique du discours dans la prédiction de la transition vers la psychose: Quels enjeux pour le patient et le psychiatre ?]},
	year = {2019},
	journal = {Information Psychiatrique},
	volume = {95},
	number = {2},
	pages = {89 – 94},
	doi = {10.1684/ipe.2019.1911},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063995444&doi=10.1684%2fipe.2019.1911&partnerID=40&md5=fc98712474c661e56d696ce751125456},
	affiliations = {Département de psychiatrie universitaire, CHU Brest, France},
	abstract = {For some time, prediction in the field of schizophrenia has been one of the major challenges facing psychiatrists worldwide. Several centers have been set up for early detection of subjects at risk of developing psychotic disorders, enabling rapid intervention. To enhance prediction, the Brest Department of Psychiatry has focused on identifying specific linguistic markers of transition towards psychosis using machine learning techniques. From reification of language to desubjectification of the individual, this transformation in clinical practice raises ethical and epistemological challenges. In keeping with the principle of beneficence and the duty to intervene with respect to vulnerable subjects, a precautionary ethical approach could achieve the right balance between advocates of abstention and those who extol “intervention at any cost”. In deploying energy to constantly evolve, this approach would thus, like language, act as a mediator between an individual’s “inner world” and the “common world.” Copyright © 2019 John Libbey Eurotext.},
	author_keywords = {Ethics; Evaluation; Language; Linguistics; Machine learning; Predictive medicine; Psychiatry; Psychosis; Risk indicators; Schizophrenia},
	correspondence_address = {P.-F. Bazziconi; Département de psychiatrie universitaire, CHU Brest, France; email: pfbazziconi@gmail.com},
	publisher = {John Libbey Eurotext},
	issn = {00200204},
	coden = {IPSYB},
	language = {French},
	abbrev_source_title = {Inf. Psychiatr.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Watson2019,
	author = {Watson, David S. and Krutzinna, Jenny and Bruce, Ian N. and Griffiths, Christopher E.M. and McInnes, Iain B. and Barnes, Michael R. and Floridi, Luciano},
	title = {Clinical applications of machine learning algorithms: Beyond the black box},
	year = {2019},
	journal = {BMJ (Online)},
	volume = {364},
	doi = {10.1136/bmj.l886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062890886&doi=10.1136%2fbmj.l886&partnerID=40&md5=2d62d79b5ad7f62c511f9a858e9b6b31},
	affiliations = {Oxford Internet Institute, University of Oxford, 1 St Giles', Oxford, OX1 3JS, United Kingdom; Centre for Translational Bioinformatics, William Harvey Research Institute, Queen Mary University of London, London, United Kingdom; Alan Turing Institute, London, United Kingdom; Arthritis Research UK Centre for Epidemiology, Centre for Musculoskeletal Research, University of Manchester, Manchester, United Kingdom; NIHR Manchester Biomedical Research Centre, Manchester University Hospitals NHS Foundation Trust, Manchester, M13 9WL, United Kingdom; Dermatology Centre, Salford Royal NHS Foundation Trust, University of Manchester, Salford, United Kingdom; Institute of Infection, Immunity and Inflammation, University of Glasgow, Glasgow, United Kingdom},
	keywords = {Algorithms; Attitude of Health Personnel; Attitude to Computers; Clinical Decision-Making; Computer Security; Diagnosis, Computer-Assisted; Ethics, Medical; Health Knowledge, Attitudes, Practice; Humans; Machine Learning; Therapy, Computer-Assisted; Article; artificial intelligence; artificial neural network; clinical decision making; clinical practice; diagnostic error; electronic health record; health care policy; human; learning algorithm; medical ethics; personalized medicine; priority journal; statistical model; algorithm; attitude to computers; attitude to health; clinical decision making; computer assisted diagnosis; computer assisted therapy; computer security; ethics; health personnel attitude; legislation and jurisprudence; machine learning; procedures},
	correspondence_address = {D.S. Watson; Oxford Internet Institute, University of Oxford, Oxford, 1 St Giles', OX1 3JS, United Kingdom; email: david.watson@oii.ox.ac.uk},
	publisher = {BMJ Publishing Group},
	issn = {09598146},
	coden = {BMJOA},
	pmid = {30862612},
	language = {English},
	abbrev_source_title = {BMJ (Online)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 194; All Open Access, Green Open Access}
}

@ARTICLE{Zandi20192,
	author = {Zandi, Diana and Reis, Andreas and Vayena, Effy and Goodman, Kenneth},
	title = {New ethical challenges of digital technologies, machine learning and artificial intelligence in public health: A call for papers},
	year = {2019},
	journal = {Bulletin of the World Health Organization},
	volume = {97},
	number = {1},
	pages = {2},
	doi = {10.2471/BLT.18.227686},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059482953&doi=10.2471%2fBLT.18.227686&partnerID=40&md5=e4646de66726b7c26ea0d2fc7f89f15f},
	affiliations = {Service Delivery and Safety, World Health Organization, avenue Appia 20, Geneva 27, 1211, Switzerland; Information, Evidence and Research, World Health Organization, Geneva, Switzerland; Institute of Translational Medicine, Eidgenössische Technische Hochschule Zürich, Zürich, Switzerland; Institute for Bioethics and Health Policy, University of Miami, Miami, United States},
	keywords = {algorithm; artificial intelligence; chronic disease; Editorial; ethics; health care personnel; health care system; high income country; information processing; information technology; Internet; low income country; machine learning; middle income country; problem solving; public health; public health campaign; software; technology},
	correspondence_address = {D. Zandi; Service Delivery and Safety, World Health Organization, avenue Appia 20, Geneva 27, 1211, Switzerland; email: zandid@who.int},
	publisher = {World Health Organization},
	issn = {00429686},
	coden = {BWHOA},
	language = {English},
	abbrev_source_title = {Bull. WHO},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Sen2019,
	author = {Sen, Debraj and Chakrabarti, R. and Chatterjee, S. and Grewal, D.S. and Manrai, K.},
	title = {Artificial intelligence and the radiologist: The future in the Armed Forces Medical Services},
	year = {2019},
	journal = {Journal of the Royal Army Medical Corps},
	doi = {10.1136/jramc-2018-001055},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85060929255&doi=10.1136%2fjramc-2018-001055&partnerID=40&md5=15746facbdd2dff435fc7448859b8949},
	affiliations = {Department of Radiodiagnosis, Command Hospital (SC), Pune, 411040, India; Department of Radiodiagnosis, Post-Graduate Institute of Medical Education and Research (PGIMER), Chandigarh, India; Department of Radiodiagnosis, Armed Forces Medical College (AFMC), Pune, India},
	abstract = {Artificial intelligence (AI) involves computational networks (neural networks) that simulate human intelligence. The incorporation of AI in radiology will help in dealing with the tedious, repetitive, time-consuming job of detecting relevant findings in diagnostic imaging and segmenting the detected images into smaller data. It would also help in identifying details that are oblivious to the human eye. AI will have an immense impact in populations with deficiency of radiologists and in screening programmes. By correlating imaging data from millions of patients and their clinico-demographic-therapy-morbidity-mortality profiles, AI could lead to identification of new imaging biomarkers. This would change therapy and direct new research. However, issues of standardisation, transparency, ethics, regulations, training, accreditation and safety are the challenges ahead. The Armed Forces Medical Services has widely dispersed units, medical echelons and roles ranging from small field units to large static tertiary care centres. They can incorporate AI-enabled radiological services to subserve small remotely located hospitals and detachments without posted radiologists and ease the load of radiologists in larger hospitals. Early widespread incorporation of information technology and enabled services in our hospitals, adequate funding, regular upgradation of software and hardware, dedicated trained manpower to manage the information technology services and train staff, and cyber security are issues that need to be addressed. © Author(s) (or their employer(s)) 2019. No commercial re-use. See rights and permissions. Published by BMJ.},
	author_keywords = {Armed Forces Medical Services (AFMS); artificial intelligence (AI); deep learning; machine learning; radiology},
	keywords = {Artificial Intelligence; Forecasting; Humans; Military Medicine; Radiology; artificial intelligence; devices; education; forecasting; human; military medicine; procedures; radiology},
	correspondence_address = {D. Sen; Department of Radiodiagnosis, Command Hospital (SC), Pune, 411040, India; email: sendebraj@gmail.com},
	publisher = {BMJ Publishing Group},
	issn = {00358665},
	coden = {JRAMA},
	pmid = {30709922},
	language = {English},
	abbrev_source_title = {J. R. Army Med. Corps},
	type = {Review},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Ebert2019583,
	author = {Ebert, David Daniel and Harrer, Mathias and Apolinário-Hagen, Jennifer and Baumeister, Harald},
	title = {Digital Interventions for Mental Disorders: Key Features, Efficacy, and Potential for Artificial Intelligence Applications},
	year = {2019},
	journal = {Advances in Experimental Medicine and Biology},
	volume = {1192},
	pages = {583 – 627},
	doi = {10.1007/978-981-32-9721-0_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074707862&doi=10.1007%2f978-981-32-9721-0_29&partnerID=40&md5=16179331f81c7dec861769be3da43979},
	affiliations = {Department of Clinical Psychology, Vrije Universiteit Amsterdam, Van der Boechorststraat 1, Amsterdam, 1881 BT, Netherlands; Clinical Psychology and Psychotherapy, Friedrich-Alexander-University Erlangen-Nuremberg, Erlangen, Germany; Faculty of Psychology, Department of Health Psychology, FernUniversität in Hagen, Hagen, Germany; Clinical Psychology and Psychotherapy, University of Ulm, Ulm, Germany},
	abstract = {Mental disorders are highly prevalent and often remain untreated. Many limitations of conventional face-to-face psychological interventions could potentially be overcome through Internet-based and mobile-based interventions (IMIs). This chapter introduces core features of IMIs, describes areas of application, presents evidence on the efficacy of IMIs as well as potential effect mechanisms, and delineates how Artificial Intelligence combined with IMIs may improve current practices in the prevention and treatment of mental disorders in adults. Meta-analyses of randomized controlled trials clearly show that therapist-guided IMIs can be highly effective for a broad range of mental health problems. Whether the effects of unguided IMIs are also clinically relevant, particularly under routine care conditions, is less clear. First studies on IMIs for the prevention of mental disorders have shown promising results. Despite limitations and challenges, IMIs are increasingly implemented into routine care worldwide. IMIs are also well suited for applications of Artificial Intelligence and Machine Learning, which provides ample opportunities to improve the identification and treatment of mental disorders. Together with methodological innovations, these approaches may also deepen our understanding of how psychological interventions work, and why. Ethical and professional restraints as well as potential contraindications of IMIs, however, should also be considered. In sum, IMIs have a high potential for improving the prevention and treatment of mental health disorders across various indications, settings, and populations. Therefore, implementing IMIs into routine care as both adjunct and alternative to face-to-face treatment is highly desirable. Technological advancements may further enhance the variability and flexibility of IMIs, and thus even further increase their impact in people’s lives in the future. © Springer Nature Singapore Pte Ltd. 2019.},
	author_keywords = {Artificial intelligence; eHealth; Internet interventions; Machine learning; Mental disorders; Prevention; Psychotherapy},
	keywords = {Adult; Artificial Intelligence; Humans; Internet; Mental Disorders; Mobile Applications; Psychotherapy; Telemedicine; artificial intelligence; clinical decision support system; clinical effectiveness; clinical practice; cost effectiveness analysis; digital intervention; empowerment; evidence based medicine; human; intermethod comparison; Internet; machine learning; medical ethics; mental disease; mental health care; meta analysis (topic); methodology; mobile application; population; priority journal; prophylaxis; psychiatric diagnosis; psychotherapist; psychotherapy; randomized controlled trial (topic); reinforcement; technology; theory; treatment contraindication; adult; mental disease; mobile application; procedures; psychotherapy; telemedicine},
	correspondence_address = {D.D. Ebert; Department of Clinical Psychology, Vrije Universiteit Amsterdam, Amsterdam, Van der Boechorststraat 1, 1881 BT, Netherlands; email: d.d.ebert@vu.nl},
	publisher = {Springer New York LLC},
	issn = {00652598},
	coden = {AEMBA},
	pmid = {31705515},
	language = {English},
	abbrev_source_title = {Adv. Exp. Med. Biol.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22}
}

@CONFERENCE{Mika201920,
	author = {Mika, Nieminen and Nadezhda, Gotcheva and Jaana, Leikas and Raija, Koivisto},
	title = {Ethical AI for the governance of the society: Challenges and opportunities},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2505},
	pages = {20 – 26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075973887&partnerID=40&md5=11957a27e5340ffba70e65c59988d399},
	affiliations = {VTT Technical Research Centre of Finland Ltd., Visiokatu 4, Tampere, Finland},
	abstract = {Artificial Intelligence (AI) technologies are expected to have numerous and diverse social implications that cut deep into our society. Due to AI’s specific nature as emergent and constantly evolving generic technology, we need new approaches, methodologies, and processes to govern and steer the utilization of AI technologies both in the public and private sectors. This is both a multilevel and multi-dimensional governance challenge. First, there has to be a shared and coordinated understanding across various social and administrational sectors on how AI is implemented and regulated. Second, good coordination between different levels of governance is crucial. Third, there is a challenge to find a balance between soft and hard governance mechanisms in varying implementation and organizational contexts. This paper presents an overview of a new Strategic Research Council funded project project entitled “Ethical AI for the Governance of the Society” (ETAIROS). The project focuses on studying and co-developing together with stakeholders practical governance approaches, as well as design and technology solutions that help public, private and civil society actors enhance the ethical sustainability of operations in the use of AI. To achieve its ambitious goals, this interdisciplinary endeavour integrates expertise in foresight, ethics, design, machine learning and governance. Copyright © 2019 for this paper by its authors.},
	author_keywords = {Artificial intelligence (AI); Design; Ethics; Foresight; Governance; Responsibility; Societal impacts},
	keywords = {Artificial intelligence; Design; Ethics; Foresight; Governance; Responsibility; Societal impacts; Philosophical aspects},
	editor = {Rantanen M.M. and Jani J.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 3rd Seminar of Techonology Ethics, Tethics 2019; Conference date: 23 October 2019 through 24 October 2019; Conference code: 155250}
}

@ARTICLE{Barnett2019565,
	author = {Barnett, Ian and Torous, John},
	title = {Ethics, transparency, and public health at the intersection of innovation and Facebook's suicide prevention efforts},
	year = {2019},
	journal = {Annals of Internal Medicine},
	volume = {170},
	number = {8},
	pages = {565 – 566},
	doi = {10.7326/M19-0366},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85064558043&doi=10.7326%2fM19-0366&partnerID=40&md5=4733801d9b246afc65c18fdc6147a89c},
	affiliations = {University of Pennsylvania, Perelman School of Medicine, Philadelphia, PA, United States; Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, MA, United States; University of Pennsylvania, Perelman School of Medicine, 423 Guardian Drive, Philadelphia, 19104, PA, United States; Department of Psychiatry, Beth Israel Deaconess Medical Center, Harvard Medical School, 75 Fenwood Road, Boston, 02115, MA, United States},
	keywords = {Algorithms; Emergency Medical Services; Humans; Organizational Innovation; Privacy; Public Health; Risk Factors; Social Media; Suicide; United States; clinical research; emergency health service; evidence based practice; human; language; machine learning; medical ethics; Note; priority journal; public health; risk assessment; social media; suicide; algorithm; epidemiology; ethics; organization; organization and management; privacy; public health; risk factor; social media; suicide; United States},
	correspondence_address = {J. Torous; Department of Psychiatry, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, 75 Fenwood Road, 02115, United States; email: jtorous@bidmc.harvard.edu},
	publisher = {American College of Physicians},
	issn = {00034819},
	coden = {AIMEA},
	pmid = {30743261},
	language = {English},
	abbrev_source_title = {Ann. Intern. Med.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 26}
}

@ARTICLE{Cadzow20191058,
	author = {Cadzow, Scott},
	title = {Ethics as a Security Role},
	year = {2019},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {876},
	pages = {1058 – 1062},
	doi = {10.1007/978-3-030-02053-8_161},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85055807403&doi=10.1007%2f978-3-030-02053-8_161&partnerID=40&md5=b580a9bbdaf550b3f68c3a753f211503},
	affiliations = {C3L, Sawbridgeworth, CM21 9NP, United Kingdom},
	abstract = {Artificial Intelligence (AI) will produce societal change, thus amongst the topics that developers, implementors and legislators for the domains that will use AIs have to look at are Ethics, Liability, Responsibility and Societal Integration. These are all elements of the social compass of human intelligence and it is reasonable to assume that AI also addresses these things. In designing AIs it is essential to place each of these characteristics in the learning process of both the AI designer and the AI itself. On the understanding that AI presents risk to the system it is proposed that the handling of Ethics in systems is addressed in the security domain to ensure that the risks arising from ethical decision making are addressed by well designed mitigation and containment processes. In addition it is proposed that mechanisms to manage ethics should be addressed in the standards domain. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Artificial Intelligence; Ethics; Machine learning; Security},
	keywords = {Artificial intelligence; Decision making; Learning systems; Systems engineering; Ethical decision making; Ethics; Human intelligence; Learning process; Security; Security domains; Societal changes; Philosophical aspects},
	correspondence_address = {S. Cadzow; C3L, Sawbridgeworth, CM21 9NP, United Kingdom; email: scott@cadzow.com},
	editor = {Ahram T. and Taiar R. and Karwowski W.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-303002052-1},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st International Conference on Human Systems Engineering and Design: Future Trends and Applications, IHSED 2018; Conference date: 25 October 2018 through 27 October 2018; Conference code: 219909}
}

@ARTICLE{Hersh20191,
	author = {Hersh, Craig P. and Adcock, Ian M. and Celedón, Juan C. and Cho, Michael H. and Christiani, David C. and Himes, Blanca E. and Kaminski, Naftali and Mathias, Rasika A. and Meyers, Deborah A. and Quackenbush, John and Redline, Susan and Steiling, Katrina A. and Tabor, Holly K. and Tobin, Martin D. and Wurfel, Mark M. and Yang, Ivana V. and Koppelman, Gerard H.},
	title = {High-throughput sequencing in respiratory, critical care, and sleep medicine research an official American thoracic society workshop report},
	year = {2019},
	journal = {Annals of the American Thoracic Society},
	volume = {16},
	number = {1},
	pages = {1 – 16},
	doi = {10.1513/AnnalsATS.201810-716WS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059234159&doi=10.1513%2fAnnalsATS.201810-716WS&partnerID=40&md5=811291151292eeb49957d006ca3b2989},
	affiliations = {Channing Division of Network Medicine, Brigham and Women’s Hospital, 181 Longwood Avenue, Boston, 02115, MA, United States; Channing Division of Network Medicine, Brigham and Women’s Hospital, Boston, MA, United States; Division of Pulmonary and Critical Care Medicine, Brigham and Women’s Hospital, Boston, MA, United States; Division of Sleep and Circadian Disorders, Brigham and Women’s Hospital, Boston, MA, United States; Harvard Medical School, Boston, MA, United States; Department of Pediatric Pulmonology and Pediatric Allergology, Beatrix Children’s Hospital, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Groningen Research Institute for Asthma and COPD, University Medical Center Groningen, University of Groningen, Groningen, Netherlands; Airways Disease Section, National Heart and Lung Institute, Imperial College London, London, United Kingdom; Division of Pediatric Pulmonary Medicine, Allergy and Immunology, Children’s Hospital of Pittsburgh, University of Pittsburgh Medical Center, Pittsburgh, PA, United States; Department of Environmental Health, Harvard T.H. Chan School of Public Health, Boston, MA, United States; Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, MA, United States; Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, MA, United States; Pulmonary and Critical Care Division, Department of Medicine, Massachusetts General Hospital, Boston, MA, United States; Department of Biostatistics, Epidemiology and Informatics, University of Pennsylvania, Philadelphia, PA, United States; Pulmonary, Critical Care and Sleep Medicine, Yale University School of Medicine, New Haven, CT, United States; Division of Allergy and Clinical Immunology, Department of Medicine, Johns Hopkins University, Baltimore, MD, United States; University of Arizona College of Medicine, Tucson, AZ, United States; Department of Medicine, Beth Israel Deaconess Medical Center, Boston, MA, United States; Division of Computational Biomedicine, Boston University School of Medicine, Boston, MA, United States; Stanford Center for Biomedical Ethics, Department of Medicine, Stanford University, School of Medicine, Stanford, CA, United States; Department of Health Sciences, University of Leicester, Leicester, United Kingdom; National Institute for Health Research Leicester Respiratory Biomedical Research Centre, Glenfield Hospital, Leicester, United Kingdom; Division of Pulmonary, Critical Care and Sleep Medicine, University of Washington, Seattle, WA, United States; Department of Medicine, University of Colorado, Denver, CO, United States},
	abstract = {High-throughput, “next-generation” sequencing methods are now being broadly applied across all fields of biomedical research, including respiratory disease, critical care, and sleep medicine. Although there are numerous review articles and best practice guidelines related to sequencing methods and data analysis, there are fewer resources summarizing issues related to study design and interpretation, especially as applied to common, complex, nonmalignant diseases. To address these gaps, a single-day workshop was held at the American Thoracic Society meeting in May 2017, led by the American Thoracic Society Section on Genetics and Genomics. The aim of this workshop was to review the design, analysis, interpretation, and functional follow-up of high-throughput sequencing studies in respiratory, critical care, and sleep medicine research. This workshop brought together experts in multiple fields, including genetic epidemiology, biobanking bioinformatics, and research ethics, along with physician-scientists with expertise in a range of relevant diseases. The workshop focused on application of DNA and RNA sequencing research in common chronic diseases and did not cover sequencing studies in lung cancer, monogenic diseases (e.g., cystic fibrosis), or microbiome sequencing. Participants reviewed and discussed study design, data analysis and presentation, interpretation, functional follow-up, and reporting of results. This report summarizes the main conclusions of the workshop, specifically addressing the application of these methods in respiratory, critical care, and sleep medicine research. This workshop report may serve as a resource for our research community as well as for journal editors and reviewers of sequencing-based manuscript submissions in our research field. Copyright © 2019 by the American Thoracic Society.},
	author_keywords = {Bioinformatics; Functional genomics; Genetic epidemiology; RNA sequencing; Whole-genome sequencing},
	keywords = {Critical Care; High-Throughput Nucleotide Sequencing; Humans; Pulmonary Medicine; Sleep Medicine Specialty; Societies, Medical; United States; Whole Genome Sequencing; DNA; RNA; airway obstruction; asthma; biobank; bioinformatics; cell heterogeneity; chronic disease; chronic obstructive lung disease; Conference Paper; data analysis; deep learning; DNA sequence; epigenetics; exercise physiology; expression quantitative trait locus; fibrosing alveolitis; follow up; functional genomics; gene expression; gene knockdown; genetic epidemiology; health equity; high throughput sequencing; intensive care; lung cancer; lung dysplasia; machine learning; medical research; medical society; metabolomics; microbiome; narcolepsy; next generation sequencing; phenotype; physician; practice guideline; proteomics; pulmonary vascular disease; pulmonary veno-occlusive disease; quality control; research ethics; respiratory tract disease; RNA sequence; scientist; sepsis; sleep medicine; smoking; software; statistical analysis; study design; systemic inflammatory response syndrome; transcriptomics; whole genome sequencing; workflow; workshop; human; pulmonology; United States},
	correspondence_address = {C.P. Hersh; Channing Division of Network Medicine, Brigham and Women’s Hospital, Boston, 181 Longwood Avenue, 02115, United States; email: craig.hersh@channing.harvard.edu},
	publisher = {American Thoracic Society},
	issn = {23256621},
	pmid = {30592451},
	language = {English},
	abbrev_source_title = {Ann. Am. Thorac. Soc.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@CONFERENCE{Harlow2019393,
	author = {Harlow, Harold D.},
	title = {Human capital and artificial intelligence (AL): Preparing for the singularity},
	year = {2019},
	journal = {Proceedings of the European Conference on Intellectual Capital},
	volume = {2019-May},
	pages = {393 – 396},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85069990709&partnerID=40&md5=4a32be126d866e204deabcc0612f20fb},
	affiliations = {Wingate University, NC, United States},
	abstract = {Singularity is the point where Al and machine learning using Al begins to exceed the capability of humans. This point of no return is fast approaching with some researchers predicting that this will occur within five (5) years. This developmental paper-2000 words-begins researching the state of the art of artificial intelligence (Al) control and its place in the intellectual capital of companies and how this computer capability alters the relationship of machines to man. In particular, the extraction of intellectual capital by Al at singularity where the intellectual capital maybe less understood by humans and completely developed by the Al agent may lead to ethical problems and human second class overview. The developmental literature review further lays some groundwork for the Al/Human interface at Singularity model presented and the connections between the use of Al and the singularity ethical considerations and its effect on humans. The use of a stated data protection for customers business and Al code of conduct backed up by legal constraints is developing but is in its infancy and may not be prepared for the quickly evolving eventual domination of Al in developing intellectual capital and running human enterprises. This paper presents a preliminary Al/Human interface at Singularity model for further research on the control of outcomes of using Al past the point of singularity and the factors driving those outcomes as well as warnings for mankind and how mankind might be protected. © 2019 Academic Conferences Limited. All rights reserved.},
	author_keywords = {Artificial Intelligence; Ethics; Singularity},
	correspondence_address = {H.D. Harlow; Wingate University, United States; email: h.harlow@wingate.edu},
	editor = {Sargiacomo M.},
	publisher = {Academic Conferences Limited},
	issn = {20490933},
	isbn = {978-191276418-1},
	language = {English},
	abbrev_source_title = {Proc. Eur. Conf. Intellect. Cap.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; Conference name: 10th European Conference on Intangibles and Intellectual Capital, ECIIC 2019; Conference date: 23 May 2019 through 24 May 2019; Conference code: 149406}
}

@ARTICLE{Reger201971,
	author = {Reger, Greg M. and McClure, Mary Lou and Ruskin, David and Carter, Sarah P. and Reger, Mark A.},
	title = {Integrating predictive modeling into mental health care: An example in suicide prevention},
	year = {2019},
	journal = {Psychiatric Services},
	volume = {70},
	number = {1},
	pages = {71 – 74},
	doi = {10.1176/appi.ps.201800242},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059551932&doi=10.1176%2fappi.ps.201800242&partnerID=40&md5=9cb5cd5285593ebd269c8fbf13f6ec69},
	affiliations = {Mental Health Service, Veterans Affairs Puget Sound Health Care System, Seattle/Takoma, WA, United States; Psychiatry and Behavioral Sciences, University of Washington School of Medicine, Seattle, United States},
	abstract = {Recent advances in statistical methods and computing power have improved the ability to predict risks associated with mental illness with more efficiency and accuracy. However, integrating statistical prediction into a clinical setting poses new challenges that need creative solutions. A case example explores the challenges and innovations that emerged at a Department of Veterans Affairs hospital while implementing REACH VET (Recovery Engagement and Coordination for Health - Veterans Enhanced Treatment), a suicide prevention program that is based on a predictive model that identifies veterans at statistical risk for suicide. © 2019 American Psychiatric Association. All rights reserved.},
	keywords = {Humans; Mental Disorders; Mental Health Services; Models, Statistical; Patient Acceptance of Health Care; Risk Assessment; Suicide; United States; United States Department of Veterans Affairs; Veterans; Article; care coordinator; communication skill; demography; health care system; human; interpersonal communication; knowledge; leadership; machine learning; medical ethics; mental health; mental health care; mental health center; mental health service; national health organization; prediction; preventive health service; risk assessment; staff training; statistical model; suicide; suicide attempt; teamwork; government; mental disease; organization and management; patient attitude; psychology; suicide; United States; veteran},
	correspondence_address = {G.M. Reger; Mental Health Service, Veterans Affairs Puget Sound Health Care System, Seattle/Takoma, United States; email: greg.reger@va.gov},
	publisher = {American Psychiatric Association},
	issn = {10752730},
	coden = {PSSEF},
	pmid = {30301448},
	language = {English},
	abbrev_source_title = {Psychiatr. Serv.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Bronze Open Access}
}

@ARTICLE{2019,
	title = {20th International Conference on Artificial Intelligence in Education, AIED 2019},
	year = {2019},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {11625 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85068349323&partnerID=40&md5=0f43b883cd7ee407ad7e187d0b3e30a6},
	abstract = {The proceedings contain 121 papers. The special focus in this conference is on Artificial Intelligence in Education. The topics include: Autonomy and types of informational text presentations in game-based learning environments; examining gaze behaviors and metacognitive judgments of informational text within game-based learning environments; using “idealized peers” for automated evaluation of student understanding in an introductory psychology course; 4D affect detection: Improving frustration detection in game-based learning with posture-based temporal data fusion; Designing for complementarity: Teacher and student needs for orchestration support in AI-enhanced classrooms; the case of self-transitions in affective dynamics; how many times should a pedagogical agent simulation model be run?; A survey of the general public’s views on the ethics of using AI in education; promoting inclusivity through time-dynamic discourse analysis in digitally-mediated collaborative learning; evaluating machine learning approaches to classify pharmacy students’ reflective statements; investigating help-giving behavior in a cross-platform learning environment; comfort with robots influences rapport with a social, entraining teachable robot; a concept map based assessment of free student answers in tutorial dialogues; deep (Un)learning: Using neural networks to model retention and forgetting in an adaptive learning system; checking it twice: Does adding spelling and grammar checkers improve essay quality in an automated writing tutor?; what’s most broken? Design and evaluation of a tool to guide improvement of an intelligent tutor; reducing mind-wandering during vicarious learning from an intelligent tutoring system; annotated examples and parameterized exercises: Analyzing students’ behavior patterns; investigating the effect of adding nudges to increase engagement in active video watching.},
	editor = {Isotani S. and Hastings P. and Ogan A. and McLaren B. and Millán E. and Luckin R.},
	publisher = {Springer Verlag},
	issn = {03029743},
	isbn = {978-303023203-0},
	language = {English},
	abbrev_source_title = {Lect. Notes Comput. Sci.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 20th International Conference on Artificial Intelligence in Education, AIED 2019; Conference date: 25 June 2019 through 29 June 2019; Conference code: 227669}
}

@ARTICLE{Lacroix2019101,
	author = {Lacroix, Paulette},
	title = {Big Data Privacy and Ethical Challenges},
	year = {2019},
	journal = {Lecture Notes in Bioengineering},
	pages = {101 – 111},
	doi = {10.1007/978-3-030-06109-8_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062992928&doi=10.1007%2f978-3-030-06109-8_9&partnerID=40&md5=ad913ec458d08041233b2a3cab317c6b},
	affiliations = {PC Lacroix Consulting Inc., North Vancouver, Canada},
	abstract = {Big data is a complex phenomenon of technical advances in storage capacity, computational speed, the low cost of data collection and predictive analytics. Artificial Intelligence (AI) is a key to unlocking the value of big data, and machine learning underpins and facilitates AI. All three concepts combine to result in big data analytics, the properties of which challenge compliance with information privacy principles that have led to recent significant legislative changes in data protection. Further, the use of profiling and automated decision-making made possible by machine learning and AI go well beyond privacy protections and will require ethical oversight. Personal data protection regimes, like the European Union General Data Protection Regulation, are instruments for governance of data flows and remain valuable for classical data processing. Yet they may be inadequate to address the unprecedented challenges raised by big data. New digital geopolitics created by differences in data protection rules across national borders no longer represent the limits of data flows, and the consequences for global governance are significant. There is rising consensus that a digital ethics framework is needed to provide modern terms for identifying, analyzing and communicating new human realities with existing and foreseeable technological changes. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Big data; Data ethics; Data scientist; Privacy; Research},
	correspondence_address = {P. Lacroix; PC Lacroix Consulting Inc., North Vancouver, Canada; email: placroix@placroix.ca},
	publisher = {Springer},
	issn = {2195271X},
	language = {English},
	abbrev_source_title = {Lect. Notes Bioeng.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Schlögl2019259,
	author = {Schlögl, Stephan and Postulka, Claudia and Bernsteiner, Reinhard and Ploder, Christian},
	title = {Artificial intelligence tool penetration in business: Adoption, challenges and fears},
	year = {2019},
	journal = {Communications in Computer and Information Science},
	volume = {1027},
	pages = {259 – 270},
	doi = {10.1007/978-3-030-21451-7_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85067677105&doi=10.1007%2f978-3-030-21451-7_22&partnerID=40&md5=bbc42d91eac1405145abe5ef1aacc646},
	affiliations = {Department Management, Communication and IT, MCI Management Center Innsbruck, Universitätsstraße 15, Innsbruck, 6020, Austria},
	abstract = {Artificial Intelligence (AI) and its promise to improve the efficiency of entire business value chains has been headlining newspapers for the last years. However, it seems that many companies struggle in finding the right tools and use cases for their distinct fields of application. Thus, the aim of the presented study was to evaluate the current state of machine learning and co in various European companies. Talking to 19 employees from various different industry sectors, we explored applicability of AI tools as well as human attitudes towards these technologies. Results show that AI implementations are still in their early stages, with a rather small number of viable use cases. Tools are predominantly bespoke and internally built, while off-the-shelf solutions suffer from a lack of trust in third party service providers. Although companies claim to have no intention of reducing the workforce in favor of AI technology, employees fear job loss and thus often reject adoption. Another important challenge concerns data privacy and ethics, which has grown in relevance with respect to recent changes in European legislation. In summary, we found that companies recognize the competitive advantage AI may attribute to their value chains, in particular when it comes to automation and increased process efficiency. Yet they are also aware of the rather social challenges, which currently inhibit the proliferation of AI-driven solutions. © Springer Nature Switzerland AG 2019.},
	author_keywords = {Artificial intelligence; Implementation challenges; Interview study; Technology adoption},
	keywords = {Artificial intelligence; Competition; Data privacy; Efficiency; Employment; Learning systems; Personnel; Artificial intelligence tools; Competitive advantage; European companies; European legislation; Implementation challenges; Interview study; Technology adoption; Third-party service providers; Knowledge management},
	correspondence_address = {S. Schlögl; Department Management, Communication and IT, MCI Management Center Innsbruck, Innsbruck, Universitätsstraße 15, 6020, Austria; email: stephan.schloegl@mci.edu},
	editor = {Uden L. and Ting I.-H. and Corchado J.M.},
	publisher = {Springer Verlag},
	issn = {18650929},
	isbn = {978-303021450-0},
	language = {English},
	abbrev_source_title = {Commun. Comput. Info. Sci.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; Conference name: 14th International Conference on Knowledge Management in Organizations, KMO 2019; Conference date: 15 July 2019 through 18 July 2019; Conference code: 227229}
}

@ARTICLE{Cunningham2019211,
	author = {Cunningham, Margaret and Kular, Dalwinderjeet},
	title = {Improving cyber situation awareness by building trust in analytics},
	year = {2019},
	journal = {Advances in Intelligent Systems and Computing},
	volume = {903},
	pages = {211 – 216},
	doi = {10.1007/978-3-030-11051-2_32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059943875&doi=10.1007%2f978-3-030-11051-2_32&partnerID=40&md5=168d165538fb90ce2ffbdbe69d6488e8},
	affiliations = {Forcepoint, Austin, TX, United States},
	abstract = {Analysts depend on technology to access and understand information, information that ultimately impacts their level of Cyber Situation Awareness (CyberSA). Adoption of advanced analytics, particularly those that generate risk scores or that depend on machine learning, can be impacted by a lack of trust in what the scores represent. Lack of trust in analytics can negatively impact CyberSA and efficient decision making, as analysts who do not trust outcomes from analytic models continue to search for information that confirms the analytic outcome, or continue to seek supplementary environmental information prior to making critical decisions. While human-driven investigative work is, and will remain, critical for security operations, delays in decision making, and increased efforts in information gathering, can negatively impact the efficiency of threat detection. Semi-structured interviews with analysts revealed five avenues for improving trust in analytics, including Context-Based, Case-Based, Model-Based, Ethics-Based, and Human-Centric AI Improvements. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Analytics; CyberSA; HCI; Risk scores; UEBA},
	keywords = {Behavioral research; Human computer interaction; Integration; Intelligent systems; Learning systems; Analytics; CyberSA; Environmental information; Information gathering; Risk score; Semi structured interviews; Situation awareness; UEBA; Decision making},
	correspondence_address = {M. Cunningham; Forcepoint, Austin, United States; email: Margaret.Cunningham@Forcepoint.com},
	editor = {Ahram T. and Karwowski W.},
	publisher = {Springer Verlag},
	issn = {21945357},
	isbn = {978-303011050-5},
	language = {English},
	abbrev_source_title = {Adv. Intell. Sys. Comput.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; Conference name: 2nd International Conference on Intelligent Human Systems Integration, IHSI 2019; Conference date: 7 February 2019 through 10 February 2019; Conference code: 222829}
}

@ARTICLE{Eickhoff2019,
	author = {Eickhoff, Simon B. and Langner, Robert},
	title = {Neuroimaging-based prediction of mental traits: Road to Utopia or Orwell?},
	year = {2019},
	journal = {PLoS Biology},
	volume = {17},
	number = {11},
	doi = {10.1371/journal.pbio.3000497},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85075814935&doi=10.1371%2fjournal.pbio.3000497&partnerID=40&md5=65a659e3025e12917f262c784102fe8f},
	affiliations = {Institute of Systems Neuroscience, Medical Faculty, Heinrich Heine University Düsseldorf, Düsseldorf, Germany; Institute of Neuroscience and Medicine, Brain and Behaviour (INM-7), Research Centre Jülich, Jülich, Germany},
	abstract = {Predicting individual mental traits and behavioral dispositions from brain imaging data through machine-learning approaches is becoming a rapidly evolving field in neuroscience. Beyond scientific and clinical applications, such approaches also hold the potential to gain substantial influence in fields such as human resource management, education, or criminal law. Although several challenges render real-life applications of such tools difficult, future conflicts of individual, economic, and public interests are preprogrammed, given the prospect of improved personalized predictions across many domains. In this Perspective paper, we thus argue for the need to engage in a discussion on the ethical, legal, and societal implications of the emergent possibilities for brain-based predictions and outline some of the aspects for this discourse. © 2019 Eickhoff, Langner. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Brain; Forecasting; Humans; Machine Learning; Neuroimaging; Neurosciences; Personality; brain; criminal law; education; human; human experiment; machine learning; neuroimaging; neuroscience; prediction; resource management; review; classification; ethics; forecasting; legislation and jurisprudence; neuroimaging; personality; physiology; procedures},
	correspondence_address = {S.B. Eickhoff; Institute of Systems Neuroscience, Medical Faculty, Heinrich Heine University Düsseldorf, Düsseldorf, Germany; email: s.eickhoff@fz-juelich.de},
	publisher = {Public Library of Science},
	issn = {15449173},
	coden = {PBLIB},
	pmid = {31725713},
	language = {English},
	abbrev_source_title = {PloS Biol.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{2019,
	title = {CEUR Workshop Proceedings},
	year = {2019},
	journal = {CEUR Workshop Proceedings},
	volume = {2484},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85076032664&partnerID=40&md5=d40bc07f3c667791ec2ba686f4ad5d63},
	abstract = {The proceedings contain 7 papers. The topics discussed include: principles for the trustworthy adoption of AI in legal systems: the IEEE global initiative on ethics of autonomous and intelligent systems; revolutionizing the practice of law through data science:  use case and applications; an approach to human-machine teaming in legal investigations using  anchored narrative visualization and machine learning; utilizing AI in the legal assistance sector testing a role for legal information institutes; distilling jurisprudence through argument mining for case assessment; and evaluation of seed set selection approaches and active learning strategies in predictive coding.},
	editor = {Conrad J.G. and Pickens J. and Jones A. and Baron J.R. and Henseler H.},
	publisher = {CEUR-WS},
	issn = {16130073},
	language = {English},
	abbrev_source_title = {CEUR Workshop Proc.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 1st Workshop on AI and Intelligent Assistance for Legal Professionals in the Digital Workplace, LegalAIIA 2019; Conference date: 17 June 2019; Conference code: 155247}
}

@ARTICLE{Sans2019318,
	author = {Sans, Alger and Casacuberta, David},
	title = {Remarks on the possibility of ethical reasoning in an artificial intelligence system by means of abductive models},
	year = {2019},
	journal = {Studies in Applied Philosophy, Epistemology and Rational Ethics},
	volume = {49},
	pages = {318 – 333},
	doi = {10.1007/978-3-030-32722-4_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074702682&doi=10.1007%2f978-3-030-32722-4_19&partnerID=40&md5=5a530bee3763fe059fe12b679871c451},
	affiliations = {Philosophy Department, Universitat Autònoma de Barcelona, Barcelona, Spain},
	abstract = {Machine learning and other types of AI algorithms are now commonly used to make decisions about important personal situations. Institutions use such algorithms to help them figure out whether a person should get a job, receive a loan or even be granted parole, sometimes leaving the decision completely to an automatic process. Unfortunately, these algorithms can easily become biased and make unjust decisions. To avoid such problems, researchers are working to include an ethical framework in automatic decision systems. A well-known example is MIT’s Moral Machine, which is used to extract the basic ethical intuitions underlying extensive interviews with humans in order to apply them to the design of ethical autonomous vehicles. In this chapter, we want to show the limitations of current statistical methods based on preferences, and defend the use of abductive reasoning as a systematic tool for assigning values to possibilities and generating sets of ethical regulations for autonomous systems. © 2019, Springer Nature Switzerland AG.},
	author_keywords = {Abduction; Ethics of AI; Machine learning; Values},
	correspondence_address = {A. Sans; Philosophy Department, Universitat Autònoma de Barcelona, Barcelona, Spain; email: alger.sans@uab.cat},
	publisher = {Springer International Publishing},
	issn = {21926255},
	language = {English},
	abbrev_source_title = {Stud. Appl. Philos. Epistemol. Ration. Ethics},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Badrick20191350,
	author = {Badrick, Tony and Banfi, Giuseppe and Bietenbeck, Andreas and Cervinski, Mark A. and Loh, Tze Ping and Sikaris, Ken},
	title = {Machine learning for clinical chemists},
	year = {2019},
	journal = {Clinical Chemistry},
	volume = {65},
	number = {11},
	pages = {1350 – 1356},
	doi = {10.1373/clinchem.2019.307512},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85074305834&doi=10.1373%2fclinchem.2019.307512&partnerID=40&md5=599a6be263a2ab270e7e4a769f16cb39},
	affiliations = {RCPA Quality Assurance Programs, St. Leonards, Sydney, Australia; Scientific Director, IRCCS Orthopedic Institute Galeazzi, Milan, Italy; Università Vita e Salute San Raffaele, Milan, Italy; Institut für Klinische Chemie und Pathobiochemie, Klinikum rechts der Isar der Technischen Universität München, München, Germany; Director of Clinical Chemistry, Department of Pathology and Laboratory Medicine, Dartmouth-Hitchcock Medical Center, Lebanon, NH, United States; Associate Professor of Pathology and Laboratory Medicine, Geisel School of Medicine at Dartmouth, Hanover, NH, United States; National University Hospital, Singapore; Director Clinical Support Systems, Sonic Healthcare IT, Melbourne, VIC, Australia},
	keywords = {Chemistry, Clinical; Clinical Laboratory Services; Humans; Machine Learning; algorithm; artificial intelligence; artificial neural network; autoimmune disease; biological variation; biomedical technology assessment; blood cell; clinical chemistry; clinical effectiveness; clinical laboratory; clinical study; data mining; decision tree; deep learning; diagnostic error; diagnostic imaging; drug development; electrocardiogram; electronic medical record; epidemiological data; genomics; health care facility; histopathology; human; immunofluorescence; information technology; learning algorithm; machine learning; medical decision making; medical information; medical technologist; Note; pharmacogenomics; predictive value; primary medical care; prognosis; proteomics; quality control; random forest; risk assessment; support vector machine; time; treatment outcome; urine sediment; vitamin D deficiency; clinical chemistry; clinical laboratory service; ethics; interview; procedures},
	correspondence_address = {T. Badrick; Sydney, Suite 201, 8 Herbert Street, St Leonards, 2065, Australia; email: tony.badrick@rcpaqap.com.au},
	publisher = {American Association for Clinical Chemistry Inc.},
	issn = {00099147},
	coden = {CLCHA},
	pmid = {31551313},
	language = {English},
	abbrev_source_title = {Clin. Chem.},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Bronze Open Access}
}

@ARTICLE{London201915,
	author = {London, Alex John},
	title = {Artificial Intelligence and Black-Box Medical Decisions: Accuracy versus Explainability},
	year = {2019},
	journal = {Hastings Center Report},
	volume = {49},
	number = {1},
	pages = {15 – 21},
	doi = {10.1002/hast.973},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85061976337&doi=10.1002%2fhast.973&partnerID=40&md5=2c62f791fad75cc412457148d22c8960},
	abstract = {Although decision-making algorithms are not new to medicine, the availability of vast stores of medical data, gains in computing power, and breakthroughs in machine learning are accelerating the pace of their development, expanding the range of questions they can address, and increasing their predictive power. In many cases, however, the most powerful machine learning techniques purchase diagnostic or predictive accuracy at the expense of our ability to access “the knowledge within the machine.” Without an explanation in terms of reasons or a rationale for particular decisions in individual cases, some commentators regard ceding medical decision-making to black box systems as contravening the profound moral responsibilities of clinicians. I argue, however, that opaque decisions are more common in medicine than critics realize. Moreover, as Aristotle noted over two millennia ago, when our knowledge of causal systems is incomplete and precarious—as it often is in medicine—the ability to explain how results are produced can be less important than the ability to produce such results and empirically verify their accuracy. © 2019 The Hastings Center},
	keywords = {Algorithms; Artificial Intelligence; Clinical Decision-Making; Deep Learning; Humans; Knowledge; Reproducibility of Results; Social Responsibility; Uncertainty; article; artificial intelligence; clinician; diagnostic test accuracy study; human; machine learning; medical decision making; morality; responsibility; algorithm; artificial intelligence; clinical decision making; ethics; knowledge; reproducibility; social responsibility; uncertainty},
	publisher = {John Wiley and Sons Inc.},
	issn = {00930334},
	pmid = {30790315},
	language = {English},
	abbrev_source_title = {Hast. Cent. Rep.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 254}
}

@CONFERENCE{Vähäkainu2019431,
	author = {Vähäkainu, Petri and Lehto, Martti},
	title = {Artificial intelligence in the cyber security environment},
	year = {2019},
	journal = {14th International Conference on Cyber Warfare and Security, ICCWS 2019},
	pages = {431 – 440},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85066011006&partnerID=40&md5=cd17fec7584cf8d0b9a1935eb67d41cd},
	affiliations = {University of Jyväskylä, Finland},
	abstract = {Artificial Intelligence (AI) is intelligence exhibited by machines. Any system that perceives its environment and takes actions that maximize its chance of success at some goal may be defined as AI. The family of AI research is rich and varied. For example, cognitive computing is a comprehensive set of capabilities based on technologies such as deep learning, machine learning, natural language processing, reasoning and decision technologies, speech and vision technologies, human interface technologies, semantic technology, dialog and narrative generation, among other technologies. Artificial intelligence and robotics have steadily growing roles in our lives and have the potential to transform vital functions of the society. Organizations benefit from the ability of cognitive systems to improve their expertise quickly and from sharing it to all those who need it. The know-how of top experts is quickly made available to all, when their subject matter expertise is taught to a cognitive system. Through repeated use, the system will provide increasingly accurate responses, eventually eclipsing the accuracy of human experts. With artificial intelligence, comprehension can be outsourced. As the intelligence of machines improve, they will use deep learning to understand the collective information of humankind. With the use of digital sensor data, equipment based on artificial intelligence can used to develop smart advisors, teachers or assistants. As artificial intelligence technology is helping society to advance, there are risks associated with its use, found in the operating systems, hardware, algorithms, system management, ethics and liability, and privacy. The study focuses on artificial intelligence threats and risks and how AI may help to solve cyber security problems. This study uses taxonomy classification principle to classify 12 the most crucial areas of cyber security. Research method of this study was to gather 11 AI solutions that were divided into seven different categories of the crucial areas of cyber security represented in introduction chapter. AI solutions gathered uses artificial intelligence in detecting and predicting information security threats and anomalies and blocking them. The purpose of this study is to classify AI-based cyber security solutions gathered, and provide information what they can offer in solving problems in the field of cyber security. © 2019 14th International Conference on Cyber Warfare and Security, ICCWS 2019. All rights reserved.},
	author_keywords = {Anomaly; Artificial intelligence; Cognitive abilities; Cyber security; Supervised machine learning; Unsupervised machine learning},
	keywords = {Artificial intelligence; Classification (of information); Cognitive systems; Computer crime; Deep learning; Learning algorithms; Machine learning; Natural language processing systems; Security of data; Semantics; Supervised learning; Technology transfer; Anomaly; Cognitive ability; Cyber security; Supervised machine learning; Unsupervised machine learning; Engineering education},
	editor = {Leenen L. and van der Waag-Cowling N. and van der Waag-Cowling N.},
	publisher = {Academic Conferences and Publishing International Limited},
	isbn = {978-151088292-8},
	language = {English},
	abbrev_source_title = {Int. Conf. Cyber Warf. Secur., ICCWS},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; Conference name: 14th International Conference on Cyber Warfare and Security, ICCWS 2019; Conference date: 28 February 2019 through 1 March 2019; Conference code: 147886}
}

@ARTICLE{Weber201915,
	author = {Weber, Cynthia},
	title = {Engineering Bias in AI},
	year = {2019},
	journal = {IEEE Pulse},
	volume = {10},
	number = {1},
	pages = {15 – 17},
	doi = {10.1109/MPULS.2018.2885857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85062922289&doi=10.1109%2fMPULS.2018.2885857&partnerID=40&md5=ed02fa1492c73dd57f54605b1432645f},
	abstract = {After working at Apple designing circuits and signal processing algorithms for products including the first iPad, Timnit Gebru (Figure 1) received her Ph.D. from the Stanford Artificial Intelligence Laboratory in the area of computer vision. She recently completed a postdoc with Microsoft Research in the FATE (Fairness, Transparency, Accountability, and Ethics in Artificial Intelligence (AI)) group, was a cofounder of Black in AI, and is currently working as a research scientist in the Ethical AI team at Google. Her research in algorithmic bias and the ethical implications of data mining have appeared in multiple publications, including The New York Times and The Economist. IEEE Pulse recently spoke with Gebru about the role societal bias plays in engineering AI, the deficits and dangers in the field caused by limited diversity, and the challenges inherent in addressing these complex issues. © 2019 IEEE.},
	keywords = {Algorithms; Artificial Intelligence; Bias; Data Mining; Databases, Factual; Ethics, Research; Humans; Artificial intelligence; Philosophical aspects; Product design; Signal processing; Ethical implications; Microsoft researches; New york time; Signal processing algorithms; Stanford; accuracy; algorithm; artificial intelligence; biodiversity; civil disorder; community care; computer analysis; cultural diversity; decision making; education; engineering; ethics; genetic variability; human; learning; machine learning; population; professional standard; pulse wave; Review; self concept; social acceptance; technology; data mining; ethics; factual database; research ethics; statistical bias; Data mining},
	correspondence_address = {C. Weber; email: clweberb@mtu.edu},
	publisher = {Institute of Electrical and Electronics Engineers Inc.},
	issn = {21542287},
	pmid = {30872208},
	language = {English},
	abbrev_source_title = {IEEE Pulse},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Fournier2019164,
	author = {Fournier, Helene and Molyneaux, Heather and Kop, Rita},
	title = {Emerging technologies and learning innovation in the new learning ecosystem},
	year = {2019},
	journal = {Smart Innovation, Systems and Technologies},
	volume = {111},
	pages = {164 – 170},
	doi = {10.1007/978-3-030-03577-8_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85056455321&doi=10.1007%2f978-3-030-03577-8_19&partnerID=40&md5=b5c53184a71ee4b1adb1a4f52e02b7ae},
	affiliations = {National Research Council Canada, 100 des Aboiteaux Street, Suite 1100, Moncton, E1A 7R1, NB, Canada; National Research Council Canada, 46 Dineen Drive, Fredericton, E3B 9W4, NB, Canada; Yorkville University, Yorkville Landing, Suite 102, 100 Woodside Lane, Fredericton, E3C 2R9, NB, Canada},
	abstract = {This paper highlights a decade of research by the National Research Council in the area of Personal Learning Environments, including MOOCs and learning in networked environments. The value of data analytics, algorithms, and machine learning is explored in more depth, as well as challenges in using personal learning data to automate the learning process, the use of personal learning data in educational data mining (EDM), and important ethics and privacy issues around networked learning environments. © Springer Nature Switzerland AG 2019.},
	author_keywords = {Algorithms; Data analytics; Ethics and privacy; Machine learning; Personal Learning Environments},
	keywords = {Algorithms; Artificial intelligence; Computer aided instruction; Data mining; Data privacy; Information systems; Information use; Learning systems; Philosophical aspects; Data analytics; Educational data minings (EDM); Emerging technologies; Learning ecosystems; National Research Council; Networked environments; Networked learning; Personal learning environment; Learning algorithms},
	correspondence_address = {H. Fournier; National Research Council Canada, Moncton, 100 des Aboiteaux Street, Suite 1100, E1A 7R1, Canada; email: Helene.Fournier@nrc-cnrc.gc.ca},
	editor = {Rocha A. and Serrhini M.},
	publisher = {Springer Science and Business Media Deutschland GmbH},
	issn = {21903018},
	isbn = {978-303003576-1},
	language = {English},
	abbrev_source_title = {Smart Innov. Syst. Technol.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; Conference name: 2nd International conference on Europe Middle East and North Africa Information Systems and Technologies to support Learning, EMENA-ISTL 2018; Conference date: 25 October 2018 through 27 October 2018; Conference code: 220149}
}