{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "7cb09190",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pdfplumber\n",
    "import os\n",
    "import pdfplumber\n",
    "import re\n",
    "from re import search\n",
    "from sklearn.cluster import KMeans\n",
    "import sklearn.metrics\n",
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "b0c95078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = r'H:\\\\Dropbox\\\\Personale\\\\Ricerca\\\\XAI\\\\00. A.Gatti\\\\Quantitative AI\\\\GreenAI\\\\Articolo\\\\Bibliografia\\TUTTI'\n",
    "path = r'c:\\temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "3ab33807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\temp\n",
      "c:\\temp\\07.Sustainability challenges of Artificial Intelligence and Policy Implications.pdf\n",
      "c:\\temp\\08.SustainableAIEnvironmentalImplicationsChallengesandOpportunities.pdf\n",
      "c:\\temp\\09. GreenAlgorithmsQuantifyingthecarbonfootprintofcomputation.pdf\n",
      "c:\\temp\\A Systematic Review of Green AI.pdf\n",
      "c:\\temp\\Diversification in the age of the 4th industrial revolution_ The role of artificial intelligence_ green bonds and cryptocurrencies.pdf\n",
      "c:\\temp\\Emerging technologies based on artificial intelligence to assess the quality and consumer preference of beverages.pdf\n",
      "c:\\temp\\Towards green automated machine learning_ Status quo and future directions.pdf\n",
      "c:\\temp\\__a smart framework for supplying the biogas energy in green buildings using an integration of response surface methodology_ artificial intelligence and petri net__.pdf\n"
     ]
    }
   ],
   "source": [
    "articles = []\n",
    "titles=[]\n",
    "print(path)\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        titles.append(filename)\n",
    "        fullpath = os.path.join(path, filename)\n",
    "        print(fullpath)\n",
    "        all_text = \"\"\n",
    "        with pdfplumber.open(fullpath) as pdf:\n",
    "            for page in pdf.pages:\n",
    "                text = page.extract_text().lower()\n",
    "                #print(text)\n",
    "                all_text += '\\n' + text\n",
    "        articles.append(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d1ebef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.DataFrame(list(zip(titles,articles)),columns=['Article','Text'])\n",
    "corpus.to_csv(\"corpus.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85a07711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggiungere il titolo al testo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "e0abfc89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Article</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>07.Sustainability challenges of Artificial Int...</td>\n",
       "      <td>\\nsustainability of digitalisation\\ndiscussing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>08.SustainableAIEnvironmentalImplicationsChall...</td>\n",
       "      <td>\\n1\\nsustainable ai: environmental implication...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>09. GreenAlgorithmsQuantifyingthecarbonfootpri...</td>\n",
       "      <td>\\ngreen algorithms: quantifying the carbon\\nfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Systematic Review of Green AI.pdf</td>\n",
       "      <td>\\na systematic review of green ai\\nrobertoverd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diversification in the age of the 4th industri...</td>\n",
       "      <td>\\ncitation:\\nhuynh, tld and hille, e and nasir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Emerging technologies based on artificial inte...</td>\n",
       "      <td>\\nbeverages\\nreview\\nemerging technologies bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Towards green automated machine learning_ Stat...</td>\n",
       "      <td>\\njournalofartificialintelligenceresearch77(20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>__a smart framework for supplying the biogas e...</td>\n",
       "      <td>\\n1 constructing a novel smart framework for s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Article  \\\n",
       "0  07.Sustainability challenges of Artificial Int...   \n",
       "1  08.SustainableAIEnvironmentalImplicationsChall...   \n",
       "2  09. GreenAlgorithmsQuantifyingthecarbonfootpri...   \n",
       "3                A Systematic Review of Green AI.pdf   \n",
       "4  Diversification in the age of the 4th industri...   \n",
       "5  Emerging technologies based on artificial inte...   \n",
       "6  Towards green automated machine learning_ Stat...   \n",
       "7  __a smart framework for supplying the biogas e...   \n",
       "\n",
       "                                                Text  \n",
       "0  \\nsustainability of digitalisation\\ndiscussing...  \n",
       "1  \\n1\\nsustainable ai: environmental implication...  \n",
       "2  \\ngreen algorithms: quantifying the carbon\\nfo...  \n",
       "3  \\na systematic review of green ai\\nrobertoverd...  \n",
       "4  \\ncitation:\\nhuynh, tld and hille, e and nasir...  \n",
       "5  \\nbeverages\\nreview\\nemerging technologies bas...  \n",
       "6  \\njournalofartificialintelligenceresearch77(20...  \n",
       "7  \\n1 constructing a novel smart framework for s...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a64f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#regex = re.compile('[^a-zA-Z]')\n",
    "regex = re.compile('a-zA-Z0-9_]')\n",
    "\n",
    "for index in range(len(articles)):\n",
    "    if search('abstract', articles[index]):\n",
    "        articles[index] = articles[index].split('abstract')[1]\n",
    "\n",
    "    #First parameter is the replacement, second parameter is your input string\n",
    "    articles[index] = regex.sub('', articles[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0890a15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_df=0.8,         # drop words that occur in more than X percent of documents\n",
    "                             #min_df=8,      # only use words that appear at least X times\n",
    "                             use_idf=True,   # Use idf\n",
    "                             norm=u'l2',     # Normalization\n",
    "                             smooth_idf=True # Prevents divide-by-zero errors\n",
    "                       )\n",
    "\n",
    "X = vectorizer.fit_transform(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3d28c0cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 Silhouette Score: 0.0192\n",
      "3 Silhouette Score: 0.02285\n",
      "4 Silhouette Score: 0.02412\n",
      "5 Silhouette Score: 0.02656\n",
      "6 Silhouette Score: 0.02778\n",
      "7 Silhouette Score: 0.0261\n",
      "8 Silhouette Score: 0.02013\n",
      "9 Silhouette Score: 0.01874\n",
      "10 Silhouette Score: 0.01606\n",
      "11 Silhouette Score: 0.01238\n",
      "12 Silhouette Score: 0.01312\n",
      "13 Silhouette Score: 0.01309\n",
      "14 Silhouette Score: 0.01288\n",
      "15 Silhouette Score: 0.01357\n",
      "16 Silhouette Score: 0.00911\n",
      "17 Silhouette Score: 0.01289\n",
      "18 Silhouette Score: 0.01323\n",
      "19 Silhouette Score: 0.01366\n",
      "Clusters: 6\n"
     ]
    }
   ],
   "source": [
    "K = range(2,20)\n",
    "max = -1\n",
    "clusters = 2\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k, init='k-means++', \n",
    "            max_iter=1000, n_init=1, verbose=0, random_state=3425)\n",
    "    kmeanModel.fit(X)\n",
    "    score = round(sklearn.metrics.silhouette_score(X, kmeanModel.labels_, metric='euclidean', random_state=42),5)\n",
    "    print(k, 'Silhouette Score:', score)\n",
    "    if max < score:\n",
    "        max = score\n",
    "        clusters = k\n",
    "\n",
    "print(\"Clusters:\", clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "2c732e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 2, 4, 5, 1, 4, 5, 1, 4, 4, 5, 1, 5, 4, 4, 1, 0, 4, 4, 4, 1,\n",
       "       0, 4, 4, 3, 4, 4, 3, 1, 4, 4, 4, 0, 1, 1, 1, 1, 1, 4, 1, 4, 4, 4,\n",
       "       4, 1, 1, 4, 4, 5, 4, 4, 4, 4, 4, 3, 4, 1, 0, 1, 1, 5, 4, 1, 0, 0,\n",
       "       4, 5, 5, 1, 4, 1, 4, 0, 5, 1, 4, 4, 5, 2, 4, 0, 0, 1, 1, 2, 4, 4,\n",
       "       5, 5, 1, 0, 4, 4, 4, 0, 4, 1, 1, 4, 1, 4, 0, 5, 0, 4, 4, 3, 5, 3,\n",
       "       0, 4, 4, 4, 3, 5, 1, 5])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = clusters\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=1000, n_init=10)\n",
    "model.fit(X)\n",
    "labels=model.labels_\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "dcfef80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(titles,labels)),columns=['Article','Cluster'])\n",
    "df_s= df.sort_values(by=['Cluster'])\n",
    "df_s.to_csv(\"clusters.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fe4c61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
