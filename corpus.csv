,Article,Text
0,07.Sustainability challenges of Artificial Intelligence and Policy Implications.pdf,"
sustainability of digitalisation
discussing implications of artificial intelligence
sustainability challenges of artificial
intelligence and policy implications
automated decision-making based on artificial complex neural networks to quite simple software applications
intelligence is associated with growing expecta- that calculate, weigh up and sort data based on simple rules (cf.
algorithmwatch 2018). in this arcticle, we focus on weak ai,
tions and is to contribute to sustainable develop-
for example decision-making with more or less complex data-
ment goals. which opportunities and risks
learning algorithms.
for the environment, economy and society are yet even weak ai-based systems and applications (in the fol-
associated with artificial intelligence-based lowing we will only use the term ai) allows computers to partly
take over human decision-making and to fully automate sys-
applications and how can they be governed?
tems’ management as, for example, when supporting architects
by friederike rohde, maike gossen,
in constructing new buildings, doctors in making medical deci-
josephin wagner and tilman santarius
sions, recruiters in selecting new employees or assigning uber-
drivers to trips. however, ai uses data and algorithmic reason-
ing to make recommendations that are not transparent – and
a d vances in artificial intelligence (ai) effectiveness have that in many cases not even ai-researchers fully understand.
made its application ubiquitous in many economic sec- therefore, the current rise of ai raises questions of what form
tors. whether speech or facial recognition, computer games or of comprehensive political rules are needed to ensure the hu-
social bots, medical diagnostics or predictive maintenance, or man-centred and ecological use of those technologies. this ar-
autonomous driving, many actors expect opportunities not only ticle helps to shed light on the social, ecological, and economic
for product innovations and new markets but also for new re- implications of ai and on what guidelines, rules and regula-
search perspectives. economic and political actors alike expect tions need to be discussed and implemented to address sus-
ai-based systems and applications to contribute positively to tainability concerns.
sustainability goals (jetzke et al. 2019). these include, for ex- there are two interlinked perspectives of how to relate ai to
ample, the opportunities offered by ai for improving the man- sustainability. the first one refers to employing ai in areas that
agement of smart grids (jungblut this issue), and transport in- contribute to socially and ecological desirable developments,
frastructures, for conducting more precise earth observation, such as climate protection or education (ai for sustainable de-
for creating new weather warning and forecasting systems, or velopment; see jungblut, this issue). we investigate the second
for enhancing solutions for waste and resource management. perspective, which refers to developing, implementing, and us-
ing ai in a way that minimizes negative social, ecological and
economic impacts of the applied algorithms (sustainable ai).
do we really talk about artificial intelligence?
ai is generally used to describe machines (usually com-
rules for responsible artificial intelligence
puters) that mimic cognitive functions, for example by repro-
ducing human decision-making structures through functions over the last decade, several issues concerning the societal
with trainable parameters. ai research typically addresses prob- implications of ai and the respective algorithms have been
lems of reasoning, knowledge representation, planning, learn- discussed intensively, mainly under the concept of ethical ai
ing, natural language processing, and perception. while the guidelines (see jobin et al. 2019 for an overview). aspects such
comprehensive reproduction of human intelligence, usually re- as transparency, trustworthiness, autonomy, and data protec-
ferred to as “strong ai” (e. g., cogprime, cf. goertzel et al. 2014), tion are discussed – while the consideration of ecological and
is still far from real-world application, “weak ai”, such as deep equitable aspects of ai is, by and large, still lacking. the ai eth-
learning, is now increasingly found in numerous applications. ics global inventory (algorithmwatch 2020) identifies more
these forms of “weak ai” are also described as computational than 160 rules or guidelines published by diverse actors includ-
intelligence (poole et al. 1998) or intelligent agents (russell/ ing not only ngos, business associations and trade unions
norvig 2003) as they allow decision preparation, and even im- but also various governments and intergovernmental organi-
plementation, to be delegated to computers. those algorithmic zations such as the united nations and the european union
decision-making processes can include anything from highly (eu). the rules for using ai can range from recommendations
ökologischeswirtschaften online-ausgabe o1.2021 (36) | doi 10.14512/oewo360136 nd/4.0/deed.de), which permits copying and redistributing the material in any medium
36 ökologischeswirtschaften online-ausgabe o1.2021 (36) or format, provided the original work is properly cited, it is dnoot iu s1e0d.1 f4o5r1 c2o/momewerocia3l6 0136
© 2021 f. rohde, m. gossen, j. wagner, t. santarius; licensee iöw and oekom verlag. purposes and it is not remixed, transformed or built upon. the access to the digital ver-
this is an article distri buted under the terms of the creative commons attribution sion of this article is reserved to subscribers of ökologischeswirtschaften until two years
non-commercial no derivates license (http://creativecommons.org/licenses/by-nc- after the date of publication; after two years it is available to all readers.
sustainability of digitalisation
over voluntary commitments to binding regulations, some of
sustainability challenges for artificial
which are currently developed at the eu-level.
intelligence
for example, the ngo irights lab developed the algo.rules,
a catalogue of nine rules that should be adhered to in order to two questions are particularly relevant with regard to sus-
enable and facilitate a socially beneficial design and appropri- tainable development and ai. first, are the data sets generally
ate use of algorithmic systems. these rules include aspects used to train ai algorithms at all useful for transforming exist-
such as strengthening competencies of those who develop, op- ing production and consumption patterns towards sustainabil-
erate and/or make decisions regarding the use of algorithmic ity? the challenge here is that existing data sets provide diverse
systems or define responsibilities in a transparent and reason- information about the past but hardly any information about
able way and not transfer the responsibility to the algorithmic desired futures. therefore, ai trained on historical data sets
system itself, users or people affected by it. other rules define may be biased to reproduce the unsustainable status quo. to
that objectives and expected impact of the use of an algorithmic give an example: ai algorithms can optimize traffic flow man-
system must be documented and assessed prior to implemen- agement in cities or in logistics and thereby contribute to re-
tation, the application must have been tested, and the use of an ducing fuel consumption per kilometre driven. but (how) can
algorithmic system must be identified as such (bertelsmann existing data sets train ai to help sustainably transform the
stiftung/i.rights lab 2020). the compliance with these rules transport system as a whole, e. g., to make it less car-depend-
should be ensured by design when systems are being developed. ent? every weak ai or algorithmic system is only as good as the
the eu has published a white paper providing a general utility function it seeks to optimize and the data that it is based
regulatory regime for developing and implementing ai. the upon. that is, sustainability goals, such as reducing car traffic
white paper is based on recommendations from the high level not only have to be implemented into the utility function of the
expert group on ai, which published its ethical guidelines for respective algorithms but in the political regulations and con-
a trustworthy ai in april 2019 (ai hleg 2019). the white pa- ditions, as well.
per focuses on creating “ecosystems for excellence”, as well as second, how can ai-supported sustainability transforma-
on trust and a safe and trustworthy use of ai. an “ecosystem for tions of production and consumption patterns be democrati-
excellence” mainly refers to the cooperative action of eu mem- cally legitimized? to stay with the transport example: should
ber states to maintain europe’s leading position in research, ai-based recommendations be trimmed to inscribe preferences
promote innovation, expand the use of ai, and achieve the ob- for ecological means of transport (bicycle, bus and train) over
jectives of the european green deal. the “ecosystem for trust” less ecological means of transport (car, taxi, plane)? little doubt,
is based on existing law, in particular on the provisions of the other criteria such as travel time or safety are decisive for us-
general data protection regulation (gdpr) and the directive ers when choosing a mode of transport. a situation may arise
on data protection in law enforcement. in which users cannot clearly understand which criteria (i. e.,
the white paper’s intended eu regulatory regime would ap- which specific set of preferences) are used in an ai-based rec-
ply extended regulation only to ai that contains a particular risk ommendation system to make or propose decisions. to avoid
potential regarding protection of safety and consumer and fun- sustainability transformations becoming visible only through
damental rights (european commission 2020). the white pa- the output of the systems, the algorithms must be as transpar-
per proposes defining high risk cumulatively: ai used in “high ent as possible, as should information on the algorithm train-
risk” sectors such as health, transport, police or jurisdiction ing data. this inclusion could prevent the data analysis from
and ai application that poses significant risks, i. e., the pur- reproducing the discriminatory and unsustainable patterns ex-
pose of the respective ai. regarding for example the health isting in society (wolfangel 2018).
sector there is a difference between using ai for appointment
scheduling in hospitals or using ai for medical diagnosis. the
resource and energy intensities of
commission states that ai for the purpose of “remote biomet-
artificial intelligence
ric identification and other intrusive surveillance technologies
would always be considered high-risk” (european commission the discussion about ai opportunities and risks has only
2020: 18). in germany, the data ethics commission advocates recently begun to take into account how much energy and re-
a five-level risk-based regulatory regime, ranging from no reg- sources ai itself consumes for computing. the training pe-
ulation for the lowest risk ai to a complete ban for the high- riod of an artificial neural network (ann), devour particularly
est risk ai, such as autonomous weapon systems. finally, the large amounts of energy. a study using bert, an ann used
eu announced in the white paper it would foster the develop- for speech recognition, found that the training period alone re-
ment of ai for climate change mitigation and for the protec- sulted in 0.65 tons of co being emitted (strubell et al. 2019).
22
tion of natural resources. considering ai as an enabler, the this amount corresponds to the emissions generated from a
eu aims to combine the european green deal with the devel- return flight between berlin and madrid. however, the study’s
opment of “trustworthy ai made in europe” (european com- frequently cited result that “training a single ai model can emit
mission 2020). as much carbon as five cars in their lifetimes” (hao 2019) is in-
ökologischeswirtschaften online-ausgabe o1.2021 (36) 37
sustainability of digitalisation
""artificial intelligence"":
rof
training deep-learning models increases energy noitaicossa .)9102( )0202.20.72
.t vsc.supg/atad/retsam/bolb/tcapmi/2oclm/moc.buhtig//:sptth
,serdnad
and resource consumption eht no
fo & deveirter(
gniteem ,.v
the multi-layered machine-learning processes of ai-based systems are becoming increasingly ,tdimhcs
complex and need large amounts of compute and energy1). the different applications generally use launna 1fernf#/etupmoc-dna-ia/golb/moc.ianepo//:sptth
,.a
pre-trained, customized models. .pln ,inoiccul
ni
gninrael ,.a
,etsocal
peed
amount of compute & energy consumption of different models ees(cid:31))001valset
rof
snoitaredisnoc
image classification speech recognition moves in a game
&
(e.g. vgg) (e.g. deepspeech2) (e.g. alphazero) upg( 00790.0191:vixra
0,12 pfs-d* 0,25 pfs-d* 400 pfs-d* erawdrah
ycilop :enilno
about 56 kwh2) about 117 kwh2) about 186.667 kwh2)
dna rof ,ia
ygrene esabatad tnirperp nepo
9102
.)9102( yluj & vixra :ni .etupmoc
werdna .ylati dohtem .gninrael
,ecnerolf dna
,mullaccm ,)nilreb enihcam ia
.)8102(
.)trohs ut(
;aynana lca( robal fo snoissime ynnad
iad
scitsiugnil ,xednanreh
*amount of compute needed to train a single model. ,hsenag & wöi nobrac
(peta-flop/s-day corresponds to 1015 floating point ;amme lanoitatupmoc snoitaluclac eht ;oirad
operations per second in one day)3) gniyfitnauq
,lleburts ,iedoma
:secruos nwo
© institute for ecological economy research (iöw), cc-by-nc-sa, www.nachhaltige-digitalisierung.de/en )1 )2 )3
figure 1: “artificial intelligence”: training deep-learning models increases energy and resource consumption
correct (cf. lobe 2019). this often-cited amount of 313 tons of moreover, the development of applications for automated de-
co refers to neural architecture search, very different from cision-making, data processing, tracking, or recommendation
22
training a “typical” ann. notwithstanding, the training of in- systems should take into account alternative methods and tools
creasingly complex deep learning models can be expected to to calculate, predict and classify data. for example, the accuracy
require more compute and hence even more electricity (see of an ann for learning a new task involves an energy-intensive
figure 1). trial-and-error process (strubell et al. 2019) that sometimes only
ensuring that ai – particularly those used for sustainabil- leads to a comparatively small increase in network performance.
ity purposes – generate net benefits by reducing energy and in certain applications that currently use ai, statistical analysis
emissions requires assessing whether the energy consumed in methods, such as linear regressions, with a significantly lower
the training and use phases justifies the intended effects. un- energy consumption can lead to similar results. in addition to
til now, most ai has not been used solely to improve sustain- high power consumption, the ai’s material requirements pose
ability but applied in other fields ranging from optimizing on- further ecological challenges due to the hardware used in data
line advertising to industrial production or medical technology. centres and end-user devices whose production is extremely re-
that is, the impact which derives from this energy intensive source-intensive (see pohl et al. in this issue).
training process is highly dependent on the application. how
much additional energy consumption of future, yet-to-be-de-
ecological sustainability of artificial
veloped, ai can societies justify when, at the same time, they
intelligence
have committed to the unfccc paris declaration and want
to achieve the 1.5 °c climate change goal? it appears evident concerning general sustainability criteria for software, nau-
that ai development must be related more strongly to socially mann et al. (2011) developed a comprehensive catalogue of cri-
and ecologically relevant challenges (jetzke et al. 2019; see jun- teria that take into account an application’s entire software life
gblut in this issue). cycle – from the original coding, over its use, to deinstallation.
38 ökologischeswirtschaften online-ausgabe o1.2021 (36)
sustainability of digitalisation
moreover, the software criteria cover the kind of hardware a cer-
regulation of market power and monopolies
tain software requires. these considerations were further devel-
oped and extended to modern software architectures by also tak- the interests of actors driving the creation of new ai applica-
ing into account the electricity load on a remote server, the local tions and markets will considerably determine whether and to
client, or the network as a transport medium (gröger et al. 2018). what extent ai actually supports a transition towards sustainable
applying a whole-system approach allows for sharpening the production and consumption patterns. the majority of ai today
view for indirect effects, also referred to as higher order effects pursues the aim to personalise services, forecasting customers’
of ict (pohl et al. 2019) which relate to behavioural and struc- purchasing interests and optimizing online marketing and ad-
tural changes, that occur due to new business models or the vertisements (heumann/jentzsch 2019). these applications in-
transformation of everyday practices, such as online shopping. tend to increase both individual and societal levels of consump-
schwartz et al. (2019) propose criteria that are suitable for as- tion, which in many countries are already unsustainably high.
sessing the ecological effects of ai and include criteria such as the marketing of ai-based technologies generates high reve-
co emissions, power consumption, training duration, number nues. for example, in the market segment of multi-purpose as-
22
of parameters, and number of floating-point operations (flop). sistants such as siri or alexa, revenues of usd 11.9 billion are
however, these criteria raise the question of the type of measure- forecast for 2021 (hecker et al. 2017). large tech companies lead-
ment as different computers consume different amounts of en- ing these markets are currently using ai to enhance their mar-
ergy for the same operation. the current project “sustainability ket power and competitive advantages. the related dominance
index for artificial intelligence” [1], a cooperation between the of a few global tech corporations, first and foremost google, am-
advocacy organisation algorithmwatch, the institute for ecolog- azon, facebook, apple, microsoft and a few others, will most
ical economy research (iöw) and distributed artificial intelli- likely continue with the development and commercialization of
gence laboratory (dai) at tu berlin, aims to develop a compre- ai in the future (c. f. kingaby, this issue; staab/butollo 2018).
hensive set of sustainability criteria for ai-based systems and due to the high importance of big data for ai, tech corporations
establish particular guidelines for sustainable ai-development. are reluctant to make “their” data openly available to compet-
in addition to guidelines for developing and applying ai, itors, while using mergers and acquisitions to gain access to
politics can set appropriate regulatory frameworks. oftentimes, further data sources. because the control over large amounts
their focus is not specifically on ai only, but include wider tech- of data functions as a central barrier to ai market entry (wig-
nological developments that are ai-related, such as the gdpr, gerthale 2019), existing competitive challenges associated with
eprivacy directive, energy prices, or the pricing of carbon emis- large platform monopolies are likely to be aggravated in coming
sions. thus, co -taxes on electricity could make the develop- years. since all large tech corporations are shareholder-owned,
22
ment of less complex and energy-saving models more attrac- and hence have to service capital interests on financial markets,
tive – incentivizing software developers and their clients to bal- it is questionable whether increasing market concentration will
ance energy costs with performance benefits. one of the most help ai business models that place people and the planet over
relevant steps, not only for the development of ai but also for profits. today’s antitrust laws are not suited to counteracting
developing data-based applications in general, is the promotion this development. since monopolies are legal under competi-
of green cloud computing and green data centres, as argued by tion law, antitrust laws only take effect when companies abuse
köhn et al. (2020). data centres should be legally bound to pro- their market power to deprive competitors, exploit market part-
vide energy certificates that provide information on their en- ners, or raise unjustifiably high consumer prices.
ergy consumption and performance. by collecting this infor- large concentrations of data in the hands of few actors are
mation in a central data register, establishing and expanding by no means a topic for antitrust and competition laws. if they
new data centres can be better planned and promoted. further- were a topic, large tech companies would no longer be able to
more, cloud services should provide information on their eco- take over ai competitors and start-ups. antitrust law world-
logical impact by way of a co -footprint per service unit (e. g., wide should be reformed accordingly. for example, the initia-
22
per hour, per year). ai-developers should be obliged to report tive “restrict corporate power” [3] urges the german govern-
on the co emissions of the ai-models used, e. g., by way of ment to prohibit dangerous monopolies in the digital economy
22
initiatives such as the “co impact calculator” [2]. creating under cartel law and to create legislation allowing them to be
22
greater transparency would also incentivize cloud providers to disbanded. to counteract the concentration of power on a few
offer more climate-friendly services. large platforms, independent data collaborations are being dis-
finally, overarching incentive instruments for reduced en- cussed (heumann/jentzsch 2019). according to research by the
ergy and resource consumption, such as taxes on co or re- stiftung neue verantwortung (engl. foundation new respon-
22
source, a sustainability-oriented national (or eu-wide) resource sibilty) [4], numerous approaches already exist for jointly us-
policy, or public procurement guidelines could provide further ing data platforms or pools, but so far with little success. the
incentives to enhance the development and use of the most en- state can support data cooperation by providing a distinct reg-
ergy- and resource-efficient ai, and for consumers to choose al- ulatory regime and more legal security, for example with re-
ternatives to ai where possible. gard to liability and data protection. moreover, to curb data mo-
ökologischeswirtschaften online-ausgabe o1.2021 (36) 39
sustainability of digitalisation
nopolies and, at the same time, make data more openly acces- goertzel, b./pennachin, c./geisweiller, n. (2014): a brief overview of
sible for socially- and sustainability-oriented companies and cogprime. in: goertzel, b./pennachin, c./geisweiller, n. (eds.): engineer-
ing general intelligence, part 1. a path to advanced agi via embodied
other causes, governments could establish public data trusts
learning and cognitive synergy. paris, atlantis press. 21–40.
to function as intermediaries between those actors that gener-
gröger, j./köhler, a./naumann, s./filler, a./guldner, a./kern, e./hilty, l./
ate data and those that intend to use it (staab 2019). different maksimov, y. (2018): entwicklung und anwendung von bewertungsgrund-
data trusts could be established for energy-related, mobility-re- lagen für ressourceneffiziente software unter berücksichtigung bestehen-
der methodik. abschlussbericht. dessau-roßlau, umweltbundesamt.
lated, or (smart) city-related data.
hao, k. (2019): training a single ai model can emit as much carbon as five
to protect the interests and safety of consumers, necessary
cars in their lifetimes. www.technologyreview.com/2019/06/06/239031/
regulatory frameworks could also include liability issues (euro- training-a-single-ai-model-can-emit-as-much-carbon-as-five-cars-in-their-
pean commission 2020). due to the difficulty of tracing poten- lifetimes/
heumann, s./jentzsch, n. (2019): wettbewerb um daten – über datenpools
tially problematic decisions made by ai, individuals harmed by
zu innovationen. berlin, stiftung neue verantwortung e. v.
an ai may not have access to evidence crucial for a court case. jetzke, t./richter, s./ferdinand, j./schaat, s. (2019): künstliche intelligenz
relevant eu legislation should be adapted, and ai standardiza- im umweltbereich – anwendungsbeispiele und zukunftsperspektiven im
tion should ensure that processes are comprehensible and ac- sinne der nachhaltigkeit. dessau-roßlau, umweltbundesamt.
jobin, a./ienca, m./vayena, e. (2019): the global landscape of ai ethics
cessible for evidence (german bundestag 2020).
guidelines. in: nature machine intelligence 1/9, 389–399.
finally, discussions are underway about a digital tax at the
köhn, m./gröger, j./stobbe, l. (2020): energie- und ressourceneffizienz
national or european level that would ensure value creation in digitaler infrastrukturen – ergebnisse des forschungsprojektes „green
the digital economy also contributes to financing public tasks cloud-computing”. dessau-roßlau, umweltbundesamt.
lobe, a. (2019): ki ist alles andere als grün. www.spektrum.de/news/
(see ganter, this issue). from a sustainability perspective, a fur-
kuenstliche-intelligenz-verbraucht-fuer-den-lernprozess-unvorstellbar-viel-
ther step would be discussing the allocation of funds solely for energie/1660246
sustainable ai. naumann, s./dick, m./kern, e./johann, t. (2011): the greensoft model:
it is key to ensure that the broad application of ai-based sys- a reference model for green and sustainable software and its engineering.
in: sustainable computing: informatics and systems 1/4, 294–304.
tems, which opinion leaders expect in the future, will be imple-
pohl, j./hilty, l. m./finkbeiner, m. (2019): how lca contributes to the envi-
mented in a sustainable way. modern data-driven architectures ronmental assessment of higher order effects of ict application: a review
and specialized hardware and the peculiarities of machine learn- of different approaches. in: journal of cleaner production 219: 698–712.
ing and ai still lack suitable sustainability criteria. achieving poole, d./mackworth, a./goebel, r. (1998): computational intelligence:
a logical approach. new york, oxford university press.
sustainable ai needs comprehensive guidelines, rules, and reg-
russell, s. j./norvig, p. (2003): artificial intelligence: a modern approach.
ulations. these should ensure a reasonable and purposive use upper saddle river (nj), prentice hall.
of ai with regard to the desired objectives, ecologically sustain- schwartz, r./dodge, j./smith, n. a./etzioni, o. (2019): green ai. http://arxiv.
able, transparent and free from exclusion and discrimination. org/abs/1907.10597
staab, p. (2019): digitaler kapitalismus – markt und herrschaft in der öko-
nomie der unkappheit. frankfurt, suhrkamp.
annotations staab, p./butollo, f. (2018): digitaler kapitalismus – wie china das silikon
valley herausfordert. in: wiso direkt. bonn, friedrich-ebert-stiftung.
[1] www.ioew.de/projekt/sustain_nachhaltigkeitsindex_fuer_kuenstliche_
strubell, e./ganesh, a./mccallum, a. (2019): energy and policy considera-
intelligenz
tions for deep learning in nlp. in: proceedings of the 57th annual meet-
[2] https://mlco2.github.io/impact/
ing of the association for computational linguistics.
[3] www.forumue.de/projekte/konzernmacht-initiative/
vzbv – verbraucherzentrale bundesverband (2020): weißbuch
[4] www.stiftung-nv.de/
zur künstlichen intelligenz. www.vzbv.de/sites/default/files/
downloads/2020/07/27/20-06-30_vzbv_stellungnahme_weissbuch_ki.pdf
references wiggerthale, m. (2019): konzernmacht in der digitalen welt. ökologisches
wirtschaften 33/1: 10.
ai hleg – high level expert group on artificial intelligence (2019): ethics
wolfangel, e. (2018): programmierter rassismus. www.zeit.de/impressum/
guidelines for trustworthy ai. https://ec.europa.eu/digital-single-market/
index
en/news/ethics-guidelines-trustworthy-ai
algorithmwatch (2018): atlas der automatisierung – automatisierte ent-
scheidungen und teilhabe in deutschland. https://atlas.algorithmwatch.
org/wp-content/uploads/2019/07/atlas_der_automatisierung_von_
algorithmwatch.pdf
authors + contact
algorithmwatch (2020): global invetory. https://inventory.algorithmwatch.
org/?sfid=172&sort_order=_sfm_i_date+asc+alpha friederike rohde, maike gossen and josephin wagner
bertelsmann stiftung/i.rights lab (2020): praxisleitfaden zu den algo.rules – are researchers at the iöw.
orientierungshilfen für entwickler:innen und ihre führungskräfte. institut für ökologische wirtschaftsforschung (iöw),
www.bertelsmann-stiftung.de/fileadmin/files/alg/algo.rules_ potsdamer str. 105, 10785 berlin. e-mail: friederike.rohde@ioew.de,
praxisleitfaden.pdf maike.gossen@ioew.de, josephin.wagner@ioew.de, tel.: +49 30 8845940
european commission (2020): white paper on artificial intelligence: a euro-
tilman santarius is professor of social-ecological
pean approach to excellence and trust. commission-white-paper-artificial-
transformation and sustainable digitalisation at the technical university
intelligence-feb2020_en.pdf
of berlin and the einstein center digital futures.
german bundestag (2020): unterrichtung der enquete-kommission künst-
liche intelligenz – gesellschaftliche verantwortung und wirtschaftliche, technical university of berlin, marchstraße 23, 10587 berlin.
soziale und ökologische potenziale. bundestags-drucksache 19/23700. e-mail: santarius@tu-berlin.de, tel.: +49 30 31478838
40 ökologischeswirtschaften online-ausgabe o1.2021 (36)"
1,08.SustainableAIEnvironmentalImplicationsChallengesandOpportunities.pdf,"
1
sustainable ai: environmental implications,
challenges and opportunities
carole-jean wu, ramya raghavendra, udit gupta, bilge acun, newsha ardalani, kiwan maeng,
gloria chang, fiona aga behram, james huang, charles bai, michael gschwind, anurag gupta, myle ott,
anastasia melnikov, salvatore candido, david brooks, geeta chauhan, benjamin lee, hsien-hsin s. lee,
bugra akyildiz, maximilian balandat, joe spisak, ravi jain, mike rabbat, kim hazelwood
facebook ai
2202
abstract—this paper explores the environmental impact of
ai in different disciplines
thesuper-lineargrowthtrendsforaifromaholisticperspective,
250
spanning data, algorithms, and system hardware. we character- stnuoc sdnasuoht computer science
izethecarbonfootprintofaicomputingbyexaminingthemodel 200 math
naj development cycle across industry-scale machine learning use elcitravixra machine learning
cases and, at the same time, considering the life cycle of system 150 physics
hardware.takingastepfurther,wecapturetheoperationaland
9 manufacturingcarbonfootprintofaicomputingandpresentan 100
end-to-end analysis for what and how hardware-software design evitalumuc
]gl.sc[ and at-scale optimization can help reduce the overall carbon 50
footprint of ai. based on the industry experience and lessons
learned, we share the key challenges and chart out important 0
2011 2013 2015 2017 2019
development directions across the many dimensions of ai. we source: arxiv.org
hope the key messages and insights presented in this paper
fig.1. thegrowthofmlisexceedingthatofmanyotherscientificdisciplines.
can inspire the community to advance the field of ai in an
significantresearchgrowthinmachinelearningisobservedinrecentyearsas
environmentally-responsible manner.
illustratedbytheincreasingcumulativenumberofpaperspublishedinmachine
2v46300.1112:vixra learningwithrespecttootherscientificdisciplinesbasedonthemonthlycount
(y-axismeasuresthecumulativenumberofarticlesonarxiv).
i. introduction
in research, development, and deployment have led to a super-
artificial intelligence (ai) is one of the fastest growing
linear growth in ai data, models, and infrastructure capacity.
domains spanning research and product development and
with the dramatic growth of ai, it is imperative to understand
significant investment in ai is taking place across nearly every
the environmental implications, challenges, and opportunities
industry, policy, and academic research. this investment in
ofthisnascenttechnology.thisisbecausetechnologiestendto
ai has also stimulated novel applications in domains such as
create a self-accelerating growth cycle, putting new demands
science, medicine, finance, and education. figure 1 analyzes
on the environment.
thenumberofpaperspublishedwithinthescientificdisciplines,
this work explores the environmental impact of ai from
illustrating the growth trend in recent years1.
a holistic perspective. more specifically, we present the
ai plays an instrumental role to push the boundaries of
challenges and opportunities to designing sustainable ai
knowledge and sparks novel, more efficient approaches to
computing across the key phases of the machine learning (ml)
conventional tasks. ai is applied to predict protein structures
development process — data, experimentation, training, and
radically better than previous methods. it has the potential to
inference — for a variety of ai use cases at facebook, such
revolutionizebiologicalsciencesbyprovidingin-silicomethods
as vision, language, speech, recommendation and ranking. the
for tasks only possible in a physical laboratory setting [1]. ai
solution space spans across our fleet of datacenters and on-
is demonstrated to achieve human-level conversation tasks,
device computing. given particular use cases, we consider the
such as the blender bot [2], and play games at superhuman
impact of ai data, algorithms, and system hardware. finally,
levels, such as alphazero [3]. ai is used to discover new
weconsideremissionsacrossthelifecycleofhardwaresystems,
electrocatalysts for efficient and scalable ways to store and
from manufacturing to operational use.
utilize renewable energy [4], predicting renewable energy
ai data growth. in the past decade, we have seen an
availability in advance to improve energy utilization [5],
exponential increase in ai training data and model capacity.
operatinghyperscaledatacentersefficiently[6],growingplants
figure 2(b) illustrates that the amount of training data at
using less natural resources [7], and, at the same time, being
facebook for two recommendation use cases — one of the
used to tackle climate changes [8], [9]. it is projected that, in
fastestgrowingareasofmlusageatfacebook—hasincreased
thenextfiveyears,themarketforaiwillincreaseby10×into
by2.4×and1.9×inthelasttwoyears,reachingexabytescale.
hundreds of billions of dollars [10]. all of these investments
the increase in data size has led to a 3.2× increase in data
ingestion bandwidth demand. given this increase, data storage
1basedonmonthlycounts,figure1estimatesthecumulativenumberof
paperspublishedpercategoryonthearxivdatabase. and the ingestion pipeline accounts for a significant portion of
(a) 1000x model size scaling (b) data growth trend (d) system growth trend
4.5x 3x 2.9x
gpt english2french gpt french2english noitsegni 4 dlrm1 data
recsys search recsys images htdiwdnab 3.5 dlrm2 data training inference
45 0.035 tnemevorpmi 2.5 23 data ingestion bw yticapac 2.5
erocs 4 30 5 1,000x 0.03 0.025 & atadezis 0.5 1.5 1 2.5x
30 time
uelb 25 0.02 cua (c) model growth trend 20x metsys 2
20 0.015 20x
11 05 0.01 etulosba ledom 15 dlrm parameter #s ia 1.5
5 0.005 10
5
0 0
0.1x 10x 1000x 0 1
model size (billions of parameters in log scale) time 2019-21 yr1-q1yr1-q2yr1-q3yr1-q4yr2-q1yr2-q2
fig.2. deeplearninghaswitnessedanexponentialgrowthindata,modelparameters,andsystemresourcesovertherecentyears.(a)the1000×modelsize
growthhasledtohighermodelaccuracyforvariousmltasks.forexample,withgpt-3,toincreasethemodelqualitybleuscorefrom5to40requiresa
model1,000×largerinsize.(b)atfacebook,theamountofdataforrecommendationusecaseshasroughlydoubledbetween2019and2021,leadingto3.2
timesincreaseinthedataingestionbandwidthdemand.(c)facebook’srecommendationandrankingmodelsizeshaveincreasedby20timesduringthesame
timeperiod[11].(d)theexplosivegrowthinaihasdriven2.9×and2.5×capacityincreasesforaitrainingandinference,respectively.
the infrastructure and power capacity compared to ml training for both operational and embodied carbon footprint of ai.
and end-to-end machine learning life cycles. we must look at the ml pipeline end-to-end: data collection,
aimodelgrowth.theever-increasingdatavolumehasalso model exploration and experimentation, model training, model
drivenasuper-lineartrendinmodelsizegrowth.figure2(a)de- optimization and run-time inference. the frequency of training
picts the 1000× model size increase for gpt3-based language and scale of each stage of the ml development cycle matter.
translation tasks [12], [13], whereas for baidu’s search engine, from the systems perspective, the life cycle of ml software
the model of 1000× larger in size improves accuracy in auc and system hardware, including manufacturing and operational
by 0.030. despite small, the accuracy improvement can lead use, must also be considered.
to significantly higher-quality search outcomes [14]. similarly, optimizing across ml pipelines and systems life cycles end-
figure 2(c) illustrates that between 2019 and 2021, the size to-end is a complex and challenging task. while training large,
of recommendation models at facebook has increased by sparsely-activated neural networks improves model scalability,
20× [15], [16], [17], [11]. despite the large increase in model achieving higher accuracy at lower operational energy foot-
sizes, the memory capacity of gpu-based ai accelerators, print [21], it can incur higher embodied carbon footprint from
e.g. 32gb (nvidia v100, 2018) to 80gb (nvidia a100, theincreaseinthesystemresourcerequirement.shiftingmodel
2021), has increased by < 2× every 2 years. the resource training and inference to data centers with carbon-free energy
requirements for strong ai scaling clearly outpaces that of can reduce emissions; however, this approach may not scale to
system hardware. a broad set of use cases. infrastructure for carbon-free energy
aiinfrastructuregrowth.thestrongperformancescaling is limited by factors such as geography and available materials
demand for ml motivates a variety of scale-out solutions [11], (e.g.rare metals),and takes significanteconomic resourcesand
[18]byleveragingparallelismatscalewithamassivecollection time to build. in addition, as on-device learning becomes more
oftrainingaccelerators.figure2(d)illustratesthattheexplosive ubiquitously adopted to improve data privacy, we can see more
growth in ai use cases at facebook has driven 2.9× increase computation being shifted away from data centers to the edge,
in ai training infrastructure capacity over the 1.5 years. in where access to renewable energy is limited.
addition, we observe trillions of inference per day across aholisticapproach.thispaperisthefirsttotakeaholistic
facebook’s data centers—more than doubling in the past 3 approach to characterize the environmental footprint of ai
years. the increase in inference demands has also led to an computing from experimentation and training to inference.
2.5× increase in ai inference infrastructure capacity. last but we characterize the carbon footprint of ai computing by
notleast,thecarbonfootprintofaigoesbeyonditsoperational examining the model development cycle across industry-scale
energyconsumption.theembodiedcarbonfootprintofsystems machine learning use cases at facebook (section ii). this is
isbecomingadominatingfactorforai’soverallenvironmental illustrated by the more than 800× operational carbon footprint
impact (section iii) [19]. reduction achieved through judicious hardware-software co-
the elephant in the room. despite the positive societal design for a transformer-based universal language model.
benefits [20], the endless pursuit of achieving higher model taking a step further, we present an end-to-end analysis for
qualityhasledtotheexponentialscalingofaiwithsignificant bothoperationaland embodiedcarbonfootprintforaitraining
energy and environmental footprint implications. although and inference (section iii). based on the industry experience
recent work shows the carbon footprint of training one large and lessons learned, we chart out opportunities and important
ml model, such as meena [21], is equivalent to 242,231 miles developmentdirectionsacrossthedimensionsofaiincluding—
driven by an average passenger vehicle [22], this is only one data, algorithm, systems, metrics, standards, and best practices
aspect; to fully understand the real environmental impact we (section iv). we hope the key messages (section vi) and the
must consider the ai ecosystem holistically going forward — insights in this paper can inspire the community to advance
beyond looking at model training alone and by accounting the field of ai in an environmentally-responsible manner.
2
machine learning model development and deployment phases [section 2.1] (a) fleet view
data
data experimentation training inference (b) machine learning task view t tr ra ai in ni in ng g ( (o of nf ll ii nn ee /) evaluation)
[section 3.1] deployment
data efficiency resource-efficient experimentation, algorithms, and
[section 4.1] model architectures [section 4.2] rm1
system life cycle [section 2.2] 0% 20% 40% 60% 80% 100%
(c) infrastructure view
12
snoillim
e2oc 10 [use] operational (renewable)
deep learning 8 [use] operational scope 1,2
storage –network --compute framework & library snot [manufacturing] value chain co2 scope 3
6
efficient, environmentally-sustainable ai system hardware [section 4.3] carbon removal
cirtem 4
2
manufacturing transport product use recycling 0
2016 2017 2018 2019 2020
-2
fig.3. modeldevelopmentphasesoveraisystemhardwarelifecycle:(a)atfacebook,weobservearoughpowercapacitybreakdownof10:20:70for
aiinfrastructuresdevotedtothethreekeyphases—experimentation,training,andinference;(b)consideringtheprimarystagesofthemlpipeline
end-to-end,theenergyfootprintofrm1isroughly31:29:40overdata,experimentation/training,andinference;(c)despitetheinvestmenttoneutralize
theoperationalfootprintwithcarbon-freeenergy,theoveralldatacenterelectricityusecontinuestogrow,demandingover7.17millionmwhin2020[23].
ii. modeldevelopmentphasesandaisystem frequencies.forexample,modelssupportingfacebook’ssearch
hardwarelifecycle serviceweretrainedatanhourlycadencewhereasthelanguage
translationmodelsweretrainedweekly[24].ap50production
figure 3 depicts the major development phases for ml —
model training workflow takes 2.96 gpu days while a training
data processing,experimentation,training,andinference
workflow at p99 can take up to 125 gpu days.
(section ii-a) — over the life cycle of ai system hardware
finally, for inference, the best-performing model is de-
(section ii-b). driven by distinct objectives of ai research
ployed,producingtrillionsofdailypredictionstoservebillions
and advanced product development, infrastructure is designed
of users worldwide. the total compute cycles for inference
and built specifically to maximize data storage and ingestion
predictions are expected to exceed the corresponding training
efficiency for the phase of data processing, developer effi-
cycles for the deployed model.
ciency for the phase of experimentation, training throughput
efficiency for the phase of training, and tail-latency bounded
throughput efficiency for inference. b. machine learning system life cycle
life cycle analysis (lca) is a common methodology to
assess the carbon emissions over the product life cycle. there
a. machine learning model development cycle
are four major phases: manufacturing, transport, product use,
ml researchers extract features from data during the data and recycling2. from the perspective of ai’s carbon footprint
processing phase and apply weights to individual features
analysis, manufacturing and product use are the focus. thus,
basedonfeatureimportancetothemodeloptimizationobjective.
in this work, we consider the overall carbon footprint of
during experimentation, the researchers design, implement
ai by including manufacturing — carbon emissions from
and evaluate the quality of proposed algorithms, model ar-
building infrastructures specifically for ai (i.e., embodied
chitectures, modeling techniques, and/or training methods for
carbon footprint) and product use — carbon emissions from
determining model parameters. this model exploration process
the use of ai (i.e., operational carbon footprint).
is computationally-intensive. a large collection of diverse ml
while quantifying the exact breakdown between operational
ideas are explored simultaneously at-scale. thus, during this
and embodied carbon footprint is a complex process, we
phase, we observe unique system resource requirements from
estimate the significance of embodied carbon emissions using
the large pool of training experiments. within facebook’s ml facebook’sgreenhousegas(ghg)emissionstatistics3.inthis
researchcluster,50%(p50)ofmltrainingexperimentstakeup
case, more than 50% of facebook’s emissions owe to its value
to1.5gpudayswhile99%(p99)oftheexperimentscomplete
chain — scope 3 of facebook’s ghg emission. as a result,
within24gpudays.thereareanumberoflarge-scale,trillion
a significant embodied carbon cost is paid upfront for every
parameter models which require over 500 gpus days.
systemcomponentbroughtintofacebook’sfleetofdatacenters,
onceamlsolutionisdeterminedaspromising,itmovesinto
where ai is the biggest growth driver.
training where the ml solution is evaluated using extensive
productiondata—datathatismorerecent,islargerinquantity, 2recyclingisanimportantdomain,forwhichtheindustryisdeveloping
and contains richer features. the process often requires a circular economy model to up-cycle system components — design with
recyclinginmind.
additional hyper-parameter tuning. depending on the ml task
3facebooksustainabilitydata:https://sustainability.fb.com/report/2020-sust
requirement, the models can be trained/re-trained at different ainability-report/.
3
operational carbon footprint of large-scale ml tasks overall carbon footprint of large-scale ml tasks
1.4
snoillimml snoillim
1.00 offline training online training inference operational carbon cost (offset with solar)
operational carbon cost (rest)
1.2
projected embodied carbon cost
1
)gk( 0.50 )gk( carbon-free energy
0.8
e2oc
e2oc
0.6
0.00 0.4
1-mr 2-mr 3-mr 4-mr 5-mr san-treb remrofsnart 5taneem b006-drahsg remrofsnart 3tpg
0.2
0
devlove hctiws lm rm-1 rm-2 rm-3 rm-4 rm-5
fig.5. whenconsideringtheoveralllifecycleofmlmodelsandsystemsin
facebook oss large-scale ml models
thisanalysis,manufacturingcarboncostisroughly50%ofthe(location-based)
*training footprint only operationalcarbonfootprintoflarge-scalemltasks(figure4).takinginto
accountcarbon-freeenergy,suchassolar,theoperationalenergyconsumption
fig. 4. the carbon footprint of the lm model is dominated by inference can be significantly reduced, leaving the manufacturing carbon cost as the
whereas,forrm1–rm5,thecarbonfootprintoftrainingversusinferenceis dominatingsourceofai’scarbonfootprint.
roughlyequal.theaveragecarbonfootprintformltrainingtasksatfacebook
is1.8timeslargerthanthatofmeenausedinmodernconversationalagents
and 0.3 times of gpt-3’s carbon footprint. carbon footprint for inference bothtrainingandinferencecancontributesignificantlytothe
tasksisincludedformodelsthatareusedinproduction.note:theoperational
overallcarbonfootprintofmachinelearningtasksatfacebook.
carbonfootprintofaidoesnotcorrelatewiththenumberofmodelparameters.
theosslarge-scalemltasksarebasedonthevanillamodelarchitectures the exact breakdown between the two phases varies across
from[21]andmaynotbereflectiveofproductionusecases. ml use cases.
the overall operational carbon footprint is categorized into
offline training, online training, and inference. offline training
iii. aicomputing’scarbonfootprint
encompasses both experimentation and training models with
a. carbon footprint analysis for industry-scale ml training historical data. online training is particularly relevant to
and deployment recommendation models where parameters are continuously
updatedbasedonrecentdata.theinferencefootprintrepresents
figure 4 illustrates the operational carbon emissions for theemissionfromservingproductiontraffic.theonlinetraining
model training and inference across the ml tasks. we analyze and inference emissions are considered over the period of
six representative machine learning models in production offline training. for recommendation use cases, we find the
at facebook4. lm refers to facebook’s transformer-based carbon footprint is split evenly between training and inference.
universal language model for text translation [25]. rm1 – on the other hand, the carbon footprint of lm is dominated
rm5 represent five unique deep learning recommendation and by the inference phase, using much higher inference resources
ranking models for various facebook products [26], [27]. (65%) as compared to training (35%).
we compare the carbon footprint of facebook’s production
both operational and embodied carbon emissions can con-
ml models with seven large-scale, open-source (oss) models:
tribute significantly to the overall footprint of ml tasks.
bert-nas, t5, meena, gshard-600b, switch transformer,
and gpt-3. note, we present the operational carbon footprint operational carbon footprint: across the life cycle of
of the oss model training from [28], [21]. the operational the facebook models shown in figure 4, the average carbon
carbon footprint results can vary based on the exact ai footprint is 1.8× higher than that of the open-source meena
systems used and the carbon intensity of the energy mixture. model [30] and one-third of gpt-3’s training footprint. to
models with more parameters do not necessarily result in quantify the emissions of facebook’s models we measure
longer training time nor higher carbon emissions. training the total energy consumed, assume location-based carbon
the switch transformer model equipped with 1.5 trillion intensities for energy mixes,5 and use a data center power
parameters [29] produces significantly less carbon emission usage effectiveness (pue) of 1.1. in addition to model-level
thanthatofgpt-3(750billionparameters)[13].thisillustrates andhardware-leveloptimizations,facebook’srenewableenergy
the carbon footprint advantage of operationally-efficient model procurement [23] programs mitigates these emissions.
architectures. embodied carbon footprint: to quantify the embodied
carbon footprint of ai hardware, we use lca (section ii-b).
4intotal,thesixmodelsaccountforavastmajorityofcomputeresources we assume gpu-based ai training systems have similar
for the overall inference predictions at facebook, serving billions of users
worldwide. 5renewableenergyandsustainabilityprogramsoffacebook[23].
4
optimization is an iterative process 1,000 level-mroftalp srotarelecca noitazimitpo
25% 810 gnihcac
mhtirogla+
ot
tnemevorpmi dezilamron
erutcurtsarfni
supg
20% resource-efficient upg laciremun
ai models no 100 121
[figure 8] tnirptoof remrofsnart erawdrah
tnirptoofrewop
ia x
llarevo 15% utilization model 018
[at-scale data center optimization;
low-precision hardware] platform rewop +mroftalp
ot infrastructure dezimitpo
lanoitarepo dezilamron 10% hardware lanoitarepo 10 12
performance-per-watt 5
[domain-specific
5% acceleration]
1
performance-per-watt 1
[moore’s law] cpu baseline cpu data gpu fp32 gpu fp16 opftaimstiezred
0% management ttrraannssffoorrmmeerr
2-year time period
fig.6. optimizationisaniterativeprocess—wehaveachievedanaverageof fig.7. forthecross-lingualmltask(lm),theoperationalenergyfootprint
20%operationalenergyfootprintreductionevery6monthsacrossthemachine canbesignificantlyreducedbymorethan800×usingplatform-levelcaching,
learninghardware-softwarestack. gpus,lowprecisiondataformat,andadditionalalgorithmicoptimization.
embodied footprint as the production footprint of apple’s 28- the compounded benefits highlight the need for cross-stack
core cpu with dual amd radeon gpus (2000kg co ) [31]. optimizations.
2
forcpu-onlysystems,weassumehalftheembodiedemissions. optimizing the carbon footprint of lms: we dive
basedonthecharacterizationofmodeltrainingandinferenceat into a specific machine learning task at facebook: language
facebook,weassumeanaverageutilizationof30-60%overthe translation using a transformer-based architecture (lm). lm
3- to 5-year lifetime for servers. figure 5 presents the overall is designed based on the state-of-the-art cross-lingual un-
carbon footprint for the large scale ml tasks at facebook, derstanding through self-supervision. figure 7 analyzes the
spanning both operational and embodied carbon footprint. powerfootprintimprovementsoveracollectionofoptimization
based on the assumptions of location-based renewable energy steps for lm: platform-level caching, gpu acceleration, low
availability, the split between the embodied and (location- precision format on accelerator, and model optimization. in
based) operational carbon footprint is roughly 30% / 70% aggregate the optimizations reduce the infrastructure resources
for the large scale ml tasks. taking into account carbon-free required to serve lm at scale by over 800×. we outline the
energy, such as solar, the operational carbon footprint can be optimization benefits from each area below.
significantly reduced, leaving the manufacturing carbon cost • platform-level caching. starting with a cpu server
as the dominating source of ai’s carbon footprint. baseline, application-level caching improves power effi-
ciency by 6.7×. these improvements are a result of pre-
b. carbon footprint optimization from hardware-software computing and caching frequently accessed embeddings
co-design for language translation tasks. using dram and flash
storagedevicesascaches,thesepre-computedembeddings
optimization is an iterative process — we reduce the power
can be shared across applications and use cases.
footprint across the machine learning hardware-software stack
• gpu acceleration. in addition to caching, deploying lm
by 20%every6months.butatthesametime,aiinfrastructure
across gpu-based specialized ai hardware unlocks an
continued to scale out. the net effect, with jevon’s paradox, is
additional 10.1× energy efficiency improvement.
a 28.5% operational power footprint reduction over two years
• algorithmic optimization. finally, algorithmic optimiza-
(figure 8).
tions provide an additional 12× energy efficiency re-
optimizationacrossaimodeldevelopmentandsystem duction. halving precision (e.g., going from 32-bit to
stack over time: figure 6 shows the operational power 16-bit operations) provides a 2.4× energy efficiency
footprint reduction across facebook’s ai fleet over two years. improvementongpus.another5×energyefficiencygain
the improvement come from four areas of optimizations: can be achieved by using custom operators to schedule
model (e.g., designing resource-efficient models), platform encoding steps within a single kernel of the transformer
(e.g., pytorch’s support for quantization), infrastructure (e.g., module, such as [32].
data center optimization and low-precision hardware), and optimizing the carbon footprint of rms: the lm
hardware (e.g., domain-specific acceleration). each bar illus- analysis is used as an example to highlight the optimiza-
trates the operational power reduction across facebook’s ai tion opportunities available with judicious cross-stack, hard-
fleet over 6-month period from each of the optimization areas. ware/software optimization. in addition to optimizing the
the optimizations in aggregate provide, on average, a 20% carbon footprint for the language translation task, we describe
reduction in operational power consumption every six months. additional optimization techniques tailored for ranking and
5
baseline optimized (section 3.2) more effective amortization of shared infrastructure overheads.
1.3 furthermore,datacentercapacityisnotonlylimitedbyphysical
tnirptoof
space but also power capacity — higher operational power
1.2
efficiency directly reduces the inherited carbon cost from
rewop 1.1 utilization 28.5% improvement manufacturing of it infrastructures and datacenter buildings.
[at-scale data center optimization; at-scale efficiency optimization for facebook data
low-precision hardware]
lanoitarepo 1 centers:serversinfacebookdatacenterfleetsarecustomized
performance-per-watt for internal workloads only — machine learning tasks [24]
0.9 [domain-specific
acceleration] or not [36], [37]. compared to public cloud providers, this
0.8 puts facebook at a unique position for at-scale resource man-
yr1-h1 yr1-h2 yr2-h1 yr2-h2
agement design and optimization. first, facebookcustomizes
server skus — compute, memcached, storage tiers and ml
fig.8. theiterativeoptimizationprocesshasledto28.5%operationalenergy
footprintreductionoverthetwo-yeartimeperiod(sectioniii-b).despitethe accelerators — to maximize performance and power efficiency.
significantoperationalpowerfootprintreduction,wecontinuetoseetheoverall achieving a power usage effectiveness (pue) of about 1.10,
electricity demand for ai to increase over time — an example of jevon’s
facebook’s data centers are about 40% more efficient than
paradox, where efficiency improvement stimulates additional novel ai use
cases. small-scale, typical data centers.
furthermore, the large-scale deployment of servers of
different types provides an opportunity to build performance
recommendation use cases.
measurementandoptimizationtoolstoensurehighutilizationof
a major infrastructure challenge faced by deep learning
the underlying infrastructure. for data center fleets in different
rm training and deployment (rm1 – rm5) is the fast-rising
geographicalregionswheretheactualserverutilizationexhibits
memorycapacityandbandwidthdemands(figure2).thereare
a diurnal pattern, auto-scaling frees the over-provisioned
two primary sub-nets in a rm: the dense fully-connected (fc)
capacity during off-peak hours, by up to 25% of the web
network and the sparse embedding-based network. the fc
tier’s machines [38]. by doing so, it provides opportunistic
network is constructed with multi-layer perceptions (mlps),
server capacity for others to use, including offline ml training.
thuscomputationally-intensive.theembeddingnetworkisused
furthermore, static power consumption plays a non-trivial role
toprojecthundredsofsparse,high-dimensionalfeaturestolow-
in the context of the overall data center electricity footprint.
dimension vectors. it can easily contribute to over 95% of the
this motivates more effective processor idle state management.
total model size. for a number of important recommendation
carbon-free energy: finally, over the past years, face-
and ranking use cases, the embedding operation dominates the
bookhasinvestedincarbonfreeenergysourcestoneutralizeits
inference execution time [27], [33].
operational carbon footprint [23]. reaching net zero emissions
to tackle the significant memory capacity and bandwidth
entails matching every unit of energy consumed by data
requirement, we deploy model quantization for rms [34].
centers with 100% renewable energy purchased by facebook.
quantization offers two primary efficiency benefits: the low-
remaining emissions are offset with various sustainability
precision data representation reduces the amount of compu-
programs, further reducing the operational carbon footprint of
tation requirement and, at the same time, lowers the overall
ai computing at facebook. as section iv-c will later show,
memory capacity need. by converting 32-bit floating-point
more can be done.
numerical representation to 16-bit, we can reduce the overall
rm2 model size by 15%. this has led to 20.7% reduction in
memory bandwidth consumption. furthermore, the memory d. going beyond efficiency optimization
capacity reduction enabled by quantization unblocks novel
despite the opportunities for optimizing energy efficiency
systems with lower on-chip memory. for example, for rm1,
and reducing environmental footprint at scale, there are many
quantization has enabled rm deployment on highly power-
reasons why we must care about scaling ai in a more
efficient systems with smaller on-chip memory, leading to an
environmentally-sustainablemanner.aigrowthismultiplicative
end-to-end inference latency improvement of 2.5 times.
beyond current industrial use cases. although domain-specific
architectures improve the operational energy footprint of ai
c. machine learning infrastructures at scale model training by more than 90% [21], these architectures
ml accelerators: gpus are the de-facto training acceler- require more system resources, leading to larger embodied
ators at facebook, contributing to significant power capacity carbon footprints.
investment in the context of facebook’s fleet of datacenters. while shifting model training and inference to data centers
however, gpus can be severely under-utilized during both the with carbon-free energy sources can reduce emissions, the
ml experimentation and training phases (figure 10) [35]. to solution may not scale to all ai use cases. infrastructure for
amortizetheupfrontembodiedcarboncostofeveryaccelerator carbon free energy is limited by rare metals and materials,
deployed into facebook’s datacenters, maximizing accelerator and takes significant economic resources and time to build.
utilization is a must. furthermore, the carbon footprint of federated learning and
efficiency of scale: the higher throughput performance optimization use cases at the edge is estimated to be similar to
densityachievedwithmlacceleratorsreducesthetotalnumber that of training a transformer big model (figure 11). as on-
of processors deployed into datacenter racks. this leads to devicelearningbecomesmoreubiquitouslyadoptedtoimprove
6
overallcommunityremainsunder-investedinresearchthataims
embodied operational (rest) operational (offset w/ solar)
8 at deeply understanding and minimizing the cost of ai. we
tnirptoof )%57 conjecture the factors that may have contributed to the current
6 state in appendix a. to bend the exponential growth curve
ot
dezilamron( of ai and its environmental footprint, we must build a future
nobrac 4
where efficiency is an evaluation criterion for publishing ml
researchoncomputationally-intensivemodelsbeyondaccuracy-
2
ml related measures.
0
20% 30% 50% 75%
a. data utilization efficiency
gpu utilization
data scaling and sampling: no data is like more data
fig.9. asacceleratorutilizationimprovesovertime,bothoperationaland
— data scaling is the de-facto approach to increase model
embodiedcarbonfootprintsofaiimprove.carbon-freeenergyhelpsreduce
theoperationalcarbonfootprint,makingembodiedcarboncostthedominating quality, where the primary factor for accuracy improvement
factor.toreducetherisingcarbonfootprintofaicomputingat-scale,wemust is driven by the size and quality of training data, instead of
complementefficiencyandutilizationoptimizationwithnovelapproachesto
algorithmic optimization. however, data scaling has significant
reducetheremainingembodiedcarbonfootprintofaisystems.
environmental footprint implications. to keep the model
training time manageable, overall system resources must be
data privacy, we expect to see more computation being shifted
scaled with the increase in the data set size, resulting in larger
away from data centers to the edge, where access to renewable
embodied carbon footprint and operational carbon footprint
energy may be limited. the edge-cloud space for ai poses
fromthedatastorageandingestionpipelineandmodeltraining.
interesting design opportunities (section iv-c).
alternatively, if training system resources are kept fixed, data
thegrowthofaiinalldimensionsoutpacestheefficiencyim-
scaling increases training time, resulting in a larger operational
provement at-scale. figure 9 illustrates that, as gpu utilization
energy footprint.
is improved (x-axis) for lm training on gpus, both embodied
when designed well, however, data scaling, sampling and
and operational carbon emissions will reduce. increasing gpu
selectionstrategiescanimprovethecompetitiveanalysisforml
utilization up to 80%, the overall carbon footprint decreases
algorithms, reducing the environmental footprint of the process
by 3×. powering ai services with renewable energy sources
(appendix a). for instance, sachdeva et al. demonstrated that
can further reduce the overall carbon footprint by a factor of 2.
intelligent data sampling with merely 10% of data sub-samples
embodied carbon cost becomes the dominating source of ai’s
can effectively preserve the relative ranking performance
overall carbon footprint. to curb the rising carbon footprint
of different recommendation algorithms [42]. this ranking
of ai computing at-scale (figure 8 and figure 9), we must
performanceisachievedwithanaverageof5.8timesexecution
look beyond efficiency optimization and complement efficiency
time speedup, leading to significant operating carbon footprint
andutilizationoptimizationwitheffortstotackletheremaining
reduction.
embodied carbon footprint of ai systems.
data perishability: understanding key characteristics of
data is fundamental to efficient data utilization for ai applica-
iv. asustainabilitymindsetforai
tions.notalldataiscreatedequalanddatacollectedovertime
to tackle the environmental implications of ai’s exponential
loses its predictive value gradually. understanding the rate at
growth (figure 2), the first key step requires ml practitioners
which data loses its predictive value has strong implications on
and researchers to develop and adopt an sustainability mindset.
the resulting carbon footprint. for example, natural language
the solution space is wide open—while there are significant
data sets can lose half of their predictive value in the time
efforts looking at ai system and infrastructure efficiency opti-
periodoflessthan7years(thehalf-lifetimeofdata)[43].the
mization, the ai data, experimentation, and training algorithm
exact half-life period is a function of context. if we were able
efficiency space (sections iv-a and iv-b) beyond system
to predict the half-life time of data, we can devise effective
design and optimization (section iv-c) is less well explored.
sampling strategies to subset data at different rates based on
we cannot optimize what cannot be measured — telemetry to
its half-life. by doing so, the resource requirement for the data
track the carbon footprint of ai technologies must be adopted
storageandingestionpipelinecanbesignificantlyreduced[44]
by the community (section v-a). we synthesize a number of
— lower training time (operational carbon footprint) as well as
importantdirectionstoscaleaiinasustainablemannerandto
storage needs (embodied carbon footprint).
minimize the environmental impact of ai for the next decades.
the field of ai is currently primarily driven by research that
b. experimentation and training efficiency
seeks to maximize model accuracy — progress is often used
synonymously with improved prediction quality. this endless the experimentation and training phases are closely coupled
pursuit of higher accuracy over the decade of ai research has (sectionii).thereisanaturaltrade-offbetweentheinvestment
significant implications in computational resource requirement inexperimentationandthesubsequenttrainingcost(sectioniii).
and environmental footprint. to develop ai technologies neural architecture search (nas) and hyperparameter op-
responsibly, we must achieve competitive model accuracy at a timization (hpo) are techniques that automate the design
fixed or even reduced computational and environmental cost. space exploration. despite their capability to discover higher-
despitetherecentcalls-to-action[28],[39],[40],[41],[21],the performing neural networks, nas and hpo can be extremely
7
resource-intensive, involving training many models, especially
when using simple approaches. strubell et al. show that grid- gpu utilization
search nas can incur over 3000× environmental footprint
overhead [28]. utilizing much more sample-efficient nas and
hpo methods [45], [46] can translate directly into carbon ytilibaborp
footprint improvement. in addition to reducing the number of
training experiments, one can also reduce the training time of
each experiment. by detecting and stopping under-performing
training workflows early, unnecessary training cycles can be
eliminated.
multi-objective optimization explores the pareto frontier of
efficient model quality and system resource trade-offs. if used fig.10. avastmajorityofmodelexperimentation(overtensofthousandsof
earlyinthemodelexplorationprocess,itenablesmoreinformed trainingworkflows)utilizesgpusatonly30-50%,leavingroomforutilization
andefficiencyimprovements.
decisions about which model to train fully and deploy given
certain infrastructure capacity. beyond model accuracy and
timing performance [47], [48], [49], [50], energy and carbon c. efficient,environmentally-sustainableaiinfrastructureand
footprint can be directly incorporated into the cost function as system hardware
optimization objectives to enable discovery of environmentally-
toamortizetheembodiedcarbonfootprint,modeldevelopers
friendly models. furthermore, when training is decoupled from
and system architects must maximize the utilization of acceler-
nas, sub-networks tailoring to specialized system hardware
atorandsystemresourceswheninuseandprolongthelifetime
canbeselectedwithoutadditionaltraining[51],[52],[53],[54].
of ai infrastructures. existing practices such as the move to
such approaches can significantly reduce the overall training
domain-specific architectures at cloud scale [68], [69], [70]
time, however, at the expense of increased embodied carbon
reduce ai computing’s footprint by consolidating computing
footprint.
resources at scale and by operating the shared infrastructures
developing resource-efficient model architectures funda- more environmentally-friendly with carbon free energy6.
mentally reduce the overall system capacity need of ml accelerator virtualization and multi-tenancy support:
tasks. from the systems perspective, accelerator memory figure10illustratestheutilizationofgpuacceleratorsinface-
is scarce. however, dnns, such as neural recommendation book’s research training infrastructure. a significant portion
models, require significantly higher memory capacity and of machine learning model experimentation utilizes gpus at
bandwidth [55], [33]. this motivates researchers to develop only 30-50%, leaving significant room for improvements to
memory-efficient model architectures. for example, the tensor- efficiency and overall utilization. virtualization and workload
train compression technique (tt-rec) achieves more than consolidation technologies can help maximize accelerator
100× memory capacity reduction with negligible training time utilization [71]. google’s tpus have also recently started
and accuracy trade-off [56]. similarly, the design space trade- supportingvirtualization[72].multi-tenancyforaiaccelerators
off between memory capacity requirement, training time, and is gaining traction as an effective way to improve resource
model accuracy is also explored in deep hash embedding utilization, thereby amortizing the upfront embodied carbon
(dhe) [57]. while training time increases lead to higher footprint of customized system hardware for ai at the expense
operational carbon footprint, in the case of tt-rec and dhe, of potential operational carbon footprint increase [73], [74],
the memory-efficient model architectures require significantly [75], [76], [77].
lowermemorycapacitywhilebetterutilizingthecomputational environmentalsustainabilityasakeyaisystemdesign
capability of training accelerators, resulting in lower embodied principle:today,serversaredesignedtooptimizeperformance
carbon footprint. and power efficiency. however, system design with a focus
developing efficient training algorithms is a long-time on operational energy efficiency optimization does not always
objective of research in optimization and numerical meth- produce the most environmentally-sustainable solution [78],
ods [58]. evaluations of optimization methods should account [79], [19]. with the rising embodied carbon cost and the expo-
for all experimentation efforts required to tune optimizer nential demand growth of ai, system designers and architects
hyperparameters, not just the method performance after tun- must re-think fundamental system hardware design principles
ing [59], [60]. in addition, significant research has gone to minimize computing’s footprint end-to-end, considering the
into algorithmic approaches to efficiently scale training [61], entire hardware and ml model development life cycle. in
[62] by reducing communication cost via compression [63], additiontotherespectiveperformance,power,andcostprofiles,
[64], pipelining [65], and sharding [66], [67]. the advances the environmental footprint characteristics of processors over
have enabled efficient scaling to larger models and larger thegenerationsofcmostechnologies,ddrxandhbmmem-
datasets. we expect efficient training methods to continue ory technologies, ssd/nand-flash/hdd storage technologies
as an important domain. while this paper has focused on can be orders-of-magnitude different [80]. thus, designing ai
supervised learning relying labeled data, algorithmic efficiency
6wediscussadditionalimportantdirectionsforbuildingenvironmentally-
extends to other learning paradigms including self-supervised
sustainable systems in appendix b, including datacenter infrastructure
and semi-supervised learning (appendix c). disaggregation;faulttolerant,resilientaisystems.
8
systems with the least environmental impact requires explicit 3.5
sderdnuh1-lf download upload compute """"
consideration of environmental footprint characteristics at the
3
design time.
2.5
the implications of general-purpose processors,
2
general-purpose accelerators, reconfigurable systems, )gk(
1.5
and asics for ai: there is a wide variety of system
e2oc 1
hardware choices for ai from general-purpose processors
0.5
(cpus), general-purpose accelerators (gpus or tpus), field-
0
programmablegatearrays(fpgas)[81],toapplication-specific 2-lf esab-upt neerg-upt esab-001p neerg-001p
integrated circuit (asic), such as eyeriss [82]. the exact
system deployment choice can be multifaceted — the cadence
of ml algorithm and model architecture evolution, the di-
versity of ml use cases and the respective system resource facebook transformer-big (non-fl)
requirements,andthematurityofthesoftwarestack.whileml
fig.11. federatedlearningandoptimizationcanresultinanon-negligible
accelerator deployment brings a step-function improvement in
amount of carbon emissions, equivalent to the carbon footprint of training
operational energy efficiency, it may not necessarily reduce transformerbig [21]. fl-1 and fl-2 represent two production fl
the carbon footprint of ai computing overall. this is because applications.p100-baserepresentsthecarbonfootprintoftransformerbig
trainingonp100gpuwhereastpu-baseistransformerbig trainingon
of the upfront embodied carbon footprint associated with the
tpu. p100-green and tpu-green consider renewable energy at the cloud
different system hardware choices. from the environmental (methodologydetailinappendixb).
sustainability perspective, the optimal point depends on the
compoundingfactorofoperationalefficiencyimprovementover
that of training an orders-of-magnitude larger transformer-
generations of ml algorithms/models, deployment lifetime
based model in a centralized setting. as fl trains local
and embodied carbon footprint of the system hardware. thus,
modelsonclientdevicesandperiodicallyaggregatesthemodel
to design for environmental sustainability, one must strike a
parameters for a global model, without collecting raw user
careful balance between efficiency and flexibility and, at the
data[87], thefl processcan emitnon-negligiblecarbon atthe
same time, consider environmental impact as a key design
edge due to both computation and wireless communication.
dimension for next-generation ai systems.
it is important to reduce ai’s environmental footprint at the
carbon-efficientschedulingforaicomputingat-scale:
edge. with the ever-increasing demand for on-device use cases
as the electricity consumption of hyperscale data centers
overbillionsofclientdevices,suchasteachingaitounderstand
continuestorise,datacenteroperatorshavedevotedsignificant
the physical environment from the first-person perception [91]
investment to neutralize operational carbon footprint. by
or personalizing ai tasks, the carbon footprint for on-device
operating large-scale computing infrastructures with carbon
ai can add up to a dire amount quickly. also, renewable
freeenergy,technologycompaniesaretakinganimportantstep
energy is far more limited for client devices compared to
to address the environmental implications of computing. more
datacenters. optimizing the overall energy efficiency of fl
can be done however.
and on-device ai is an important first step [92], [93], [94],
as the renewable energy proportion in the electricity grid
[95], [96]. reducing embodied carbon cost for edge devices is
increases,fluctuationsinenergygenerationwillincreasedueto
also important, as manufacturing carbon cost accounts for 74%
the intermittent nature of renewable energy sources (i.e. wind,
of the total footprint [19] of client devices. it is particularly
solar). elastic carbon-aware workload scheduling techniques
challenging to amortize the embodied carbon footprint because
can be used in and across datacenters to predict and exploit
client devices are often under-utilized [97].
the intermittent energy generation patterns [83]. however such
scheduling algorithms might require server over-provisioning
v. call-to-action
to allow for flexibility of shifting workloads to times when
a. development of easy-to-adopt telemetry for assessing ai’s
carbon-free energy is available. furthermore, any additional
environmental footprint
server capacity comes with manufacturing carbon cost which
needs to be incorporated into the design space. alternatively, while the open source community has started building tools
energystorage(e.g.batteries,pumpedhydro,flywheels,molten toenableautomaticmeasurementofaitraining’senvironmental
salt) can be used to store renewable energy during peak footprint[39],[40],[98],[99]andthemlresearchcommunity
generation times for use during low generation times. there requiringabroaderimpactstatementforthesubmittedresearch
is an interesting design space to achieve 24/7 carbon-free ai manuscript,morecanbedoneinordertoincorporateefficiency
computing. and sustainability into the design process. enabling carbon
on-device learning on-device ai is becoming more accounting methodologies and telemetry that is easy to adopt
ubiquitously adopted to enable model personalization [84], is an important step to quantify the significance of our
[85], [86] while improving data privacy [87], [88], [89], [90], progress in developing ai technologies in an environmentally-
yet its impact in terms of carbon emission is often overlooked. responsible manner. while assessing the novelty and quality
on-device learning emits non-negligible carbon. figure 11 of ml solutions, it is crucial to consider sustainability metrics
illustrates that the operational carbon footprint for training a including energy consumption and carbon footprint along with
small ml task using federated learning (fl) is comparable to measures of model quality and system performance.
9
metrics for ai model and system life cycles: standard systemhardware,includingmanufacturingandoperationaluse,
carbon footprint accounting methods for ai’s overall carbon must also be accounted for.
footprint are at a nascent stage. we need simple, easy-to- efficiencyoptimization:optimizationacrosstheaxesofal-
adopt metrics to make fair and useful comparisons between gorithms, platforms, infrastructures, hardware can significantly
ai innovations. many different aspects must be accounted reduce the operational carbon footprint for the transformer-
for, including the life cycles of both ai models (data, based universal translation model by 810×. along with other
experimentation, training, deployment) and system hardware efficiency optimization at-scale, this has translated into 25.8%
(manufacturing and use) (section ii). operationalenergyfootprintreductionoverthetwo-yearperiod.
in addition to incorporating an efficiency measure as part more must be done to bend the environmental impact from the
of leader boards for various ml tasks, data [100], models7, exponential growth of ai (figure 8 and figure 9).
training algorithms [101], environmental impact must also be an sustainability mindset for ai: optimization beyond
consideredandadoptedbyaisystemhardwaredevelopers.for efficiency across the software and hardware stack at scale is
example, mlperf [102], [103], [104] is the industry standard crucial to enabling future sustainable ai systems. to develop
for ml system performance comparison. the industry has ai technologies responsibly, we must achieve competitive
witnessed significantly higher system performance speedup, model accuracy at a fixed or even reduced computational
outstripping what is enabled by moore’s law [105], [106]. and environmental cost. we chart out potentially high-impact
moreover, an algorithm efficiency benchmark is under develop- researchanddevelopmentdirectionsacrossthedata,algorithms
ment8. the mlperf benchmark standards can advance the field andmodel,experimentationandsystemhardware,andtelemetry
of ai in an environmentally-competitive manner by enabling dimensions for ai at datacenters and at the edge (section iv).
the measurement of energy and/or carbon footprint. we must take a deliberate approach when developing
carbonimpactstatementsandmodelcards:webelieve ai research and technologies, considering the environmental
it is important for all published research papers to disclose impact of innovations and taking a responsible approach to
the operational and embodied carbon footprint of proposed technologydevelopment[108].thatis,weneedaitobegreen
design; we are only at the beginning of this journey9. note, and environmentally-sustainable.
while embodied carbon footprints for ai hardware may not be
readilyavailable,describinghardwareplatforms,thenumberof vii. conclusion
machines, total runtime used to produce results presented in a
this paper is the first effort to explore the environmental
research manuscript is an important first step. in addition, new
impact of the super-linear trends for ai growth from a holistic
modelsmustbeassociatedwithamodelcardthat,amongother
perspective, spanning data, algorithms, and system hardware.
aspects of data sets and models [107], describes the model’s
we characterize the carbon footprint of ai computing by
overall carbon footprint to train and conduct inference.
examining the model development cycle across industry-scale
ml use cases at facebook and, at the same time, considering
vi. keytakeaways
the life cycle of system hardware. furthermore, we capture
the growth of ai: deep learning has witnessed an
the operational and manufacturing carbon footprint of ai
exponential growth in training data, model parameters, and
computing and present an end-to-end analysis for what and
system resources over the recent years (figure 2). the amount
how hardware-software design and at-scale optimization can
of data for ai has grown by 2.4×, leading to 3.2× increase in
help reduce the overall carbon footprint of ai. we share
the data ingestion bandwidth demand at facebook. facebook’s
the key challenges and chart out important directions across
recommendation model sizes have increased by 20× between
all dimensions of ai—data, algorithms, systems, metrics,
2019 and 2021. the explosive growth in ai use cases has
standards, and best experimentation practices. advancing the
driven 2.9× and 2.5× capacity increases for ai training and
field of machine intelligence must not in turn make climate
inference at facebook over the recent 18 months, respectively.
change worse. we must develop ai technologies with a deeper
the environmental footprint of ai is staggering (figure 4,
understanding of the societal and environmental implications.
figure 5).
a holistic approach: to ensure an environmentally-
acknowledgement
sustainable growth of ai, we must consider the ai ecosystem
holistically going forward. we must look at the machine learn- we would like to thank nikhil gupta, lei tian, weiyi
ing pipelines end-to-end — data collection, model exploration zheng, manisha jain, adnan aziz, and adam lerer for
and experimentation, model training, optimization and run- their feedback on many iterations of this draft, and in-depth
time inference (section ii). the frequency of training and technical discussions around building efficient infrastructure
scale of each stage of the ml pipeline must be considered and platforms; adina williams, emily dinan, mona diab,
to understand salient bottlenecks to sustainable ai. from the ashkan yousefpour for the valuable discussions and insights
system’s perspective, the life cycle of model development and on ai and environmental responsibility; mark zhou, niket
agarwal, jongsoo park, michael anderson, xiaodong wang;
7paperswithcode:https://paperswithcode.com/sota/image-classification-on yatharth saraf, hagay lupesco, jigar desai, joelle pineau,
-imagenet
ram valliyappan, rajesh mosur, ananth sankarnarayanan and
8https://github.com/mlcommons/algorithmic-efficiency/
eytan bakshy for their leadership and vision without which
9https://2021.naacl.org/ethics/faq/#-if-my-paper-reports-on-experiments-t
hat-involve-lots-of-compute-timepower this work would not have been possible.
10
references [20] n. tomasev, j. cornebise, f. hutter, s. mohamed, a. picciariello,
b.connelly,d.belgrave,d.ezer,f.c.vanderhaert,f.mugisha,
[1] j.jumper,r.evans,a.pritzel,t.green,m.figurnov,o.ronneberger,
g.abila,h.arai,h.almiraat,j.proskurnia,k.snyder,m.otake-
k.tunyasuvunakool,r.bates,a.zˇ´ıdek,a.potapenko,a.bridgland,
matsuura,m.othman,t.glasmachers,w.d.wever,y.teh, m.e.
c. meyer, s. a. a. kohl, a. j. ballard, a. cowie, b. romera-
khan,r.d.winne,t.schaul,andc.clopath,“aiforsocialgood:
paredes,s.nikolov,r.jain,j.adler,t.back,s.petersen,d.reiman,
unlockingtheopportunityforpositiveimpact,”naturecommunications,
e.clancy,m.zielinski,m.steinegger,m.pacholska,t.berghammer,
vol.11,2020.
s.bodenstein,d.silver,o.vinyals,a.w.senior,k.kavukcuoglu,
p.kohli,andd.hassabis,“highlyaccurateproteinstructureprediction [21] d.patterson,j.gonzalez,q.le,c.liang,l.-m.munguia,d.rothchild,
withalphafold,”nature,2021. d. so, m. texier, and j. dean, “carbon emissions and large neural
networktraining,”arxivpreprintarxiv:2104.10350,2021.
[2] m.komeili,k.shuster,andj.weston,“internet-augmenteddialogue
generation,”arxiv:2107.07566,2021. [22] epa,“unitedstatesenvironmentalprotectionagencygreenhousegas
equivalenciescalculator,”2021.
[3] d. silver, t. hubert, j. schrittwieser, and d. hassabis, “alphazero:
sheddingnewlightonchess,shogi,andgo,”2018. [23] facebook,“2020sustainabilityreport,”2021.
[4] c. l. zitnick, l. chanussot, a. das, s. goyal, j. heras-domingo, [24] k.hazelwood,s.bird,d.brooks,s.chintala,u.diril,d.dzhulgakov,
c.ho,w.hu,t.lavril,a.palizhati,m.riviere,m.shuaibi,a.sriram, m.fawzy,b.jia,y.jia,a.kalro,j.law,k.lee,j.lu,p.noordhuis,
k.tran,b.wood,j.yoon,d.parikh,andz.ulissi,“anintroduction m.smelyanskiy,l.xiong,andx.wang,“appliedmachinelearning
toelectrocatalystdesignusingmachinelearningforrenewableenergy atfacebook:adatacenterinfrastructureperspective,”inproceedings
storage,”arxivpreprintarxiv:2010.09435,2020. oftheieeeinternationalsymposiumonhighperformancecomputer
architecture,2018.
[5] c.elkinands.witherspoon,“machinelearningcanboostthevalue
ofwindenergy,”2019. [25] a. conneau, k. khandelwal, n. goyal, v. chaudhary, g. wenzek,
f. guzma´n, e. grave, m. ott, l. zettlemoyer, and v. stoyanov,
[6] r. evans and j. gao, “deepmind ai reduces google data centre
“unsupervised cross-lingual representation learning at scale,” arxiv
coolingbillby40%,”2016.
preprintarxiv:1911.02116,2020.
[7] k.sheikh,“agrowingpresenceonthefarm:robots,”february2020.
[26] m. naumov, d. mudigere, h.-j. m. shi, j. huang, n. sundaraman,
[8] d. rolnick, p. l. donti, l. h. kaack, k. kochanski, a. lacoste,
j.park,x.wang,u.gupta,c.-j.wu,a.g.azzolini,d.dzhulgakov,
k.sankaran,a.s.ross,n.milojevic-dupont,n.jaques,a.waldman-
a. mallevich, i. cherniavskii, y. lu, r. krishnamoorthi, a. yu,
brown,a.luccioni,t.maharaj,e.d.sherwin,s.k.mukkavilli,k.p.
v. kondratenko, s. pereira, x. chen, w. chen, v. rao, b. jia,
kording, c. gomes, a. y. ng, d. hassabis, j. c. platt, f. creutzig,
l. xiong, and m. smelyanskiy, “deep learning recommendation
j. chayes, and y. bengio, “tackling climate change with machine
modelforpersonalizationandrecommendationsystems,”arxivpreprint
learning,”arxiv:1906.05433,2019.
arxiv:1906.00091,2019.
[9] r. nishant, m. kennedy, and j. corbett, “artificial intelligence
[27] u. gupta, c.-j. wu, x. wang, m. naumov, b. reagen, d. brooks,
for sustainability: challenges, opportunities, and a research agenda,”
b. cottel, k. hazelwood, m. hempstead, b. jia, h.-h. s. lee,
internationaljournalofinformationmanagement,vol.53,2020.
a.malevich,d.mudigere,m.smelyanskiy,l.xiong,andx.zhang,
[10] factsandfactors,“globalartificialintelligencemarket,”2021. “thearchitecturalimplicationsoffacebook’sdnn-basedpersonalized
[11] d. mudigere, y. hao, j. huang, a. tulloch, s. sridharan, x. liu, recommendation,”inproceedingsoftheieeeinternationalsymposium
m.ozdal,j.nie,j.park,l.luo,j.a.yang,l.gao,d.ivchenko, onhighperformancecomputerarchitecture,2020.
a.basant,y.hu,j.yang,e.k.ardestani,x.wang,r.komuravelli, [28] e.strubell,a.ganesh,anda.mccallum,“energyandpolicyconsid-
c.chu,s.yilmaz,h.li,j.qian,z.feng,y.ma,j.yang,e.wen, erations for deep learning in nlp,” arxiv preprint arxiv:1906.02243,
h. li, l. yang, c. sun, w. zhao, d. melts, k. dhulipala, k. r. 2019.
kishore, t. graf, a. eisenman, k. k. matam, a. gangidi, g. j.
[29] w.fedus,b.zoph,andn.shazeer,“switchtransformers:scalingto
chen, m. krishnan, a. nayak, k. nair, b. muthiah, m. khorashadi,
trillion parameter models with simple and efficient sparsity,” corr,
p.bhattacharya,p.lapukhov,m.naumov,l.qiao,m.smelyanskiy,
vol.abs/2101.03961,2021.
b.jia,andv.rao,“software-hardwareco-designforfastandscalable
training of deep learning recommendation models,” arxiv preprint [30] d.adiwardanaandt.luong,“towardsaconversationalagentthatcan
arxiv:2104.05158,2021. chatabout...anything,”2020.
[12] d.hernandezandt.b.brown,“measuringthealgorithmicefficiency [31] apple,“productenvironmentalreportmacpro,”2019.
ofneuralnetworks,”arxivpreprintarxiv:2005.04305,2020. [32] nvidia,“fastertransformer,”2021.
[13] t.b.brown,b.mann,n.ryder,m.subbiah,j.kaplan,p.dhariwal, [33] l. ke, u. gupta, b. y. cho, d. brooks, v. chandra, u. diril,
a.neelakantan,p.shyam,g.sastry,a.askell,s.agarwal,a.herbert- a.firoozshahian,k.hazelwood,b.jia,h.-h.s.lee,m.li,b.maher,
voss,g.krueger,t.henighan,r.child,a.ramesh,d.m.ziegler, d. mudigere, m. naumov, m. schatz, m. smelyanskiy, x. wang,
j.wu,c.winter,c.hesse,m.chen,e.sigler,m.litwin,s.gray, b.reagen,c.-j.wu,m.hempstead,andx.zhang,“recnmp:accel-
b.chess,j.clark,c.berner,s.mccandlish,a.radford,i.sutskever, eratingpersonalizedrecommendationwithnear-memoryprocessing,”
andd.amodei,“languagemodelsarefew-shotlearners,”arxivpreprint inproceedingsoftheacm/ieeeannualinternationalsymposiumon
arxiv:2005.14165,2020. computerarchitecture,2020.
[14] p.nayak,“understandingsearchesbetterthaneverbefore,”2019. [34] z.deng,j.park,p.t.p.tang,h.liu,j.yang,h.yuen,j.huang,
[15] x. yi, y.-f. chen, s. ramesh, v. rajashekhar, l. hong, n. fiedel, d.khudia,x.wei,e.wen,d.choudhary,r.krishnamoorthi,c.-j.wu,
n.seshadri,l.heldt,x.wu,ande.h.chi,“factorizeddeepretrieval s.nadathur,c.kim,m.naumov,s.naghshineh,andm.smelyanskiy,
anddistributedtensorflowserving,”inproceedingsofmachinelearning “low-precision hardware architectures meet recommendation model
andsystems,2018. inferenceatscale,”ieeemicro,vol.41,no.5,pp.93–100,2021.
[16] w.zhao,d.xie,r.jia,y.qian,r.ding,m.sun,andp.li,“distributed [35] l. wesolowski, b. acun, v. andrei, a. aziz, g. dankel, c. gregg,
hierarchicalgpuparameterserverformassivescaledeeplearningads x. meng, c. meurillon, d. sheahan, l. tian, j. yang, p. yu, and
systems,”arxivpreprintarxiv:2003.05622,2020. k. hazelwood, “datacenter-scale analysis and optimization of gpu
machinelearningworkloads,”ieeemicro,vol.41,no.5,2021.
[17] m.lui,y.yetim,o.ozkan,z.zhao,s.-y.tsai,c.-j.wu,andm.hemp-
stead,“understandingcapacity-drivenscale-outneuralrecommendation [36] a. sriraman, a. dhanotia, and t. f. wenisch, “softsku: optimizing
inference,” in proceedings of the ieee international symposium on server architectures for microservice diversity @scale,” in proceed-
performanceanalysisofsystemsandsoftware,2021. ingsofthe46thinternationalsymposiumoncomputerarchitecture,
[18] s.rajbhandari,o.ruwase,j.rasley,s.smith,andy.he,“zero-infinity: associationforcomputingmachinery,2019.
breakingthegpumemorywallforextremescaledeeplearning,”arxiv [37] a. sriraman and a. dhanotia, “accelerometer: understanding ac-
preprintarxiv:2104.07857,2021. celeration opportunities for data center overheads at hyperscale,” in
[19] u. gupta, y. kim, s. lee, j. tse, h. s. lee, g. wei, d. brooks, proceedingsoftheinternationalconferenceonarchitecturalsupport
andc.wu,“chasingcarbon:theelusiveenvironmentalfootprintof forprogramminglanguagesandoperatingsystems,2020.
computing,”inproceedingsoftheieeeinternationalsymposiumon [38] c.tang,k.yu,k.veeraraghavan,j.kaldor,s.michelson,t.kooburat,
high-performancecomputerarchitecture,2021. a.anbudurai,m.clark,k.gogia,l.cheng,b.christensen,a.gartrell,
11
m.khutornenko,s.kulkarni,m.pawlowski,t.pelkonen,a.rodrigues, [60] p. t. sivaprasad, f. mai, t. vogels, m. jaggi, and f. fleuret, “opti-
r.tibrewal,v.venkatesan,andp.zhang,“twine:aunifiedcluster mizerbenchmarkingneedstoaccountforhyperparametertuning,”in
managementsystemforsharedinfrastructure,”inproceedingsofthe proceedings of the international conference on machine learning,
usenixsymposiumonoperatingsystemsdesignandimplementation, 2020.
2020. [61] p.goyal,p.dolla´r,r.girshick,p.noordhuis,l.wesolowski,a.kyrola,
[39] a.lacoste,a.luccioni,v.schmidt,andt.dandres,“quantifyingthe a.tulloch,y.jia,andk.he,“accurate,largeminibatchsgd:training
carbonemissionsofmachinelearning,”workshopontacklingclimate imagenetin1hour,”arxivpreprintarxiv:1706.02677,2017.
changewithmachinelearningatneurips2019,2019. [62] m.ott,s.edunov,d.grangier,andm.auli,“scalingneuralmachine
[40] p.henderson,j.hu,j.romoff,e.brunskill,d.jurafsky,andj.pineau, translation,”arxivpreprintarxiv:1806.00187,2018.
“towardsthesystematicreportingoftheenergyandcarbonfootprints [63] d. alistarh, d. grubic, j. li, r. tomioka, and m. vojnovic, “qsgd:
ofmachinelearning,”corr,vol.abs/2002.05651,2020. communication-efficientsgdviagradientquantizationandencoding,”in
[41] e.m.bender,t.gebru,a.mcmillan-major,ands.shmitchell,“on proceedingsoftheadvancesinneuralinformationprocessingsystems,
thedangersofstochasticparrots:canlanguagemodelsbetoobig?,”in vol.30,2017.
proceedingsoftheacmconferenceonfairness,accountability,and [64] t.vogels,s.p.karinireddy,andm.jaggi,“powersgd:practicallow-
transparency,2021. rankgradientcompressionfordistributedoptimization,”inproceedings
[42] n.sachdeva,c.-j.wu,andj.mcauley,“svp-cf:selectionviaproxy of the advances in neural information processing systems, vol. 32,
forcollaborativefilteringdata,”arxivpreprintarxiv:2107.04984,2021. 2019.
[43] e.valavi,j.hestness,n.ardalani,andm.iansiti,timeandthevalue [65] y.huang,y.cheng,a.bapna,o.firat,d.chen,m.chen,h.lee,
ofdata. workingpapers,harvardbusinessschool,2020. j.ngiam,q.v.le,y.wu,etal.,“gpipe:efficienttrainingofgiant
neural networks using pipeline parallelism,” in proceedings of the
[44] m. zhao, n. agarwal, a. basant, b. gedik, s. pan, m. ozdal,
advancesinneuralinformationprocessingsystems,vol.32,2019.
r. komuravelli, j. pan, t. bao, h. lu, s. narayanan, j. langman,
k.wilfong,h.rastogi,c.wu,c.kozyrakis,andp.pol,“understanding [66] s. rajbhandari, j. rasley, o. ruwase, and y. he, “zero: memory
andco-designingthedataingestionpipelineforindustry-scalerecsys optimizationstowardtrainingtrillionparametermodels,”inproceedings
training,”corr,vol.abs/2108.09373,2021. of the international conference for high performance computing,
networking,storageandanalysis,2020.
[45] r. turner, d. eriksson, m. mccourt, j. kiili, e. laaksonen, z. xu,
andi.guyon,“bayesianoptimizationissuperiortorandomsearchfor [67] j.rasley,s.rajbhandari,o.ruwase,andy.he,“deepspeed:system
machine learning hyperparameter tuning: analysis of the black-box optimizations enable training deep learning models with over 100
optimizationchallenge2020,”corr,vol.abs/2104.10201,2021. billionparameters,”inproceedingsoftheacmsigkddinternational
conferenceonknowledgediscoveryanddatamining,2020.
[46] p.ren,y.xiao,x.chang,p.-y.huang,z.li,x.chen,andx.wang,
“acomprehensivesurveyofneuralarchitecturesearch:challengesand [68] n.p.jouppi,c.young,n.patil,d.patterson,g.agrawal,r.bajwa,
solutions,”acmcomput.surv.,vol.54,no.4,2021. s. bates, s. bhatia, n. boden, a. borchers, r. boyle, p.-l. cantin,
c. chao, c. clark, j. coriell, m. daley, m. dau, j. dean, b. gelb,
[47] q.song,d.cheng,h.zhou,j.yang,y.tian,andx.hu,“towards
t.v.ghaemmaghami,r.gottipati,w.gulland,r.hagmann,c.r.
automatedneuralinteractiondiscoveryforclick-throughrateprediction,”
ho, d. hogberg, j. hu, r. hundt, d. hurt, j. ibarz, a. jaffey,
proceedingsofthe26thacmsigkddinternationalconferenceon
a.jaworski,a.kaplan,h.khaitan,d.killebrew,a.koch,n.kumar,
knowledgediscoveryanddatamining,2020.
s. lacy, j. laudon, j. law, d. le, c. leary, z. liu, k. lucke,
[48] m.r.joglekar,c.li,m.chen,t.xu,x.wang,j.k.adams,p.khaitan, a.lundin,g.mackean,a.maggiore,m.mahony,k.miller,r.na-
j.liu,andq.v.le,“neuralinputsearchforlargescalerecommendation garajan,r.narayanaswami,r.ni,k.nix,t.norrie,m.omernick,
models,”inproceedingsoftheacmsigkddinternationalconference n.penukonda,a.phelps,j.ross,m.ross,a.salek,e.samadiani,
onknowledgediscoveryanddatamining,2020. c.severn,g.sizikov,m.snelham,j.souter,d.steinberg,a.swing,
[49] m. tan and q. v. le, “efficientnet: rethinking model scaling for m. tan, g. thorson, b. tian, h. toma, e. tuttle, v. vasudevan,
convolutionalneuralnetworks,”arxivpreprintarxiv:1905.11946,2020. r. walter, w. wang, e. wilcox, and d. h. yoon, “in-datacenter
performanceanalysisofatensorprocessingunit,”inproceedingsofthe
[50] d.eriksson,p.i.chuang,s.daulton,p.xia,a.shrivastava,a.babu,
acm/ieeeinternationalsymposiumoncomputerarchitecture,2017.
s.zhao,a.aly,g.venkatesh,andm.balandat,“latency-awareneural
architecturesearchwithmulti-objectivebayesianoptimization,”corr, [69] j.hamilton,“awsinferentiamachinelearningprocessor,”2018.
vol.abs/2106.11890,2021. [70] azure,“newazurehpcandpartnerofferingsatsupercomputing19,”
[51] h.cai,c.gan,t.wang,z.zhang,ands.han,“once-for-all:train 2019.
onenetworkandspecializeitforefficientdeployment,”arxivpreprint [71] nvidia,“gpusforvirtualization,”2021.
arxiv:1908.09791,2020.
[72] a.spiridonov,“newcloudtpuvmsmaketrainingyourmlmodels
[52] d.stamoulis,r.ding,d.wang,d.lymberopoulos,b.priyantha,j.liu, ontpuseasierthanever,”2021.
and d. marculescu, “single-path nas: designing hardware-efficient
[73] m.gschwind,t.kaldewey,andd.tam,“optimizingtheefficiency
convnetsinlessthan4hours,”arxivpreprintarxiv:1904.02877,2019.
of deep learning through accelerator virtualization,” ibm journal of
[53] w. chen, x. gong, and z. wang, “neural architecture search on researchanddevelopment,vol.61,no.4-5,2017.
imagenetinfourgpuhours:atheoreticallyinspiredperspective,”arxiv
[74] s. ghodrati, b. h. ahn, j. kyung kim, s. kinzer, b. r. yatham,
preprintarxiv:2102.11535,2021.
n.alla,h.sharma,m.alian,e.ebrahimi,n.s.kim,c.young,and
[54] j.mellor,j.turner,a.storkey,ande.j.crowley,“neuralarchitecture h. esmaeilzadeh, “planaria: dynamic architecture fission for spatial
searchwithouttraining,”arxivpreprintarxiv:2006.04647,2021. multi-tenantaccelerationofdeepneuralnetworks,”inproceedingsof
[55] b. acun, m. murphy, x. wang, j. nie, c. wu, and k. hazelwood, theieee/acminternationalsymposiumonmicroarchitecture,2020.
“understandingtrainingefficiencyofdeeplearningrecommendation [75] s.-c.kaoandt.krishna,“domain-specificgeneticalgorithmformulti-
modelsatscale,”inproceedingsoftheieeeinternationalsymposium tenant dnnaccelerator scheduling,” arxiv preprint arxiv:2104.13997,
onhigh-performancecomputerarchitecture,2021. 2021.
[56] c. yin, b. acun, x. liu, and c.-j. wu, “tt-rec: tensor train [76] m. jeon, s. venkataraman, a. phanishayee, u. qian, w. xiao, and
compressionfordeeplearningrecommendationmodels,”inproceedings f. yang, “analysis of large-scale multi-tenant gpu clusters for dnn
oftheconferenceonmachinelearningandsystems,2021. trainingworkloads,”inproceedingsoftheusenixannualtechnical
[57] w.-c.kang,d.z.cheng,t.yao,x.yi,t.chen,l.hong,ande.h. conference,2019.
chi,“learningtoembedcategoricalfeatureswithoutembeddingtables [77] p.yuandm.chowdhury,“salus:fine-grainedgpusharingprimitives
forrecommendation,”arxivpreprintarxiv:2010.10784,2021. fordeeplearningapplications,”arxivpreprintarxiv:1902.04610,2019.
[58] a.s.nemirovskijandd.b.yudin,problemcomplexityandmethod [78] r.jainandj.wullert,“challenges:environmentaldesignforpervasive
efficiencyinoptimization. wiley-interscience,1983. computingsystems,”inproceedingsoftheinternationalconference
[59] d. choi, c. j. shallue, z. nado, j. lee, c. j. maddison, and g. e. onmobilecomputingandnetworking,2002.
dahl,“onempiricalcomparisonsofoptimizersfordeeplearning,”arxiv [79] j.chang,j.meza,p.ranganathan,c.bash,anda.shah,“greenserver
preprintarxiv:1910.05446,2019. design:beyondoperationalenergytosustainability,”inproceedingsof
12
theinternationalconferenceonpowerawarecomputingandsystems, [96] d. stamoulis, t.-w. r. chin, a. k. prakash, h. fang, s. sajja,
2010. m.bognar,andd.marculescu,“designingadaptiveneuralnetworks
[80] m.garciabardon,p.wuytens,l.-a.ragnarsson,g.mirabelli,d.jang, for energy-constrained image classification,” in proceedings of the
g.willems,a.mallik,a.spessot,j.ryckaert,andb.parvais,“dtco internationalconferenceoncomputer-aideddesign,2018.
including sustainability: power-performance-area-cost-environmental [97] c.gao,a.gutierrez,m.rajan,r.g.dreslinski,t.mudge,andc.-
score(ppace)analysisforlogictechnologies,”inproceedingsofthe j.wu,“astudyofmobiledeviceutilization,”inproceedingsofthe
ieeeinternationalelectrondevicesmeeting,2020. ieee international symposium on performance analysis of systems
[81] a.putnam,a.m.caulfield,e.s.chung,d.chiou,k.constantinides, andsoftware,2015.
j.demme,h.esmaeilzadeh,j.fowers,g.p.gopal,j.gray,m.hasel- [98] v.schmidt,k.goyal,a.joshi,b.feld,l.conell,n.laskaris,d.blank,
man, s. hauck, s. heil, a. hormati, j.-y. kim, s. lanka, j. larus, j. wilson, s. friedler, and s. luccioni, “codecarbon: estimate and
e.peterson,s.pope,a.smith,j.thong,p.y.xiao,andd.burger, trackcarbonemissionsfrommachinelearningcomputing,”2021.
“areconfigurablefabricforacceleratinglarge-scaledatacenterservices,” [99] k.lottick,s.susai,s.a.friedler,andj.p.wilson,“energyusage
ieeemicro,2015. reports:environmentalawarenessaspartofalgorithmicaccountability,”
[82] y.-h. chen, j. emer, and v. sze, “eyeriss: a spatial architecture workshop on tackling climate change with machine learning at
for energy-efficient dataflow for convolutional neural networks,” in neurips2019,2019.
proceedingsoftheacm/ieeeinternationalsymposiumoncomputer [100] d. kiela, m. bartolo, y. nie, d. kaushik, a. geiger, z. wu,
architecture,2016. b. vidgen, g. prasad, a. singh, p. ringshia, z. ma, t. thrush,
[83] a. radovanovic, r. koningstein, i. schneider, b. chen, a. duarte, s.riedel,z.waseem,p.stenetorp,r.jia,m.bansal,c.potts,and
b.roy,d.xiao,m.haridasan,p.hung,n.care,etal.,“carbon-aware a.williams,“dynabench:rethinkingbenchmarkinginnlp,”arxiv
computingfordatacenters,”arxivpreprintarxiv:2106.11750,2021. preprintarxiv:2104.14337,2021.
[84] h.cai,c.gan,l.zhu,ands.han,“tinytl:reducememory,notparam- [101] d.hernandezandt.b.brown,“measuringthealgorithmicefficiency
etersforefficienton-devicelearning,”arxivpreprintarxiv:2007.11622, ofneuralnetworks,”arxivpreprintarxiv:2005.04305,2020.
2020. [102] p.mattson,v.j.reddi,c.cheng,c.coleman,g.diamos,d.kanter,
[85] k. wang, r. mathews, c. kiddon, h. eichner, f. beaufays, and p.micikevicius,d.patterson,g.schmuelling,h.tang,g.-y.wei,and
d.ramage,“federatedevaluationofon-devicepersonalization,”arxiv c.-j.wu,“mlperf:anindustrystandardbenchmarksuiteformachine
preprintarxiv:1910.10252,2019. learningperformance,”ieeemicro,vol.40,no.2,pp.8–16,2020.
[86] k. bonawitz, h. eichner, w. grieskamp, d. huba, a. ingerman, [103] v.j.reddi,c.cheng,d.kanter,p.mattson,g.schmuelling,andc.-j.
v. ivanov, c. kiddon, j. konecˇny`, s. mazzocchi, h. b. mcmahan, wu,“thevisionbehindmlperf:understandingaiinferenceperformance,”
et al., “towards federated learning at scale: system design,” arxiv ieeemicro,vol.41,no.3,pp.10–18,2021.
preprintarxiv:1902.01046,2019. [104] v. j. reddi, d. kanter, p. mattson, j. duke, t. nguyen, r. chukka,
[87] a.hard,k.rao,r.mathews,s.ramaswamy,f.beaufays,s.augen- k.shiring,k.-s.tan,m.charlebois,w.chou,m.el-khamy,j.hong,
stein,h.eichner,c.kiddon,andd.ramage,“federatedlearningfor m. buch, c. trinh, t. atta-fosu, f. cakir, m. charkhabi, x. chen,
mobilekeyboardprediction,”arxivpreprintarxiv:1811.03604,2018. j.chiang,d.dexter,w.heo,g.schmuelling,m.shabani,andd.zika,
[88] t.yang,g.andrew,h.eichner,h.sun,w.li,n.kong,d.ramage, “mlperfmobileinferencebenchmark,”arxiv:2012.02328,2021.
and f. beaufays, “applied federated learning: improving google [105] p. mattson, c. cheng, g. diamos, c. coleman, p. micikevicius,
keyboardquerysuggestions,”arxivpreprintarxiv:1812.02903,2018. d. patterson, h. tang, g.-y. wei, p. bailis, v. bittorf, d. brooks,
[89] s. ramaswamy, r. mathews, k. rao, and f. beaufays, “federated d. chen, d. dutta, u. gupta, k. hazelwood, a. hock, x. huang,
learning for emoji prediction in a mobile keyboard,” arxiv preprint d.kang,d.kanter,n.kumar,j.liao,d.narayanan,t.oguntebi,
arxiv:1906.04329,2019. g.pekhimenko,l.pentecost,v.janapareddi,t.robie,t.stjohn,c.-
j.wu,l.xu,c.young,andm.zaharia,“mlperftrainingbenchmark,”
[90] d. huba, j. nguyen, k. malik, r. zhu, m. rabbat, a. yousefpour,
inproceedingsofmachinelearningandsystems,vol.2,2020.
c.-j.wu,h.zhan,p.ustinov,h.srinivas,k.wang,a.shoumikhin,
j.min,andm.malek,“papaya:practical,private,andscalablefederated [106] v. j. reddi, c. cheng, d. kanter, p. mattson, g. schmuelling, c.-j.
learning,”arxiv:2111.04877,2021. wu,b.anderson,m.breughe,m.charlebois,w.chou,r.chukka,
c. coleman, s. davis, p. deng, g. diamos, j. duke, d. fick, j. s.
[91] k.grauman,a.westbury,e.byrne,z.chavis,a.furnari,r.girdhar,
gardner,i.hubara,s.idgunji,t.b.jablin,j.jiao,t.s.john,p.kanwar,
j. hamburger, h. jiang, m. liu, x. liu, m. martin, t. nagarajan,
d. lee, j.liao, a. lokhmotov, f. massa,p.meng, p. micikevicius,
i. radosavovic, s. k. ramakrishnan, f. ryan, j. sharma, m. wray,
c.osborne,g.pekhimenko,a.t.r.rajan,d.sequeira,a.sirasao,
m.xu,e.z.xu,c.zhao,s.bansal,d.batra,v.cartillier,s.crane,
f. sun, h. tang, m. thomson, f. wei, e. wu, l. xu, k. yamada,
t.do,m.doulaty,a.erapalli,c.feichtenhofer,a.fragomeni,q.fu,
b.yu,g.yuan,a.zhong,p.zhang,andy.zhou,“mlperfinference
c.fuegen,a.gebreselasie,c.gonzalez,j.hillis,x.huang,y.huang,
benchmark,” in proceedings of the acm/ieee annual international
w.jia,w.khoo,j.kolar,s.kottur,a.kumar,f.landini,c.li,y.li,
symposiumoncomputerarchitecture,2020.
z.li,k.mangalam,r.modhugu,j.munro,t.murrell,t.nishiyasu,
w.price,p.r.puentes,m.ramazanova,l.sari,k.somasundaram, [107] m.mitchell,s.wu,a.zaldivar,p.barnes,l.vasserman,b.hutchin-
a.southerland,y.sugano,r.tao,m.vo,y.wang,x.wu,t.yagi, son, e. spitzer, i. d. raji, and t. gebru, “model cards for model
y.zhu,p.arbelaez,d.crandall,d.damen,g.m.farinella,b.ghanem, reporting,”proceedingsoftheconferenceonfairness,accountability,
v.k.ithapu,c.v.jawahar,h.joo,k.kitani,h.li,r.newcombe, andtransparency,2019.
a.oliva,h.s.park,j.m.rehg,y.sato,j.shi,m.z.shou,a.torralba, [108] c.-j. wu, s. manne, p. ranganathan, s. bird, and s. greenstein,
l.torresani,m.yan,andj.malik,“ego4d:aroundtheworldin3,000 “socio-technologicalchallengesandopportunities:pathsforward,”arxiv
hoursofegocentricvideo,”arxiv:2110.07058,2021. preprintarxiv:2108.06738,2021.
[92] y. g. kim and c.-j. wu, “autofl: enabling heterogeneity-aware [109] r.schwartz,j.dodge,n.a.smith,ando.etzioni,“greenai,”arxiv
energyefficientfederatedlearning,”inproceedingsoftheieee/acm preprintarxiv:1907.10597,2019.
internationalsymposiumonmicroarchitecture,2021. [110] k. maeng, s. bharuka, i. gao, m. c. jeffrey, v. saraph, b.-y. su,
[93] y.kang,j.hauswald,c.gao,a.rovinski,t.mudge,j.mars,and c. trippel, j. yang, m. rabbat, b. lucia, and c.-j. wu, “cpr:
l.tang,“neurosurgeon:collaborativeintelligencebetweenthecloud understandingandimprovingfailuretoleranttrainingfordeeplearning
and mobile edge,” in proceedings of the international conference recommendationwithpartialrecovery,”inproceedingsoftheconference
onarchitecturalsupportforprogramminglanguagesandoperating onmachinelearningandsystems,2021.
systems,2017. [111] a.eisenman,k.k.matam,s.ingram,d.mudigere,r.krishnamoorthi,
[94] y.g.kimandc.-j.wu,“autoscale:energyefficiencyoptimizationfor k. nair, m. smelyanskiy, and m. annavaram, “check-n-run: a
stochasticedgeinferenceusingreinforcementlearning,”inproceedings checkpointing system for training deep learning recommendation
oftheieee/acminternationalsymposiumonmicroarchitecture,2020. models,”arxivpreprintarxiv:2010.08679,2021.
[95] t.-j.yang,y.-h.chen,andv.sze,“designingenergy-efficientconvolu- [112] h. d. dixit, s. pendharkar, m. beadon, c. mason, t. chakravarthy,
tionalneuralnetworksusingenergy-awarepruning,”arxiv:1611.05128, b. muthiah, and s. sankar, “silent data corruptions at scale,” arxiv
2017. preprintarxiv:2102.11245,2021.
13
[113] p.h.hochschild,p.turner,j.c.mogul,r.govindaraju,p.ranganathan,
d.e.culler,anda.vahdat,“coresthatdon’tcount,”inproceedings 00..709107
oftheworkshoponhottopicsinoperatingsystems,2021.
[114] x.qiu,t.parcollet,j.fernandez-marques,p.p.b.degusmao,d.j.
beutel, t. topal, a. mathur, and n. d. lane, “a first look into the )retteb 00..709058
carbonfootprintoffederatedlearning,”arxivpreprintarxiv:2102.07627,
2021.
[115] h.wang,b.kim,j.xie,andz.han,“howisenergyconsumedin si rewol( 00..709036 y = r²= 0.7892x-0.004 0.9969
smartphone deep learning apps? executing locally vs. remotely,” in data scale: 1x
proceedingsoftheieeeglobalcommunicationsconference,2019. data scale: 2x
00..070941 d da at ta s sc ca al le e: 4 8x
[116] c.-j.wu,d.brooks,k.chen,d.chen,s.choudhury,m.dukhan, rorre a : x
data scale: 16x
k.hazelwood,e.isaac,y.jia,b.jia,t.leyvand,h.lu,y.lu,l.qiao, model scale: 2x
b.reagen,j.spisak,f.sun,a.tulloch,p.vajda,x.wang,y.wang, ledom model scale: 4x
00..708092 model scale: 8x y = 0.7903x-0.002
b.wasti,y.wu,r.xian,s.yoo,andp.zhang,“machinelearning model scale: 16x r²= 0.9986
atfacebook:understandinginferenceattheedge,”inproceedingsof model scale: 32x
model scale: 64x
the ieee international symposium on high performance computer 0.708 7 model scale: 128x
architecture,2019.
0.125 0.25 0.5 1 2 4
[117] r.bommasani,d.a.hudson,e.adeli,r.altman,s.arora,s.von energy/step (j)
arx,m.s.bernstein,j.bohg,a.bosselut,e.brunskill,etal.,“on
the opportunities and risks of foundation models,” arxiv preprint fig.12. modelqualityofrecommendationusecasesimprovesaswescaleup
arxiv:2108.07258,2021. theamountofdataand/orthenumberofmodelparameters(e.g.,embedding
[118] t.chen,s.kornblith,m.norouzi,andg.hinton,“asimpleframework cardinality or dimension), leading to higher energy and carbon footprint.
forcontrastivelearningofvisualrepresentations,”inproceedingsofthe maximizingmodelaccuracyforthespecificrecommendationusecasecomes
internationalconferenceonmachinelearning,pp.1597–1607,2020. withsignificantenergycost—roughly4×energysavingcanbeachieved
withonly0.004modelqualitydegradation(greenvs.yellowstars).
[119] m.assran,m.caron,i.misra,p.bojanowski,a.joulin,n.ballas,
andm.rabbat,“semi-supervisedlearningofvisualfeaturesbynon-
appendix
parametricallypredictingviewassignmentswithsupportsamples,”arxiv
preprintarxiv:2104.13963,2021. despite the recent calls-to-action [28], [39], [40], [41], the
[120] l.m.dery,p.michel,a.talwalkar,andg.neubig,“shouldwebe overallcommunityremainsunder-investedinresearchthataims
pre-training?anargumentforend-taskawaretrainingasanalternative,”
at deeply understanding and minimizing the cost of ai. there
arxivpreprintarxiv:2109.07437,2021.
are several factors that may have contributed to the current
state of ai:
• lack of incentives: over 90% of the ml publications
only focus on model accuracy improvements at the
expense of efficiency [109]. challenges10 incentivize
investment into efficient approaches.
• lack of common tools: there is no standard telemetry
in place to provide accurate, reliable energy and carbon
footprint measurement. the measurement methodology
is complex — factors, such as datacenter infrastructures,
hardware architectures, energy sources, can perturb the
final measure easily.
• lack of normalization factors: algorithmic progress in
mlisoftenpresentedinsomemeasureofmodelaccuracy,
e.g., bleu, points, elo, cross-entropy loss, but without
consideringresourcerequirementasanormalizationfactor,
e.g., the number of
cpu/gpu/tpu hours used, the overall energy consump-
tion and/or carbon footprint required.
• platform fragmentation: implementation details can
have a significant impact on real-world efficiency, but
best practices remain elusive and platform fragmentation
prevents performance and efficiency portability across
model development.
a. data utilization efficiency
figure 12 depicts energy footprint reduction potential when
data and model scaling is performed in tandem. the x-axis
10efficientopen-domainquestionanswering(https://efficientqa.github.io/),
sustainlp: simple and efficient natural language processing (https://site
s.google.com/view/sustainlp2020/home), and wmt: machine translation
efficiencytask(http://www.statmt.org/wmt21/efficiency-task.html).
14
represents the energy footprint required per training step corruption, leading to erroneous computation, model accuracy
whereas the y-axis represents model error. the blue solid degradation, non-deterministic ml execution, or fatal system
lines capture model size scaling (through embedding hash failure. in a large fleet of processors, silent data corruption
scaling) while the training data set size is kept fixed. each can occur frequently enough to have disruptive impact on
line corresponds to a different data set size, in an increasing service productivity [112], [113]. decommissioning an ai
orderfromtoptobottom.thepointswithineachlinerepresent systementirelybecauseofhardwarefaultsisexpensivefromthe
different model (embedding) sizes, in an increasing order from perspective of resource and environmental footprints. system
lefttoright.thereddashedlinescapturedatascalingwhilethe architects can design differential reliability levels for micro
model size is kept fixed. each line corresponds to a different architectural components on an ai system depending on the
embedding hash size, in an increasing order from left to right. ml model execution characteristics. alternatively, algorithmic
the points within each line represent different data sizes, in fault tolerance can be built into deep learning programming
an increasing order from top to bottom. the dashed black frameworks to provide a code execution path that is cognizant
line captures the performance scaling trend as we scale data of hardware wear-out characteristics.
and model sizes in tandem. this represents the energy-optimal on-device learning: federated learning and optimization
scaling approach. can result in a non-negligible amount of carbon emissions
scalingdatasizesormodelsizesindependentlydeviatesfrom at the edge, similar to the carbon footprint of training
the energy-optimal trend. we highlight two energy-optimal transformer [21]. figure 11 shows that the federated
big
settings along the pareto-frontier curve. the yellow star uses learning and optimization process emits non-negligible carbon
the scaling setting of data scaling 2× and model scaling 2× at the edge due to both computation and wireless communi-
whereas the green star adopts the setting of data scaling 8× cation during the process. to estimate the carbon emission,
andmodelscaling16×.theyellowstarconsumesroughly4× we used a similar methodology to [114]. we collected the
lower energy as compared to the green star with only 0.004 90-day log data for federated learning production use cases
model quality degradation in normalized entropy. overall at facebook, which recorded the time spent on computation,
model quality performance has a (diminishing) power-law data downloading, and data uploading per client device. we
relationship with the corresponding energy consumption and multiplied the computation time with the estimated device
the power of the power law is extremely small (0.002-0.004). power and upload/download time with the estimated router
thismeansachievinghighermodelqualitythroughmodel-data power,andomittedotherenergy.weassumedadevicepowerof
scaling for recommendation use cases incurs significant energy 3wandarouterpowerof7.5w[115],[114].modeltrainingon
cost. client edge devices is inherently less energy-efficient because
of the high wireless communication overheads, sub-optimal
trainingdatadistributioninindividualclientdevices[114],large
b. efficient, environmentally-sustainable ai systems
degree of system heterogeneity among client edge devices, and
disaggregating machine learning pipeline stages: as highly-fragmented edge device architectures that make system-
depicted in figure 3, the overall training throughput efficiency level optimization significantly more challenging [116]. note,
for large-scale ml models depends on the throughput perfor- the wireless communication energy cost takes up a significant
mance of both data ingestion and pre-processing and model portion of the overall energy footprint of federated learning,
training. disaggregating the data ingestion and pre-processing making energy footprint optimization on communication im-
stage of the machine learning pipeline from model training portant.
is the de-facto approach for industry-scale machine learning
model training. this allows training accelerator, network
c. efficiency and self-supervised learning
and storage i/o bandwidth utilization to scale independently,
thereby increasing the overall model training throughput by self-supervised learning (ssl) have received much attention
56% [44]. disaggregation with well-designed check-pointing in the research community in recent years. ssl methods train
support [110], [111] improves training fault tolerance as well. deep neural networks without using explicit supervision in
by doing so, failure on nodes that are responsible for data the form of human-annotated labels for each training sample.
ingestion and pre-processing can be recovered efficiently having humans annotate data is a time-consuming, expensive,
without requiring re-runs of the entire training experiment. and typically noisy process. ssl methods are typically used
from a sustainability perspective, disaggregating the data to train foundation models — models that can readily be fine-
storage and ingestion stage from model training maximizes tuned using a small amount of labeled data on a down-stream
infrastructure efficiency by using less system resources to task [117]. ssl methods have been extremely successful for
achievehighertrainingthroughput,resultinginlowerembodied pre-training large language models, becoming the de-facto
carbon footprint. by increasing fault tolerance, the operational standard,andtheyhavealsoattractedgreatinterestincomputer
carbon footprint is reduced at the same time. vision.
fault-tolerant ai systems and hardware: one way to when comparing supervised and self-supervised methods,
amortize the rising embodied carbon cost of ai infrastructures there is a glaring trade-off between having labels and the
is to extend hardware lifetime. however, hardware ages amountofcomputationaloverheadinvolvedinpre-training.for
— depending on the wear-out characteristics, increasingly example, chen et al. report achieving 69.3% top-1 validation
more errors can surface over time and result in silent data accuracy with a resnet-50 model after ssl pre-training for
15
1000 epochs on the imagenet dataset and using the linear
evaluation protocol, freezing the pre-trained feature extractor,
andfine-tuningalinearclassifierontopfor60epochsusingthe
fullimagenetdatasetwithalllabels[118].incontrast,thesame
model typically achieves at least 76.1% top-1 accuracy after
90 epochs of fully-supervised training. thus, in this example,
using labels and supervised training is worth a roughly 10×
reduction in training effort, measured in terms of number of
passes over the dataset.
recentworksuggeststhatincorporatingevenasmallamount
of labeled data can significantly bridge this gap. assran et
al. describe an approach called predicting view assignments
with support samples (paws) for semi-supervised pre-training
inspired by ssl [119]. with access to labels for just 10% of
the training images in imagenet, a resnet-50 achieves 75.5%
top-1 accuracy after just 200 epochs of paws pre-training.
runningon64v100gpus,thistakesroughly16hours.similar
observations have recently been made for language model pre-
training as well [120].
self-supervised pre-training potentially has advantages in
that a single foundation model can be trained (expensive) but
then fine-tuned (inexpensive), amortizing the up front cost
across many tasks [117]. substantial additional research is
needed to better understand the cost-benefit trade-offs for this
paradigm.
16"
2,09. GreenAlgorithmsQuantifyingthecarbonfootprintofcomputation.pdf,"
green algorithms: quantifying the carbon
footprint of computation
loïc lannelongue^1,4,7, jason grealey^2,3, michael inouye*1,2,4,5,6,7,8
1cambridge baker systems genomics initiative, department of public health and primary care, university of cambridge,
cambridge, uk
2cambridge baker systems genomics initiative, baker heart and diabetes institute, melbourne, victoria, australia
3department of mathematics and statistics, la trobe university, melbourne, australia
4british heart foundation cardiovascular epidemiology unit, department of public health and primary care, university of
cambridge, cambridge, uk
5british heart foundation centre of research excellence, university of cambridge, cambridge, uk
6national institute for health research cambridge biomedical research centre, university of cambridge and cambridge
university hospitals, cambridge, uk
7health data research uk cambridge, wellcome genome campus and university of cambridge, cambridge, uk
8the alan turing institute, london, uk
^ joint first authors
* correspondence: mi (mi336@medschl.cam.ac.uk; minouye@baker.edu.au)
abstract
climate change is profoundly affecting nearly all aspects of life on earth, including human societies,
economies and health. various human activities are responsible for significant greenhouse gas
emissions, including data centres and other sources of large-scale computation. although many
important scientific milestones have been achieved thanks to the development of high-performance
computing, the resultant environmental impact has been underappreciated. in this paper, we present
a methodological framework to estimate the carbon footprint of any computational task in a
standardised and reliable way, based on the processing time, type of computing cores, memory
available and the efficiency and location of the computing facility. metrics to interpret and
contextualise greenhouse gas emissions are defined, including the equivalent distance travelled by
car or plane as well as the number of tree-months necessary for carbon sequestration. we develop
a freely available online tool, green algorithms (www.green-algorithms.org), which enables a user
to estimate and report the carbon footprint of their computation. the green algorithms tool easily
integrates with computational processes as it requires minimal information and does not interfere
with existing code, while also accounting for a broad range of cpus, gpus, cloud computing, local
servers and desktop computers. finally, by applying green algorithms, we quantify the greenhouse
gas emissions of algorithms used for particle physics simulations, weather forecasts and natural
language processing. taken together, this study develops a simple generalisable framework and
freely available tool to quantify the carbon footprint of nearly any computation. combined with a
series of recommendations to minimise unnecessary co emissions, we hope to raise awareness
2
and facilitate greener computation.
1
introduction
the concentration of greenhouse gases in the atmosphere has a dramatic influence on climate
change with both global and locally focused consequences, such as rising sea levels, devastating
wildfires in australia, extreme typhoons in the pacific, severe droughts across africa, as well as
repercussions for human health.
with 100 megatonnes of co emissions per yeara, similar to american commercial aviation, the
2
contribution of data centres and high-performance computing facilities to climate change is
substantial. so far, rapidly increasing demand has been paralleled by increasingly energy-efficient
facilities, with overall electricity consumption of data centres somewhat stable. however, this stability
is likely to end in the coming years, with a best-case scenario forecasting a three-fold increase in the
energy needs of the sector1,2.
advances in computation, including those in hardware, software and algorithms, have enabled
scientific research to progress at unprecedented rates. weather forecasts have increased in
accuracy to the point where 5-day forecasts are approximately as accurate as 1-day forecasts 40
years ago3, physics algorithms have produced the first direct image of a black hole 55 million light-
years away4–6, the human genome has been mined to uncover thousands of genetic variants for
disease7, and machine learning permeates many aspects of society, including economic and social
interactions8–11. however, the costs associated with large-scale computation are not being fully
captured.
power consumption results in greenhouse gas (ghg) emissions and the environmental costs of
performing computations using data centres, personal computers, and the immense diversity of
architectures are unclear. while programmes in green computing (the study of environmentally
responsible information and communications technologies) have been developed over the past
decade, these mainly focus on energy-efficient hardware and cloud-related technologies12–14.
with widely recognised power-hungry and expensive training algorithms, deep learning has begun
to address its carbon footprint. machine learning (ml) models have grown exponentially in size over
the past few years15, with some algorithms training for thousands of core-hours, and the associated
energy consumption and cost have become a growing concern16. in natural language processing
(nlp), strubell et al.17 found that designing and training translation engines can emit between 0.6
and 280 tonnes of co . while not all nlp algorithms require frequent retraining, algorithms in other
2
fields are run daily or weekly, multiplying their energy consumption.
previous studies have made advances in estimating ghg emissions of computation but have
limitations which preclude broad applicability. these limitations include the requirement that users
self-monitor their power consumption17 and are restricted with respect to hardware (e.g. gpus and/or
cloud systems18,19), software (e.g. python package integration19), or applications (e.g. machine
learning)17–19. to facilitate green computing and widespread user uptake, there is a clear, and
arguably urgent, need for both a general and easy-to-use methodology for estimating carbon
emissions that can be applied to any computational task.
in this study, we present a simple and widely applicable method and a tool for estimating the carbon
footprint of computation. the method considers the different sources of energy usage, such as
a supplementary note 1
2
processors and memory, overhead of computing facilities and geographic location, while balancing
accuracy and practicality. the online calculator (www.green-algorithms.org) implements this
methodology and provides further context by interpreting carbon amounts using travel distances and
carbon sequestration. we demonstrate the applicability of the green algorithms method by
estimating the carbon footprint of particle physics simulations, weather forecast models, and nlp
algorithms as well as the carbon effects of distributed computation using multiple cpus. finally, we
make recommendations on ways for scientists to reduce their ghg emissions as well as discuss the
limitations of our approach.
methods
the carbon footprint of an algorithm depends on two factors: the energy needed to run it and the
pollutants emitted when producing such energy. the former depends on the computing resources
used (e.g. number of cores, running time, data centre efficiency) while the later, called carbon
intensity, depends on the location and production methods used (e.g. nuclear, gas or coal).
there are several competing definitions of “carbon footprint”, and in this project, we use the extended
definition from wright et al.20. the climate impact of an event is presented in terms of carbon dioxide
equivalent (co eb) and summarises the global warming effect of the ghg emitted in the determined
2
timeframe, here running a set of computations. the ghgs considered are carbon dioxide (co ),
2
methane (ch ) and nitrous oxide (n o)21; these are the three most common ghgs of the “kyoto
4 2
basket” defined in the kyoto protocol22 and represent 97.9% of global ghg emissions23. the
conversion into co e is done using global warming potential (gwp) factors from the
2
intergovernmental panel on climate change (ipcc)21,24 based on a 100-year horizon (gwp100).
when estimating these parameters, accuracy and feasibility must be balanced. this study focuses
on a methodology that can be easily and broadly adopted by the community and therefore, restricts
the scope of the environmental impact considered to ghgs emitted to power computing facilities for
a specific task. moreover, the framework presented requires no extra computation, nor involves
invasive monitoring tools.
energy consumption
we model an algorithm’s energyc needs as a function of the running time, the number, type and
process time of computing cores (cpu or gpu), the amount of memory mobilised and the power
draw of these resources. the model further includes the efficiency of the data centred, i.e. how much
extra power is necessary to run the facility (e.g. cooling and lighting).
similar to previous works17,18, our estimate is based on the power draw from processors and memory,
as well as the efficiency of the data centre. however, we refine the formula and add flexibility by
b sometimes also called co eq, co equivalent or cde.
2 2
c power (in watt, w) measures the instantaneous draw of a component. energy (in kilowatt-hours, kwh)
measures the power draw over time and is obtained by multiplying the power draw by the running time.
d by data centre, we mean the facility hosting the cores and memory, which may not be a dedicated data
centre.
3
including a unitary power draw (per core and per gb of memory) and the processor’s usage factor.
we express the energy consumption 𝐸 (in kilowatt-hours, kwh) as:
𝐸 = 𝑡×(𝑛 ×𝑃 ×𝑢 +𝑛 ×𝑃 )×𝑃𝑈𝐸×0.001 (1)
! ! ! "" ""
where 𝑡 is the running time (hours), 𝑛 the number of cores and 𝑛 the size of memory available
! ""
(gigabytes). 𝑢 is the core usage factor (between 0 and 1). 𝑃 is the power draw of a computing core
! !
and 𝑃 the power draw of the memory (watt). 𝑃𝑈𝐸 is the efficiency coefficient of the data centre.
""
the assumptions made regarding the different components are discussed below. it has been
previously shown that the power draw of the motherboard is negligible25.
power draw of the computing core
the metric commonly used to report the power draw of a processor, either cpu or gpu, is its thermal
design power (tdp, in watt) and is provided by the manufacturer. tdp values frequently correspond
to cpu specifications which include multiple cores, thus here tdp values are normalised to per-
core. while tdp is not a direct measure of power consumption, rather the amount of heat a cooling
system dissipates during regular use - it is commonly considered a reasonable approximation.
the energy used by the processor is the power draw multiplied by processing time, scaled by the
usage factor. however, processing time cannot be known a priori and, on some platforms, tracking
can be impractical at scale. modelling exact processing time of past projects may also necessitate
re-running jobs, which would generate unnecessary emissions. therefore, when this processing time
is unknown, we make the simplifying assumption that core usage is 100% of run time (𝑢 = 1 in (1)).
!
power draw from memory
memory power draw is mainly due to background consumption with a negligible contribution from
the workload and database size26. moreover, the power draw is mainly affected by the total memory
allocated, not by the actual size of the database used, because the load is shared between all
memory slots which keeps every slot in a power-hungry active state. therefore, the primary factor
influencing power draw from memory is the quantity of memory mobilised, which simply requires an
estimation of the power draw per gigabyte. measured experimentally, this has been estimated to be
0.3725 w/gb26,27.
for example, requesting 29gb of memory draws 10.8 w, which is the same as one core of a popular
core-i5 cpu. supplementary figure 1 further compares the power draw of memory to a range of
popular cpus.
power draw from storage
the power draw of storage equipment (hdd or ssd) varies significantly with workload28. however,
in regular use, storage is typically solicited far less than memory and is mainly used as a more
permanent record of the data, independently of the task at hand. in idle mode (i.e. not servicing a
request but ready to begin the next one), non-optimised hdds rarely consume more than 6w for
1tb of storage and modern ssds can draw as little as 0.6w for 800gb of storage28. under
conservative assumptions, storage power draw would be 0.006 w/gb. as above, by comparison,
the power draw of memory (0.3725 w/gb) and a core-i5 cpu (10.8w/core) are more than an order
of magnitude greater. while the researcher overhead for approximating storage usage may not be
4
substantial, it is unlikely to make a significant difference to overall power usage (and ghg emissions)
estimation. therefore, we do not consider the power consumption of storage in this work.
energy efficiency
data centre energy consumption includes additional factors, such as server cooling systems, power
delivery components and lighting. the efficiency of a given data centre can be measured by the
power usage effectiveness (pue)29,30, defined as the ratio between the total power drawn by the
facility and the power used by it equipment:
𝑃
#$#%&
𝑃𝑈𝐸 = (2)
𝑃
!$""’(#)
a data centre pue of 1.0 represents an ideal situation where all power supplied to the building is
utilised by computing equipment. the global average of data centres has been estimated as 1.67 in
201931. while data centres with relatively inefficient pue may not report it as such, some data centres
and companies have invested significant resources to bring their pues as close to 1.0 as possible;
for example, google has utilised machine learning to reduce its global yearly average pue to
1.1032,33.
carbon intensity of energy production
for a given country and energy mix, the carbon footprint in co e represents the amount of co with
2 2
the same global warming impact as the ghgs emitted, which simplifies the comparison between
different electricity production methods. the carbon footprint of producing 1 kwh of energy is called
carbon intensity (ci) and varies significantly between locations due to the broad range of production
methods (supplementary figure 2), e.g. from 19 gco e/kwh in switzerland (mainly powered by
2
hydro) to 880 gco e/kwh in australia (mainly powered by coal and gas)34,35. we use the 2020 carbon
2
intensity values aggregated by carbon footprint35. these production factors take into account the
ghg emissions at the power plants (power generation) as well as, when available, the footprint of
distributing energy to the data centre.
estimation of carbon footprint
the carbon footprint 𝐶 (in gco e) of producing a quantity of energy 𝐸 (in kwh) from sources with a
2
carbon intensity 𝐶𝐼 (in gco e/kwh) is then:
2
𝐶 = 𝐸 ×𝐶𝐼 (3)
by putting together equations (1) and (3), we obtain the long-form equation of the carbon footprint
𝐶:
𝐶 = 𝑡×(𝑛 ×𝑃 ×𝑢 +𝑛 ×𝑃 )×𝑃𝑈𝐸×𝐶𝐼×0.001 (4)
! ! ! "" ""
co e of driving and air travel
2
we contextualise gco e by estimating an equivalence in terms of distance travelled by car or by
2
passenger aircraft. previous studies have estimated the emissions of the average passenger car in
5
europe as 175 gco e/km21,36 (251 gco e/km in the united states37). the emissions of flying on a
2 2
jet aircraft in economy class have been estimated between 139 and 244 gco e/km/person,
2
depending on the length of the flight21. we use three reference flights: paris to london (50,000
gco e), new york to san francisco (570,000 gco e) and new york to melbourne (2,310,000
2 2
gco e)38.
2
co sequestration by trees
2
trees play a major role in carbon sequestration and although not all ghgs emitted can be
sequestered, co represents 74.4% of these emissions39. to provide a metric of reversion for co e,
2 2
we compute the number of trees needed to sequester the equivalent of the emissions of a given
computation. we define the metric tree-months, the number of months a mature tree needs to absorb
a given quantity of co . while the amount of co sequestered by a tree per unit of time depends on
2 2
a number of factors, such as its species, size or environment, it has been estimated that a mature
tree sequesters, on average, approximately 11 kg of co per year40, giving the multiplier in tree-
2
months a value close to 1kg of co per month (0.92g).
2
pragmatic scaling factor
many analyses are presented as a single run of a particular algorithm or software tool; however,
computations are rarely performed only once. algorithms are run multiple times, sometimes
hundreds, systematically or manually, with different parameterisations. statistical models may
include any number of combinations of covariates, fitting procedures, etc. it is important to include
these repeats in the carbon footprint. to take into account the number of times a computation is
performed in practice, we define the pragmatic scaling factor (psf), a scaling factor by which the
estimated ghg emissions are multiplied.
the value and causes of the psf vary greatly between tasks. in machine learning, tuning the hyper-
parameters of a model requires hundreds, if not thousands17, of runs, while other tools require less
tuning and can sometimes be run a smaller number of times. as per published work or the user’s
own experience, the psf should be estimated for any specific task; however, in green algorithms
we provide for, and recommend that, each user estimate their own psf.
6
figure 1: the green algorithms calculator (www.green-algorithms.org)
results
we developed a simple method which estimates the carbon footprint of an algorithm based on a
number of factors, including the hardware requirements of the tool, the runtime and the location of
the data centre (methods). using a pragmatic scaling factor, we further augment our model by
allowing for empirical estimates of repeated computations for a particular task, e.g. parameter tuning
and trial-and-errors. the resultant gco e is compared to the amount of carbon sequestered by trees
2
and the emissions of common activities such as driving a car and air travel. we designed a freely
available online tool, green algorithms (www.green-algorithms.org; figure 1), which implements our
approach and allows users to evaluate their computations or estimate the carbon savings or costs
of redeploying them on other architectures.
7
we apply this tool to a range of algorithms selected from a variety of scientific fields: physics (particle
simulations and dna irradiation), atmospheric sciences (weather forecasting), and machine learning
(natural language processing) (figure 2). for each task, we curate published benchmarks and use
www.green-algorithms.org to estimate the ghg emissions (methods). for parameters independent
of the algorithm itself, we use average worldwide values, such as the worldwide average pue of
1.6731 and carbon intensity of 475 gco e/kwh41.
2
figure 2: carbon footprint (gco e) for a selection of algorithms, with and without their
2
pragmatic scaling factor.
particle physics simulations
in particle physics, complex simulations are used to model the passage of particles through matter.
geant442 is a popular toolkit based on monte-carlo methods with wide-ranging applications, such as
the simulation of detectors in the large hadron collider and analysis of radiation burden on patients
in clinical practice or external beam therapy43–45. meylan et al.46 investigated the biological effects of
ionising radiations on dna on an entire human genome (6.4´109 nucleotide pairs) using geant4-
dna, an extension of geant4.
to quantify the dna damage of radiation, they run experiments with photons of different energy,
from 0.5 mev to 20 mev. each experiment runs for three weeks to simulate 5,000 particles (protons)
using 24 processing threads and up to 10gb of memory. using the green algorithms tool, and
assuming an average cpu power draw (such as the xeon e5-2680, capable of running 24 threads
on 12 cores), and worldwide average values for pue and carbon intensity, we estimated that a single
experiment emits 49,465 gco e. when taking into account a psf of 11, corresponding to the 11
2
different energy levels tested, the carbon footprint of such study is 544,115 gco e. using estimates
2
of car and air travel (methods), 544,115 gco e is approximately equivalent to driving 3,109 km (in
2
8
a european car) or flying economy from new york to san francisco. in terms of carbon sequestration
(methods), it would take a mature tree 49 years to remove the co equivalent to the ghg emissions
2
of this study from the atmosphere (593 tree-months).
a common way to reduce the running time of algorithms is to distribute the computations over
multiple processing cores. if the benefit in terms of time is well documented for each task, as in 47,
the environmental impact is usually not taken into account. geant4 is a versatile toolbox; it contains
an electromagnetic package simulating particle transport in matter and high energy physics detector
response48. schweitzer et al.47 use a standardised example, testem1249, to compare the
performances of different hardware configurations, from 1 to 60 cores (i.e. a full xeon phi cpu).
with the green algorithms tool, we estimated the carbon footprint of each configuration (figure 3),
which shows that increasing the number of cores up to 15 improves both running time and ghg
emissions. however, when multiplying the number of cores further by 4 (from 15 to 60), the running
time is only halved, resulting in a two-fold increase in emissions, from 238 to 481 gco2e. generally,
if the reduction in running time is lower than the relative increase in the number of cores, distributing
the computations will worsen the carbon footprint. in particular, scientists should be mindful of
marginal improvements in running time which have disproportionally large effects on ghg
emissions, as demonstrated by the gap between 30 and 60 cores in figure 3. for any parallelised
computation, there is likely to be a specific optimal number of cores for minimal ghg emissions.
figure 3: effect of parallelisation using multiple cores on run time and carbon footprint using
testem12 geant4 simulation.
weather forecasting
weather forecasts are based on sophisticated models simulating the dynamics between different
components of the earth (such as the atmosphere and oceans). operational models face stringent
time requirements to provide live predictions to the public, with a goal of running about 200-300
forecast days (fds) in one (wall clock) day50. neumann et al.50 present the performances of two
9
models in use for current weather forecasts: (i) the integrated forecast system (ifs)51 used by the
european centre for medium-range weather forecasts (ecmwf) for 10-day forecasts, and (ii) the
icosahedral non-hydrostatic (icon)52 designed by the german weather service (deutscher
wetterdienst, dwd) and whose predictions are used by more than 30 national weather services53.
the configurations in daily use by the ecmwf include a supercomputer based in reading, uk,
which has a pue of 1.4554, while icon is run on the german meteorological computation centre
(dmrz)55 based in germany (pue unknown). neumann et al.50 ran their experiments on hardware
similar to that equipped by both facilities, “broadwell” cpu nodes (intel e5-2695v4, 36 cores) and
minimum 64gb memory per node. we utilise these parameters for our co e emission estimates. it
2
is important to note that icon and ifs each solve slightly different problems, and therefore are not
directly comparable.
the dwd uses icon with a horizontal resolution of 13kme and generates a forecast day in 8
minutes. based on the experiments run by neumann et al.50, this requires 575 broadwell nodes
(20,700 cpu cores). we estimate that generating one forecast day emits 12,848 gco e (14 tree-
2
months). with a running time of 8min/fd, icon can generate 180 forecast days in 24 hours. when
taking into account this pragmatic scaling factor of 180, we estimated that each day, the icon
weather forecasting algorithm releases approximately 2,312,653 gco e, equivalent to driving 13,215
2
km or flying from new york to san francisco four times. in terms of carbon sequestration, the
emissions of each day of icon weather forecast are equivalent to 2,523 tree-months.
at ecmwf, ifs makes 10-day operational weather forecasts with a resolution of 9km. to achieve
a similar threshold of 180 fds/day, 128 broadwell nodes are necessary (4,608 cores)50,56. using the
pue of the uk ecmwf facility (1.45), we estimate the impact of producing one forecast day with
ifs to be 1,660 gco e. using a psf of 180 for one day’s forecasts, we estimated emissions of
2
298,915 gco e, equivalent to driving 1,708 km or three return flights between paris and london.
2
these emissions are equivalent to 326 tree-months.
furthermore, we modelled the planned scenario of the ecmwf transferring its supercomputing to
bologna, italy, in 202157. compared to the data centre in reading, the new data centre in bologna
is estimated to have a more efficient pue of 1.2758. prima facie this move appears to save substantial
ghg emissions; however, it is notable that the carbon intensity of italy is 33% higher than the uk35.
unless the sources of electricity for the data centre in bologna are different from the rest of italy and
in the absence of further optimisations, we estimated that the move would result in an 18% increase
in ghg emissions from the ecmwf (from 298,915 to 350,063 gco e).
2
natural language processing
in natural language processing (nlp), the complexity and financial costs of model training are major
issues16. this has motivated the development of language representations that can be trained once
to model the complexity of natural language, and which could be used as input for more specialised
algorithms. the bert (bidirectional encoder representations from transformers)59 algorithm is a
field leader which yields both high performance and flexibility: state-of-the-art algorithms for more
specific tasks are obtained by fine-tuning a pre-trained bert model, for example in scientific text
analysis60 or biomedical text mining61. yet, while the bert model is intended to avoid retraining,
e the horizontal resolution represents the level of geographical detail achieved when modelling the different
weather phenomenon.
10
many data scientists, perhaps understandably, continue to recreate or attempt to improve upon
bert, leading to redundant and ultimately inefficient computation as well as excess co e
2
emissions. even with optimised hardware (such as nvidia volta gpus), a bert training run may
take three days or more62.
using these optimised parameters, strubell et al.17 showed that a run time of 79 hours on 64 tesla
v100 gpus was necessary to train bert, with a usage factor of the gpus of 62.7%. with the
greens algorithms calculator, we estimated that a bert training run would emit 754,407 gco e
2
(driving 4,311 km in a european car; 1.3 flights from new york to san francisco; and 823 tree-
months). when considering a conservative psf of 100 for hyperparameters search, we obtain a
carbon footprint of 75,440,740 gco e.
2
while bert is a particularly widely utilised nlp tool, google has also developed a chatbot algorithm,
meena, which was trained for 30 days on a tpu-v3 pod containing 2,048 tensor processing unit
(tpu) cores63. there is limited information on the power draw of tpu cores and memory; however,
the power supply of this pod has been estimated to be 288 kw64. using a run time of 30 days,
assuming full usage of the tpus and ignoring memory power draw, the greens algorithms calculator
estimated that meena training emitted 164,488,320 gco e, which corresponds to 179,442 tree-
2
months or 71 flights between new-york and melbourne.
discussion
the method and green algorithms tool presented here provides users with a practical way to
estimate the carbon footprint of their computations. the method focuses on producing sensible
estimates with small overheads for scientists wishing to measure the footprint of their work.
consequently, the online calculator is simple to use and generalisable to nearly any computational
task. we applied the green algorithms calculator to a variety of tasks, including particle physics
simulations, weather forecasting and natural language processing, to estimate their relative and
ongoing carbon emissions. real-world changes to computational infrastructures, such as moving
data centres, was also quantifiable in terms of carbon footprint and was shown to be of substantive
importance, e.g. moving data centres may attain a more efficient pue but a difference in carbon
intensity may negate any efficiency gains, potentially making such a move detrimental to the
environment.
our work substantially enhances and extends prior frameworks for estimating the carbon footprint of
computation. in particular, we have integrated and formalised previously unclear factors such as
usage factor and unitary power draw (per-core or per-gb of memory). as a result, and as presented
in the methods, the carbon footprint of an algorithm can be broken down to a small number of key,
easily quantifiable elements, such as number of cores, memory size and usage factor. this reduces
the burden on the user, who is not required to either measure the power draw of hardware manually
or use a limited range of cloud providers for their computations. this makes the method highly flexible
in comparison to previous work. besides drawing attention to the growing issue of ghg emissions
of data centres, one of the benefits of presenting a detailed open methodology and tool is to provide
users with the information they need to reduce their carbon footprint. perhaps the most important
challenge in green computing is to make the estimation and reporting of ghg emissions a standard
practice. this requires transparent and easy-to-use methodology, such as the green algorithms
calculator (www.green-algorithms.org) and open-source code and data presented here (see code
availability).
11
our approach has a number of limitations. first, the carbon footprint estimated is restricted to ghgs
emitted to power computers during a particular task. we do not perform a life cycle assessment
(lca) and therefore, do not consider the full environmental and social impact of manufacturing,
maintaining and disposing of the hardware used, or the maintenance of the power plants. including
these is impractical at scale and would greatly reduce who can use the method. besides, the
conversion of the impact of various ghg into co e is commonly based on a 100-year timescale;
2
however, this is now debated as it can misrepresent the impact of short-lived climate pollutants like
methane65 and new standards may be needed in the future. second, the tdp may substantially
underestimate power draw in some situations. for example, when hyperthreading is used, the real
power consumption can be double the indicated tdp66. the tdp value remains a sensible estimate
of the base consumption of the processor in most situations, but users using hyperthreading should
be aware of the impact on power consumption. third, while the power consumption from storage is
usually minimal at the scale of one computation, if central storage is constantly queried by the
algorithm (e.g. to avoid overloading memory), this can be an important factor in power draw;
however, there are resources which can be utilised if the algorithm is designed to be heavily storage
reliant28. moreover, at the scale of the data centre, storage represents a significant part of electricity
usage28 and research projects relying on large databases should separately acknowledge the long-
term carbon footprint of storage. fourth, while some averaging is necessary, the energy mix of a
country varies by the hour. for example, the carbon intensity of south australia, which relies on wind
and gas to produce electricity67, can vary between 112 and 592 gco e/kwh within one day,
2
depending on the quantity of coal-produced electricity imported from the neighbouring state of
victoria34. although most regions are relatively stable, these outliers may require a finer estimation.
our online calculator uses averaged values sourced from government reports35. fifth, the pue has
some limitations as a measure of data centres energy usage68,69, due to inconsistencies in ways to
calculate it. for example, reporting of pue is highly variable from yearly averages to best-case
scenarios, e.g. in winter when minimal cooling is required (as demonstrated by google’s quarterly
results32). whether to include infrastructure components such as security or on-site power generation
is also source of discrepancies between data centres30. although some companies present well-
justified results, many pues have no or insufficient justification. furthermore, pue is not defined
when computations are run on a laptop or desktop computer. as the device is used for multiple tasks
simultaneously, it is impossible to estimate the power overhead due to the algorithm. in the
calculator, we use a pue of 1 because of the lack of information, but we caution this should not be
interpreted as a sign of efficiency. even though discrepancies will remain, the widespread adoption
of an accurate, transparent and certified estimation of pue, such as the iso/iec standard70, would
be a substantial step for the computing community. sixth, the carbon emissions in the results are
based on manual curation of the literature. when parameters such as usage factor or pue were not
specified, we made some assumptions (100% core usage, or using average pue) that can explain
differences between our estimates and the real emissions. for best results, authors should estimate
and publish their emissions.
there are various, realistic actions one can take to reduce the carbon footprint of their computation.
acting on the various parameters in green algorithms (see methods), is a clear and easy way
approach. below, we describe a selection of practical changes one can make:
algorithm optimisation: increasing the efficiency of an algorithm can have myriad benefits, even
apart from reducing its carbon footprint. therefore, we highly recommend this and foresee algorithm
optimisation as one of the most productive, easily recognisable core activities of green computing.
while speed is an obvious efficiency gain, part of algorithm optimisation also includes memory
minimisation. the power draw from memory mainly depends on the memory requested, not the
actual memory used26, and the memory requested is often the peak memory needed for one step of
12
the algorithm (typically a merge or aggregation). by optimising these steps, one can easily reduce
energy consumption.
reduce the pragmatic scaling factor: limiting the number of times an algorithm runs, especially
those that are power hungry, is perhaps the easiest way to reduce carbon footprint. relatedly, best
practices to limit psf (as well as financial cost) include limiting parameter fine-tuning to the minimum
necessary and building a small-scale example for debugging.
choice of data centre: carbon footprint is directly proportional to data centre efficiency and the
carbon intensity of the location. the latter is perhaps the parameter which most affects total carbon
footprint because of inter-country variation, from under 20 gco2e/kwh in norway and switzerland
to over 800 gco2e/kwh in australia, south africa and some us states. to rigorously assess the
impact of punctually relocating computations, the marginal carbon intensity, rather than the average
one, should be used71. the marginal value depends on which power plant would be solicited to meet
the unexpected increased demand. although it would ideally be used, it varies by the hour and is
often not practical to estimate accurately at scale. when the marginal carbon intensity is unknown,
the average one (presented in methods and supplementary figure 2) can be used by scientists
as a practical lower bound estimate to assess the benefit of moving computations. indeed, due to
the low operating cost of renewable technologies, the marginal power plants (which are the last one
solicited) are generally high-carbon technologies such as fuel or gas71 which leads the marginal ci
to be higher than the average ci. besides, if the move is permanent, by relocating an hpc facility or
using cloud computing for example, then the energy needs are incorporated into utility planning and
the average carbon intensity is the appropriate metric to use. data centre efficiency (pue) varies
widely between facilities but, in general, large data centres optimise cooling and power supply,
reducing the energy overhead and make them more efficient than personal servers. notably, a 2016
report estimated that if 80% of small us data centres were aggregated into hyperscale facilities,
energy usage would reduce by 25%72. for users to make informed choices, data centres should
report their pue and other energy metrics. while large providers like google or microsoft widely
advertise their servers’ efficiency32,73, smaller structures often do not.
offsetting ghg emissions: carbon offsetting is a flexible way to compensate for carbon footprint.
an institution or a user themself can directly support reductions in co or other greenhouse gases,
2
e.g. fuel-efficient stoves in developing countries, reducing deforestation or hydroelectric or wind-
based power plants74,75. the pros and cons of carbon offsetting are still debated due to the variety
of mechanisms and intricate international legislations and competing standards. therefore, we only
present here an overview and point interested scientists at some resources. multiple international
standards regulate the purchase of carbon credits and ensure the efficiency of the projects
supported76. most of the well-established standards are managed by non-profits and abide by the
mechanisms set in place by the kyoto protocol (in particular certified emission reduction)77 and the
pas 2060 carbon neutrality standard from the british standards institution78. although the primary
aim is carbon offsetting, projects are often also selected in line with the united nations’ agenda 30
for sustainable development79, a broader action plan addressing inequalities, food security and
peace. amongst the most popular standards are the gold standard (founded by wwf and other
ngos)80, verra (formerly verified carbon standard)81 and the american carbon registry (a private
voluntary greenhouse gas registry)82. in addition to direct engagement with these standards,
platforms like carbon footprint74 select certified projects and facilitate the purchase of credits.
13
conclusions
the framework presented here is generalisable to nearly any computation and may be used as a
foundation for other aspects of green computing. the carbon footprint of computation is substantial
and may be affecting the climate. we therefore hope that this new tool and metrics raise awareness
of these issues as well as facilitate pragmatic solutions which may help to mitigate the environmental
consequences of modern computation. overall, with the right tools and practices, we believe hpc
and cloud computing can be immensely positive forces for both improving the human condition and
saving the environment.
14
data availability
all data used for the calculator is available on github:
https://github.com/greenalgorithms/green-algorithms-tool/tree/master/data.
code availability
all code supporting the calculator is available on github:
https://github.com/greenalgorithms/green-algorithms-tool
references
1. jones, n. how to stop data centres from gobbling up the world’s electricity. nature 561, 163–
166 (2018).
2. andrae, a. & edler, t. on global electricity usage of communication technology: trends to
2030. challenges 6, 117–157 (2015).
3. alley, r. b., emanuel, k. a. & zhang, f. advances in weather prediction. science 363, 342–344
(2019).
4. collaboration, t. e. h. t. et al. first m87 event horizon telescope results. i. the shadow of
the supermassive black hole. astrophys. j. lett. 875, l1 (2019).
5. collaboration, t. e. h. t. et al. first m87 event horizon telescope results. iii. data processing
and calibration. astrophys. j. lett. 875, l3 (2019).
6. collaboration, t. e. h. t. et al. first m87 event horizon telescope results. iv. imaging the
central supermassive black hole. astrophys. j. lett. 875, l4 (2019).
7. buniello, a. et al. the nhgri-ebi gwas catalog of published genome-wide association
studies, targeted arrays and summary statistics 2019. nucleic acids res. 47, d1005–d1012
(2019).
8. ben-israel, d. et al. the impact of machine learning on patient care: a systematic review. artif.
intell. med. 103, 101785 (2020).
9. dimiduk, d. m., holm, e. a. & niezgoda, s. r. perspectives on the impact of machine learning,
deep learning, and artificial intelligence on materials, processes, and structures engineering.
integrating mater. manuf. innov. 7, 157–172 (2018).
10. choy, g. et al. current applications and future impact of machine learning in radiology.
radiology 288, 318–328 (2018).
11. athey, s. the impact of machine learning on economics. econ. artif. intell. agenda 507–547
(2018).
12. towards green ict strategies: assessing policies and programmes on ict and the
environment. vol. 155 https://www.oecd-ilibrary.org/science-and-technology/towards-green-ict-
strategies_222431651031 (2009).
13. sarkar, s. & misra, s. theoretical modelling of fog computing: a green computing paradigm to
support iot applications. iet netw. 5, 23–29 (2016).
15
14. gai, k., qiu, m., zhao, h., tao, l. & zong, z. dynamic energy-aware cloudlet-based mobile
cloud computing model for green computing. j. netw. comput. appl. 59, 46–54 (2016).
15. goodfellow, i., bengio, y. & courville, a. deep learning. (mit press, 2016).
16. schwartz, r., dodge, j., smith, n. a. & etzioni, o. green ai. arxiv190710597 cs stat (2019).
17. strubell, e., ganesh, a. & mccallum, a. energy and policy considerations for deep learning in
nlp. arxiv190602243 cs (2019).
18. lacoste, a., luccioni, a., schmidt, v. & dandres, t. quantifying the carbon emissions of
machine learning. arxiv191009700 cs (2019).
19. henderson, p. et al. towards the systematic reporting of the energy and carbon footprints of
machine learning. arxiv200205651 cs (2020).
20. wright, l. a., kemp, s. & williams, i. ‘carbon footprinting’: towards a universally accepted
definition. carbon manag. 2, 61–72 (2011).
21. hill, n. et al. 2020 government greenhouse gas conversion factors for company reporting:
methodology paper. dep. bus. energy ind. strategy 128 (2020).
22. kyoto protocol to the united nations framework convention on climate change. (1997).
23. ritchie, h. & roser, m. co₂ and greenhouse gas emissions. our world data (2020).
24. fourth assessment report — ipcc. https://www.ipcc.ch/assessment-report/ar4/.
25. geng, h. data center handbook. (john wiley & sons, 2014).
26. karyakin, a. & salem, k. an analysis of memory power consumption in database systems. in
proceedings of the 13th international workshop on data management on new hardware -
damon ’17 1–9 (acm press, 2017). doi:10.1145/3076113.3076117.
27. angelini, c., august 29, i. w. & 2014. intel core i7-5960x, -5930k and -5820k cpu review:
haswell-e rises. tom’s hardware https://www.tomshardware.com/uk/reviews/intel-core-i7-
5960x-haswell-e-cpu,3918-13.html.
28. tomes, e. & altiparmak, n. a comparative study of hdd and ssd raids’ impact on server
energy consumption. in 2017 ieee international conference on cluster computing (cluster)
625–626 (2017). doi:10.1109/cluster.2017.103.
29. belady, c. l. & malone, c. g. metrics and an infrastructure model to evaluate data center
efficiency. in 751–755 (american society of mechanical engineers digital collection, 2010).
doi:10.1115/ipack2007-33338.
30. avelar, v., azevedo, d., french, a. & power, e. n. pue: a comprehensive examination of the
metric. white pap. 49, (2012).
31. andy lawrence. is pue actually going up? uptime institute blog
https://journal.uptimeinstitute.com/is-pue-actually-going-up/ (2019).
32. efficiency – data centers – google. google data centers
https://www.google.com/about/datacenters/efficiency/.
33. gao, j. machine learning applications for data center optimization. (2014).
34. tranberg, b. et al. real-time carbon accounting method for the european electricity markets.
energy strategy rev. 26, 100367 (2019).
35. carbonfootprint.com - international electricity factors.
https://www.carbonfootprint.com/international_electricity_factors.html.
16
36. helmers, e., leitão, j., tietge, u. & butler, t. co2-equivalent emissions from european
passenger vehicles in the years 1995–2015 based on real-world use: assessing the climate
benefit of the european “diesel boom”. atmos. environ. 198, 122–132 (2019).
37. us epa, o. greenhouse gas emissions from a typical passenger vehicle. us epa
https://www.epa.gov/greenvehicles/greenhouse-gas-emissions-typical-passenger-vehicle
(2016).
38. carbon footprint calculator. https://calculator.carbonfootprint.com/calculator.aspx?tab=3.
39. ritchie, h. & roser, m. greenhouse gas emissions. our world in data
https://ourworldindata.org/greenhouse-gas-emissions.
40. akbari, h. shade trees reduce building energy use and co2 emissions from power plants.
environ. pollut. 116, s119–s126 (2002).
41. emissions – global energy & co2 status report 2019 – analysis. iea
https://www.iea.org/reports/global-energy-co2-status-report-2019/emissions.
42. agostinelli, s. et al. geant4—a simulation toolkit. nucl. instrum. methods phys. res. sect. accel.
spectrometers detect. assoc. equip. 506, 250–303 (2003).
43. jan, s. et al. gate - geant4 application for tomographic emission: a simulation toolkit for pet
and spect. phys. med. biol. 49, 4543–4561 (2004).
44. jan, s. et al. gate v6: a major enhancement of the gate simulation platform enabling
modelling of ct and radiotherapy. phys. med. biol. 56, 881–901 (2011).
45. sarrut, d. et al. a review of the use and potential of the gate monte carlo simulation code for
radiation therapy and dosimetry applications. med. phys. 41, 064301 (2014).
46. meylan, s. et al. simulation of early dna damage after the irradiation of a fibroblast cell nucleus
using geant4-dna. sci. rep. 7, (2017).
47. schweitzer, p. et al. performance evaluation of multithreaded geant4 simulations using an intel
xeon phi cluster. scientific programming vol. 2015 e980752
https://www.hindawi.com/journals/sp/2015/980752/ (2015).
48. apostolakis, j. et al. validation and verification of geant4 standard electromagnetic physics. j.
phys. conf. ser. 219, 032044 (2010).
49. geant4 - an object-oriented toolkit for simulation in hep. gitlab
https://gitlab.cern.ch/geant4/geant4/tree/edb408b5618b3b1cd3f40c5759aa5da4aa56bb7b/exa
mples/extended/electromagnetic/testem5.
50. neumann, p. et al. assessing the scales in numerical weather and climate predictions: will
exascale be the rescue? philos. trans. r. soc. math. phys. eng. sci. 377, 20180148 (2019).
51. keeley, s. modelling and prediction: integrated forecast system. ecmwf
https://www.ecmwf.int/en/research/modelling-and-prediction (2013).
52. zängl, g., reinert, d., rípodas, p. & baldauf, m. the icon (icosahedral non-hydrostatic)
modelling framework of dwd and mpi-m: description of the non-hydrostatic dynamical core. q.
j. r. meteorol. soc. 141, 563–579 (2015).
53. wetter und klima - deutscher wetterdienst - numerical weather prediction models - icon
(icosahedral nonhydrostatic) model.
https://www.dwd.de/en/research/weatherforecasting/num_modelling/01_num_weather_predict
ion_modells/icon_description.html.
17
54. baylis, s. green computing. (2011) doi:10.21957/cemub9f8.
55. wetter und klima - deutscher wetterdienst - information technology - data processing, dmrz.
https://www.dwd.de/en/aboutus/it/functions/teasergroup/dataprocessing.html?nn=24864.
56. león, j. a. p. progress in using single precision in the ifs. ecmwf
https://www.ecmwf.int/en/newsletter/157/meteorology/progress-using-single-precision-ifs
(2018).
57. lentze, g. ecmwf signs contract with atos for new supercomputer. ecmwf
https://www.ecmwf.int/en/about/media-centre/news/2020/ecmwf-signs-contract-atos-new-
supercomputer (2020).
58. ecmwf. ecmwf q&a. https://www.ecmwf.int/sites/default/files/medialibrary/2019-
02/industry_day_-_qa.pdf.
59. devlin, j., chang, m.-w., lee, k. & toutanova, k. bert: pre-training of deep bidirectional
transformers for language understanding. arxiv181004805 cs (2019).
60. beltagy, i., lo, k. & cohan, a. scibert: a pretrained language model for scientific text. in
proceedings of the 2019 conference on empirical methods in natural language processing and
the 9th international joint conference on natural language processing (emnlp-ijcnlp) 3615–
3620 (association for computational linguistics, 2019). doi:10.18653/v1/d19-1371.
61. lee, j. et al. biobert: a pre-trained biomedical language representation model for biomedical
text mining. bioinformatics 36, 1234–1240 (2020).
62. nvidia ai. bert meets gpus – future vision – medium.
https://web.archive.org/web/20190521104957/https://medium.com/future-vision/bert-meets-
gpus-403d3fbed848 (2019).
63. adiwardana, d. et al. towards a human-like open-domain chatbot. arxiv200109977 cs stat
(2020).
64. teich, p. tearing apart google’s tpu 3.0 ai coprocessor. the next platform
https://www.nextplatform.com/2018/05/10/tearing-apart-googles-tpu-3-0-ai-coprocessor/
(2018).
65. allen, m. r. et al. a solution to the misrepresentations of co 2 -equivalent emissions of short-
lived climate pollutants under ambitious mitigation. npj clim. atmospheric sci. 1, 1–8 (2018).
66. cutress, i. why intel processors draw more power than expected: tdp and turbo explained.
https://www.anandtech.com/show/13544/why-intel-processors-draw-more-power-than-
expected-tdp-turbo.
67. sa.gov.au - sa’s electricity supply and market. https://www.sa.gov.au/topics/energy-and-
environment/energy-supply/sas-electricity-supply-and-market.
68. zoie, r. c., mihaela, r. d. & alexandru, s. an analysis of the power usage effectiveness metric
in data centers. in 2017 5th international symposium on electrical and electronics engineering
(iseee) 1–6 (2017). doi:10.1109/iseee.2017.8170650.
69. yuventi, j. & mehdizadeh, r. a critical analysis of power usage effectiveness and its use in
communicating data center energy consumption. energy build. 64, 90–94 (2013).
70. iso/iec 30134-2:2016(en), information technology — data centres — key performance
indicators — part 2: power usage effectiveness (pue). https://www.iso.org/obp/ui/#iso:std:iso-
iec:30134:-2:ed-1:v1:en.
18
71. mccarthy, r. & yang, c. determining marginal electricity for near-term plug-in and fuel cell
vehicle demands in california: impacts on vehicle greenhouse gas emissions. j. power sources
195, 2099–2109 (2010).
72. shehabi, a. et al. united states data center energy usage report. (2016).
73. azure global infrastructure | microsoft azure. https://azure.microsoft.com/en-gb/global-
infrastructure/.
74. carbonfootprint.com - carbon offset projects.
https://www.carbonfootprint.com/carbonoffsetprojects.html.
75. project map – climatecare. https://climatecare.org/project-map/.
76. michaelowa, axel, shishlov, igor, hoch, stephan, bofill, patricio & espelage, aglaja. overview
and comparison of existing carbon crediting schemes. https://www.nefco.org/wp-
content/uploads/2019/05/nica-crediting-mechanisms-final-february-2019.pdf (2019).
77. emissions trading | unfccc. https://unfccc.int/process/the-kyoto-
protocol/mechanisms/emissions-trading.
78. pas 2060 carbon neutrality. https://www.bsigroup.com/en-gb/pas-2060-carbon-neutrality/.
79. united nations. transforming our world: the 2030 agenda for sustainable development.
https://www.un.org/ga/search/view_doc.asp?symbol=a/res/70/1&lang=e (2015).
80. the gold standard. https://www.goldstandard.org/.
81. verra. verra https://verra.org/.
82. american carbon registry. https://americancarbonregistry.org/.
acknowledgements
ll was supported by the university of cambridge mrc dtp (mr/s502443/1). jg was supported by
a la trobe university postgraduate research scholarship jointly funded by the baker heart and
diabetes institute and a la trobe university full-fee research scholarship. this work was
supported by core funding from: the uk medical research council (mr/l003120/1), the british heart
foundation (rg/13/13/30194; rg/18/13/33946) and the national institute for health research
[cambridge biomedical research centre at the cambridge university hospitals nhs foundation
trust] [*]. this work was also supported by health data research uk, which is funded by the uk
medical research council, engineering and physical sciences research council, economic and
social research council, department of health and social care (england), chief scientist office of
the scottish government health and social care directorates, health and social care research
and development division (welsh government), public health agency (northern ireland), british
heart foundation and wellcome. mi was supported by the munz chair of cardiovascular prediction
and prevention. this study was supported by the victorian government’s operational infrastructure
support (ois) program.
*the views expressed are those of the authors and not necessarily those of the nhs, the nihr or
the department of health and social care.
19
supplementary materials
supplementary figure 1: comparison of power draw (per core) between popular cpus and
memory.
20
supplementary figure 2: worldwide carbon intensity distribution by countries, curated from
carbon footprint35.
supplementary note 1
we estimated the annual ghg emissions of data centres to be around 100 mt co e using two
2
distinct approaches. first, using the total electricity demand of data centres, estimated to be around
200 twh1 (1% of global demand) and the world average carbon intensity (475 gco e/kwh41).
2
equation (3) (methods) gives a total footprint of 95 x 106 tco e. another estimation is based on data
2
centres being responsible for 0.3% of global emissions1 (0.3% of 36 x 109 tco e23), which yields
2
108 x 106 tco e.
2
21"
3,A Systematic Review of Green AI.pdf,"
a systematic review of green ai
robertoverdecchia junesallou luíscruz
vrijeuniversiteitamsterdam tudelft tudelft
amsterdam,thenetherlands delft,thenetherlands delft,thenetherlands
r.verdecchia@vu.nl j.sallou@tudelft.nl l.cruz@tudelft.nl
abstract
a systematic review of green ai
withtheever-growingadoptionofai-basedsystems,thecarbon roberto verdecchia, june sallou, luis cruz
footprintofaiisnolongernegligible.airesearchersandpracti- systematic literature type of studies
tionersarethereforeurgedtoholdthemselvesaccountableforthe review
carbonemissionsoftheaimodelstheydesignanduse.thisledin 98
3202 primary
recentyearstotheappearanceofresearchestacklingaienviron-
studies position papers observational solution papers
mentalsustainability,afieldreferredtoasgreenai.despitethe (11) studies (35) (52)
rapidgrowthofinterestinthetopic,acomprehensiveoverviewof green ai topics
greenairesearchistodatestillmissing.toaddressthisgap,inthis
naj
paper,wepresentasystematicreviewofthegreenailiterature.
fromtheanalysisof98primarystudies,differentpatternsemerge. footprint hyperparameter benchmarking deployment precision/energy algorithm other
monitoring tuning trade off design
62 thetopicexperiencedaconsiderablegrowthfrom2020onward. recurrent green ai most considered ai most considered artefacts
moststudiesconsidermonitoringaimodelfootprint,tuninghy- domains phase
perparameterstoimprovemodelsustainability,orbenchmarking
]ia.sc[ models.amixofpositionpapers,observationalstudies,andsolu-
tionpapersarepresent.mostpapersfocusonthetrainingphase, general edge computing training phase additia oi n m ao l d fel is ndingsdata ai pipeline
arealgorithm-agnosticorstudyneuralnetworks,anduseimage
recurrent algorithm
data.laboratoryexperimentsarethemostcommonresearchstrat-
neural
egy.reportedgreenaienergysavingsgoupto115%,withsavings
network research energy industry tool
over50%beingrathercommon.industrialpartiesareinvolvedin strategies savings involvement availability
1v74011.1032:vixra greenaistudies,albeitmosttargetacademicreaders.greenaitool
provisioningisscarce.asaconclusion,thegreenairesearchfield
resultstohavereachedaconsiderablelevelofmaturity.therefore,
graphicalabstract:fromasystematicreviewofthegreen
fromthisreviewemergesthatthetimeissuitabletoadoptother
ai literature, green ai results to focus on solutions, and
greenairesearchstrategies,andportthenumerouspromising
is often not bound to a specific context or algorithm. the
academicresultstoindustrialpractice.
greenairesearchfieldresultstobemature,i.e.,themoment
issuitabletoportresultsfromacademicresearchtoindus-
trialpractice.
1 introduction
system’slifecycle(e.g,datacollection,training,monitoring),dif-
inrecentyears,theartificialintelligence(ai)communityhasbeen ferentartifacts(e.g.,data,model,pipeline,architecture,hardware),
challengedtobringthecarbonfootprintofaimodelstothetop etc[3].
oftheirresearchagenda.theiconicpaperbystrubelletal.[93] giventheheterogeneityofthefield,itisalsodifficulttohavea
analyzesthecarbonimpactoftrainingtheirownstate-of-the-art broadviewofallthegreenailiteraturethathasbeenpublishedin
models.resultsleadtotheconclusionthatweneedtoreducethe thepastyears.tounderstandtheexistingresearch,weconducta
carbonfootprintofdevelopingandrunningaimodels. systematicliteraturereviewongreenai.weprovideanoverview
thisself-reflectionwasaneye-openertotheairesearchcommu- andcharacterizationoftheexistingresearchinthisfield.moreover,
nity.manypapersfollowed,callingforanewresearchdirectionthat westudyhowthefieldhasbeenevolvingovertheyears,pinpoint
wouldconsiderthisproblem.schwartzetal.coinedthetermgreen themaintopics,approaches,artifacts,andsoon.
aias“airesearchthatyieldsnovelresultswhiletakingintoaccount thisliteraturereviewshowsthattherehasbeenasignificant
thecomputationalcost”[88].benderetal.publishedapositionpaper growthingreenaipublications–76%ofthepapershavebeenpub-
highlightingtheconsequencesofcontinuouslyincreasingthesize lishedsince2020.themostpopulartopicsrevolvearoundmonitor-
ofaimodels[27].anaturalquestionthatisposediswhetherwe ing,hyperparametertuning,deployment,andmodelbenchmarking.
aredoingenoughasaresearchcommunitytomitigatethecarbon wealsohighlightotheremergingtopicsthatmightleadtointer-
impactofdevelopingandrunningai-basedsoftware. estingsolutions–namely,datacentricgreenai,precision/energy
aisystemsaresignificantlycomplexand,toachievegreenai, trade-off analysis.thecurrentbodyofresearchhasalreadyshow-
weneedajointeffortthattargetsallthedifferentstagesofanai casedpromisingresultswithenergysavingsfrom13%upto115%.
robertoverdecchia,junesallou,andluíscruz
still,mostoftheexistingworkfocusesonthetrainingstageofthe literatureindexingplatformstoexecutetheautomatedsearchal-
aimodel.moreover,weobservethatthereislittleinvolvement lowsustoconductanencompassingsearchoftheliteraturebased
oftheindustry(23%)andthatmoststudiesrevolvearoundlabora- onmultiplesources,henceallowingustomitigatepotentialthreats
toryexperiments.wearguethatthefieldisgrowingtoalevelof toexternalvalidity,asfurtherdocumentedinsection5.following,
maturityinwhichinvolvementoftheindustryisquintessentialto thedetailsofeachstepofourresearchprocessaredocumented
enabletheoverarchinggoalofgreenai:harnessthefullpotential indetail.
ofaiwithoutanegativeimpactinourplanet. 2.2.1 automatedinitialsearch.toidentifyapreliminarysetof
toencourageopenscienceandthereproducibilityofthisstudy, potentiallyrelevantresearchworks,wedesignanencompassing
weprovidealldataandscriptsinareplicationpackageavailable automatedquerytobeexecutedonthreedifferentliteraturein-
onlinewithanopensourcelicense1.
dexers, namely google scholar, scopus, and web of science. the
theremainderofthispaperisstructuredasfollows.insection2, automatedquerytargettingpublicationtitlesstatesasfollows:
wedescribethemethodologyusedtocollectandanalyzegreen
ailiterature.insection3,wepresentalltheresultsyieldedbyour
methodology.section4discussesfindingsandreflectsontheimpact
ofourresultsintheresearchcommunity.insection5,wereflect
on the potential threats of the validity of this study. following, listing1:automatedsearchquery
section6describesrelatedworkandpinpointsthedifferenceswith 1 intitle(""green"" or ""sustainab*"") and
ourstudy.themainconclusionsandfutureworkarepresentedin 2 intitle(""ai"" or ""ml"" or ""artificial␣intelligence""
section7. 3 or ""machine␣learning"" or ""deep␣learning"")
2 methodology thequeryisdesignedtoretrieveliteraturewithtitlescontaining
inthissection,wedocumenttheresearchdesign,whichwasrigor- keywordsrelatedtosustainability,identifiedbythekeywordsgreen
ouslyadheredtoduringtheplanningandexecutionofthestudy.we or sustainability and its variations, e.g., “sustainable” (listing 1,
primarilyfollowedtheguidelinesforconductingslrsinsoftware lines1).thesecondpartofthequeryinsteadisusedtoretrieve
engineeringresearchpresentedbykitchenham[6]. literatureconcerningai,orrelatedsynonymsandacronyms(list-
ing1,lines2-3).thequeryisexecutedonthethreeaforementioned
2.1 researchobjectiveandquestion literaturelibrariesandindexesonthe18thofjuly2022,andled
thegoalofthisreviewistounderstandthecharacteristicsofex- totheidentificationof190potentiallyrelevantstudies.inorder
istinggreenairesearch.byutilizingthegoal-question-metric tobeascomprehensiveaspossible,andavoidpotentialthreatsto
method[1],thisobjectivecanbedescribedmoreformallyasfollows: externalvalidity,theyearofpublicationisleftunboundedinthe
automatedsearch.
analyzegreenailiterature 2.2.2 applicationofselectioncriteria.subsequenttotheidenti-
ficationoftheinitialpotentiallyrelevantstudies,weexecutethe
forthepurposeofknowledgecollectionandcategorization
manualselectionofthestudiesviaasetofselectioncriteriadefined
withrespecttoai
apriori.apaperisconfirmedasprimarystudyifitadherestoall
fromtheviewpointofresearchersandpractitioners
inclusioncriteria,andnoneoftheexclusionones.thefollowing
inthecontextofenvironmentalsustainability.
inclusion(i)andexclusion(e)criteriaareused:
thegoalofthisresearchcanbedirectlytranslatedinaresearch
question(rq),whichstatesasfollows: i1- thestudyregardsai
i2- thestudyregardsenvironmentalsustainability
rq1: whatarethecharacteristicsofgreenaistate-of-the-artre-
i3- thestudyregardstheenvironmentalsustainabilityofai
search?
i4- thestudyregardsthesoftwarelevel
byansweringourresearchquestion,weaimatgainingasystem- e1- thestudyisnotwritteninenglish
aticoverviewofthegreenaibodyofknowledge,startingfrom e2- thestudyisnotavailable
anoutlineofthegeneralpublicationtrends,toadetailedanaly- e3- thestudyisaduplicateorextensionsofanalreadyincluded
sisofthepastandcurrentgreenairesearchactivitiesandtheir study
characteristics. e4- thestudyisasecondaryortertiarystudy
e5- thestudyisintheformofeditorials,tutorials,books,ex-
2.2 researchprocess
tendedabstracts,etc.
anoverviewoftheresearchprocessfollowedisdepictedinfigure1. e6- thestudyisanon-scientificpublicationorgreyliterature
theprocessstartswiththeexecutionofaconservativeautomated
searchqueryviathedigitallibrariesandindexingplatformsgoogle withthefirstthreeinclusioncriteria(i1-i3),weensurethatthe
scholar,scopus,andwebofscience,complementedbyasubsequent primarystudiesfocusongreenai(i1,i2),andthatthestudies
iterativebidirectionalsnowballingprocess,whichisconductedun- regardtheenvironmentalsustainabilityof ai,ratherthantheim-
tiltheachievementoftheoreticalsaturation.includingmultiple provementofenvironmentalsustainabilitythroughai.withthe
fourthinclusioncriterioninstead(i4),weensurethattheprimary
studiesfocusonsoftware-centricgreenai.thislattercriterionis
1replicationpackage:https://github.com/luiscruz/slr-green-ai usedtoexcludestudiesfocusingonhardware-specificgreenai
asystematicreviewofgreenai
190 16 98 data extraction
automated initial application of snowballing
and report
search selection criteria (2 iterations)
data synthesis
144 21
25
google web of
scopus
scholar science
figure1:systematicliteraturereviewprocessoverview.
techniques,e.g.,theuseofadhocimplementedhardwarecompo- thefirstphaseconsistsofadataexplorationprocess,which
nents,whichweconsideroutofreachformostresearchers/practi- terminateswiththeestablishmentofthedataextractionframework
tionersinterestedingreenai,andisonlymarginaltothedefinition ofthisstudy.specifically,duringthisfirstphase,thethreeauthors
ofgreenaiitself[88]. ofthisreviewindependentlyscantheidentifiedprimarystudies,
theexclusioncriteriaaredesignedtoensurethatdatacanbe andannotatethecharacteristicsofthestudieswhicharerelevant
extractedfromthepapers(e1,e2),donotrepresentduplicationor toanswerourrq.theidentifiedcharacteristicsarethenjointly
redundancywithrespecttootherprimarystudies(e3,e4),andare discussedandrefined,leadingtotheconsolidationofthefields
providedintheformofscientificstudies(e5,e6). constitutingthedataextractionframeworkofthisreview.
toeasetheprimarystudyselectionprocess,adaptivereading in the second data extraction phase, the primary studies are
depth[11]isusedtoefficientlyassesspotentiallyrelevantstudies. thoroughlyanalyzed,andthedataisextractedfromthestudies
inordertomitigatesubjectivebiasesandinterpretations,thethree accordingtothedataextractionframework.
authorsindependentlyutilizedtheselectioncriteriatoscrutinize63- the fields of the data extraction framework utilized for this
64candidatestudies.weeklymeetingareheldduringtheselection literaturereviewongreenaiarethefollowing.
processtojointlydiscussexamples,doubts,andaligntheselection
processbetweenthethreeresearchers. • studytype:theoverarchingtypeofstudy,whichcouldbe
theapplicationoftheselectioncriteriaconcludeswiththeiden- eitherpresentingapositionongreenai,agreenaisolution,
tificationof16primarystudies,whichconstitutethestartingset oranobservationalstudyongreenai;
forthesubsequentsnowballingprocess. • topic:thegreenaitopicconsideredinthestudy,e.g.,hyperparameter-
2.2.3 snowballing.inordertoenrichthesetofselectedprimary tuningtoachieveenergyefficiencyofanaialgorithm;
studies,andensurethattheprimarystudycomprehensivelyrepre- • domain:thedomainconsideredinthestudy,e.g.,edgeor
sentsthegreenaibodyofliterature,theautomatedsearchresults mobilecomputing;
arecomplementedwitharecursivebidirectionalsnowballingpro- • typeofdata:thetypeofdatautilizedbyaiinthestudy,e.g.,
cess[17].thisstepentailsthescrutinyofallstudieseitherciting textorimages;
orcitedbythealreadyincludedprimarystudies.asfortheappli- • artifactconsidered:theaiartifactconsideredinthestudy,
cationofselectioncriteria,threeresearchersareinvolvedinthe e.g.,thedatausedbyaimodels,theaimodelsthemselves,
snowballing.duringeachsnowballinground,theresearchersin- ortheaideploymentpipeline.
dependentlysnowballdifferentprimarystudies,andproposenew • consideredphase: ifthestudyfocusedontheaitraining
primarystudiestobeincluded,i.e.,thenewidentifiedstudieswhich phase,theaiinferencephase,orboth.
adheretotheselectioncriteria.duringeachsnowballinground,ex- • researchstrategy:theresearchstrategy,asdefinedin[14],
amples,doubts,anddivergencesarejointlyrevisitedandresolved, usedtosupporttheclaimsreportedinthestudy;
andthenextsnowballingiterationisstarted.atotaloftworounds • datasetsize:thesizeofthedataset,innumberofdatapoints,
ofbackwardandforwardsnowballingareexecutedbeforenonew consideredinthestudy(ifany);
studiesareidentified,i.e.,whentheoreticalsaturationisreached. • energy savings: the reported percentage energy savings
thesnowballingprocessterminateswiththeinclusionof82new achievedbysolutionsreportedinthestudy(ifanyisdocu-
primariesstudies,leadingtoatotalof98primarystudieswhichare mented);
consideredintheliteraturereviewreportedinthisresearch. • industryinvolvement:industryinvolvementintheauthor-
shipofthestudy,whichcouldbeeitheracademic-onlyau-
2.2.4 data extraction.in order to achieve the intended goal of
thorship,industrial-onlyauthorship,ormixedauthorship;
this study and answer our rq (see section 2.1), we proceed to
systematically extract data from the primary studies. the data • intendedreader:ifthestudyisprimarilyintendedforaca-
demicreaders,industrialreaders,orthegeneralpublic.
extractionprocessconsistedoftwosubsequentphases.
• toolavailability:theavailabilityofthetool(s)toaddress
greenaipresentedinthestudy(ifany).
robertoverdecchia,junesallou,andluíscruz
2.2.5 datasynthesis.duringthedataextractionprocess,thedata 52
washarmonizedbyrelyingontheconstantcomparison[2]ofex-
tractedkeywords,breakingupkeywordsintomorespecificones 40 35
whentheirsemanticdepthrequiredit,ormergingverysimilarkey-
wordstoavoidredundancy.thisanalysisprocessreliedonopen 20
11
coding[4]tosystematicallyidentifyrecurrentconcepts,followed
byaxialcoding[4]tomanagetheincreasingcomplexityofsome 0
emergingconcepts. solution observational position
the only exceptions were made for the research strategy, in- study type
dustry involvement, and tool availability fields of the extraction
framework(seesection2.2.4),forwhichprovisionalcodingwas figure3:numberofpublicationsperstudytype.
used[4].specifically,codingoftheresearchstrategyreliedonthe
researchstrategycategoriesreportedbystoletal.[14]wasused.
theindustryinvolvementinsteadreliedonthreepre-definedfields, 3.2 venuetypes
namely“academic-onlyauthorship”,“industrial-onlyauthorship”, publicationsareparticularlyconcentratedonconferences(⊲47out
or“mixedauthorship”.finally,toolavailabilitycouldonlyassume of98papers.)andjournals(⊲39outof98papers.).only12outof
oneoftwopre-definedvalues,namely“yes”(ifthetoolisavailable) the98publicationsareassociatedwithaworkshop.conferences
or“no”(ifthetoolisnotavailable,ornoneispresentedinthe beingtreatedasanequalpublishingvenueasjournalsfollowsthe
primarystudy). trendsobservedinthecomputerscienceresearchfield[5,16].
duringthedataextractionandsynthesisphase,emergingcodes
arecontinuouslydiscussedamongthethreeauthorsofthereview. greenaipublicationtrends
thisprocessensuresthattheemergingcodesandtheirabstraction ¤thetopicofgreenaiisexperiencinganincreasingtrend
levelarekeptconsistentamongresearchers,andarealignedwith ofpopularity,withaconsiderablegrowthinpublicationsfrom
theresearchgoalandquestionofthestudy. 2020onward.moststudiesarepublishedinconferencesand
journals,whileonlyaminorportioninworkshops.
3 results
inthissection,wepresenttheresultscollectedwithourslron
3.3 studytypes
greenai.
existingliteratureongreenaispansacrossthreetypesofstudies,
3.1 publicationyears namelyobservational,solution,andpositionpapers(seealsosec-
theliteraturespansfrom2015withthefirstpublicationonthetopic tion2.2.4).asshowninfigure3,fromthe98paperscoveredin
tothispresentyear(i.e.,2022).figure2presentsthedistribution thisreview,themostcommonaresolutionpapers,with52entries,
oftheliteraturepapersregardingthepublicationyear.weobserve followedbyobservationalwith35,andpositionpaperswith11.
aglobalincreasefollowingtheyears.furthermore,aspikeinthe notethatstudytypesaremutuallyexclusive,i.e.,asinglepaperhas
numberofpublicationsisseenin2020,goingfrom7publications onlyonestudytype.
in2019to20in2020.astheautomatedinitialsearchwaslaunched
in2022,thepublicationtrendsreportedinthisreviewmightnot
3.4 greenaitopics
berepresentativeoftheactualresearchoutputof2022(seealso
fromouranalysisweidentify13maintopicsbeingaddressedbythe
section2.2.1).
greenailiterature.figure4depictsthedistributionofpublications
acrossthedifferenttopics.themostpopulartopicismonitoring,
addressedby28papers,followedbyhyperparametertuning(18),
33 modelbenchmarking(17),deployment(17),andmodelcomparison
30 (17).sincepapersarenotexclusivetoasingletopic,thesetop-4
topicsalonecover61%ofthepapersinthisreview.below,wepin-
20 21 pointeachtopicwithashortsummaryandtherespectivenumber
20
ofpublications.
10 monitoring ⊲ 28 out of 98 papers. covering monitoring ap-
6 7 7 proachestostudytheenergyand/orcarbonfootprintofaimodels.
3
1 inthistopic,papersreportandreflectontheenergyfootprint
0
2015 2016 2017 2018 2019 2020 2021 2022 ofstate-of-the-artmodelsthroughouttheirlifecycle.forexample,
wuetal.[106]providealandscapeofthecarbonfootprintofai
year
modelsacrossfacebook.findingsshowcasethat,typically,through-
outthelifetimeofaimodels,50%oftheircarboncostliesinthe
figure2:numberofpublicationsperyear.
embodiedcarbonfootprintofthehardwareusedtodevelopthese
models.however,thepapershowsthatthevastmajorityoftraining
workflowsunder-utilizesgpusat30–50%oftheirfullcapacity.
asystematicreviewofgreenai
otherpaperswithinthistopicfocusonsolutionstomakecarbon someworksproposesmallchangestothealgorithmsthatmakea
monitoring feasible in any ai project [44]. as an example, the bigdifferenceinthefinalenergyconsumption.forexample,garcia-
carbontrackeroffersatoolsettotrackandpredicttheenergyand martinetal.[42]approximatethesplittingcriteriabyselecting
carbonfootprintoftrainingdlmodels[22].thesestudiesargue branchesthatrequirelesscomputationaleffort.resultsshowcase
thatitisquintessentialtoreporttheenergyandcarbonfootprint decisiontreesthatareupto31%moreenergyefficientandwith
ofmodeldevelopmentandtrainingalongsideperformancemetrics. minimalimpactonaccuracy.otherexamplesincludeespnetv2[77],
alightweightconvolutionalneuralnetworkdesignedwithpower-
hyperparametertuning ⊲18outof98papers.improvingor
efficiencyinmind.
assessing the impact on the energy consumption of optimizing
hyperparameterswhentraininganaimodel. libraries ⊲8outof98papers.ourchoiceoflibrarieshavean
manypublicationsaremotivatedbythefactthattuningparame- impactonthefinalcarbonfootprintofaisystems.studieswithin
tersleadstosignificantenergycosts–itrequiresretrainingamodel thistopicprovidesomesortofevaluationofdifferentailibraries
multipletimesinordertofindtheoptimalsetofhyperparameter andhowtheycontributetoenergyefficiency.
values.hence,mostpublicationswithinthistopicfocusoniden- thiscategoryshowsthatsoftwareengineeringstudiesplayan
tifyingalternativestrategiesthatreducethenumberofiterations importantroleinenablinggreenai.georgiouetal.[46]compare
requiredtotunehyperparameters[91]. theenergyfootprintofdeeplearningframeworks.resultsshowcase
onadifferentperspective,chavannesetal.[83]explorehow thatpytorchismoreenergy-efficientthantensorflowatthetrain-
hyperparametertuningcanhelpdelivermoreenergy-efficientmod- ingstage.however,tensorflowtendstobemoreenergy-efficientat
elsbyaddingpowerconsumptiontothesetofparametersbeing theinferencestage.thestudydelvesintotheframework’sdifferent
optimized. apimethodsandhighlightscodeintheframeworksthatshouldbe
optimizedtoreduceenergyconsumption.finally,theauthorsmoti-
modelbenchmarking. ⊲17outof98papers.studiesthatcon-
vatetheimportanceofreportinganddiscussingenergyefficiency
tributewithbenchmarkstocomparetheenergyfootprintofdiffer-
inthedocumentationofdeeplearningframeworks.
entmodelsortrainingtechniques.
benchmarkshelpthecommunityunderstandhowthestateof datacentric ⊲6outof98papers.typically,theaicommunity
the art behaves w.r.t. given performance indicators. ultimately, haslookedintocomingupwithbettermodeltrainingstrategies.
theyhelpcreatebaselinessothatnewapproachescanbeprop- however,thereisanewtrendinaithatisraisingtheimportance
erlyvalidatedandcomparedtothestateoftheart.asexampleof ofdevelopingbetterdatacollectionandprocessingtechniquesasa
publicationswithinthiscategory,aspertietal.[23]evaluatethe moreeffectivewaytodeliverbetteraimodels.thislineofthought
energycostofdifferentvariationalautoencoders.anotherstudy,by withingreenaiaimsatreducingthecarbonfootprintofaiby
yuetal.[113],comparestheenergyefficiencyofcommonmachine tacklingtheproblematthedatalevel.
learningalgorithmswhenappliedtoclinicallaboratorialdatasets. data-centricapproachesforgreenaishowthatfeatureselection
deployment ⊲17outof98papers.addressingthedeployment andsubsamplingtechniquescansignificantlyreducetheenergy
stageofthelifecycleofanaimodel. consumptionoftrainingmachinelearningmodels[98].subsam-
typically,publicationsinthistopicdiscusstheproblemofde- plingstrategiescanbemoresophisticatedbyremovingdatapoints
ployingaimodelsinarealscenarioorinascenariowithpecu- thatareexpectedtoberedundantintermsofknowledgeacquisi-
liarconstraintsthatchallengeastandardapproach.forexample, tion[35].
deployment publications showcase the challenges of deploying
network architecture ⊲ 6 out of 98 papers. the impact of a
energy-efficientaiinfpga[97],inedgedevices[47,64],inmobile
distributednetworkontheenergyefficiencyofai.aimodelsare
devices[58,75,100],andsoon.
oftendeployedinadistributedcontext–e.g.,iot,edgecomputing,
precision/energytradeoff ⊲11outof98papers.thereisa etc.hencethedesignandarchitectureofthenetworkplaysan
turningpointwheretoincreaseaverysmallfractionofthemodel importantroleinleveragingsustainablemodels.
performance,itisrequiredtoendureanenergy-intensivetraining forexample,kimandwu[64]proposeanadaptiveexecution
loop.withinthistopic,papersaddresstheparetotrade-offbetween enginethatselectstheinferencestrategyaccordingtothesignal
havingoptimalaccuracyand/oroptimalenergyefficiency. strengthofthenetworkindifferentdevices,asitisknowntoaffect
zhangetal.[114]studyhowremovingneuronsfromneural theenergyefficiencyoftheedgemobilesystem.
networksaffectsbothaccuracyandenergyconsumption.results
estimation ⊲5outof98papers.collectingandmakingsense
indicate that a good portion of neurons are redundant and can
ofenergyorclimatedataisfarfromtrivial–manydifferentfactors
beremovedtoreduceenergyconsumptionwithoutasignificant
contributetothefinalestimation[44].thistopicrevolvesaround
impactonaccuracy.atthesametime,itshowsthatthereisaturning
understandingwaysofestimatingtheenergyconsumptionorcar-
point where removing neurons improves energy efficiency but
bonfootprintofmodels.
significantlyreducesaccuracy.hence,thetwoparametersalways
existingsolutionstoestimateenergyconsumptionforsoftware
needtobeanalyzedtogether.otherworksoptforoptimizingenergy
failtoprovidemeaningfulinsightaboutenergyconsumptionthat
whilekeepingaccuracylosswithinanegligiblemargin[102].
can be mapped to a machine learning model’s structure. irene
algorithmdesign ⊲10outof98papers.designofnewtraining createsagraphthatbreaksdownnlpmodelsintointolow-level
algorithmsthatproducemodelsthataresignificantlymoreenergy- machinelearningprimitivesandprovidesenergyestimationsat
efficientthanthestateoftheart. theprimitivelevel[33].
robertoverdecchia,junesallou,andluíscruz
emissions ⊲4outof98papers.papersthatfocusonunderstand-
greenaitopicsbystudytype
ingthecarbonimpactofcreatingand/orconsumingaisystems.
¤mostpublicationsonethics,policy,andemissionsareposi-
dhar[36]flagstheimportanceofbeingabletoquantifycarbonim-
tionstudiescallingformoreresearchinthesetopics.
pactandthelackoftoolsanddataavailable.fraga-lamasetal.[40]
go beyond reporting the energy consumption of an ai-enabled
iotscenarioandpresenthowmuchcarbonwouldbeemittedin 3.6 domains
differentcountriesanddifferentenergysources. figure6presentsthedistributionofthepublicationsaccordingto
policy ⊲3outof98papers.studieswithinthistopicaddressand thedomaintheycover.themajorityofthepublications(i.e.,⊲58
discussstrategiesonhowweshouldhandlethecarbonfootprintof outof98papers.)donotdevotetheirstudiestoaspecificdomain,but
aiasasociety. tackletheenergyefficiencyofaiinageneralcontext.regarding
perucicaandandjelkovic[81]reflectontheenvironmentalpoli- themostspecificstudies,themostcovereddomainsare:
ciesimplementedbytheeuropeanunion,discussingwhetherthey
fittheaieraornewregulationsareneeded.rhodeetal.[85]call edge regardinginternetofthingsandedgecomputing,which
areusuallyassociatedwithdistributedsystemsandnetworks.
outfortheuncleardilemmabetweentheimpactofexisting/up-
⊲24outof98papers.
comingaitechnologiesandthecommitmenttoachievethe1.5℃
climatechangegoalasexpressedintheunfcccparisdeclaration. computervision regardingimagerecognition.⊲6outof98pa-
pers.
ethics ⊲3outof98papers.papersthatfocusontheethicalim- cloud ⊲5outof98papers.
plicationsofthegrowingcarbonfootprintofai.tamburrini[96] mobile ⊲4outof98papers.
discusses the responsibilities of ai scientists, ai infrastructure
providers,andotherstakeholdersinenablinggreenai.thepa- theothercategorygatherspublicationsaboutaspecificdomain,
perquestionswhetheritisethicallyjustifiedtocreatemassiveai being covered only once, among health, autonomous driving,
pipelinestoimproveaccuracy. smartcities,humanactivity,wearables,andembeddedsystems.
other ⊲5outof98papers.studiesaddressingarelevanttopic
withonlyasinglepublicationintotal:uservalues[65],schedul- greenaidomains
ing[116],reboundeffects[105],security[89],energycapping[66]. ¤themajorityofgreenaistudiesdoesnotfocusaspecific
domain.amongspecificdomains,edgecomputingresultstobe
greenaitopicsbystudytype themostrecurrentone.
¤thereare13maintopicsongreenai.themajority(61%)
ofthepublicationsfocusesonmonitoring,hyperparameter- 3.7 aipipelinephases
tuning,modelbenchmarking,anddeployment.despitebeing
the ai pipeline is divided into two major phases: the training,
important,topicssuchasdata-centric,estimation,andemis-
whentheaimodelisbuilt,andtheinference,whenthemodel
sionsareunderrepresentedinthescientificliterature.
isusedtomakepredictionsfromnewdata.thus,weclassifythe
papersaccordingto3categories:training,inference,andall.the
3.5 greenaitopicsbystudytype allcategorytranslatesthefactthatthepaperdoesnotconsidera
wefurtherinvestigatethedistributionofpapersacrossdifferent particularphase,butthewholepipeline.
topicspercategory.figure5presentsabubbleplotthatdrawsa asdepictedinfigure7,wefindthatmostofthepublications
bubbleforeachpairtopic(x-axis)andstudytype(y-axis).thesize onthetopicsofgreenaifocusonthetrainingphase(⊲49outof
ofthebubbleisproportionaltothenumberofpaperspublishedin 98papers.).incomparison,fewerpapersdirecttheirstudiesatthe
eachpair.theplotenablesafewobservations. inferencephase(⊲17outof98papers.)orontheoverallprocess
mosttopicsadheretothegeneralpatternobservedearlierinsec- (⊲32outof98papers.).
tion3.3:themajorityofpapersconsistofsolutionstudies,followed
byobservationalandthenposition.however,thetopicsofmodel greenaipipelinephase
benchmarkingandlibrariesdonotfollowthispattern,beingmostly
¤approximatelyhalfofgreenaistudiesfocusonthetraining
coveredbyobservationalpapers.thisisexpectedasthesetopics
phase,whileaminorportionconsiderstheentireaipipeline.
revolvearoundcomparingdifferentlibrariesandmodelstoprovide
onlyaminorportionofthegreenailiteraturefocusesonthe
insightontheenergyefficiencyofdifferentdesigndecisions.
inferencephase.
moreover,papersfromtheleastrepresentedtopicsethics,policy,
andemissionstendtobepositionpapers.fromthetenstudiesin
3.8 consideredartifacts
thesethreetopics,onlyoneisobservationalandnoneissolution.
alsoworthnoticingisthefactthatthemajorityoftheposition aisystemsarebasedonseveralartifacts,andtacklingtheenergy
studiesingreenaionlycoverthesmallesttopics.considering efficiencyofsuchsystemscanthusinvolvemultipleofthosearti-
thetop-10topics–frommonitoringtoestimation–only5are facts(e.g.,data,model,pipeline)ordifferentrelatedartifacts(e.g.,
positionpapers.incontrast,thebottom-4topics(includingother) architecture,framework,cpu).westudywhatparticularartifacts
arecoveredby10positionpapers. arethefocusofthetrendsinpublication.wedefinecategories
accordingtothoseartifactsas:
asystematicreviewofgreenai
28
20 18 17 17
11 10
10 8
6 6 5 4 3 3 5
0
hm yo pn ei rt po ar ri ang meter- mt ou den li n bg enchmar i pn rg ecd ie sipl oo n-y em ne en rt gy trade al- go off rithm-design libraries data n- etce wn ot rri c architecture estimation emissions policy ethics other
topic
figure4:numberofpaperspergreenaitopic.
60 58
other 2 2 1
40
eth cs 3
24
pol c- 3 20
5 4 4 7
em ss ons 1 3 0
general edge computer cloud mobile other
vision
est mat on 1 4
domain
network arch tecture 1 5
figure6:numberofpublicationsperstudydomain.
data-centr c 1 4 1
l brar es 7 1 49
40
algor thm-des gn 1 9 32
20 17
precision-energ- trade-off 3 8
0
deployment 5 12
training all inference
considered stage
model benchmarking 14 3
figure7:numberofpublicationsperstudiedphaseofai.
hyperparameter-tuning 6 12
monitoring 11 13 4
data papersthataddressenergyefficiencythroughthestudyof
observational solution position thedatausedintheaipipeline.⊲8outof98papers.
pipeline studieslookingatthewholeaipipeline.⊲3outof98
figure5:numberofpublicationsbytopicandstudytype. papers.
other publicationsdealingwithcpu,architecture,andframework.
⊲4outof98papers.
general thepapersdonotspecifyaparticularartifactandaddress
model thepublicationswithinthiscategoryfocusonthemodel
aisystemsasawhole.⊲24outof98papers.
and/orassociatedalgorithmtotackletheenergyefficiency
ofai.⊲63outof98papers.
robertoverdecchia,junesallou,andluíscruz
63
60 42
40
32
40 30
22
24 20
20
10
10
8 3 4 4 2
0 0
algorithm general data pipeline other image textual numeric video audio not
specified
artifact
data type
figure8:numberofpublicationsperstudiedartifact.
figure9:occurrenceofdatatypesusedinthegreenailit-
erature.
3.9 algorithmtypes
byconsideringtheprimarystudieswhichfocusonaspecificalgo-
findinghastobeprimarilyattributedtothepositionandtheoretical
rithm(⊲51outof98papers.),wenotethatthevastmajorityfocus
papersincludedinthereview(seealsosection3.3andsection3.4).
onneuralnetworks(⊲41outof98papers.).onlyamuchsmaller
fractionfocusesonalgorithmsofdifferentnature,suchasdecision
greenaidatatypes
trees(⊲5outof98papers.),geneticalgorithms(⊲1outof98papers.),
¤imagedataisthemostuseddatatypeingreenaistudies,
orlogisticregressionmodels(⊲5outof98papers.).
followedbytextualandnumericdata.
regardingthedeepneuralnetworkalgorithms,wealsonotea
furthercharacterizationofthisfield,with8studiesfocusingon
convolutionalneuralnetworks,oneontransformers,andone 3.11 datasetsizes
onspikingneuralnetworks.wealsoobservethreealgorithms
regardingthesizeofthedatasetsusedinthepapers,approximately
thatappearonlyonceinthegreenailiterature(othercategory,
halfoftheprimarystudies(⊲48outof98papers.))directlyreference
⊲3outof98papers.),namelygeneticalgorithms,logicregression
thenumberofdatapointsused.byinspectingsuchnumbers,we
algorithms,andstochasticgradientdescentalgorithms.
notethatthenumberofdatapointsusedtostudyandtoevaluate
greenaialgorithmsandapproachesvariesgreatly,andrangesfrom
greenaialgorithmtypes
1kdatapoints[47]to40mdatapoints[41].almosthalfofthe
¤mostgreenaiprimarystudiesarealgorithm-agnosticor
studiesreportingthenumberofdatapoints(⊲25outof48papers)
focusonneuralnetworks.asmallfractionusesdecisiontrees.
utilizedatapointsintheorderofthousands(1𝑘 ≤#𝑑𝑎𝑡𝑎𝑝𝑜𝑖𝑛𝑡𝑠 ≤
70𝑘),whiletheremaining(⊲23outof48papers)useonemillion
3.10 datatypesused
datapointsormore(1𝑀 ≤#𝑑𝑎𝑡𝑎𝑝𝑜𝑖𝑛𝑡𝑠 ≤40𝑀).
regardingthetypesofdatausedinthegreenaibodyofliterature,
anoverviewoftheirdistributionisreportedinfigure9.fromthe greenaidatasetsizes
figure, we can observe that the recurrence of data types across ¤datasetsizesrangefrom1kto40mdatapoints,withap-
primarystudiesis: proximatelyhalfofthestudiesutilizing1mormoredatapoints.
imagedata ⊲42outof98papers.
textualdata ⊲22outof98papers.
numericdata ⊲10outof98papers. 3.12 researchstrategies
videodata ⊲4outof98papers. byconsideringtheresearchstrategies[14]utilizedinthegreenai
audiodata ⊲2outof98papers. literature,thedistributionofthevariousstrategies,accordingto
fromthedistributionofdatatypes,wenoticethatimagedata thecollectedprimarystudies,isreportedinfigure10.
isbyfarthemostusedone,andisutilizedbyalmosthalfofthe themajorityofpaperresultsadoptlaboratoryexperiments
studiesinthebodyofliterature.thesecondmostutilizeddatatype (⊲72outof98papers.),whileonlyafractionusesotherresearch
istextualdata,whichneverthelessappearsapproximatelyhalfas strategies,suchasfieldexperiments(⊲6outof98papers.),i.e.,
oftenastheimageone.othertypesofdataresulttobelessrecurrent, experimentsconductedinpre-existingsettingsandcomputersim-
withonlyfewstudiesutilizingaudiodata(e.g.,lenherretal.present ulations,i.e.,“insilico”simulationsconductedinanonempirical
ametrictomeasurethesustainabilityofgreenaibyconsidering setting(⊲5outof98papers.).asexamples,liuetal.[73]usea
ascasestudytheintelmovidiusxprocessor,anembeddedvideo fieldstudytoassessagreensoftwarestackforcomputervision
processorwithaneuralengineforvideoprocessingandobject ofautonomousrobots,whileyosufetal.[112]leveragecomputer
detection[70]). simulationstostudyhowvirtualizedcloudfognetworkscanbe
aratherhighnumberofprimarystudiesdoesnotspecifyany usedtoimproveaienergyefficiency.
kindofdata(notspecifiedcategory,⊲32outof98papers.).this
asystematicreviewofgreenai
72
60
40
20 13 academic industrial
6 5 3 76 21 3
0
laboratory field computer simula ion judgemen none
experiment experiment s udy
research s ra egy
figure 10: occurrence of research strategies used in the
greenailiterature.
figure11:industryinvolvement.
greenairesearchstrategies
¤mostgreenaistudiesuselaboratoryexperiments,while
onlyaminorityadoptotherresearchstrategies,suchasfield
¤industryinvolvement
experimentsandcomputersimulations.
moststudiesarewrittenbyacademicauthors,whileaminor
portionbyamixofacademicandindustrialauthors.greenai
3.13 energysavings
studieswrittenexclusivelybyacademicauthorsareveryrare.
byconsideringtheenergysavingsreportedachievableviagreenai
strategies,wenotethatonlyapproximatelyathirdoftheprimary
3.15 intendedreaders
studiesexplicitlydocumentthem(⊲27outof98papers.).outof
by considering the intended readers of the green ai scientific
all green ai strategies, among the ones which report concrete
savingpercentages,atechniquebasedonstructuresimplification literature, the vast majority targets academic readers (⊲ 85 out
of98papers.),whileamuchsmallerportionbothacademicand
fordeepneuralnetworksresultstosavemoreenergy,amounting
industrialreaders(⊲8outof98papers.).despitescientificpapers
to115%energysavings[114].theothertechniqueswhichresult
targettingintuitivelyaspecializedaudience,amongthegreenai
tooptimizeenergythemostarebasedonquantizingtheinputsof
literature,fewstudiesareintendedalsoforthegeneralpublic(⊲5
decisiontrees[19](97%energysavings),usingdata-centricgreen
outof98papers.).forexample,dharetal.[36],presentanintuitive
aitechniques[98](92%energysavings),andleveragingefficient
yetthoroughlypositionedarticleonthesystemiceffectofaion
deploymentofaialgorithmsviavirtualizedcloudfognetworks
carbonemissions.interestingly,amongtheprimarystudies,feware
(91%energysavings)[112].overall,morethanhalfofthepapers
intendedalsoforpolicymakers,i.e.,aimtosensibilizegovernment
explicitlyreportingenergysavingpercentagesreportasavingofat
stakeholderstoconsiderissuesrelatedtogreenai.forexample,
least50%(⊲17outof27papers),whileonlyaminornumbersavings
inapaperbyrohdeetal.[85],howopportunitiesandrisksfor
between13%and49%.
theenvironment,economyandsocietyassociatedwithaicanbe
¤greenaienergysavings governedarediscussed.
studiesreportenergysavingsbetween13%and115%energy
¤intendedreaders
savings,withmorethanhalfofthepapersreportingsavingsof
thevastmajorityofgreenaistudiesaretargettingacademic
atleast50%.
readers,whileamuchsmallerportiontargetsbothacademic
andindustrialreaders.ahandfulofstudies,especiallyposition
3.14 industryinvolvement
papers,areintendedforthegeneralpublic.
regardingtheindustryinvolvementingreenaiscientificpublica-
tions(seealsosection2.2.4),anoverviewoftheauthorshipofthe
3.16 toolprovision
greenaiprimarypapersisdepictedinfigure11.
fromthefigure,wecannotethatmostgreenaistudiesareau- amongtheprimarystudiescollectedforthisliteraturereviewon
thoredexclusivelybyacademicresearchers(⊲75outof98papers.), greenai,onlyasmallfraction(⊲15outof98papers.)makestools
whilealsoaconsiderableportion,amountingalmosttoafourthof availabletotacklegreenai.thetoolsprovidedareofheteroge-
allprimarystudies,areauthoredbyamixofacademicandindus- neousnature,andrangefromtoolstomonitortheresourceeffi-
trialresearchers(⊲20outof98papers.).greenaistudieswritten ciencyofaialgorithms[48],totoolsoptimizingtheenergyeffi-
exclusivelybyindustrialauthorsappearonlyinrareinstances(⊲3 ciencyforstochasticedgeinference[64],andimplementationsof
outof98papers.). convolutionalneuralnetworksoptimizedforenergyefficiency[77].
robertoverdecchia,junesallou,andluíscruz
alsonotethattheincreasingdistributionofdigitalinfrastructures
¤greenaitoolprovision
toachieveenvironmentalsustainability[15]mighthaveplayeda
albeitnumerousstudiesprovidesolutiontotacklegreenai, roleingreenairesearch,withedgecomputingbeingthemost
only a fraction of them makes tools based on the solutions consideredspecificdomain.
readilyavailableonlineasanimplementedtool. theresultsregardingtheaipipelinephasesconsideredinthe
literatureunequivocallypointtotrainingasthemoststudiedphase.
4 discussion albeit the training phase is intuitively the most energy-greedy
phase,thisresultscallsforawordofcaution.fromrecentresults
fromtheanalysisofthegreenaipublicationtrendsaclearpicture
(e.g.,astudyondata-centricgreenai[98])theinferencephasere-
emerges.thetopicisgainingincreasingtractionintheacademic
sultstoconsumeonlyanegligiblefractionoftheenergyconsumed
community,especiallyifthelatestyearsareconsidered(from2020
inthetrainingphase.nevertheless,giventhehighexecutionrate
onward).despitebeingaquitenewresearchtopic(withthefirstpa-
oftheinferencephase,howtheenergyconsumedbytheinfrequent
perongreenaibeingpublishedin2015),thesocio-environmental
executionofthetrainingphasecomparestooneofthehighlyexe-
relevanceofthetopicseemstobereflectedinitstargetedpublica-
cutedinferencephaseisstillanopenquestion.asacallforaction,
tionvenues.withconferencesandjournalbeingthemostrecurrent
studiesshouldbeconductedbyconsideringtheenergyconsumed
greenaipublicationvenues,thegreenairesearchfieldseems
throughoutthewholelifecycleofaimodels,fromtheirtraining
tohavepositionedandconsolidateditselfquitequicklywithinai
toinferencephase,tilltheireventualdeprecation.
researchcommunities.
byconsideringthedatatypesusedingreenaistudies,wenote
regardinggreenaitopics,the13differenttopicswediscover
that the vast majority of the literature uses image data. to the
inthisreviewemphasizethatgreenaiisabroadfieldthatneeds
bestofourknowledge,thischoiceisnotguidedbyanyspecific
tobetackledasatransdisciplinaryfield.sometopicsarenaturally
researchdesignchoice(e.g.,aimodelsbasedonimagedatabeing
tiedtotrainingstrategies(e.g.,monitoring,hyperparametertuning,
themostusedinpractice,orbeingthemostenergygreedyones).
algorithmdesign).however,thereareothertopicsthattakegreen
forthisreason,weconjecturethatthepopularityofutilizingimage
aioutsidethetrainingrealm.
data for green ai data is mostly driven by convenience, either
thisisthecaseforexampleofdeployment,libraries,andesti-
becausepastworkfocusedonsuchdatabychance,imagedatasets
mationthatpromisetoberelevantinenablinggreenai.weargue
aremoreaccessible/standardizedwithrespecttootherones,or
thatotherdisciplinesneedtobeinvolved.forexample,software
moreofftheshelfimageaimodels/librariesarecurrentlyavailable.
engineeringwhichhasbeendealingwiththesetopicsfortradi-
regardlessofthecause,thisresultpointstotheneedofutilizing
tionalsoftwaresystems.ashighlightedbycaoetal.intheirwork
moreheterogeneousdatatypes,ratherthanfocusingprimarilyon
onestimation[33],onecannotexpectexistingstrategiesfortradi-
imagedata,inordertogainaholisticunderstandingofgreenai.
tionalsoftwaretoaddressthenewchallengesofai-basedsystems.
themostcommonresearchstrategyadoptedforgreenaistudies
conversely,onlyafewgreenaipapers[46,52,76]comefrom
clearlyemergesfromtheliteratureasbeinglaboratoryexperiments.
softwareengineeringvenues.
giventhefastpopularizationandconsolidationofthegreenai
ouranalysisalsoshowsthatthetopicsestimationandemis-
researchfield,fromthisreviewitseemsasifthetimeissuitableto
sionsareunder-represented,withsixandfivepapers,respectively.
shiftthefocustootherresearchstrategies,e.g.,fieldexperiments
wearguethatmoreworkisquintessentialinthesetopicstohelp
andcasestudies.thiswouldnotonlyallowtochangetheconsid-
scientistsandpractitionersreportthecarbonfootprintoftheirai
eredcontextfromaninvitrotoaninvivosetting,butalsotobridge
modelsinaseamlessway.
potentialgapsbetweenacademicresearchandindustrialpractice.
weshowcasethatpapersunderthetopicpolicyareonlycovered
fromtheresultsofthisreviewregardingenergysavings,we
bypositionpapers.wefindthisfindingdisconcerting:newpolicies
deduce that the research field of green ai is highly promising,
toencouragegreenaiwithinbothindustryandacademiccontexts
withmorethanhalfofthepapersreporting50%ormoreenergy
needtobebackedupwithreliableevidence.hence,weneedmore
savings. this study focuses on the state of the art of green ai,
observationalandsolutionpapersthattacklethistopicinthenear
ratherthanfocusingonthestateofpractice.itwouldbetherefore
future.
interestingtounderstand,asfuturework,theextenttowhichthis
the same issue is present in emissions – only one paper is
encouragingresultsaretransposedtoindustrialpractice,andthe
observationalandtheremainingareposition.itmightbethecase
potentialimpedimentswhichhindertheiradoptionorfullpotential.
thatcomputingtheclimateimpactofaiisfarfromtrivialandit
regardingindustryinvolvementingreenaistudies,theresults
iseasiersaidthendone.again,thisisacallforthecommunityto
gatheredfromthisreviewarepromising.theauthorshipofgreen
takeaction.itisnotenoughtoaskbigcompaniestoprovidetheir
ailiteratureresultstobetoagoodextentsharedbetweenaca-
dataoncarbonimpact–wealsoneedtoprovidestrategiesand
demicandindustrialresearchers/practitioners.thisfindingmight
solutionstomakeitstandardandstraightforward.
highlightthesensibilityofindustrytowardsgreenaiconcerns,
fromtheresultscollectedregardingthegreenaidomainswe
and/ortheimportanceofmovingtowardsmoreenvironmentally
deducethat,inordertoimprovetheenvironmentalsustainability
sustainableaipractices.
ofai,itisoftennotnecessarytofocusonaspecificdomain.this
asapotentialimpedimenttotheindustrialadoptionofgreenai
impliesthatfrequentlyfundamentalaspectsofgreenaiarestill
research,ourresultspointtoalowrecurrenceofstudiestargeted
opentoinvestigation,andresultscanthenbeportedfromageneric
towardspractitioners.whilenumerousjournalsareexplicitlyaimed
settingtospecificdomains.however,fromtheobtainedresults,we
asystematicreviewofgreenai
atpractitioners,e.g.,ieeesoftware2,onlyfewstudiesongreenai andinterpretationsweremitigatedbycloselycomplyingwiththe
includedinourreviewtargetthem.thisresultmightpointtothe selectioncriteriatoevaluatethestudies.moreover,weeklymeeting
factthatthegreenaiinterestisstillprimarilyfocusedtowards were held during the selection process to jointly discuss exam-
academicactivities,whiletheauthorshipshowcasesaratherhigh ples,doubts,andtoaligntheselectionprocessbetweenthethree
interestofindustry.astakeaway,similartotheconsiderations researchers.
madeforthegreenairesearchstrategies,itmightbetheright constructvaliditytoensurethatthesetofstudiesanswered
momenttoconsiderahigherinvolvementofindustryingreenai, ourresearchquestions,weappliedaprioricarefullyconstructed
whichresultstodatetobearesearchareastilltargetedprimarily inclusionandexclusioncriteriatostrictlycontrolthemanualselec-
towardsacademicreaders. tionofstudies.wethenusedthebidirectionalsnowballingtech-
finally,fromthisreview,wenotethatthecurrentsituationre- niquetoexpandtherangeofrelevantprimarystudiestoamore
gardingtheprovisioningofgreenaitoolsisnotbright.albeitthe comprehensiveset.
majorityofthestudiespresentgreenaisolutions,onlyasmallfrac- conclusionvaliditypossiblesourcesofbiasarisingfromthe
tionofthemmakesthesolutionsavailableasatool.weconjecture dataextractionandanalysisphasesweremitigatedbystrictcompli-
thatthisresultmighteitherpointtowards(i)afast-pacednature ancewithanaprioridefinedprotocol,explicitlytailoredtocollect
ofgreenairesearch,inwhichresultsarerapidlydeprecated,and thedataneededtoanswerourresearchquestions.inall,wefol-
hencetoolsarenotmeaningful,or(ii)animmaturityoftheresearch lowedthebestpractisesofthestandardguidelinesforsystematic
field,whichstillrequiresasolidempiricalfoundationonwhich literaturereviews[6–8,12,17].lastly,wedocumentedallthedata
toolscanbebuiltupon. throughoutthewholereviewprocessandmadethemavailablefor
reproducibilityandreplicabilitypurposes(seesection1).
5 threatstovalidity
6 relatedwork
inthissection,wediscussthethreatstovalidityofourstudy.toen-
surethequalityoftheresults,weestablishedawell-definedresearch despitethegrowinginterestaroundgreenai,thetopichasbeen
protocoltoproceedwiththedatacollection.inaddition,throughout marginallyconsideredonlyinahandfulofreviews.therelated
ourstudy,wefollowedtherecommendationsoftheguidelinesfor workmanlyinvestigatesthetopicasanintersectionofaiandenvi-
conductingasystematicliteraturereview[6–8,12,17].wedesigned ronmentalsustainability,orbydefiningitasaspecificsubdomain
andcarriedthedifferentreviewingprocessesaccordingtotherig- ofsoftwareengineering.tothebestofourknowledge,thisreview
orousprotocolweestablishedaftertheguidelinesanddescribed isthefirstaimingtowardsacomprehensivereviewofgreenai
insection2.nevertheless,somethreatstovaliditycanstillexist researchanditscharacteristics.
evenwithourbestefforts.inthefollowing,wepresentthethreats inarecentpublication,natarajanetal.performasystematic
whichcouldhaveinfluencedourstudy,jointlywiththestrategies literaturereviewonthetopicsof‘aiforenvironmentalsustain-
weadoptedtomitigatethem. ability’aswellas‘environmentalsustainabilityofai’.theauthors
externalvaliditythemainthreattoexternalvalidityisthat presenttheaffordancesoftheuseofaiforsustainabilitythatthey
theliteraturecollectedandanalysedinthisstudyisnotsufficiently extractedfromtheliterature[10].‘aiaffordances’areintroduced
representative.toavoidthissituation,wesurveyedthreepromi- astheposibleactionsofferedbyaiartifactstoanorganizational
nentliteratureindexersthroughanautomaticquery(i.e.,google actorwhosegoalistoachieveenvironmentalsustainability.the
scholar,scopus,andwebofscience),andlefttheyearofpublica- authorspointoutthefocusofpreviousresearchonthetechnical
tionunbounded,toreducetheprobabilityofmissinganyrelevant side,andtheyadvocateforafurtherexplorationoftheconcept
publication.inaddition,thesearchquerywasdesignedtotarget ofsustainableaiaffordancesfromasocio-technicalperspective.
relevantliteraturedirectlywithspecifickeywords,whileallowfor theliteratureisexclusivelyanalyzedwithrespecttobuildingthe
flexibilitybyconsideringsimilar,complementary,andvariationof aiaffordances,andothercharacteristicsofthestate-of-theartof
thekeywords(e.g.,thekeywordsgreen,sustainability,andsustain- greenaiareconsiderednordiscussedinthestudy.incontrast,
able).wealsomitigatedthethreatofhavinganincompletesetof ourreviewfocusesonthesustainabilityofai,andmapstheen-
studies,aswellasthethreatassociatedwiththespecificityofthe tiretyofthegreenailiterature.inourreview,weaimatproviding
termsusedinthesearchquery,byperformingacomplementary adetailedandcomprehensiveoverviewofthecharacteristicsof
iterativebidirectionalsnowballingprocessofthequeryresults.this the green ai state-of-the-art research (e.g., topic, domain, type
lattersearchstrategyallowedustoincludeliteraturerelatedtoour ofstudy,targetedartifact,overviewofenergysavings,toolprovi-
querythatwasnotdirectlyreferencinganyoftheautomatedsearch sion,industrialinvolvement).therefore,incontrasttothework
keywords.welimitedourreviewoftheliteraturetopeer-reviewed ofnatarajanetal.[10],weconsiderthedifferentfacetsofgreen
studies,tomoderatethethreataboutthelowqualityofthesetof ai,ratherthanexclusivelyonaiaffordances,leadingtoamore
primarystudies.wedeemthatsuchpracticedoesnotconstitute holisticreviewofgreenai,andahighernumberofconsidered
anadditionalthreat,aspeer-reviewisastandardrequirementof primarystudies(98versus41papers).thisdifferencecouldbeex-
high-qualitypublications. plainedbythefactthattheirreviewonlyincludespapersinvolving
internalvaliditytoaddresspotentialthreatstointernalvalid- consumerproductsandservicesandexcludespapersdealingwith
ity,weestablishedarigorousresearchprotocolapriori,andwe non-commercialapplications,whereasweprovideanoverviewof
followedittoconductalltheresearchactivities.subjectivebiases thewholefieldofgreenai.
2https://www.computer.org/csdl/magazine/so.accessed22nddecember2022.
robertoverdecchia,junesallou,andluíscruz
previousliteraturereviewsconsidergreenairesearchbyfo- theportofpromisingacademicresultstoindustrialpractice.in
cusingexclusivelyonspecificsubdomainsofaiandapplication otherwords,ourstudycallsoutfortheimportanceofhavingre-
subdomainsofsoftwareengineering,e.g.,deeplearning[18],in- producibleresearch.onlyasmallfractionofsolutionpapersoffers
formationretrieval[13],orembeddedsystems[9].incontrast,our atoolorsoftwarepackagethatcanbeusedbythecommunity.we
research aims to review the entirety of the green ai literature, arguethatgreenaiisanurgentandnecessarylineofresearch
regardlessofthespecificaiorsoftwareengineeringsubdomainit thatneedstogrowfastandsolid–non-replicableresearchcanonly
focuseson. slowusdown.
inthesurveyofxuetal.[18],theauthorsprovideanoverview thisreviewalsoservesasafoundationforfutureresearchthat
oftheapproachesaimedatimprovingtheenvironmentalsustain- ultimatelyaimstoreducetheclimateimpactofai.inthisrespect,
abilityofdeeplearning.theauthorsmapthedifferentapproaches weseepotentialinfollow-upgreyliteratureorinterviewstudies
usingataxonomyofthedeeplearninglifecyclestageanditsrelated tounderstandhowaiprofessionalsarecurrentlyaddressingthe
artifacts.incontrasttosuchstudy,inthisreviewwetargetahigher issue.
numberofgreenaicharacteristics(seesection2.2.4),andtarget
references
theentiretyofgreenailiterature,ratherthanexclusivelytheone
ondeeplearning. [1] victorr.basili,gianluigicaldiera,anddieterrombach.1994.thegoalquestion
scellsetal.[13]providealiteraturereviewonmethodsrelated metricapproach.inencyclopediaofsoftwareengineering.wiley,528–532.
[2] barneygglaser.1965.theconstantcomparativemethodofqualitativeanalysis.
tothedomainofgreeninformationretrieval.theauthorsexplain socialproblems12,4(1965),436–445.
thatthedomainofinformationretrieval(ir)producesrelatively [3] markhaakman,luíscruz,henniehuijgens,andarievandeursen.2021.ai
lifecyclemodelsneedtoberevised.empiricalsoftwareengineering26,5(2021),
lowemissionscomparedtootherresearchdomains,buttheyalso
1–29.
warnthatsimilartrendsofcostsandenvironmentalimpactmay [4] bryanjenner,uweflick,ernstvonkardoff,andinessteinke.2004.acompanion
appearconsideringthegrowingdevelopmentofnewir-focused toqualitativeresearch.sage,271–275.
[5] jinseokkim.2019.author-basedanalysisofconferenceversusjournalpublication
deeplearningmodels.naturallanguageprocessingandmachine
incomputerscience.j.assoc.inf.sci.technol.70,1(jan.2019),71–82. https:
learningarealsodiscussed,butonlywithrespecttotheinformation //doi.org/10.1002/asi.24079
retrievaldomain.therefore,theyarenotaddressingthewholefield [6] barbarakitchenham.2004.proceduresforperformingsystematicreviews.keele,
uk,keeleuniversity33,tr/se-0401(2004),28.
ofai,asdoneinthisreview. [7] barbarakitchenhamandpearlbrereton.2013.asystematicreviewofsystematic
finally,theoptimizationsthatcanbemadefortheimplementa- reviewprocessresearchinsoftwareengineering. informationandsoftware
technology55,12(2013),2049–2075.
tionofdeeplearningmodelsonthespecificplatformofnvidia
[8] philippmayringetal.2004. qualitativecontentanalysis. acompanionto
jetsonarereviewedwithafocusonenergyefficiencybymittal[9]. qualitativeresearch1,2(2004),159–176.
thereviewcoversstudiesatboththehardwareandsoftwarelevel. [9] sparshmittal.2019. asurveyonoptimizedimplementationofdeeplearning
nevertheless,thereviewaddressesonlythejetsonplatform3.we modelsonthenvidiajetsonplatform.j.syst.archit.97(aug.2019),428–442.
https://doi.org/10.1016/j.sysarc.2019.01.011
differentiateourselvesfromthisstudybyprovidingaholisticreview [10] harishkarthinatarajan,daniellydepaula,christiandremel,andfalkueber-
ofgreenai,ratherthanfocusingexclusivelyondeeplearning. nickel.2022. atheoreticalreviewonaiaffordancesforsustainability.in
americasconferenceoninformationsystems.
[11] kaipetersen,robertfeldt,shahidmujtaba,andmichaelmattsson.2008. sys-
7 conclusion
tematicmappingstudiesinsoftwareengineering.internationalconferenceon
evaluationandassessmentinsoftwareengineering,68–77.
in thissystematicliteraturereview,we aimedat characterizing
[12] kaipetersen,sairamvakkalanka,andludwikkuzniarz.2015. guidelinesfor
theexistingbodyofresearchingreenai.weidentified98peer- conductingsystematicmappingstudiesinsoftwareengineering:anupdate.
reviewedpublicationsthatshowasignificantgrowthinthisre- informationandsoftwaretechnology64(2015),1–18.
[13] harrisenscells,shengyaozhuang,andguidozuccon.2022. reduce,reuse,
searchfieldsince2020.
recycle:greeninformationretrievalresearch. insigir’22:proceedingsof
weprovideanencompassingoverviewandcharacterizationof the45thinternationalacmsigirconferenceonresearchanddevelopmentin
thedifferenttopicsbeingaddressedbygreenaipapers.weidenti- informationretrieval.associationforcomputingmachinery,newyork,ny,usa,
2825–2837. https://doi.org/10.1145/3477495.3531766
fied13differentgreenaitopics,showcasingthatthespotlightfalls [14] klaas-janstolandbrianfitzgerald.2018. theabcofsoftwareengineering
onmonitoring,hyperparameter-tuning,modelbenchmarking,and research.acmtransactionsonsoftwareengineeringandmethodology(tosem)
27,3(2018),1–51.
deployment.lessfrequenttopics–suchasdata-centric,estimation,
[15] robertoverdecchia,patricialago,andcaroldevries.2022. thefutureof
andemissions–showlessobviousapproachesthatdeservefurther sustainabledigitalinfrastructures:alandscapeofsolutions,adoptionfactors,
researchintheupcomingyears. impediments,openproblems,andscenarios.sustainablecomputing:informatics
andsystems(2022),100767.
thepotentialofgreenaicannotbedisregarded:themajorityof
[16] georgevrettasandmarksanderson.2015. conferencesversusjournalsin
publicationsshowsignificantenergysavings,upto115%,atlittle computerscience.j.assoc.inf.sci.technol.66,12(dec.2015),2674–2684. https:
ornocostinaccuracy.however,wearguethatmostpublications //doi.org/10.1002/asi.23349
[17] claeswohlin.2014. guidelinesforsnowballinginsystematicliteraturestud-
revolvearoundlaboratorystudies.morefieldexperimentsarequin- iesandareplicationinsoftwareengineering.ininternationalconferenceon
tessentialtohelpaipractitionersembracegreenstrategiesthat evaluationandassessmentinsoftwareengineering.acmpress,1–10.
[18] jingjingxu,wangchunshuzhou,zhiyifu,haozhou,andleili.2021.asurvey
areeffective,feasible,andmensurable.thisisalsoreflectedinthe
ongreendeeplearning.arxiv(nov.2021). https://doi.org/10.48550/arxiv.2111.
smallparticipationoftheindustryinthesestudies–only23%of 05193arxiv:2111.05193
publicationsinvolveindustrypartners.
atthesametime,weconcludethatthefieldseemstobereaching
primarystudies
aconsiderablelevelofmaturity.hence,itisnecessarytoencourage
[19] brunnoabreu,mateusgrellert,andsergiobampi.2020.vlsidesignoftree-
basedinferenceforlow-powerlearningapplications.in2020ieeeinternational
3https://developer.nvidia.com/embedded-computing.accessed23thdecember2022. symposiumoncircuitsandsystems(iscas).ieee,1–5.
asystematicreviewofgreenai
[20] brunnoabreu,mateusgrellert,andsergiobampi.2022.aframeworkfordesign- [39] marizaferro,gabrielid.silva,felipeb.depaula,vitorvieira,andbruno
ingpower-efficientinferenceacceleratorsintree-basedlearningapplications. schulze.2021. towardsasustainableartificialintelligence:acasestudyof
engineeringapplicationsofartificialintelligence109(2022),104638. energyefficiencyindecisiontreealgorithms. concurrencycomputat.pract.
[21] phyllisang,bhuwandhingra,andlisawuwills.2022. characterizingthe exper.n/a,n/a(dec.2021),e6815. https://doi.org/10.1002/cpe.6815
efficiencyvs.accuracytrade-offforlong-contextnlpmodels.inproceedings [40] paulafraga-lamas,sérgioivanlopes,andtiagom.fernández-caramés.2021.
ofnlppower!thefirstworkshoponefficientbenchmarkinginnlp.association greeniotandedgeaiaskeytechnologicalenablersforasustainabledigital
forcomputationallinguistics,dublin,ireland,113–121. https://doi.org/10. transitiontowardsasmartcirculareconomy:anindustry5.0usecase.sensors
18653/v1/2022.nlppower-1.12 21,17(aug.2021),5745. https://doi.org/10.3390/s21175745
[22] lassef.wolffanthony,benjaminkanding,andraghavendraselvan.2020. [41] evagarcia-martin,niklaslavesson,andhåkangrahn.2017. identification
carbontracker:trackingandpredictingthecarbonfootprintoftrainingdeep ofenergyhotspots:acasestudyoftheveryfastdecisiontree. ingreen,
learningmodels.icmlworkshoponchallengesindeployingandmonitoring pervasive,andcloudcomputing.springer,cham,switzerland,267–281. https:
machinelearningsystems. arxiv:2007.03051. //doi.org/10.1007/978-3-319-57186-7_21
[23] andreaasperti,davideevangelista,andelenalolipiccolomini.2021.asurvey [42] evagarcía-martín,niklaslavesson,håkangrahn,emilianocasalicchio,and
onvariationalautoencodersfromagreenaiperspective.sncomput.sci.2,4 veselkaboeva.2021.energy-awareveryfastdecisiontree.int.j.datasci.anal.
(july2021),1–23. https://doi.org/10.1007/s42979-021-00702-9 11,2(march2021),105–126. https://doi.org/10.1007/s41060-021-00246-4
[24] nesrinebannour,saharghannay,aurélienévéol,andanne-laureligozat. [43] ángelm.garcía-vicoandfranciscoherrera.2021. apreliminaryanalysis
2021.evaluatingthecarbonfootprintofnlpmethods:asurveyandanalysisof onsoftwareframeworksforthedevelopmentofspikingneuralnetworks.
existingtools.inemnlp,workshopsustainlp. inhybridartificialintelligentsystems.springer,cham,switzerland,564–575.
[25] michelbarlaudandfrédéricguyard.2021.learningsparsedeepneuralnet- https://doi.org/10.1007/978-3-030-86271-8_47
worksusingefficientstructuredprojectionsonconvexconstraintsforgreenai. [44] evagarcía-martín,crefedafaviolarodrigues,grahamriley,andhåkangrahn.
in202025thinternationalconferenceonpatternrecognition(icpr).1566–1573. 2019.estimationofenergyconsumptioninmachinelearning.j.paralleland
https://doi.org/10.1109/icpr48806.2021.9412162 distrib.comput.134(2019),75–88.
[26] soroushbateni,hushengzhou,yuankunzhu,andcongliu.2018.predjoule: [45] kentgauen,rohitrangan,anupmohan,yung-hsianglu,weiliu,and
atiming-predictableenergyoptimizationframeworkfordeepneuralnetworks. alexanderc.berg.2017. low-powerimagerecognitionchallenge.in2017
in2018ieeereal-timesystemssymposium(rtss).ieee,107–118. 22ndasiaandsouthpacificdesignautomationconference(asp-dac).99–104.
[27] emilym.bender,timnitgebru,angelinamcmillan-major,andshmargaret https://doi.org/10.1109/aspdac.2017.7858303
shmitchell.2021.onthedangersofstochasticparrots:canlanguagemodels [46] stefanosgeorgiou,mariakechagia,tusharsharma,federicasarro,andying
betoobig?infacct’21:proceedingsofthe2021acmconferenceonfairness, zou.2022. greenai:dodeeplearningframeworkshavedifferentcosts? in
accountability,andtransparency.associationforcomputingmachinery,new icse’22:proceedingsofthe44thinternationalconferenceonsoftwareengineering.
york,ny,usa,610–623. https://doi.org/10.1145/3442188.3445922 associationforcomputingmachinery,newyork,ny,usa,1082–1094. https:
[28] alexandereibrownlee,jasonadair,saemunduroharaldsson,andjohnjabbo. //doi.org/10.1145/3510003.3510221
2021. exploringtheaccuracy–energytrade-offinmachinelearning.in2021 [47] santoshgondiandvineelpratap.2021.performanceandefficiencyevaluation
ieee/acminternationalworkshopongeneticimprovement(gi).ieee,11–18. ofasrinferenceontheedge.sustainability13,22(nov.2021),12392. https:
[29] sevdaozgebursa,ozlemdurmazincel,andgulfemisiklaralptekin.2022. //doi.org/10.3390/su132212392
transformingdeeplearningmodelsforresource-efficientactivityrecognition [48] achimguldner,sandrokreten,andstefannaumann.2021.explorationand
onmobiledevices.in20225thconferenceoncloudandinternetofthings(ciot). systematicassessmentoftheresourceefficiencyofmachinelearning..ingi-
ieee,83–89. jahrestagung.287–299.
[30] ermaocai,da-chengjuan,dimitriosstamoulis,anddianamarculescu.2017. [49] abhishekgupta,camyllelanteigne,andsarakingsley.2020.secure:aso-
neuralpower:predictanddeployenergy-efficientconvolutionalneuralnet- cialandenvironmentalcertificateforaisystems. icml2020challengesin
works.inproceedingsoftheninthasianconferenceonmachinelearning(pro- deployingandmonitoringmachinelearningsystemsworkshop(june2020).
ceedingsofmachinelearningresearch,vol.77),min-lingzhangandyung- https://doi.org/10.48550/arxiv.2006.06217arxiv:2006.06217
kyunnoh(eds.).pmlr,yonseiuniversity,seoul,republicofkorea,622–637. [50] maríagutiérrez,maángelesmoraga,andfélixgarcía.2022. analysingthe
https://proceedings.mlr.press/v77/cai17a.html energyimpactofdifferentoptimisationsformachinelearningmodels.in2022
[31] antoniocandelieri,riccardoperego,andfrancescoarchetti.2021. green internationalconferenceonictforsustainability(ict4s).ieee,46–52.
machinelearningviaaugmentedgaussianprocessesandmulti-information [51] başakgülerandaylinyener.2021.energy-harvestingdistributedmachine
sourceoptimization. softcomput.25,19(oct.2021),12591–12603. https: learning.in2021ieeeinternationalsymposiumoninformationtheory(isit).
//doi.org/10.1007/s00500-021-05684-7 320–325. https://doi.org/10.1109/isit45174.2021.9518045
[32] qingqingcao,arunabalasubramanian,andniranjanbalasubramanian.2020. [52] ralucamariahampau,mauritskaptein,robinvanemden,thomasrost,and
towardsaccurateandreliableenergymeasurementofnlpmodels.inpro- ivanomalavolta.2022. anempiricalstudyontheperformanceandenergy
ceedingsofsustainlp:workshoponsimpleandefficientnaturallanguagepro- consumptionofaicontainerizationstrategiesforcomputer-visiontasks
cessing.associationforcomputationallinguistics,online,141–148. https: ontheedge.inproceedingsoftheinternationalconferenceonevaluationand
//doi.org/10.18653/v1/2020.sustainlp-1.19 assessmentinsoftwareengineering2022(gothenburg,sweden)(ease’22).
[33] qingqingcao,yashkumarlal,harshtrivedi,arunabalasubramanian,and associationforcomputingmachinery,newyork,ny,usa,50–59. https:
niranjanbalasubramanian.2021. irene:interpretableenergypredictionfor //doi.org/10.1145/3530019.3530025
transformers. proceedingsofthe59thannualmeetingoftheassociationfor [53] walida.hanafy,tergelmolom-ochir,androhanshenoy.2021.designcon-
computationallinguisticsandthe11thinternationaljointconferenceonnatural siderationsforenergy-efficientinferenceonedgedevices. ine-energy’21:
languageprocessing(volume1:longpapers)(2021). https://doi.org/10.18653/ proceedingsofthetwelfthacminternationalconferenceonfutureenergysys-
v1/2021.acl-long.167 tems.associationforcomputingmachinery,newyork,ny,usa,302–308.
[34] franciscomcastro,nicolásguil,manueljmarín-jiménez,jesúspérez-serrano, https://doi.org/10.1145/3447555.3465326
andmanuelujaldón.2019.energy-basedtuningofconvolutionalneuralnet- [54] soheilhashemi,nicholasanthony,hokchhaytann,ririsbahar,andsherief
worksonmulti-gpus.concurrencyandcomputation:practiceandexperience reda.2017.understandingtheimpactofprecisionquantizationontheaccu-
31,21(2019),e4786. racyandenergyofneuralnetworks.indesign,automation&testineurope
[35] priyadarshandhabe,parammirani,rahulchugwani,andsadanandgande- conference&exhibition(date),2017.ieee,1474–1479.
war.2021.datasetreductiontoimprovecomputingefficiencyandenergy [55] peterhenderson,jieruhu,joshuaromoff,emmabrunskill,danjurafsky,and
consumptioninhealthcaredomain. indigitalliteracyandsocio-cultural joellepineau.2020.towardsthesystematicreportingoftheenergyandcarbon
acceptanceofictindevelopingcountries.springer,53–64. footprintsofmachinelearning.journalofmachinelearningresearch21,248
[36] payaldhar.2020.thecarbonimpactofartificialintelligence.nat.mach.intell. (2020),1–43. http://jmlr.org/papers/v21/20-312.html
2,8(2020),423–425. [56] mirohodakandajaydholakia.2021.recentefficiencygainsindeeplearning:
[37] josefadíaz-álvarez,pedroacastillo,franciscofernándezdevega,fran- performance,power,andsustainability.in2021ieeeinternationalconference
ciscochávez,andjorgealvarado.2022.populationsizeinfluenceontheen- onbigdata(bigdata).ieee,2040–2045.
ergyconsumptionofgeneticprogramming.measurementandcontrol(2022), [57] hamzaoui ikhlasse, duthil benjamin, courboulay vincent, and medromi
00202940211064471. hicham.2022. recentimplicationstowardssustainableandenergyefficient
[38] jessedodge,taylorprewitt,remitachetdescombes,erikaodmark,roy aiandbigdataimplementationsincloud-fogsystems:anewsworthyinquiry.
schwartz,emmastrubell,alexandrasashaluccioni,noaha.smith,nicole journalofkingsauduniversity-computerandinformationsciences34,10,part
decario,andwillbuchanan.2022.measuringthecarbonintensityofaiin a(nov.2022),8867–8887. https://doi.org/10.1016/j.jksuci.2021.11.002
cloudinstances.infacct’22:2022acmconferenceonfairness,accountability, [58] nitthilankanappanjayakodi,syrinebelakaria,aryandeshwal,andjanard-
andtransparency.associationforcomputingmachinery,newyork,ny,usa, hanraodoppa.2020. designandoptimizationofenergy-accuracytradeoff
1877–1894. https://doi.org/10.1145/3531146.3533234 networksformobileplatformsviapretraineddeepmodels.acmtransactions
robertoverdecchia,junesallou,andluíscruz
onembeddedcomputingsystems(tecs)19,1(2020),1–24. andqosin5giothetnets.appl.sci.10,20(oct.2020),7120. https://doi.org/
[59] wandrijooste,rejwanulhaque,andandyway.2022.knowledgedistillation: 10.3390/app10207120
amethodformakingneuralmachinetranslationmoreefficient.information [79] elenamorotti,davideevangelista,andelenalolipiccolomini.2021.agreen
13,2(feb.2022),88. https://doi.org/10.3390/info13020088 prospectiveforlearnedpost-processinginsparse-viewtomographicreconstruc-
[60] sorinliviujurj,flaviusopritoiu,andmirceavladutiu.2020.environmentally- tion.journalofimaging7,8(2021),139.
friendlymetricsforevaluatingtheperformanceofdeeplearningmodelsand [80] davidpatterson,josephgonzalez,urshölzle,quocle,chenliang,lluis-
systems.ininternationalconferenceonneuralinformationprocessing.springer, miquelmunguia,danielrothchild,davidr.so,maudtexier,andjeffdean.
232–244. 2022.thecarbonfootprintofmachinelearningtrainingwillplateau,then
[61] petrajääskeläinen,danielpargman,andandréholzapfel.2022.ontheenvi- shrink.computer55,7(2022),18–28. https://doi.org/10.1109/mc.2022.3148714
ronmentalsustainabilityofaiart(s).ineighthworkshoponcomputingwithin [81] natasaperucicaandkatarinaandjelkovic.2022.isthefutureofaisustainable?
limits. https://doi.org/10.21428/bf6fb269.c46375fa acasestudyoftheeuropeanunion.transforminggovernment:people,process
[62] lynnh.kaack,priyal.donti,emmastrubell,georgekamiya,felixcreutzig, andpolicy16,3(june2022),347–358. https://doi.org/10.1108/tg-06-2021-0106
anddavidrolnick.2022.aligningartificialintelligencewithclimatechange [82] supadchayapuangpontipandrattikornhewett.2020.energyusageofdeep
mitigation.nat.clim.change12(june2022),518–527. https://doi.org/10.1038/ learninginsmartcities.in2020internationalconferenceoncomputational
s41558-022-01377-7 scienceandcomputationalintelligence(csci).ieee,1143–1148.
[63] minsukim,walidsaad,mohammadmozaffari,andmerouanedebbah.2022.on [83] lucashøybergpuvisdechavannes,madsguldborgkjeldgaardkongsbak,
thetradeoffbetweenenergy,precision,andaccuracyinfederatedquantized timmierantzau,andleonderczynski.2021.hyperparameterpowerimpactin
neuralnetworks.inicc2022-ieeeinternationalconferenceoncommunications. transformerlanguagemodeltraining.inproceedingsofthesecondworkshopon
2194–2199. https://doi.org/10.1109/icc45855.2022.9838362 simpleandefficientnaturallanguageprocessing.associationforcomputational
[64] younggeunkimandcarole-jeanwu.2020. autoscale:energyefficiency linguistics,virtual,96–118. https://doi.org/10.18653/v1/2021.sustainlp-1.12
optimizationforstochasticedgeinferenceusingreinforcementlearning.in2020 [84] crefedafaviolarodrigues,grahamriley,andmikelluján.2018.synergy:
53rdannualieee/acminternationalsymposiumonmicroarchitecture(micro). anenergymeasurementandpredictionframeworkforconvolutionalneural
ieee,1082–1096. networksonjetsontx1.inproceedingsoftheinternationalconferenceonparallel
[65] pascald.könig,stefanwurster,andmarkusb.siewert.2022. consumers anddistributedprocessingtechniquesandapplications(pdpta).thesteering
arewillingtopayapriceforexplainable,butnotforgreenai.evidence committeeoftheworldcongressincomputerscience,375–382.
fromachoice-basedconjointanalysis. bigdata&society9,1(jan.2022), [85] friederikerohde,maikegossen,josephinwagner,andtilmansantarius.2021.
20539517211069632. https://doi.org/10.1177/20539517211069632 sustainabilitychallengesofartificialintelligenceandpolicyimplications.ökol-
[66] adamkrzywaniak,pawelczarnul,andjerzyproficz.2022.gpupowercapping ogischeswirtschaften-fachzeitschrift36,o1(2021),36–40.
forenergy-performancetrade-offsintrainingofdeepconvolutionalneural [86] bitadarvishrouhani,azaliamirhoseini,andfarinazkoushanfar.2016. de-
networksforimagerecognition.ininternationalconferenceoncomputational light:addingenergydimensiontodeepneuralnetworks. inislped’16:
science.springer,667–681. proceedingsofthe2016internationalsymposiumonlowpowerelectronicsand
[67] mohitkumar,xingzhouzhang,liangkailiu,yifanwang,andweisongshi. design.associationforcomputingmachinery,newyork,ny,usa,112–117.
2020.energy-efficientmachinelearningontheedges.in2020ieeeinternational https://doi.org/10.1145/2934583.2934599
parallelanddistributedprocessingsymposiumworkshops(ipdpsw).912–921. [87] kanokwanrungsuptaweekoon,vasakavisoottiviseth,andryouseitakano.
https://doi.org/10.1109/ipdpsw50202.2020.00153 2017.evaluatingthepowerefficiencyofdeeplearninginferenceonembedded
[68] jaehakung,duckhwankim,andsaibalmukhopadhyay.2015.apower-aware gpusystems.in20172ndinternationalconferenceoninformationtechnology
digitalfeedforwardneuralnetworkplatformwithbackpropagationdrivenap- (incit).ieee,1–5.
proximatesynapses.in2015ieee/acminternationalsymposiumonlowpower [88] royschwartz,jessedodge,noaha.smith,andorenetzioni.2020.greenai.
electronicsanddesign(islped).ieee,85–90. commun.acm63,12(nov.2020),54–63. https://doi.org/10.1145/3381831
[69] loïclannelongue,jasongrealey,andmichaelinouye.2021.greenalgorithms: [89] iliashumailov,yirenzhao,danielbates,nicolaspapernot,robertmullins,
quantifyingthecarbonfootprintofcomputation.adv.sci.8,12(june2021), androssanderson.2021.spongeexamples:energy-latencyattacksonneural
2100707. https://doi.org/10.1002/advs.202100707 networks.in2021ieeeeuropeansymposiumonsecurityandprivacy(euros&p).
[70] nicolalenherr,renépawlitzek,andbrunomichel.2021.newuniversalsustain- ieee,212–231.
abilitymetricstoassessedgeintelligence.sustainablecomputing:informatics [90] martinosorbaro,qianliu,massimobortone,andsadiquesheik.2020.opti-
andsystems31(sept.2021),100580. https://doi.org/10.1016/j.suscom.2021. mizingtheenergyconsumptionofspikingneuralnetworksforneuromorphic
100580 applications.frontiersinneuroscience14(2020),662.
[71] dali,xinbochen,michelabecchi,andziliangzong.2016. evaluatingthe [91] dimitriosstamoulis,ermaocai,da-chengjuan,anddianamarculescu.2018.
energyefficiencyofdeepconvolutionalneuralnetworksoncpusandgpus. hyperpower:power-andmemory-constrainedhyper-parameteroptimization
in2016ieeeinternationalconferencesonbigdataandcloudcomputing(bd- forneuralnetworks.in2018design,automation,andtestineuropeconference.
cloud),socialcomputingandnetworking(socialcom),sustainablecomputing 19–24. https://doi.org/10.23919/date.2018.8341973
andcommunications(sustaincom)(bdcloud-socialcom-sustaincom).477–484. [92] dimitriosstamoulis,ting-wurudychin,anandkrishnanprakash,haocheng
https://doi.org/10.1109/bdcloud-socialcom-sustaincom.2016.76 fang,sribhuvansajja,mitchellbognar,anddianamarculescu.2018.designing
[72] anne-laureligozat,julienlefevre,auréliebugeau,andjacquescombaz.2022. adaptiveneuralnetworksforenergy-constrainedimageclassification.in2018
unravelingthehiddenenvironmentalimpactsofaisolutionsforenvironment ieee/acminternationalconferenceoncomputer-aideddesign(iccad).acm,
lifecycleassessmentofaisolutions.sustainability14,9(april2022),5172. 1–8.
https://doi.org/10.3390/su14095172 [93] emmastrubell,ananyaganesh,andandrewmccallum.2019. energyand
[73] liangkailiu,jiaminchen,marcobrocanelli,andweisongshi.2019.e2m:an policyconsiderationsfordeeplearninginnlp.inproceedingsofthe57th
energy-efficientmiddlewareforcomputervisionapplicationsonautonomous annualmeetingoftheassociationforcomputationallinguistics.associationfor
mobilerobots.inproceedingsofthe4thacm/ieeesymposiumonedgecomputing. computationallinguistics,florence,italy,3645–3650. https://doi.org/10.18653/
59–73. v1/p19-1355
[74] michelemagno,michaelpritz,philippmayer,andlucabenini.2017.deepemote: [94] yuyangsun,zhixinou,juanchen,xinxinqi,yifeiguo,shunzhecai,and
towardsmulti-layerneuralnetworksinalowpowerwearablemulti-sensors xiaomingyan.2021.evaluatingperformance,powerandenergyofdeepneural
bracelet.in20177thieeeinternationalworkshoponadvancesinsensorsand networksoncpusandgpus.innationalconferenceoftheoreticalcomputer
interfaces(iwasi).ieee,32–37. science.springer,196–221.
[75] susmitadeymanasi,farhanasharminsnigdha,andsachinssapatnekar.2020. [95] yuxuansun,shengzhou,anddenizgündüz.2020. energy-awareanalog
neupart:usinganalyticalmodelstodriveenergy-efficientpartitioningofcnn aggregationforfederatedlearningwithredundantdata.inicc2020-2020ieee
computationsoncloud-connectedmobileclients. ieeetransactionsonvery internationalconferenceoncommunications(icc).ieee,1–7.
largescaleintegration(vlsi)systems28,8(2020),1844–1857. [96] guglielmotamburrini.2022. theaicarbonfootprintandresponsibilities
[76] andreamcintosh,safwathassan,andabramhindle.2019.whatcanandroid ofaiscientists. philosophies 7,1(jan.2022),4. https://doi.org/10.3390/
mobileappdevelopersdoabouttheenergyconsumptionofmachinelearning? philosophies7010004
empir.softwareeng.24,2(april2019),562–601. https://doi.org/10.1007/s10664- [97] yudongtao,ruima,mei-lingshyu,andshu-chingchen.2020.challenges
018-9629-2 inenergy-efficientdeepneuralnetworktrainingwithfpga.inproceedings
[77] sachinmehta,mohammadrastegari,lindashapiro,andhannanehhajishirzi. oftheieee/cvfconferenceoncomputervisionandpatternrecognition(cvpr)
2019.espnetv2:alight-weight,powerefficient,andgeneralpurposeconvolu- workshops.
tionalneuralnetwork.inproceedingsoftheieee/cvfconferenceoncomputer [98] robertoverdecchia,luíscruz,junesallou,michellelin,jameswickenden,
visionandpatternrecognition.9190–9200. andestellehotellier.2022.data-centricgreenaianexploratoryempirical
[78] thahamohammed,aiiadalbeshri,iyadkatib,andrashidmehmood.2020. study.in2022internationalconferenceonictforsustainability(ict4s).ieee,
ubipriseq—deepreinforcementlearningtomanageprivacy,security,energy, 35–45. https://doi.org/10.1109/ict4s55073.2022.00015
asystematicreviewofgreenai
[99] chengchengwan,muhammadsantriaji,erirogers,henryhoffmann,michael internationalconferenceonlearningrepresentations(iclr)(2019).
maire,andshanlu.2020. {alert}:accuratelearningforenergyandtimeli- [108] tien-juyang,yu-hsinchen,andviviennesze.2017.designingenergy-efficient
ness.in2020usenixannualtechnicalconference(usenixatc20).353–369. convolutionalneuralnetworksusingenergy-awarepruning.inproceedings
[100] congwang,binhu,andhongyiwu.2022.energyminimizationforfederated oftheieeeconferenceoncomputervisionandpatternrecognition(cvpr).
asynchronouslearningonbattery-poweredmobiledevicesviaapplication [109] xiangyuyang,shenghua,yuanmingshi,haowang,junzhang,andkhaledb.
co-running.in2022ieee42ndinternationalconferenceondistributedcomputing letaief.2020. sparseoptimizationforgreenedgeaiinference. journalof
systems(icdcs).939–949. https://doi.org/10.1109/icdcs54860.2022.00095 communicationsandinformationnetworks5,1(2020),1–15. https://doi.org/10.
[101] quwang,yongxiao,huixiangzhu,zijiansun,yingyuli,andxiaohuge.2021. 23919/jcin.2020.9055106
towardsenergy-efficientfederatededgeintelligenceforiotnetworks.in2021 [110] zhaohuiyang,mingzhechen,walidsaad,choongseonhong,andmohammad
ieee41stinternationalconferenceondistributedcomputingsystemsworkshops shikh-bahaei.2020.energyefficientfederatedlearningoverwirelesscommuni-
(icdcsw).55–62. https://doi.org/10.1109/icdcsw53096.2021.00016 cationnetworks.ieeetransactionsonwirelesscommunications20,3(2020),
[102] yuwang,rongge,andshuangqiu.2020. energy-awarednngraphopti- 1935–1949.
mization.resource-constrainedmachinelearning(recoml)workshopofml- [111] chunrongyao,wantaoliu,weiqingtang,jinrongguo,songlinhu,yijunlu,
sys2020conference(may2020). https://doi.org/10.48550/arxiv.2005.05837 andweijiang.2021.evaluatingandanalyzingtheenergyefficiencyofcnn
arxiv:2005.05837 inferenceonhigh-performancegpu.concurrencyandcomputation:practice
[103] yuewang,ziyujiang,xiaohanchen,pengfeixu,yangzhao,yingyanlin, andexperience33,6(2021),e6064.
andzhangyangwang.2019. e2-train:trainingstate-of-the-artcnnswith [112] barzanayosuf,sanaahmohamed,mohammedmalenazi,taisirehel-gorashi,
over80%energysavings.inadvancesinneuralinformationprocessingsystems, andjaafarmhelmirghani.2021.energy-efficientaioveravirtualizedcloud
h.wallach,h.larochelle,a.beygelzimer,f.d'alché-buc,e.fox,andr.garnett fognetwork.inproceedingsofthetwelfthacminternationalconferenceon
(eds.),vol.32.curranassociates,inc. https://proceedings.neurips.cc/paper/ futureenergysystems.328–334.
2019/file/663772ea088360f95bac3dc7ffb841be-paper.pdf [113] jia-rueiyu,chun-hsienchen,tsung-weihuang,jang-jihlu,chia-ruchung,
[104] simonwenninger,cankaymakci,christianwiethe,j¨""orgr¨""ommelt,lukas ting-weilin,min-hsienwu,yi-jutseng,andhsin-yaowang.2022.energy
baur,bj¨""ornh¨""ackel,andalexandersauer.2022.howsustainableismachine efficiencyofinferencealgorithmsforclinicallaboratorydatasets:green
learninginenergyapplications?–thesustainablemachinelearningbalance artificialintelligencestudy. j.med.internetres.24,1(jan.2022),e28036.
sheet. https://aisel.aisnet.org/wi2022/sustainable_it/sustainable_it/1 https://doi.org/10.2196/28036
[105] martinawillenbacher,torstenhornauer,andvolkerwohlgemuth.2021.re- [114] boyuzhang,azadehdavoodi,andyuhenhu.2018. exploringenergyand
boundeffectsinmethodsofartificialintelligence. inadvancesandnew accuracytradeoffinstructuresimplificationoftraineddeepneuralnetworks.
trendsinenvironmentalinformatics.springer,cham,switzerland,73–85. https: ieeejournalonemergingandselectedtopicsincircuitsandsystems8,4(2018),
//doi.org/10.1007/978-3-030-88063-7_5 836–848. https://doi.org/10.1109/jetcas.2018.2833383
[106] carole-jeanwu,ramyaraghavendra,uditgupta,bilgeacun,newshaardalani, [115] xingzhouzhang,yifanwang,andweisongshi.2018.pcamp:performance
kiwanmaeng,gloriachang,fionaaga,jinshihuang,charlesbai,etal.2022. comparisonofmachinelearningpackagesontheedges.inusenixworkshop
sustainableai:environmentalimplications,challengesandopportunities.pro- onhottopicsinedgecomputing(hotedge18).
ceedingsofmachinelearningandsystems4(2022),795–813. [116] shazhu,kaoruota,andmianxiongdong.2021. greenaiforiiot:energy
[107] haichuanyang,yuhaozhu,andjiliu.2019.energy-constrainedcompression efficientintelligentedgecomputingforindustrialinternetofthings. ieee
fordeepneuralnetworksviaweightedsparseprojectionandlayerinputmasking. trans.greencommun.networking6,1(aug.2021),79–88. https://doi.org/10.
1109/tgcn.2021.3100622"
4,Diversification in the age of the 4th industrial revolution_ The role of artificial intelligence_ green bonds and cryptocurrencies.pdf,"
citation:
huynh, tld and hille, e and nasir, m-a (2020) diversification in the age of the 4th indus-
trial revolution : the role of artificial intelligence, green bonds and cryptocurrencies.
technological forecasting and social change, 159. p. 120188. issn 0040-1625 doi:
https://doi.org/10.1016/j.techfore.2020.120188
link to leeds beckett repository record:
https://eprints.leedsbeckett.ac.uk/id/eprint/6890/
document version:
article (accepted version)
the aim of the leeds beckett repository is to provide open access to our research, as required by
funder policies and permitted by publishers and copyright law.
the leeds beckett repository holds a wide range of publications, each of which has been
checked for copyright and the relevant embargo period has been applied by the research services
team.
we operate on a standard take-down policy. if you are the author or publisher of an output
and you would like it removed from the repository, please contact us and we will investigate on a
case-by-case basis.
each thesis in the repository has been cleared where necessary by the author for third party
copyright. if you would like a thesis to be removed from the repository or believe there is an issue
with copyright, please contact us on openaccess@leedsbeckett.ac.uk and we will investigate on a
case-by-case basis.
diversification in the age of the 4th industrial revolution: the role of
artificial intelligence, green bonds and cryptocurrencies
toan luu duc huynh1,a,b, erik hillec, muhammad ali nasird
a university of economics ho chi minh city, vietnam
b whu – otto beisheim school of management, germany
c hhl leipzig graduate school of management, germany
d leeds beckett university, united kingdom
abstract
in the context of the 4th industrial revolution, artificial intelligence (ai) and environmental
challenges, this study investigates the role of ai, robotics stocks and green bonds in portfolio
diversification. using daily data from 2017 to 2020, we employ tail dependence as copulas and the
generalized forecast error variance decomposition to examine the volatility connectedness. our
results suggest that, first, portfolios consisting of these assets exhibit heavy-tail dependence which
implies that in the times of economic turbulence, there will be a high probability of large joint
losses. second, volatility transmission is higher in the short term, implying that short-term shocks
can cause higher volatility in the assets, but in the long run, volatility transmission decreases. third,
bitcoin and gold are vital assets for hedging, though the bitcoin is also affected by its past volatility,
a feature it shares with green bonds and nasdaq ai. during economic downturns, gold may act
as a safe haven, as its shock transmission to nasdaq ai is just around 1.41%. lastly, the total
volatility transmission of all financial assets is considerably high, suggesting that the portfolio has
an inherent self-transmitting risk which requires careful diversification. the nasdaq ai and
general equity indexes are not good hedging instruments for each other.
keywords: artificial intelligence; portfolio diversification; green bonds; nasdaq ai; 4th industrial revolution;
cryptocurrencies.
jel codes: g11, g15, g17
declarations of interest: there is no conflict of interest to be declared.
1 corresponding author: toan luu duc huynh, university of economics ho chi minh city (vietnam). e-mail:
toanhld@ueh.edu.vn.
* acknowledgement: authors are thankful to two anonymous reviewers and the participants of the international
conference on the contemporary issues in finance, trade and macroeconomy (icofint) for the kind remarks and
comments on the initial draft of this paper. all remaining errors are our own.
1
1 introduction
portfolio diversification and the need for safe-haven assets have been important elements of
investment strategies for many decades. in this context, gold has traditionally played the role of
hedging in normal times and of a safe haven in the times of market turmoil (baur and lucey, 2010;
shahzad et al., 2020). while the increased investment in gold for speculative and hedging purposes
might have altered its safe-haven property (baur and glover 2012), new investment opportunities
and multiple ways to both diversify portfolios and hedge risk have emerged in the recent years.
specifically, this paper is focused on three of these new investment opportunities that the era of the
4th industrial revolution has brought us. these are the emergence of artificial intelligence (ai) and
robotics technology companies, green bonds which provide benefits to environmentally friendly
projects and bitcoin which is the leading cryptocurrency.
ai and robotics are key technologies of the 4th industrial revolution. through these disruptive
technological advances, the 4th industrial revolution is expected to blur the boundaries among
physical, digital, and biological worlds, thereby rapidly and fundamentally changing the ways we
live, work, and interact with each other. during the past decade, the activities related to ai and
robotics have significantly increased (felten et al. 2018; furman and seamans, 2019). for instance,
while the worldwide shipments of robots rose by roughly 150% between 2010 and 2016, the share
of jobs demanding ai skills was nearly five times higher in 2016 as compared to 2013 (furman
and seamans, 2019). similarly, investment in ai has rapidly grown (bughin et al., 2017). in 2016
alone, established companies spent $18 to $27 billion for internal investments in ai-related projects
and between $2 and $3 billion on ai-related mergers and acquisitions. venture capital investment
in innovative ai start-ups increased by 40% between 2013 and 2016. companies use ai and
robotics technologies for various reasons, including lower costs and production times, consistent
product quality, and supply chain operations management (webster and ivanov, 2020). however,
while ai and robotics may help to increase productivity growth, the effects on employment are
mixed, particularly in the short-run (acemoglu and restrepo, 2018, 2019; brynjolfsson et al. 2017;
furman and seamans, 2019; graetz and michaels, 2018). at present, ai and robotics technologies
are adopted across the world, penetrating not only the manufacturing sectors using industrial robots
but also other economic activities, such as trading on financial markets, transportation through
autonomous vehicles, customer relationship management using chatbots, legal provision, and
medical diagnostics and operations (webster and ivanov, 2020). intuitively, ai and robotics
technology companies have become increasingly influential, representing an interesting investment
option for portfolio diversification.
green bonds are also a potential venue for portfolio diversification and have been developed into
popular financial instruments in recent years, mainly because they address the need for both
financial resources and environmental protection. in general, green bonds have similar
characteristics as conventional fixed-income corporate bonds, yet their earnings are used for
environmentally friendly projects only (reboredo and ugolini, 2019). consequently, green bonds
may help to improve the financial performance of companies as well as environmental
performance, by fostering green innovations and long-term green investments (flammer, 2019). in
this regard, green bonds complement the actions of governments which have increasingly
implemented environmental policy instruments to induce green innovation, build up clean energy
technology capacities and thus improve the environmental quality (hille et al., 2020). given the
2
urgent need to fight climate change and potential intergenerational regulatory conflicts, some
researchers consider green bonds as the instrument of choice to finance climate change mitigation
(flaherty et al., 2017; sartzetakis, 2020). the transparency and reputation of green bonds have
been enhanced by the publication of the green bond principles (gbp) by the international capital
markets association in 2014, establishing standardised rules for labelling bonds as green
(reboredo, 2018). while stock exchanges around the world have opened specific green bond
segments in recent years, the size and significance of the green bonds market has been growing,
making green bonds a well-established and sustainable investment instrument (febi et al., 2018;
reboredo and ugolini, 2019).
cryptocurrencies such as bitcoin have been developed as decentralized digital currencies and
payment systems. while cryptocurrencies are used to verify transactions, they have become a
popular investment instrument and are sometimes considered as a better currency or even as digital
gold (barber et al., 2012; selmi et al., 2018). the use of blockchain technology has been seen as a
great financial disruptor and manifestation of the 4th industrial revolution (white et al., 2020). the
cryptocurrencies have accumulated a considerable market capitalization of about $190 billion since
the inception of bitcoin in 2009. at present, there exist more than one thousand cryptocurrencies
(corbet et al., 2019). however, the role that cryptocurrencies will play in future financial markets
remains unclear. for instance, dyhrberg (2016a) argued that the bitcoin can be classified between
gold and us dollar on a scale that considers the advantages of a pure medium of exchange on the
one hand, to those of a pure storage of value on the other. gronwald (2019) argued that the bitcoin
resembles more to an asset or speculative investment rather than a currency. similarly, instead of
a currency or a security, white et al. (2020) saw bitcoin as a technology-based product, an
emerging asset class or a bubble event. contextualising on this debate, the subject study analyses
the role of stocks of ai and robotics companies for portfolio diversification, thereby considering
average returns, possible risk, and correlations with alternative investments, such as green bonds
and bitcoin. it contributes to the existing evidence in two main aspects. first, using data on the
nasdaq artificial intelligence and robotics index (nasdaq ai), this is the first study that
specifically considers the role of ai and robotics company stocks for portfolio diversification. the
nasdaq ai is recently established in december 2017 to track the performance of technology-
intensive companies active in the ai and robotics sector. prior studies have only considered
technology-intensive companies in general (ahmad and rais, 2018; kumar et al., 2012) or
companies of other specific technology-intensive sectors, such as it or clean energy technologies
(jawadi et al., 2013; ortas and moneva, 2013). second, the focus of this study is on the dynamic
interdependencies with other assets, including green bonds and bitcoin. hence, we also supplement
the recently popular and rapidly growing empirical literature on green financial instruments and
cryptocurrencies (bouri et al., 2018; lundgren et al., 2018; selmi et al., 2018; tang and zhang,
2019). to analyse extreme market situations as well as short- and long-term volatility spillovers,
we use two main methodological approaches. specifically, we consider tail dependences via
copulas (embrechts et al., 2001) and frequent interconnectedness via variance decompositions and
their spectral representation in combination with the generalized forecast error variance
decomposition (baruník and kocenda, 2019).
drawing on daily data from 19th december 2017 to 16th january 2020, we employ tail dependence
as copulas and the generalized forecast error variance decomposition to analyse volatility
3
connectedness. our key findings suggest that, first, portfolios consisting of the underlying assets
exhibit heavy-tail dependence, thus in times of economic turmoil losses can exacerbate with
alternative investments, having a high probability of extreme losses at the same time. second, the
volatility transmission is higher in the short term than in the long term, implying that short-term
shocks may cause higher volatility in the assets in our portfolio. however, holding this portfolio
would decrease the volatility transmission among the assets in the long term. third, bitcoin and
gold are the most vital assets for hedging, although the bitcoin is also affected by its past volatility,
a feature it shares with green bonds and nasdaq ai. gold seems to play an important role in
hedging during economic and financial downturns, as the shock transmission of gold to nasdaq
ai is only around 1.41%. lastly, the total volatility transmission of all financial assets is
considerably high, suggesting that the portfolio has an inherent and self-transmitting risk, which
requires careful diversification. the nasdaq ai and the general equity indexes are not good
hedges for each other. these findings on ai stocks, cryptocurrencies and green investment
opportunities have important implications for portfolio diversification in the age of the 4th industrial
revolution. the existing evidence (details in next section) acknowledges the importance of these
investment classes. however, despite the irrefutable evidence on the importance of ai, green
bonds, and cryptocurrencies for different aspects of the economy and financial sector, their usage
in portfolio diversification and hedging against each other is underexplored. concomitantly, the
subject study fills this gap by analysing their role in portfolio diversification in the context of the
4th industrial revolution.
the paper proceeds as follows: section 2 provides a critical review of the existing literature on the
subject. details on the methodology and data are provided in section 3. findings are presented in
section 4, and lastly, section 5 concludes.
2 literature review
there are generally several approaches to the decision on whether an asset is suitable for
investment. for instance, from a risk perspective, when an asset is negatively related with other
assets in the portfolio, then adding this asset to the portfolio will diversify the portfolio and hence
decrease risks (bouri, 2017). nonetheless, there is a difference between a diversifier, a hedge and
a safe haven (baur and lucey, 2010; ratner and chiu, 2013). a diversifier is an asset that has a
weak positive correlation with another asset on average. while a hedge is an asset that is either
uncorrelated or negatively correlated with another asset on average, the same properties hold for a
safe haven, but in times of market turmoil. hence, a diversifier and a hedge provide diversification
benefits on average, yet unlike a safe-haven investment, they do not necessarily reduce risk when
it is needed the most (baur and lucey, 2010). traditionally, gold has been regarded as a hedge and
safe haven, yet more recently these properties have also been tested for other assets, including
credit default swaps (ratner and chiu, 2013), bitcoins (selmi et al. 2018) and a vast literature has
considered the broader aspects of portfolio diversification (arouri et al., 2015; brière et al., 2015;
guesmi et al., 2019; reboredo, 2018).
in the context of portfolio diversification, this study has three aspects and hence can be related to
three strands of literature. firstly, the stocks of ai and robotics companies. dirican (2015) and
furman and seamons (2019) reviewed the impact of ai and robotics on business models and the
economy. to the best of the authors’ knowledge, no prior study has analysed the role of ai and
4
robotics company stocks for portfolio diversification. however, there have been studies
considering the stocks of technology-intensive and technology-related companies, such as of
technology companies in general (chen and lin, 2014; smales, 2019), it companies (kamssu et
al., 2003; jawadi et al., 2013) and clean-technology companies (ortas and moneva, 2013). on
average, it is expected that both the returns and volatility of ai and robotics company stocks are
higher than those of companies which are in less technology-intensive sectors. these
characteristics would generally be in line with those of technology company stocks in general. that
is, the volatility of technology stocks has tended to be much higher than that of overall equity
markets (jiang et al., 2011). similarly, the performance of technology stocks has often exceeded
conventional stocks (kamsu et al., 2003; ortas and moneva, 2013). in this regard, a higher market
value of r&d-intensive companies is found to be positively associated with a higher r&d
capability (e.g. filed patents) of the respective company (deng et al., 1999; lin and liang 2010).
previous studies have examined the relationship between technology stocks and a variety of other
stocks and assets, including general equity markets (hansda and ray, 2002; jawadi et al., 2013),
oil prices and clean energy company stocks (kumar et al. 2012; sadorsky, 2012), cryptocurrencies
(smales, 2019; symitsi and chalvatzis, 2018), gold (chen and lin, 2014; chen and wang, 2018),
and credit default swaps (ratner and chiu, 2013). it has been reported that technology stock prices
affect conventional domestic and foreign stocks (hansda and ray, 2002) and they also react to
changes in global capital markets (jawadi et al., 2013). a comparatively large body of research has
analysed the interdependences between technology stocks, oil prices, and clean energy stocks,
revealing dependence, causality, and spillovers. one reason is that an increase in the oil price often
causes clean energy stock prices to rise, which in turn tends to increase technology stock prices
(lundgren et al., 2018). consequently, empirical studies have estimated similar market responses
of technology stock prices and those of clean energy stocks, often reflected in positive causality
(henriques and sadorsky, 2008; kumar et al., 2012; managi and okomoto, 2013). similarly,
volatility spillovers between the prices of technology company stocks, oil, and clean energy
company stocks have been found (ahmad 2017; ahmad and rais, 2018; sadorsky, 2012).
concerning the relation with cryptocurrencies, symitsi and chalvatzis (2018) reported both returns
and short-term volatility spillover from technology company stocks to bitcoin, yet smales (2019)
detected no significant correlation of the respective returns. while gold has often been attributed
as a safe haven for equity markets, this property appears to hold to a limited extent for technology
firms (chen and lin, 2014; chen and wang, 2018). likewise, credit default swaps have only in
parts been a strong safe haven for technology and telecommunication stock indices during periods
of market turmoil (ratner and chiu, 2013).
secondly, a related strand of literature has focused on green stocks and bonds. in this context, the
results on the performance of environmental investments are mixed. while ortas and moneva
(2013) found that the returns and risks of clean-technology equity indices are higher than those of
conventional stock indices, other studies, such as climent and soriano (2011) and reboredo et al.
(2017b), reported that green mutual funds have lower or similar returns and lower downside risk
protection than conventional mutual funds. similarly, green bonds tend to yield lower returns than
conventional bonds (baker et al., 2018; hachenberg and schiereck, 2018; zerbid, 2019), and
experience larger volatility (pham, 2016).
5
a relatively large number of studies has analysed the dynamic relationship between oil prices and
clean energy stocks, reporting causality, tail dependence (reboredo, 2015; reboredo et al., 2017a),
and volatility spillovers (sadorsky, 2012; wen et al., 2014). in line with this, prior studies have
found that prices of renewable energy firms are sensitive to oil price changes (henriques and
sadorsky, 2008; kumar et al., 2012; managi and okimoto, 2013). related literature, that is
particularly relevant to this study, has examined the interdependencies between green bond markets
and other markets. for instance, broadstock and cheng (2019) and pham (2016) analysed the
relationship between different bond markets. while the former detected that the relation between
green and black bond prices is contingent on financial market conditions, such as economic policy
uncertainty and volatility, the latter showed that shocks in the conventional bond market tend to
spill over to the green bond market. in studies by reboredo (2018) and reboredo and ugolini
(2019), weak or no dependencies were found between green bond markets and stock, energy, and
high-yield corporate bond markets. on the contrary, the two studies estimated close relationships
with treasury and corporate markets on the one hand, as well as with fixed-income and currency
markets on the other. strong dependencies of stock prices are estimated in lundgren et al. (2018)
and tang and zhang (2018). specifically, according to lundgren et al. (2018), the european stock
market depends on changes in renewable energy stock prices, whereas uncertainties play an
important role regarding return and volatility spillover to energy investments. in a study by tang
and zhang (2019), stock prices reacted positively to the announcement of green bond issuance, and
both institutional ownership and stock liquidity increased following the issuance of green bonds.
thirdly, the literature on cryptocurrencies is comparatively more recent, yet rapidly growing. while
corbet et al. (2019) provided an overview of the empirical literature on cryptocurrencies since their
introduction as a financial asset, dwyer (2015) explained the general economic and financial
properties of cryptocurrencies. most of the studies have focused on a single cryptocurrency, very
often the bitcoin (bouri et al., 2017; shahzad et al., 2019; urquhart and zhang, 2019). although
the volatility of cryptocurrencies is significantly higher than that of traditional assets and currencies
(corbet et al., 2018; dwyer, 2015), investors may earn higher returns and minimize overall risk by
including cryptocurrencies into diversified portfolios (brière et al., 2015; guesmi et al., 2019;
selmi et al., 2018). cryptocurrencies may, in part, act as a safe haven for oil price movements
(selmi et al., 2018), certain national currencies (urquhart and zhang, 2019), gold, and commodities
(shahzad et. al, 2019). nonetheless, investors should also be cautious, because cryptocurrencies
may be subject to inherent pricing bubbles (cheah and fry, 2015, huynh et al 2020), regulatory
disorientation (corbet et al., 2019), and cyber-criminality (gandal et al., 2018). moreover,
cryptocurrencies’ valuation is affected not only by traditional market forces but also by digital
currency-specific factors, such as social media activities on internet forums (mai et al., 2018) and
the respective cryptocurrency’s attractiveness for investors and users (ciaian et al., 2016).
several studies have investigated the relationship between cryptocurrency prices and other assets
and reported mixed evidence. on the one hand, no or weak links with classic asset prices are
reported. for instance, giudici and polinesi (2019) found that bitcoin prices are not influenced by
traditional asset prices, yet their volatilities are. according to baur et al. (2017), this missing
relationship is present during both normal times and times of financial turmoil. while
cryptocurrency markets are interrelated with each other, corbet et al. (2018) estimated that
cryptocurrency prices are relatively decoupled from a variety of assets, such as stocks, bonds, and
6
gold, hence offering a diversification benefit. similar conclusions are reached by bouri et al. (2017)
and dyhrberg (2016b), who estimated small positive correlations, and suggested that such
decoupling and diversification benefit is only present in the short run and may vanish in the long
run. on the other hand, some studies reported important linkages between cryptocurrencies and
other assets, suggesting high price correlations (jin et al. 2019), tail dependence (selmi et al., 2018)
as well as return and volatility spillovers (symitsi and chalvatzis, 2018). for example, jin et al.
(2019) reported that bitcoin prices are influenced relatively strongly by price fluctuations in gold
and oil markets. they found mostly negative dynamic correlations between bitcoin and the other
two markets. white et al. (2020) showed that the bitcoin market tends to be highly correlated with
derivatives and inversely correlated to major currencies. according to bouri et al. (2018),
cryptocurrency returns are relatively strongly related to other assets, especially commodities, and
cryptocurrency markets receive more volatility than they transmit. although estimating low
correlations of bitcoins with stock indices, symitsi and chalvatzis (2018) detected return spillovers
from energy and technology stock indices to bitcoins as well as long-run volatility effects from
bitcoins on fossil fuel and clean energy stocks.
to sum up, while no prior research has considered the role of ai and robotics company stocks for
portfolio diversification, we expect their characteristics to be similar to those of other technology-
intensive companies. specifically, both the returns and volatility of ai and robotics company stocks
are expected to be rather higher than for other stocks. as these firms are participants of a market
that is not yet mature, their stocks may tend to react significantly to changes in other asset markets,
such as the general equity markets and the oil price. a mixed picture exists concerning the hedging
and safe haven properties of other assets for stocks of technology-intensive firms. for green bonds,
prior studies have reported lower returns and higher volatility than for conventional bonds. the
relationship of green bond markets with other assets is mixed. for instance, while significant
interdependencies have been estimated with conventional bond, treasury, and currency markets,
green bonds tend to have weak or no dependencies with stock, energy, and high-yield corporate
bond markets. the rapidly growing research on cryptocurrencies has shown that both their returns
and volatility are comparatively high. mixed evidence exists regarding cryptocurrencies’
relationship with other assets. that is, not only weak or no linkages have been estimated, suggesting
that cryptocurrencies may partly act as hedges or safe havens, but researchers have also reported
important linkages in the form of high price correlations, tail dependence, and high return and
volatility spillovers.
3 data and methodology
3.1 data collection and descriptive statistics
we collected daily data from thomson reuters for eight financial asset classes for the period from
19th december 2017 to 16th january 2020. the main reason to start from 19th december 2017 is
that the data on nasdaq ai index has been available from this date, whereas the other
components were already traded earlier. in total, our time frame includes 544 observations for each
variable. the nasdaq ai was established to track the performance of firms that are active in ai
and robotics, including technology, industrial, medical, and other economic sectors. therefore, this
proxy reflects the innovation level of the market as well as the performance of this industry in the
era of the 4th industrial revolution. moreover, oil, gold, cboe volatility (vix), and msci equity
7
indices (msci world and msci usa) are well-known investments and, in parts, safe havens for
investors. we used the s&p green bond select index as a proxy for the green bond market. this
index is a market value-weighted subset of the s&p green bond index, designed to track the
performance of green-labelled bonds issued globally. although the market size of green bonds is
relatively small compared to the other potential financial investments, green investments have
attracted much attention from investors recently, and therefore including a green bond index is
important to consider the inherent risk for portfolio diversification. last, we included bitcoin in
the underlying portfolio, because the boom of cryptocurrencies since 2013 has increased this
market’s attractiveness for investors.
table 1. descriptive statistics
variables mean standard deviation skewness kurtosis jb adf
nasdaq ai 0.00041 0.01002 -0.60558 4.41910 78.75*** -19.783***
oil 0.00004 0.01996 -0.00049 8.36033 650.1*** -22.469***
bitcoin -0.00144 0.14705 -0.30783 32.51568 2000*** -35.272***
green bond -0.00002 0.00483 0.21941 97.20986 20000*** -32.123***
msci world 0.00025 0.01301 0.26417 60.51622 75000*** -26.018***
msci usa 0.00039 0.01525 0.04356 62.62450 80000*** -27.623***
gold 0.00038 0.01376 0.27584 76.08298 12000*** -29.404***
vix 0.00047 0.09822 0.96772 20.60982 7101*** -26.435***
notes: the symbols ***, ** and * indicate significance at the 1%, 5% and 10% levels, respectively. jb denotes the jarque-
bera test for normality.
fig 1. investment performance from january 2018 to january 2020a, b
a source: self-prepared using the data from thomson reuters eikon.
b note: to make the scales comparable, we normalised the rate of return of the assets to 100. the right y-axis refers to
bitcoin and vix and the left y-axis to the remaining assets.
8
as can be seen in table 1, except for bitcoin and green bonds that exhibit negative returns, the
average returns of the assets were positive during the period of analysis, hence they were potentially
promising investments. the highest average return can be observed for vix, followed by the
nasdaq ai. however, the nasdaq ai has a much lower standard deviation (0.01) than vix
(0.09), implying that the same one unit of oscillation offers a higher return for nasdaq ai than
vix. moreover, it is important to note that all variables have non-normal distributions and are
stationary at levels. these characteristics are important to consider when choosing the appropriate
econometric approach to examine the possible risk of the diversified portfolio. the general picture
of the average values is supported by figure 2, depicting the normalized returns over time. that is,
especially bitcoin tends to underperform during the period of analysis, while vix displays high
uncertainties, which spike at the beginning of 2018 and 2019. similarly, crude oil exhibits a highly
volatile pattern that peaked above 130 shortly before dropping below 80. consequently, a thorough
analysis is necessary to avoid excessive risks and optimise the portfolio diversification for the
different financial assets.
table 2 depicts the correlations between the underlying variables. first, vix has a negative
correlation with all other investments. that is, based on the mean-variance analysis, vix can be a
good hedging instrument for these assets. we are particularly interested in the price movement of
the nasdaq ai, representing the performance of ai and robotics industry companies. there are
three assets with significantly positive correlation with nasdaq ai, namely oil and the two msci
equities. overall, nasdaq ai does not linearly commove with bitcoin, green bonds, and gold,
whereas it strongly correlates with oil, equities, and vix. oil is independent of the movement of
bitcoin, green bonds, and gold, while green bonds are independent of nasdaq ai, oil, and
bitcoin. bitcoin appears to be independent of all other assets, which is in line with findings of
several prior studies suggesting that it could be used as a safe haven for other financial assets (bouri
et al., 2017), gold and commodities (shahzad et. al, 2019), other currencies (urquhart and zhang,
2019), and oil price movements (selmi et al., 2018). regarding the correlations, this only holds to
a limited extent for gold, which shows significant association with several assets. except for
bitcoin, the equity indices are significantly and positively correlated with all other assets. however,
correlation is based on a linear dependence structure, while we found non-normal distributions for
our variables in table 1. hence, the subsequent empirical analysis will provide more insights for a
profound diversification strategy in the era of the 4th industrial revolution.
table 2. correlation matrix
variables nasdaq ai oil bitcoin green bond msci world msci usa gold vix
nasdaq ai 1
oil 0.2149*** 1
bitcoin 0.0293 -0.0117 1
green bond 0.0332 -0.0228 0.0135 1
msci world 0.4994*** 0.1029** 0.0234 0.6334*** 1
msci usa 0.5120*** 0.0962** 0.023 0.4357*** 0.9539*** 1
gold -0.0102 -0.0212 0.028 0.7821*** 0.7287*** 0.6533*** 1
vix -0.6333*** -0.1552*** -0.0409 -0.4131*** -0.6561*** -0.5982*** -0.2863*** 1
note: the symbols ***, ** and * indicate significance at the 1%, 5% and 10% levels, respectively.
9
3.2 methodology
to examine the role of diversification of these assets in a portfolio, we follow two main
methodological approaches. these are tail-dependence as copulas (embrechts et al., 2001) and
volatility interconnectedness via the generalized forecast error variance decomposition (baruník
and kocenda, 2019). there are also two main reasons to employ these methods. first, we would
like to examine how the financial assets co-move in the case of economic downturns, i.e. we are
interested in the extreme negative values. second, it is important to consider the level of volatility
spillovers among the assets in the short and long term for diversification strategies.
copulas are the structure of dependence in terms of joint distribution between two uniform
marginal variables. copulas were first introduced in the form of sklar's theorem. to account for
asymptotically large losses, nguyen and huynh (2019), boako et al. (2019), and rivieccio and de
luca (2016) demonstrated how to define the dependence structure through the family of heavy-tail
and stochastic copulas. to summarize our methodology, we begin with two variables x and y,
which are random and continuous. to examine if heavy-tail dependence is present in the portfolio,
we examine two kinds of copulas, namely gaussian copulas for the normal tail and student-t
copulas for the heavy tail. equation 1 represents the parameter estimation of gaussian copulas:
1 (exp(−𝜃𝑥)−1)(exp(−𝜃𝑦)−1)
𝐶(𝑥,𝑦) = − ln⁡(1+ ⁡⁡(eq.1)
𝜃 exp(−𝜃)−1
where θ denotes the linear correlation coefficient. as mentioned earlier, our variables do not
linearly commove. thus, we consider student-t copulas with heavy-tail estimates. in particular,
𝑡−1(𝑢) denotes the inverse of the cumulative distribution function of the standard univariate
𝜐
student-t distribution, with 𝜐 being the degree of freedom. equation 2 demonstrates how the
parameter, known as extreme dependence, can be estimated using student-t copulas:
𝑡𝜐−1(𝑥) 𝑡𝜐−1(𝑦) 1 𝑠2 −2𝜃𝑠𝑡 +𝑡2 𝑣+2
𝐶(𝑥,𝑦) = ∫ ∫ (1+ )− 2 𝑑𝑠𝑑𝑡⁡⁡⁡⁡⁡(eq.2)⁡⁡
2𝜋√1−𝜃2 𝑣(1−𝜃2)
−∞ −∞
following lourme and maurer (2017), we also employ the maximum likelihood approach to
choose the most appropriate copulas and to analyse the dependence structure between variables.
after considering the tail structure, we would like to see how these variables transmit volatility in
the portfolio. for this reason, we use the generalized arch or garch model with garch (1,1)
to predict the volatility, except for vix. afterwards, we employ the generalized var and spillover
index of diebold and yilmaz (2012, 2014) to investigate the directional spillovers. this approach
is advantageous in that it is invariant to the ordering of the variables. it also allows for the
calculation of both the direction and the strength of spillovers over time and among different
variables. we build a var(p) process for the vector of volatilities of all variables, v =
t
(v ,…,v )′, such as:
1t nt
p
v = ∑φ v +ε ⁡⁡where⁡⁡ε ⁡~⁡n(0,∑ )⁡⁡⁡(eq.3)
t i t−i t t
𝜀
i=1
the moving average representation of residual ε in var(p) has the following form:
t
10
∞
v = ∑ψ ε ⁡⁡⁡⁡⁡⁡⁡⁡⁡(eq.4)
t i t−i
i=1
in which ψ is a matrix of the coefficients. we briefly summarize the total spillovers index by using
i
the h-step-ahead generalized forecast error variance decomposition matrix, having the following
elements for h = 1,2…
2
σ−1∑h−1(e′ ψ σ e )
θh = kk h=0 j h ε k ,⁡⁡⁡⁡⁡⁡⁡⁡⁡j,k = 1,…n⁡(eq.5)
jk ∑h−1(e′ ψ ∑ ψ′ e )
h=0 j h ε h k
specifically, ψ is a matrix of the moving average coefficients, forecasted at time t, whereas σ
h ε
denotes the variance matrix for the error vector ε , and 𝜎 is the kth diagonal element of σ .
𝑡 𝑘𝑘 ε
furthermore, e and e are selection errors with 1 as the jth and kth element and 0 otherwise. we
j k
refer to baruník and kočenda (2019) to measure directional spillovers from asset j to asset k using
the following equation:
n
1
sh = 100× ∑θ̃h⁡⁡⁡⁡⁡(eq.6)⁡⁡⁡⁡⁡
n,j↔∎ n jk
k=1
j≠k
the receiving effects are calculated by adding all numbers in rows j, except for the terms on the
diagonal that refer to the effect on the asset itself. the sending effects are estimated as the sum of
numbers in the column, except for the numbers on the diagonal. to sum up, we employed two
general approaches, to answer two main questions: (i) does a dependence structure exist among
the considered investments? (ii) how much volatility do the investments transmit if we construct
a portfolio consisting of these assets?
4 empirical results
4.1 heavy-tail dependence
table 3 summarizes our copula parameters’ estimations and maximum log-likelihood values. we
select the most appropriate copula based on the highest maximum log-likelihood value. this
approach follows the recommendation of studies, such as rodriguez (2007). as can be seen, all
pairs share the heavy-tail phenomenon, which implies that in the extreme value case that may
happen in times of market turbulence, investors would have large joint losses. in other words, a
portfolio consisting of these assets will be bearish when there is market turbulence.
table 3. copulas estimates
pairs normal-copula student-t copulas
nasdaq ai – oil 0.2382 0.2469
[15.28] [17.81]
nasdaq ai – bitcoin 0.005916 0.00408
[0.0091] [0.9616]
nasdaq ai – green bond 0.02244 0.01573
11
[0.1313] [1.198]
nasdaq ai – gold -0.04039 -0.04523
[0.4255] [2.936]
nasdaq ai – msci world 0.8404 0.8618
[328.2] [382.5]
nasdaq ai – msci us 0.802 0.8234
[275.6] [325.9]
nasdaq ai - vix -0.6784 -0.685
[164] [175.3]
notes: the table displays the estimated copula dependence parameters for the gaussian and student-t
copulas. the maximum log-likelihoods are in brackets. the parameter range depends on the specific
copula. for instance, the gaussian parameter is restricted to the interval (-1, 1). the parameters measure
the magnitude of dependence. maximum log-likelihoods were calculated to choose the most
appropriate copula model from the recommendation of previous studies, such as rodriguez (2007).
compared to earlier research, our paper is the first endeavour to consider the tail-dependence
structure of nasdaq ai with different financial assets. several prior studies have reported
evidence of co-movement for some of under analysis alternative investments, including green
bonds and financial markets (reboredo, 2018), oil and equity markets (aloui et al., 2013), and gold
and stock markets (nguyen et al., 2016).
4.2 volatility transmission in the short and long term
we used the generalized forecast error variance decomposition to determine the volatility
connectedness, and thereby two general features are important. first, we choose two timeframes,
namely for the short-term analysis from one to five trading days, and for the long-term analysis
from five trading days to infinity. the main reason for this approach is that conventional trading
usually takes place for five days every week. a week is a reasonable amount of time for investors
to restructure the portfolio, i.e. to balance the portfolio based on performance. second, as this
method is based on vector-autoregressive estimations, two trading days are chosen as the optimal
lag length using the akaike information criterion. this is also the optimal lag length for our short-
and long-term analysis. tables 4 and 5 show the volatility connectedness for the short- and long-
term horizon, respectively. before going to the detailed analysis, it is worth noting that the total
volatility transmission is 60.48%. this implies that the volatility among the assets is higher than
the average.
table 4. volatility transmission from 1 to 5 trading days
from
to
nasdaq ai oil bitcoin green bond msci world msci usa gold vix
nasdaq ai 38.21 0.26 0.12 0.76 0.25 0.17 0.35 4.42
oil 0.46 78.30 0.07 0.28 0.09 0.16 0.14 0.42
bitcoin 0.37 0.15 70.84 0.12 0.05 0.06 0.04 0.14
green bond 1.04 0.17 0.10 71.32 2.64 13.68 4.12 2.27
msci world 1.51 0.13 0.03 10.82 60.41 0.10 1.06 3.67
msci usa 1.30 0.20 0.04 5.25 64.32 1.72 1.46 2.09
gold 0.71 0.17 0.03 12.11 54.94 0.69 3.56 5.22
vix 0.48 0.34 0.32 3.53 0.35 2.56 1.04 79.76
12
notes: the values reported are the variance decomposition, which is based on the diebold and yılmaz (2014) generalized var spillover
model with exogenous variables. the optimal lag length for the var model is selected using the akaike information criterion.
overall, the volatility transmission is higher in the short term than in the long term. taking a closer
look at the short term, it can be observed that nasdaq ai tends to be a more active sender than
a receiver. the average percentage that the other financial assets send to this asset ranges between
0.12% and 0.76%, except for vix with 4.42%. in contrast, this index contributes 0.48%, 1.30%,
and 1.51% volatility to vix, the us equity market, and the global equity market, respectively.
while the values for the equity markets are larger than the corresponding received volatilities, their
magnitudes are relatively small, suggesting that nasdaq ai has a quite low oscillation in the
equity markets. similarly, nasdaq ai transmits larger volatilities to the remaining assets than it
respectively receives. yet the marginal effects are also relatively small, for instance, amounting to
0.46% volatility transmitted to oil vs. 0.26% received from oil. thus, we can draw two main
inferences from our short-term analysis. first, the volatility transmission from other financial assets
to nasdaq-ai is relatively lower than 1.5%, except for self-transmission. noticeably, our
findings also confirm the role of bitcoin and gold as hedging instruments for a portfolio with stocks
of firms of the ai and robotics industry (arouri et. al, 2015; baur and lucey, 2010; selmi et al.,
2018; urquhart and zhang, 2019). importantly, the bilateral transmission between gold and bitcoin
is less than 0.03%. second, one should be cautious when putting similar categories in one portfolio,
specifically, nasdaq ai, msci world, and msci usa. however, as these effects are below
2%, they are not large enough to cause significant issues.
when it comes to the longer time horizon as shown in table 5, the volatility transmission is less
persistent, which provides evidence that there is no considerable interconnectedness among the
assets. thus, if investors tend to hold a portfolio in the long run, they should consider two points
in particular. first, the spillover effects among equity assets are dominant no matter what the time
horizon is. second, along with nasdaq ai, other assets including oil, gold, and bitcoin could be
put in the portfolio for diversification purposes.
table 5. volatility transmission from 5 to infinity trading days
from
to
nasdaq ai oil bitcoin green bond msci world msci usa gold vix
nasdaq ai 41.74 0.11 0.10 0.18 0.31 0.08 0.13 12.82
oil 0.41 19.25 0.05 0.07 0.00 0.01 0.04 0.25
bitcoin 0.23 0.09 27.86 0.00 0.04 0.00 0.00 0.00
green bond 0.67 0.01 0.01 2.69 0.03 0.69 0.05 0.51
msci world 0.23 0.02 0.03 3.30 18.25 0.01 0.30 0.14
msci usa 0.09 0.05 0.03 1.87 19.83 0.50 0.54 0.71
gold 0.12 0.02 0.05 3.71 18.54 0.02 0.06 0.05
vix 0.46 0.12 0.04 0.42 0.03 0.39 0.06 10.10
notes: the values reported are the variance decomposition, which is based on the diebold and yılmaz (2014) generalized var spillover model
with exogenous variables. the optimal lag length for the var model is selected using the akaike information criterion.
4.3 total interconnectedness
figure 2 depicts the total interconnectedness for the portfolio consisting of all considered financial
assets by using the rolling window for at least 250 trading days. therefore, our estimates focus on
13
the end of 2018 until the beginning of 2020. to our greatest surprise, the average
interconnectedness is around 50%. meanwhile, in the year 2019, we witnessed two times that this
total value spikes at the peak. if we have a closer look at figure 2, it is clear that the main shock
senders are bitcoin, green bonds, and nasdaq ai. furthermore, bitcoin and green bonds show
quite large endogenous shocks (70.84% and 71.32% in the given order), which implies very volatile
returns as depicted in figure 3. following this, nasdaq ai also manifests endogenous shocks in
the short- and long term (38.21% and 41.74%, respectively). these values support our finding that
bitcoin, green bonds, and nasdaq ai are shock senders. moreover, the results suggest that
although nasdaq ai, bitcoin, and green bonds can be considered as good investments due to
high returns, the high volatility in these assets’ price movement and hence inherent risk arising
from them, needs to be taken into account. on the contrary, the remaining assets are just receivers,
because the net spillover values are negative over this period.
(a) total volatility interconnectedness (b) net spillover volatility
fig 2. the total interconnectedness and net spillover volatility in the portfolio
fig 3. price movement of bitcoin, green bond, and nasdaq ai
14
5. conclusion
the 4th industrial revolution has brought a whole set of unprecedented challenges to the global
economy, financial markets and all stakeholders of society. it has also brought new opportunities
in terms of ai, blockchain, and cryptocurrencies. in parallel to these, climate change poses an
existential challenge faced by the world in the 21st century. to tackle this challenge, there are
efforts from various sectors, including the financial sector in the form of green investment
opportunities like green bonds. contextualising on this background, this study endeavoured to find
the answer to a very old question in the very new era of the 4th industrial revolution. we explored
the notion of portfolio diversification in the presence of ai, blockchain or cryptocurrencies, green
bonds as well as the pre-industrial revolution assets such as gold, and traditional assets like
common stocks. in so doing, this pioneering study provides evidence on the specific role of ai and
robotics stocks in portfolio diversification and contributes to the rapidly growing empirical research
on green financial instruments and cryptocurrencies.
the overarching findings and conclusion have four main aspects. first, a portfolio consisting of
these assets exhibits heavy-tail dependence. this implies that in the times of economic and
financial turbulences the worst case happens, as all alternative investments have a high probability
of significant losses at the same time. second, the volatility transmission is higher in the short term
than in the long term. consequently, short-term shocks can cause higher volatility in the other
financial assets in the portfolio, whereas holding this portfolio in the long run would decrease the
volatility transmission among the assets. third, the bitcoin and gold are estimated to be the
dominant hedging positions, with the limitation that the bitcoin is also affected by its past volatility,
requiring some cautiousness. this characteristic of volatility persistence is also found in green
bonds and nasdaq ai. to hedge against economic downturn risk in our portfolio, gold, which
is one of the oldest assets class, turned out to be very useful. this is due to the reason that its shock
transmission to nasdaq ai is just around 1.41%. lastly, the total volatility transmission of all
financial assets is considerably high, amounting to on average around 50%, with two spikes even
close to 90%. this led us to infer that the portfolio has an inherent self-transmitting risk that
requires appropriate diversification.
there are several useful implications that can be derived from our findings for both policymakers
and investors interested in portfolio diversification in the age of the 4th industrial revolution.
investors, that diversify their portfolio with stocks of ai and robotics companies, cryptocurrencies,
and green bonds, need to be aware that some portfolio risks prevail. in particular, during market
turmoil, such a portfolio faces a high risk of large joint losses. to hedge risk during both normal
times and times of economic downturn, we would particularly emphasize the role of gold as a
hedge and safe haven. given that volatility transmission is lower in the long term, our results
suggest a buy and hold investment strategy to reduce the risks associated with volatility spillovers.
to address the high total volatility transmission, investors need to diversify carefully. for example,
not putting the nasdaq ai and the general equity indexes into the same portfolio may be a wise
choice. hence, investors need to be aware that besides the performance of ai and robotics firms,
the performance of ai indexes is still massively influenced by other sectors. we draw the attention
of policymakers and manager based on two main perspectives. first, the legal framework regarding
the information asymmetries should be considered to mitigate the potential risk among these
markets. it is obvious that fintech and ai financial assets have brought ambiguous information in
15
terms of financial ratios. second, managers should consider the threshold of potential losses, i.e.
the value-at-risk, the worst-case scenario in the internal guidance for trading. furthermore, the clear
procedure to update the newly released information about financial technologies might help to
reduce the risk transmission among these markets.
our analysis is subject to some limitations since the ai index is a new investment venue, the
instruments like ai indexes, cryptocurrencies, and green bonds are yet to mature. further research
can focus on broadening the asset classes and by extending to other developed and developing
markets. furthermore, thanks to the development of machine learning, there are other promising
approaches and methodologies, such as xgtboost, which can also be used in future research.
16
references
acemoglu, d., & restrepo, p. (2018). the race between man and machine: implications of technology for
growth, factor shares, and employment. american economic review, 108(6), 1488-1542.
acemoglu, d., & restrepo, p. (2019). the wrong kind of ai? artificial intelligence and the future of labor
demand. nber working paper, no. 25682.
ahmad, w. (2017). an analysis of directional spillover between crude oil prices and stock prices of clean
energy and technology companies. research in international business and finance, 42(1), 376-389.
ahmad, w., & rais, s. (2018). time-varying spillover and the portfolio diversification implications of clean
energy equity with commodities and financial assets. emerging markets finance and trade, 54(8), 1837-
1855.
aloui, r., hammoudeh, s., & nguyen, d. k. (2013). a time-varying copula approach to oil and stock
market dependence: the case of transition economies. energy economics, 39, 208-221.
andersen, t. g., & bollerslev, t. (1998). answering the skeptics: yes, standard volatility models do provide
accurate forecasts. international economic review, 885-905.
arouri, m. e. h., lahiani, a., & nguyen, d. k. (2015). world gold prices and stock returns in china:
insights for hedging and diversification strategies. economic modelling, 44, 273-282.
baker, m., bergstresser, d., serafeim, g., & wurgler, j. (2018). financing the response to climate change:
the pricing and ownership of us green bonds. nber working paper, no. 25194.
barber, s., boyen, x., shi, e., & uzun, e. (2012). bitter to better: how to make bitcoin a better currency.
in: international conference on financial cryptography and data security. springer, berlin, heidelberg,
pp. 399-414.
baruník, j., & kocenda, e. (2019). total, asymmetric and frequency connectedness between oil and forex
markets. the energy journal, 40(special issue).
baur, d. g., & glover, k. j. (2012). the destruction of a safe haven asset? applied finance letters, 1(1),
8-15.
baur, d. g., hong, k., & lee, a. d. (2017). bitcoin: medium of exchange or speculative assets? journal
of international financial markets, institutions and money, 54(1), 177-189.
baur, d. g., & lucey, b. m. (2010). is gold a hedge or a safe haven? an analysis of stocks, bonds and
gold. the financial review, 45, 217-229.
bouri, e., das, m., gupta, r., & roubaud, d. (2018). spillovers between bitcoin and other assets during
bear and bull markets. applied economics, 50(55), 5935-5949.
bouri, e., molnár, p., azzi, g., roubaud, d., & hagfors, l. i. (2017). on the hedge and safe haven
properties of bitcoin: is it really more than a diversifier? finance research letters, 20, 192-198.
boako, g., tiwari, a. k., ibrahim, m., & ji, q. (2019). analysing dynamic dependence between gold and
stock returns: evidence using stochastic and full-range tail dependence copula models. finance research
letters, 31.
brière, m., oosterlinck, l., & szafarz, a. (2015). virtual currency, tangible return: portfolio diversification
with bitcoin. journal of asset management 16 (6), 365–373.
broadstock, d. c., & cheng, l. t. (2019). time-varying relation between black and green bond price
benchmarks: macroeconomic determinants for the first decade. finance research letters, 29, 17-22.
brynjolfsson, e., rock, d., & syverson, c. (2017). artificial intelligence and the modern productivity
paradox: a clash of expectations and statistics. nber working paper, no. 24001.
17
bughin, j., hazan, e., ramaswamy, s., chui, m., allas, t., dahlström, p., henke, n., & trench, m. (2017).
artificial intelligence: the next digital frontier? mgi report, mckinsey global institute, june. http:// www
.mckinsey .com /business ‑ functions /mckinsey ‑ analytics /our
cheah, e.-t., & fry, j. (2015). speculative bubbles in bitcoin markets? an empirical investigation into the
fundamental value of bitcoin. economics letters 130, 32-36.
chen, a.-s., & lin, j. w. (2014). the relation between gold and stocks: an analysis of severe bear markets.
applied economics letters, 21(3), 158-170.
chen, k., & wang, m. (2018). is gold a hedge and safe haven for stock market? applied economics letters,
26(13), 1080-1086.
ciaian, p., rajcaniova, m., & kancs, d. a. (2016). the economics of bitcoin price formation. applied
economics, 48(19), 1799-1815.
climent, f., & soriano, p. (2011). green and good? the investment performance of us environmental
mutual funds. journal of business ethics, 103(2), 275-287.
corbet, s., meegan, a., larkin, c., lucey, b., & yarovaya, l. (2018). exploring the dynamic relationships
between cryptocurrencies and other financial assets. economics letters, 165(1), 28-34.
corbet, s., lucey, b., urquhart, a., & yarovaya, l. (2019). cryptocurrencies as a financial asset: a
systematic analysis. international review of financial analysis, 62(1), 182-199.
deng, z., lev, b., & narin, f. (1999). science and technology as predictors of stock performance. financial
analysts journal, 55(3), 20-32.
diebold, f. x., & yilmaz, k. (2012). better to give than to receive: predictive directional measurement of
volatility spillovers. international journal of forecasting, 28(1), 57-66.
diebold, f. x., & yılmaz, k. (2014). on the network topology of variance decompositions: measuring the
connectedness of financial firms. journal of econometrics, 182(1), 119-134.
dirican, c. (2015). the impacts of robotics, artificial intelligence on business and economics. procedia -
social and behavioral sciences, 195, 564-573.
dwyer, g. p. (2015). the economics of bitcoin and similar private digital currencies. journal of financial
stability, 17(1), 81-91.
dyhrberg, a. h. (2016a). bitcoin, gold and the dollar: a garch volatility analysis. finance research
letters 16(1), 85-92.
dyhrberg, a. h. (2016b). hedging capabilities of bitcoin. is it the virtual gold? finance research letters,
16(1), 139-144.
embrechts, p., lindskog, f., & mcneil, a. (2001). modelling dependence with copulas. rapport technique,
département de mathématiques, institut fédéral de technologie de zurich, zurich, 14.
engle, r. f. (2010). volatility and time series econometrics: essays in honor of robert engle. oxford
university press.
febi, w., schäfer, d., stephan, a., & sun, c. (2018). the impact of liquidity risk on the yield spread of
green bonds. finance research letter, 27(1), 53-59.
felten, e., raj, m., & seamans, r. (2018). a method to link advances in artificial intelligence to
occupational abilities. american economic association papers & proceedings, 108, 54-57.
flaherty, m., gevorkyan, a., radpour, s., & semmler, w. (2017). financing climate policies through
climate bonds: a three stage model and empirics. research in international business and finance, 42(1),
468-479.
flammer, c. (2019). corporate green bonds. academy of management proceedings, 2019(1).
18
furman, j., & seamans, r. (2019). ai and the economy. innovation policy and the economy, 19(1), 161-
191.
gandal, n., hamrick, j. t., moore, t., & oberman, t. (2018). price manipulation in the bitcoin ecosystem.
journal of monetary economics, 95(1), 86-96.
giudici, p., & polinesi, g. (2019). crypto price discovery through correlation networks. annals of
operations research, forthcoming.
graetz, g., & michaels, g. (2018): robots at work. the review of economics and statistics, 100(5), 753-
768.
gronwald, m. (2019). is bitcoin a commodity? on price jumps, demand shocks, and certainty of supply.
journal of international money and finance, 97(1), 86-92.
guesmi, k., saadi, s., abid, i., & ftiti, z. (2019). portfolio diversification with virtual currency: evidence
from bitcoin. international review of financial analysis, 63(1), 431-437.
hansda, s. k., & ray, p. (2002). bse and nasdaq: globalisation, information technology and stock prices.
economic and political weekly, 37(5), 459-468.
hachenberg, b., & schiereck, d. (2018). are green bonds priced differently from conventional bonds?
journal of asset management, 19(6), 371-383.
henriques, i., & sadorsky, p. (2008). oil prices and the stock prices of alternative energy companies. energy
economics, 30, 998-1010.
hille, e., althammer, w., & diederich, h. (2020). environmental regulation and innovation in renewable
energy technologies: does the policy instrument matter? technological forecasting and social change,
153(1), 119921.
huynh, t. l. d. nasir, m. a. vo, x.v. nguyen, t. t. (2020), “small things matter most”: the spillover
effects in the cryptocurrency market and gold as a silver bullet, north american journal of economics and
finance, forthcoming.
jawadi, f., jawadi, n., nguyen, d. k., & obeid, h. (2013). information technology sector and equity
markets: an empirical investigation. applied financial economics, 23(9), 729-737.
jiang, c. x., kim, j.-c., & wood, r. a. (2011). a comparison of volatility and bid–ask spread for nasdaq
and nyse after decimalization. applied economics, 43(10), 1227-1239.
jin, j., yu, j., hu, y., & shang, y. (2019). which one is more informative in determining price movements
of hedging assets? evidence from bitcoin, gold and crude oil markets. physica a: statistical mechanics and
its applications, 527(1), 121121.
kamssu, a. j., reithel, b. j., & ziegelmayer, j. l. (2003). information technology and financial
performance: the impact of being an internet-dependent firm on stock returns. information systems
frontiers, 5(3), 279-288.
kumar, s., managi, s., & matsuda, a. (2012). stock prices of clean energy firms, oil and carbon markets:
a vector autoregressive analysis. energy economics, 34, 215-226.
lin, y.-l., & liang, c.-j. (2010). how does research and development investment affect market value?
journal of statistics and management systems, 13(6), 1165-1185.
lourme, a., & maurer, f. (2017). testing the gaussian and student's t copulas in a risk management
framework. economic modelling, 67, 203-214.
lundgren, a. i., milicevic, a., uddin, g. s., & kang, s. h. (2018). connectedness network and dependence
structure mechanism in green investments. energy economics, 72(1), 145-153.
19
mai, f., bai, q., shan, z., wang, x., & chiang, r. (2018). how does social media impact bitcoin value? a
test of the silent majority hypothesis. journal of management information systems, 35(1), 19-52.
managi, s., & okimoto, t. (2013). does the price of oil interact with clean energy prices in the stock
market? japan and the world economy, 27(1), 1-9.
nguyen, c., bhatti, m. i., komorníková, m., & komorník, j. (2016). gold price and stock markets nexus
under mixed-copulas. economic modelling, 58, 283-292.
nguyen, s. p., & huynh, t. l. d. (2019). portfolio optimization from a copulas-gjr-garch-evt-cvar
model: empirical evidence from asean stock indexes. quantitative finance and economics, 3(3), 562.
ortas, e., & moneva, j. m. (2013). the clean techs equity indexes at stake: risk and return dynamics
analysis. energy, 57, 259-269.
pham, l. (2016). is it risky to go green? a volatility analysis of the green bond market. journal of
sustainable finance and investment, 6, 263-291.
ratner, m., & chiu, c. (2013). hedging stock sector risk with credit default swaps. international review of
financial analysis, 30, 18-25.
reboredo, j. c. (2015). is there dependence and systemic risk between oil and renewable energy stock
prices? energy economics, 48, 32-45.
reboredo, j. c. (2018). green bond and financial markets: co-movement, diversification and price spillover
effects. energy economics, 74, 38-50.
reboredo, j. c., rivera-castro, m. a., & ugolini, a. (2017a). wavelet-based test of co-movement and
causality between oil and renewable energy stock prices. energy economics, 61, 241-252.
reboredo, j. c., quintela, m., & otero, l. (2017b). do investors pay a premium for going green? evidence
from alternative energy mutual funds. renewable and sustainable energy reviews, 73, 512-520.
reboredo, j. d., & ugolini, a. (2019). price connectedness between green bond and financial markets.
economic modelling, forthcoming.
rivieccio, g., & de luca, g. (2016). copula function approaches for the analysis of serial and cross
dependence in stock returns. finance research letters, 17, 55-61.
rodriguez, j. c. (2007). measuring financial contagion: a copula approach. journal of empirical finance,
14(3), 401-423.
sadorsky, p. (2012). correlations and volatility spillovers between oil prices and the stock prices of clean
energy and technology companies. energy economics, 34(1), 248-255.
sartzetakis, e. s. (2020). green bonds as an instrument to finance low carbon transition. economic change
and restructuring, forthcoming.
shahzad, s. j. h., bouri, e., roubaud, d., kristoufek, l., & lucey, b. (2019). is bitcoin a better safe-haven
investment than gold and commodities? international review of financial analysis, 63, 322-330.
selmi, r., mensi, w., hammoudeh, s., & bouoiyour, j. (2018). is bitcoin a hedge, a safe haven or a
diversifier for oil price movements? a comparison with gold. energy economics, 74, 787-801.
smales, l. a. (2019). bitcoin as a safe haven: is it even worth considering? finance research letters, 30(1),
385-393.
symitsi, e., & chalvatzis, k. j. (2018). return, volatility and shock spillovers of bitcoin with energy and
technology companies. economics letters, 170(1), 127-130.
tang, d. y., & zhang, y. (2018). do shareholders benefit from green bonds? journal of corporate finance,
forthcoming.
20
urquhart, a., & zhang, h. (2019). is bitcoin a hedge or safe haven for currencies? an intraday analysis.
international review of financial analysis, 63, 49-57.
webster, c., & ivanov, s. h. (2020). robotics, artificial intelligence, and the evolving nature of work. in
george, b., & paul, j. (eds.). digital transformation in business and society: theory and cases. palgrave-
macmillan, cham.
wen, x., guo, y., wei, y., & huang, d. (2014). how do the stock prices of new energy and fossil fuel
companies correlate? evidence from china. energy economics, 41, 63-75.
white, r., marinakis, y., islam, n., & walsh, s. (2020). is bitcoin a currency, a technology-based product,
or something else? technological forecasting and social change, 151(1), 119877.
zerbid, o. d. (2019). the effect of pro-environmental preferences on bond prices: evidence from green
bonds. journal of banking and finance, 98(1), 39-60.
21"
5,Emerging technologies based on artificial intelligence to assess the quality and consumer preference of beverages.pdf,"
beverages
review
emerging technologies based on artificial
intelligence to assess the quality and consumer
preference of beverages
claudiagonzalezviejo1,* ,damird.torrico1,2 ,frankr.dunshea1 and
sigfredofuentes1
1 schoolofagricultureandfood,facultyofveterinaryandagriculturalsciences,universityofmelbourne,
parkville,vic3010,australia;damir.torrico@lincoln.ac.nz(d.d.t.);fdunshea@unimelb.edu.au(f.r.d.);
sfuentes@unimelb.edu.au(s.f.)
2 departmentofwine,foodandmolecularbiosciences,facultyofagricultureandlifesciences,lincoln
university,7647lincoln,newzealand
* correspondence: cgonzalez2@unimelb.edu.au;tel.:+61-412-055-704
(cid:1)(cid:2)(cid:3)(cid:1)(cid:4)(cid:5)(cid:6)(cid:7)(cid:8)(cid:1)
(cid:1)(cid:2)(cid:3)(cid:4)(cid:5)(cid:6)(cid:7)
received: 23august2019;accepted: 10october2019;published: 1november2019
abstract: beveragesisabroadandimportantcategorywithinthefoodindustry,whichiscomprised
ofawiderangeofsub-categoriesandtypesofdrinkswithdifferentlevelsofcomplexityfortheir
manufacturingandqualityassessment. traditionalmethodstoevaluatethequalitytraitsofbeverages
consistoftedious,time-consuming,andcostlytechniques,whichdonotallowresearcherstoprocure
resultsinreal-time. therefore,thereisaneedtotestandimplementemergingtechnologiesinorderto
automateandfacilitatethoseanalyseswithinthisindustry. thispaperaimedtopresentthemostrecent
publicationsandtrendsregardingtheuseoflow-cost,reliable,andaccurate,remoteornon-contact
techniques using robotics, machine learning, computer vision, biometrics and the application of
artificialintelligence,aswellastoidentifytheresearchgapswithinthebeverageindustry. itwas
foundthatthereisawideopportunityinthedevelopmentanduseofroboticsandbiometricsforall
typesofbeverages,butespeciallyforhotandnon-alcoholicdrinks. furthermore,thereisalackof
knowledgeandclaritywithintheindustry,andresearchabouttheconceptsofartificialintelligence
andmachinelearning,aswellasthatconcerningthecorrectdesignandinterpretationofmodeling
relatedtothelackofinclusionofrelevantdata,additionaltopresentingover-orunder-fittedmodels.
keywords: robotics;machinelearning;computervision;biometrics;artificialintelligence
1. introduction
beverages are often classified into three main categories: (i) alcoholic drinks, (ii) hot drinks,
and(iii)non-alcoholicdrinks. alcoholicdrinks(i)refertothosebeveragesthatarecomposedofa
minimumalcoholcontent,whichvariesaccordingtotheregulationsfromeachcountry; examples
fromthiscategoryincludebeer,wine,andspirits[1]. thehotdrinksgroup(ii)ismainlycomposed
of coffee, tea and hot chocolate [2]. on the other hand, non-alcoholic drinks (iii) includes juices,
stillandcarbonatedwater,milk,andsoftdrinks,whicharethosethatdonotbelongtoanyoftheother
categoriesandthatusuallycontainsweeteners,acids,flavoringagentsand/orcarbonation,suchas
carbonatedbeverages,energy,andsportsdrinks,amongothers[3,4]. qualityassessmentiscriticalto
meetconsumers’demandsandtoofferproductswithhighstandardsthatcomplywithregulations.
for all types of beverages, the quality traits to control may vary due to the specific characteristics
ofeachproduct. however,ingeneral,parameterssuchascolor,clarity,tastes,aromas,flavors,ph,
viscosityanddensityarestandardqualityindicators[5,6].
beverages2019,5,62;doi:10.3390/beverages5040062 www.mdpi.com/journal/beverages
beverages2019,5,62 2of25
incarbonateddrinks,otherdescriptorssuchasbubbleandfoam-relatedparametersareamong
the most important [7,8], while proteins or amino-acids and carbohydrates must be considered in
beveragessuchaswine,beer,coffee,tea,hotchocolateandjuices[9–11].
traditionalmethodstoassessqualityinbeveragesinvolvetediousandtime-consuminglaboratory
analysis,whichusuallyrequiresseveralexpensiveapparatusesandtheuseofconsumablesandskilled
personneltooperatethem. thesetechniquesgenerallyinvolveequipmentsuchasgaschromatography
(gc),high-performanceliquidchromatography(hplc),spectrometersforuv-visibleandnear-infrared,
colorimetersandviscometers,amongothers[12]. furthermore,sensoryevaluationisusedtoassess
theintensitiesoforganolepticdescriptors,suchasflavor,aroma,mouthfeel,andtastes,amongothers.
thistypeofsensorytestrequiresafixedpanelofeighttosixteenparticipantswithseveraltraining
sessions for the specific product, which leads to costly and time-consuming methods, including
conductingthesessions,datahandlingandstatisticalanalysis[13]. someindustries(i.e.,brewing),
relyononeortwopeople,suchasthemasterbrewer,toassessthesensoryqualityoftheproduct;
however,thisisnotanobjective,accuratenorreliablemethod,asitdoesnotfollowanystructuredand
quantitativemethod,anddoesnotinvolveanystatisticalanalysis[14]. anothertypeofsensorytest
istheacceptability,whichconsistsofgatheringaminimumof30–100consumers,dependingonthe
numberofsamplestoevaluateandthetargetmeanvaluesexpectedforlikingresults. this,alongwith
theextendedquestionnairestypicallypresentedtoparticipants,makethetechniquestime-consuming
andsubjective,astheyrelyontheconsumersresponsesthatmaybebiased,duetomanyfactorssuch
asculturaleffects;forexample,asianshaveshownatrendtobepoliteandavoidusingtheextremes
ofthescales[15,16]. therefore,theuseofbiometricstoassessconsumers’subconsciousresponses
bytappingintotheautonomicnervoussystemhasbeenimplemented,obtaininginterestingresults,
whichwillalsobereviewedinthispaper[17,18].
some novel methods, which involve the use of automated analysis techniques coupled with
artificial intelligence (ai), such as computer vision (cv), have been developed to assess some
of those quality parameters in food and beverages. these are more cost-effective and less
time-consuming methods, which allow having more objective, accurate, consistent, and reliable
results [19]. these techniques involve the use of different data sources, such as images or videos,
whicharethenprocessedusingcomputer-basedalgorithms,whichmaybefullyautomatedbycoupling
itwiththeuseofrobotics,andintegratedwiththeuseofmachinelearning(ml)modelingtopredict
thequalityofthefinalproductbasedondifferentmeasuredparameters. thosemethodsmayalso
consistoftheuseofmultisensorsystemsorarraysofsensors,whichareusuallyintegratedwithother
aitechniquestoassessspecificqualityparameters,suchasaromas,tastes,defects,andprocessing
conditions, amongothers. thispaperaimedtopresentthemostrecentdevelopmentsinlow-cost,
reliable,andaccurateremoteornon-contacttechniques,whichinvolvetheuseofcomputervision,
robotics,machinelearning,andbiometricmethodstoassessqualityinthebeverageindustrytodate.
thecontactsensortechnologywasreviewedonlyforthosetechniquesinwhichtheyarecoupledwith
anyoftheaforementionedtechnologies,andforcomparisonpurposeswhenappropriate.
2. robotics
robots refer to machines that can perform tasks or operations by themselves after being
programmedusingacomputer[20]. thosetasksmaybeeithersimpleandrepetitive, oradaptive
andmorecomplex,inwhichthelatterrequirestheintegrationofotheraimethods,suchascvand
ml,tocontinuallyretrainandlearntocarryoutmoreadvancedoperations[21]. theuseofrobotics
inthefoodandbeverageindustrieshasincreased,astheyhavetheadvantageofbeingreliable,not
getting tired or bored, and tasks may be done in less time with high accuracy and precision [22].
withinthemainapplicationsofroboticsinthebeverageindustryarepackaging,palletizing,pickand
place,andproduction[23]. however,somecompaniesandresearchentitieshavecoupledthemwith
aidivisionsformoreautomatedapplicationssuchasinspection,qualitycontrol,andaspourersor
dispensingmachinesforbeverages,whicharethemostcommon,amongothers[24].
beverages2019,5,62 3of25
2.1. roboticsinalcoholicbeverages
thecategoryofalcoholicbeverageshasbeenthemostexploredintermsofroboticsdevelopment
forproductdevelopment,production,andqualityassessment. aroboticcocktailmixernamedmakr
shakrhasbeendevelopedusingai,anditworksusingamobileapplicationinwhichtheuserisableto
designtheircocktaildrinkfromaselectionof60differentspirits,andthemitispreparedbytworobotic
arms[25]. forthewineproductionindustry,robotshavebeendevelopedtocarryoutthebottling
andpackagingtasks,whichconsistsofamodel94decaser(a-b-cpackagingmachinecorporation,
tarponsprings,fl,usa),whichisabletopickthewinebottlesandplacethemintoaconveyorthat
transportsthemtothecleaningarea,andthisisthenfollowedbyfilling,corkingorcapping,allin
anautomatedprocess[26]. condeetal.[27]developedarobot(fizzeyerobot, theuniversityof
melbourne,melbourne,victoria,australia)touniformsparklingwinepouring,andthisrobotisableto
®
servearound50mluptothreetimesfromthesamebottle;itworkswitharduino boards(arduino
computingplatform,ivrea,italy)andservomotors,andmaybecalibratedbymodifyingtheangle
ofthebottlepositionandthedelaytimes. thispourerwasdesignedtocontroltheservingvolume,
andtofurtherusecvtomeasurefoamandbubble-relatedparameters;thiswillbefurtherexplained
laterinthisreview.
regarding beer, a robotic beer dispenser has been developed using two robotic arms; one is
programmedtoholdtheglass, whiletheotherisabletocontrolthetap; botharecontrolledusing
®
robotstudio (abb robotics, zürich, switzerland) [28]. yasui et al. [29] developed an automatic
pourer,whichconsistsofapivotpointattheneckofthebeerbottleandmotion;however,theauthors
did not specify the type of motors and controllers used; this machine may hold and serve several
bottles simultaneously. the purpose of this robot is to control pouring to measure foam collapse
time; therefore,theheightofthebottleisalsocontrollable. morerecently,aroboticpourernamed
®
robobeer(theuniversityofmelbourne,melbourne,vic,australia)wasdevelopedusinglego
blocks and servo motors (the lego group, billund, denmark), and this is coupled with infrared
®
temperature,carbondioxide,andethanolgasubiquitoussensorscontrolledwitharduino boards.
this robot consists of a glass chamber, a bottle holder and a pivot in the bottle neck, and may be
adaptedforanybottleshapesandheighttopour80±10ml;this,coupledwithcvandml,isableto
predictbeerqualitybasedoncolorandfoam-relatedparameters,whichwillbeexplainedlaterinthis
paper[7,9,14,17,30–32].
2.2. roboticsinhotbeverages
in tea and coffee, robots have been developed for brewing and dispensing purposes.
kayaalpetal. [33] designed a tea brewing machine, which is able to make cups of tea in specific
timeswithadequatewatertemperatureandrecordtheconsumptionpatterns;thissystemworkswith
®
arduino boardsandwi-ficonnectivity. anotherrecentdevelopmentwasarobotnamedteforia;
itconsistsofanin-hometeamakerinwhichtheuserisabletoaddanycombinationoftealeavesand
water,thentherobotiscontrolledusingasmartphoneapplicationtostarttheprocess;itclaimstobe
abletobrewthebeveragetoachievetheoptimalflavorprofileforeachconsumer[34]. teabotis
anotherteabrewingrobotcapableofmakingacupofteain30s;itispre-loadedwithaselectionof
leaves,andtheuserisabletochooseinatabletthecombinationandproportiontocreateapersonalized
cupoftea[35].
inthecaseofcoffee,aroboticcoffeemaker,mugsy,wasdevelopedusingraspberrypi(raspberry
pifoundation,cambridge,uk),anditispossibletointegrateitwithdifferentapplicationssuchastext
messages,twitteroranalexadevice(amazon,bellevue,wa,usa),whichareusedtoindicateto
therobottostartbrewingthecoffee. mugsyiscapableofgrindingcoffeebeans,controllingthewater
temperatureandpouringthebrewintoacup,andisabletolearnandpersonalizethedrinkforspecific
users[36]. furthermore,akiosk,cafex,wascreated;itconsistsoftwocoffeemakersandasix-axis
roboticarm. theuserisabletochoosethetypeofbrewfromatablet,andtherobotisabletoperform
thetasksofabaristainashortertimeandwithmoreprecision[37].
beverages2019,5,62 4of25
2.3. roboticsinnon-alcoholicbeverages
somerecentdevelopmentshavebeenmaderelatedtoroboticsinnon-alcoholicbeverages;doand
burgard[38]usedacommercialroboticpourerpr2(willowgarage,paloalto,ca,usa),whichconsists
oftwoarmsandascreen;theauthorsintegrateditwithacamera,whichisabletodetectthelevel
oftheliquidtopredictwhentostopserving. moritaetal.[39]developedateahouse,whichconsists
ofamotion-sensingdevicetocountthenumberofpeopleenteringtheestablishment;theyarethen
directedtothecounter,whereamicrophonewithspeechrecognitionwasimplementedtotakethe
order. aroboticarmwasdesignedtopickacupandservethebeverageordered(orangejuice,apple
juiceoricedtea),asecondrobotwasprogrammedtopickthebottledsoftdrinksandtakethemtothe
clients’table,whileathirdmachinewasintendedtohaveaconversationwithclientswhilewaiting
fortheorder. caietal.[40]developedaroboticbeveragemaker,whichconsistsofascreenforthe
usertoselectthedesireddrink. thedevicehasanarmtoholdthecontainerandisabletorotateand
findtherawmaterialaccordingtotheselectionmade,whichmaybetea,ice,and/orsyrup,followed
bytheshakingsteptopouritintoaglass. morerecently,aroboticmachinewasdevelopedtomake
smoothies;itwasdesignedasavendingmachine,andusersareabletodownloadanapplicationto
choosetherecipeaccordingtotheirpreferences,thenaquickresponse(qr)codeisgeneratedand
readbytheapparatustomakethedesiredbeverage[41].
3. computervisiontechniques
thecvtechniquereferstoasubdivisionofai,whichconsistsofautomaticinformationextraction
fromeitherimagesorvideosbyimitatingthehumaneyefunctions[42]. itcanbecoupledwithrobotics,
specificequationsoralgorithms,basicstatistics,andmlalgorithms,tofullyautomatethetechniqueas
anaisystem;thismayallowtheproceduretobestand-aloneandtoclassifyorpredictthequality
parametersoftheproduct. someadvantagesincludethatitisnon-destructive,non-contact,maybe
replicated, isautomatic, andtherefore, consideredasarapidmethod, whichismoreaccurateand
reliablethansometraditionalproceduressuchasvisualinspectionandsensoryanalysis,whichinclude
humanerrorasapossibledrawback[19,43].
theprocedureofcvconsistsofthreemainstepstofollowfortheimageorvideo: (i)acquisition,
(ii)pre-processing, and(iii)analysisandinterpretation. for(i)acquisition, theequipmentneeded
consistsofacameraorscannerandaconstantanduniformlightingsource[44]. for(ii)pre-processing
and(iii)analysisandinterpretation,theuseofacomputerandsoftwarewithimageanalysiscapabilities
® ®
suchasmatlab (mathworksinc.,natick,ma,usa),imagej (u.s.nationalinstitutesofhealth,
bethesda,md,usa)orimage-proplus(mediacybernetics,inc.,rockville,md,usa)isrequired
(figure1)[45,46]. specificalgorithmsneedtobedevelopedaccordingtothetypeofvisualassessment
andtheparameterstoevaluate. thesemayconsistofimageenhancement,segmentation,recognition,
andinterpretation[47]. enhancementreferstotheoptimizationoftheimagestoimprovetheirquality;
itmayincludesharpening,contrastadjustment,anddenoising,amongothers[48]. segmentationis
thedivisionoftheimagesorframesinspecificregionsofinterest. recognitionusuallyconsistsof
specificmathematicalequationsorintegrationofotheralgorithmstodefineordetecttheobjectorarea
ofinterest,whileinterpretationinvolvestheuseofstatisticalanalysis,whichmayincludemachine
learning to classify the product into different categories or predict more specific information [49].
methodsinvolvingcomputervisionhavebeendevelopedtobeusedindifferentindustriessuchas
medical,marketing,psychology,agriculture,food,andbeverages,amongothers. thistechnology
has been used for different applications, which include an assessment of hand hygiene [42], face
recognitionandtracking[18],object[50]andtextrecognition[51],andcoloranalysis[7,43,50],among
others. thefoodindustryisamongthetopindustrieswiththefastestgrowthintheautomationof
qualityassessmentusingmachineorcv[52].
beverages2019,5,62 5of25
beverages 2019, 5, x for peer review 5 of 25
figure 1. diagram showing the equipment typically needed for computer vision (cv) analysis,
wfhigicuhrec o1.n dsiisatgsroafma schamowerina,gt hthees eaqmupiplem,aenlitg thytp-sicoaullryce n,eaenddedco fmorp cuotmerpsuotfetwr vairseiofnor (canva)l yansiasl.ysis, which
consists of a camera, the sample, a light-source, and computer software for analysis.
3.1. computervisioninalcoholicbeverages
3.1. ctohmerpeuthear vveisnioont ibne eanlcmohaonliyc bcevvermageetsh odsdevelopedforspirits. however,inbeveragessuchas
cachaça,whichisabraziliandistilleddrinkmadefromsugarcane,amethodtoassesscolorfromimage
there have not been many cv methods developed for spirits. however, in beverages such as
analysiswasdevelopedusingalightingsourcebelowtheglassasabackgroundandadigitalcamera
cachaça, which is a brazilian distilled drink made from sugarcane, a method to assess color from
placedabovetheglass,obtainingresultsinbothrgbandcielabcolorscales[53]. pessoaetal.[54]
image analysis was developed using a lighting source below the glass as a background and a digital
developedamethodbasedoncolorassessmenttodeterminecopperinsugarcanespiritsusingimages
camera placed above the glass, obtaining results in both rgb and cielab color scales [53]. pessoa et
capturedwithadigitalcamerawithabayerrgbmosaicfilter,whichconsistsofagridofcolorfilters
al. [54] developed a method based on color assessment to determine copper in sugarcane spirits using
andphotosensors,andacharge-coupleddevice,apartfromanilluminatedblackbox,andaporcelain
images captured with a digital camera with a bayer rgb mosaic filter, which consists of a grid of
plaque. wangetal.[55]presentedatechniquetodetectforeignmatterinchinesehealthwinetoassess
color filters and photosensors, and a charge-coupled device, apart from an illuminated black box, and
thesafetyandqualityofthefinalproductattheendoftheproductionline.
a porcelain plaque. wang et al. [55] presented a technique to detect foreign matter in chinese health
severalmethodsusingcvhavebeendevelopedtoevaluatedifferentqualityparametersinwine.
wine to assess the safety and quality of the final product at the end of the production line.
martin et al. [56] analyzed the color of different wines using a digital camera and digieye system
several methods using cv have been developed to evaluate different quality parameters in wine.
(verivideltd.,leicester,uk)andevaluatedthesamplespouredintoapetridishandacocktailglassat
martin et al. [56] analyzed the color of different wines using a digital camera and digieye system
differentdepths. theauthorsfoundthebestresultswiththesamplesinacocktailglassandobtained
(verivide ltd., leicester, uk) and evaluated the samples poured into a petri dish and a cocktail glass
ahighcorrelation(r>0.90)betweentheinstrumentalcolormeasurements(lightness,colorfulness,
at different depths. the authors found the best results with the samples in a cocktail glass and
andhuecomposition)andthenon-contactassessmentusingthedigieyesystem. inanotherstudy,
obtained a high correlation (r > 0.90) between the instrumental color measurements (lightness,
alow-costmethodusingasmartphonewasdevelopedtoassessthebrowningprocessofsparkling
colorfulness, and hue composition) and the non-contact assessment using the digieye system. in
wines,andthiswasachievedbyusingablackboxwithadiffuselightboxbelowa96-wellplateto
another study, a low-cost method using a smartphone was developed to assess the browning process
evaluate several samples simultaneously. the software used to assess color in rbg scale through
of sparkling wines, and this was achieved by using a black box with a diffuse lightbox below a 96-
imageanalysiswasimagej® [57]. arakawaetal.[58]developedasniffercameratoassessethanolin
well plate to evaluate several samples simultaneously. the software used to assess color in rbg scale
winebyplacinganenzymemeshsubstrateovertheglassandcapturingimagesusingacharge-coupled
through image analysis was imagej® [57]. arakawa et al. [58] developed a sniffer camera to assess
devicecamera.
ethanol in wine by placing an enzyme mesh substrate over the glass and capturing images using a
insparklingwine,severalmethodstoassessbubblesandfoam-relatedparametershavebeen
charge-coupled device camera.
developed. cilindreetal.[59]appliedanautomatedmethodcalledcomputerizedassistedviewing
in sparkling wine, several methods to assess bubbles and foam-related parameters have been
developed. cilindre et al. [59] applied an automated method called computerized assisted viewing
equipment (cave), which used three video cameras to record the wine during pouring to assess
parameters such as serving time, height of foam, foam velocity and foam thickness, among others.
beverages2019,5,62 6of25
equipment (cave), which used three video cameras to record the wine during pouring to assess
parameterssuchasservingtime,heightoffoam,foamvelocityandfoamthickness,amongothers.
conde et al. [27] used the fizzeyerobot to pour sparkling wine samples and analyzed 12
parameters,suchasfoamstability,volumeoffoam,bubblesize,collarandfoamdrainage,among
others,usingasmartphonetocapturevideosofthepouring,andanalyzingthemusingcustomized
®
codesdevelopedinmatlab . morerecently,crumptonetal.[60]developedthefreepourtechnique
bymanuallypouringsparklingwinesamplesandrecordingthemusingonecameraonthetopand
®
oneonthesideoftheglass;videoswerepost-processedusingimagej softwaretoassesscollarwidth
andfoamheightandstability.
beeristhealcoholicbeverageforwhichmoremethodshavebeendevelopedusingcvtechniques,
asthemainqualitytraitsofthistypeofdrinkarethecolor,bubbles,andfoam-relatedparameters.
silvaetal.[61]recordedimagesofpalelagersamplespouredintopetridishesusingadeskscanner
andanalyzedwithascilabsoftware(scilabenterprises,rungis,france)togetcolorinthergbscale
of each beer sample. fengxia et al. [62] used a microtek scanmaker e6 scanner (microtek corp.,
hsinchu,taiwan)andavcamcharge-coupleddevicecamera(amecorp.,hsinchu,taiwan)tocapture
imagesofbeersamples;theymeasuredthecolorinthergbscaleandcalculatedthesaturationvalue
tofurtherobtaintheresultsintheeuropeanbreweryconvention(ebc)scale. bubblehazerefers
to a large number of micro-bubbles formed when the beer is poured, and that circulate the liquid
beforereachingthesurface. basedonthelatter,hepworthetal.[63]developedamethodtomeasure
thesurgetime,risevelocityofhazeandbubblesizeusingacharge-coupleddevicecameraandthe
matrixvisionimageprocessingsoftware(matrixvisiongmbh,oppenweiller,germany). inanother
study,hepworthetal.[64]developedacvmethodtomeasurethebubblesizedistributionusinga
charge-coupleddevicecamerawithachipabletocapturepixelsandconvertintoimagestobefurther
analyzedusingimage-proplus4.1software.
differentmethodstoanalyzefoam-relatedparametersinbeerhavebeendeveloped,suchasfoam
collapsetimeorstability,whichconsistsofthevideorecordingofbeerpouringusingacharge-coupled
devicecamera,andanalyzedusingcomputersoftwarewhosenamewasnotspecifiedbytheauthors[29].
however,mostofthosetechniquesrequiretheuseofacharge-coupleddevicecameraandspecialized
equipmentsuchasanozzle,waterjackets,andachipattachedtothecamera,amongothers;thesemake
themlessaffordableandavailabletootherusers. therefore,othermethods,suchasthelow-costimage
analysisrudinmethoddevelopedbyciminietal.[65]requiretheuseofanaffordableraspberrypi
computerandcameramodule,butitisonlyabletomeasurethefoamhalf-time. anewlydeveloped
®
methodusingmatlab algorithmstoassessbeercolorandfoam-relatedparameterswerepresented
by gonzalez viejo et al. [7]. in this study, 5-min videos of samples from the three different types
offermentation(top,bottomandspontaneous)wererecordedduringautomatedpouringusingthe
robobeerandasmartphonecamera. videoswerefurtheranalyzedobtaining13parameterssuch
ascolorincielabandrgbscales,bubblesizedistribution(small,medium,large),foamdrainage,
lifetimeoffoam,totallifetimeoffoamandmaximumvolumeoffoamusingcomputervisiontechniques,
plustwoparameters(ethanolgasandcarbondioxide)obtainedfromubiquitoussensorsattachedto
®
arduino boards.
3.2. computervisioninhotbeverages
some cv techniques in tea and coffee have been developed; however, there is still a broad
area within hot beverages that may be explored to automate and ease their quality assessment.
image analysis has been implemented in tea, especially to evaluate color and texture in leaves
duringorafterfermentationinordertoassessthequalityoftheprimaryingredientofthebeverage.
dongetal.[66]evaluatedthecolorofgreentealeavesusingasingle-lensreflexcameraanduniform
lighting,whichwerethenanalyzedinacomputertoobtainrgb,hsv,cielab,andgraycolorscales.
singhandkamal[67]analyzedthecolorandsizeoffermentedteagrainstocalculatetheteaquality
index(tqi;equation(1))usingacharge-coupleddevicecamerawithuniformlightingtoacquirethe
beverages2019,5,62 7of25
images,andthesewereprocessedusinggrayimagehistogramextraction,imageenhancement,zoom,
thresholdingandsegmentationsteps.
(tqi = area+perimeter+diameter+r+g+b) (1)
wheretqi=teaqualityindex,area,perimeter,anddiameteroftheteagrains,r=red,g=green,andb
=blue.
ontheotherhand,kumaretal.[68]usedacharge-coupleddevicecameratoevaluatethecolorof
tealiquorinthergbscaleandtransformedittocielab,asthisisconsideredasclosertohumancolor
perception. inamorerecentstudy,akulietal.[69]developedamethodtoassesscolorintealiquor
orinfusedteausingablackboxwithuniformillumination,andalow-costcamerapositioned30cm
abovethesample,andthustheyobtainedcolorinbothrbgandcielabscales.
similartotea,mostofthecvmethodsdevelopedforcoffeehavebeentoanalyzecoffeebeans’
qualityparameters,andaremorefocusedonthecolorassessment. oblitasandcastro[70]designed
asystemtoevaluatethecolorofroastedcoffeebeansbyplacingthesampleinapetridishinsidea
chamberwithauniformlightingsource,andrecordingitwithavideocameratofurtherprocessitusing
®
analgorithmwritteninmatlab ,theobtainingvaluesinthecielabcolorscale. várvölgyietal.[71]
presentedanothertechniquetomeasurecolorusingacharge-coupleddevicecamera,12halogenlights,
andametalholderforthesampletoobtainthehueofroastedcoffeebeans;however,theauthorsdidnot
mentionthesoftwareusedtoanalyzetheimages. inamorerecentstudy,moraisdeoliveiraetal.[72]
reported a cv system to evaluate green arabica coffee beans using a black chamber composed of
whitelighting,andadigitalcamera,whichwasfixed40cmabovethesample. imageswereconverted
®
tothetaggedimagefileformat(tiff)usingthedigitalphotoprofessional software(canoninc.,
o¯ta,tokyo,japan)andanalyzedusingimagej®
bycroppingtheimagesandmeasuringcolorinrgb
and cielab scales. chu et al. [73] used hyperspectral imaging to obtain the near-infrared spectra
of coffee beans within the 874–1734 nm range by building a device consisting of a conveyor belt
withamotor,uniformilluminationandacharge-coupleddevicecamerawithaspectrographanda
lensplaced32cmabovethesample. imageswereacquiredwiththespectral-cubesoftware(isuzu
optics corp., hsinchu, taiwan) and processed using the imspector n17e (spectral imaging ltd.,
oulu,finland). ontheotherhand,piazzaetal.[74]assessedthefoamabilityofbrewedcoffeemade
with 70% arabica and 30% robusta; the beverage was poured in a plexiglas vessel and stirred to
formfoam,thenimageswerescannedatdifferenttimes(40–1860s)andprocessedusingimage-pro
plus5.0software. anothermethodtoanalyzefoamabilityandfoamstabilityinespressobrewswas
proposedbyburattietal.[75],whopercolatedthesamplesinaplexiglasvesselwithtwocoollight
bulbsinthetop,andacquiredimagesusingadigitalcamera. imageswererecordedevery30sfor
5minandevaluatedusingimage-proplus6.2softwarebydetectingtheareaofinterest,correction,
andconversionofmeasurementsfrompixelstommthroughspatialcalibration.
3.3. computervisioninnon-alcoholicbeverages
somecvmethodshavebeenimplementedtoassessthequalitytraitsofnon-alcoholicdrinks.
however, more research needs to be done to develop more of these non-destructive and rapid
techniquesforthisbeveragecategory. damascenoetal.[76]publishedanimage-basedmethodto
assesstotalhardnessandalkalinityofstillwaterusinganenzyme-linkedimmunosorbentassay(elisa)
plateandascannertoobtaintheimages. theymeasureddifferentconcentrationsofstandardsfor
bothhardness(ca2+ andmg2+ )andalkalinity(buffersolutionph10,alkali),andsamplesofdrinking
®
waterfromthetap,fountainandbottle,andthesewereanalyzedforcolorchangesusingmatlab .
barkeretal.[77]evaluatedbubblegrowthincarbonatedwaterusingacharge-coupleddevicevideo
camera,whichrecordedat20framespersecond,andacontrolledlightsource;imageswereanalyzed
using image-pro plus software. more recently, a cv method was developed to measure bubble
beverages2019,5,62 8of25
diameterinpixelsandbubblesizedistribution(small,medium,andlarge)incarbonatedwaterusing
®
analgorithmdevelopedinmatlab [78].
insoftdrinks,imageanalysismethodshavebeendevelopedtoassesstheconcentrationofdyes,
specificallyforyellowsunset,alsoknownasyellow6ore110,whichisderivedfrompetroleumand
hasbeenreportedtotriggersomesideeffectssuchasallergies,headache,andhyperactivity,among
others[79]. botelhoetal.[80],usedascannertoobtainimagesofdegassedorangesodasandisotonic
drinkswithyellowsunsetdyeplacedinapetridishandselectedandanalyzedthecenterpartofthe
®
containerusingmatlab softwaretomeasurecolorinthergbscale. similarly,sorouraddinetal.[81]
usedascannertoacquireimagesoforangesoftdrinks,andthesewereanalyzedwithphotoshopcs5
®
(adobe,sanjose,ca,usa)andmatlab tocalculatethergbcolorvalues. hosseininiaetal.[82]
designedasystemthatconsistedofamatteblackbox,acharge-coupleddevicecameraplaced30cm
awayfromthesoftdrinksamples,andilluminationusingtwofluorescentlampsforuniformlighting.
imageswereprocessedusingtheimagej1.45software,inwhichthecenterofthesampleareawas
croppedandanalyzedforcolorincielab,hueandchromascales. ontheotherhand,imagecolor
methodshavealsobeendevelopedtoassesscolorinorangejuiceusingthedigieyesystem;samples
®
wererecordedintransparentplasticbottleswithawhitebackground. theauthorsusedthedigifood
software[83]toconvertcolorfromrgbtocielabandfoundahighandsignificantcorrelation(r=0.93;
p<0.05)withthecolorintensityevaluatedbyatrainedsensorypanel[84,85].
the application of cv in milk has been different from other non-alcoholic beverages, as they
targetspecificmeasurements. velez-ruizandbarbosa-canovas[86]analyzedimagesofmilkobtained
fromascanningelectronmicroscope,andthesewereanalyzedusingthenihimagesoftware(u.s.
nationalinstitutesofhealth,bethesda,md,usa)tomeasurefatglobules’dimensions. furthermore,
dossantosandpereira-filho[87]usedascannerwithablackcovertoacquireimagesof5mlofmilk
pouredintoabeakerwitheitherbromophenolblueorbromothymolblueasacid—baseindicators.
imageswereanalyzedusingmatlab® tocalculatedifferentcolorparameterssuchasrgb,luminosity,
relativecolorsofrgbcalculatedbydividingthevaluesbytheluminosity;hue,saturationandvalue
(hsv)werealsoobtained. multivariatedataanalysiswasperformedtodevelopmodelstoassess
whetherthemilksampleswereadulteratedornot.
4. machinelearning
machinelearning(ml)isabranchofartificialintelligence, whichreferstoacomputer-based
systemthatmaybetrainedtofindpatternsamongadatasettoclassifyorpredictspecificparameters,
and it is able to improve its performance by feeding new data [21,30]. machine learning may be
dividedintosupervisedandunsupervisedalgorithms,which,atthesametime,maybeclassifiedinto
differentsubtypes. however,thispaperwillonlyfocusonthesupervisedgroup,asitthetypethat
hasbeenmostlyappliedtofoodandbeverages; itmaybedividedinto(i)classificationorpattern
recognitionand(ii)regressionalgorithms[30,88]. theclassificationlearnersareusedtocategorize
samplesintodifferentgroupsandhavebeenappliedfordifferentpurposesindistinctfieldssuchas
agriculture[50],medicaldiagnosis,foodandbeverages[17,18]. someofthemainclassifiertypesconsist
of(i)decisiontrees,(ii)discriminantanalysis,(iii)logisticregression,(iv)naïvebayes,(v)support
vectormachines,(vi)nearestneighbor,(vii)ensembleand(viii)artificialneuralnetworks(ann)[89].
regressionorfittinglearnersareusuallyemployedtopredictspecificattributesorparameterssuchas
chemometrics,microbialcounts,andintensitiesofsensorydescriptors,amongothers,andhavebeen
usedinareassuchasagriculture[90],foodandbeverages[9,14],amongothers. thistypeofmlmay
beclassifiedas(i)linearregression,(ii)regressiontrees,(iii)supportvectormachines,(iv)gaussian
process regression, (v) ensembles of trees, and (vi) ann [89]. both main types of supervised ml
aresubcategorizedintodifferentalgorithms,asshowninfigure2. someofthecommonsoftwareto
®
developmlmodelingincludematlab ,scikit-learnandtensorflow,whicharemodulesdesignedfor
python[91,92],weka(theuniversityofwaikato,hamilton,nz),whichmaybeusedasstand-aloneor
integratedasapackageinrsoftware(rstudio,inc.,boston,ma,usa)[93,94],amongothers.
beverages2019,5,62 9of25
the use of ml has been increasing in recent years in the food and beverage industry due
to its ability to improve production and assess the quality in a faster, more accurate, objective,
andcost-effectiveway. theindustryneedsfortheimplementationofmlhavebeenderivedfromthe
factthataround95%offoodandbeveragesfailwithinthreeyearsofbeinglaunched. therefore,ml
mbeovedraegless h20a1v9,e 5b, xe feonrd peeveerl orpeevdiewto predictconsumers’needs,acceptability,sensorydescriptorso9 fotfh 2e5
products,andphysicochemicalcomposition,amongotherqualitytraits,whichaidinthedevelopment
ohfighhigehr eqruqauliatlyit yprpordoudcutcst swwithit hggreraetaetre raacccecepptatabbiliiltiyty frfroomm ccoonnssuummeerrss [[9955]].. hhoowweevveerr,, aa ccoommmmoonn iissssuuee
ffoouunndd iinn mmll mmooddeelliinngg iiss tthhee oovveerrfifittttiinngg,, wwhhiicchh iiss ggiivveenn wwhheenn tthhee mmooddeell llaacckkss ggeenneerraalliizzaattiioonn ooff tthhee
ddaattaa.. tthhiiss uussuuaallllyy hhaappppeennss wwhheenn tthheerree iiss lliimmiitteedd ddaattaa iinn tthhee ttrraaiinniinngg sseett,, aanndd ssaammpplliinngg nnooiissee eexxiissttss,,
wwhheerree tthhiiss lleeaaddss ttoo aann aappppaarreenntt aaccccuurraattee ttrraaiinniinngg ssttaaggee,, bbuutt iitt wwiillll nnoott bbee aabbllee ttoo ppeerrffoorrmm ccoorrrreeccttllyy
wwhheenn tteessttiinnggn neewws saammpplleess[ [9966,9,977]]..
ffiigguurree 22.. ttyyppeess aanndda alglgoorritithhmmssf foorrm maacchhinineel eleaarrnnininggm mooddeelilningg.. iinnffoorrmmaattiioonn oobbttaaiinneedd ffrroomm mmaattllaabb
mmaacchhiinnee lleeaarrnniinngg aanndd ddeeeepp lleeaarrnniinnggt toooolblbooxxeess[ 8[899].].
4.1. machine learning in alcoholic beverages
a broad application of ml has been made for alcoholic beverages, especially in the last decade.
in spirits, it has been used to develop models to classify whisky (whiskey) samples according to (i)
age, (ii) cask material, (iii) distillery and (iv) variety, using ramah spectra (600–1800 cm−1) as inputs,
wherein the authors compared different ml algorithms, obtaining the best results, using relevance
radial basis function networks with an accuracy > 95% [98]. ceballos-magaña et al. [99] analyzed the
mineral content in tequilas from different regions, and developed models using the linear support
beverages2019,5,62 10of25
4.1. machinelearninginalcoholicbeverages
abroadapplicationofmlhasbeenmadeforalcoholicbeverages,especiallyinthelastdecade.
in spirits, it has been used to develop models to classify whisky (whiskey) samples according to
cm−1)
(i) age, (ii) cask material, (iii) distillery and (iv) variety, using ramah spectra (600–1800 as
inputs, wherein the authors compared different ml algorithms, obtaining the best results, using
relevanceradialbasisfunctionnetworkswithanaccuracy>95%[98]. ceballos-magañaetal.[99]
analyzed the mineral content in tequilas from different regions, and developed models using the
linearsupportvectormachine(svm)algorithmandtestingdifferentpercentagesofdatadivisionfrom
40to70%fortraining,thusobtainingaccuracieswithinthe96–100%rangetoclassifysamplesper
regionforauthenticitypurposes. anotherapplicationofmlintequilawaspublishedbyandrade
et al. [100] who analyzed samples with an ultraviolet-visible (uv-vis) spectrometer and used the
absorbancevalueswithinthe250–550nmrangeasinputstoclassifysamplesintothreedifferenttypes:
(i) white, (ii) rested and (iii) aged. the authors compared different algorithms from discriminant
analysis,svm,andcounter-propagationann,gettingthebestresultsfromquadraticdiscriminant
analysiscombinedwithprincipalcomponentsanalysis(pca)withanaccuracyof89%. ontheother
hand,rodriguesetal.[101]assessedthechemicalcomponentsandcolorinrgbandcielabscalesof
cachaçasamplesandusedthosevaluesasinputstodevelopannmodelstoclassifythebeverages
accordingto(i)ageand(ii)typeofwoodusedforaging.
severalstudieshaveuseddifferentmlalgorithmstoclassifyorpredictdistinctparametersrelated
towinequality. erandatasoy[102]developedtwomlmodels,comparingthreedifferentclassifiers
(randomforest,supportvectormachineandk-nearestneighbors)(i)topredictthetypeofwine(red
orwhite)and(ii)togroupwinesamplesaccordingtotheirqualitybasedonsensoryratings, both
modelsusingphysicochemicaldataasinputs,andobtainingthebestresultswitharandomforest
algorithm. however, the models to predict quality had a moderate to low accuracy of ~60–70%.
furthermore,theauthorsdidnotexplainclearlyhowtheyobtained,grouped,ordefinedwinequality
based on sensory ratings, and yet they stated that some of those values were based on only three
participants,whichmakestheresultslessobjectiveandreliable. dacostaetal.[103]developeda
modelusingsvmtoclassifycabernetsauvignonwinesaccordingtotheircountryoforigin(chileand
brazil)usingphysicochemicaldataasinputs,withanaccuracyof89%. perrotetal.[104]developed
adecisiontoolbasedonmachinelearningnamedfgrapedbn,whichisacombinationoffuzzy
logicanddynamicbayesiannetworktopredictthematurityofgrapesforwineproduction,obtaining
determinationcoefficientsr2=0.82forsugarcontentandr2=0.77fortotalacidity. lvovaetal.[105]
used an electronic tongue (e-tongue), which consists of a device with an array of sensors capable
ofmimickingthehumantastesensethroughtheuseofachemometricprocessingtechnique[106],
andinthecaseofthementionedstudy,thee-tonguehadeightpotentiometricchemicalsensorsto
measure different wine samples from primitivo and negroamaro varieties, and used partial least
squaresregression—discriminantanalysistoclassifysamplesintothetypeofwinewithanaccuracyof
71%. furthermore,theseauthorsdevelopedamodeltoclassifynegroamarosamplesintothecontrol
andthosewithfaultswitha97%accuracy. onamorerecentstudy,fuentesetal.[107]constructedan
annmodelusingthesequentialorderweightbiastrainingalgorithm,andemployingthecanopy
temperature,infraredindexandcropwaterstressindexfrominfrared-thermalimagesfromgrapevine
leavesasinputstodetectthosecontaminatedduetosmokefrombushfires,whichwouldpotentiallybe
usedtopredictsmoketaintingrapes;thismodelhadanaccuracyof96%. thesameauthorsdeveloped
anannmodelalsousingasequentialorderweightbiasalgorithmtopredictguaiacolglycoconjugates
in berries and wine, and 4-methyl guaiacol in wine using near-infrared absorbance values within
the700–1100nmspectraasinputs,obtainingacorrelationcoefficientr=0.97. ontheotherhand,
navajasetal. [108] presented an svm regression model to predict astringency in wine using their
chemicalcompositionasinputswitharootmeansquarederror(rmse)=0.19. fuentesetal.[109]
usedweatherdatafromverticalvintages(2008–2013)todeveloptworegressionannmodelswiththe
beverages2019,5,62 11of25
levenbergmarquardttrainingalgorithmtopredict(i)twentyonevolatilearomacompoundsinthe
wineand(ii)eightchemicalparametersinthewineobtainedfromthosevintages.
thiswaspresentedasapotentialmethodtoobtainanticipatedinformationtowinemakersabout
theproduct,whichwouldallowearlydecisionsbasedupontheexpectedwinequality.
inbeer, therehavebeenmanyapplicationsofmlfordifferentclassificationsandpredictions
regardingquality,eitherduringthebrewingprocessorforthefinalproduct. cetóetal.[110]analyzed
commercialbeersamplesusingane-tongueandappliedtheseresultstodevelopamodelwithlinear
discriminantanalysisinordertoclassifythesamplesaccordingtothebeerstylewith82%accuracy.
inanotherstudy,ansvmalgorithmwasusedtoclassifybeersaccordingtotheircountryoforigin
with minerals and polyphenols content as inputs, obtaining a highly accurate model (99%) [111].
rousuetal.[112]developedadecisiontreemodeltoclassifybeerfermentationintosloworfastwithan
accuracy>95%atlaboratoryscaleand70%atanindustrialscale. inthatstudy,theauthorsalsotested
aregressionmodelusinganntopredictthefermentationtime;however,noaccuracyorcorrelation
coefficientwasreported,andtheyclaimedthatbackpropagationwasused,butdidnotspecifythe
specifictrainingalgorithm. santosandlozano[113]usedanelectronicnose(e-nose),whichconsistsof
adevicewithanarrayofgassensorsthatmaybeametaloxideorpolymersemiconductorscapable
ofmimickingtheolfactorysystem[114]toanalyzetwomainbeeroff-odors,acetaldehydeandethyl
acetate;theauthorsusedtheoutputvaluesfromthee-noseasinputstodevelopaprobabilisticneural
networkmodelwith94%accuracyinthevalidationstagetopredictwhetherthosecompoundsfell
abovethethreshold,whichareconsideredasdefectsinbeer. vossetal.[115]developedane-nosewith
13differentgassensorstoanalyzebeers,andusedtheseresponsesasinputsinanextremelearning
machinemodeltopredictalcoholcontentwithrmse=0.63invalidationandrmse=0.33inthe
testingstage;however,theauthorsdidnotmentionthecorrelationordeterminationcoefficientvalues
forthismethod. zhangetal.[116]usedsvmtoconstructamodelusingthefermentationparameters
to predict the acetic acid (vinegar) content in the beer; however, the reported validation accuracy
waslow(r<0.60). ontheotherhand,gonzalezviejoetal.[7]developedanannmodelusinga
scaledconjugategradienttrainingalgorithmtoclassifybeersaccordingtothetypeoffermentation,
top, bottomorspontaneous, usingcolorandfoam-relatedparametersasinputs, andobtainingan
accuracy of 92%. those same authors used the aforementioned inputs to predict the intensity of
tensensorydescriptorswithannandthelevenbergmarquardtalgorithm,possessinganoverall
accuracyr=0.91[14],andtopredictconsumers’acceptabilityusingannandbayesianregularization
algorithm(r=0.98)[30]. furthermore,gonzalezviejoetal.[18]usedthephysiologicalandemotional
responsesfromconsumerswhentastingdifferentbeerstodevelopanannmodelbasedonascaled
conjugategradienttoclassifythesamplesintolowandhighlikingofmouthfeel,flavorandoverall
likingwith>80%accuracy.
4.2. machinelearninginhotbeverages
comparedtoothertypesofbeverages,theapplicationofmlhasbeenlessexploredinhotdrinks.
nevertheless,someauthorshavedevelopedmodels,especiallyann,usingdifferentinputstopredict
the quality of green or black tea. yu et al. [117] were able to accurately (>85%) classify green teas
accordingtothequalitygradeusingbothbackpropagationneuralnetworksandprobabilisticneural
networkswiththeoutputsofane-noseasinputsofthemodels. similarly,chenetal.[118]usedoutputs
fromane-nosetoconstructamodelusingsvmtoclassifygreenteaintoqualitygradesaccordingto
resultsfromasensorypanel,obtaininganaccuracyof95%inthetestingstage. cimpoiuetal.[119]
developed an ann model using the flavonoids, catechins, and total methyl-xanthines content to
predicttheantioxidantactivitywithanr=0.99;however,theydidnotspecifythetrainingalgorithm
used. inthesamestudy,theauthorsdevelopedaprobabilisticneuralnetworkmodeltoclassifythe
samplesintothetypeoftea(green,blackorexpressblack)usingthechemicalcompoundsasinputs,
claiminganaccuracyof100%,buttheyonlyusedfivesamplesfortesting,whichisnotenoughto
test a model, and thus risked a high probability of over-fitting. guo et al. [120] used results from
beverages2019,5,62 12of25
near-infraredspectroscopyfrom1,000to2,500nmasinputstopredictfreeamino-acidsinteathrough
annbackpropagationalgorithmswithr=0.96.
otherauthorswereabletomodelthepredictionofsensoryqualityperceptionusingphysicaldata
fromthegreentealeaveswiththeradialbasisfunction(r=0.95)[121].
afewrecentstudiesrelatedtoqualitymodelingofcoffeehavebeenpublished,messiasetal.[122]
usedannbasedonthelevenbergmarquardtalgorithmwithreducingsugarsasinputstoclassify
intoarabicacoffeequalitygradesaccordingtoresultsfromsensoryanalysis,achievinganaccuracyof
80%. moraisdeoliveiraetal.[72]usedthecielabcolorparametersofcoffeebeanstoclassifythem
accordingtotheircolorthroughannwitha100%accuracy;however,thatperfectclassificationis
duetothedirectrelationshipofthecategoriesandtheinputs,whichmakesthemodelsenselessand
useless. otherauthorshavedevelopedamodeltopredicttheroastingdegreeofcoffeeusingresults
fromhyperspectralimages(874–1734nm)throughsupportvectormachinewitha90%accuracy[73].
dominguezetal.[123]measuredmexicancoffeesamplesusingane-tongueanddevelopedmlmodels
with svm and lda to classify the samples into different coffee growing conditions, obtaining an
accuracyof88%forldaand96%forsvm.romanietal.[124]usedane-nosecomposedofanarrayof
tensensorstomeasurecoffeesampleswithdifferentroastinglevelsanddevelopedageneralregression
neuralnetworkmodelusingthee-noseresponsesasinputstopredicttheroastingtime,obtaining
ahighaccuracyr2=0.98;however,theauthorsdevelopedthemodelwithonlyeightobservations,
whichisnotenoughformodelingpurposes. morerecently,thazinetal.[125]usede-noseoutputsas
inputstopredictthelevelofacidityaccordingtoasensorypanel,basedonaradialbasisfunctionwith
95%accuracy.
4.3. machinelearninginnon-alcoholicbeverages
thereareseveralstudiesusingmlinnon-alcoholicbeverages;however,ithasnotbeenapplied
extensively for water quality assessment, and nothing has been done in bottled water. bucak
andkarlin[126]developedanannmodeltoassessthequalityofdrinkingwaterwhenentering
the distribution system, using microbiological and chemical data as inputs with 100% accuracy.
furthermore,camejoetal.[127]usedthek-nearestneighborclassifiertogroupdrinkingwaterfrom
portugalandcanadaintomediumandhighqualitywithchemometricsasinputs(accuracy: 98%).
asimilarapproachwastakenbychatterjeeetal.[128]usinganncoupledwithamulti-objective
geneticalgorithmwithchemicalcompoundsasinputs,achievinga97%accuracy.
norecentstudieshavebeenpublishedregardingtheapplicationofmlinsoftdrinks;however,
therearesomepapersinfruitjuices. theuseofe-noseoutputsasinputstomodelfruitjuices’quality
hasbeenpopular,qiuetal.[129]usedextrememltoclassifystrawberryjuicesamplesaccordingto
theprocessingtreatmentwith100%accuracyandr=0.82toquantifyvitaminc.hongetal.[130]
usedacombinationofe-noseoutputsandchemometricsasinputsusinglineardiscriminantanalysis
toclassifytomatojuicequalitygrade(accuracy: 98%). likewise,qiuandwang[131]alsousede-nose
andchemometricsdataasinputs,butwiththeobjectiveofpredictingfoodadditivesaddedtofruit
juiceswithlineardiscriminantanalysis,obtainingaccuraciesof>85%topredicttheamountofchitosan
andbenzoicacid. nandeshwaretal.[132]usedlineardiscriminantanalysistoidentifyiforangejuice
sampleswereadulteratedwitheithertapwaterorsugar,achievinganaccuracyof87%. ontheother
hand, rácz et al. [133] used near-infrared spectroscopy to measure the transmittance of 90 energy
drinks,anddevelopedmachinelearningmodelsusingfourdifferentmethods: (i)lineardiscriminant
analysis,(ii)partialleastsquaresdiscriminantanalysis,(iii)randomforestand(iv)boostedtreesto
classifythesamplesintothreegroupsaccordingtothesugarconcentration. thebestperformance
based on the receiver operating characteristics curve was obtained with the boosted trees > 90%
true positive values. in a different publication, the same authors presented two machine learning
regressionmodelstopredict(i)thesugarand(ii)caffeinecontentofenergydrinks. fourier-transform
near-infraredspectroscopydatawasusedtodevelopthemodelswithpartialleastsquaresregression
beverages2019,5,62 13of25
algorithmsobtainingahighdeterminationcoefficientforbothmodels;r2 =0.94forthesugarand
r2=0.97forthecaffeinemodel[134].
afewpapershavebeenpublishedusingmilkbeveragesassamples,suchasthedevelopmentof
abackpropagationannmodelwithsensorydescriptorsasinputstopredicttheoverallacceptability
ofcoffee-flavoredmilk(r=0.99). mamatandsamad[135]classifiedflavoredmilkaccordingtotheir
brand,usingasinputsane-noseandcolorparametersandsvm,obtaininganaccuracyof97%. dueto
existingproblemswithmilkadulteration,someauthorshaveusedmlasanapproachtodetectthis.
balabinandsmirnov[136]measuredliquidmilk,infantformulaandmilkpowderwithnear-infrared
spectroscopy>1110nm,andusedthosedataasinputstopredictmelaminecontentthroughann
comparedwithsvm,achievingrmsevaluesbetween0.25and6.10ppmforlowandhighmelamine
content,respectively. dossantosandpereira-filho[87]usedbromophenolblueorbromothymolblue
asacid—baseindicatorsinmilk,andanalyzedcolorusingimageanalysis;thesedatawereusedas
inputstodevelopapartialleastsquaresregressionmethodtodetectadulteratedsampleswithan
r=0.94.
5. biometrics
thetermbiometricsreferstothemethodsthatmaybeusedinhumansoranimalstoidentify
orrecognizetheirphysiologicalandbehavioraldistinctivecharacteristics. thistechnologyisoften
usedinhumansforauthenticationpurposes,andthemostpopulartechniquesarefacerecognition,
fingerprinting,voicerecognition,retinalscanners,andbodytemperature,amongothers[137]. however
morerecently,thesetechniqueshavebeenappliedtogathermoreinformationaboutconsumerswhen
evaluatingproductssuchasfood,beverages,andpackaging. ithasbeenusedasatooltotapintothe
unconsciousresponsesfromtheautonomicnervoussystem,which,alongwithothermeasurements
suchasemotionalandcognitive,hasshowntoprovidemoreprecisedatafromconsumers’attitudes
towardsproductstoassessacceptability,qualityperceptionanddecisionmaking[17,18].
in the assessment of food and beverages, face recognition has been used to analyze facial
expressionsthatmayberelatedtoemotions. somecommercialsoftwaresuchasfacereader™(noldus
information technology, wageningen, netherlands) and affectiva (affectiva, boston, ma, usa)
havethecapabilityofdetectingandtrackingthehumanfaceusingtheviola-jonescascadedetector
algorithm [138], as well as the macro- and micro-movements of different features using the active
appearancemodelinthecaseoffacereader™(figure3),andthehistogramoftheorientedgradientfor
theaffectiva. thentheyuseml(annforfacereader™andsvmforaffectiva)developedthrough
a database of movements, which have been associated with facial expressions and translated into
emotionssuchashappinessorjoy,sadness,disgust,contempt,anger,neutralandscaredorfear,among
others(figure3)[139,140]. torecordthosevideosduringsensoryevaluation,anintegratedcamera
system,whichconsistsofaninfrared-thermalcameraflirax8™(flirsystems,wilsonville,or,
usa),andatabletcoupledwithanovelbio-sensoryapp(theuniversityofmelbourne,melbourne,
vic,australia),hasbeendeveloped. thissystemisabletodisplayasensoryquestionnaireandcapture
thevideosandinfraredthermalimagesofparticipantswhiletastingthefoodorbeveragesamples[141].
beverages 2019, 5, x for peer review 14 of 25
beverages2019,5,62 14of25
figure 3. diagram showing the techniques used in the face recognition to assess emotions from
consumers;theexampledepictedwasobtainedusingfacereader™software.
fbigoudrey o3.r dskiaingrtaemm spheorwatiunrge tihseo tfetcehnnuiqsueeds aussbedio imn etthreic fsa,caen rdectohgenreitiaorne tdoi ff asesreesnst ewmaoytisotnos mfroemas ureit,
suchcoanssuusminegrss; ethnes oexrsamatptalec hdeedpitcotetdh webaso dobyt,awinheidc husisinugs fuaaclelyretahdeehr™an dsooftrwraerme.o telywithinfrared-thermal
camerasbyassessingthetemperaturefromtheeyesection,whichistheclosesttobodytemperature
(figbuoredy4 )o[r1 s8k,1in4 2te,1m43p]e.raotunreth ise ooftthener uhseadn da,s tbyipoimcaeltrwicas,y asntdo tmheeraes aurree dhieffaerrternat tweacyosn tsois mt oefaspularec iint,g
suelcehc tarosd uessionng tsheencshoersst ,aetatarclohbeedo trofi tnhgee rb;ohdoyw, ewvehri,cthh eisse umsuetahlolyd sthaere hcaonndsi doerr eredmasoitnevlya swivietho rininfrtrauresidv-e,
thwehrmichal mcaamkeerthase bpya ratiscsiepsasnintsg atwhea rteemofptehreatsuernes ofrrosman tdhea leteyre thseecitriopnh,y wsiohliochg icisa lthrees pcloonsseesst [to14 b2o,1d4y4 ].
tetmhepreerfaotruer,es o(fmigeunroen 4-)i n[1v8a,s1i4v2e,1m43e]t.h oodns thweh oicthhecro hnasnisdt,o tfympiecaasl uwrianygs htoe amrteraastuerere hspeaornt sreasteu scionngsivsitd oefo
palancailnygs ieslehcatvroedbeese onnd tehvee clohpeestd, ;etahre lsoebme oerth foindgsear;r ehobwaseevdeor,n thpehsoet mopeltehtohdyss maroeg croanpshidy,earsedth aesy inmveaassivuere
otrh ientlruumsiivneo, swithyicchh amnagkees tdhue epatortbicliopoadntfls oawwairne tohfe thfaec seen[1s4o5r,s1 a4n6d]. aalterre tcheenirt psthuydsyioulosginicgalt hreissptoynpseeos f
[1m4e2t,1h4o4d].w tahsepreufbolriseh, esdom[1e4 7n]o,nin-iwnvhaicshivae nmoent-hcoondtsa cwthteicchh ncioqnuseiswt aosf dmeveealsoupreindgt ohaesasret srsahtee arretsrpaotensaensd
ubslionogd vpidreesos uanrealuyssiins ghvavidee boesefnro dmevpealrotpiceidp;a nthtsesbea smeedthoondtsh earleu mbainseodsi toync phhanotgoepslienthtyhsemgoregernapchhyan, anse l
thaenyd mmeaachsuinree ltehaer nluinmgimnoosditeyli nchgawnigtehsh diguhe atcoc ublroaocyd (frlo=w0 i.8n5 t)hwe hfeanceu [s1in45g,1re4s6u].l tasf rroemcenatn sotsucdilylo umseintrgi c
thbilso otydpper oefs smureethmodon witaosr pasutbalrisgheetdv a[l1u4e7s]., ionn wthheicoht ha enrohna-ncodn,teaycet ttreacchkniinqguies wusaesd dteovdeleotpecetda tnod afsoslelossw
hgeaazrte rmatoev aenmde bnltosoadn pdrpeosssuitrieo nuswinhge nvildoeooksin fgroamt apparatritciicpualnartss bamaspedle oonr athreea luomfiinntoesrietsyt .cihtawngoerks sinu tshineg
gcraemene crah-abnanseedl asnedn smoraschthinate ulesaerinnifnrgar medodlieglhintgto wtriathck htighhe gacaczuerfiaxcayt (iorn =s ,0a.8s5se) swshpeunp uilsdinilga trieosnualtnsd frgoamze
adni orescctiilolonm. eintritch belfoooodd parnedssbuerev emraogneitionrd auss ttariregse,ti vtaisluuessu. aollny tuhsee odthtoera hssaensds, leaybee ltsraacnkdinpga icsk uagseindg toto
deevteaclut aatnedc ofnoslluomwe rgsaazcec empotavbeimliteynatsn danbde hpaovsiiotrio[n1 7w,1h48e]n. looking at a particular sample or area of
interest. it works using camera-based sensors that use infrared light to track the gaze fixations, assess
pupil dilation and gaze direction. in the food and beverage industries, it is usually used to assess
labels and packaging to evaluate consumers acceptability and behavior [17,148].
bbeevveerraaggeess 22001199,, 55,, x6 2for peer review 151 5oof f2255
figure4. diagramshowingthetechniqueusedtomeasurebodytemperaturefromconsumersduring
fthigeusreen 4s.o dryiasgersasmio snhsouwsiinngg tahne itnefcrhanrieqduteh uesremda tloc mameaesruaraen bdodcoym tepmupteerravtuisrieo nfroamlgo crointhsmumsecrasp daubrleinogf
trheec osgenniszoirnyg stehseseioyness eucstiinogn .an infrared thermal camera and computer vision algorithms capable of
recognizing the eye section.
5.1. biometricsinalcoholicbeverages
5.1. beiommoettrioicns sina asslecoshsmoliecn btevtherraoguegs h face recognition has been the most used biometric to assess
alcoholicbeverages. kambojetal.[149]assessedtheeffectofalcoholdrinksonthefacialexpressions
emotions assessment through face recognition has been the most used biometric to assess
ofconsumers;theauthorsusedtheabrosoftfantamorphsoftware(abrosoftco.,beijing,china)and
alcoholic beverages. kamboj et al. [149] assessed the effect of alcohol drinks on the facial expressions
wereabletoassessemotionssuchasbeinghappyorangry,havingfear,sadness,disgustandneutral.
of consumers; the authors used the abrosoft fantamorph software (abrosoft co., beijing, china) and
itwasfoundthatparticipantsthatconsumedmoderatealcoholdosesexpressedhigherlevelsofneutral
were able to assess emotions such as being happy or angry, having fear, sadness, disgust and neutral.
emotionthanthosewhoconsumedhighalcoholoraplacebo,andthosewhotastedhighalcoholdrinks
it was found that participants that consumed moderate alcohol doses expressed higher levels of
presentedhighervaluesofdisgust. beytsetal.[150]assessedheartrateusinganelectrocardiogram
neutral emotion than those who consumed high alcohol or a placebo, and those who tasted high
withelectrodesattachedbelowthecollarbone,skintemperaturewithasensorplacedontheforearm,
alcohol drinks presented higher values of disgust. beyts et al. [150] assessed heart rate using an
andfacialmovementsusingtwoelectrodesplacedontheforeheadandleftcheek,toevaluateconsumers’
electrocardiogram with electrodes attached below the collar bone, skin temperature with a sensor
responsestobeeraromas. resultsshowednosignificant(p≥0.05)differencesbetweensamplesfor
placed on the forearm, and facial movements using two electrodes placed on the forehead and left
heartrateandskintemperature,butsignificantforfacialexpressionresponses. otherauthors[18]
cheek, to evaluate consumers’ responses to beer aromas. results showed no significant (p ≥ 0.05)
evaluatedninedifferentbeersamplesusingthebio-sensoryapplication[141]torecordvideosand
differences between samples for heart rate and skin temperature, but significant for facial expression
infraredthermalimageswhileconsumerstastethesamples. theauthorsmeasuredtheemotional
responses. other authors [18] evaluated nine different beer samples using the bio-sensory application
(facereader™),physiologicalresponses,suchasheartrateusingvideoanalysis,andbodytemperature
[141] to record videos and infrared thermal images while consumers taste the samples. the authors
usingaflirax8™camera,andbrainwavedatausinganelectroencephalogram(eeg)headset. results
measured the emotional (facereader™), physiological responses, such as heart rate using video
showedrelationshipsbetweenthebiometricandself-reportedresponses,suchasanegativeassociation
analysis, and body temperature using a flir ax8™ camera, and brainwave data using an
betweentemperatureandlikingoffoamheightandbetweendisgustedandlikingoffoamstability.
electroencephalogram (eeg) headset. results showed relationships between the biometric and self-
the same authors conducted another study using similar methods to obtain the emotional
reported responses, such as a negative association between temperature and liking of foam height
and physiological responses, but including eye-tracking techniques (theeyetribe©, copenhagen,
and between disgusted and liking of foam stability.
s.denmark)toassessbeersamplesacceptabilityfromthevisualcharacteristics,especiallyfocusedon
the same authors conducted another study using similar methods to obtain the emotional and
physiological responses, but including eye-tracking techniques (theeyetribe©, copenhagen, s.
beverages2019,5,62 16of25
foamandbubblesandcoupledwiththeuseofrobobeerparameters. theauthorsfoundthatbody
temperaturewasnegatively-relatedtothelikingofclarity,andheartratewaspositively-correlated
withperceivedquality[17].
5.2. biometricsinhotbeverages
therearebarelyanystudiespublishedusingbiometricstoassessconsumers’acceptabilityin
hot drinks; however, a study was found using coffee. garcia-burgos and zamora [151] measured
disgustandhappyemotionsusingfacereader™toassessconsumers’responsestowardsbitterdrinks,
usingcoffeewithinthesamplesetwhensubjectedtostressors. theyfoundthatstress-relatedimages
decreasedthedisgustofparticipantswhentastingcoffee.
5.3. biometricsinnon-alcoholicbeverages
innon-alcoholicdrinks,afewstudieshavebeenconductedusingbiometricsandself-reported
sensory responses. de wijk et al. [142] assessed breakfast beverages such as drink yogurts and
fruitdrinksbyevaluatingthephysiologicalandemotionalresponsesfromconsumers. theauthors
analyzed skin conductance and skin temperature using electrodes placed on the palm, heart rate
with sensors attached to the chest, and facial expressions using facereader™ software. from the
results,theyfoundarelationshipbetweenthelikingofsamples,andheartrateandskintemperature
aswellasneutralexpressions. danneretal.[152]conductedastudywithdifferentjuiceandvegetable
juicestoassessbiometricsfromconsumers. themeasurementsdoneconsistedoffacialexpressions
usingfacereader™,skinconductance,skintemperature,andheartratewithbiofeedback2000x-pert
electrodes (assessment systems, praha, czech republic) attached to the forefinger. the reported
resultsshowedacorrelationbetweenthelikingofthesamplesandskinconductance. furthermore,
anotherstudyusingfacereader™toevaluatethefacialexpressionsofconsumerstowardsorange
juicesampleswasconducted,findingacorrelationbetweenliking,andhappyanddisgustedemotions
inlikedanddislikedjuices,respectively[153].
6. artificialintelligence
theconceptofartificialintelligence(ai)datesbacktothe1960sinwhichjohnmccarthycame
upwiththeidesofautomatingmachines,andcreatedanailaboratoryatstanforduniversity[154].
in general, the term ai refers to the machines that are designed and automated to think, behave,
solveproblemsandmakedecisionsashumanswoulddo,apartfromhavingtheabilitytoimprove
throughself-learning[21]. itmaybeclassifiedinto(i)strongorgeneralizedai,whichiscapableof
understanding,improving,andsolvingproblems,usuallyusingml,and(ii)weakorappliedaithat
islimitedtoperformspecifictaskssuchasrecognizing,searching,oranalyzingcertaincomponents.
currently,thegeneralizedaiexistsintheory,butonlytheweakorappliedaihasbeendeveloped[155].
theoverallconceptofaimayconsistofanycombinationofitsdifferentbranches,suchasml,andcv;
itmayalsoincludetheuseofrobotics,sensors,andbiometrics(figure5). however,themainpurpose
ofaiapplicationisnottofullyreplacehumans,buttodevelopintelligentsystemsabletoperform
accurate,reliable,morerapidandobjectivetasksorjobswhichmaybetiringandtediousforhumans,
and that could lead to errors [21,154]. furthermore, ai allows the performance of manufacturing
processeswithhighersafetylevels,lesswasteandtheabilitytoproducehigh-qualityproducts[156].
beverages 2019, 5, x for peer review 17 of 25
beverages2019,5,62 17of25
figure5. venndiagramshowingtherelationshipbetweenartificialintelligenceandotherintegrated
fteicghunreo l5o.g vieesn.nt dhioasgeratmha sthaorweionugt stihdee rtehlaetimonasinhicpa bteegtworeyenre aprrteifsiecinatl tiencthelnliigqeunecset ahnadt motahyerf uinntcetgioranteads
tsetachnndo-alolognieesa. ntdhdosoen tohtant eacrees soauritlsyideen ttehrew mitahiinn cthateeagrotrifiy criaeplirnetseelnlitg etencchengiqrouueps itnhaatl lmcaasye sf.unction as
stand-alone and do not necessarily enter within the artificial intelligence group in all cases.
regardingtheapplicationsofaiinthebeverageindustry,ithasbeenusedformonitoring,quality
assuranceandcontrol,productdevelopmentanddecision-making,amongothers[156]. inrecentyears,
regarding the applications of ai in the beverage industry, it has been used for monitoring,
somebeveragecompanieshaveimplementedai,suchascarlsberg,whichusesthistechnologyto
quality assurance and control, product development and decision-making, among others [156]. in
developnewbeersinacost-effectiveandrapidwaythroughacombinedmethodusingmicrosoft®
recent years, some beverage companies have implemented ai, such as carlsberg, which uses this
(microsoftcorporation,redmond,wa,usa)platformandsensorstodeterminecomplexflavorsin
technology to develop new beers in a cost-effective and rapid way through a combined method using
theproducts[95]. intelligentxdevelopedageneralizedaitechniquetoimprovebeerstylesbyusing
microsoft® (microsoft corporation, redmond, wa, usa) platform and sensors to determine complex
feedbackfromconsumersthroughsocialmedia;thesystemisabletomakedecisionsandcharacterize
flavors in the products [95]. intelligentx developed a generalized ai technique to improve beer styles
theproductstocreatethebestbeeraccordingtoconsumers’needs[31].
by using feedback from consumers through social media; the system is able to make decisions and
characterize the products to create the best beer according to consumers’ needs [31].
7. keyfindingsandfuturetrends
7. kedy efsipnidteinthges ianncdre fasuitnugretr tenrednidnst heapplicationofemergingtechnologies,whichinvolvetheuseof
robotics,ml,cv,andbiometricsinthebeverageindustry,therearestillseveralgapstobecovered,
despite the increasing trend in the application of emerging technologies, which involve the use
especiallyinthebiometricsfield. roboticsscienceneedstobemoreexploredinbeveragesasatoolto
of robotics, ml, cv, and biometrics in the beverage industry, there are still several gaps to be covered,
aidotheraicomponents,whichwouldmaximizetheuseofsomeemergingmethods. regardingcv,
especially in the biometrics field. robotics science needs to be more explored in beverages as a tool
mostapproachesdevelopedmainlyfortheassessmentofhotdrinksandnon-alcoholicbeveragesare
to aid other ai components, which would maximize the use of some emerging methods. regarding
basedontheanalysisofcolor;however,moreresearchneedstobeconductedtoapplythistechnology
cv, most approaches developed mainly for the assessment of hot drinks and non-alcoholic beverages
tomeasureotherparametersrelatedtothequalitytraitsspecifictoeachproduct. themainissuewith
are based on the analysis of color; however, more research needs to be conducted to apply this
mlisthatthereisstillalackofknowledgeamongresearchersconcerningtheproperdevelopment
technology to measure other parameters related to the quality traits specific to each product. the
techniques, usage,andinterpretationofthealgorithmsandmodeling,aswellasthewaytoselect
main issue with ml is that there is still a lack of knowledge among researchers concerning the proper
the best models to avoid over- or under-fitting, which are common problems within the existing
development techniques, usage, and interpretation of the algorithms and modeling, as well as the
publications. on the other hand, although biometrics has been used in the sensory science field
way to select the best models to avoid over- or under-fitting, which are common problems within the
over the last decade, it needs to be explored more in-depth using beverages as samples to assess
existing publications. on the other hand, although biometrics has been used in the sensory science
theirqualitybyunderstandingconsumerssubconsciousresponses,whichwouldallowtheindustry
field over the last decade, it needs to be explored more in-depth using beverages as samples to assess
to develop products with higher acceptability and quality based on the market trends and needs.
their quality by understanding consumers subconscious responses, which would allow the industry
furthermore,thecombinationoftwoormoreoftheaforementionedmethodsshouldbeconsideredto
to develop products with higher acceptability and quality based on the market trends and needs.
beimplementedasanapproachtoaiinthedifferentbeveragecategories,especiallyforhotandother
furthermore, the combination of two or more of the aforementioned methods should be considered
non-alcoholicdrinksinwhichthesetechnologieshavenotbeenverypopularamongcompanies.
to be implemented as an approach to ai in the different beverage categories, especially for hot and
other non-alcoholic drinks in which these technologies have not been very popular among
authorcontributions: c.g.v., d.d.t., f.r.d., ands.f.contributedequallyinthepreparationandwritingof
cthoimsrpevaineiwe.s.
afuunthdoinr gc:otnhtirsibreusteioanrcsh: cre.gce.ivv.e, ddn.do.tex.,t fer.rna.dl.f,u annddi nsg.f.. contributed equally in the preparation and writing of this
arecvkienwow. ledgments:c.g.v.wassupportedbythemelbourneresearchscholarshipfromtheuniversityofmelbourne.
beverages2019,5,62 18of25
conflictsofinterest: theauthorsdeclarenoconflictsofinterest.
glossaryofqualityindicators
aroma volatilearomaticcompoundsdetectedviatheretronasalolfactorysystem
bubblegrowth rateatwhichabubbleincreasesitssize
bubblehaze largenumberofmicro-bubblesformedwhenthebeerispoured,andthatcirculatethe
liquidbeforereachingthesurface
bubblesizedistribution numberofsmall,mediumandlargebubbles
cielab colorparametersinwhichl=lightness,a=redtogreen,andb=yellowtobluevalues
clarity leveloftransparencyoftheliquidduetolackofsuspendedparticles
collar arrayofbubblesthatremainsattheedgeoftheglass
color visualelementproducedwhenthelightthathitsanobjectisreflectedtotheeye
density massdividedbythevolumeunitofaliquid
flavor perceptionofbasictastes,aromasandtrigeminalsensationsduringmastication
foamability capacitytoformfoam
foamdrainage excessofliquiddrainedfromthewetfoamtoproducedryfoam
foamstability lifetimeoffoam
foamthickness viscosityofthefoam
foamvolume amountoffoaminml
foamvelocity rateatwhichthefoamcollapses
off-odors odorsthatarenotcharacteristicoftheproductandareconsideredasfaults
ph measurementoftheacidityoralkalinitybasedonthenumberofhydrogenions
rgb colorinred,greenandbluescale
taste perceptionthroughthereceptorcellsfoundinthepapillae
texture sensorycharacteristicofthesolidorrheologicalstateofaproduct
viscosity consistencyofaliquidwhichmayvaryfromthintothick
waterhardness highmineralconcentrationinwater
references
1. pang,x.-n.; li,z.-j.; chen,j.-y.; gao,l.-j.; han,b.-z.acomprehensivereviewofspiritdrinksafety
standardsandregulationsfromaninternationalperspective. j.foodprot. 2017,80,431–442. [crossref]
[pubmed]
2. pushpangadan,p.;dan,v.m.;ijinu,t.;george,v.food,nutritionandbeverage. indianj.tradit. knowl. 2012,
11,26–34.
3. mise,j.k.;nair,c.;odera,o.;ogutu,m.factorsinfluencingbrandloyaltyofsoftdrinkconsumersinkenya
andindia. int. j.bus. manag. econ. res. 2013,4,706–713.
4. schwarz,b.;bischof,h.-p.;kunze,m.coffee,tea,andlifestyle. prev. med. 1994,23,377–384. [crossref]
[pubmed]
5. plutowska,b.;wardencki,w.applicationofgaschromatography–olfactometry(gc–o)inanalysisand
qualityassessmentofalcoholicbeverages–areview. foodchem. 2008,107,449–463. [crossref]
6. viejo,c.g.;fuentes,s.;torrico,d.d.;godbole,a.;dunshea,f.r.chemicalcharacterizationofaromasin
beerandtheireffectonconsumersliking. foodchem. 2019,293,479–485. [crossref]
7. viejo, c.g.; fuentes, s.; li, g.; collmann, r.; condé, b.; torrico, d. development of a robotic pourer
constructed with ubiquitous materials, open hardware and sensors to assess beer foam quality using
computervisionandpatternrecognitionalgorithms: robobeer.foodres. int. 2016,89,504–513. [crossref]
8. bamforth,c.;russell,i.;stewart,g.beer: aqualityperspective;academicpress: cambridge,ma,usa,2011.
9. gonzalezviejo,c.;fuentes,s.;torrico,d.;howell,k.;dunshea,f.r.assessmentofbeerqualitybasedon
foamabilityandchemicalcompositionusingcomputervisionalgorithms,nearinfraredspectroscopyand
artificialneuralnetworksmodellingtechniques. j.sci. foodagric. 2018,98,618–627. [crossref]
10. belitz,h.-d.;grosch,w.;schieberle,p.coffee,tea,cocoa. infoodchemistry;springer: berlin/heidelberg,
germany,2009;pp.938–970.
11. cullen,p.;cullen,p.j.;tiwari,b.k.;valdramidis,v.novelthermalandnon-thermaltechnologiesforfluidfoods;
academicpress: sandiego,ca,usa,2011.
beverages2019,5,62 19of25
12. wang,l.;sun,d.-w.;pu,h.;cheng,j.-h.qualityanalysis,classification,andauthenticationofliquidfoods
bynear-infraredspectroscopy: areviewofrecentresearchdevelopments. crit. rev. foodsci. nutr. 2017,57,
1524–1538. [crossref]
13. piper,d.; scharf,a.descriptiveanalysis: stateoftheartandrecentdevelopments; forschungsforumev:
göttingen,germany,2004.
14. gonzalezviejo,c.;fuentes,s.;torrico,d.d.;howell,k.;dunshea,f.r.assessmentofbeerqualitybasedon
aroboticpourer,computervision,andmachinelearningalgorithmsusingcommercialbeers. j.foodsci.
2018,83,1381–1388. [crossref]
15. kemp,s.;hollowood,t.;hort,j.sensoryevaluation: apracticalhandbook;wiley: oxford,uk,2011.
16. stone,h.;bleibaum,r.;thomas,h.a.sensoryevaluationpractices;elsevier: amsterdam,thenetherlands;
academicpress: cambridge,ma,usa,2012.
17. gonzalez viejo, c.; fuentes, s.; howell, k.; torrico, d.; dunshea, f.r. robotics and computer vision
techniquescombinedwithnon-invasiveconsumerbiometricstoassessqualitytraitsfrombeerfoamability
usingmachinelearning: apotentialforartificialintelligenceapplications. foodcontrol2018,92,72–79.
[crossref]
18. gonzalezviejo,c.;fuentes,s.;howell,k.;torrico,d.d.;dunshea,f.r.integrationofnon-invasivebiometrics
withsensoryanalysistechniquestoassessacceptabilityofbeerbyconsumers. phys. behav. 2019,200,139–147.
[crossref][pubmed]
19. gill,g.s.;kumar,a.;agarwal,r.monitoringandgradingofteabycomputervision–areview. j.foodeng.
2011,106,13–19. [crossref]
20. ceccarelli,m.fundamentalsofmechanicsofroboticmanipulation;springer: dordrecht,thenetherlands,2004.
21. delltechnologies. thedifferencebetweenai,machinelearning,androbotics. availableonline: https://
www.delltechnologies.com/en-us/perspectives/the-difference-between-ai-machine-learning-and-robotics/
(accessedon15august2019).
22. nayik,g.a.;muzaffar,k.;gull,a.roboticsandfoodtechnology: aminireview. j.nutr. foodsci. 2015,5,
1–11.
23. iqbal,j.;khan,z.h.;khalid,a.prospectsofroboticsinfoodindustry. foodsci. technol. 2017,37,159–165.
[crossref]
24. caldwell, d.g. robotics and automation in the food industry: current and future technologies; elsevier:
amsterdam,thenetherlands,2012.
25. makr shakr srl. makr shakr. available online: https://www.makrshakr.com/ (accessed on
15august2019).
26. wilson,a.visionandrobotsteamupforwineproduction. 2016. availableonline: https://www.vision-
systems.com/non-factory/article/16736826/vision-and-robots-team-up-for-wine-production/(accessedon
17august2019).
27. condé,b.c.;fuentes,s.;caron,m.;xiao,d.;collmann,r.;howell,k.s.developmentofaroboticand
computervisionmethodtoassessfoamqualityinsparklingwines. foodcontrol2017,71,383–392. [crossref]
28. peano, d.; chiaberge, m. innovative beer dispenser based on collaborative robotics. ph.d. thesis,
politecnicoditorino,torino,italy,2018.
29. yasui,k.;yokoi,s.;shigyo,t.;tamaki,t.;shinotsuka,k.acustomer-orientedapproachtothedevelopment
ofavisualandstatisticalfoamanalysis. j.am. soc. brew. chem. 1998,56,152–158. [crossref]
30. gonzalezviejo,c.; torrico,d.d.; dunshea,f.r.; fuentes,s.developmentofartificialneuralnetwork
modelstoassessbeeracceptabilitybasedonsensorypropertiesusingaroboticpourer: acomparative
modelapproachtoachieveanartificialintelligencesystem. beverages2019,5,33. [crossref]
31. marr,b.howartificialintelligenceisusedtomakebeer. forbes. 2019. availableonline: https://www.
forbes.com/sites/bernardmarr/2019/02/01/how-artificial-intelligence-is-used-to-make-beer/#35b077d070cf
(accessedon1february2019).
32. hutson,m.beer-slingingrobotpredictswhetheryou’llgivethatbrewathumbsup—ordown. science2018.
[crossref]
33. kayaalp,k.;ceylan,o.;süzen,a.a.;yildiz,z.internetcontrolledsmartteamachinedesignwitharduino
andteaconsumptionanalysis. uluborlumesl. bilimlerderg. 2018,1,29–37.
34. buhr,s.meetteforia,ateabrewingrobotforthehome.techcrunch. 30october2015. availableonline:
https://techcrunch.com/2015/10/29/meet-teforia-a-tea-brewing-robot-for-the-home/(accessedon1february2019).
beverages2019,5,62 20of25
35. buhr,s.tastetestingwithteabot,therobotthatbrewsuplooseleafteainunder30seconds.techcrunch,
24july2015. availableonline: https://techcrunch.com/2015/07/23/taste-testing-with-teabot-the-robot-that-
brews-up-loose-leaf-tea-in-under-30-seconds/(accessedon18june2019).
36. coward,c.mugsy,theraspberrypi-poweredcoffeemaker,isnearingproduction. mediumcorporation.
2019. availableonline: https://www.hackster.io/news/mugsy-the-raspberry-pi-based-robotic-coffee-maker-
is-now-on-kickstarter-8a24f38ffbe6(accessedon15july2019).
37. budds,d.cana$25,000robotmakebettercoffeethanabarista? curbed;voxmedia,inc.,23february2018.
availableonline: https://www.curbed.com/2018/2/23/17041842/cafe-x-automated-coffee-robot-ammunition-
design(accessedon15july2019).
38. do,c.;burgard,w.accuratepouringwithanautonomousrobotusinganrgb-dcamera. inproceedingsof
theinternationalconferenceonintelligentautonomoussystems,singapore,1–3march2018;pp.210–221.
39. morita,t.;kashiwagi,n.;yorozu,a.;walch,m.;suzuki,h.;karagiannis,d.;yamaguchi,t.practiceof
multi-robotteahousebasedonprintepsandevaluationofservicequality. inproceedingsofthe2018ieee
42ndannualcomputersoftwareandapplicationsconference(compsac),tokyo,japan,23–27july2018;
pp.147–152.
40. cai,d.c.;chen,j.f.;chang,y.w.designanddevelopmentofbeveragemaker. appl. mech. mater. 2014,590,
581–585. [crossref]
41. albrecht,c.albertsbringsrobotsmoothiestationstoeurope. thespoon. 18april2018. availableonline:
https://thespoon.tech/alberts-brings-robot-smoothie-stations-to-europe/(accessedon15july2019).
42. awwad,s.;tarvade,s.;piccardi,m.;gattas,d.j.theuseofprivacy-protectedcomputervisiontomeasure
thequalityofhealthcareworkerhandhygiene. int. j.qual. healthcare2018,31,36–42. [crossref][pubmed]
43. wu,d.;sun,d.-w.colourmeasurementsbycomputervisionforfoodqualitycontrol–areview. trendsfood
sci. technol. 2013,29,5–20. [crossref]
44. lukinac,j.;mastanjevic´,k.;mastanjevic´,k.;nakov,g.;jukic´,m.computervisionmethodinbeerquality
evaluation—areview. beverages2019,5,38. [crossref]
45. solem,j.e.programmingcomputervisionwithpython: toolsandalgorithmsforanalyzingimages;o’reilly
media,inc.: sebastopol,ca,usa,2012.
46. marques,o.practicalimageandvideoprocessingusingmatlab;johnwiley&sons: hoboken,nj,usa,2011.
47. sun,d.-w.inspectingpizzatoppingpercentageanddistributionbyacomputervisionmethod. j.foodeng.
2000,44,245–249. [crossref]
48. sarangi,p.; mishra,b.; majhi,b.; dehuri,s.gray-levelimageenhancementusingdifferentialevolution
optimizationalgorithm. inproceedingsofthe2014internationalconferenceonsignalprocessingand
integratednetworks(spin),noida,india,20–21february2014;pp.95–100.
49. vala,h.j.;baxi,a.areviewonotsuimagesegmentationalgorithm. intern. j.adv. res. comput. eng. technol.
(ijarcet)2013,2,387–389.
50. fuentes,s.;hernández-montes,e.;escalona,j.;bota,j.;viejo,c.g.;poblete-echeverría,c.;tongson,e.;
medrano, h. automated grapevine cultivar classification based on machine learning using leaf
morpho-colorimetry, fractal dimension and near-infrared spectroscopy parameters. comput. electron.
agric. 2018,151,311–318. [crossref]
51. szeliski, r. computer vision: algorithms and applications; springer science & business media: london,
uk,2010.
52. sun,d.-w.computervisiontechnologyforfoodqualityevaluation;academicpress:cambridge,ma,usa,2016.
53. rodrigues,b.u.;dacosta,r.m.;salvini,r.l.;dasilvasoares,a.;dasilva,f.a.;caliari,m.;cardoso,k.c.r.;
ribeiro,t.i.m.cachaçaclassificationusingchemicalfeaturesandcomputervision. procediacomput. sci.
2014,29,2024–2033. [crossref]
54. pessoa,k.d.;suarez,w.t.;dosreis,m.f.;franco,m.d.o.k.;moreira,r.p.l.;dossantos,v.b.adigitalimage
methodofspottestsfordeterminationofcopperinsugarcanespirits. spectrochim. actaparta:mol. biomol.
spectrosc. 2017,185,310–316. [crossref]
55. wang,y.;zhou,b.;zhang,h.;ge,j.avision-basedintelligentinspectorforwineproduction. intern. j.mach.
learn. cybern. 2012,3,193–203. [crossref]
56. martin,m.l.g.-m.;ji,w.;luo,r.;hutchings,j.;heredia,f.j.measuringcolourappearanceofredwines.
foodqual. preference2007,18,862–871. [crossref]
beverages2019,5,62 21of25
57. pérez-bernal, j.l.; villar-navarro, m.; morales, m.l.; ubeda, c.; callejón, r.m. the smartphone as an
economicalandreliabletoolformonitoringthebrowningprocessinsparklingwine. comput. electron. agric.
2017,141,248–254. [crossref]
58. arakawa,t.;iitani,k.;wang,x.;kajiro,t.;toma,k.;yano,k.;mitsubayashi,k.asniffer-cameraforimaging
ofethanolvaporizationfromwine: theeffectofwineglassshape. analyst2015,140,2881–2886. [crossref]
[pubmed]
59. cilindre,c.;liger-belair,g.;villaume,s.;jeandet,p.;marchal,r.foamingpropertiesofvariouschampagne
winesdependingonseveralparameters: grapevariety,aging,proteinandco2content. anal. chim. acta
2010,660,164–170. [crossref][pubmed]
60. crumpton,m.;rice,c.j.;atkinson,a.;taylor,g.;marangon,m.theeffectofsucroseadditionatdosage
stageonthefoamattributesofabottle-fermentedenglishsparklingwine. j.sci. foodagric. 2018, 98,
1171–1178. [crossref]
61. silva,t.;godinho,m.s.;deoliveira,a.e.identificationofpalelagerbeersviaimageanalysis. lat. am. appl.
res. 2011,41,141–145.
62. fengxia,s.;yuwen,c.;zhanming,z.;yifeng,y.determinationofbeercolorusingimageanalysis. j.am. soc.
brew. chem. 2004,62,163–167. [crossref]
63. hepworth,n.;varley,j.;hind,a.characterizinggasbubbledispersionsinbeer. foodbioprod. process. 2001,
79,13–20. [crossref]
64. hepworth,n.; hammond,j.; varley,j.novelapplicationofcomputervisiontodeterminebubblesize
distributionsinbeer. j.foodeng. 2004,61,119–124. [crossref]
65. cimini,a.;pallottino,f.;menesatti,p.;moresi,m.alow-costimageanalysissystemtoupgradetherudin
beerfoamheadretentionmeter. foodbioprocesstechnol. 2016,9,1587–1597. [crossref]
66. dong,c.-w.;zhu,h.-k.;zhao,j.-w.;jiang,y.-w.;yuan,h.-b.;chen,q.-s. sensoryqualityevaluationfor
appearanceofneedle-shapedgreenteabasedoncomputervisionandnonlineartools. j.zhejianguniv. sci.
b2017,18,544–548. [crossref][pubmed]
67. singh,g.;kamal,n.machinevisionsystemforteaqualitydetermination-teaqualityindex(tqi).iosrj.
eng. 2013,3,46–50. [crossref]
68. kumar,a.;singh,h.;sharma,s.;kumar,a.coloranalysisofblacktealiquorusingimageprocessing
techniques. int. j.electron. commun. technol. 2011,2,292–296.
69. akuli,a.;pal,a.;bej,g.;dey,t.;ghosh,a.;tudu,b.;bhattacharyya,n.;bandyopadhyay,r.amachine
visionsystemforestimationoftheaflavinsandthearubiginsinorthodoxblacktea. int. j.smartsens.
intell. syst. 2016,9,709–731. [crossref]
70. oblitascruz,j.;castrosilupu,w.computervisionsystemfortheoptimizationofthecolorgeneratedby
thecoffeeroastingprocessaccordingtotime,temperatureandmeshsize. ingenieríayuniversidad2014,18,
355–368. [crossref]
71. várvölgyi,e.;werum,t.;dénes,l.;soós,j.;szabó,g.;felföldi,j.;esper,g.;kovács,z.visionsystemand
electronictongueapplicationtodetectcoffeeadulterationwithbarley. actaaliment. 2014, 43, 197–205.
[crossref]
72. deoliveira,e.m.;pereira,r.g.f.a.;leme,d.s.;barbosa,b.h.g.;rodarte,m.p.acomputervisionsystem
forcoffeebeansclassificationbasedoncomputationalintelligencetechniques. j.foodeng. 2016,171,22–27.
[crossref]
73. chu,b.;yu,k.;zhao,y.;he,y.developmentofnoninvasiveclassificationmethodsfordifferentroasting
degreesofcoffeebeansusinghyperspectralimaging. sensors2018,18,1259. [crossref]
74. piazza,l.;bulbarello,a.;gigli,j.rheologicalinterfacialpropertiesofespressocoffeefoamingfractions.
in proceedings of the 13th world congress of food science & technology 2006, nantes, france,
17–21september2006;p.873.
75. buratti,s.; benedetti,s.; giovanelli,g.applicationofelectronicsensestocharacterizeespressocoffees
brewedwithdifferentthermalprofiles. eur. foodres. technol. 2017,243,511–520. [crossref]
76. damasceno,d.;toledo,t.g.;soares,a.d.s.;deoliveira,s.b.;deoliveira,a.e.compvis: anovelmethod
fordrinkingwateralkalinityandtotalhardnessanalyses. anal. methods2016,8,7832–7836. [crossref]
77. barker,g.;jefferson,b.;judd,s.;judd,s.thecontrolofbubblesizeincarbonatedbeverages. chem. eng. sci.
2002,57,565–573. [crossref]
beverages2019,5,62 22of25
78. viejo,c.g.;torrico,d.d.;dunshea,f.r.;fuentes,s.theeffectofsonicationonbubblesizeandsensory
perceptionofcarbonatedwatertoimprovequalityandconsumeracceptability. beverages2019,5,58.
[crossref]
79. aliabadi,r.s.;mahmoodi,n.o.synthesisandcharacterizationofpolypyrrole,polyanilinenanoparticles
andtheirnanocompositeforremovalofazodyes;sunsetyellowandcongored. j.clean. prod. 2018,179,
235–245. [crossref]
80. botelho,b.g.;deassis,l.p.;sena,m.m.developmentandanalyticalvalidationofasimplemultivariate
calibrationmethodusingdigitalscannerimagesforsunsetyellowdeterminationinsoftbeverages. food
chem. 2014,159,175–180. [crossref][pubmed]
81. sorouraddin,m.-h.; saadati,m.; mirabi,f.simultaneousdeterminationofsomecommonfooddyesin
commercialproductsbydigitalimageanalysis. j.fooddruganal. 2015,23,447–452. [crossref]
82. hosseininia,s.a.r.;kamani,m.h.;rani,s.quantitativedeterminationofsunsetyellowconcentrationin
softdrinksviadigitalimageprocessing. j.foodmeas. charact. 2017,11,1065–1070. [crossref]
®
83. heredia,f.;gonzález-miret,m.;álvarez,c.;ramírez,a.digifood (análisisdeimagen). registrono. se
1298. 2006. availableonline: http://www.https.com//digifood.com/(accessedon1november2019).
84. fernández-vázquez,r.;stinco,c.m.;hernanz,d.;heredia,f.j.;vicario,i.m.colourtrainingandcolour
differencesthresholdsinorangejuice. foodqual. preference2013,30,320–327. [crossref]
85. fernandez-vazquez, r.; stinco, c.m.; melendez-martinez, a.j.; heredia, f.j.; vicario, i.m. visual and
instrumentalevaluationoforangejuicecolor: aconsumers’preferencestudy. j.sens. stud. 2011,26,436–444.
[crossref]
86. vélez-ruiz,j.;barbosa-cánovas,g.flowandstructuralcharacteristicsofconcentratedmilk. j.texturestud.
2000,31,315–333. [crossref]
87. dossantos,p.m.;pereira-filho,e.r.digitalimageanalysis–analternativetoolformonitoringmilkauthenticity.
anal. methods2013,5,3669–3674. [crossref]
88. goodfellow,i.;bengio,y.;courville,a.deeplearning;mitpress: cambridge,ma,usa,2016.
89. mathworksinc. masteringmachinelearning: astep-by-stepguidewithmatlab;mathworksinc.: sherborn,
ma,usa,2018.
90. romero,m.;luo,y.;su,b.;fuentes,s.vineyardwaterstatusestimationusingmultispectralimageryfrom
anuavplatformandmachinelearningalgorithmsforirrigationschedulingmanagement. comput. electron.
agric. 2018,147,109–117. [crossref]
91. pedregosa,f.;varoquaux,g.;gramfort,a.;michel,v.;thirion,b.;grisel,o.;blondel,m.;prettenhofer,p.;
weiss,r.;dubourg,v.scikit-learn: machinelearninginpython. j.mach. learn. res. 2011,12,2825–2830.
92. abadi,m.;barham,p.;chen,j.;chen,z.;davis,a.;dean,j.;devin,m.;ghemawat,s.;irving,g.;isard,m.
tensorflow: asystemforlarge-scalemachinelearning. inproceedingsofthe12th{usenix}symposium
onoperatingsystemsdesignandimplementation({osdi}16),savannah,ga,usa,2–4november2016;
pp.265–283.
93. witten,i.h.; frank,e.; hall,m.a.; pal,c.j.datamining: practicalmachinelearningtoolsandtechniques;
morgankaufmann: burlington,ma,usa,2016.
94. hornik,k.;buchta,c.;zeileis,a.open-sourcemachinelearning: rmeetsweka. comput. stat. 2009,24,
225–232. [crossref]
95. buss,d.foodcompaniesgetsmartaboutartificialintelligence. foodtechnol. 2018,72,26–41.
96. srivastava,n.;hinton,g.;krizhevsky,a.;sutskever,i.;salakhutdinov,r.dropout: asimplewaytoprevent
neuralnetworksfromoverfitting. j.machinelearn. res. 2014,15,1929–1958.
97. martino,j.c.r.hands-onmachinelearningwithmicrosoftexcel2019: buildcompletedataanalysisflows,from
datacollectiontovisualization;packtpublishing: birmingham,uk,2019.
98. backhaus, a.; ashok, p.c.; praveen, b.b.; dholakia, k.; seiffert, u. classifying scotch whisky from
near-infraredramanspectrawitharadialbasisfunctionnetworkwithrelevancelearning. inproceedings
ofthe20theuropeansymposiumonartificialneuralnetworks,computationalintelligenceandmachine
learning,esann,bruges,belgium,25–27april2012;pp.411–416.
99. ceballos-magaña,s.g.;jurado,j.m.;muñiz-valencia,r.;alcázar,a.;depablos,f.;martín,m.j.geographical
authenticationoftequilaaccordingtoitsmineralcontentbymeansofsupportvectormachines. foodanal.
methods2012,5,260–265. [crossref]
beverages2019,5,62 23of25
100. andrade, j.m.; ballabio, d.; gómez-carracedo, m.p.; pérez-caballero, g. nonlinear classification of
commercialmexicantequilas. j.chemom. 2017,31,e2939. [crossref]
101. rodrigues, b.u.; soares, a.d.s.; costa, r.m.d.; van baalen, j.; salvini, r.; silva, f.a.d.; caliari, m.;
cardoso, k.c.r.; ribeiro, t.i.m.; delbem, a.c. a feasibility cachaca type recognition using computer
visionandpatternrecognition. comput. electron. agric. 2016,123,410–414. [crossref]
102. er,y.;atasoy,a.theclassificationofwhitewineandredwineaccordingtotheirphysicochemicalqualities.
int. j.intell. syst. appl. eng. 2016,4,23–26. [crossref]
103. dacosta,n.l.;castro,i.a.;barbosa,r.classificationofcabernetsauvignonfromtwodifferentcountriesinsouth
americabychemicalcompoundsandsupportvectormachines.appl.artif.intell.2016,30,679–689. [crossref]
104. perrot,n.;baudrit,c.;brousset,j.m.;abbal,p.;guillemin,h.;perret,b.;goulet,e.;guerin,l.;barbeau,g.;
picque,d.adecisionsupportsystemcouplingfuzzylogicandprobabilisticgraphicalapproachesforthe
agri-foodindustry: predictionofgrapeberrymaturity. plosone2015,10,e0134373. [crossref][pubmed]
105. lvova,l.;yaroshenko,i.;kirsanov,d.;dinatale,c.;paolesse,r.;legin,a.electronictongueforbrand
uniformitycontrol: acasestudyofapulianredwinesrecognitionanddefectsevaluation. sensors2018,18,
2584. [crossref][pubmed]
106. cetó,x.;gutiérrez,j.m.;moreno-barón,l.;alegret,s.;delvalle,m.voltammetricelectronictongueinthe
analysisofcavawines. electroanalysis2011,23,72–78. [crossref]
107. fuentes,s.;tongson,e.j.;debei,r.;gonzalezviejo,c.;ristic,r.;tyerman,s.;wilkinson,k.non-invasive
toolstodetectsmokecontaminationingrapevinecanopies,berriesandwine: aremotesensingand
machinelearningmodelingapproach. sensors2019,19,3335. [crossref]
108. navajas,m.p.s.; delteso,s.f.; romero,m.; dario,p.; díaz,d.; gonzález,v.f.; zurbano,p.f.modelling
wineastringencyfromitschemicalcompositionusingmachinelearningalgorithms. oenoone2019,53,
498–510.
109. fuentes,s.;gonzalezviejo,c.;wang,x.;torrico,d.d.aromaandqualityassessmentforverticalvintages
usingmachinelearningmodellingbasedonweatherandmanagementinformation. inproceedingsofthe
21stgiescointernationalmeeting,thessaloniki,greece,23–28june2019.
110. cetó,x.;gutiérrez-capitán,m.;calvo,d.;delvalle,m.beerclassificationbymeansofapotentiometric
electronictongue. foodchem. 2013,141,2533–2540. [crossref]
111. alcázar,á.;jurado,j.m.;palacios-morillo,a.;depablos,f.;martín,m.j.recognitionofthegeographicaloriginof
beerbasedonsupportvectormachinesappliedtochemicaldescriptors.foodcontrol2012,23,258–262. [crossref]
112. rousu,j.;elomaa,t.;aarts,r.predictingthespeedofbeerfermentationinlaboratoryandindustrialscale.
inproceedingsoftheinternationalwork-conferenceonartificialneuralnetworks,alicante,spain,2–4june
1999;pp.893–901.
113. santos,j.p.;lozano,j.realtimedetectionofbeerdefectswithahandheldelectronicnose. inproceedingsof
the201510thspanishconferenceonelectrondevices(cde),aranjuez-madrid,spain,11–13february2015;
pp.1–4.
114. gardner,j.w.;bartlett,p.n.abriefhistoryofelectronicnoses. sens. actuatorsbchem. 1994,18,210–211.
[crossref]
115. voss,h.g.j.;mendesjúnior,j.j.a.;farinelli,m.e.;stevan,s.l.aprototypetodetectthealcoholcontentof
beersbasedonanelectronicnose. sensors2019,19,2646. [crossref]
116. zhang,y.;jia,s.;zhang,w.predictingaceticacidcontentinthefinalbeerusingneuralnetworksandsupport
vectormachine. j.inst. brew. 2012,118,361–367. [crossref]
117. yu,h.;wang,j.;yao,c.;zhang,h.;yu,y.qualitygradeidentificationofgreenteausinge-nosebycaand
ann.lwt-foodsci. technol. 2008,41,1268–1273. [crossref]
118. chen,q.;zhao,j.;chen,z.;lin,h.;zhao,d.-a.discriminationofgreenteaqualityusingtheelectronicnose
techniqueandthehumanpaneltest,comparisonoflinearandnonlinearclassificationtools. sens. actuators
bchem. 2011,159,294–300. [crossref]
119. cimpoiu, c.; cristea, v.-m.; hosu, a.; sandru, m.; seserman, l. antioxidant activity prediction and
classificationofsometeasusingartificialneuralnetworks. foodchem. 2011,127,1323–1328. [crossref]
120. guo,z.; chen,l.; zhao,c.; huang,w.; chen,q.nondestructiveestimationoftotalfreeaminoacidin
greenteabynearinfraredspectroscopyandartificialneuralnetworks. inproceedingsoftheinternational
conferenceoncomputerandcomputingtechnologiesinagriculture,beijing,china,29–31october2011;
pp.43–53.
beverages2019,5,62 24of25
121. zhu,h.;ye,y.;he,h.;dong,c.evaluationofgreenteasensoryqualityviaprocesscharacteristicsandimage
information. foodbioprod. process. 2017,102,116–122. [crossref]
122. messias,j.a.;melo,e.d.c.;lacerdafilho,a.f.d.;braga,j.l.;cecon,p.r.determinationoftheinfluenceof
thevariationofreducingandnon-reducingsugarsoncoffeequalitywithuseofartificialneuralnetwork.
engenhariaagrícola2012,32,354–360. [crossref]
123. domínguez,r.;moreno-barón,l.;muñoz,r.;gutiérrez,j.voltammetricelectronictongueandsupport
vectormachinesforidentificationofselectedfeaturesinmexicancoffee. sensors2014, 14, 17770–17785.
[crossref]
124. romani,s.;cevoli,c.;fabbri,a.;alessandrini,l.;dallarosa,m.evaluationofcoffeeroastingdegreeby
usingelectronicnoseandartificialneuralnetworkforoff-linequalitycontrol. j.foodsci. 2012,77,c960–c965.
[crossref]
125. thazin,y.;pobkrut,t.;kerdcharoen,t.predictionofaciditylevelsoffreshroastedcoffeesusinge-noseand
artificialneuralnetwork. inproceedingsofthe201810thinternationalconferenceonknowledgeandsmart
technology(kst),chiangmai,thailand,31january–3february2018;pp.210–215.
126. bucak,i.o.;karlik,b.detectionofdrinkingwaterqualityusingcmacbasedartificialneuralnetworks.
ekoloji2011,20,75–81. [crossref]
127. camejo,j.; pacheco,o.; guevara,m.classifierfordrinkingwaterqualityinrealtime. inproceedings
of the 2013 international conference on computer applications technology (iccat), sousse, tunisia,
20–22january2013;pp.1–5.
128. chatterjee,s.;sarkar,s.;dey,n.;sen,s.;goto,t.;debnath,n.c.waterqualityprediction: multiobjective
geneticalgorithmcoupledartificialneuralnetworkbasedapproach. inproceedingsofthe2017ieee15th
internationalconferenceonindustrialinformatics(indin),emden,germany,24–26july2017;pp.963–968.
129. qiu,s.;gao,l.;wang,j.classificationandregressionofelm,lvqandsvmfore-nosedataofstrawberry
juice. j.foodeng. 2015,144,77–85. [crossref]
130. hong,x.;wang,j.;qi,g.e-nosecombinedwithchemometricstotracetomato-juicequality. j.foodeng.
2015,149,38–43. [crossref]
131. qiu,s.;wang,j.thepredictionoffoodadditivesinthefruitjuicebasedonelectronicnosewithchemometrics.
foodchem. 2017,230,208–214. [crossref][pubmed]
132. nandeshwar,v.j.;phadke,g.s.;das,s.classificationoforangejuiceadulterationusinglda,pcaand
ann.inproceedingsofthe2016ieee1stinternationalconferenceonpowerelectronics,intelligentcontrol
andenergysystems(icpeices),delhi,india,4–6july2016;pp.1–5.
133. rácz,a.;bajusz,d.;fodor,m.;héberger,k.comparisonofclassificationmethodswith“n-class”receiver
operatingcharacteristiccurves: acasestudyofenergydrinks. chemom. intell. lab. syst. 2016,151,34–43.
[crossref]
134. rácz,a.; héberger,k.; fodor,m.quantitativedeterminationandclassificationofenergydrinksusing
near-infraredspectroscopy. anal. bioanal. chem. 2016,408,6403–6411. [crossref][pubmed]
135. mamat, m.; samad, s.a. classification of beverages using electronic nose and machine vision systems.
inproceedingsofthe2012asiapacificsignalandinformationprocessingassociationannualsummitand
conference,hollywood,ca,usa,3–6december2012;pp.1–6.
136. balabin,r.m.;smirnov,s.v.melaminedetectionbymid-andnear-infrared(mir/nir)spectroscopy: aquick
andsensitivemethodfordairyproductsanalysisincludingliquidmilk,infantformula,andmilkpowder.
talanta2011,85,562–568. [crossref]
137. jain,a.;flynn,p.;ross,a.a.handbookofbiometrics;springer: newyork,ny,usa,2007.
138. viola,p.;jones,m.rapidobjectdetectionusingaboostedcascadeofsimplefeatures. inproceedingsofthe
2001ieeecomputersocietyconferenceoncomputervisionandpatternrecognition. cvpr2001,kauai,
hi,usa,8–14december2001;volume511,pp.i-511–i-518.
139. mcduff,d.;mahmoud,a.;mavadati,m.;amr,m.;turcot,j.;kaliouby,r.e. affdexsdk:across-platform
real-timemulti-faceexpressionrecognitiontoolkit. inproceedingsofthe2016chiconferenceextended
abstractsonhumanfactorsincomputingsystems,sanjose,ca,usa,7–12may2016;pp.3723–3726.
140. leanneloijens,o.k.;vankuilenburg,h.;denuyl,m.;ivan,p.facereader™version6.1referencemanual;
noldusinformationtechnologyb.v: wageningen,thenetherlands,2015.
141. fuentes,s.;gonzalezviejo,c.;torrico,d.;dunshea,f.developmentofabiosensorycomputerapplication
toassessphysiologicalandemotionalresponsesfromsensorypanelists. sensors2018,18,2958. [crossref]
beverages2019,5,62 25of25
142. dewijk,r.a.;he,w.;mensink,m.g.;verhoeven,r.h.;degraaf,c.ansresponsesandfacialexpressions
differentiatebetweenthetasteofcommercialbreakfastdrinks. plosone2014,9,e93823. [crossref]
143. he,w.;boesveldt,s.;degraaf,c.;dewijk,r.a.dynamicsofautonomicnervoussystemresponsesand
facialexpressionstoodors. front. psychol. 2014,5,110. [crossref]
144. frelih,n.g.;podlesek,a.;babicˇ,j.;geršak,g.evaluationofpsychologicaleffectsonhumanposturalstability.
measurement2017,98,186–191. [crossref]
145. jain,m.;deb,s.;subramanyam,a.facevideobasedtouchlessbloodpressureandheartrateestimation.
inproceedingsofthe2016ieee18thinternationalworkshoponmultimediasignalprocessing(mmsp),
montreal,qc,canada,21–23september2016;pp.1–5.
146. carvalho,l.;virani,m.h.;kutty,m.s.analysisofheartratemonitoringusingawebcam. analysis2014,3,
6593–6595.
147. viejo,c.g.;fuentes,s.;torrico,d.d.;dunshea,f.r.non-contactheartrateandbloodpressureestimations
fromvideoanalysisandmachinelearningmodellingappliedtofoodsensoryresponses: acasestudy
forchocolate. sensors2018,18,1802. [crossref][pubmed]
148. torrico,d.d.;fuentes,s.;viejo,c.g.;ashman,h.;gurr,p.a.;dunshea,f.r.analysisofthermochromic
labelelementsandcolourtransitionsusingsensoryacceptabilityandeyetrackingtechniques. lwt2018,89,
475–481. [crossref]
149. kamboj,s.k.;joye,a.;bisby,j.a.;das,r.k.;platt,b.;curran,h.v.processingoffacialaffectinsocialdrinkers:
adose–responsestudyofalcoholusingdynamicemotionexpressions. psychopharmacology2013,227,31–39.
[crossref][pubmed]
150. beyts,c.;chaya,c.;dehrmann,f.;james,s.;smart,k.;hort,j.acomparisonofself-reportedemotionaland
implicitresponsestoaromasinbeer. foodqual. preference2017,59,68–80. [crossref]
151. garcia-burgos,d.;zamora,m.c.exploringthehedonicandincentivepropertiesinpreferencesforbitter
foodsviaself-reports,facialexpressionsandinstrumentalbehaviours. foodqual. preference2015,39,73–81.
[crossref]
152. danner,l.;haindl,s.;joechl,m.;duerrschmid,k.facialexpressionsandautonomousnervoussystem
responseselicitedbytastingdifferentjuices. foodres. int. 2014,64,81–90. [crossref]
153. danner,l.;sidorkina,l.;joechl,m.;duerrschmid,k.makeaface! implicitandexplicitmeasurementof
facialexpressionselicitedbyorangejuicesusingfacereadingtechnology. foodqual. preference2014,32,
167–172. [crossref]
154. mcpherson,s.s.artificialintelligence: buildingsmartermachines;twenty-firstcenturybooks: minneapolis,
mn,usa,2018.
155. joshi, n. how far are we from achieving artificial general intelligence? forbes, 10 june 2019.
availableonline: https://www.forbes.com/sites/cognitiveworld/2019/06/10/how-far-are-we-from-achieving-
artificial-general-intelligence/#2edd17436dc4(accessedon17july2019).
156. mohammadi, v.; minaei, s. artificial intelligence in the production process. in engineering tools in the
beverageindustry;elsevier: amsterdam,thenetherlands,2019;pp.27–63.
©2019bytheauthors. licenseemdpi,basel,switzerland. thisarticleisanopenaccess
articledistributedunderthetermsandconditionsofthecreativecommonsattribution
(ccby)license(http://creativecommons.org/licenses/by/4.0/)."
6,Towards green automated machine learning_ Status quo and future directions.pdf,"
journalofartificialintelligenceresearch77(2023)427-457 submitted10/2022;published06/2023
towards green automated machine learning:
status quo and future directions
tanja tornede tanja.tornede@upb.de
alexander tornede alexander.tornede@upb.de
jonas hanselle jonas.hanselle@upb.de
department of computer science, paderborn university, germany
felix mohr felix.mohr@unisabana.edu.co
universidad de la sabana, chia, cundinamarca, colombia
marcel wever marcel.wever@ifi.lmu.de
eyke hu¨llermeier eyke@ifi.lmu.de
institute of informatics, university of munich (lmu), germany
munich center for machine learning (mcml), germany
abstract
automated machine learning (automl) strives for the automatic configuration of ma-
chine learning algorithms and their composition into an overall (software) solution — a
machinelearningpipeline — tailoredtothelearningtask(dataset)athand. overthelast
decade, automlhasdevelopedintoanindependentresearchfieldwithhundredsofcontri-
butions. at the same time, automl is being criticized for its high resource consumption
as many approaches rely on the (costly) evaluation of many machine learning pipelines, as
well as the expensive large-scale experiments across many datasets and approaches. in the
spiritofrecentworkongreenai,thispaperproposesgreenautoml,aparadigmtomake
the whole automl process more environmentally friendly. therefore, we first elaborate
on how to quantify the environmental footprint of an automl tool. afterward, different
strategies on how to design and benchmark an automl tool w.r.t. their “greenness”, i.e.,
sustainability, are summarized. finally, we elaborate on how to be transparent about the
environmental footprint and what kind of research incentives could direct the community
in a more sustainable automl research direction. as part of this, we propose a sustain-
ability checklist to be attached to every automl paper featuring all core aspects of green
automl.
1. introduction
a machine learning (ml) pipeline is a combination of suitably configured ml algorithms
into an overall (software) solution that can be applied to a specific learning task, which is
typically characterized by a dataset on which a (predictive) model ought to be trained. the
design of such pipelines is a time and resource consuming task due to the immense number
of solutions conceivable, each of them solving the same problem but varying in performance
(i.e., producing models of better or worse predictive accuracy). therefore, aiming to find
the best performing pipeline, candidates are evaluated on the dataset at hand to further
adapt and improve its composition and configuration. aiming at the automation of this
process, automl (hutter et al., 2019) develops methods for searching the space of ml
pipelines in a systematic way, typically with a predefined timeout after which the most
©2023theauthors. publishedbyaiaccessfoundationundercreativecommonsattributionlicenseccby4.0.
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
promising candidate is used to train the final model. the interest in the field of automl
has rapidly increased in the recent past, and the field has broadened in scope, though
predictive performance remains the main measure of interest.
in the field of automl, theoretical results are quite difficult to obtain, because the
problemiscomplexandhardlyamenabletotheoreticalanalysis. accordingly,mostresearch
contributions are of empirical nature: the proposition of a new technique or approach is
accompanied by large experimental studies to show the benefits of the proposed techniques.
asoneisinterestedintechniquesthatworkwellingeneral,acrossabroadrangeofproblems,
a large number of datasets is required for evaluation. additionally, as there is not a single
automlsystemrepresentingthestateoftheart(sota)anddominatingallothers,multiple
competitorsneedtobeassessed. tothisend, eachcompetitorisusuallyre-evaluatedonthe
samedatasetsandideallyunderidenticalconditions,forexample,thesamesearchspaceand
hardware restrictions. combined with long evaluation times of a single solution candidate
of up to several hours or even days, like in the case of neural architecture search (nas)
(elsken et al., 2019b), all this culminates in a field that is quite resource-intensive and
therefore producing immense carbon emission — much of which could be mostly avoided
as we discuss later on. note that carbon emissions or co e refer to co equivalents, i.e.,
2 2
the amount of co with the same global warming potential as the actual gas emitted.
2
tofullycoverthecarbonemissionsproducedthroughasinglepublishedautomlpaper,
one has to consider the whole production chain, starting with the generation and storage of
data, thecomputationaleffortandmemoryneededduringthedevelopmentoftheaccording
automl system and also the final benchmark. usually, most of the carbon emission is
caused by the automl process, namely the evaluations of ml pipelines and the storage of
the intermediate results of the search process, which is why we mostly focus on this part
throughout the paper.
however,wewouldliketostressthatpaperswithalargeenvironmentalfootprintarenot
necessarilytobedoomed(thiswillbediscussedinmoredetaillateron). whatisimportant,
instead, is to carefully trade-off cost versus benefit. for example, a paper investing many
resources in creating a benchmark, which then allows other researchers to save resources on
their papers, might offer a much larger benefit than a paper investing the same resources in
evaluating a method that only grants a 0.001% improvement compared to sota methods.
the general problem is not exclusive to automl but similarly applies to many other
ai-related fields, in particular deep learning due to its ever-increasing architectures (ben-
der et al., 2021; patterson et al., 2022). lately, there has been a growing interest in being
more environmentally friendly in the whole field of ai. while ai for sustainability is quite
commonly known, sustainability of ai has long been less of a concern. in 2019, schwartz
et al. (2019) introduced the notion of green ai, advocating to consider the energy efficiency
of ai algorithms during their development. additionally, they propose to attach relevant
information, such as the elapsed runtime of all experiments or carbon emissions to every ai
paper published. similarly, van wynsberghe (2021) campaigns for more work on sustain-
ability of ai, especially economic, social, and environmental sustainability. even large tech
companies such as google advocate for the consideration of the co e footprint as part of
2
papers and corresponding transparency about it (patterson et al., 2022).
in the spirit of the recent work on green ai, we seek to transfer the ideas and problems
to thefield of automl,we dub this paradigmgreen automl. thefoundation thereof isthe
428
towards green automl: status quo and future directions
quantificationoftheenvironmentalfootprintofautomlapproaches(section2). ingeneral,
we identify four categories of actions the community may take towards the reduction of the
environmental footprint of research on automl. the design (section 3) and benchmarking
(section 4) of automl systems are both key aspects to consider for improving the environ-
mental footprint. furthermore, being transparent about that footprint (section 5) can give
valuable additional information about an automl approach. lastly, appropriate research
incentives (section 6) could direct the automl research in a more sustainable direction.
additionally, we elaborate on the trade-off between focusing on environmental impact and
the freedom of research (section 7) and on the prospects of automl (section 8), prior to
concluding this paper.
2. quantifying sustainability
quantifying the sustainability of an automl approach is usually the first step towards a
more environmentally friendly approach. however, measuring sustainability in terms of a
single number, suitable as a basis for comparing different approaches with each other, is a
challenging problem.
2.1 measures for post-hoc analysis
first and foremost, it is important to differentiate between the efficiency of an approach
and the environmental footprint of a specific experiment featuring the approach. when
assessing several measures in the following regarding their ability to quantify efficiency, we
alwaysrefertotheperformancecurveoftheapproach(cf. section4.3). thiscurvedescribes
the dependency between the measure of interest (e.g. runtime) and the performance (e.g.
accuracy)achievedbytheapproachafteracertainamountofbudgetw.r.t. thatmeasurehas
been consumed. for example, we would consider a tool achieving an accuracy of 0.8 after
30 seconds of runtime to be more efficient than a tool requiring 60 seconds, if runtime was a
suitablemeasureforquantifyingefficiency. moreover,measurestoquantifyefficiencyshould
be hardware-independent, very much like the o-notation for characterizing complexity in
theoreticalcomputerscience,butofcoursenotonlyasymptotic,because“constants”clearly
matter in this case.
in practice, however, approaches are often run on varying hardware with different prop-
erties, such as energy consumption. furthermore, experiments often vary in terms of scope.
consider, for example, two works suggesting different approaches where one evaluates on
only two datasets using an old laptop with a cpu having a high energy consumption and
the other one evaluates on 100 datasets on much more efficient and also suitable hardware
provided by a compute center. the second work will most likely have a larger environ-
mental footprint because more energy is consumed than the first one, although it could
potentially be a much more efficient approach. moreover, while any reasonable measure
for efficiency should be hardware-independent, measures for the environmental impact of a
specific experiment on a specific machine must be hardware-dependent.
accordingly, green automl research can neither be quantified solely on the basis of the
efficiency of an approach nor the environmental impact of a specific (set of) experiment(s).
instead, the two must be considered jointly. in the following, we discuss several such
measures w.r.t. their suitability for both measuring energy efficiency and environmental
429
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
properties quantification
tnirptooflatnemnorivne
ecnednepednierawdrah
ytilibaterpretninamuh
ytilibarusaem
ycneicffie
measure
runtime × (cid:88) × × ◦
cpu/gpu hours × (cid:88) × × ◦
floating point operations × (cid:88) × × ×
energy consumption × × (cid:88) × (cid:88)
co e × × (cid:88) × (cid:88)
2
table 1: summary of discussed measures to quantify efficiency and environmental impact,
together with their properties (fulfilled: (cid:88); partially fulfilled: ◦; not fulfilled: ×).
impact, which is visually summarized in table 1. for the following discussion, we focus
mostlyonaspectsofsustainabilityinducedbycomputationandlargelyignoreotheraspects,
such as the software lifecycle or reliability, which are considered in general research on
softwaresustainability(caleroetal.,2013;lagoetal.,2015;caleroetal.,2019;lannelongue
et al., 2021). in particular, the measures we discuss in the following can be attributed to
the area of performance efficiency proposed by calero et al. (2013) and, as the majority
of the measures in that area, our discussed measures focus on estimating time or resource
consumption in one way or the other.
2.1.1 runtime
although runtime completely ignores aspects such as memory consumption, it strongly
correlates with the energy consumption of the corresponding experiment, which is usually
a linear function of runtime and energy consumption of the components. however, runtime
by itself is not easy to interpret by a human with regard to the size of an environmental
footprint, asitisnotanumberthatcanbedirectlycomparedtosomethingcommonlyused,
for example the footprint of a flight.
nevertheless, if enough additional information, such as the energy consumption of the
used hardware (per time unit) and the composition of the energy mix, are available, it
is a suitable foundation for computing an estimate on the overall co e footprint of the
2
experiment at the location and time it was performed. furthermore, compared to other
measures (to be discussed in the following), runtime is rather straightforward to measure
on most hardware.
overall, runtime is a poor measure of efficiency, as it is not hardware-independent, but
it is quite practical as a proxy of the environmental impact.
430
towards green automl: status quo and future directions
2.1.2 cpu/gpu hours
similarly, measuring cpu/gpu hours is both practical and easy to quantify environmental
impact. unfortunately, cpu/gpu time is often used ambiguously, as one can measure
either wall clock cpu/gpu time or true cpu/gpu time, which results in different in-
terpretations for quantifying environmental impact. on one hand, if wall clock time is
used, the impact of other operations like memory access is implicitly included. this also
includes overloaded main memory where the computer starts swapping. on the other hand,
if real cpu/gpu time is used, those operations are partially ignored. similarly, as before,
cpu/gpu hours make it hard for a human to quantify the impact in comparison to other
causes known from daily life. moreover, counting cpu/gpu hours is a poor proxy for effi-
ciency, as it is hardware-dependent. nevertheless, as of now, it is one of the most practical
proxies as it is easy to measure and rather easy to convert into co e assuming that the
2
cpu/gpu consistently uses a certain amount of energy and that the energy mix is known.
2.1.3 floating point operations
althoughcounter-intuitive,floatingpointoperations(fpo)areahardware-dependentmea-
sure and as such they are not well suited for quantifying efficiency either. the hardware
dependence is caused by the optimization of the compiler when the corresponding code is
compiled. dependingonthedegreeofoptimization(andthehardwarethecodeisoptimized
for), the amount of fpos can vary. at the same time, it is also problematic as a proxy for
environmentalfootprint,because,similartothepreviousmeasures,itignoresotherelements
such as memory usage. however, fpos are often easy to measure, as most cpu/gpus
have corresponding counters that can be read. once again, from a human perspective, this
measure is hard to interpret and put in comparison with others.
2.1.4 energy consumption
similar to runtime, energy consumption is not hardware independent but heavily depends
ontheenergyefficiencyofthehardware. thus, whilebeingabadmeasureofefficiencyofan
approach, itisanexcellentmeasureforquantifyingtheenvironmentalfootprintofaspecific
experiment on specific hardware, as energy, apart from the hardware itself, is the main
external resource required to perform automl experiments. moreover, from the amount of
consumed energy, one can often reasonably approximate the actual co e emissions caused
2
by the experiment at the location and time of execution, if enough additional information
(such as the energy mix) is available. even more so, humans can often quite easily put
energy consumption in perspective, as most people are aware of their own consumption at
home. unfortunately, measuring energy consumption is often difficult in practice, where
hpc systems are used to perform experimental evaluations. while one can measure the
energy used by a personal computer quite easily, using appropriate electrical instruments,
measuring the energy consumption across several nodes of a cluster, which might even be
shared with other users, can be very complicated. we refer to garc´ıa-mart´ın et al. (2019)
for a comprehensive overview of available estimation methods and corresponding software.
431
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
2.1.5 co equivalents
2
co eis, inprinciple, an excellent and probably the most direct measure for quantifyingthe
2
environmental footprint of an experiment, if the physical location and the time of execution
are provided as well. however, co e as a measure suffers even more from the problem of
2
measurability than energy consumption, because it is not directly measurable. instead, it
canbecomputedbasedontheenergyconsumptionandadditionalinformationontheenergy
mix. in practice, obtaining corresponding information is often not possible, and in fact, the
energymixmightevenvarydependingonexternaleffects, suchastheweather, ifitcontains
renewable energy components. moreover, while the energy consumption of an experiment
is mostly independent of thetime and locationof execution, the co efootprint ofthe same
2
experiment can vary drastically depending on these factors. consequently, the energy mix
should be noted as part of the footprint. for example, running an experiment at a compute
center completely powered by renewable energy will result in no direct co e emissions,
2
whereas running the same experiment on a unit powered by energy produced from coal will
result in much larger co e emissions. patterson et al. (2021) even demonstrate that the
2
choice of the actual (deep learning) model, the compute center and the compute unit can
influence the carbon footprint of a work by a factor of 1000, and that simply choosing the
right compute center location can result in a factor of up to 10.
2.2 ignored side factors
none of the measures previously discussed includes other side factors such as the resources
used by the scheduler of the hpc system, or by a potential database holding the data, or
thewholeprocessofgeneratingandtransferringthedata. especiallythelatteriscrucial, as
reusing existing data (instead of generating new ones) makes a paper more environmentally
friendlyifonedoesnotaccountforthedatageneration. similarly, theshareofthefootprint
caused by the production of the hardware itself is almost impossible to quantify, as this
would require knowledge of details about both the lifetime and the future usage of the
hardware in advance. lastly, one actually needs to quantify the environmental impact in
terms of multiple measures, as the production of hardware, the operation of hpc systems
and other factors also impact the environment apart from co e emissions, for example,
2
through water usage. overall, the problem of quantifying the environmental footprint of
scientific research is extremely complex and may constitute a custom paper on its own.
we refer the interested reader to the research area of software sustainability for more all-
encompassing general work on the matter (calero et al., 2013; lago et al., 2015; calero
et al., 2019).
2.3 best practices for quantifying sustainability
to measure the environmental footprint of a specific experiment, it is most practical to use
the wall clock time based cpu/gpu hours as a proxy. this number is usually easy to
capture without any timely investigations about the energy mix and the energy consump-
tion, which, in case of hpc, might be impossible to obtain. nevertheless, in case those
additional information is easy to access, the environmental footprint itself can be estimated
by multiplying the cpu/gpu hours with the energy consumption per unit and co e of
2
432
towards green automl: status quo and future directions
the energy mix. note that although the energy mix might be green, the computation is
still not for free. the mere usage of resources already leaves a footprint (tool wear, etc.),
which is why saving any cpu/gpu hours of any energy mix, or avoiding any unnecessary
computational time, will reduce the overall footprint of the research. overall, it is most
important to be transparent about the environmental footprint, which might help inter-
ested readers to decide which method from a paper suits their needs. therefore, attaching
this information to a published paper is key towards achieving green automl, which we
elaborate on in section 5.
when it comes to estimating the efficiency of an approach independent of the hardware,
we do not have a concrete suggestion, as none of the solutions previously discussed is truly
satisfying. nevertheless, we think this is an important aspect that should be covered in
future work.
2.4 tooling and software
there exists software and tool support that can help to quantify environmental impact.
one example is carbontracker (anthony et al., 2020), which tracks and predicts the carbon
emissions consumed while training deep learning models. similarly, irene (cao et al., 2021)
predicts the energy consumption of transformer-based natural language processing (nlp)
models. parcollet and ravanelli (2021) propose a framework to investigate carbon emis-
sions of end-to-end automatic speech recognition (asr). energyvis (shaikh et al., 2021)
is a more general tool, which is capable of tracking energy consumption for various kinds
of machine learning models and provides an interactive view to compare the consumption
across different locations. unfortunately, it is limited to the usa at the moment. similarly,
the machine learning emissions calculator1 (lacoste et al., 2019) is an easy-to-use online
tool for estimating the co e footprint of a set of experiments. similarly, the tool by lan-
2
nelongue et al. (2021) called greenalgorithms2 estimates the co e of any software artifact
2
based on several quantities such as the cpu or gpu hours. notably, they also consider the
energy consumed by memory and other factors making it perhaps the most comprehensive
tool. schmidtetal.(2021)designedapythonlibrary, calledcodecarbon3, directlyallowing
to measure the co e footprint of your application within code. we close the tool section
2
with (garc´ıa-mart´ın et al., 2019), which gives a comprehensive overview of methods and
software for estimating the energy consumption of machine learning techniques.
3. design of automl systems
although, as mentioned earlier, the evaluation of automl approaches is presumably the
largest source of negative environmental impact directly caused by automl research, it can
arguably be seen as a symptom rather than a true cause. the evaluation of such systems is
only as expensive as the search process employed, and especially the evaluation of solution
candidates is often very resource intensive. hence, we believe that developing methods
inherently considering their environmental footprint is a key idea towards green automl.
1. https://mlco2.github.io/impact
2. http://calculator.green-algorithms.org/
3. https://www.codecarbon.io/
433
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
in general, we differentiate between three research directions that could be taken in this
regard. first, one can focus on the development of methods that produce energy-efficient
ml pipelines (section 3.1). second, one can zoom in on designing approaches that strive
for a compromise between finding a good ml pipeline and minimizing the energy consumed
by their search process itself (section 3.2). third, one can try to optimize the development
process of automl approaches to be more energy-efficient (section 3.3).
3.1 finding energy-efficient pipelines
developing methods whose final output is very energy-efficient does not necessarily reduce
the environmental footprint of the automl system itself. however, it is a step in the right
direction, as it most likely reduces the long-term footprint of the resulting pipeline, which
willbeusedinproduction. thus, quantifyingtheco esavedbythedeployedmodelshould
2
also be considered when quantifying the environmental footprint of the automl process
itself. in principle, it is even conceivable to estimate the saved co e by a deployed model
2
to determine if the execution of the automl system is actually worth it. although the
pipeline resulting from an automl process in a research context is usually not deployed,
this is, of course, the case for industrial applications of automl where the reduction in
co e footprint can indeed make a difference.
2
moreover, finding energy-efficient pipelines is not only of interest from a sustainability
driven point of view but also from a practical one. when trying to design pipelines for
embedded systems such as sensor nodes or mobile devices, which rely on a battery that
is not often recharged, energy efficiency becomes a core criterion. recent work started to
target this issue (he et al., 2018; wang et al., 2019b; stamoulis et al., 2018b). for example,
he et al. (2018) suggest automl approaches to compress and accelerate neural network
models for usage on mobile devices and thus naturally reduce their energy consumption by
reducing the number of flops required for a pass through the network. similarly, wang
et al. (2019b) suggest to iteratively enlarge a neural network through a splitting procedure
which explicitly considers the increase in energy cost by splitting a certain neuron such
that resulting networks are more energy-efficient than competitors. in this regard, it is also
conceivabletoobtainmoreenergy-efficientpipelinesasaresultofthesearchprocessthrough
the use of multi-objective automl methods such as (elsken et al., 2019a; pfisterer et al.,
2019; schmucker et al., 2021; candelieri et al., 2022), initialized with both performance and
energy-efficiency as target measures.
3.2 energy-efficient automl methods
theseconddirectionistargetedatimprovingtheenvironmentalfootprintofautomlmeth-
ods themselves, i.e., the underlying search algorithms. to this end, once again, several
approaches are conceivable.
3.2.1 warmstarting
warmstarting refers to a mechanism that integrates knowledge gained in prior executions
intothecurrentexecutionsuchthattheoptimizationprocessdoesnotstartcompletelyfrom
scratch, without any prior information. clearly, the idea of warmstarting is to find good
candidates early, which hence would allow for shorter timeouts with the confidence that
434
towards green automl: status quo and future directions
these are indeed (nearly) optimal. research on warmstarting techniques has been heavily
boosted by automl challenges with short timeouts (cf. section 6).
typically, warmstartingisbasedononeortheotherformofmeta-learning(vanschoren,
2018). that is, based on experiences from the past, which may or may not be associated
with particular dataset properties, a recommendation is made for the current dataset.
a very simple case of warmstarting is when there is just a constant initial sequence that
is followed. for example, in ml-plan (mohr et al., 2018), a fixed order of algorithms is
provided,whichisdeterminedbasedontheoverallaverageperformanceofalgorithmsacross
previous datasets. similarly, auto-sklearn 2.0 (feurer et al., 2022) scans a static portfolio
that tries to cover different use cases.
alternatively, the dataset properties can be considered in order to make recommenda-
tions. although various forms of warmstarting have been suggested in the field of hyper-
parameter optimization (swersky et al., 2013; bardenet et al., 2013; yogatama and mann,
2014), the firstapproachfor automlwe areawareofthat appliesthiskind ofwarmstarting
was auto-sklearn (feurer et al., 2015). here, the dataset meta-features (such as numbers
of instances, features, skewedness, etc.) are used to match them to datasets seen in the
past. then, the pipelines that performed best on those datasets are considered with prior-
ity. meanwhile, warmstarting has become a standard technique for many automl systems
(lindauer and hutter, 2018; perrone et al., 2017; yang et al., 2019; fusi et al., 2018).
3.2.2 zero-shot automl
an extreme case of warmstarting is zero-shot automl, motivated by the idea of zero-shot
learning (xian et al., 2017). here, the warmstarting mechanism recommends only a single
candidate pipeline, and this one is adopted by the system without even evaluating it at all.
interestingly, zero-shot automl was among the first approaches in the field. for exam-
ple, the meta-miner approach was based on recommendations obtained from an ontology
over dataset and algorithm properties (nguyen et al., 2011). even though at that time the
term zero-shot automl was not yet coined, no evaluation was involved in this recommen-
dation.
a couple of zero-shot automl approaches have been proposed recently (drori et al.,
2019; singh et al., 2021; mellor et al., 2021; lin et al., 2021). those approaches leverage
transfer(torreyandshavlik,2010)andmeta-learning(vanschoren,2018)inanofflinephase
prior to their usage. during this phase, the approaches either use existing performance
data of ml pipelines on a variety of datasets or generate such data on their own in order
to learn a mapping from datasets to ml pipelines, which can then be queried more or less
instantaneously during the actual usage. to enable such a learning, datasets usually need
to be represented in terms of features, so-called meta-features (rivolli et al., 2018). for
example, given a new dataset (drori et al., 2019) compute meta-features based on a learned
embedding of the dataset description, find the closest dataset from their offline training
phase in terms of a measure defined on the meta-feature space and return the pipeline,
which performed best on that dataset.
obviously, these methods cannot work completely without energy-consuming computa-
tions, butshifttheneedforcomputationawayfromtheactualsearchphasetoaprioroffline
phaseofferingtwopotentialadvantages. first,itallowsonetoschedulesuchanofflinephase
435
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
at times where renewable energy is readily available while the actual system can then still
be used at any time in order to propose a pipeline for a given dataset. second, it enables
one to save large amounts of energy if the automl system is used excessively enough, such
that the initial training phase requires less energy than using a standard automl system
during the search.
clearly, less extreme variants such as one-shot (lake et al., 2011) or few-shot (wang
et al., 2020) approaches could be used as well. in fact, recent challenges in this field have
stimulated currently ongoing research (cf. section 6).
3.2.3 avoiding evaluations with a timeout
typically, automl systems that are based on a trial and error strategy, i.e., training and
validating candidate ml pipelines on the given data, specify a timeout for the evaluation
of those candidates. the reason for such timeouts is that some candidates can be very
time-consuming to evaluate, and thus impair exploration or, in extreme cases, even lead to
a stall of the optimization process. while limiting the evaluation time and terminating the
assessment of candidate pipelines prematurely — if the specified time budget is exceeded
— is a technical necessity, it severely affects the efficiency of such automl systems. as
pointed out by mohr et al. (2021), a large portion of computational resources are spent
on evaluating pipelines that will be prematurely terminated due to a timeout yielding only
very limited information for the search process. in fact, often there is no information at all,
so the cpu/gpu time is literally wasted.
itishenceanaturalobjectivetoreducethenumberofsuchevents. forthisreason,mohr
et al. (2021) suggest to equip automl systems relying on executing solution candidates
with a so-called safeguard, which estimates the runtime of a pipeline prior to execution and
prohibits its evaluation in case a timeout is likely to occur. similarly, yang et al. (2019)
involve a runtime prediction component allowing one to maximize the information gain in
comparison to the time spent on the evaluation of a pipeline.
theproblemofpipelineruntimepredictionisarguablyharderthantheoneofpredicting
the runtime of “atomic” learning algorithms alone. in fact, there has been a lot of work on
algorithm runtime prediction in general (e.g., (hutter et al., 2014; tornede et al., 2020a;
huang et al., 2010; smith-miles and van hemert, 2011; eggensperger et al., 2020)). how-
ever, as shown by mohr et al. (2021), predicting pipeline runtimes is more than just aggre-
gating runtimes of its components, because the output of components, e.g., pre-processing
steps, often impacts the runtime of subsequent components, e.g., other pre-processors or
the learner.
concepts similar to the safeguard mentioned above can be found in the domain of algo-
rithm configuration (hutter et al., 2009; ans´otegui et al., 2009; hutter et al., 2011), where
an algorithm should be configured to optimize its runtime and racing or adaptive capping
mechanisms (hutter et al., 2009) are used. essentially, adaptive capping prematurely ter-
minates the evaluation of solution candidates to speed up the optimization process based
on some criterion, such as bounds on the achievable performance.
436
towards green automl: status quo and future directions
3.2.4 multi-fidelity performance measurements
an alternative approach is to make evaluations so cheap that there is no longer a need to
consider timeouts. the idea here is to use a cheap-to-compute function to approximate the
relative performance of a candidate pipeline. of course, the performance of a candidate is
always only estimated, but often this is done through (costly) cross-validation procedures
using a lot of data. the idea of low-fidelity estimation is to have a cheap estimator that
is trained on low-cost approximations and which is faithful with respect to the ordering of
candidates.
as one approach, one could try to pick models based on evaluations using subsamples
of the data for which the models are cheap to evaluate. in fact, this approach has been
proposed early on and was shown to be quite effective (petrak, 2000). while this approach
assigns a constant (prior) evaluation sample size, more recent approaches in the area of
multi-fidelity optimization add the evaluation fidelity (sample size) as a degree of freedom
to the optimizer. typical resource candidates to influence the degree of evaluation fidelity
are the size of the training set or the number of iterations for iterative learning algorithms
such as gradient descent. when being able to evaluate performance at different degrees
of fidelity, adapted bayesian optimization methods can be leveraged in order to optimize
machine learning pipelines in a cost-effective manner (kandasamy et al., 2017; klein et al.,
2017; falkner et al., 2018; wu et al., 2019; candelieri et al., 2021; zimmer et al., 2021;
candelieri et al., 2022; feurer et al., 2022). in particular, the fabolas approach (klein
et al., 2017) actively trades off the sample size against the expected performance. similarly,
other optimization methods based on multi-armed bandits or differential evolution can be
equipped with ideas from multi-fidelity optimization (li et al., 2017; awad et al., 2021).
orthogonaltothis,itispossibletoreducethenumberofrepetitionsinacross-validation.
that is, one trades the stability obtained from various validation iterations for evaluation
speed. while k-fold cross-validation is not very flexible in this regard, monte-carlo cross-
validation(mccv)canbeconsideredinafine-granularmannerconfiguringboth thesample
size and the number of iterations. to our knowledge, there are no studies that analyze let
alone dynamically fine-tune mccv in order to reduce computational time without losing
the order on the candidates.
3.2.5 early discarding of unpromising candidates
early discarding means to abandon a candidate early in its training process if it gets appar-
entthatitwillnotbecompetitive. earlydiscardingisoperationalizedviaempiricallearning
curves. that is, by analyzing the partially available learning curves, one can decide on the
relevance of the respective candidate.
we distinguish between approaches that adopt early discarding based on a horizontal
or vertical model selection strategy. in a horizontal scenario, a portfolio of candidates is
fixed in the beginning, and learning curves are grown simultaneously for increasing anchor
sizes (hence horizontally from left to right). at each anchor, a set of candidates is dropped.
this is the core idea of successive halving (jamieson and talwalkar, 2016). horizontal
approaches are also sometimes called multi-fidelity optimizers. in a vertical scenario, candi-
dates are generated sequentially and each of them is evaluated on increasing anchors until
it can be predicted that it will not be competitive. this approach was considered first for
437
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
neural networks in (domhan et al., 2015) and more recently in the learning curve based
cross-validation scheme (lccv) for all types of learners (mohr and van rijn, 2021). the
authors showed that, even if all learners are non-iterative, the time required to evaluate a
specific portfolio can be reduced by over 20% on average compared to a cross-validation.
for portfolios with iterative learners, one would expect this improvement to increase even
further.
between these extremes, there are also hybrid approaches. for example, hyperband (li
et al., 2017) follows a horizontal approach but adds new candidates to the portfolio at each
stage. another approach is freeze-thaw-optimization (swersky et al., 2014), which allows
for pausing training processes and resume them later if the candidate appears attractive
again.
3.2.6 energy consumption as part of the objective function
it is also conceivable to make the automl search algorithm directly aware of the energy it
consumes. for example, one could adapt bayesian optimization (bo) for automl (thorn-
ton et al., 2013; feurer et al., 2015; komer et al., 2014) by incorporating a version of
expected improvement, which considers the energy consumed when evaluating the next so-
lution candidate. in analogy to the idea of expected improvement per second (snoek et al.,
2012), one way of considering energy consumption in the optimization process is to employ
expected improvement per kwh of consumed energy as an acquisition function, i.e.,
ei(p)
eikwh(p) = , (1)
kwh(p)
where ei(p) denotes the expected improvement associated with pipeline p, and kwh(p)
denotes the estimated energy consumption associated with evaluating pipeline p, might
be a good candidate for further investigation. with such an acquisition function, bo is
guided towards carefully weighing between the information gain of a solution candidate and
its execution cost. however, similar to the methods presented in section 3.2.3, this idea
requiresknowledgeabouttheenergyconsumptionofaspecificpipelinepriortoitsexecution.
first work on corresponding estimation techniques exists (cao et al., 2021; stamoulis et al.,
2018a; anthony et al., 2020). stamoulis et al. (2018a) also suggest a similar acquisition
functionexplicitlyincorporatingenergyconstraintsonmodels. however, theyonlyconsider
the amount of energy required for inference of a trained network instead of the energy for
training, which we are interested in. similarly, instantiating hyperband (li et al., 2017)
with energy as a budget is also an option. in principle, one could even consider combining
both ideas in order to create an adapted version of bohb (falkner et al., 2018), which
essentially constitutes a bo-hyperband hybrid.
3.2.7 exploiting heterogeneous hardware resources
as another possible approach, one could consider the design of automl systems that ex-
ploit the heterogeneity of solution candidates w.r.t. their energy consumption on different
hardware to improve the overall consumption. to this end, one could exploit a heteroge-
neous (w.r.t. the types of computational devices, i.e., cpus, gpus, fpgas, etc.) cluster
andthenscheduletheevaluationofasolutioncandidateonthehardwarebestsuitedforthe
438
towards green automl: status quo and future directions
current model in terms of energy-efficiency. for example, while a neural network should be
evaluated on a gpu, other learners can potentially be more efficiently executed on cpus.
this might not necessarily speed up the automl search process in terms of time, but can
still result in an improvement regarding energy consumption. while we believe that this is
a potentially interesting line of research, we are not aware of any work in this direction.
3.2.8 intelligent stopping criteria
automl systems can also be improved by implementing intelligent stopping criteria, which
consider if it can be assumed that an improvement is possible within the remaining run-
time. the main idea is to decide whether the granted runtime is actually needed or if
the search can be stopped early. those considerations are similar to the ideas of early
stopping (prechelt, 2012) in machine learning or early stopping criteria from the field of
metaheuristics (gendreau, 2003).
asanexample,theconceptsproposedinleanml(samo,2021)couldbeusedassuchan
intelligentcriterion. itisbasedontheideaofestimatingthehighestachievableperformance
on a dataset, which can then be used to prematurely stop the automl search process, once
the chance of finding a better solution in the remaining time is very small.
a work in this direction, which won the best paper award at the first automl con-
ference in 2022, was recently presented by makarova et al. (2022), who suggest stopping
hyperparameter optimization when the validation performance is presumably close to the
achievable performance. to this end, they analyze the estimated difference between the
validation loss and the test loss and stop when it is roughly equivalent to the estimation
error associated with this difference.
3.2.9 use of saved resources
as we have seen, there are various possibilities to save runtime, such as avoiding timeouting
evaluations(cf. section3.2.3),discardingunpromisingcandidatesearly(cf.section3.2.5)or
implementing intelligent stopping criteria (cf. section 3.2.8). in general, there are two ways
to make use of saved resources. one option is to terminate early, which directly influences
the environmental footprint. alternatively, the search could be continued such that more
solution candidates can be considered, and eventually less of the allocated resources will be
wasted. accordingly, it is important to note that simply reducing the amount of wasted
resources does not automatically coincide with energy savings unless the overall search
budget is reduced according to the search time saved. nevertheless, such improvements can
be valuable even when the search time is not reduced as the benefit/environmental cost
ratio increases.
3.3 efficiency of automl approach development
the third direction is to address the development phase of automl approaches. due to the
complexity of automl approaches, one usually needs multiple evaluations until the system
is (mostly) free of bugs and all concepts are working as intended. although a lot of effort
can be made to decrease the environmental footprint of an automl approach or its final
pipeline, in a research context, usually the development phase makes up a significant part
439
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
of the actual environmental footprint and, therefore, the carbon emissions produced. in the
following, we elaborate on a few concepts that can be applied to avoid wasting resources.
a very basic concept, which can decrease the environmental footprint drastically, is
a simple caching strategy. the key idea is to cache the results of evaluated pipelines so
that at least some solution candidates do not need to be reevaluated when restarting the
automl approach. in such a case, the runtime should, of course, be cached as well in order
to add it to the elapsed time, such that a rerun does not benefit from previous executions.
this is especially important for automl settings, where the evaluation of a single solution
candidate takes a lot of time, like in neural architecture search (elsken et al., 2019b) or in
the field of automl for predictive maintenance (tornede et al., 2020b, 2021).
another way to decrease the environmental footprint is to work with a very small de-
velopment dataset and search space. based on that, testing the implementation can be
done within a short amount of time, thereby again decreasing the runtime and saving both
development time and energy.
4. benchmarking
since automl is an empirical research branch, experimentation is an inherent part of the
research in general and at the heart of almost every publication. due to the complexity
of automl systems, theoretical results are rather hard to obtain and usually assume some
simplifications, which in turn limits the scope of conclusions that can be drawn from the
results. moreover, most theoretical results are accompanied by experiments to show that
these are also reflected in practical scenarios. typically, experimentation in automl not
onlyinvolvesexperimentationwiththenewlyproposedmethodbutalsowithitscompetitors
as baselines to demonstrate that the novel method is indeed superior to the current sota.
however, asinthecaseofthebasealgorithmsbeingselectedandconfiguredbyautoml
systems, the performances of automl systems themselves are complementary to each other
(mohr et al., 2018). hence, there is not a single best automl system representing the
current sota, but rather an array of competitive methods. as a consequence, comparisons
are carried out to a (growing) set of baselines, in turn, leading to increased computational
costs. while feurer et al. (2015) report computational cost of 11 cpu-years (cpuy), the
experimental data of mohr et al. (2018) is the result of 52 cpuy worth of computations.
in (wever et al., 2021), the experimental study is as extensive as 84 cpuy. in the sub-
field of neural architecture search (nas) (elsken et al., 2019b), computational costs for
experimentation can even be higher. single automl runs use the computational power of
450gpusfor7days(realetal.,2019)oreven800gpusfor28days(zophandle,2017)4.
note that the published numbers usually only take into account the computational costs of
the results eventually presented and not those incurred during development for testing.
the main issue causing baselines to be executed repeatedly with almost every study
is that there is no gold standard for the experiment setup. that is, datasets as well as
specifics of the setup (such as hardware resources, timeouts, search spaces, configurations
4. assumingagtx1080tiwithatdpof250w,thegpupowerdemandperrunamountsto134.4mwh,
whichistheequivalentoftheyearlypowerconsumptionofroughly304-personshouseholdswithapower
demand of 4,250kwh each. this does not yet include the power consumption of the remaining system.
on current aws gpu nodes, a single such run costs 483,840$.
440
towards green automl: status quo and future directions
of the automl systems) vary from study to study, impeding not only comparability across
publications but also reproducibility as some important details concerning the experiment
setup might be missing. to address these issues, various benchmarks have been proposed
in order to foster reproducibility and comparability (section 4.1) as well as sustainabil-
ity (section 4.2). moreover, we propose to consider ecological performance profiles when
benchmarking automl systems (section 4.3).
4.1 reproducibility and comparability
from a research perspective, benchmarks serve the purpose of providing a common plat-
form for empirical research. the main goal is to establish or increase the comparability
and reproducibility of results. for the research area of automated machine learning this
includes, for example, the definition of certain variables such as the set of datasets to be
examined, the target metric to be optimized, time bounds for both the evaluation of single
candidate solutions and the total runtime of the automl system, the hardware to be used,
the search space definition, etc. according to the complexity of automl systems and the
many possible configurations, there is a large number of variables that can and need to be
fixed by benchmarks or explicitly left open.
for example, the openml (vanschoren et al., 2013) automl benchmark (gijsbers
et al., 2019) features 39 datasets, for each of which an automl system is given a total of 4
hours to search for a suitable pipeline. every such run is repeated ten times with different
seeds. furthermore, the benchmark suggests to use amazon aws m5.2xlarge compute
nodes, featuring an intel xeon platinum 8000 series skylake-sp processor with 8 cpu
cores and 32gb memory. the reason for this is that, on the one hand, the specifications
are in line with the hardware specifications of the majority of automl publications and,
on the other hand, in principle anyone can get access to such compute nodes. according
to the specifications of the benchmark, the evaluation of a single automl system requires
12,480 cpuh. hence, for estimating the computational resources of an entire study, the
amount of cpu hours can simply be multiplied by the number of considered automl
systems or baselines. fortunately, when using the same computing infrastructure as well
as the exact same experiment setup, there is no need to re-evaluate already benchmarked
automl systems, as the results should be comparable in principle.
however, it is important to note that all the different criteria need to be met exactly
in order to ensure comparability. in the literature (liu et al., 2019, 2018), results are
sometimes borrowed one-to-one from previous publications without accounting for changes
in the experiment setup based on which the newly proposed method is evaluated. while
this is certainly using as little energy as possible, the results are incomparable and valid
conclusions can hardly be drawn. obviously, the energy consumption is relatively low,
however, energy efficiency in turn is poor since the information obtained through investing
energy is not as valuable as desired. various benchmarks for automl systems have already
identified a plethora of confounding factors (balaji and allen, 2018; gijsbers et al., 2019;
wever et al., 2021; z¨oller and huber, 2021), which hinder interpretation of the results and
insights derived from them.
441
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
4.2 sustainability and democratizing research
beyond the properties of reproducibility and comparability, benchmarks can also serve an-
other interest, namely to make experiments more sustainable and to democratize research
on extremely computationally expensive problems. for example, several benchmarks have
already been presented in the automl sub-field of neural architecture search (nas), for
which all possible architectures within a certain search space have been evaluated once,
and the determined performances are stored in a lookup table (ying et al., 2019; dong and
yang, 2020; zela et al., 2020; klyuchnikov et al., 2022; li et al., 2021). when evaluating
new approaches for optimizing neural architectures, it is sufficient to look up the perfor-
mance of a solution candidate in that table instead of actually training and validating the
respective architecture. typically, the lookup tables of such benchmarks comprise the per-
formance values of roughly 50,000 different architectures. while the costs for creating such
a benchmark are obviously quite substantial, they represent a one-time investment. more-
over, since the evaluation of such a large number of architectures requires massive amounts
of computations with gpus, these benchmarks also enable researchers and practitioners,
who do not have access to such computational resources, to do research on nas.
as the number of possible architectures is quite limited in the aforementioned bench-
marks, siems et al. (2020) propose a surrogate model to predict the performance value of a
neural architecture. to this end, the surrogate model is trained on the performance values
of roughly 60,000 different architectures and is found to generalize these training exam-
ples quite well. using a surrogate model allows for more flexibility, as it can also provide
performance estimates for candidate solutions that have not been evaluated at all. hence,
benchmarks centered around such a surrogate model can be even more sustainable. how-
ever, these models need to be constructed with care to ensure that they do not mislead the
research on new methods. furthermore, in order to reach the level of quality of the surro-
gatemodel, siemsetal.(2020)needtocreateanextensiveamountoftrainingdata, namely,
60,000 architectures have been evaluated for this purpose. while this means an immense
amountofcomputation,itisagainaone-timecostthatamortizeswitheachsubsequenteval-
uation. when employing a surrogate model, however, additional constraints on how to use
the benchmark need to be imposed. more specifically, the benchmark specification requires
the surrogate model to be used in a query-only mode, i.e., any approach is only allowed
to request performance estimates for some neural architecture. consequently, it excludes
approaches exploiting the surrogate model, e.g., by analyzing its internal structure.
allinall, benchmarksarepowerfultoolstomakeresearchonautomlmoresustainable.
in particular, they can avoid repetitive evaluations of candidate solutions. this not only
helps to save energy but also enables institutions that cannot afford the necessary resources
to research on this topic. moreover, in general, research can also be accelerated, since
evaluations of candidate solutions require only milliseconds instead of minutes, hours, or
even days. consequently, the use of benchmarks should clearly be advocated and also
requested, since several advantages that benchmarks bring with them can be combined in
this way. however, within the community, care should also be taken to ensure that multiple
very similar or possibly even identical benchmarks are not developed in parallel, as this
would again unnecessarily drive up energy costs. ideally, the development of benchmarks
442
towards green automl: status quo and future directions
performance
runtime
figure 1: example figure of two performance curves, where the blue tool achieves a good
performance value (grey area) long before the orange one.
should be a community effort and thus be communicated at an early stage, as it was done
in the case of dacbench5, for example.
4.3 ecological performance profiles
when assessing the performance of an automl system, it is not sufficient to compare the
final performances after the complete run has passed. some automl approaches show
strong anytime performance while others may yield the best final performances. instead,
one should take a look at the performance curve of the system, i.e., what solution quality
can be expected after a certain amount of computational budget has been consumed. an
example of the ecological performance profiles of two competing automl systems can be
found in figure 1, where the blue tool achieves a good performance long before the orange
tool. ideally, we would look at an ecological performance profile that relates predictive per-
formance to the amount of co e emitted for computations. however, as already discussed
2
in section 2, it is more practical to investigate the cpu/gpu hours instead of the actual
environmental impact as a proxy of it. while we can assume for any reasonable automl
system that the performance profiles are monotonic, i.e., exhibiting better performances
with an increasing budget, the curves of the individual approaches may still cross each
other. the ecological performance profile of an automl system may depend on several
properties such as the runtime, the degree of parallelism, how well heterogeneous execution
environments can be utilized, etc. assuming the same hardware setting has been used for
all competitors, runtime can indeed be a good proxy. having access to such performance
profiles would allow the user to choose the automl system which is most suitable for their
budget and co e footprint. a single evaluation at a fixed point is not a sufficient basis for
2
such a decision. however, those performance profiles still depend on the hardware used for
assessing the performance of the approaches and deriving their profiles.
5. https://github.com/automl/dacbench
443
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
5. transparency
being transparent about the efficiency and environmental footprint is a key step towards
greenautomlandingeneralamoresustainableworld, whichwebelieveshouldbemanda-
torywhenpublishingapaper. theacceptanceofapaperisusuallybasedonitsnoveltyand
performance improvement, but the environmental footprint should also be considered. one
maywonderwhetherrejectingapaperwithstrongresultssolelyforreasonsofenvironmental
impactisunreasonable — afterall,thepollutioncannotbeundone,andpollutionwithpub-
lished results might be better than pollution without results. nevertheless, authors should
be incentivized to avoid environmental impact right from the beginning. accordingly, as a
first step, we advocate extending checklists recently introduced in major machine learning
conferences by the questions noted below. such checklists need to be filled out prior to
paper submission and are intended to help authors reflect on issues such as reproducibility,
transparency, research ethics, and societal impact. obviously, authors could also be asked
for the compute resources used for their paper, whether any measures have been taken to
quantify or reduce the consumption, etc.
oneaspectofbeingtransparentistoincludeinformationaboutthecompensationofthe
footprint, and in the best case, also about how it is compensated. if it is done via planting
trees, for example, those trees have to survive 10 years to compensate the footprint. this
might also create more awareness that it takes a long time until the consumed resources are
actually compensated, and therefore researchers might run experiments with more caution.
in addition, we as a community should strongly advocate the publication of failed at-
tempts and negative results in order to foster green automl or more general green science.
we all know cases, where despite a promising idea, a lot of work, and experiments, one
just could not get the idea to work as well as expected in practice and hence, it was never
published. thisisnotonlyunfortunatefromanenvironmentalbutalsofromascientificper-
spective. first, due to the rapidly growing scientific community (especially in ai), chances
are high that someone else might work or might have worked on the same idea at a distance
in time and potentially come to a similar conclusion. this work would not have been done
multiple times if the negative result was published. second, withholding negative results
can decelerate scientific progress as chances are high that even if one deems an idea fully
explored, someone else might have a good idea on how to turn a negative result into a
positive one by making the correct adjustment to the idea. especially, due to the large
amount of computational resources needed to perform research in the field of automl, it
is even more important to find a way to share failed attempts. a compiled list of journals
targeting negative results can be found online6.
5.1 sustainability checklist
apart from all aspects mentioned above, we believe that a key aspect towards green au-
toml is to be transparent about the environmental impact. accordingly, authors should
provide a summary of all the efforts made to make the automl design, development, and
evaluation more sustainable, as well as information about the environmental footprint of
their work, such that other people can take this information into account when deciding
6. https://www.enago.com/academy/top-10-journals-publish-negative-results/
444
towards green automl: status quo and future directions
which method to use. we propose to attach a sustainability checklist to each paper sub-
mitted, that includes the following aspects:
design, development and evaluation
(cid:3) what key aspects does your approach design include to be efficient? state
if and how your approach is built with efficiency in mind. for example: do you
use warmstarting? do you apply multi-fidelity evaluations? does it avoid timeout-
ing evaluations? is your approach aware of its environmental impact, like expected
improvement per kwh or per g/co e?
2
(cid:3) what steps did you consider during the development to reduce the foot-
print of the development process? state whether and how you attempted to
avoid wasting resources.
(cid:3) does the evaluation consider a metric related to environmental footprint?
state whether and how the evaluation does not only consider performance but also
other metrics, e.g., related to improvement per invested co e tons.
2
(cid:3) does the work yield an improvement over sota in terms of efficiency or
environmental impact? state whether and how the presented method improves
compared to the sota in terms of efficiency or environmental impact.
(cid:3) did you add your approach to an existing benchmark? state whether you
added your approach to an appropriate existing benchmark.
(cid:3) did you make the generated data publicly available? state whether you
created a publicly available repository of the data generated during the creation of
the work such as pipeline evaluations on datasets.
resource consumptions
(cid:3) what resources have you used for the final evaluation? state the type of
cpu/gpu hours and the kind of parallelization that has been used.
(cid:3) how many cpu/gpu hours have been used for the final evaluation? state
the amount of cpu hours that have been used for the evaluation presented in the
paper.
(cid:3) what is the used energy mix? state if and to what degree your experiments
were run using renewable energy. to this end, reaching out to your compute center
provider will most likely be necessary.
(cid:3) what is your footprint? state how many tons of co e you produced during the
2
creation of the paper.
(cid:3) did you compensate the carbon emissions? especially if non-renewable energy
has been used for the creation of your paper, state to what degree the corresponding
amountofcarbonemissionshavebeencompensated,e.g.,throughsupportingacarbon
offset project.
445
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
6. research incentives
in order to foster research on green automl, we believe that it is of great help to set
according research incentives.
a potential driver for advances in green automl are scientific challenges. those chal-
lenges often impose narrow and rigidly realized timeouts, which oblige approaches not only
toadheretothetimeoutsbutalsotobefast infindinggoodsolutions. forexample, theau-
toml challenge realized in 2015-2018 granted only 20 minutes of compute time to identify
a model (guyon et al., 2019). in some cases, datasets assumed sizes of several hundreds of
megabytes, in some cases over a gigabyte. in such situations it is impossible to conduct any
sort of “exhaustive” search, so very resource efficient approaches needed to be developed;
maybe even entirely abstaining from search in a classical sense. one immediate evidence
for the impact of challenges is the posh (feurer et al., 2018) approach, which combines
portfolios with successive halving to be successful in the previously mentioned challenge,
and which is the basis for auto-sklearn 2.0 (feurer et al., 2022). this challenge has been
continued for the problem of deep learning (el baz et al., 2021) and in its latest edition,
which is active at the time of writing, looks at the problem of few-shot deep learning.
since challenges at a time provide meaningful baselines, they are a valuable resource for
researchers in supporting the efficiency of their approaches and hence serve as catalysts for
efficient approaches in whole research fields.
moreover, funding agencies can advocate research on green automl, or more broadly,
green/sustainable ai, by a variety of means. for example, they can complement the pro-
posal evaluation criteria by considering both the potential environmental footprint and the
environmental benefits of a project (proposal). to this end, applicants need to include
this information in their proposals, of course. similarly, special programs can be initiated
especially targeted at sustainable and green ai. as a commendable example, the german
research foundation (dfg) has recently released a press release7 promoting their focus
on sustainability. to this end, they have set up a special committee (called the german
committeefutureearth)targetedatadvancinginterdisciplinaryresearchonsustainability.
furthermore, since the end of 2020, carbon emissions resulting from business trips as part
of dfg funded projects can be compensated for by buying according compensation certifi-
cates, which can be accounted as travel costs8. in fact, new proposals can even contain a
special category for co e compensation as part of the travel expenses category. unfortu-
2
nately, according to personal communication with the dfg, it is currently not possible to
budget money for co e compensation of experiments.
2
finally, journals and conferences can advocate special issues and special tracks focus-
ing on green automl, or, more broadly green/sustainable ai. similarly, special awards for
work on sustainability are tools to put a spotlight on noteworthy work, but also the topic
itself. as an example of such efforts, in 2013 the aaai offered a special track on compu-
tational sustainability and ai9. however, the track was mainly focused on applying ai for
sustainability in general and less on improving the sustainability of ai itself. remarkably,
in 2021 the first conference on sustainable ai10 was held in germany organized by prof.
7. https://www.dfg.de/en/service/press/press_releases/2020/press_release_no_38/index.html
8. https://www.dfg.de/en/service/press/press_releases/2020/press_release_no_59/index.html
9. https://www.aaai.org/conferences/aaai/2013/aaai13csaicall.php
10. https://www.sustainable-ai.eu/
446
towards green automl: status quo and future directions
dr. van wynsberghe from the university of bonn. the first automl conference11 held in
2022 featured parts of the checklist suggested by us in an earlier version of this manuscript
in their submission form.
7. discussion on trade-off between freedom of research and
environmental impact
so far, we have discussed why we believe that sustainability and, in particular, the environ-
mental footprint induced by (research on) automl is an important topic, which is already
addressed in some works, but should be focused on much more. however, an important
question is to what degree this should be done and to what extent this limits the potential
of the freedom of research. for example, questions of the following nature arise:
• how strong should incentives made by a conference or a funding agency be?
• what is considered a wasteful or too extensive evaluation in a paper?
• when is a certain improvement, e.g., in terms of performance or another measure,
worth the invested resources?
• what is a reasonable degree of transparency which authors should focus on for their
publications?
naturally, none of these questions is easy to answer due to the corresponding impli-
cations. in essence, we, as a community, are faced with a many-objective optimization
problem where two of the objectives are sustainability and freedom of research. on the
one hand, making any of the incentives for sustainability too strict and thus essentially
designing and enforcing rules, for example, on the side of the funding agencies, bears the
danger of limiting the freedom of research and therefore the potential progress of research
quite strongly. on the other hand, completely ignoring sustainability is also not an op-
tion considering the global climate crisis, which impacts everyone and thus should also be
addressed by everyone to a certain degree. in practice, the multi-objective problem actu-
ally has many more dimensions, such as social responsibility related aspects (cheng et al.,
2021), fair data principles (wilkinson et al., 2016), and others. as a consequence, the
community always has to strike a trade-off among all of these dimensions. naturally, such
a trade-off is hard to achieve and a rather continuous process, which is constantly shifting.
due to the complexity of the matter, we believe that there is no clear answer to the
questionsraisedinthissection, andevenmoreimportantly, itisnotclearwhoisresponsible
foransweringtheminparticular. nevertheless,webelievethateverymemberoftheresearch
community can strive to achieve a trade-off that they deem good in their research. the
most important thing is to stay open to new ideas and be aware of the different, perhaps
not so obvious, aspects of one’s research, such as sustainability or social responsibility.
8. prospects of automl
while we have so far focused on how to make automl approaches themselves or research
on automl greener, automl can in turn be used to make other systems or processes more
11. https://automl.cc/
447
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
sustainable as well (van wynsberghe, 2021; tu et al., 2022). first, manually configuring
machine learning algorithms is usually both time-consuming and inefficient. this is due
to the fact that human intuition is usually a good heuristic for manageable problems, but
rather unsuitable for traversing a high-dimensional space of possible candidate solutions,
which in turn leads to a lower solution quality (bergstra et al., 2011). automl can possi-
bly remedy this situation, since corresponding systems typically try to traverse the search
space as efficiently as possible, thereby also wasting less energy on uninformative candidate
evaluations.
second, automl gives a broader range of users access to ml technology, which in turn
can be used to optimize other processes or (technical) systems, e.g., production facilities.
for example, computationally complex simulations could be approximated by quick-to-
evaluate ml models, so-called surrogate models, thus saving the energy to calculate the
simulation (reiner et al., 2021). data-driven surrogate models (martins and ning, 2021)
can be obtained using automl, which can further improve the sustainability aspect of
surrogate models (bliek, 2022). in addition, other resources can be saved, such as spare
parts, when automl is used for predictive maintenance tasks (tornede et al., 2020b, 2021),
for instance. while the actual task in predictive maintenance is to schedule maintenance
cycles of plants more precisely so that the maintenance takes place as late as possible but
still without any unplanned downtime or a breakdown of the plant, resources in terms of
spare parts can also be saved. if parts of a plant are replaced too early, this not only costs
moneyunnecessarilybutalsonegativelyaffectstheeco-balance,sincethebottomlineisthat
more spare parts are needed over time and therefore also have to be produced. obviously,
this production again requires energy and raw materials. consequently, if automl enables
more companies to reduce the usage of spare parts, automl can be leveraged to not only
reduce the expenses of the company but also to save energy and physical resources.
similarly,automlcanalsobeusedtofindamodelthatpredictswhenrenewableenergy
willbereadilyavailableintheenergydistributiongrid(wangetal.,2019a),andhencewhen
energyextensiveoperationssuchasautomlbenchmarkingshouldpreferablybeperformed.
this does not only help in making benchmarking itself more environmentally friendly but
also in taking pressure off the distribution grid because too much energy in the distribution
grid is as much a problem as too few. overall, one can think of many such scenarios where
data-driven models, possibly produced by automl, can contribute to sustainability.
9. conclusion
in this paper, we proposed the idea of green automl, a paradigm to make automl more
efficient and environmentally friendly. we have shown varying ways to determine the car-
bon emissions produced, motivated different methods that can be integrated with automl
approaches to make the process more efficient, discussed existing methods as well as new
ideas, and elaborated on strategies to reduce the required resources of the benchmark. fur-
ther work on empirical studies about the environmental footprint of automl systems could
providefurtherinsightsintothistopic. onecouldbeastudyaboutthebehaviorofdifferent
automl systems with varying co e budget. furthermore, we suggested giving detailed
2
information about different aspects of the efficiency and environmental friendliness of the
approach at the end of each published automl paper. in particular, we think that the
448
towards green automl: status quo and future directions
environmental impact of a paper should be considered as a criterion in the review process.
on the other side, failed attempts and negative results should also be published to avoid
duplicated work on the same ideas. in general, appropriate research incentives can push
the research in the direction of green automl due to special issues and special tracks of
journals and conferences. furthermore, the funding agencies should force the researchers
to work in the direction of green automl through corresponding calls for projects or ac-
ceptance criteria for projects, and allow also co e compensation for experimental analysis.
2
additionally, one could question if it is reasonable to publish a paper at a conference hosted
ontheothersideoftheworldifanon-sitepresentationandthus,alongandco eexpensive
2
flight is required. regardless of the aforementioned aspects, it is the community that has
to take action, sooner rather than later.
acknowledgments
this work was partially supported by the german federal ministry of education and re-
search (its.ml project no. 01is18041d) and the german research foundation (dfg)
within the collaborative research center “on-the-fly computing” (sfb 901/3 project
no. 160364472).
we also thank the coseal community for their feedback on a poster based on this
work at the coseal workshop in 2021 and the automl fall school 2021 organizers for
the opportunity to highlight the topic of green automl at the panel discussion. moreover,
we would like to thank the panelists for their remarks and ideas on the topic, which have
been incorporated into this work.
lastly, we thank the anonymous reviewers for their feedback and pointers to interesting
related areas of research and papers, which helped to make this a better paper.
references
ans´otegui, c., sellmann, m., and tierney, k. (2009). a gender-based genetic algorithm for
the automatic configuration of algorithms. in proceedings of 15th international confer-
ence on principles and practice of constraint programming (cp’09).
anthony, l. w., kanding, b., and selvan, r. (2020). carbontracker: tracking and predict-
ing the carbon footprint of training deep learning models. arxiv/2007.03051.
awad, n., mallik, n., and hutter, f. (2021). dehb: evolutionary hyberband for scalable,
robustandefficienthyperparameteroptimization. inproceedingsofthe13thinternational
joint conference on artificial intelligence (ijcai’21).
balaji, a. and allen, a. (2018). benchmarking automatic machine learning frameworks.
arxiv/1808.06492.
bardenet, r., brendel, m., k´egl, b., and sebag, m. (2013). collaborative hyperparam-
eter tuning. in proceedings of the 30th international conference on machine learning
(icml’13).
449
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
bender, e., gebru, t., mcmillan-major, a., and shmitchell, s. (2021). on the dangers of
stochastic parrots: can language models be too big? in proceedings of the 4th acm
conference on fairness, accountability, and transparency (acm facct’21).
bergstra,j.,bardenet,r.,bengio,y.,andk´egl,b.(2011). algorithmsforhyper-parameter
optimization. in proceedings of the 25th conference on neural information processing
systems (neurips’11).
bliek, l. (2022). a survey on sustainable surrogate-based optimisation. sustainability.
calero, c., bertoa, m., and moraga, m. a´. (2013). a systematic literature review for
software sustainability measures. in greens 2013: 2nd international workshop on
green and sustainable software.
calero, c., mancebo, j., garc´ıa, f., moraga, m. a´., bern´a, j., fern´andez-alem´an, j.,
and toval, a. (2019). 5ws of green and sustainable software. tsinghua science and
technology.
candelieri, a., perego, r., and archetti, f. (2021). green machine learning via augmented
gaussian processes and multi-information source optimization. soft computing.
candelieri, a., ponti, a., and archetti, f. (2022). fair and green hyperparameter op-
timization via multi-objective and multiple information source bayesian optimization.
arxiv/2205.08835.
cao, q., lal, y., trivedi, h., balasubramanian, a., and balasubramanian, n. (2021).
irene: interpretableenergypredictionfortransformers. inproceedingsofthe59thannual
meetingoftheassociationforcomputationallinguisticsandthe11thinternationaljoint
conference on natural language processing, (acl/ijcnlp’21).
cheng, l., varshney, k., and liu, h. (2021). socially responsible ai algorithms: issues,
purposes, and challenges. journal of artificial intelligence research (jair’21).
domhan, t., springenberg, j., and hutter, f. (2015). speeding up automatic hyperparam-
eter optimization of deep neural networks by extrapolation of learning curves. in pro-
ceedings of the 24th international joint conference on artificial intelligence (ijcai’15).
dong, x. and yang, y. (2020). nas-bench-201: extending the scope of reproducible
neuralarchitecturesearch. inproceedingsofthe8thinternationalconferenceonlearning
representations, (iclr’20).
drori, i., liu, l., nian, y., koorathota, s., li, j., moretti, a. k., freire, j., and udell, m.
(2019). automl using metadata language embeddings. arxiv/1910.03698.
eggensperger, k., haase, k., mu¨ller, p., lindauer, m., and hutter, f. (2020). neural
model-based optimization with right-censored observations. arxiv/2009.13828.
elbaz, a., guyon, i., liu, z., vanrijn, j., treguer, s., andvanschoren, j.(2021). metadl
challengedesignandbaselineresults. inaaai: workshop on meta-learning and metadl
challenge.
450
towards green automl: status quo and future directions
elsken, t., metzen, j., and hutter, f. (2019a). efficient multi-objective neural architecture
search via lamarckian evolution. in proceedings of the 7th international conference on
learning representations (iclr’19).
elsken, t., metzen, j., and hutter, f. (2019b). neural architecture search: a survey.
journal of machine learning research (jmlr’19).
falkner, s., klein, a., and hutter, f. (2018). bohb: robust and efficient hyperparameter
optimization at scale. in proceedings of the 35th international conference on machine
learning (icml’18).
feurer, m., eggensperger, k., falkner, s., lindauer, m., and hutter, f. (2018). practical
automated machine learning for the automl challenge 2018. in icml: international
workshop on automatic machine learning.
feurer, m., eggensperger, k., falkner, s., lindauer, m., and hutter, f. (2022). auto-
sklearn 2.0: hands-free automl via meta-learning. journal of machine learning re-
search (jmlr’22).
feurer, m., klein, a., eggensperger, k., springenberg, j., blum, m., andhutter, f.(2015).
efficient and robust automated machine learning. in proceedings of the 28th conference
on neural information processing systems (neurips’15).
fusi, n., sheth, r., and elibol, m. (2018). probabilistic matrix factorization for automated
machinelearning.inproceedingsofthe31thconferenceonneuralinformationprocessing
systems (neurips’18).
garc´ıa-mart´ın, e., rodrigues, c., riley, g., and grahn, h. (2019). estimation of energy
consumption in machine learning. journal of parallel and distributed computing.
gendreau, m. (2003). an introduction to tabu search. international series in operations
research & management science. springer.
gijsbers, p., ledell, e., thomas, j., poirier, s., bischl, b., and vanschoren, j. (2019). an
open source automl benchmark. arxiv/1907.00909.
guyon, i., sun-hosoya, l., boull´e, m., escalante, h., escalera, s., liu, z., jajetic, d., ray,
b., saeed, m., sebag, m., statnikov, a., tu, w., and viegas, e. (2019). analysis of the
automl challenge series 2015-2018, pages 177–219. springer series on challenges in
machine learning. springer.
he, y., lin, j., liu, z., wang, h., li, l., and han, s. (2018). amc: automl for model
compression and acceleration on mobile devices. in proceedings of the 15th european
conference on computer vision (eccv’18).
huang,l.,jia,j.,yu,b.,chun,b.,maniatis,p.,andnaik,m.(2010). predictingexecution
timeofcomputerprogramsusingsparsepolynomialregression. inproceedings of the 24th
conference on neural information processing systems (neurips’10).
451
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
hutter, f., hoos, h., and leyton-brown, k. (2011). sequential model-based optimization
for general algorithm configuration. in proceedings of the 5th international conference
on learning and intelligent optimization (lion’11).
hutter, f., hoos, h., leyton-brown, k., and stu¨tzle, t. (2009). paramils: an automatic
algorithmconfigurationframework. journal of artificial intelligence research (jair’09).
hutter, f., kotthoff, l., and vanschoren, j., editors (2019). automated machine learning:
methods, systems, challenges. springer.
hutter, f., xu, l., hoos, h., and leyton-brown, k. (2014). algorithm runtime prediction:
methods & evaluation. artificial intelligence (aij’14).
jamieson, k. and talwalkar, a. (2016). non-stochastic best arm identification and hyper-
parameteroptimization. inproceedings of the 19th international conference on artificial
intelligence and statistics (aistats’16).
kandasamy, k., dasarathy, g., schneider, j., andp´oczos, b.(2017). multi-fidelitybayesian
optimisation with continuous approximations. in proceedings of the 34th international
conference on machine learning (icml’17).
klein, a., falkner, s., bartels, s., hennig, p., and hutter, f. (2017). fast bayesian opti-
mization of machine learning hyperparameters on large datasets. in proceedings of the
20th international conference on artificial intelligence and statistics (aistats’17).
klyuchnikov, n., trofimov, i., artemova, e., salnikov, m., fedorov, m., filippov, a., and
burnaev, e. (2022). nas-bench-nlp: neural architecture search benchmark for natural
language processing. ieee access.
komer, b., bergstra, j., and eliasmith, c. (2014). hyperopt-sklearn: automatic hyperpa-
rameter configuration for scikit-learn. in icml: workshop on automl.
lacoste, a., luccioni, a., schmidt, v., and dandres, t. (2019). quantifying the carbon
emissions of machine learning. arxiv/1910.09700.
lago, p., koc¸ak, s., crnkovic, i., and penzenstadler, b. (2015). framing sustainability as
a property of software quality. communications of the acm.
lake, b., salakhutdinov, r., gross, j., and tenenbaum, j. (2011). one shot learning of
simplevisualconcepts. inproceedingsofthe33thannualmeetingofthecognitivescience
society (cogsci’11).
lannelongue, l., grealey, j., and inouye, m. (2021). green algorithms: quantifying the
carbon footprint of computation. advanced science.
li, c., yu, z., fu, y., zhang, y., zhao, y., you, h., yu, q., wang, y., hao, c., and lin,
y. (2021). hw-nas-bench: hardware-aware neural architecture search benchmark. in
proceedings of the 9th international conference on learning representations (iclr’21).
452
towards green automl: status quo and future directions
li, l., jamieson, k., desalvo, g., rostamizadeh, a., andtalwalkar, a.(2017). hyperband:
a novel bandit-based approach to hyperparameter optimization. journal of machine
learning research (jmlr’17).
lin, m., wang, p., sun, z., chen, h., sun, x., qian, q., li, h., and jin, r. (2021). zen-
nas: a zero-shot nas for high-performance deep image recognition. arxiv/2102.01063.
lindauer, m. and hutter, f. (2018). warmstarting of model-based algorithm configuration.
in proceedings of the 32th conference on artificial intelligence, (aaai’18).
liu, c., zoph, b., neumann, m., shlens, j., hua, w., li, l., fei-fei, l., yuille, a., huang,
j., and murphy, k. (2018). progressive neural architecture search. in proceedings of the
15th european conference on computer vision (eccv’18).
liu, h., simonyan, k., and yang, y. (2019). darts: differentiable architecture search. in
proceedings of the 7th international conference on learning representations (iclr’19).
makarova, a., shen, h., perrone, v., klein, a., faddoul, j., krause, a., seeger, m., and
archambeau, c. (2022). automatic termination for hyperparameter optimization. in
proceedings of the 1st conference on automated machine learning (automl’22).
martins, j. and ning, a. (2021). engineering design optimization. cambridge university
press.
mellor, j., turner, j., storkey, a., and crowley, e. (2021). neural architecture search with-
out training. in proceedings of the 38th international conference on machine learning
(icml’21).
mohr, f. and van rijn, j. (2021). towards model selection using learning curve cross-
validation. in icml: workshop on automated machine learning.
mohr, f., wever, m., and hu¨llermeier, e. (2018). ml-plan: automated machine learning
via hierarchical planning. machine learning (mlj’18).
mohr, f., wever, m., tornede, a., and hu¨llermeier, e. (2021). predicting machine learning
pipeline runtimes in the context of automated machine learning. ieee transactions on
pattern analysis and machine intelligence (tpami’21).
nguyen, p., kalousis, a., and hilario, m. (2011). a meta-mining infrastructure to
support kd workflow optimization. in proceedings of the european conference on
machine learning and principles and practice of knowledge discovery in databases
(ecml/pkdd’11).
parcollet, t. and ravanelli, m. (2021). the energy and carbon footprint of training end-to-
endspeechrecognizers. inproceedings of the 22ndannual conference of the international
speech communication association (interspeech’21).
patterson, d., gonzalez, j., h¨olzle, u., le, q., liang, c., munguia, l., rothchild, d., so,
d., texier, m., and dean, j. (2022). the carbon footprint of machine learning training
will plateau, then shrink. computer.
453
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
patterson, d., gonzalez, j., le, q., liang, c., munguia, l., rothchild, d., so, d., tex-
ier, m., and dean, j. (2021). carbon emissions and large neural network training.
arxiv/2104.10350.
perrone, v., jenatton, r., seeger, m., and archambeau, c. (2017). multiple adap-
tive bayesian linear regression for scalable bayesian optimization with warm start.
arxiv/1712.02902.
petrak, j. (2000). fast subsampling performance estimates for classification algorithm
selection. in ecml: workshop on meta-learning: building automatic advice strategies
for model selection and method combination.
pfisterer, f., coors, s., thomas, j., and bischl, b. (2019). multi-objective automatic
machine learning with autoxgboostmc. arxiv/1908.10796.
prechelt, l. (2012). early stopping - but when? in neural networks: tricks of the trade -
second edition. springer.
real, e., aggarwal, a., huang, y., and le, q. (2019). regularized evolution for image clas-
sifier architecture search. in proceedings of the 33rd conference on artificial intelligence
(aaai’19).
reiner, j., vaziri, r., and zobeiry, n. (2021). machine learning assisted characterisation
and simulation of compressive damage in composite laminates. composite structures.
rivolli, a., garcia, l., soares, c., vanschoren, j., and de carvalho, a. (2018). characteriz-
ingclassificationdatasets: astudyofmeta-featuresformeta-learning. arxiv/1808.10406.
samo, y. (2021). leanml: a design pattern to slash avoidable wastes in machine learning
projects. arxiv/2107.08066.
schmidt, v., goyal, k., joshi, a., feld, b., conell, l., laskaris, n., blank, d., wilson, j.,
friedler, s., and luccioni, s. (2021). codecarbon: estimate and track carbon emissions
from machine learning computing. arxiv/2007.04074.
schmucker, r., donini, m., zafar, m., salinas, c., and archambeau, c. (2021). multi-
objective asynchronous successive halving. arxiv/2106.12639.
schwartz, r., dodge, j., smith, n., and etzioni, o. (2019). green ai. arxiv/1907.10597.
shaikh, o., saad-falcon, j., wright, a., das, n., freitas, s., asensio, o., and chau, d.
(2021). energyvis: interactively tracking and exploring energy consumption for ml
models. in proceedings of the conference on human factors in computing systems
(chi’21).
siems, j., zimmer, l., zela, a., lukasik, j., keuper, m., and hutter, f. (2020).
nas-bench-301 and the case for surrogate benchmarks for neural architecture search.
arxiv/2008.09777.
singh, n., kates, b., mentch, j., kharkar, a., udell, m., and drori, i. (2021). privileged
zero-shot automl. arxiv/2106.13743.
454
towards green automl: status quo and future directions
smith-miles, k. and van hemert, j. (2011). discovering the suitability of optimisation
algorithms by learning from evolved instances. annals of mathematics and artificial
intelligence.
snoek, j., larochelle, h., and adams, r. (2012). practical bayesian optimization of ma-
chine learning algorithms. in proceedings of the 26th conference on neural information
processing systems (neurips’12).
stamoulis, d., cai, e., juan, d., and marculescu, d. (2018a). hyperpower: power and
memory constrained hyperparameter optimization for neural networks. in proceedings of
the conference on design, automation and test in europe (date’18).
stamoulis, d., chin, t., prakash, a., fang, h., sajja, s., bognar, m., and marculescu, d.
(2018b). designing adaptive neural networks for energy-constrained image classification.
in proceedings of the international conference on computer-aided design (iccad’18).
swersky, k., snoek, j., and adams, r. (2013). multi-task bayesian optimization. in pro-
ceedings of the 27th conference on neural information processing systems (neurips’13).
swersky, k., snoek, j., and adams, r. (2014). freeze-thaw bayesian optimization.
arxiv/1406.3896.
thornton,c.,hutter,r.,hoos,h.,andleyton-brown,k.(2013). auto-weka:combined
selection and hyperparameter optimization of classification algorithms. in proceedings
of the 19th acm international conference on knowledge discovery and data mining,
(kdd’13).
tornede, a., wever, m., werner, s., mohr, f., and hu¨llermeier, e. (2020a). run2survive:
a decision-theoretic approach to algorithm selection based on survival analysis. in pro-
ceedings of the 12th asian conference on machine learning, (acml’20).
tornede, t., tornede, a., wever, m., and hu¨llermeier, e. (2021). coevolution of remaining
useful lifetime estimation pipelines for automated predictive maintenance. in proceedings
of the genetic and evolutionary computation conference (gecco’21).
tornede, t., tornede, a., wever, m., mohr, f., and hu¨llermeier, e. (2020b). automl
for predictive maintenance: one tool to rul them all. in ecml/pkdd: workshop
on iot streams for data-driven predictive maintenance and iot, edge, and mobile for
embedded machine learning.
torrey, l. and shavlik, j. (2010). transfer learning. in handbook of research on machine
learning applications and trends: algorithms, methods, and techniques. igi global.
tu, r., roberts, n., prasad, v., nayak, s., jain, p., sala, f., ramakrishnan, g., talwalkar,
a., neiswanger, w., and white, c. (2022). automl for climate change: a call to action.
in neurips: workshop on tackling climate change with machine learning.
van wynsberghe, a. (2021). sustainable ai: ai for sustainability and the sustainability of
ai. ai ethics.
455
tornede, tornede, hanselle, wever, mohr, & hu¨llermeier
vanschoren, j. (2018). meta-learning: a survey. arxiv/1810.03548.
vanschoren, j., van rijn, j., bischl, b., and torgo, l. (2013). openml: networked science
in machine learning. sigkdd explorations.
wang, c., b¨ack, t., hoos, h., baratchi, m., limmer, s., and olhofer, m. (2019a). au-
tomated machine learning for short-term electric load forecasting. in proceedings of the
ieee symposium series on computational intelligence (ssci’19).
wang, d., li, m., wu, l., chandra, v., and liu, q. (2019b). energy-aware neural archi-
tecture optimization with fast splitting steepest descent. arxiv/1910.03103.
wang, y., yao, q., kwok, j., and ni, l. (2020). generalizing from a few examples: a
survey on few-shot learning. acm computing surveys.
wever, m., tornede, a., mohr, f., andhu¨llermeier, e.(2021). automlformulti-labelclas-
sification: overview and empirical evaluation. ieee transactions on pattern analysis
and machine intelligence (tpami’21).
wilkinson, m., dumontier, m., aalbersberg, i., appleton, g., axton, m., baak, a.,
blomberg, n., boiten, j., da silva santos, l., bourne, p., bouwman, j., brookes, a.,
clark, t., crosas, m., dillo, i., dumon, o., edmunds, s., evelo, c., finkers, r.,
gonzalez-beltran, a., gray, a., groth, p., goble, c., grethe, j., heringa, j., ’t hoen,
p., hooft, r., kuhn, t., kok, r., kok, j., lusher, s., martone, m., mons, a., packer,
a., persson, b., rocca-serra, p., roos, m., van schaik, r., sansone, s., schultes, e.,
sengstag, t., slater, t., strawn, g., swertz, m., thompson, m., van der lei, j., van
mulligen, e., velterop, j., waagmeester, a., wittenburg, p., wolstencroft, k., zhao, j.,
and mons, b. (2016). the fair guiding principles for scientific data management and
stewardship. scientific data.
wu, j., toscano-palmerin, s., frazier, p., and wilson, a. (2019). practical multi-fidelity
bayesian optimization for hyperparameter tuning. in proceedings of the 35th conference
on uncertainty in artificial intelligence (uai’19).
xian, y., schiele, b., and akata, z. (2017). zero-shot learning - the good, the bad and the
ugly. inproceedingsoftheieeeconferenceoncomputervisionandpatternrecognition
(cvpr’17).
yang, c., akimoto, y., kim, d., and udell, m. (2019). oboe: collaborative filtering for
automl model selection. in proceedings of the 25th acm international conference on
knowledge discovery and data mining, (kdd’19).
ying, c., klein, a., christiansen, e., real, e., murphy, k., and hutter, f. (2019). nas-
bench-101: towards reproducible neural architecture search. in proceedings of the 36th
international conference on machine learning (icml’19).
yogatama, d. and mann, g. (2014). efficient transfer learning method for automatic
hyperparameter tuning. in proceedings of the 17th international conference on artificial
intelligence and statistics (aistats’14).
456
towards green automl: status quo and future directions
zela, a., siems, j., and hutter, f. (2020). nas-bench-1shot1: benchmarking and dissect-
ingone-shotneuralarchitecturesearch. inproceedingsofthe8thinternationalconference
on learning representations (iclr’20).
zimmer, l., lindauer, m., and hutter, f. (2021). auto-pytorch: multi-fidelity meta learn-
ingforefficientandrobustautodl. ieeetransactionsonpatternanalysisandmachine
intelligence (tpami’21).
z¨oller, m. and huber, m. (2021). benchmark and survey of automated machine learning
frameworks. journal of artificial intelligence research (jair’21).
zoph, b. and le, q. (2017). neural architecture search with reinforcement learning. in
proceedings of the 5th international conference on learning representations (iclr’17).
457"
7,__a smart framework for supplying the biogas energy in green buildings using an integration of response surface methodology_ artificial intelligence and petri net__.pdf,"
1 constructing a novel smart framework for supplying biogas energy in green
2 buildings using an integration of response surface methodology, artificial
3 intelligence and petri net modelling
4 mohammad m. shahsavar1, mehran akrami2, mohammad gheibi2,3, babak
5 kavianpour3,4, kourosh behzadian5, amir m. fathollahi-fard6*
6 1department of civil engineering, sajad university of technology, mashhad, iran
7 2 department of civil engineering, ferdowsi university of mashhad, mashhad, iran
8 3 zistpardazesharia knowledge based company, mashhad, iran
9 4 department of chemical engineering, school of chemical and petroleum engineering, shiraz
10 university, shiraz, iran
11 5department of civil engineering, university of west london, london, uk
12 6department of electrical engineering, école de technologie supérieure, university of québec,
13 montréal, canada
14
15 abstract
16 nowadays energy crisis is considered an essential active issue for future urbanization in
17 megacities. while the rate of population growth increases, the volume of municipal solid waste
18 production increases significantly. this highlights the need of sustainable development goals
19 (sdgs) for both developed and developing countries. this paper introduces a novel smart
20 framework for supplying biogas energy to study waste management and energy supply in green
21 buildings. this framework integrates the response surface methodology (rsm), artificial
22 intelligence (ai), and petri net modeling. firstly, the particular biogas generation setup is invented
23 for food waste digestion by integrating sequencing batch reactors (sbr) sludge and clostridial
24 microorganisms. before experimental practices, for evaluation of waste characterizations, the
25 quartering and coning method is utilized. in the experimental practices, different variables
26 including sludge/waste, inoculum (clostridiales/waste), ph, temperature and, time, are
27 appraised in the lab-scale setup. also, in the experimental section for measuring the variables
28 through biogas production procedure, three protocols containing epa-821-r-01-015, organic
29 matter and alkalinity evaluation by american public health association (apha, 2017) and
30 einhorn saccharometer technique are utilized. the optimum conditions are appraised based on
31 central composition design (ccd) using rsm. artificial intelligence techniques including the
32 random tree (rt), random forest (rf), artificial neural network (ann) and, adaptive-
33 network-based fuzzy inference system (anfis) are employed. plus, for creating the optimum
34 condition, a dynamic controlling system petri net modeling is used.
35 the outcomes of present investigation have illustrated that the optimum conditions for sludge/food
36 waste (s/w), clostridiales/ food waste (c/w), ph, temperature (t) and retention time (t) as
37 effective parameters are equal to 163 mg/g, 54 mg/g, 7, 30 °c and 55 days, respectively. likewise,
38 the analysis of variance (anova) assessment demonstrated that the most effective parameters
39 are s/w and t with high amount of f-value and low amount of p-value. plus, between all machine
40 learning methods, anfis with 0.99 correlation coefficient had the best accuracy for accumulated
41 biogas production (abp) based on effective factors.
42 sludge and clostridial based bio-engine are compared with together asper biogas/methane
43 generation and fluctuation of total organic carbon (toc), chemical oxygen demand (cod)
44 and total alkaline are appraised. the outcomes have demonstrated that efficiency of sludge-based
45 system is two times more than clostridial based reactors, because of available nutrient and active
46 microorganisms. finally, circular economy (ce) scrutinizing have proved that with application
47 of this method in a green building, all electrical energy/heat demands can be supplied by 381 kwh
48 (3051 mj) in the case study (in one residential unit). also, the remained digested food waste with
49 310 mg/l cod is valuable for gardening activities in green buildings.
50 finally, with the outcomes of present study, some different scientific issues such as clean energy
51 supplying in green buildings, smart sustainable biogas production control system, integrated solid
52 waste management (iswm), ce and sdgs in green buildings are tackled as a novel framework
53 in smart and sustainable cities.
54 keywords: biogas, food waste, sludge, clostridial microorganisms, response surface
55 methodology, artificial intelligence, petri net modelling;
56 1. introduction
57 one of the main concerns in green building concepts (gbc) [1], sustainable development goals
58 (sdgs) [2] and clean technologies theory (ctt) [3] is related to stable energy supplying in
59 short, middle and long terms [4]. when energy demand is increased in different megacities of
60 developing countries based on population accumulation [5], consumerism [6], cultural diversion
61 [7] and global warming effects [8] which is continued every year. plus, waste generation,
62 especially biological wastes in developing countries, is augmented as per life style changing [9]
63 and developing urbanization in some countries such as iran [10], india [11] and china [12]. energy
64 crisis and biological waste generation problem are noteworthy challenges when they are seen
65 separately, but, in a holistic view of gbc, they can be considered as an opportunity for biogas
66 production for implementation of ctt in future lifestyle of developing countries [13].
67 biogas generation from biological wastes is assumed as a green method for integrated solid waste
68 management (iswm) during anaerobic digestion in household reactors [14, 15]. the scheme of
69 circular economy (ce) in biogas generation from biological waste and biochemical reaction are
70 illustrated in figs. 1 [16-18] and 2 [19-21], respectively. according to fig. 1, with ce approach
71 the threats of waste generation can be converted to opportunities for energy demand crisis and
72 fertilizer providing in green building’s plants from digested wastes [22]. whereas, as per fig. 2, it
73 is clear that biogas generation is done in four stages containing hydrolysis, acidogenesis,
74 acetogenesis, and methanogenesis [23].
75
76
77 fig. 1. the schematic plan of biogas generation cycle [16-18].
78
79 fig. 2. the schematic plan of biochemical reactions [19-21].
80
81 cavaignac et al. (2021) have presented a novel concept for operation of biogas reactors with
82 considering technical, economic and environmental aspects. in the mentioned study, main issue
83 was related to amine scrubbing role in biogas generation enhancing. plus, by application of life
84 cycle assessment (lca) method, emission of co was predicted with high accuracy [24]. also,
2
85 miranda et al. (2021) have evaluated green technologies for energy supplying in some countries
86 including brazil, russia, india, china, and south africa (brics). for the mentioned goal,
87 methodi ordinatio methodology with concentration on sustainability indices was used [25]. plus,
88 niu et al. (2021) have designed a biogas system for rural usages energy providing in china. in this
89 study, environmental and social benefits have been scrutinized by monetization method. likewise,
90 the performance of partially competitive strategy is discussed for medium- and large-scale biogas
91 projects (mlbps) [26]. abanades et al. (2021) have presented a framework for biogas generation
92 in the globe based on critical review concept [27]. lomazov et al. (2021) have optimized biogas
93 energy production plants with application of fuzzy and genetic algorithm techniques [28]. stürmer
94 et al. (2021) have compared the biogas production based on agricultural wastes in different regions.
95 the declared research has assessed legal framework and regional structures on biogas production
96 [29]. jung et al. (2021) and akbulut et al. (2021) have designed local biogas system in large-scale
97 with considering syngas system energy supplying and energy planning in malatya, respectively
98 [30, 31]. brémond et al. (2021) have presented a novel framework for improvements of solid
99 digestion process in continuously stirred tank reactors (cstrs) with agricultural waste feeding.
100 in the declared study, some different strategies are assessed for enhancing the efficiency of biogas
101 production [32]. naquash et al. (2021) have presented some outcomes for production of liquefied
102 natural gas through solidification of co through biogas procedure. likewise, in the mentioned
2
103 investigation, all simulations are done in aspen hysys® v11 platform [33]. moreover, zhang et
104 al. (2021) have designed food-waste-to-energy system as decentralized energy supplying
105 approach. the researchers have concentrated on organic matter loading and temperature effects on
106 biogas production efficiency. also, with application of sankey diagram in energy flow, the
107 performance of anaerobic digestion and combined heat and power (chp) are scrutinized [34].
108 wu et al. (2021) have scheduled the biogas-solar-wind as integrated energy systems (iess) in a
109 case study. in the mentioned study, for programming energy usages multi-objective optimization
110 (moo) are utilized [35]. su et al. (2021) have presented a novel system for thermal collecting of
111 bio-methane production with application of photovoltaic facilities. in the avowed research,
112 reducing the fossil fuel consumption are proposed as cost function [36].
113 as the reviewed investigations, application of artificial intelligence (ai) and response surface
114 methodology (rsm) for biogas generation in green building energy supplying is so rare as a
115 research gap and this research wants to present a novel smart model for bio-energy contributing.
116 the present study aims to:
117 - inventing biogas setup for household energy applications based on biological wastes in
118 green buildings with combination of clostridiales, wastewater treatment plant’s sludge and
119 food wastes digesting activities.
120 - optimizing the effective parameters on biogas production in green buildings by central
121 composition design (ccd)-rsm technique.
122 - creating smart controlling model for operating system by random tree (rt), random
123 forest (rf), artificial neural network (ann) and adaptive-network-based fuzzy
124 inference system (anfis) soft computations.
125 - presenting controlling model in green buildings as per petri net system.
126 in the present study, with application of ccd-rsm technique, the optimum conditions are
127 determined and likewise, the number of experimental runs are reduced. on the other words, by
128 ccd-rsm method plus enhancing the performance of biogas production process, the
129 experimental costs are decreased. in the followings, the ai computations evaluate the behavior
130 of bio-system performance for controlling possible reactor's problems in the especial situations
131 with prediction the future manners. finally, with comparison of the outcomes of ai and ccd-
132 rsm, the effective method for controlling and prediction of biogas production are suggested
133 as the scientific fact.
134 the rest of this paper is organized as follows: section 2 provides the materials and methods
135 including the framework of this research, used materials, instrumentation, lab-scale setup,
136 microbiological methods, optimization, prediction and controlling models. section 3 presents
137 the test results and provides the discussion on the results. finally, a summary of this research
138 with findings and recommendations, is concluded in section 4.
139
140 2. materials and methods
141 2.1.case study
142 the present research is done in a residential complex with fifteen household units which is
143 illustrated as per fig. 3. also, monthly electrical demand (fig. 4) of each unit is demonstrated in
144 fig. 4 according to pvsystem simulations software [37]. plus, approximate analysis of food wastes
145 which is appraised based on quartering and coning method [38] is summarized in table 1.
146
147 fig. 3. location of mashhad, iran.
148
350
300
)hwk(
250
dnamed
200
150
ygrene
100
50
0
jan feb mar apr may jun jul aug sep oct nov des
month
149
150 fig. 4. the pattern of electrical energy consumption in the case study in mashhad, iran.
151
152
153
154
155
156 table 1. approximate specification of residential wastes as per quartering and coning method in
157 present research.
waste type percentage moisture (%)
paper 21 8
glass 9 2
food waste 40 82
plastic waste 27 12
cloth waste 3 15
158
159 2.2.research roadmap
160 in this study, research roadmap is divided to four sections such as experimental efforts,
161 optimization and statistical evaluations, predictive models and controlling algorithm as a
162 decision support system (dss) which are demonstrated in fig. 5.
163 according to fig. 5, in the first step, the energy demands of the case study is computed by
164 simulation and application of some different data banks. by applying this section, the value of
165 energy demand is determined in different months. then, with quartering and coning method,
166 the quality and quantity of available solid wastes are measured as the first section of second
167 stage. plus, in the second section the lab scale setup is designed and built and then in the last
168 section of this stage, the experimental efforts are started. for design of experiments, ccd-
169 rsm method is employed as sensitive analysis, optimization and regression prediction
170 equations. after, optimizing the mentioned experiments by ccd-rsm, the suggested
171 optimum conditions are compared by real test’s amounts until reaching to desirable precision.
172 if the ccd-rsm values are not fit to real experiments, the ccd-rsm should be redesigned.
173 in the next stage, by the ccd-rsm outcomes, petri net modelling are done for creating the
174 concept of smart operation system of biogas generation process with focusing on approved
175 optimum conditions. in the fifth stage of present research, the rf, rt, ann and anfis
176 computations are utilized for smart forecasting microorganism’s behavior through the biogas
177 production procedure. finally, after assessment of biogas energy supplying performance in this
178 study, a conceptual model is designed for implementation of sdgs. ce and iswm in the
179 research.
180
181
182 fig. 5. the research roadmap of present study (ccd-rsm: central composition design-response surface
183 methodology, ai: artificial intelligence, rt: random tree, rf: random forest, ann: artificial neural network
184 and anfis: adaptive-network-based fuzzy inference system, ce: circular economy, sdgs: sustainable
185 development goals and iswm: integrated solid waste management)
186 2.3.materials and instrumentation
187 all reagents and materials for experimental practices and sampling are shown in table 2.
188 likewise, sampling is done three times with quartering and coning method, initial and final
189 gas generation tests. whereas, all applied instruments are utilized for sampling, gas
190 measurement and effective parameters determinations are mentioned in table 3.
191 table 2. crucial materials and regents for present study.
compounds conditions company
molecular weight is
naoh equal to sigma aldrich, usa
40 gr mol-1
this sludge have
been provided from
from al-teymour
secondary sludge sedimentation as an secondary clarifier
wastewater treatment plant
inoculum tank in sequencing
in mashhad city
batch reactor
(sbr)
silicon,
nanopowder, <100
nm particle size
silicone glue (tem), ≥98% trace sigma aldrich, usa
metals basis with
28.09 gr mol-1
molecular weight
nitrogen, ≥
99.998% with 28.01
n gas sigma aldrich, usa
2
gr mol-1 molecular
weight
70% purity and with
hno 63.01 gr mol-1 sigma aldrich, usa
3
molecular weight
it is obtained after from case study in
mixed food waste
one day mashhad city
clostridiales liquid sample iranian genetic bank (igb)
192 table 3. functional equipment in present study.
instrument conditions/model/description company
vwr® international
vacuum flask with glass hose connector
co.
suction capacity
vacuum pump ppi pumps co.
550 to 15000 m3 h-1
borosil technologies
lab scale storage borosilicate glass
co.
high pressure and temperature
one-liter glass batch-mode digester nunc lab-tek co.
mode
ph meter thin. professional. hanna ph meter co.
multi ea® 5100 for micro-
total organic carbon meter analytik jena co.
elemental analysis
vertical floor-standing
autoclaves (top-loading) from
autoclave systec. v-series co.
40 to 150 liters chamber
volume
stainless steel bain marie
bain-marie mindiamart co.
(brand:ssfw), 220v
drying oven 125 basic dry (5 -
oven ika co.
250 centigrade degree )
electrical control circuit micro pragma schneider electric co.
fits 16mm or 13mm hach
chemical oxygen demand meter cod vials, test n tube vials hach co.
or tntplus™ vials
submersible pump sku: eco-185 lab society co.
sensor net connect
temperature sensor plug & track co.
temperature monitoring
pneumatic connections uniflex™ basic model broen–lab co.
steel with 403 grade and
electro thermal elements temperature threshold is equal iran element co.
to 400 °c
high pressure and temperature
gas storage bag nunc lab-tek co.
mode
high pressure and temperature
heat water tank nunc lab-tek co.
mode
the carbon dioxide created in
the fermenting process would
einhorn’s saccharometer rise to the top of the closed vwr co.
tube and force the level of
liquid down.
20 cc syringe standard plastic mode samen co.
193
194 2.4.lab-scale setup and experimental methodology
195 the schematic plan of biogas lab scale setup including mechanical devices, chemical sensors
196 and equipment and structural tools are depicted in fig. 6. also, the algorithm of experimental
197 methods in each run is illustrated in fig. 7.
198
199 fig. 6. schematic plan of bio-energy reactor in present study.
200 -
201
202 fig. 7. the algorithm of experimental methods in present study [39-41].
203 2.5.ccd-rsm model
204 in this study, ccd-rsm statistical model is used in design expert 7.0.0 software which it
205 determines sensitive analysis, optimum conditions and mathematical regression based
206 predictive model for energy supplying in green buildings. also, in the design of experiments
207 (doe), value of alpha is set in 1.2 amount [42]. the specifications of doe for each effective
208 parameter in this study is demonstrated in table 4. in this research accumulated biogas
209 (methane) production (abp) is assumed as a cost function (response) in ml unit. both sludge
210 and inoculum play role as bio-engine for degradation of food waste in biogas generation cycle.
211 but, in present investigation, the character of each one is separated for comparison of
212 wastewater treatment plant’s bacteria and clostridiales gas generation abilities. the key
213 parameters for experimentation are selected as per literature review evaluations in different
214 investigations [29-31, 39-41].
215 table 4. the variables and values used for biogas process optimization in ccd.
variables symbo coded factors level
unit -1.2
l +1 0 -1 1.2 (high)
(low)
sludge/waste mg/gr s/w 90 100 150 200 210
inoculum
(clostridiales/wast mg/gr c/w 6 10 30 50 54
e)
ph ____ ph 5.2 6 7 8 8.2
temperature °c t 6.5 25 35 45 48.5
time day t 6 10 30 50 54
216 after determination of optimum conditions, for creating smart controlling models petri net
217 [43] concept is utilized. in the declared model, each adjustable factor and conditional values
218 are put in place and transition functions, correspondingly. the algorithm of petri net modelling
219 design is shown in fig. 8.
220
221 fig. 8. schematic plan of petri net modelling in present study.
222 2.6.ai techniques
223 in the present study, for creating the predictive model as smart controlling systems, some
224 different machine learning computations such as ann [44], anfis [45], rt [46] and rf [47]
225 are used. for implementation of the mentioned algorithm matlab 2013 b and weka
226 software are performed which is described in table 5.
227 table 5. the ai computation specifications in present research.
method software conditions
multilayer perceptron and percentage split is set on
ann weka 3.9
90%
rt weka 3.9 cross-validation folds are set on 30
weka 3.9 and
rf percentage split is set on 80%
matlab 2018b®
sugeno, membership functions are three gaussian
anfis matlab 2018b® type 2, optim method and number of epochs are
selected equal to hybrid and 70, correspondingly.
228
229 3. results and discussions
230 3.1.optimization and experiments
231 the outcomes of experimental efforts as per analysis based on ccd-rsm technique are
232 summarized in table s.1. plus, the fitness of linear, 2fi, quadratic and cubic distributions have
233 illustrated that the r-squared and predicted r-squared of quadratic function is more acceptable in
234 comparison of other ones (table 6). according to table 6, quadratic model with 0.92 and 0.64 r-
235 squared and predicted r-squared can achieve the best outcomes in curve fitting aspect (equation
236 1). in mathematical viewpoint, quadratic model could satisfy abp (ml) according to effective
237 parameters containing s/w, c/w, ph, t and t. but, for prediction abp, the created statistical
238 model with 0.62 predicted r-squared cannot meet forecasting expectations. thus, for estimations
239 of abp, application of ai can be useful as an online soft monitoring system in detail of dss.
240 table 6. the results of mathematical models in ccd-rsm.
adjusted predicted
std. r-
source r- r- press
dev. squared
squared squared
linear 1518.185 0.20 0.119179 0.0187 1.26e+08
2fi 1647.652 0.28 -0.03745 0.18523 1.96e+08
quadratic 1125.946 0.92 0.515523 0.64 1.26e+08 suggested
cubic 867.7422 0.91 0.712247 -0.79628 2.3e+08 aliased
241 equation 1
242 abp = -46061.41463+126.90239 * s/w+85.91509 * c/w+9832.81639 * ph+237.44436 * t-
243 4.22495 * t-0.034750 * s/w * c/w-3.26625 * s/w * ph+0.026214 * s/w * t-0.10325 * s/w *
244 t-12.65625 * c/w * ph-0.23429 * c/w * t+1.04234 * c/w * t-0.81786 * ph * t-1.35625 * ph
245 *t+0.035000*t* t-0.29929 * (s/w)2-0.10317 * (c/w)2-612.44931* (ph)2-3.62682* (t)2+0.12339
246 * (t)2
247
248 the outputs of analysis of variance (anova) evaluations and sensitive analysis is demonstrated
249 in table 7 and fig. 9, respectively. with considering to table 7, the p-value of model and its lack
250 of fit are computed equal to less than 0.0001 (significant) and 0.1415 (not significant) respectively,
251 which it conveys high level of validity in achieved statistical model. also, according to table 7,
252 the p-value of both s/w and t factors are less than 0.0001. therefore, s/w and t have the most
253 significant effect on abp in comparison other ones. likewise, the f-value of s/w with 89.73
254 amount is more than t parameter (with 11.09) and it determines that s/w is the most important
255 parameter between all effective factors on abp. whereas, the least significant parameter is related
256 to t with 0.28 and 1.19 p-value and f-value correspondingly. the sensitive analysis of dual
257 effective parameters vs abp is illustrated in fig. 9. as per this fig., the most slope variations are
258 related to s/w and t factors which illustrate the influences of them on abp in comparison of other
259 ones.
260 table 7. the results of anova evaluation in ccd-rsm.
p-value
sum of mean
source df f value (prob >
squares square
f)
model 91455700 20 4572785 3.60 < 0.0001 significant
a-s/w 10235044 1 10235044 89.73 < 0.0001
b-c/w 1611124 1 1611124 1.27 0.26
c-ph 3700598 1 3700598 2.91 0.09
d-t 9741058 1 9741058 11.09 < 0.0001
e-t 1517780 1 1517780 1.19 0.28
ab 38642 1 38642 0.03 0.86
ac 853471.1 1 853471.1 0.67 0.41
ad 16836.13 1 16836.13 0.01 0.90
ae 341138 1 341138 0.27 0.60
bc 2050313 1 2050313 1.61 0.21
bd 215168 1 215168 0.17 0.68
be 5562780 1 5562780 4.38 0.04
cd 6555.125 1 6555.125 0.005 0.94
ce 23544.5 1 23544.5 0.018 0.89
de 4802 1 4802 0.003 0.95
a^2 2832988 1 2832988 2.23 0.14
b^2 8618.599 1 8618.599 0.006 0.93
c^2 1898166 1 1898166 1.49 0.23
d^2 6243064 1 6243064 4.92 0.03
e^2 12327.59 1 12327.59 0.009 0.92
residual 36764876 29 1267754
lack of not
32146334 22 1461197 2.21 0.14
fit significant
pure
4618542 7 659791.6
error
cor total 1.28e+08 49
261
262
263 (a) (b)
264
265 (c) (d)
266
267
268 (e) (f)
269
270
271 (g) (h)
272
273 (i) (j)
274 fig. 9. the sensitive analysis of effective parameters in ccd-rsm.
275 the normal plot of residuals is demonstrated in fig. s.1 which shows distribution of abp’s
276 results in neighborhood of normal diagram. so, the results of experimental activities follow
277 normal statistical distributions in different runs. the five suggested optimum conditions based
278 on ccd-rsm computations are summarized in table 8. according to declared table,
279 optimum values of s/w, c/w, ph, t and t are equal to 163 mg/g, 54 mg/g, 7, 30 °c and 55
280 days, respectively. also, the mentioned suggestions are examined in lab scale setup with three
281 repetitions and 6310.2 ml, 6282.3 ml and 6325.1 are measured as experimental outputs. while,
282 the mean value of predicted abp with 6259.96 ml has 99.6% accuracy with mean value of
283 experimental results (with 6306.1 ml). desirability of mathematical prediction outcomes vs
284 variations of s/w and c/w is illustrated in fig. s.2.
285 table 8. the outcomes of optimum conditions in ccd-rsm.
experimental experimental experimental
predicted outcomes outcomes outcomes
number s/w c/w ph t t
abp (ml) repetition 1- repetition 2- repetition 3-
abp (ml) abp (ml) abp (ml)
1 163.1 54 6.97 31.02 55 6261.1
2 163.69 54 6.98 30.88 52 6260.3
3 161.76 54 6.99 31 54 6260.2 6310.2 6282.6 6325.5
4 161.45 54 6.93 30.73 51 6259.8
5 163.08 54 6.92 30.33 53 6258.4
286
287 3.2.smart control systems
288 in the followings, experimental outcomes modeled by ann, rf and rt machine learning
289 algorithms which is shown in table 9. as per the mentioned soft computing systems, the most
290 accuracy with 0.93 correlation coefficient is related to rt algorithm. plus, ann and rf algorithms
291 are in the next places with 0.91 and 0.87 correlation coefficients, respectively. also, plot matrix of
292 input and output data is demonstrated in fig. s.3. the computational rt algorithm and rt
293 conceptual model are demonstrated in equation s.1 and fig. 10, respectively. with following this
294 tree, abp of each fabulous condition can be predicted as a soft sensor.
295 table 9. the statistical outcomes of ann, rf and rt algorithms in present research.
statistical parameters ann rf rt
correlation coefficient 0.91 0.87 0.93
mean absolute error 890.97 1070.74 755.6
root mean squared error 952.41 1207.11 870.98
relative absolute error 51.58% 58.21% 43.74%
root relative squared error 49.94% 61.23% 45.67%
total number of instances 5 10 5
296
297
298 fig. 10. the rt conceptual model in present study.
299 the confusion matrix and parallel coordinates plot of rf algorithm are illustrated in fig. 11 and
300 s.4, correspondingly. according to fig. 11, the population of positive predictive value is more
301 than negative predictive value which demonstrates validity of rf computations in this research.
302 also, the parallel coordinates plot depicts the high level of correct predictions for abp values as
303 per effective parameters. with focusing on fig. s.4, staccato lines (as an incorrect prediction)
304 cannot be seen in comparison of allied lines (as a correct estimation).
305
306 fig. 11. the confusion matrix of rf algorithm in present study.
307 structural of anfis model for smart estimation of abp as per s/w, c/w, ph, t and t with 3
308 membership functions is depicted in fig. 12. also, adaption of training data and fis outputs is
309 declared in figs. s.5-6 and table 10 which accent to high level of accuracy in anfis
310 computations. likewise, duo to evaluation of significant degree in each effective parameter for
311 abp the dual sensitive analysis of anfis calculation algorithm is demonstrated in fig. 13.
312 with regard to fig.13, it is clear that s/w and t parameters have the most slope variations on
313 the 3d plots and this indicates the high degree of importance of these factors in comparison of
314 other parameters.
315
316
317 fig. 12. structural anfis computational algorithm in present study.
318 table 10. the statistical outcomes of anfis algorithm in present research.
regression statistics
multiple r 0.981825
r square 0.96398
adjusted r square 0.963229
standard error 310.1929
observations 50
319
320 (a)
321
322 (b)
323
324 (c)
325
326 (d)
327
328 (e)
329
330 (f)
331
332 (g)
333
334 (h)
335
336 (i)
337
338 (j)
339 fig. 13. the sensitive analysis of effective parameters in anfis model.
340 for creating dss for smart controlling of bio-energy supplying, petri net modelling with
341 combination of ccd-rsm optimization are utilized. the invented smart model for bio-energy
342 management is depicted in fig. 14. in the mentioned smart system, all effective parameters
343 containing s/w, c/w, ph, t and t are set on optimum conditions and they check and modify
344 sequentialy until to adjust in appropriate value throught a loop. also, the mentioned concep first,
345 evaluate s/w and t because of their significant effects on abp in the parallel lines. then, in the
346 other series, ph (souring control plan in the biogas system [48]) and s/w are controlled and
347 adjusted. finally, time of reaction as the least important factor is checked and justified. with
348 application of petri net modelling according to fig. 14, optimum conditions of biogas generation
349 system can be controlled smartly.
350
351 fig. 14. the petri net modelling in present study.
352 3.3.green building approach
353 the results of present research have illustrated that with the role of sludge-based bacteria is more
354 significant than clostridiales. for scrutinizing the mentioned result, the experimental setup is
355 appraised in a run without sludge and in the other one without clostridiales. in each run, all
356 effective parameters are set in optimum conditions, just, sludge and clostridiales injecting are
357 eliminated in determined tests. the output of daily and accumulated biogas/methane vs time
358 variations is illustrated as per fig. 15. according to fig. 15, with application of sludge (without
359 clostridiales) biogas and methane production are around twice as much as biogas production with
360 clostridiales (without sludge) during 55-day retention time. one of the main achievements in this
361 research was linked to presenting smart model for dynamic integrated management of sludge and
362 clostridiales bio-engines in the same time.
363 in the following, the recent investigations approved that 99% of biogas productions including
364 methane and carbon dioxide [49-52]. also, the nutrients (nitrogen and phosphor) and active
365 anaerobic microorganisms are provided by injected sludge from secondary clarifier tank in sbr.
366 thus, in the alone clostridiales bioreactor the efficiency of anaerobic digester is reduced because
367 of less nutrient and active microorganisms’ values [53]. likewise, the variation of toc, cod and
368 total alkaline of food wastes in both bioreactors (with clostridiales and sludge) are illustrated in
369 fig. 16. according to this fig., the organic matter digestion rate of sludge-based system is more
370 than clostridiales based bioreactor which is related to biodegradation ability of sludge-based
371 microorganisms [54]. the alkalinity increasing in both reactors can be related to protein and amino
372 acid biodegradation in the sequential reactions (equation 3) [55]. while, in sludge-based system,
373 rate of biodegradation is more than alone clostridiales system and therefore, the amounts of total
374 alkaline is increased in the declared system.
375 equation 3
376 nh + h o + co ® nh + + hco -
3 2 2 4 3
7000
)lm(
6000
enahtem/sagoib/pba 5000
4000
3000
2000
1000
0
0 10 20 30 40 50 60
time (day)
biogas (ml)-sludge based (daily)
abp (ml)-sludge based
methane (ml)-sludge based (daily)
accumulated methane (ml)-sludge based
377
378 (a)
4000
)lm(
3500
enahtem/sagoib/pba)l/gm( 3000
2500
2000
1500
1000
500
0
0 10 20 30 40 50 60
time (day)
biogas (ml)-clostridiales based (daily)
abp (ml)-clostridiales based
methane (ml)-clostridiales based (daily)
accumulated methane (ml)-clostridiales based
379
380 (b)
381 fig. 15. daily and accumulated biogas/methane production in (a) sludge based system and
382 (b) clostridiales based system.
7000
6000
5000
4000
cot 3000
2000
1000
0
0 10 20 30 40 50 60
time (day)
toc-sludge based (mg/l c) toc-clostridiales based (mg/l c)
383
384 (a)
20000
18000
16000
14000
)l/gm(
12000
10000
doc)3ocac
8000
6000
4000
2000
0
0 10 20 30 40 50 60
time (day)
cod-sludge based (mg/l) cod-clostridiales based (mg/l)
385
386 (b)
6000
5000
l/gm( 4000
3000
enilakla
2000
1000
latot
0
0 10 20 30 40 50 60
time (day)
total alkaline - sludge based (mg/l caco3)
total alkaline -clostridiales based (mg/l caco3)
387
388 (c)
389 fig. 16. efficiency of sludge and clostridiales based systems for food waste biodegradation
390 as per (a) toc (b) cod and (c) total alkaline fluctuations.
391 as a result, it is clear that integration of sbr’s sludge and clostridiales can enhance the efficiency
392 of bio-reactor in this study. also, as can be seen in table s.1, the integrated bioreactor has the
393 acceptable efficiency in the low retention time and temperature which is affected by dual bio-
394 engine activities in the same time [56]. in the last part of this research, pattern of energy production
395 according to circular economy [57], industry ecology (ie) [58], integrated solid waste
396 management (iswm) [59] and sustainable development goals (sdgs) [60] is illustrated in fig.
397 17. whereas, the digested food waste is biogas generation procedure can be useful as a fertilizer
398 [61,62]. as per fig. 17, the electrical energy generation of biogas system in present research can
399 supply all energy demand based on fig. 4. also, the produced energy can be utilized for heat
400 demand with 3051 mj in 55-day (one operating duration) as a bio-energy supplying in green
401 buildings. finally, the digested organic materials with 310 mg/l cod value is appropriate for
402 green environmental supporting in residential complex in the case study. also, with considering
403 to fig. 4, the energy demand of case study is ranged 250 – 350 kwh/month and based on the
404 achievements of present study, the available biogas energy is around 175 kwh/month (by 40%
405 efficiency [63]). therefore, around 50% of energy demand in the case study can be provided by
406 biogas production in the present study.
407
408 fig. 17. the conceptual model of ce, iswm and sdgs for implementation of green buildings in
409 present investigation.
410
411 4. conclusion
412 food wastes have high level of variety in forming compositions containing proteins, fatty acids,
413 carbohydrates, vitamins and other organic matters that they can product considerable
414 biogas/methane through anaerobic digestion process. the declared technique is so beneficial for
415 waste management and bio-energy supplying in the same time as a novel approach in green
416 buildings. one of the main concerns about application of biological process in energy supplying
417 is related to complexity of operation. therefore, combination of smart controlling soft systems
418 with biodegradation techniques can cover the weakness of bio-systems.
419 the main experimental, numerical and simulation practices in present research including:
420 - preparing lab-scale setup for anaerobic digestion of food wastes with sbr’s sludge and
421 clostridiales microorganisms.
422 - optimizing and sensitive analyzing effective parameters by ccd-rsm technique.
423 - implementation of smart system with four soft computing techniques containing rt, rf,
424 ann and anfis.
425 - creating dynamic control system for adjusting effective parameters with petri net
426 modelling.
427 - assessment of sbr’s sludge and clostridiales on food waste anaerobic digestion in
428 separated reactors.
429 - presenting conceptual model as a ce platform for green buildings.
430 in the following, as per all experimental and computational efforts the main outcomes are listed
431 below.
432 • optimum values of s/w, c/w, ph, t and t are computed equal to 163 mg/g, 54 mg/g, 7,
433 30 °c and 55 days, respectively based on ccd-rsm optimization.
434 • the most significand effective factors on abp/methane production are s/w and t with
435 less than 0.0001 p-value according to anova calculations.
436 • the correlation coefficient of rt, rf, ann and anfis computations are equal to 0.93,
437 0.87, 0.91 and 0.99 values. therefore, anfis model has the best precision for abp
438 forecasting in dss.
439 • in the petri net model, controlling s/w and t is prioritized in comparison of other
440 parameters because of their p-value and f-value amounts.
441 • the efficiency of sbr’s sludge is more than clostridiales based bioreactor because of
442 nutrient availability and activity of microorganisms. in the same conditions, methane
443 production of sludge-based bioreactor 42% is more than other one.
444 • with performing bio-energy supplying 381 kwh (3051 mj) can be obtained that is enough
445 for electrical energy demand or heat energy consumption.
446
447 references:
448 1- mojtahedi, m., fathollahi-fard, a.m., tavakkoli-moghaddam, r. and newton, s., 2021.
449 sustainable vehicle routing problem for coordinated solid waste management. journal of
450 industrial information integration, 23, p.100220.
451 2- eftekhari, m., gheibi, m., azizi-toupkanloo, h., hossein-abadi, z., khraisheh, m.,
452 fathollahi-fard, a.m. and tian, g., 2021. statistical optimization, soft computing prediction,
453 mechanistic and empirical evaluation for fundamental appraisal of copper, lead and malachite
454 green adsorption. journal of industrial information integration, 23, p.100219.
455 3- ali, s.m., paul, s.k., chowdhury, p., agarwal, r., fathollahi-fard, a.m., jabbour, c.j.c. and
456 luthra, s., 2021. modelling of supply chain disruption analytics using an integrated approach:
457 an emerging economy example. expert systems with applications, 173, p.114690.
458 4- theophilus, o., dulebenets, m.a., pasha, j., lau, y.y., fathollahi-fard, a.m. and mazaheri,
459 a., 2021. truck scheduling optimization at a cold-chain cross-docking terminal with product
460 perishability considerations. computers & industrial engineering, 156, p.107240.
461 5- pasha, j., dulebenets, m.a., fathollahi-fard, a.m., tian, g., lau, y.y., singh, p. and liang,
462 b., 2021. an integrated optimization method for tactical-level planning in liner shipping with
463 heterogeneous ship fleet and environmental considerations. advanced engineering
464 informatics, 48, p.101299.
465 6- zhang, c., fathollahi-fard, a.m., li, j., tian, g. and zhang, t., 2021. disassembly sequence
466 planning for intelligent manufacturing using social engineering optimizer. symmetry, 13(4),
467 p.663.
468 7- islam, m.r., ali, s.m., fathollahi-fard, a.m. and kabir, g., 2021. a novel particle swarm
469 optimization-based grey model for the prediction of warehouse performance. journal of
470 computational design and engineering, 8(2), pp.705-727.
471 8- cai, w., yang, k., wu, l., huang, g., santoso, a., ng, b., wang, g. and yamagata, t., 2021.
472 opposite response of strong and moderate positive indian ocean dipole to global warming.
473 nature climate change, 11(1), pp.27-32.
474 9- noorollahi, y., janalizadeh, h., yousefi, h. and jahangir, m.h., 2021. biofuel for energy self-
475 sufficiency in agricultural sector of iran. sustainable energy technologies and assessments,
476 44, p.101069.
477 10- more, m., agrawal, c., sharma, d., rathore, n. and samar, k., 2021. development of pellet
478 machine for utilization of biogas slurry. in advances in engineering design (pp. 509-519).
479 springer, singapore.
480 11- tagne, r.f.t., dong, x., anagho, s.g., kaiser, s. and ulgiati, s., 2021. technologies,
481 challenges and perspectives of biogas production within an agricultural context. the case of
482 china and africa. environment, development and sustainability, pp.1-28.
483 12- de sousa, m.h., da silva, a.s.f., correia, r.c., leite, n.p., bueno, c.e.g., dos santos
484 pinheiro, r.l., de santana, j.s., da silva, j.l., sales, a.t., de souza, c.c. and da silva aquino,
485 k.a., 2021. valorizing municipal organic waste to produce biodiesel, biogas, organic fertilizer,
486 and value-added chemicals: an integrated biorefinery approach. biomass conversion and
487 biorefinery, pp.1-15.
488 13- chen, t., qiu, x., feng, h., yin, j. and shen, d., 2021. solid digestate disposal strategies to
489 reduce the environmental impact and energy consumption of food waste-based biogas systems.
490 bioresource technology, 325, p.124706.
491 14- yong, z.j., bashir, m.j. and hassan, m.s., 2021. biogas and biofertilizer production from
492 organic fraction municipal solid waste for sustainable circular economy and environmental
493 protection in malaysia. science of the total environment, 776, p.145961.
494 15- su, b., wang, h., zhang, x., he, h. and zheng, j., 2021. using photovoltaic thermal
495 technology to enhance biomethane generation via biogas upgrading in anaerobic digestion.
496 energy conversion and management, 235, p.113965.
497 16- sarkar, o., santhosh, j., dhar, a. and mohan, s.v., 2021. green hythane production from food
498 waste: integration of dark-fermentation and methanogenic process towards biogas up-
499 gradation. international journal of hydrogen energy, 46(36), pp.18832-18843.
500 17- avila, r., carrero, e., vicent, t. and blánquez, p., 2021. integration of enzymatic pretreatment
501 and sludge co-digestion in biogas production from microalgae. waste management, 124,
502 pp.254-263.
503 18- dinnebier, h.c.f., matthiensen, a., michelon, w., tápparo, d.c., fonseca, t.g., favretto, r.,
504 steinmetz, r.l.r., treichel, h., antes, f.g. and kunz, a., 2021. phycoremediation and
505 biomass production from high strong swine wastewater for biogas generation improvement:
506 an integrated bioprocess. bioresource technology, 332, p.125111.
507 19- boffardi, r., de simone, l., de pascale, a., ioppolo, g. and arbolino, r., 2021. best-
508 compromise solutions for waste management: decision support system for policymaking.
509 waste management, 121, pp.441-451.
510 20- kim, s., mostafa, a., im, s., lee, m.k., kang, s., na, j.g. and kim, d.h., 2021. production
511 of high-calorific biogas from food waste by integrating two approaches: autogenerative high-
512 pressure and hydrogen injection. water research, 194, p.116920.
513 21- ajieh, m.u., isagba, e.s., ihoeghian, n., edosa, v.i., amenaghawon, a., oshoma, c.e.,
514 erhunmwunse, n., obuekwe, i.s., tongo, i., emokaro, c. and ezemonye, l.i., 2021.
515 assessment of sociocultural acceptability of biogas from faecal waste as an alternative energy
516 source in selected areas of benin city, edo state, nigeria. environment, development and
517 sustainability, pp.1-18.
518 22- chowdhury, h., chowdhury, t., miskat, m.i., hossain, n., chowdhury, p. and sait, s.m.,
519 2021. potential of biogas and bioelectricity production from rohingya camp in bangladesh: a
520 case study. energy, 214, p.118837.
521 23- llano, t., arce, c. and finger, d.c., 2021. optimization of biogas production through
522 anaerobic digestion of municipal solid waste: a case study in the capital area of re ykjavik,
523 iceland. journal of chemical technology & biotechnology, 96(5), pp.1333-1344.
524 24- cavaignac, r.s., ferreira, n.l. and guardani, r., 2021. techno-economic and environmental
525 process evaluation of biogas upgrading via amine scrubbing. renewable energy, 171, pp.868-
526 880.
527 25- miranda, i.t.p., moletta, j., pedroso, b., pilatti, l.a. and picinin, c.t., 2021. a review on
528 green technology practices at brics countries: brazil, russia, india, china, and south
529 africa. sage open, 11(2), p.21582440211013780.
530 26- niu, s., dai, r., zhong, s., wang, y., qiang, w. and dang, l., 2021. multiple benefit
531 assessment and suitable operation mechanism of medium-and large-scale biogas projects for
532 cooking fuel in rural gansu, china. sustainable energy technologies and assessments, 46,
533 p.101285.
534 27- abanades, s., abbaspour, h., ahmadi, a., das, b., ehyaei, m.a., esmaeilion, f., assad,
535 m.e.h., hajilounezhad, t., jamali, d.h., hmida, a. and ozgoli, h.a., 2021. a critical review
536 of biogas production and usage with legislations framework across the globe. international
537 journal of environmental science and technology, pp.1-24.
538 28- lomazov, v.a., lomazova, v.i., miroshnichenko, i.v., petrosov, d.a. and mironov, a.l.,
539 2021, february. optimum planning of experimental research at the biogas plant. in iop
540 conference series: earth and environmental science (vol. 659, no. 1, p. 012111). iop
541 publishing.
542 29- stürmer, b., leiers, d., anspach, v., brügging, e., scharfy, d. and wissel, t., 2021.
543 agricultural biogas production: a regional comparison of technical parameters. renewable
544 energy, 164, pp.171-182.
545 30- jung, s., lee, j., moon, d.h., kim, k.h. and kwon, e.e., 2021. upgrading biogas into syngas
546 through dry reforming. renewable and sustainable energy reviews, 143, p.110949.
547 31- akbulut, a., arslan, o., arat, h. and erbaş, o., 2021. important aspects for the planning of
548 biogas energy plants: malatya case study. case studies in thermal engineering, 26, p.101076.
549 32- brémond, u., bertrandias, a., de buyer, r., latrille, e., jimenez, j., escudié, r., steyer, j.p.,
550 bernet, n. and carrere, h., 2021. recirculation of solid digestate to enhance energy efficiency
551 of biogas plants: strategies, conditions and impacts. energy conversion and management, 231,
552 p.113759.
553 33- naquash, a., qyyum, m.a., haider, j., lim, h. and lee, m., 2021. renewable lng
554 production: biogas upgrading through co2 solidification integrated with single-loop mixed
555 refrigerant biomethane liquefaction process. energy conversion and management, 243,
556 p.114363.
557 34- zhang, j., gu, d., chen, j., he, y., dai, y., loh, k.c. and tong, y.w., 2021. assessment and
558 optimization of a decentralized food-waste-to-energy system with anaerobic digestion and
559 chp for energy utilization. energy conversion and management, 228, p.113654.
560 35- wu, t., bu, s., wei, x., wang, g. and zhou, b., 2021. multitasking multi-objective operation
561 optimization of integrated energy system considering biogas-solar-wind renewables. energy
562 conversion and management, 229, p.113736.
563 36- su, b., wang, h., zhang, x., he, h. and zheng, j., 2021. using photovoltaic thermal
564 technology to enhance biomethane generation via biogas upgrading in anaerobic digestion.
565 energy conversion and management, 235, p.113965.
566 37- hansen, a.d., sorensen, p., hansen, l.h. and bindner, h., 2000. models for a stand-alone pv
567 system. roskilde: rio national laboratory.
568 38- sulaeman, s., brown, e., quispe-abad, r. and müller, n., 2021. floating pv system as an
569 alternative pathway to the amazon dam underproduction. renewable and sustainable energy
570 reviews, 135, p.110082.
571 39- lohani, s.p., shakya, s., gurung, p., dhungana, b., paudel, d. and mainali, b., 2021.
572 anaerobic co-digestion of food waste, poultry litter and sewage sludge: seasonal performance
573 under ambient condition and model evaluation. energy sources, part a: recovery, utilization,
574 and environmental effects, pp.1-16.
575 40- ziaee, f., mokhtarani, n. and niavol, k.p., 2021. solid-state anaerobic co-digestion of organic
576 fraction of municipal waste and sawdust: impact of co-digestion ratio, inoculum-to-substrate
577 ratio, and total solids. biodegradation, pp.1-14.
578 41- guo, z., usman, m., alsareii, s.a., harraz, f.a., al-assiri, m.s., jalalah, m., li, x. and
579 salama, e.s., 2021. synergistic ammonia and fatty acids inhibition of microbial communities
580 during slaughterhouse waste digestion for biogas production. bioresource technology,
581 p.125383.
582 42- eftekhari, m., gheibi, m., azizi-toupkanloo, h., hossein-abadi, z., khraisheh, m.,
583 fathollahi-fard, a.m. and tian, g., 2021. statistical optimization, soft computing prediction,
584 mechanistic and empirical evaluation for fundamental appraisal of copper, lead and malachite
585 green adsorption. journal of industrial information integration, 23, p.100219.
586 43- gheibi, m., karrabi, m. and eftekhari, m., 2019. designing a smart risk analysis method for
587 gas chlorination units of water treatment plants with combination of failure mode effects
588 analysis, shannon entropy, and petri net modeling. ecotoxicology and environmental safety,
589 171, pp.600-608.
590 44- amini, m.h., arab, m., faramarz, m.g., ghazikhani, a. and gheibi, m., 2021. presenting a
591 soft sensor for monitoring and controlling well health and pump performance using machine
592 learning, statistical analysis, and petri net modeling. environmental science and pollution
593 research, pp.1-17.
594 45- mohammadi, m., gheibi, m., fathollahi-fard, a.m., eftekhari, m., kian, z. and tian, g.,
595 2021. a hybrid computational intelligence approach for bioremediation of amoxicillin based
596 on fungus activities from soil resources and aflatoxin b1 controls. journal of environmental
597 management, 299, p.113594.
598 46- ghadami, n., gheibi, m., kian, z., faramarz, m.g., naghedi, r., eftekhari, m., fathollahi-
599 fard, a.m., dulebenets, m.a. and tian, g., 2021. implementation of solar energy in smart
600 cities using an integration of artificial neural network, photovoltaic system and classical delphi
601 methods. sustainable cities and society, 74, p.103149.
602 47- ghadirimoghaddam, d., gheibi, m. and eftekhari, m., 2021. graphene oxide-cyanuric acid
603 nanocomposite as a novel adsorbent for highly efficient solid phase extraction of pb2+
604 followed by electrothermal atomic absorption spectrometry; statistical, soft computing and
605 mechanistic efforts. international journal of environmental analytical chemistry, pp.1-22.
606 48- latifi, p., karrabi, m. and danesh, s., 2019. anaerobic co-digestion of poultry slaughterhouse
607 wastes with sewage sludge in batch-mode bioreactors (effect of inoculum-substrate ratio and
608 total solids). renewable and sustainable energy reviews, 107, pp.288-296.
609 49- rajendran, k., aslanzadeh, s. and taherzadeh, m.j., 2012. household biogas digesters—a
610 review. energies, 5(8), pp.2911-2942.
611 50- abatzoglou, n. and boivin, s., 2009. a review of biogas purification processes. biofuels,
612 bioproducts and biorefining, 3(1), pp.42-71.
613 51- mao, c., feng, y., wang, x. and ren, g., 2015. review on research achievements of biogas
614 from anaerobic digestion. renewable and sustainable energy reviews, 45, pp.540-555.
615 52- kougias, p.g. and angelidaki, i., 2018. biogas and its opportunities—a review. frontiers of
616 environmental science & engineering, 12(3), pp.1-12.
617 53- jiang, x., sommer, s.g. and christensen, k.v., 2011. a review of the biogas industry in china.
618 energy policy, 39(10), pp.6073-6081.
619 54- černý, m., vítězová, m., vítěz, t., bartoš, m. and kushkevych, i., 2018. variation in the
620 distribution of hydrogen producers from the clostridiales order in biogas reactors depending
621 on different input substrates. energies, 11(12), p.3270.
622 55- metcalf & eddy, abu-orf, m., bowden, g., burton, f.l., pfrang, w., stensel, h.d.,
623 tchobanoglous, g., tsuchihashi, r. and aecom (firm), 2014. wastewater engineering:
624 treatment and resource recovery. mcgraw hill education.
625 56- song, j.l., ruan, z.y., hu, g.q., jiang, r.b., liu, x.f. and xu, f.h., 2010. microbial
626 diversity and community composition in biogas sludge and its enriched product. china biogas,
627 28(2), pp.3-11.
628 57- kapoor, r., ghosh, p., kumar, m., sengupta, s., gupta, a., kumar, s.s., vijay, v., kumar,
629 v., vijay, v.k. and pant, d., 2020. valorization of agricultural waste for biogas based circular
630 economy in india: a research outlook. bioresource technology, 304, p.123036.
631 58- makisha, n., 2016. waste water and biogas–ecology and economy. procedia engineering, 165,
632 pp.1092-1097.
633 59- anyaoku, c.c. and baroutian, s., 2018. decentralized anaerobic digestion systems for
634 increased utilization of biogas from municipal solid waste. renewable and sustainable energy
635 reviews, 90, pp.982-991.
636 60- lohani, s.p., dhungana, b., horn, h. and khatiwada, d., 2021. small-scale biogas technology
637 and clean cooking fuel: assessing the potential and links with sdgs in low-income countries–
638 a case study of nepal. sustainable energy technologies and assessments, 46, p.101301.
639 61- sogn, t.a., dragicevic, i., linjordet, r., krogstad, t., eijsink, v.g. and eich-greatorex, s.,
640 2018. recycling of biogas digestates in plant production: npk fertilizer value and risk of
641 leaching. international journal of recycling of organic waste in agriculture, 7(1), pp.49-58.
642 62- liang, f., xu, l., ji, l., he, q., wu, l. and yan, s., 2021. a new approach for biogas slurry
643 disposal by adopting co2-rich biogas slurry as the flower fertilizer of spathiphyllum:
644 feasibility, cost and environmental pollution potential. science of the total environment,
645 770, p.145333.
646 63- hakawati, r., smyth, b.m., mccullough, g., de rosa, f. and rooney, d., 2017. what is the
647 most energy efficient route for biogas utilization: heat, electricity or transport?. applied
648 energy, 206, pp.1076-1087.
649"
